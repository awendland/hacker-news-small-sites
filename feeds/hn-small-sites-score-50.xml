<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Wed, 09 Dec 2020 01:09:46 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Wed, 09 Dec 2020 01:09:46 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[My Procedurally Generated Music Is Awful]]>
            </title>
            <description>
<![CDATA[
Score 82 | Comments 88 (<a href="https://news.ycombinator.com/item?id=25327533">thread link</a>) | @mproud
<br/>
December 6, 2020 | https://devlog.groovelet.com/p/procedurally-generated-music-is-awful | <a href="https://web.archive.org/web/*/https://devlog.groovelet.com/p/procedurally-generated-music-is-awful">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><blockquote><p>"I don't think that this could ever create something that I wouldn't mute" </p><p><em>- Voxel, laying down the hard truths about music generation in general and my music generator in specific</em></p></blockquote><p>In groovelet32.exe, I’d like for the art assets to be capable of wiggling and booping in time with the music. </p><p>That’s seemingly simple sounding, but that simple idea contains, uh, <em>multitudes</em>.</p><p>This can be accomplished in one of a few different ways: </p><ol><li><p>Buy, commission, or write music, transcribe the music whole into the execution environment and play the music with locally available music generation tools (Tone.js in JavaScript, Helm or wwise in Unity) </p></li><li><p>Buy, commission, or write music, transcribe important moments in written music into software language, have instrument hits trigger effects.</p></li><li><p>Buy, commission, or write music, use automated analysis (Koreographer in Unity) to guess when dynamics are occcuring in the music and use those to trigger effects.</p></li><li><p>Buy, commission, or write music, output music as midi, play music while using midi engine to drive effects. </p></li><li><p>Generate music entirely in place, have instrument hits directly trigger effects.</p></li></ol><p>Each strategy has its ups and downs. Notably, the first four strategies start with the simple-sounding but imposing “buy, commission, or write music”. Buying music - well, it’s hard to build a whole game around stock music - especially if music is as fundamental to the experience as it should be in a game about musical robots. </p><p>Commissioning music is simply too expensive, if I’m planning on paying my composer fairly (which I would be, if I had any money).</p><p>Writing music on my own would imply a strong upgrade in my own personal music production skills, because currently I’m operating at somewhere near the “Three Blind Mice” level. A number of my family members are talented musically - my younger brother married into a “music teacher” family - but I don’t think any of them have ever cracked open a <a href="https://en.wikipedia.org/wiki/Digital_audio_workstation">DAW</a>, and they’re pretty busy with their own lives, so that’s a hard tree to shake and expect that video-game ready tunes will fall out.</p><p>So that leaves me with <strong>procedurally generated music</strong>. It’s perhaps naive to think that I, a person who can’t even write a regular song, could build a computer that could write music for me, but hey - if I’m good at anything¹ , it’s programming.</p><h2>A Basic Architecture for Procgen Music</h2><p>Some time back, I watched this inspiring JSConf talk: </p><p id="youtube2-_0ij8vY2gzE" data-attrs="{&quot;videoId&quot;:&quot;_0ij8vY2gzE&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}"><iframe src="https://www.youtube-nocookie.com/embed/_0ij8vY2gzE?rel=0&amp;autoplay=0&amp;showinfo=0" frameborder="0" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true"></iframe></p><p><em>so cool</em></p><p><strong>tl;dr</strong> “we built a tool called <a href="https://magenta.tensorflow.org/js-announce">Magenta.js</a> that allows you to tensorflow up some tunes”</p><p>I like tensorflow! I like tunes!</p><p>Setting upon the task with some zeal I managed to get Magenta.js generating tunes, slowly. I had a simple plan for how I would take slowly-generated 8-second tunes and convert them into longer songs:</p><ol><li><p>Have a background server process generate 8-second three-part-tune clips</p></li><li><p>Use some basic heuristics to guess at the key signature (“C# major”) of the clips, evaluate their intensity (lots of drum hits? loads of notes?) and save them in a huge clip database.</p></li><li><p>Create a search interface for the clip database.</p></li><li><p>Have the client request clips from the server in a specific key and intensity.</p></li><li><p>Weave two or three clips together, repeating them a couple of times, to make a full “song”.</p></li><li><p>Add tools to control the requested key signature, intensity, and change instrument, tempo, and what-have-you at the last second.</p></li><li><p>Take the output and make it sound like real human music that people would listen to on purpose.</p></li></ol><p>Now, there are some definite problems with this scheme. One of them is <a href="https://tonejs.github.io/">Tone.js</a> - an unbelievably powerful synth workbench written for people who have read<a href="http://msp.ucsd.edu/techniques/latest/book-html/"> the entire book on Digital Signal Processing</a>, and <em>no other people</em>.</p><p>I actually took and passed a senior-level course in DSP for music generation, some 12 years ago. I have less of an excuse than the average person to be absolutely garbage at attaching oscillators to things. I’m still garbage, mind you, I just have less of an excuse.</p><p>Anyways, after some serious effort, I got steps 1-6 working.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fca1c57c1-7653-4b87-af3b-44ec32498063_624x749.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fca1c57c1-7653-4b87-af3b-44ec32498063_624x749.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/ca1c57c1-7653-4b87-af3b-44ec32498063_624x749.png&quot;,&quot;height&quot;:749,&quot;width&quot;:624,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:41766,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>Look at that! Sliders! Tempo! Intensity! Configurable per-channel instruments and levels! </p><div><p>Here’s the first song that ever sounded remotely passable, produced by the system.</p><p>It’s… <em>okay</em>, right? Not <em>bad</em>. That’s where the system was a year ago.</p></div><p>Here’s another song from just a few days ago: </p><div><p>Admittedly, I haven’t been working on the procgen engine for that entire year, but it hasn’t evolved much in the interim, huh?</p><p>I figured I might be able to shape the musicality of the output with simple heuristic rules and adjustments and embellishments, but - I can’t. An extremely talented musician/producer might be able to, but as we’ve established, I’m worse at finding C than <a href="https://www.youtube.com/watch?v=VCr91EwGGxk">the salty pirates of landlocked Saskatchewan</a>. </p></div><p>Most of my clever changes would make the output sound better… some of the time. And worse, some of the time. Sometimes, rarely, the system produces something that, if you weren’t paying a terrible lot of attention, you might confuse for real music. A lot of the time it produces something bland and amusical. About as often it produces something <em>actively unpleasant</em>.</p><p>One idea I’ve had is building an underlying voting system to try to clear “bad” tunes out of the system - if my music generation system is actually powered by a thousand clips that sound pretty good under most any circumstances because all of the ones that sound bad have been downvoted out of existence, well, that’s one way of doing things.</p><p>But even at it’s best, the output isn’t… terribly good. </p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Faa2c453a-e28c-4d54-8a6f-02ea23b50ff9_534x577.webp"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Faa2c453a-e28c-4d54-8a6f-02ea23b50ff9_534x577.webp" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/aa2c453a-e28c-4d54-8a6f-02ea23b50ff9_534x577.webp&quot;,&quot;height&quot;:577,&quot;width&quot;:534,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:138006,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/webp&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><div><p>And a big part of the problem is just that composing music is <em>hard</em>. If you take the simplest musical style that you can think of, there’s someone online explaining in painful detail that the soundtrack to Fart Chalice IV <em>actually</em> takes advantage of phrygian pentameter and post-modern phrasing to create artificial dissonance between the fourth and sixteenth notes in an alternating jazz-inspired progression.</p><p>I can just <em>barely</em> read music. I can’t deal with that! </p></div><p>There isn’t a simple set of rules for what will sound good when music is involved - people are too different from one another. There are dozens of conflicting sets of rules, and because there are so many ways to break those rules and still have music come out sounding good (or follow the rules and still have music come out sounding bad) a lot of music theory isn’t so much “helpful guidelines” as it is “endless taxonomy”, and most of that taxonomy has been compiled over the last 500 years by mostly Germans and Italians.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F3797b22b-8653-4a82-8325-0fd59ade6bf0_960x960.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F3797b22b-8653-4a82-8325-0fd59ade6bf0_960x960.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/3797b22b-8653-4a82-8325-0fd59ade6bf0_960x960.jpeg&quot;,&quot;height&quot;:960,&quot;width&quot;:960,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:125325,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p><em>I am literally more afraid of music theory than digital signal processing.</em></p><h2>The Many Flaws of Procedural Generation</h2><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F1401d2c0-9c56-43ff-acbd-d29f26cc11c0_331x500.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F1401d2c0-9c56-43ff-acbd-d29f26cc11c0_331x500.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/1401d2c0-9c56-43ff-acbd-d29f26cc11c0_331x500.jpeg&quot;,&quot;height&quot;:500,&quot;width&quot;:331,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:41426,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>I love this book. I’ve read it cover-to-cover, more than once. Even the chapter on music generation - the author cleverly chose a scheme where they fudged it by picking a pentatonic scale where everything sounds pretty nice together and then bonking around pretty-much randomly. (A lot of procedurally generated/input driven music uses a technique like this).</p><p>It’s packed with cool ideas involving graphs and rules engines and a bunch of stuff that gets me actively excited. One of the contributing authors uses the term “gestalt” a few too many times.</p><p>A big part of the book was just talking about <strong>when</strong> to use procedural generation.</p><p>I’d summarize the book’s answer as “if you’re reading this, less than you imagine”.    </p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc8ac403-70e9-4356-bbc5-b01b4dd1d353_910x529.webp"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc8ac403-70e9-4356-bbc5-b01b4dd1d353_910x529.webp" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/bc8ac403-70e9-4356-bbc5-b01b4dd1d353_910x529.webp&quot;,&quot;height&quot;:529,&quot;width&quot;:910,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:9114,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/webp&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p><em>this, for example, is probably too big a promise, unless they mean just the clouds</em></p><p>The benefits of generated content are obvious. Infinite content - even infinite bland content, is still <em>infinite</em>. This is why people still go to buffet restaurants - unlimited bad food is still pretty compelling. </p><p>So, some of the problems of procgen:</p><ul><li><p>If you restrict the output-space too aggressively, your procgen output will feel bland and samey. <em>When I restricted the output of my music generator using too many Music Theory rules, it could only produce like, 6 different songs, which all felt very bland and similar.</em></p></li><li><p>If you don’t restrict the output-space enough, your output will feel formless and unfair. <em>When I turned off the Music Theory rules, the amount of garbage output got out of control.</em></p></li><li><p>In order to produce procedurally generated output that’s meaningful, you must understand the problem space very well, and work hard at crafting intelligent rules.</p></li><li><p>It is orders of magnitude more work than just making good output.</p></li></ul><p>Or, to put it bluntly, “<strong>don’t try to procedurally generate something that you can’t already create, dummy</strong>”.</p><p>If I play with the generator long enough, I hit little patches of vaguely almost-listenable music, but most of the time the output is more of a formless mush:</p><p>Even worse, after listening to it for long stretches of time, I’d manage to convince myself that <strong>maybe I actually had something good on my hands</strong> - usually it would take either playing it for Voxel, who <em>knows what music is supposed to sound like</em> - or listening to some actual human-generated music on my own, to remind me that I had been listening to a droning mess of nothing for several consecutive hours and it was starting to melt my brain into a puddle.</p><h2>So, You’re Giving Up, Then?</h2><p>Yeah - maybe not permanently, but sometimes it’s important to know when to throw in the towel. This part of the project has, I think, failed, and it’s reaching the point where more effort is being met with <em>diminishing returns</em>.</p><div><p>I think I’m going to try a new plan from my list - “buy, commission, or write music, output music as midi, play music while using the midi data to silently drive effects”.</p><p>I’ll probably write some basic drum-loop first-fifteen-minutes-of-the-FruityLoops-tutorial jams to get the project off the ground, and then find someone competent to compose music if I ever feel like the project is within biting distance of actually shipping. </p></div><p>Anyways, Groovelet Music Engine, you’ve got one last chance to shine. Play yourself off! Preferably with something a little sad.</p><h2>A Goodbye From the Groovelet Music Engine</h2><p>… god dammit.</p></div></div>]]>
            </description>
            <link>https://devlog.groovelet.com/p/procedurally-generated-music-is-awful</link>
            <guid isPermaLink="false">hacker-news-small-sites-25327533</guid>
            <pubDate>Sun, 06 Dec 2020 23:06:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New Sauerbraten 2020 Edition Released]]>
            </title>
            <description>
<![CDATA[
Score 127 | Comments 40 (<a href="https://news.ycombinator.com/item?id=25327267">thread link</a>) | @silentmars
<br/>
December 6, 2020 | http://www.sauerworld.org/new-sauerbraten-2020-edition-released/ | <a href="https://web.archive.org/web/*/http://www.sauerworld.org/new-sauerbraten-2020-edition-released/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<div role="main">
<div>
<article id="post-6949" data-id="6949">
<div>
<p>Dear all, we are happy to announce that the long-awaited <strong>Sauerbraten 2020 Edition</strong> is finally available! You can find it on the Sauerbraten homepage (<a href="http://sauerbraten.org/" target="_blank" rel="noopener noreferrer">http://sauerbraten.org/</a>)</p>
<p>The full changelog is here: <a href="http://sauerbraten.org/docs/history.html#_2020_11_29">http://sauerbraten.org/docs/history.html</a></p>
<h3>New Features!</h3>
<ul><li>Almost 200 (yes, 200) new maps!</li><li>A fully configurable HUD gameclock</li><li>Color coded health display</li><li>Teammate health bars for easy communication</li><li>Pickup icons display over players in item modes</li><li>Configurable HUD ammobar</li><li>Explosion brightness can now be changed in-game</li><li>Water quality has been improved</li></ul>
<h3>Game Improvements!</h3>
<ul><li>Update from SDL 1 to SDL 2</li><li>Hold has received an update. The flag counter now does not reset upon dropping the flag, but the time starts to increase back to 20 for every second it is not picked up. The enemy team picking up the flag still resets the counter for your team.</li><li>An improved design for sound radius</li><li>A new, more intelligent spawn system</li><li>The Health Boost mechanic has been redesigned – it lasts only until death and provides +100 health up to 150 for the first pickup, and up to 200 for any subsequent pickups before dying</li></ul>
<h3>Editing Stuff!</h3>
<ul><li>Atmospheric effects</li><li>Multiplayer undo in coop-edit</li><li>vcommands now work without sendmap</li><li>More user friendly editing menus</li><li>Mapmodel menu now previews the mapmodels and their animations</li><li>Texture menu now previews the texture path</li><li>Hundreds of new assets!</li></ul>
<h3>Server and Demos</h3>
<ul><li>Demos can now be named when saving</li><li><code>/seekdemo</code> allows you to fast forward, like <code>/demotime</code> in Community Edition</li><li>Default server has settings for overtime and persistent teams</li><li>Blue armour in Regen Capture can (and should) now be disabled as a server setting</li></ul>
<p>And much, much more!</p>
<p>Happy fragging!</p>

 
</div>
</article>


</div>
</div>
</div>

</div></div>]]>
            </description>
            <link>http://www.sauerworld.org/new-sauerbraten-2020-edition-released/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25327267</guid>
            <pubDate>Sun, 06 Dec 2020 22:31:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thought Leaders and Chicken Sexers]]>
            </title>
            <description>
<![CDATA[
Score 172 | Comments 58 (<a href="https://news.ycombinator.com/item?id=25325716">thread link</a>) | @michael_fine
<br/>
December 6, 2020 | https://ideolalia.com/essays/thought-leaders-and-chicken-sexers.html | <a href="https://web.archive.org/web/*/https://ideolalia.com/essays/thought-leaders-and-chicken-sexers.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

	

	<div>
		<article>
			<p>From the moment I started paying attention to the tech industry, Paul Graham was there.  My first job out of college was in SoMa, around the corner from the Justin.tv offices, and his essays were just floating around in the ether, impossible to ignore.  His popularization of Lisp was a small part of why I tried Clojure, and a big part of why Clojure was successful.</p>

<p>I recognized that he had a tendency towards <a href="http://www.paulgraham.com/avg.html">self-aggrandizement</a> and <a href="http://www.paulgraham.com/nerds.html">awkward flattery of his readers</a>, but at worst he seemed harmless.  As his writing became increasingly focused on startups, and I became increasingly sure I didn’t want to be a founder, he simply drifted out of view.</p>

<p>Recently, however, his writing has taken a reactionary turn which is hard to ignore.  He’s <a href="http://www.paulgraham.com/mod.html">written</a> about the need to defend “moderates” from bullies on the “extreme left”, <a href="https://twitter.com/paulg/status/1334441961147822081">asserted</a> that “the truth is to the right of the median” because “the left is culturally dominant,” and <a href="https://pbs.twimg.com/media/EjGX2-bU4AAWkUX?format=jpg&amp;name=medium">justified</a> Coinbase’s policy to ban discussion of anything deemed “political” by saying that it “will push away some talent, yes, but not very talented talent.”</p>

<p>I went back to the essays I had read a decade before, to see if I had missed something.  It turned out that I had.  There was a consistent intellectual framework underpinning all his writing, from his very first essays on Lisp and language design.  In many ways, those early essays contained the clearest articulation of his framework; it just took me ten years to see it.</p>

<hr>

<p>In April 2001, six years after the release of the Java language, Paul Graham weighed in:</p>

<blockquote>
  <p><a href="http://paulgraham.com/javacover.html">I’ve never written a Java program, never more than glanced over reference books about it, but I have a hunch that it won’t be a very successful language.</a></p>
</blockquote>

<p>He followed up with a number of observations about Java, such as the fact that it was designed by committee, infantilizes its users, and owed its initial success to an ailing corporate sponsor.  But, he wrote, this wasn’t an analysis of Java so much as introspection on his own “hacker’s radar”.  This radar was the aesthetic response of an expert programmer, drawn from epiphenomena surrounding the language and the opinions of other experts in his social circle.</p>

<p>A month later, in an essay on why languages are popular, he doubled down on the importance of his personal intuition:</p>

<blockquote>
  <p><a href="http://www.paulgraham.com/popular.html">Programming languages are <em>for</em> hackers, and a programming language is good as a programming language (rather than, say, an exercise in denotational semantics or compiler design) if and only if hackers like it.</a></p>
</blockquote>

<p>The quality of a language can only be judged by experts (“a tiny minority, admittedly, but that tiny minority write all the good software”), and adoption by those experts will drive adoption by everyone else.  Ultimately, “a programming language probably becomes about as popular as it deserves to be.”</p>

<p>The context for both essays was that Graham was creating his own language, <a href="http://www.paulgraham.com/arc.html">Arc</a>.  He wanted it to be popular, and was working out how to make that happen.</p>

<p>The first intrinsic driver of popularity he named was “brevity”:</p>

<blockquote>
  <p><a href="http://www.paulgraham.com/popular.html">It would not be far from the truth to say that a hacker about to write a program decides what language to use, at least subconsciously, based on the total number of characters he’ll have to type.</a></p>
</blockquote>

<p>He called back to this when discussing the importance of libraries, which can reduce any program to a single invocation:</p>

<blockquote>
  <p><a href="http://www.paulgraham.com/popular.html">Of course the ultimate in brevity is to have the program already written for you, and merely to call it. And this brings us to what I think will be an increasingly important feature of programming languages: library functions. Perl wins because it has large libraries for manipulating strings.</a></p>
</blockquote>

<p>It appears that Graham was referring to Perl’s core library functions, not the much larger set of library functions that were even then available via <a href="https://www.cpan.org/">CPAN</a>, because he placed this responsibility wholly upon the shoulders of the language designer, saying language design would become increasingly focused on “how to design great libraries.”</p>

<p>Graham named other drivers of popularity in this essay, but he returned to brevity <a href="http://www.paulgraham.com/langdes.html">again</a> and <a href="http://www.paulgraham.com/power.html">again</a> over the next year, culminating in an essay on the singular importance of brevity, now dubbed “succinctness”:</p>

<blockquote>
  <p><a href="http://www.paulgraham.com/power.html">My hypothesis is that succinctness is power, or is close enough that except in pathological examples you can treat them as identical.</a></p>
</blockquote>

<p>Drawing from studies that found “programmers seemed to generate about the same amount of code per day regardless of the language”, he declared that “the only way to get software written faster was to use a more succinct language”.</p>

<p>Nowhere, however, did he mention libraries.  The next month, he explained that given a sufficiently succinct language, users could simply write their own libraries:</p>

<blockquote>
  <p><a href="http://www.paulgraham.com/icad.html">As for libraries, their importance also depends on the application. For less demanding problems, the availability of libraries can outweigh the intrinsic power of the language. Where is the breakeven point? Hard to say exactly, but wherever it is, it is short of anything you’d be likely to call an application. If a company considers itself to be in the software business, and they’re writing an application that will be one of their products, then it will probably involve several hackers and take at least six months to write. In a project of that size, powerful languages probably start to outweigh the convenience of pre-existing libraries.</a></p>
</blockquote>

<p>This was a significant departure from his earlier writings.  Only a year before, he had stated that “[i]t’s hard to design good libraries. It’s not simply a matter of writing a lot of code.”  He had emphasized that library design was a key part of language design, and even a year later he would tell us “[d]esign usually has to be under the control of a single person to be any good.”</p>

<p>Now he argued that the language designer only need provide a barebones language of sufficient brevity, and all else would follow.  Library design can’t be both critically important and an incidental part of someone else’s six-month software project.  Despite this, Graham never mentioned libraries ever again.</p>

<p>A year later, he explained that Arc was trying to be a “hundred-year language”.  “It may seem presumptuous,” he wrote, but “[l]anguages evolve slowly because they’re not really technologies. Languages are notation. A program is a formal description of the problem you want a computer to solve for you.”  He asserted the most important part of the language were the “fundamental operators”, because the rest of the language “could in principle be written in terms of these fundamental operators”.</p>

<p>What, then, makes a language ready for the 22nd century?  Certainly not any concerns about performance, since “[e]ven if [computers] only end up being a paltry million times faster, that should change the ground rules for programming languages substantially.”  Not data structures, since they’re just a premature optimization of the humble list.  Not a mechanism (or even notation) for parallel computation, since a simple description of the problem will “ignore any advantages to be got from parallel computation, just as they will ignore advantages to be got from specific representations of data.”</p>

<p>A hundred-year language <em>should</em>, however, be succinct.  First “write down the program you’d like to be able to write, regardless of whether there is a compiler that can translate it or hardware that can run it.”  And of course the program you’d really like to write is the shortest one possible:</p>

<blockquote>
  <p><a href="http://www.paulgraham.com/hundred.html">[T]he algorithm for language design becomes: look at a program and ask, is there any way to write this that’s shorter?</a></p>
</blockquote>

<p>“If we had the hundred-year language now,” Graham wrote, “it would at least make a great pseudocode.”  Confusingly, he asserted that since it will need to perform well on its million-times-faster future processor, “presumably it could generate code efficient enough to run acceptably well on our hardware.”</p>

<p>“When you see these ideas laid out like that,” he wrote, “it’s hard not to think, why not try writing the hundred-year language now?”</p>

<hr>

<p>Four years later, in 2008, Arc was released.  It was a <a href="https://en.wikipedia.org/wiki/Common_Lisp#The_function_namespace">Lisp-1</a> with shorter names and fewer parentheses than most other Lisps, and some reader macros to make anonymous functions easier to define.  All primitives were defined in terms of MzScheme, a different Lisp, which provided the compiler and other tooling.  It also came with a barebones web framework which used continuations, reminiscent of the Smalltalk-based <a href="https://en.wikipedia.org/wiki/Seaside_(software)">Seaside framework</a> which had been around since 2002.</p>

<p>It was, in all, underwhelming.  There were many paths that could have led Graham to his professed goals, and he took none of them.</p>

<p>He had written that strings were premature optimization, and should be replaced by lists of characters.  If he had done so, and made the characters full <a href="https://en.wikipedia.org/wiki/Code_point">Unicode code points</a>, Arc could have been one of the few languages not suffering from a half-century hangover stretching all the way back to <a href="https://en.wikipedia.org/wiki/EBCDIC">EBCDIC</a>.  Instead, the initial release used byte strings which only supported the ASCII character set.</p>

<p>Graham had asked “[h]ow many times have you heard hackers speak fondly of how in, say, APL, they could do amazing things with just a couple lines of code? I think anything that really smart people really love is worth paying attention to.”  But the undeniably succinct primitives and composition rules of array programming languages were nowhere to be found.</p>

<p>Server-based deployment of software was a <a href="http://www.paulgraham.com/road.html">central theme</a> in Graham’s essays, and his continuation-based web framework was an interesting and fairly novel way to create continuity across multiple requests in a single session.  But since each link on the page was a continuation, and each continuation was stored in-memory in a single process, this created a single, memory-hungry point of failure.  For years, <a href="https://news.ycombinator.com/news">Hacker News</a> would simply display “unknown or expired link” if you waited too long to click a link.  If Arc had its own runtime, it could have supported …</p></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ideolalia.com/essays/thought-leaders-and-chicken-sexers.html">https://ideolalia.com/essays/thought-leaders-and-chicken-sexers.html</a></em></p>]]>
            </description>
            <link>https://ideolalia.com/essays/thought-leaders-and-chicken-sexers.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25325716</guid>
            <pubDate>Sun, 06 Dec 2020 19:04:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Docker's Second Death]]>
            </title>
            <description>
<![CDATA[
Score 287 | Comments 246 (<a href="https://news.ycombinator.com/item?id=25325056">thread link</a>) | @alexellisuk
<br/>
December 6, 2020 | https://www.tariqislam.com/posts/kubernetes-docker-dep/ | <a href="https://web.archive.org/web/*/https://www.tariqislam.com/posts/kubernetes-docker-dep/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><h3>Docker's Second Death</h3></p><h3 id="feels-like-forever">Feels Like Forever</h3><p>Perhaps not quite forever, but the history with Docker <em>feels</em> really long in good and bad ways. I had joined Red Hat in the summer of 2015, the same summer that OpenShift 3.0 went GA. This was a remarkable event because it marked a redesign of the platform onto Kubernetes which itself had just gone to v1.0 (this is the same timeframe that GKE went GA, if you can believe it’s that old). Like many, I had no clue what Kubernetes or OpenShift were, and I definitely didn’t know much about Docker. I knew <em>of</em> containers. By fall I was neck deep in all three, and in love with the ecosystem a few months after.</p><p>The next spring was my first “real” encounter with Docker Inc. I didn’t attend Red Hat Summit 2016, but I distinctly remember that being the year that Docker really made its first outward antagonistic move against Red Hat OpenShift, at Red Hat’s own event. They were giving out the following shirt:</p><p><img src="https://www.tariqislam.com/images/dockerpatch.jpg" alt="docker-shirt"></p><p>To briefly summarize, this was an attack on Red Hat’s model of backporting patches to older versions of software (also known as “enterprise support”). Red Hat at that time shipped a version of Docker that was just slightly behind the latest cut, whereas Docker shipped their latest. I won’t go into the details of why that matters because there is still a debate today about whether backporting patches is better for an organization versus staying on the latest version of a thing (the latter has gotten considerably better in recent times). This was significant because up until that time, Docker was an integral part of the OpenShift narrative. We sold one with the other and the underlying assumption by most if not all of us was that Docker was just a great tech. In retrospect, this should have been expected as Docker Inc. started making its moves into the enterprise space and suddenly stopped being just great tech.</p><h3 id="it-was-inevitable">It Was Inevitable</h3><p>The early platform wars, as I call them, were primarily focused around OpenShift, Docker, and Pivotal. Pivotal had made significant inroads into enterprise organizations early on, and for good reason: the platform experience was pretty great. Couple that with Pivotal Labs and you had some pretty good mojo. Docker was the up and comer. It was the industry darling making a splash and it had the tech that everyone wanted or that everyone was already using. Kubernetes was still a bit of a question mark. I spent a lot of my time talking to organizations about the nuts and bolts of Kubernetes and why it mattered, or more accurately: why it should matter to them. The move by Docker to knock on OpenShift forced Red Hat messaging to over-index on Kubernetes and Linux over and above anything else. It worked and the industry caught up.</p><p>Docker, still in its industry darling state, responded quickly with Docker Swarm but never really caught on. Swarm was eventually overwhelmed (pun intended) by the uptake of Kubernetes across the industry, and this was when it died the first time: it lost the platform wars and became the very first commodity in the cloud native ecosystem. The second half of 2016 is really when Kubernetes edged out Swarm. This was made evident by the keynote demo at DockerCon 2017 in the following Spring when the presenters showcased Docker’s integration with Kubernetes on the big stage. Notably, that was the last “big” DockerCon that made a splash. From there on out, it was the Kubernetes/CNCF show.</p><h3 id="docker-debt">Docker Debt</h3><p>In all this time, Docker was always an integral part of Kubernetes. This was the relationship:</p><p><img src="https://www.tariqislam.com/images/dockershim.png" alt="dockershim"></p><p>And for the last 19 releases, that chain is what has been supported in Kubernetes. All that just to spin up a pod with a container in it. Docker went from necessity to technical debt. And out of all that, the community laboured until now where Docker will be deprecated in the next release of 1.20. The community has (rightfully) carried the technical debt of Docker for years to ensure the industry had what it needed for the most seamless experience given the ubiquity of the docker daemon. Here is what’s been around for a little while, but will be officially prime time in 1.20 and beyond:</p><p><img src="https://www.tariqislam.com/images/withoutdocker.png" alt="withoutdocker"></p><p>It’s a great simplification, and a return to consistency. To help visualize why this was necessary, I encourage you to view Docker as a platform abstraction on top of containers which are just an aggregate of some Linux constructs. Part of this abstraction involved an integration between the docker platform and containerd, the latter of which lives on today as arguably the most popular container runtime. Docker was never the runtime. Docker simply made containerd and other Linux constructs easy to work with so that container management would be a breeze. Instead of a dozen lines of code to create and deploy a running container, all you needed was:</p><pre><code>docker run
</code></pre><p>But like any platform, that convenience comes with a lot of bloat and technical debt. Especially over time. The removal of docker and the optimization of containerd marks a cultural shift of sorts for the cloud native landscape. None of this is meant to dismiss Docker Inc. Kubernetes today would not be where it is without Docker Inc. That’s a fact. The technologies and the competition that Docker Inc drove were some of the best things to ever happen to the industry. Now as far as turning a profitable business model out of open source technology goes, Docker Inc will likely be studied as a cautionary flash in the pan. Still, it’s important that we separate out the company’s contributions versus its business model. What’s left of the Docker platform, at this point, are its shadows within Kubernetes platforms. Though it does live on strongly within CI/CD ecosystems and, ostensibly, the inner loop of development thanks to the de facto standard Dockerfile. It is a testament to the power that Docker Inc once had, that its technology lived on far beyond the obsolescence of the company until community innovation caught up to it. With all the years of bloat baked into the platform, it’s really just a matter of time before other areas to the left of the platform shed the debt of the Docker daemon.</p><p>While it had an amazing journey and an indelible impact to the industry, practically speaking Docker is dead and dying.</p></div></div>]]>
            </description>
            <link>https://www.tariqislam.com/posts/kubernetes-docker-dep/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25325056</guid>
            <pubDate>Sun, 06 Dec 2020 17:38:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EmacsConf 2020 Talks]]>
            </title>
            <description>
<![CDATA[
Score 339 | Comments 64 (<a href="https://news.ycombinator.com/item?id=25324311">thread link</a>) | @AlexeyBrin
<br/>
December 6, 2020 | https://emacsconf.org/2020/talks/ | <a href="https://web.archive.org/web/*/https://emacsconf.org/2020/talks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">



<div id="pagebody">







<div id="content" role="main">
<p><a href="https://emacsconf.org/2020/emacsconf-2020.m3u">Download an .m3u playlist</a></p>

<p>EmacsConf 2020 was on November 28 (Sat) and November 29 (Sun), 2020 from 9am-5pm Toronto/EST time; equivalently, 6am-2pm PST, 2pm-10pm UTC, 3pm-11pm Zurich/CET.</p>

<p>Many of the talks include accompanying material such as slides, questions, and notes. When present, these material are included or linked to on the talk page.</p>

<table><thead><tr><th>Duration</th><th>Title</th><th>Speakers</th></tr></thead><tbody><tr><td colspan="3">Talks</td></tr>
<tr><td colspan="3">NOVEMBER 28 (Saturday)</td></tr>
<tr><td>7:04</td><td><a href="https://emacsconf.org/2020/talks/00">Day 1 opening remarks</a></td><td>Amin Bandali, Sacha Chua, Leo Vivier</td></tr><tr>
</tr><tr><td>3:58</td><td><a href="https://emacsconf.org/2020/talks/01">Emacs News Highlights</a></td><td>Sacha Chua</td></tr><tr>
</tr><tr><td>24:15</td><td><a href="https://emacsconf.org/2020/talks/02">An Emacs Developer Story: From User to Package Maintainer</a></td><td>Leo Vivier</td></tr><tr>
</tr><tr><td>14:50</td><td><a href="https://emacsconf.org/2020/talks/03">Idea to Novel Superstructure: Emacs for Writing</a></td><td>Bala Ramadurai</td></tr><tr>
</tr><tr><td>8:26</td><td><a href="https://emacsconf.org/2020/talks/04">Music in Plain Text</a></td><td>Jonathan Gregory</td></tr><tr>
</tr><tr><td>29:50</td><td><a href="https://emacsconf.org/2020/talks/05">Bard Bivou(m)acs - Building a bandcamp-like page for an album of music</a></td><td>Grant Shangreaux</td></tr><tr>
</tr><tr><td>13:41</td><td><a href="https://emacsconf.org/2020/talks/06">Trivial Emacs Kits</a></td><td>Corwin Brust (mplsCorwin)</td></tr><tr>
</tr><tr><td>22:05</td><td><a href="https://emacsconf.org/2020/talks/07">Beyond Vim and Emacs: A Scalable UI Paradigm</a></td><td>Sid Kasivajhula (countvajhula)</td></tr><tr>
</tr><tr><td>17:19</td><td><a href="https://emacsconf.org/2020/talks/08">Building reproducible Emacs</a></td><td>Andrew Tropin (abcdw)</td></tr><tr>
</tr><tr><td>47:08</td><td><a href="https://emacsconf.org/2020/talks/21">On why most of the best features in eev look like 5-minute hacks</a></td><td>Eduardo Ochs (edrx)</td></tr><tr>
</tr><tr><td>14:09</td><td><a href="https://emacsconf.org/2020/talks/09">Orgmode - your life in plain text</a></td><td>Rainer König</td></tr><tr>
</tr><tr><td>8:18</td><td><a href="https://emacsconf.org/2020/talks/10">Lead your future with Org</a></td><td>Andrea</td></tr><tr>
</tr><tr><td>15:18</td><td><a href="https://emacsconf.org/2020/talks/11">the org-gtd package: opinions about Getting Things Done</a></td><td>Aldric</td></tr><tr>
</tr><tr><td>16:38</td><td><a href="https://emacsconf.org/2020/talks/12">One Big-ass Org File or multiple tiny ones?  Finally, the End of the debate!</a></td><td>Leo Vivier</td></tr><tr>
</tr><tr><td>12:05</td><td><a href="https://emacsconf.org/2020/talks/13">Experience Report: Steps to "Emacs Hyper Notebooks"</a></td><td>Joseph Corneli, Raymond Puzio, and Cameron Ray Smith</td></tr><tr>
</tr><tr><td>19:41</td><td><a href="https://emacsconf.org/2020/talks/14">README-Driven Design</a></td><td>Adam Ard</td></tr><tr>
</tr><tr><td>25:00</td><td><a href="https://emacsconf.org/2020/talks/15">Moving from Jekyll to OrgMode, an experience report</a></td><td>Adolfo Villafiorita</td></tr><tr>
</tr><tr><td>21:56</td><td><a href="https://emacsconf.org/2020/talks/16">Org-roam: Presentation, Demonstration, and What's on the Horizon</a></td><td>Leo Vivier</td></tr><tr>
</tr><tr><td>21:15</td><td><a href="https://emacsconf.org/2020/talks/17">Org-mode and Org-Roam for Scholars and Researchers</a></td><td>Noorah Alhasan</td></tr><tr>
</tr><tr><td>21:26</td><td><a href="https://emacsconf.org/2020/talks/18">Org-roam: Technical Presentation</a></td><td>Leo Vivier</td></tr><tr>
</tr><tr><td>8:13</td><td><a href="https://emacsconf.org/2020/talks/19">Sharing blogs (and more) with org-webring</a></td><td>Brett Gilio</td></tr><tr>
</tr><tr><td>22:50</td><td><a href="https://emacsconf.org/2020/talks/20">OMG Macros</a></td><td>Corwin Brust (mplsCorwin)</td></tr><tr>
</tr><tr><td>15:47</td><td><a href="https://emacsconf.org/2020/talks/40">Day 1 closing remarks</a></td><td>Amin Bandali, Sacha Chua, Leo Vivier, Corwin Brust</td></tr><tr>
</tr><tr><td colspan="3">NOVEMBER 29 (Sunday)</td></tr>
<tr><td>11:47</td><td><a href="https://emacsconf.org/2020/talks/41">Day 2 opening remarks</a></td><td>Amin Bandali, Sacha Chua, Leo Vivier</td></tr><tr>
</tr><tr><td>5:07</td><td><a href="https://emacsconf.org/2020/talks/38">Emacs development update</a></td><td>John Wiegley</td></tr><tr>
</tr><tr><td>29:06</td><td><a href="https://emacsconf.org/2020/talks/22">Powering-up Special Blocks</a></td><td>Musa Al-hassy</td></tr><tr>
</tr><tr><td>43:54</td><td><a href="https://emacsconf.org/2020/talks/23">Incremental Parsing with emacs-tree-sitter</a></td><td>Tuấn-Anh Nguyễn</td></tr><tr>
</tr><tr><td>20:46</td><td><a href="https://emacsconf.org/2020/talks/24">Analyze code quality through Emacs: a smart forensics approach and the story of a hack</a></td><td>Andrea</td></tr><tr>
</tr><tr><td>9:52</td><td><a href="https://emacsconf.org/2020/talks/25">Traverse complex JSON structures with live feedback</a></td><td>Zen Monk Alain M. Lafon</td></tr><tr>
</tr><tr><td>53:38</td><td><a href="https://emacsconf.org/2020/talks/39">NonGNU ELPA</a></td><td>Richard Stallman</td></tr><tr>
</tr><tr><td>14:57</td><td><a href="https://emacsconf.org/2020/talks/26">Emacs as a Highschooler: How It Changed My Life</a></td><td>Pierce Wang</td></tr><tr>
</tr><tr><td>21:26</td><td><a href="https://emacsconf.org/2020/talks/27">State of Retro Gaming in Emacs</a></td><td>Vasilij "wasamasa" Schneidermann</td></tr><tr>
</tr><tr><td>1:09:00</td><td><a href="https://emacsconf.org/2020/talks/28">Welcome To The Dungeon</a></td><td>Erik Elmshauser and Corwin Brust</td></tr><tr>
</tr><tr><td>(combined with previous)</td><td><a href="https://emacsconf.org/2020/talks/29">Pathing of Least Resistance</a></td><td>Erik Elmshauser and Corwin Brust (mplsCorwin)</td></tr><tr>
</tr><tr><td>11:30</td><td><a href="https://emacsconf.org/2020/talks/30">A tour of vterm</a></td><td>Gabriele Bozzola (@sbozzolo)</td></tr><tr>
</tr><tr><td>16:50</td><td><a href="https://emacsconf.org/2020/talks/31">Lakota Language and Emacs</a></td><td>Grant Shangreaux</td></tr><tr>
</tr><tr><td>23:57</td><td><a href="https://emacsconf.org/2020/talks/32">Object Oriented Code in the Gnus Newsreader</a></td><td>Eric Abrahamsen</td></tr><tr>
</tr><tr><td>39:16</td><td><a href="https://emacsconf.org/2020/talks/33">Maxima a computer algebra system in Emacs</a></td><td>Fermin MF</td></tr><tr>
</tr><tr><td>22:22</td><td><a href="https://emacsconf.org/2020/talks/34">Extend Emacs to Modern GUI Applications with EAF</a></td><td>Matthew Zeng</td></tr><tr>
</tr><tr><td>16:02</td><td><a href="https://emacsconf.org/2020/talks/35">WAVEing at Repetitive Repetitive Repetitive Music</a></td><td>Zachary Kanfer</td></tr><tr>
</tr><tr><td>36:29</td><td><a href="https://emacsconf.org/2020/talks/42">Day 2 closing remarks</a></td><td>Amin Bandali, Sacha Chua, Leo Vivier, Corwin Brust</td></tr><tr></tr></tbody></table>




</div>







</div>



</div></div>]]>
            </description>
            <link>https://emacsconf.org/2020/talks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25324311</guid>
            <pubDate>Sun, 06 Dec 2020 16:00:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Programming Is Hard to Fundamentally Improve (2017)]]>
            </title>
            <description>
<![CDATA[
Score 58 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25322656">thread link</a>) | @mpweiher
<br/>
December 6, 2020 | https://aidancunniffe.com/why-programming-is-hard-to-fundamentally-improve-4101612d4ad9 | <a href="https://web.archive.org/web/*/https://aidancunniffe.com/why-programming-is-hard-to-fundamentally-improve-4101612d4ad9">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><p><a href="https://medium.com/@aidandcunniffe?source=post_page-----4101612d4ad9--------------------------------" rel="noopener"><img alt="Aidan Cunniffe" src="https://miro.medium.com/fit/c/96/96/1*26JtOGzXJBiOCbDzaKjrWg.jpeg" width="48" height="48"></a></p></div></div></div></div><p id="cb76"><em>and why I’m still trying…</em></p><p id="5880">One of the curious things about being human is the ability to hold two contradictory views simultaneously. When I’m in analysis mode I try to understand what market, technical and social forces have lead to the status quo. To do this effectively, or at least to induce useful principles for later use, you have to believe that things are the way they are for good reasons. As soon as I put my innovator hat on however, I get all jazzed up and think “screw that! X would be so much better if Y”. I’ve learned over the last year that balancing these two perspectives is essential to an inventor.</p><p id="9c7d">This week I watched Bret Victor’s <a href="http://worrydream.com/dbx/" rel="noopener">Future of Programming</a> lecture from July 2013 and it compelled me to put these thoughts down on paper. During the lecture, Bret uses an overhead projector and pretends its 1973. He proudly presents the latest in programming research for the time and explains why it’d be really silly if we aren’t using them in 40 years. To Victor’s credit he remains in character the whole time as he satirically paints the ideal world we’ll soon enter — one the audience knows doesn’t really exist.</p><p id="cbac">The future Bret showed off included direct manipulations of the output (result) instead of the code, programming via constraints/goals, spatial (visual) programming paradigms, and massively parallel programming approaches. Declarative programming, functional programming, microservice architectures and WYSIWYG editors check some of those boxes, but not nearly at the level of their potential. All that being said, there’s no argument against real progress having been made the last 40 years, just not the progress many expected.</p><p id="f16a">So now I’ll put on my analysis hat and work through why the art of programming is so hard to advance beyond its current levels.</p><p id="a3f1">Many blame the lack of advancements on developers. We built shinny thing X, but developers are too arrogant, stubborn, busy, dismissive or all of the above to adopt it. I’ve even heard people accuse developers of selfishly protecting their future job prospects by trying to stifle the adoption of new programming mediums. Heck, I’ve said this before…</p><p id="f628">^ This is just wrong. In my experience developers are very rational beings. Their job is to find the most efficient way of solving problems every single day and if you create a tool that provides that they’ll be all over it. They’ll even volunteer their time to help you build it for free. If you move forward accepting that developers are mostly rational actors and have good reasons for adopting something / not adopting something you can learn a lot to inform future design.</p><p id="33a0">So I did that. I actually sat down with people over the last 3 months and asked them why they failed to adopt a variety of tools. I overwhelmingly got rational explanations to why switching to something new was irrational.</p><h2 id="99cb">Better Hammer Tradeoff</h2><p id="8f1e">Imagine you’re building a log cabin by hand with a bad, but usable hammer. When you’re 90% of the way finished a magical genie comes and offers you a better hammer. Great! But there’s a tradeoff: If you take the new shinny hammer, you have to start the house from scratch…oh and he turns back humanity to the stone age. You can get your new hammer, but you’ll have to do without bandsaws, your pickup truck, and yes, nails.</p><p id="3e8b">What’s the rational choice? Hint, it involves the old hammer.</p><p id="7f24">That parable emerged from summarizing all the interviews I conducted and highlights the frustrations developers have had with many of the new ‘solve all your problems’ tools they’ve tried. For context these tools fit into two categories: new programming languages including some flow &amp; graph based paradigms and no-code visual builders.</p><p id="6a39">There are two areas of value to consider when choosing a programming paradigm: the developer experience of the [language, tooling, GUI] and the strength of the ecosystem (what common problems have been solved already). Many of the new paradigms, while often built on sound principles, miss out on the massive body of work that already exists is language X. How do you weight these two areas when picking your paradigm? 30–70? 90–10? 1–99? Most people I spoke with rated the ecosystem as 2–3x more important than DX.</p><p id="9ab3">Tool-builders usually only focus on DX and [assume, hope, pray] that a community comes along and builds an ecosystem. This still can happens, but it was much much more common in the 90s than it is today. There are network effects in programming and a beautiful virtuous cycle quickly emerges among the most used tools. When a user shares functionality openly it makes paradigm more capable, which attracts new users, who continue to improve that paradigm. Boom! Node module for everything.</p><p id="0b6c">When you look at the languages that have really caught on recently, they tend to share one thing in common: they tap into an existing body of work. Look at TypeScript, the most popular language released after 2000, which interoperates with Javascript. Then there’s Swift, the second most popular language released after 2000. Just imagine where Swift would be today if it hadn’t been interoperable with Objective-C and the Cocoa legacy or if TypeScript’s ecosystem was a blue ocean from day one.</p><p id="272c">There are consequences for tool makers building an entirely new base abstraction, be it visual, text based or otherwise. If you choose not to interoperate with an existing ecosystem, you or your community will need to spend years coming up from the stone age to modernity. Programming is just learning to use a bunch of stacked abstractions. Even if you have an objectively better base abstraction, one that would have clearly won out over everything else had it been introduced in 1992, people will have few incentives to adopt it if there’s no ecosystem.</p><h2 id="749d">Sunk Cost…Sensibility</h2><p id="5881">Most people complete the phrase “Sunk cost _____” with “fallacy”. The classic economics thought experiment usually involves a couple staying at a concert they hate just because they paid face value for the tickets. An enlightened economist would, as the story goes, leave as soon as they became unhappy with the concert and reclaim a few precious hours. But if you had to pay $50k, $50M or $5B to leave the concert early, you’d probably stay. When the switching costs are that high, there’s good reason to stay and the largest employers of programmers in the world have enormous switching costs. This keeps mainstream programmers anchored to the status quo.</p><p id="2c6d">This is another completely rational choice developers make when sticking to the paradigms they know. The combined costs of hiring new people, training, rewriting the code, and the opportunity cost of choosing these actions over improving your product almost always outweigh the benefits of making the change. <a href="https://www.joelonsoftware.com/2000/04/06/things-you-should-never-do-part-i/" rel="noopener">Joel has a classic article about code rewrites that expands on this more.</a></p><p id="ccc1">Young companies without much in the way of legacy or those with no other choice have the luxury of picking new paradigms, but few of these companies end up becoming incumbents. Those who do make it are the kingmakers. Both Facebook and Twitter were first built on technologies that were inadequate for their eventual scale (PHP and Ruby). Facebook became so attached to PHP that they enhanced the language to suit their needs with Hack and other tools. Similarly, Twitter switched over to Scala which one could argue is a key reason for Scala’s mainstream success.</p><h2 id="a2d4">Solving the Least Important Problems</h2><p id="513f">Tool makers must strike a balance between learnability and productivity. A visual programming environment like MIT’s <a href="https://scratch.mit.edu/" rel="noopener">Scratch</a> is incredibly learnable. I’ve seen 4-5 year old kids build games with it after just a few hours. The drag/drop interface and shape based constraints are really easy to learn and prevent Scratch from ever being in a broken state. This is great for kids and individuals trying to learn programming.</p><p id="bb8d">The same things that make Scratch easy to learn also make it an unproductive environment for more serious programmers. For a professional, programming with drag and drop is way slower than keying in code — that’s just a fact.</p><p id="cad2">These tradeoffs must be considered whenever building a new tool. If you build something super learnable that is not productive you’ll get a lot of praise, but little follow through. If you build something that’s too difficult to learn, but very productive you’ll turn a lot of people off. To reach mainstream programmers you need to make something that is both learnable and productive.</p><p id="5100">I think most of the stalled innovations in programming focused disproportionally on learnability. The problem is, within a few weeks of using any paradigm developers usually have built a repository of habits that keep them from making mistakes. For instance, if a new visual logic builder prides itself on preventing all syntax errors, that’s really cool, but most developers have learned to do that automatically.</p><p id="742f">Truth is, every tool you have ever used is flawed and every new tool will also be flawed. Humans subconsciously come up with ways to cope with their tools so they can keep themselves focussed on the bigger conceptual issues. That isn’t going to change anytime soon. If professionals already have habits in place to cope with things that have been made easier/more learnable by new tooling, those new tools do not have much value to them. It’s like offering a 40 year old who’s been driving manual her whole life an automatic car — yeah that’s great, but it’s not needed and she certainly won’t pay a premium for it to be included.</p><h2 id="6e7a">Things Have Been Getting Better</h2><p id="10b2">No good analysis fails to include a few words from the Advocatus Diaboli.</p><p id="e04a">Things have been getting better. The growth has just been in the ecosystems and not the paradigms themselves. We’ve been building this amazing tower of abstraction since the early days of programming that provide really useful abstractions for things like:</p><ul><li id="fb86">Charging a credit card, which has gone from a 20 person team to processor.charge()</li><li id="b32b">Configuring a massive cluster of servers is done with a short text file instead of …</li></ul></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://aidancunniffe.com/why-programming-is-hard-to-fundamentally-improve-4101612d4ad9">https://aidancunniffe.com/why-programming-is-hard-to-fundamentally-improve-4101612d4ad9</a></em></p>]]>
            </description>
            <link>https://aidancunniffe.com/why-programming-is-hard-to-fundamentally-improve-4101612d4ad9</link>
            <guid isPermaLink="false">hacker-news-small-sites-25322656</guid>
            <pubDate>Sun, 06 Dec 2020 10:48:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Choose Boring Technology]]>
            </title>
            <description>
<![CDATA[
Score 195 | Comments 188 (<a href="https://news.ycombinator.com/item?id=25322651">thread link</a>) | @amzans
<br/>
December 6, 2020 | https://panelbear.com/blog/boring-tech/ | <a href="https://web.archive.org/web/*/https://panelbear.com/blog/boring-tech/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Note: the ideas in this post have already been covered numerous times in the past. One article that has greatly influenced my perspective over the years is <a href="https://mcfunley.com/choose-boring-technology" target="_blank" rel="noopener">McKinley's Choose Boring Technology</a>. Below I'll explore the topic from my own experience, and how I ended up using Kubernetes for a recent project.</p><p>Over the years I have observed that many engineers tend to attribute much of the success or failure of a company to the technical choices made. I know I’m often guilty of this too. And while it is often justified, I would argue that for the vast majority of startups out there, the choice of programming language, framework, or even database doesn’t matter that much. This seems especially true during the early stages.</p><h2>Through the engineering lens</h2><p>This perception is understandable, we as engineers tend to look at the world from a specific lens, and are often biased by what we know best. Our daily activities may include things such as debugging CI pipelines, implementing new features, pairing with colleagues, or migrating the always present legacy codebase. The environment that surrounds us makes it easy to believe that it all boils down to those things that we see and understand. It’s an illusion that makes us feel like we’re fully in control of what makes or breaks the product.</p><p>Don’t get me wrong, it can be a huge advantage for many companies to make their product 3x more efficient than competitors, or to have elegant, composable code. But you might be focusing on the wrong problems if nobody cares about the product you’re actually building, and sooner or later your business will hit this wall.</p><p>I’m not saying that software doesn’t matter. A solid foundation for your startup goes a long way. If investing in this allows you to build better features faster than your competitors, more power to you. But finding the right balance is highly dependent on what you’re trying to solve and the resources you have at hand. There’s no right or wrong way to do it, and as usual, it mainly comes down to tradeoffs.</p><p><img src="https://panelbear.com/static/img/blog/lenses.png" alt="Different lenses"></p><h2>Boring is less surprising</h2><p>I believe aiming for a healthy balance of risk vs reward when it comes to your technical choices is something to strive for. In particular, if it decreases the chances you get stuck on the wrong problems down the road.</p><p>Boring is often interpreted as “picking old technologies over newer ones”, but it doesn’t necessarily mean that. For me, this comes down to using proven technologies in which the ways it can fail are mostly known, but occasionally experimenting with different, possibly newer tools that might suit the problem at hand better.</p><p>Maybe you want to gain more experience by using the latest framework or programming language, or you just want to have some fun. You do what makes you happy. But if you’re trying to make a decision to increase the odds that your product or business will succeed, it’s worth stepping back and considering your options.</p><p>For me, mainly choosing software that has been around for longer is not about it being boring or older, it’s about the fact that the ways in which it fails are better known. There are fewer unknowns for you to deal with and this maximizes your chances of actually shipping the project.</p><p>For example the other day I had an issue with my Django app, and a quick search led me to tens of answers to this problem in various forums and websites. It took me at most 10 minutes to get back on track and that was the end of this issue.</p><p>I experienced the exact opposite a few years ago with a popular, but not so battle-tested Scala library my team had been using for a while. We were probably among the first to encounter the issues we were facing, and it seemed nobody had walked down this path before. Maybe it sounds like a fun challenge or a great chance to contribute back to OSS (which I’m happy to), but once you solve it, do your customers really care about it? How many days, weeks, or even months are you willing to invest in such issues? In my case, I’d rather use that time to ship new features or improve the existing ones.</p><h2>Exploit vs explore</h2><p>I try to follow an 80/20 distribution when it comes to my choice of tools. This means my stack consists of about 80% software I already know well, but I do allow myself 20% of the stack to explore tech I have less experience with. The exact ratio is not what’s important here, it’s more the fact that you should lean towards using proven technologies.</p><p>This also resonates with how <a href="https://en.wikipedia.org/wiki/Multi-armed_bandit" target="_blank" rel="noopener">Multi-armed bandits</a> work. You try to maximize your expected gain by taking advantage of what worked well in the past, while sometimes exploring new things to avoid missing out on a possible goldmine.</p><p><img src="https://panelbear.com/static/img/blog/bandits.png" alt="Balance new vs proven"></p><p>A more recent example of mine started as an embarrassingly simple Django app with no charts, all metrics were rendered on a plain HTML table, and all data was stored on a SQLite database. Took literally a weekend to get it up and running including manually deploying to a $5/mo VM. Low risk and high reward for my needs at the time.</p><p>Fast forward and as I added more features and began handling more page views for various websites, I started to notice that the codebase could use some refactoring. It also became increasingly repetitive to do things like deploying to new instances, issuing SSL certs, and keeping the DNS records up to date in case the IP address of my instances changed.</p><p>As a second iteration, I upgraded to a docker-compose setup plus lots of glue code. But soon enough I found myself reinventing what other tools already do well. There are multiple ways to solve each of these pain points, but in my case, it came down to using a tool I am very familiar with from my full-time job: Kubernetes.</p><p>Yes, I am well aware it can be overkill for a lot of projects out there, and I could have gotten away with a more traditional solution. But it works well for me, and I have been running production workloads with it for several years already. Please do not just blindly follow my path. Use what you already know best.</p><p>Kubernetes allowed me to simplify the operational aspects tremendously, and I feel comfortable debugging issues with it after having the pleasure of putting down multiple production fires for my employer over the years. It has also been around several years, there's lots of documentation, and a huge helpful community who can help. It'd argue that there's more documentation available than for any home-grown deployment system, or even EC2/Lambda/DigitalOcean for that matter.</p><p>As an added benefit, it also made it trivial when I migrated from DigitalOcean to Linode, and most recently to AWS (each migration took mostly an evening of changing my Terraform files and deploying them - I’m being serious). But that’s for another post.</p><h2>Let complexity come over time</h2><p>My point is, I moved into these technologies as the pain with the previous solution was higher than dealing with the new tech. But more importantly, it helped me ship features even faster to my customers while reducing the operational overhead for me.</p><p>If I had started with the more advanced setup from day one, I might have lost all motivation before I would have had the first version of Panelbear. The key is to solve the problems that are getting between you and your goals, not potential issues you believe one day will be yours.</p></div></div></div>]]>
            </description>
            <link>https://panelbear.com/blog/boring-tech/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25322651</guid>
            <pubDate>Sun, 06 Dec 2020 10:46:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Perils of File Typing]]>
            </title>
            <description>
<![CDATA[
Score 56 | Comments 36 (<a href="https://news.ycombinator.com/item?id=25322288">thread link</a>) | @panic
<br/>
December 6, 2020 | https://invisibleup.com/articles/34/ | <a href="https://web.archive.org/web/*/https://invisibleup.com/articles/34/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	
	
	<img src="https://invisibleup.com/articles/34/thumb.gif" alt="The Perils of File Typing thumbnail">
	
	

	
<p>Corrections added to the Creator/Type code section thanks to user "Somebody" on Hacker News</p>

<p>Suppose you double-click on a file on your computer. You're doing this so you can open the file and work with it. But does your operating system know what that means? How does it know <em>what</em> to open the file <em>in</em>? Let's look at some solutions that have been proposed over the years to solving this issue.</p>
<p>(fun fact: this originally started as a touchup of <a href="https://invisibleup.com/articles/2/">one of my oldest articles</a> before just kinda becoming this whole <em>thing</em>, so expect a bit of retreading.)</p>
<h2>Nothing</h2>
<p><img alt="IBM 709 in use" src="https://invisibleup.com/articles/34/IBM709.jpg"></p>
<p><strong>Used in</strong>: Early mainframes such as the <a href="https://en.wikipedia.org/wiki/IBM_704">IBM 704</a>, etc.</p>
<p>(Image credit: <a href="https://www.computer-history.info/Page4.dir/pages/IBM.704.dir/">Lawrence Livermore National Laboratory</a>)</p>
<p>What's a "file", anyways? It's a sequence of bytes on a disk, possibly floppy. Or a tape. (Cassette or paper, your choice.) Or on stacks of cards with holes in them. Or toggled in by hand on a front panel.</p>
<p>File types weren't relevant because <em>files</em> weren't really a thing. In the mainframe era, you typically 
1. loaded a program on to your computer from punch cards or a tape
2. fed input into that program either from a teletype terminal or from a different tape/card deck
3. received output from the teletype, a line printer, or yet another tape/card deck</p>
<p>Computers weren't complicated enough where there was any confusion as to what a file on a certain medium <em>was</em>, simply because there was so little to work with. If you had a stack of punchcards, that was your "file". Hope you labeled the box you put it in!</p>
<p>Tapes are more interesting, because they hold substantially more data. (A whopping 5.76 megabytes, stored on 3/4 of a kilometer of magentic tape. How exciting!) That said, storing more than one file on a tape was a strange task. Operating systems weren't really a <em>thing</em> yet. The best that existed were programming languages such as FORTRAN or COBOL that had statements for hardware tasks such as reading from or writing to a tape or punch card. For example, <a href="http://archive.computerhistory.org/resources/text/Fortran/102649787.05.01.acc.pdf">here's the manual for FORTRAN for the IBM 704.</a> We have several commands such as <code>READ</code> (from the punch card reader), <code>READ TAPE</code>, <code>PUNCH</code> (new cards), <code>PRINT</code> (to the printer), etc.</p>
<p>On the IBM tape units of the time (ex: the <a href="https://en.wikipedia.org/wiki/IBM_727">IBM 727</a>), tapes were separated into <em>files</em> and <em>records</em>. In FORTRAN, records were created on every <code>WRITE TAPE</code> command, and could be read with <code>READ TAPE</code> later. Records could be overwritten by using the <code>BACKSPACE</code> statement and then writing again. Files were collections of records, and could be created with an <code>END FILE</code> command.</p>
<p>As an aside, later programming languages such as C still share their heritage from this era. This is why we draw text to the screen with <a href="http://www.cplusplus.com/reference/cstdio/printf/"><code>printf</code></a> which long ago would have literally printed to a <a href="https://en.wikipedia.org/wiki/Teletype_Model_33">teletype terminal</a>, why we read files using <a href="http://www.cplusplus.com/reference/cstdio/rewind/"><code>rewind</code></a>, <a href="http://www.cplusplus.com/reference/cstdio/fseek/"><code>fseek</code></a>, <a href="http://www.cplusplus.com/reference/cstdio/fread/"><code>fread</code></a>, and <a href="http://www.cplusplus.com/reference/cstdio/fwrite/"><code>fwrite</code></a> as if we were on a tape drive still. Even <a href="http://www.asciitable.com/">ASCII</a>, the encoding most commonly used for the basic Latin alphabet, has code points for file, group, record, and unit separators. (This may also be related to block terminals, something that will be discussed in a future article.)</p>
<p>As mainframes moved onto more advanced batch processing and later interactive time-share operating systems like UNIX, <a href="https://en.wikipedia.org/wiki/OS/360_and_successors">OS/360</a>, <a href="https://en.wikipedia.org/wiki/Michigan_Terminal_System">Michigan Terminal System</a>, <a href="https://en.wikipedia.org/wiki/Incompatible_Timesharing_System">ITS</a>, etc., they gained more sophisticated methods of dealing with files than raw tape drive access. But then came the microcomputers.</p>
<h2>Type Codes</h2>
<p><img alt="Apple DOS file listing" src="https://invisibleup.com/articles/34/appledos.gif"></p>
<p><strong>Used in</strong>: <a href="https://en.wikipedia.org/wiki/Apple_DOS">Apple DOS for Apple II</a> (1978-1980), <a href="https://www.hpmuseum.org/hp28c.htm">HP-28</a> and <a href="https://www.hpmuseum.org/hp48s.htm">HP-48</a> series, etc.</p>
<p>We have floppy disks now. They can store a lot of files, rename them, delete them, etc. without too much issue. There's this neat computer called the Apple II that just came out. It uses these new-fangled disks, so it needs to figure out how to store files on it.</p>
<p>The way that Apple DOS (the Apple II's disk operating system for most of it's life) stored files is somewhat interesting. Each file has a name (up to 30 characters) and also a <em>type code</em>. 8 of them were defined but only 4 of them mattered:</p>
<ul>
<li>I (Integer BASIC program)</li>
<li>A (Applesoft BASIC program)</li>
<li>B (Binary files; either assembled programs or data)</li>
<li>T (ASCII text files)</li>
</ul>
<p>Apple DOS had some specific commands that interacted with these types. For instance, the <code>RUN</code> command worked on both Interger BASIC and Applesoft BASIC programs, and chose which one to use. <code>BRUN</code>, <em>binary run</em>, only worked on binary files. <code>OPEN</code>, <code>READ</code>, <code>WRITE</code>, and <code>CLOSE</code> all worked only on ASCII text files.</p>
<p><strong>The types more served as a way to help the operating system more so than you.</strong> This is especially evident in the late 80's and early 90's HP calculators such as the HP-28c and the HP-48GX. These calculators didn't have disks, but they did have persistent memory that could store objects into folders much like a computer.</p>
<p>These calculators used Reverse Polish Notation. Essentially, you do math by placing objects on the stack and then executing commands, which take things from the stack and put a new thing on. An <em>object</em> in RPN is something you placed on the stack. The HP-48's Advanced User's Reference Manual lists 32 distinct types, including real numbers, complex numbers, character strings, arrays, lists, variable names, executable programs, graphics objects, directories, etc. A <em>command</em> could be, say, <code>ADD</code> or some fancy plotting calculus stuff. Whatever they were, they needed to know what types they were dealing with so that they could either reject the input or properly work with it.</p>
<p>Like the Apple II, just having an integer for a type is perfectly okay because the types don't serve the user. They're just there so the operating system knows what a given chunk of bytes on the stack <em>is</em>. There are a few reserved spots for custom types, but for the most parts new types aren't expected to ever be added, nor should they be.</p>
<h3>File Extensions</h3>
<p><img alt="CP/M disk listing as seen on an Amstrad CPC" src="https://invisibleup.com/articles/34/cpm.gif"></p>
<p><strong>Used in</strong>: AMSDOS (Amstrad CPC), CP/M, MS-DOS, etc.</p>
<p>Microcomputers really started to gain in popularity with the likes of the ZX Spectrum, the Amstrad CPC and the Commodore 64 among others. These were fairly cheap and simple computers. When first launched, these came with nothing but cassette tape inputs, as disks were too expensive.</p>
<p>On these computers, you'd attach a cassette player using a standard AUX cord (although some, like the CPC, had a cassette player built in), and the computer would instruct you when to start and stop the tape. These cassette players usually came with a little counter that rolled up as the tape progressed, to help you tell where the tape was. When you insert a tape, you reset the counter to zero. When you want to <em>make</em> a file, you'd write down what the counter read, then save the file. To <em>load a specific file</em>, you'd seek the tape until you're at the location you've written down, then start reading.</p>
<p>More advanced computers such as the Amstrad CPC instead saved <a href="http://www.cpcwiki.eu/index.php/AMSDOS_Header">a header</a> with each file containing, among other things, a file name and extension. If asked for a specific file it could just read the tape until it found it. Later these computers gained disk drives, and any ad-hoc tape fiddling was replaced with a proper file system such as <a href="https://en.wikipedia.org/wiki/File_Allocation_Table">FAT</a> or <a href="https://en.wikipedia.org/wiki/Macintosh_File_System">MFS</a> that stored <em>where</em> a file was on a given disk and <em>what is was called</em>.</p>
<p>File codes are limited. It is nigh-on impossible to add more ones. What you have is what you got. So... what if we just made the codes out of letters? A couple of them? And they could be anything. Then programmers could come up with whatever file extensions they want and that's okay.</p>
<p>Suppose, in MS-DOS, you have a file named <code>REPORT.TXT</code>. <code>REPORT</code> is the file name, <code>TXT</code> is the extension. <strong>File extensions give an easy, consistent indicator of what a file contains.</strong> A <code>TXT</code> file contains text, a <code>BMP</code> file is a bitmap, etc. </p>
<p>Some file extensions, like <code>EXE</code>, <code>BAT</code>, <code>SYS</code> and <code>COM</code> had special meaning much in the same way that the Apple DOS codes had special meanings, but other than that they're just there to help the user. <strong>The user had to manually choose which program to use.</strong> This allowed for the user to choose what view or editor to use depending on what would be the most helpful. Unfortunately, there were no default programs. If the user didn't know which program, say, a <code>VIZ</code> file is for, they're out of luck. Is it a visualization? Some manga thing? The digital manifestation of a cute internet ghost who's staying up way too late geeking out about old computers? <em>The world may never know...</em></p>
<h3>Creator Codes</h3>
<p><strong>Used in:</strong> Classic Mac OS</p>
<p><img alt="File properties dialog on Classic Mac OS" src="https://invisibleup.com/articles/34/macinfo.gif"></p>
<p>Let's hop on over to the Macintosh for a quick second. It was a newfangled thing in 1984, and it had the opportunity to reinvent the wheel and break compatibility with CP/M and mainframe traditions. And so it did.</p>
<p>The original 128K Macintosh used 400K floppy disks, a not-completely-terrible amount of space for the time. It used the <a href="https://en.wikipedia.org/wiki/Macintosh_File_System">MFS</a>, which didn't support directories but <em>did</em> support files. It was also completely graphically driven. The Finder was supposed to be the primary way of interacting with files, and the <code>File &gt; Open</code> command could launch the program that made the file. How'd it do that?</p>
<p><strong>Instead of file extensions, the Macintosh used type and creator codes</strong>. These were 4-byte identifiers, much like file extensions, but there were two of them each with a different meaning. The type code was mean to represent the format the data was stored in, used to filter files in the Finder's "Open" dialog. The creator code was meant to indicate the application that created the file, and used by the Finder to choose which specific application to launch. Now, these weren't normally visible to the user. They just saw the file name and a icon for that type.</p>
<p>To do that, the system kept a database of codes and their associated icons and programs. When ran for the first time or moved from disk to disk, <strong>the Finder would read the program data and register in a database what creator codes and file types it supported.</strong> The Finder would then save this information on the disk containing the application. Later, <strong>when the user opened a file, the OS would check its type and creator code against its stored list to determine which application to use.</strong> This worked pretty well.</p>
<p><img alt="ResEdit view" src="https://invisibleup.com/articles/34/macresedit.gif"></p>
<p>A similar system was used for …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://invisibleup.com/articles/34/">https://invisibleup.com/articles/34/</a></em></p>]]>
            </description>
            <link>https://invisibleup.com/articles/34/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25322288</guid>
            <pubDate>Sun, 06 Dec 2020 09:27:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Monopoly Technology Platforms Are Colonizing Education]]>
            </title>
            <description>
<![CDATA[
Score 193 | Comments 106 (<a href="https://news.ycombinator.com/item?id=25322202">thread link</a>) | @partingshots
<br/>
December 6, 2020 | https://instituteforpubliceducation.org/monopoly-technology-platforms-are-colonizing-education/ | <a href="https://web.archive.org/web/*/https://instituteforpubliceducation.org/monopoly-technology-platforms-are-colonizing-education/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-746">
	<div>
		
		<div>
			<p>Perspectives<em>&nbsp;is an opportunity for Fellows and others to share their ideas in short, accessible essays.&nbsp;IPE/BC Fellows hold a range of views and interests relative to public education.</em></p>
<p><strong>Monopoly Technology Platforms are Colonizing Education</strong></p>
<p><strong>By Larry Kuehn</strong></p>
<p>The exposés of abuse by social media corporations like Google and Facebook have finally brought attention to the dangers of monopolies over our communications. The way these monopolies have been colonizing public education has, however, gone almost unnoticed. This is rampant privatization sneaking in as essential to “21<sup>st</sup> Century learning.”</p>
<p>The top five global capital corporations are technology platforms—Apple, Google, Microsoft, Amazon and Facebook. Platforms are a host for a variety of services and uses. All of the big five platform corporations have become too large in a short period of time to have any significant competition outside of this group. They compete against one another, adding services to secure their monopoly by offering users everything they do online.</p>
<p>If a new service is developed that seems to be gaining users, or that competes with an element of their platform, it is purchased and integrated into the platform—avoiding new competitors. Alternatively, they use their massive resources to develop a comparable app and push the potential competitor aside.</p>
<p>Snicek, in <a href="https://www.wiley.com/en-us/Platform+Capitalism-p-9781509504862"><em>Platform Capitalism</em></a>, points out that the development of these monopolies “introduces new tendencies within capitalism that pose significant challenges to a post-capitalist future.” Building public cooperative platforms becomes an impossible dream.</p>
<p>No surprise—these platforms have moved to colonize education. Public education represents a big chunk of potential revenue. Just as importantly, schools are where one can find most of the future potential consumers and users of the platform services.</p>
<p>Colonization is a process where a significant force moves into an area and dominates. It takes over not only the production and resources, but imposes—often by stealth and power—the processes and approaches and even values of the social and cultural environment. And, dominate is what the monopoly platforms are on track to do in public education.</p>
<p><img src="http://instituteforpubliceducation.org/wp-content/uploads/2019/01/G-Suite-For-Education-400x200.png" alt="" width="262" height="131" srcset="https://instituteforpubliceducation.org/wp-content/uploads/2019/01/G-Suite-For-Education-400x200.png 400w, https://instituteforpubliceducation.org/wp-content/uploads/2019/01/G-Suite-For-Education-768x384.png 768w, https://instituteforpubliceducation.org/wp-content/uploads/2019/01/G-Suite-For-Education.png 800w" sizes="(max-width: 262px) 100vw, 262px">The most successful colonizer has been Google. A recent report indicates that Google’s <em>G-Suite for Education</em> is being used by half the teachers and students in the U.S. Canada is fast approaching the same level of use. It includes a range of free software tools that can be used by students and teachers—word processing, presentations, spread sheets and the like. G-Suite incorporates “Classroom,” an integrated learning management system that keeps track of grades, attendance and more. And, of course, YouTube is linked to student use.</p>
<p>New elements are added frequently. “Google Sites” is promoted for student e-portfolios, because “every student should publish for the world.” Google acquired Workbench, integrated with Google Classroom to give “lessons connected to a variety of ‘maker’ activities focused on STEM.” It is part of Google’s plan to “help schools and educators address their universal needs around education content.”</p>
<p>Google, rather than democratic public institutions, therefore shapes what is on offer. Google’s position as colonizer is strengthened by the hardware increasingly used in schools—the Google Chromebook. <img src="http://instituteforpubliceducation.org/wp-content/uploads/2019/01/CB_canada.max-1000x1000-400x222.png" alt="" width="346" height="192" srcset="https://instituteforpubliceducation.org/wp-content/uploads/2019/01/CB_canada.max-1000x1000-400x222.png 400w, https://instituteforpubliceducation.org/wp-content/uploads/2019/01/CB_canada.max-1000x1000-768x425.png 768w, https://instituteforpubliceducation.org/wp-content/uploads/2019/01/CB_canada.max-1000x1000.png 1000w" sizes="(max-width: 346px) 100vw, 346px">It is less expensive than other computers because much of what it needs to operate is supplied by Google in the cloud—operating software, applications and memory. No need to build those into the computer.&nbsp; According to market reports, Chromebooks make up the majority of all computers sold to schools in the U.S. and are marketed globally.</p>
<p>However, one must have a gmail account to use these Google tools—so if a parent wants to protect the privacy of their child and refuses a gmail account that kid is left out while the rest of the class works away on their Chromebook and other Google tools. (See <a href="http://s3.documentcloud.org/documents/4497822/GAFE-Information-Letter-and-Consent-Form-page2.pdf">here</a> the kind of consent form parents are asked to sign, giving Google access to acquire and store student information outside of Canada.)</p>
<p><img src="http://instituteforpubliceducation.org/wp-content/uploads/2019/01/Screen-Shot-2018-12-31-at-4.20.52-PM-400x70.png" alt="" width="657" height="115" srcset="https://instituteforpubliceducation.org/wp-content/uploads/2019/01/Screen-Shot-2018-12-31-at-4.20.52-PM-400x70.png 400w, https://instituteforpubliceducation.org/wp-content/uploads/2019/01/Screen-Shot-2018-12-31-at-4.20.52-PM-768x135.png 768w, https://instituteforpubliceducation.org/wp-content/uploads/2019/01/Screen-Shot-2018-12-31-at-4.20.52-PM-1024x180.png 1024w, https://instituteforpubliceducation.org/wp-content/uploads/2019/01/Screen-Shot-2018-12-31-at-4.20.52-PM.png 1238w" sizes="(max-width: 657px) 100vw, 657px"></p>
<p>Google has even taken up teaching “internet safety,” with a program aimed at reaching 5 million students. Its core is a game for students in Grades three to six to teach them to avoid “schemers, hackers and other bad actors.” However, as critics point out, it doesn’t talk about privacy concerns when users’ personal information and actions are tracked online. Google conveniently ignores its role as a “bad actor.”</p>
<p>A <a href="https://journals.sagepub.com/doi/abs/10.1177/1474904116654917">Swedish study </a>of Google’s strategy concluded that “By making an implicit demarcation between two concepts (your) ‘data’ and (collected) ‘information’ Google can disguise the presence of a business model for online marketing and, at the same time, simulate the practices and ethics of a free public service institution.”</p>
<p>In “<a href="http://2017trends.hackeducation.com/data.html">The Weaponization of Education Data</a>,” Audrey Watters points out “the risk isn’t only hacking.&nbsp; It’s amassing data in the first place. It’s profiling. It’s tracking. It’s surveilling.”</p>
<p>Google isn’t alone in the business of colonizing education and student data—just the most successful so far. One competitor is Microsoft 365 Education, with a promise of “empowering every student on the planet to achieve more” and that it will “unlock limitless learning.”</p>
<p>It’s not an accident that it is “Microsoft 365” that is being pushed. It offers a cloud-based software and cloud storage for your work. It is the new business model for Microsoft: they don’t sell you software, you rent it—and you keep paying for it. And your work isn’t saved on your own computer, so you have to keep up your subscription. Like Google, they are hoping that students will keep using their tools when they finish being students.</p>
<p>Microsoft is imitating much of what Google offers, but by charging for the service rather than trading it for data. It offers apps, educator training and STEM lessons “to enrich science, technology, engineering and math classes.” They offer “budget friendly” Windows 10 devices with licences for Microsoft 365 Education.</p>
<p>The other major tech corporations have programs as well. Apple, for example, was the first into education with the Apple IIe and the “Apple Classroom of Tomorrow” way back in the 1980s. More recently it depended on the ease of use of the iPad, despite its cost, to sell classroom sets along with Pearson curriculum in an <a href="https://www.wired.com/2015/05/los-angeles-edtech/">ill-fated project with Los Angeles schools</a>.</p>
<p>Venture capitalists are hoping to find the magic app that will make a fortune. The potential market is indicated by expenditure of hundreds of millions each year on developing new products. The “winners” are likely to be bought up by one of the major corporations—or find their product idea taken by the monopolies.</p>
<p>Not enough attention is paid by education authorities or researchers to the shaping and distortion of education that is possible—even likely—by this colonization of education by technology monopolies.</p>
<p><em><strong>Larry Kuehn</strong>&nbsp;is an IPE/BC Fellow, IPE/BC director and Director of Research &amp; Technology for the British Columbia Teachers’ Federation.&nbsp;</em></p>


		</div><!-- .entry-content -->

		<!-- .entry-footer -->

		
<!-- .entry-auhtor -->
	</div><!-- .hentry-wrapper -->
</article></div>]]>
            </description>
            <link>https://instituteforpubliceducation.org/monopoly-technology-platforms-are-colonizing-education/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25322202</guid>
            <pubDate>Sun, 06 Dec 2020 09:07:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[VisiData in 60 Seconds]]>
            </title>
            <description>
<![CDATA[
Score 104 | Comments 14 (<a href="https://news.ycombinator.com/item?id=25322091">thread link</a>) | @luu
<br/>
December 6, 2020 | https://jsvine.github.io/intro-to-visidata/the-big-picture/visidata-in-60-seconds/ | <a href="https://web.archive.org/web/*/https://jsvine.github.io/intro-to-visidata/the-big-picture/visidata-in-60-seconds/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>TL;DR? Here’s a three-step introduction to VisiData.</p><div id="step-1-use-vd-to-open-a-data-file">
<h2>Step 1: Use <code><span>vd</span></code> to open a data file<a href="#step-1-use-vd-to-open-a-data-file" title="Permalink to this headline">¶</a></h2>
<p>Download <a download="" href="https://jsvine.github.io/intro-to-visidata/_downloads/83e70cf67e909f3ac177575439e5f3c5/faa-wildlife-strikes.csv"><code><span>faa-wildlife-strikes.csv</span></code></a>, a dataset of all aircraft-wildlife collisions <a href="https://wildlife.faa.gov/database.aspx">reported to the Federal Aviation Adminsitration</a> between 2010 and mid-2016.</p>
<p>From your terminal, move into the directory where you downloaded the dataset. Then run the following command:</p>
<div><div><pre><span></span>vd faa-wildlife-strikes.csv
</pre></div>
</div>
<p>If it worked, you should see something like this:</p>
<div>
<pre><span></span><span></span><span> OPERATOR           </span><span></span><span>|</span><span></span><span> ATYPE        </span><span></span><span>|</span><span></span><span> INCIDENT_DATE     </span><span></span><span>|</span><span></span><span> STATE </span><span></span><span>|</span><span></span><span> AIRPORT            </span><span></span><span>|</span><span></span><span> PHASE_OF_FLT</span><span></span><span>&gt;</span><span> 
</span><span></span><span> BUSINESS           </span><span></span><span></span><span>| PA-28        | 05/22/15 00:00:00 | FL    | VERO BEACH MUNICIP…| APPROACH     ║
</span><span></span><span></span><span> BUSINESS           </span><span></span><span>|</span><span> BE-1900</span><span>      </span><span>|</span><span> 06/18/15 00:00:00 </span><span>|</span><span> AK    </span><span>|</span><span> KENAI MUNICIPAL AR…</span><span>|</span><span> APPROACH     </span><span>║
</span><span></span><span> BUSINESS           </span><span></span><span>|</span><span> PA-46 MALIBU </span><span>|</span><span> 09/20/15 00:00:00 </span><span>|</span><span> TX    </span><span>|</span><span> DAVID WAYNE HOOKS …</span><span>|</span><span>              </span><span>║
</span><span></span><span> DELTA AIR LINES    </span><span></span><span>|</span><span> B-717-200    </span><span>|</span><span> 11/07/15 00:00:00 </span><span>|</span><span> MO    </span><span>|</span><span> LAMBERT-ST LOUIS I…</span><span>|</span><span> APPROACH     </span><span>║
</span><span></span><span> BUSINESS           </span><span></span><span>|</span><span> BE-90 KING   </span><span>|</span><span> 12/17/15 00:00:00 </span><span>|</span><span> FL    </span><span>|</span><span> POMPANO BEACH AIRP…</span><span>|</span><span> LANDING ROLL </span><span>║
</span><span></span><span> DELTA AIR LINES    </span><span></span><span>|</span><span> B-757</span><span>        </span><span>|</span><span> 07/17/15 00:00:00 </span><span>|</span><span> VI    </span><span>|</span><span> HENRY E ROHLSEN AR…</span><span>|</span><span>              </span><span>║
</span><span></span><span> DELTA AIR LINES    </span><span></span><span>|</span><span> B-717-200    </span><span>|</span><span> 08/02/15 00:00:00 </span><span>|</span><span> TX    </span><span>|</span><span> SAN ANTONIO INTL   </span><span>|</span><span> APPROACH     </span><span>║
</span><span></span><span> BUSINESS           </span><span></span><span>|</span><span> C-414</span><span>        </span><span>|</span><span> 08/03/15 00:00:00 </span><span>|</span><span> TX    </span><span>|</span><span> LONE STAR EXECUTIV…</span><span>|</span><span> DEPARTURE    </span><span>║
</span><span></span><span> ALLEGIANT AIR      </span><span></span><span>|</span><span> MD-80</span><span>        </span><span>|</span><span> 09/02/15 00:00:00 </span><span>|</span><span> FL    </span><span>|</span><span> TAMPA INTL</span><span>         </span><span>|</span><span> APPROACH     </span><span>║
</span><span></span><span> TRANS STATES AIRLI…</span><span></span><span>|</span><span> EMB-145</span><span>      </span><span>|</span><span> 09/07/15 00:00:00 </span><span>|</span><span> MO    </span><span>|</span><span> LAMBERT-ST LOUIS I…</span><span>|</span><span> APPROACH     </span><span>║
</span><span></span><span> BUSINESS           </span><span></span><span>|</span><span> C-172</span><span>        </span><span>|</span><span> 11/28/15 00:00:00 </span><span>|</span><span> FL    </span><span>|</span><span> OPA-LOCKA EXECUTIV…</span><span>|</span><span> APPROACH     </span><span>║
</span><span></span><span> GOVERNMENT         </span><span></span><span>|</span><span> EC120</span><span>        </span><span>|</span><span> 12/08/15 00:00:00 </span><span>|</span><span> CA    </span><span>|</span><span> NORMAN Y. MINETA S…</span><span>|</span><span>              </span><span>║
</span><span></span><span> AMERICAN AIRLINES  </span><span></span><span>|</span><span> A-321</span><span>        </span><span>|</span><span> 05/06/15 00:00:00 </span><span>|</span><span> FL    </span><span>|</span><span> FORT LAUDERDALE/HO…</span><span>|</span><span> APPROACH     </span><span>║
</span><span></span><span> EXPRESSJET AIRLINES</span><span></span><span>|</span><span> CRJ100/200   </span><span>|</span><span> 05/06/15 00:00:00 </span><span>|</span><span> AR    </span><span>|</span><span> FORT SMITH REGIONA…</span><span>|</span><span> CLIMB</span><span>        </span><span>║
</span><span></span><span> MESA AIRLINES      </span><span></span><span>|</span><span> CRJ900</span><span>       </span><span>|</span><span> 05/08/15 00:00:00 </span><span>|</span><span> AR    </span><span>|</span><span> BILL AND  HILLARY …</span><span>|</span><span> LANDING ROLL </span><span>║
</span><span></span><span> BUSINESS           </span><span></span><span>|</span><span> HELICOPTER   </span><span>|</span><span> 05/06/15 00:00:00 </span><span>|</span><span>       </span><span>|</span><span> UNKNOWN</span><span>            </span><span>|</span><span> En Route     </span><span>║
</span><span></span><span> DELTA AIR LINES    </span><span></span><span>|</span><span> A-320</span><span>        </span><span>|</span><span> 05/07/15 00:00:00 </span><span>|</span><span> CA    </span><span>|</span><span> METRO OAKLAND INTL </span><span>|</span><span>              </span><span>║
</span><span></span><span> DELTA AIR LINES    </span><span></span><span>|</span><span> A-320</span><span>        </span><span>|</span><span> 05/08/15 00:00:00 </span><span>|</span><span> UT    </span><span>|</span><span> SALT LAKE CITY INTL</span><span>|</span><span>              </span><span>║
</span><span></span><span> LUFTHANSA          </span><span></span><span>|</span><span> A-380</span><span>        </span><span>|</span><span> 05/10/15 00:00:00 </span><span>|</span><span> TX    </span><span>|</span><span> GEORGE BUSH INTERC…</span><span>|</span><span> CLIMB</span><span>        </span><span>║
</span><span></span><span> BUSINESS           </span><span></span><span>|</span><span> C-172</span><span>        </span><span>|</span><span> 05/08/15 00:00:00 </span><span>|</span><span> FL    </span><span>|</span><span> ORLANDO SANFORD IN…</span><span>|</span><span> APPROACH     </span><span>║
</span><span></span><span> SPIRIT AIRLINES    </span><span></span><span>|</span><span> A-319</span><span>        </span><span>|</span><span> 05/10/15 00:00:00 </span><span>|</span><span> IL    </span><span>|</span><span> CHICAGO O'HARE INT…</span><span>|</span><span> CLIMB</span><span>        </span><span>║
</span><span></span><span> EXPRESSJET AIRLINES</span><span></span><span>|</span><span> EMB-145</span><span>      </span><span>|</span><span> 05/11/15 00:00:00 </span><span>|</span><span> AL    </span><span>|</span><span> BIRMINGHAM-SHUTTLE…</span><span>|</span><span> LANDING ROLL </span><span>║
</span><span></span><span>1› faa-wildlife-strikes| user_macros | saul.pw/VisiData v2.1 | opening datasets/        73448 rows </span><span> </span>
</pre>
</div>
</div><div id="step-2-test-drive-a-frequency-table">
<h2>Step 2: Test-drive a frequency table<a href="#step-2-test-drive-a-frequency-table" title="Permalink to this headline">¶</a></h2>
<p>One of VisiData’s strengths is how quickly it lets you summarize your data. Frequency tables are a great example. To create one, press <kbd>Shift+F</kbd>.</p>
<p>If it worked, you should see something like this:</p>
<div>
<pre><span></span><span></span><span> OPERATOR           </span><span></span><span>║</span><span></span><span>↓count♯</span><span></span><span>|</span><span></span><span> percent%</span><span></span><span>|</span><span></span><span> histogram                                         ~</span><span></span><span>║</span><span>        
</span><span></span><span> UNKNOWN            </span><span></span><span></span><span>║ 23076 |   31.42 | ************************************************** ║</span><span>        
</span><span></span><span> SOUTHWEST AIRLINES </span><span></span><span>║</span><span>  7752 </span><span>|</span><span>   10.55 </span><span>|</span><span> ****************</span><span>                                   </span><span>║</span><span>        
</span><span></span><span> BUSINESS           </span><span></span><span>║</span><span>  5868 </span><span>|</span><span>    7.99 </span><span>|</span><span> ************</span><span>                                       </span><span>║</span><span>        
</span><span></span><span> AMERICAN AIRLINES  </span><span></span><span>║</span><span>  4337 </span><span>|</span><span>    5.90 </span><span>|</span><span> *********</span><span>                                          </span><span>║</span><span>        
</span><span></span><span> DELTA AIR LINES    </span><span></span><span>║</span><span>  2817 </span><span>|</span><span>    3.84 </span><span>|</span><span> ******</span><span>                                             </span><span>║</span><span>        
</span><span></span><span> FEDEX EXPRESS      </span><span></span><span>║</span><span>  2709 </span><span>|</span><span>    3.69 </span><span>|</span><span> *****   </span><span>                                           </span><span>║</span><span>        
</span><span></span><span> UNITED AIRLINES    </span><span></span><span>║</span><span>  2194 </span><span>|</span><span>    2.99 </span><span>|</span><span> ****</span><span>                                               </span><span>║</span><span>        
</span><span></span><span> US AIRWAYS         </span><span></span><span>║</span><span>  1885 </span><span>|</span><span>    2.57 </span><span>|</span><span> ****</span><span>                                               </span><span>║</span><span>        
</span><span></span><span> UPS AIRLINES       </span><span></span><span>║</span><span>  1773 </span><span>|</span><span>    2.41 </span><span>|</span><span> ***</span><span>                                                </span><span>║</span><span>        
</span><span></span><span> SKYWEST AIRLINES   </span><span></span><span>║</span><span>  1769 </span><span>|</span><span>    2.41 </span><span>|</span><span> ***</span><span>                                                </span><span>║</span><span>        
</span><span></span><span> JETBLUE AIRWAYS    </span><span></span><span>║</span><span>  1740 </span><span>|</span><span>    2.37 </span><span>|</span><span> ***</span><span>                                                </span><span>║</span><span>        
</span><span></span><span> EXPRESSJET AIRLINES</span><span></span><span>║</span><span>  1347 </span><span>|</span><span>    1.83 </span><span>|</span><span> **   </span><span>                                              </span><span>║</span><span>        
</span><span></span><span> AMERICAN EAGLE AIR…</span><span></span><span>║</span><span>  1041 </span><span>|</span><span>    1.42 </span><span>|</span><span> **</span><span>                                                 </span><span>║</span><span>        
</span><span></span><span> ENVOY AIR          </span><span></span><span>║</span><span>   883 </span><span>|</span><span>    1.20 </span><span>|</span><span> *   </span><span>                                               </span><span>║</span><span>        
</span><span></span><span> ALASKA AIRLINES    </span><span></span><span>║</span><span>   835 </span><span>|</span><span>    1.14 </span><span>|</span><span> * </span><span>                                                 </span><span>║</span><span>        
</span><span></span><span> REPUBLIC AIRLINES  </span><span></span><span>║</span><span>   804 </span><span>|</span><span>    1.09 </span><span>|</span><span> *</span><span>                                                  </span><span>║</span><span>        
</span><span></span><span> MESA AIRLINES      </span><span></span><span>║</span><span>   693 </span><span>|</span><span>    0.94 </span><span>|</span><span> *</span><span>                                                  </span><span>║</span><span>        
</span><span></span><span> AIR WISCONSIN AIRL…</span><span></span><span>║</span><span>   623 </span><span>|</span><span>    0.85 </span><span>|</span><span> *</span><span>                                                  </span><span>║</span><span>        
</span><span></span><span> PSA AIRLINES       </span><span></span><span>║</span><span>   577 </span><span>|</span><span>    0.79 </span><span>|</span><span> *</span><span>                                                  </span><span>║</span><span>        
</span><span></span><span> PRIVATELY OWNED    </span><span></span><span>║</span><span>   516 </span><span>|</span><span>    0.70 </span><span>|</span><span> *</span><span>                                                  </span><span>║</span><span>        
</span><span></span><span> PHI INC            </span><span></span><span>║</span><span>   491 </span><span>|</span><span>    0.67 </span><span>|</span><span> *     </span><span>                                             </span><span>║</span><span>        
</span><span></span><span> SHUTTLE AMERICA    </span><span></span><span>║</span><span>   467 </span><span>|</span><span>    0.64 </span><span>|</span><span> *</span><span>                                                  </span><span>║</span><span>        
</span><span></span><span>2› faa-wildlife-strikes_OPERATOR_freq|</span><span>                         </span><span></span><span> </span><span>        </span><span></span><span>        F         282 bins </span><span> </span>
</pre>
</div>
</div><div id="step-3-read-visidata-s-manual-page">
<h2>Step 3: Read VisiData’s manual page<a href="#step-3-read-visidata-s-manual-page" title="Permalink to this headline">¶</a></h2>
<p>VisiData’s “<a href="http://visidata.org/man/">quick reference guide</a>” enumerates all of VisiData’s commands and features. You can <a href="http://visidata.org/man/">read it online</a> or access it from anywhere within VisiData by pressing the <kbd>F1</kbd> key or typing <kbd>Control-h</kbd>:</p>
<div>
<pre>vd(1)                        Quick Reference Guide                       vd(1)                      
<span>NAME</span>                     
     <span>VisiData</span> -- a terminal utility for exploring and arranging tabular data                        
<span>SYNOPSIS</span>                 
     <span>vd</span> [<span>options</span>] [<span>input</span> ...]                     
     <span>vd</span> [<span>options</span>] <span>--play</span> <span>cmdlog</span> [<span>-w</span> <span>waitsecs</span>] [<span>--batch</span>] [<span>-o</span> <span>output</span>] [<span>field</span><span></span><span></span><span>=</span><span></span><span></span><span>value</span>]                   
     <span>vd</span> [<span>options</span>] [<span>input</span> ...] <span>+</span><span></span><span></span><span>toplevel</span>:<span>subsheet</span>:<span>col</span>:<span>row</span>                                            
<span>DESCRIPTION</span>              
     <span>VisiData</span> is an easy-to-use multipurpose tool to explore, clean, edit, and restructure          
     data. Rows can be selected, filtered, and grouped; columns can be rearranged, trans-           
     formed, and derived via regex or Python expressions; and workflows can be saved, doc-          
     umented, and replayed.                       
   <span>REPLAY</span> <span>MODE</span>           
     <span>-p</span>, <span>--play</span>=<span>cmdlog</span>       replay a saved <span>cmdlog</span> within the interface                             
     <span>-w</span>, <span>--replay-wait</span>=<span>seconds</span>                    
                             wait <span>seconds</span> between commands                                          
     <span>-b</span>, <span>--batch</span>             replay in batch mode (with no interface)                               
     <span>-o</span>, <span>--output</span>=<span>file</span>       save final visible sheet to <span>file</span> as .tsv                               
:                        
</pre>
</div>
<div>
<p>Note</p>
<p>If you open the manual from within VisiData it will launch in your terminal’s “pager” program —&nbsp;typically the <a href="https://en.wikipedia.org/wiki/Less_(Unix)">less program</a>. To move around:</p>
<table>
<colgroup>
<col width="55%">
<col width="45%">
</colgroup>
<thead>
<tr><th>Keystroke(s)</th>
<th>Action</th>
</tr>
</thead>
<tbody>
<tr><td><kbd>Space</kbd> / <kbd>b</kbd></td>
<td>Scroll forward/backward</td>
</tr>
<tr><td><kbd>/</kbd> + <em>search term</em> + <kbd>Enter</kbd></td>
<td>Search for <em>search term</em></td>
</tr>
<tr><td><kbd>n</kbd> / <kbd>N</kbd></td>
<td>Go to next/previous search match</td>
</tr>
<tr><td><kbd>q</kbd></td>
<td>Exit and return to VisiData</td>
</tr>
</tbody>
</table>
<p>You can find additional commands <a href="https://en.wikipedia.org/wiki/Less_(Unix)#Frequently_used_commands">here</a>.</p>
</div>
</div></div>]]>
            </description>
            <link>https://jsvine.github.io/intro-to-visidata/the-big-picture/visidata-in-60-seconds/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25322091</guid>
            <pubDate>Sun, 06 Dec 2020 08:41:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lessons for Early Stage Founders]]>
            </title>
            <description>
<![CDATA[
Score 123 | Comments 22 (<a href="https://news.ycombinator.com/item?id=25321667">thread link</a>) | @sarathyweb
<br/>
December 5, 2020 | https://calv.info/early-stage-lessons | <a href="https://web.archive.org/web/*/https://calv.info/early-stage-lessons">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>In Segmentâ€™s early days, we hit countless problems as a founding team. And at the time, I thought those problems were unique to our own special snowflake of a founding journey. I chalked it up to us being new grads and first-time founders.</p><p>But as I've worked with more and more startups, I've realized just how wrong I was.</p><p>Over the past five years, I've made about 25 different seed-stage investments. In doing so, it's taught me a <em>LOT</em> about the common errors that startup founders make. Even across different industries and levels of experience, I see founders hitting the exact same set of problems we encountered in the early days of Segment!</p><p>This post shares a handful of the top lessons that benefit todayâ€™s early stage founders. Itâ€™s a list of the things I wish weâ€™d figured out earlier at Segment. [1]</p><p>This sounds incredibly boring... but the #1 mistake I see startups making is that they donâ€™t set goals. If you take one thing from this post, it's that you should set goals for where you want to be.</p><p>For the longest time at Segment, we didn't have goals. We moved ahead in various (often random) directions, and we would launch features consistently... but we never really set goals at all.</p><p>As we grew the company, we started to lose momentum. Teams were spending time on a bunch of stuff that frankly just didn't really matter to the overall business.</p><p>It wasn't until we hired our VP Eng, Tido, that we finally started setting focused and audacious product goals. Just by verbalizing where we wanted to go and then grading our results, our velocity improved by an order of magnitude.</p><p>I don't care if you call them OKRs, sprints, or something else entirely. Just set a deadline when you want to have something done and a metric you want to move or some other concrete result.</p><p>When early stage founders do attempt to set goals, I often see them agonize over what specific goals to choose. In practice, a "pretty good goal" is way better than "no goals at all". Perfect is the enemy of good.</p><p>If you don't yet have product-market fit, your goal should probably be getting your first 3-5 customers using the product. If you've hit the level where you now have dozens of users, your goal should be growing by an order of magnitude. It's better to get in the habit of setting and driving towards goals rather than being too worried about their exact semantics. Worst case, you just pick a better goal later.</p><p>A great set of goals answers the question: <em><strong>"what would have to be true in order for us to feel good about our progress at the end of the month?"</strong></em><em> [2]</em></p><p>If each teammate can independently answer "what are our goals for the month?" in the same way, you'll know you've succeeded. If youâ€™re looking for prior art, read <a href="https://www.amazon.com/Measure-What-Matters-Google-Foundation/dp/0525536221">Measure What Matters</a>. </p><p>If you strictly focus on making things true by a certain date, you are bound to make at least some progress towards your end result. </p><p>At the end of the day, every billion-dollar startup is really just the sum of many small deltas.</p><p>Let's get one thing straight: your investors won't know everything. But investors won't know <em>anything</em> if you don't keep them updated on how things are going.</p><p>For the longest time, we were fearful of our Segment investors, to the point that we wouldn't bother sending them emails unless they asked about us. I can say now with confidence that this was 100% the wrong approach.</p><p>We worried that investors would think that we were screwing up (true) and failing (true as well!). And while that might be the case, a founder-friendly investor won't think that way. Investors, especially angels, invested because they believe in <em>you</em>. If I didn't think a team would go somewhere, I wouldn't put money in.</p><p>With each investor, <strong>include the goals you're working towards, as well as the asks for them</strong>. I think monthly is about the right cadence for this in the early days, moving to quarterly around Series A/B time when you start partnering more with a few board members.</p><p>Simply writing the updates should clarify your own thinking tremendously. If it takes you more than 1-2h to put together an update on the most important things happening at the company, it's probably a sign that you should be doing more thinking about the big picture.</p><p>When asking for help, the things that our investors have been able to help us with evolved quite a bit over time. But here's a good rule of thumb for what to ask for:</p><ul><li><p><u>Seed/Pre-seed</u>: user-testing, intros to beta users, hiring</p></li><li><p><u>Series A</u>: hiring, early customers, go-to-market</p></li><li><p><u>Series B/C+</u>: comparables at other companies, senior/exec hires, specific expertise around things like management, infrastructure, systems, etc.</p></li></ul><p>Not all investors will be able to help with everything. But at the very least, sending them information will help you be top of mind. I've lost track of how many times a moment of serendipity where I'm catching up with an old friend has led to a meaningful conversation for a company I've invested in.</p><p>As an extra bonus, the strongest startups send these updates to everyone on their team. It's amazing how much putting the goals in writing helps everyone stay on the same page about what's most important.</p><p>One other note here: take pictures. I now wish we had far more pictures of Segment at every stage of the company. They help turn investor updates into cherished memories.</p><p>Okay, this lesson is taken directly from the YC playbook. And YET, I see so many founders (including YC founders) fail to launch their product. </p><p>If no one notices your launch... just ignore it and then launch again. If you're doing things right, you'll never run out of stuff to launch! [3]</p><p>Why is launching so important? Let me share a personal story...</p><p>We spent about 1.5 years building different iterations of analytics tools. For every iteration, we had a waitlist that users could sign up to use. We personally reached out to the users who we thought were the best fits, and then tried to set up time to use the product. </p><p>The result? Nobody cared. We had no users. We never launched. </p><p>When we finally launched Segment in it's current incarnation, we threw out that approach entirely. We put up a self-service flow, and let anyone who wanted to sign up for it.</p><p>That's when something strange happened... we attracted an entirely new set of developers who just were crawling out of the woodwork and excited to use the new product we'd built. They were coming from companies far outside of SV that we'd never heard of.</p><p>It floored me.</p><p><strong>Lesson learned: the people you happen to be talking to now are probably not the people who have the biggest problem in your space. Do everything you can to reach the folks with the biggest problem, and then, reduce any barriers they might encounter.</strong></p><p>I expect a bunch of you reading this post to ignore this advice, just like we did in the early days. It takes a certain confidence to launch something you've built and put it out there for the world to see. Ultimately though, the rewards are worth it. You'll see users coming from communities you've never even heard of.</p><p>Let me tell you a tale of two startups.</p><p><strong>Startup A</strong> is constantly putting up interesting content on their blog. Their founders are sharing product launches, engineering posts, and creatively brainstorming about what it takes to solve problems in their market.</p><p><strong>Startup B</strong> is operating in stealth. You can't find much about them online, but one of the founders reached out with a nice personalized email mentioning their funding by a top-tier VC. </p><p>Suppose you're looking for a job... do you pick Startup A or Startup B? In my experience, A almost always wins. Momentum is a compounding force.</p><p><strong>Unless you are working in a space that heavily depends on IP, you should probably be publishing more content about what you are doing.</strong> This could be open source, it could be a weekly newsletter, it could be a changelog. [4]</p><p>Whatever it is, it's going to help you both hire <em>and</em> attract customers. So much of the internet is merely about consuming, that just by putting ideas out there, youâ€™ll have a leg up on the competition.</p><p>In the early days of Segment, our <a href="https://segment.com/blog/show-hn-to-series-d/">user acquisition was powered by open source projects and blog posts</a>. But I've seen founders have success with Twitter, Substacks, Podcasts and a variety of different channels.</p><p>If you're looking for inspiration, the <a href="https://railway.app/changelog">Railway</a> and <a href="https://linear.app/changelog">Linear</a> changelogs are epic examples. Companies like <a href="https://baremetrics.com/blog/i-sold-baremetrics">Baremetrics</a> and <a href="https://buffer.com/resources/shareholder-update-q2-2020-and-july/">Buffer</a> differentiated themselves by just being open and honest. <a href="https://stripe.com/blog/globe">Stripe</a> and <a href="https://www.figma.com/blog/behind-the-feature-the-making-of-the-new-auto-layout/">Figma's blogs</a> not only share what they build, but how they built it.</p><p>There are three big inputs that all startups need to continue growing</p><ol><li><p>product capabilities</p></li><li><p>customers and users</p></li><li><p>hiring</p></li></ol><p>I've put them in roughly the order that most teams encounter them. </p><p>Startups begin with a small product that has a modicum of utility. It starts attracting a handful of customers organically. And as more and more customers start using the product, the founders realize that they need extra help to stay on top of all of those requests.</p><p>Remember though, the real goal here is #2. Itâ€™s not the size of your team, itâ€™s the value youâ€™re able to provide to the world. [5]</p><p>I see hiring a big team before you have product-market fit as a red flag. If the company doesn't yet have a set direction, it's going to be harder to pivot with 10 people than it is with 3.</p><p>But, I've worked with startups who have traction and runway... and just seem to be spinning their wheels under load from existing customers.</p><p>I get it. Hiring isn't the most fun, especially for an introvert. It's a lot of interviewing and feeling like there's a lot of rejection. Rejecting people sucks. Losing candidates sucks. For many of our roles at Segment, we've had to talk with 50-100 different people to make an eventual hire.</p><p><strong>If you have 24 months of runway, and a clear list of things youâ€™d do if you had more copies of yourself: you probably aren't spending time to hire the people you need.</strong></p><p>At Segment, my co-founder <a href="https://twitter.com/ivolo">Ilya</a> fulfilled this role. It was back in 2014, we were 12 people at the time, had raised a $10m Series A, and had $1m in revenue.</p><p>Thing…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://calv.info/early-stage-lessons">https://calv.info/early-stage-lessons</a></em></p>]]>
            </description>
            <link>https://calv.info/early-stage-lessons</link>
            <guid isPermaLink="false">hacker-news-small-sites-25321667</guid>
            <pubDate>Sun, 06 Dec 2020 06:46:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How does Brown University know where you are?]]>
            </title>
            <description>
<![CDATA[
Score 203 | Comments 137 (<a href="https://news.ycombinator.com/item?id=25319392">thread link</a>) | @jswrenn
<br/>
December 5, 2020 | https://jack.wrenn.fyi/blog/brown-location-surveillance | <a href="https://web.archive.org/web/*/https://jack.wrenn.fyi/blog/brown-location-surveillance">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>In September 2020, Brown University <a href="https://www.browndailyherald.com/2020/09/28/remote-students-receive-emails-brown-accusing-violating-code-student-conduct">accused students</a> of lying about their location; e.g.:</p>
<p><img src="https://jack.wrenn.fyi/blog/brown-location-surveillance/notice.png" height="auto" width="100%" alt="The University has learned that between September 14, 2020 and September 21, 2020 you were allegedly in the Providence area during which time your location of study was listed as remote. This alleged behavior is a violation of the Student Code of Conduct and the COVID-19 Campus Safety Policy. A copy of the Student Commitment to COVID-19 Community Health and Safety Requirements is attached for your review, along with this link to the COVID-19 Campus Safety Policy. failure to abide by these requirements is a violation of the Code of Student Conduct. 
Based on the details of the incident and your student conduct history, the Office of Student Conduct &amp; Community Standards has decided to allow you the opportunity to accept responsibility for the following prohibited conduct without having a COVID-19 Dean's Review Meeting:
• D.8 Failure to Comply
• D.13 Misrepresentation
"></p>
<p><strong>What was Brown's basis for these accusations?</strong></p>
<p>In an <a href="https://www.browndailyherald.com/2020/09/28/remote-students-receive-emails-brown-accusing-violating-code-student-conduct">interview with The Brown Daily Herald</a>, University Spokesperson Brian Clark said the University evaluated a variety of indicators, including:</p>
<ol>
<li>indications of building access,</li>
<li>indications of accessing private electronic services,</li>
<li>indications of accessing secure networks, and</li>
<li>reports from community members.</li>
</ol>
<p>The mechanics of that last indicator are pretty self-explanatory, but what about the others? <a href="https://it.brown.edu/services/type/canvas-learning-management-system">Canvas</a> <em>doesn't</em> <a href="https://knowyourmeme.com/memes/google-wants-to-know-your-location">Want To Know Your Location</a>. <strong>In this post, I'm going to break down the technical mechanisms behind each of these indicators.</strong></p>
<p>For the most part, I do not have insider knowledge on how Brown reached its decisions. Rather, I'm going to consider each of the indicators Brian Clark named, and describe the technical mechanisms to which Brown <em>could</em> have availed itself to generating location data.</p>
<h2 id="indications-of-building-access">Indications of Building Access</h2>
<p>This is an easy one. Brown's buildings are located on Brown's campus. Brown's campus is in Providence. If you are in Brown's buildings, you are on Brown's campus, in Providence. QED.</p>
<p>At Brown, building access is primarily regulated with electronic control systems (namely Software House's <a href="https://www.swhouse.com/products/software_CCURE9000.aspx"><strong>C•CURE 9000</strong></a> system), not mechanical keys.</p>
<p>Encoded on <a href="https://en.wikipedia.org/wiki/Magnetic_stripe_card#Track_2">track 2</a> of the magnetic stripe on every University ID card is a sixteen digit number that uniquely identifies the card:</p>
<p><img src="https://jack.wrenn.fyi/blog/brown-location-surveillance/brown-id-card-back.jpg" height="auto" width="100%" alt="Image of back of Brown ID card. A tall magnetic stripe runs across the entire width of the card."></p>
<p>Well, that's underwhelming — of <em>course</em> you can't <em>see</em> it! However, up until 2017 or 2018, this number was also <em>printed</em> on the front of ID cards, just above the card-holder's name:</p>
<p><img src="https://jack.wrenn.fyi/blog/brown-location-surveillance/brown-id-card-front.jpg" height="auto" width="100%" alt="Image fo the front of a Brown ID card, displaying the building access code: 6009553660926201"></p>
<p>This pseudo-random identifier (well, its last ten digits) are what uniquely identify you whenever you swipe your Brown ID card <em>anywhere</em>. And, if you lose your Brown ID card, this is the <em>only</em> thing that's changed when you're issued a replacement. Convenient! In contrast, when you lose your dorm room's mechanical key, Brown must replace (or rather, <a href="https://en.wikipedia.org/wiki/Rekeying">rekey</a>) the locks.</p>
<p>But, <em>also</em> unlike a mechanical key, <em>every</em> swipe of a Brown ID card is logged in a central database. <strong>The C•CURE 9000 lets administrators view the complete historical building access history of a person.</strong> Last Spring, Brown used this mechanism to identify and prod students who were slow to evacuate Providence.</p>
<h2 id="indicators-from-electronic-services">Indicators from Electronic Services</h2>
<p>University web services like Canvas <em>don't</em> directly ask you for your location. Nonetheless, accessing these services leaves a location finger print: your IP address.</p>
<p>Your <a href="https://en.wikipedia.org/wiki/IP_address">IP address</a> is a number that identifies your device (computer, phone, etc.) for the purposes of network routing. In principle, nobody but you and your internet provider know the <em>exact</em> mapping of your IP address to your physical address.</p>
<p>In practice, IP addresses can be used to <em>roughly</em> geolocate a device. Batches of IP addresses are associated <em>loosely</em> with geographic areas. Since every web service access leaves an IP address as a trace, there are tremendous incentives for advertisers to be able accurately identify what city or town an IP address is probably associated with.</p>
<p>Brown probably <em>isn't</em> analyzing the access logs of its <em>individual</em> web services (like Canvas). Rather, they need only to audit the access logs of its three identity access management (IAM) systems:</p>
<ul>
<li>The <a href="https://workspace.google.com/">Google Workplace</a> IAM system is used to control access to your @brown.edu email, and to the various Google Drive services. <a href="https://support.google.com/a/answer/4580120?hl=en"><strong>Google Workplace</strong> provides administrators with login audit logs that include users' IP addresses.</a></li>
<li>The <a href="https://www.shibboleth.net/">Shibboleth</a> IAM system controls access to all <em>other</em> Brown web services, such as Canvas. It's what you think of as your "Brown account". Shibboleth is <em>very</em> flexible, and can be <a href="https://wiki.shibboleth.net/confluence/display/IDP30/AuditLoggingConfiguration#AuditLoggingConfiguration-GenericFields">configured to log IP addresses</a>.</li>
<li><a href="https://duo.com/">DUO</a> is used to provide two-factor authentication for Shibboleth logins. <a href="https://help.duo.com/s/article/1023?language=en_US#docs-internal-guid-0aa3b4ce-c686-7559-8814-1377592fce4a:%7E:text=Access%20Device">It too provides administrators with detailed access logs</a>.</li>
</ul>
<p>You can partly view your Google Workplace login history for yourself by opening your Brown email and clicking "Details" in the bottom right-hand corner of the page; e.g.:</p>
<p><img src="https://jack.wrenn.fyi/blog/brown-location-surveillance/gmail-account-activity.png" height="auto" width="100%"></p>
<p>With <em>either</em> of these access logs in hand, Brown could then turn to any number of geolocation services (<a href="https://tools.keycdn.com/geo">like this one</a>) to guess your physical location.</p>
<h2 id="indicators-from-secure-networks">Indicators from Secure Networks</h2>
<p>This is another easy one. Brown's WiFI network <a href="https://jack.wrenn.fyi/blog/blog/brown-location-surveillance/Campus_Wireless_Coverage_Map_24x36_1.pdf">blankets Brown's campus</a>. Brown's campus is in Providence. If you are on Brown's WiFi network, you are on Brown's campus. QED.</p>
<p>What might surprise you is the sheer depth of surveillance that's capable with WiFi alone. This section will <em>barely</em> scratch the surface.</p>
<h3 id="identification">Identification</h3>
<p>Brown's WiFi routers each broadcast three <a href="https://en.wikipedia.org/wiki/Service_set_(802.11_network)">service sets</a>:</p>
<ol>
<li><a href="https://it.brown.edu/services/type/wireless-network-brown">Brown</a></li>
<li><a href="https://it.brown.edu/services/type/wireless-network-eduroam">eduroam</a></li>
<li><a href="https://it.brown.edu/services/type/wireless-access-brown-guest">Brown Guest</a></li>
</ol>
<p>The Brown and eduroam networks require that you authenticate with your Brown account credentials. Brown University is thus able to identify the owner of any device connected to these networks.</p>
<p>While Brown Guest does <em>not</em> require authentication, it still provides mechanisms of identification. Your network devices broadcast a unique identifier called a <a href="https://en.wikipedia.org/wiki/MAC_address"><strong>MAC address</strong></a>.</p>
<p><a href="https://drawings.jvns.ca/mac-address/"><img type="image/svg+xml" src="https://drawings.jvns.ca/drawings/mac-address.svg" height="auto" width="100%" alt="Comic by Julia Evans. Text: Every computer on the internet has a network card. When you make HTTP requests with Ethernet/WiFi, every packet gets sent to a MAC address. (&quot;Wait, how do I know someone else on the same network isn't reading all my packets?&quot; &quot;You don't! That's one reason we use HTTPS &amp; secure WiFi networks.&quot;) Your router has a table that maps IP addresses to MAC addresses.  (Read about ARP for more.)
"></a></p>
<p>Brown <a href="https://it.brown.edu/computing-policies/network-connection-policy#32:%7E:text=CIS%20maintains%20a%20database%20of%20unique,a%20computer%20when%20it%20is%20necessary.">maintains databases of the MAC addresses of all connected devices</a>.</p>
<p>If you have ever connected to an authenticated network, Brown will be able to de-anonymize your connections to Brown Guest — <em>unless</em> your device implements <a href="https://en.wikipedia.org/wiki/MAC_address#Randomization">MAC address randomization</a>, which (as the name suggests) randomizes your device's MAC address on a per-network basis.</p>
<h3 id="localization">Localization</h3>
<p>Brown's access points log the MAC addresses of the devices that have connected to them. As of 2015, Brown retained these logs for at least several years — possibly indefinitely. Since there are so many access points on campus, which access point you are connected to can narrow your location down to a particular room. <strong>Combined, these logs paint a <em>very</em> accurate picture of your location on campus at any time.</strong></p>
<p>You do not need to be <em>actively</em> browsing the internet for Brown to know where you are via this mechanism. As you walk through campus, your phone likely <em>automatically</em> reconnects to the nearest available access point. If you are within a literal stone's throw of campus, you should assume that Brown can (roughly) identify your location.</p>
<p>Furthermore, if you are in range of three or more of Brown's ARUBA access points, Brown can, in principle, precisely triangulate your location. This functionality is <a href="https://www.arubanetworks.com/pdf/technology/whitepapers/wp_Hybrid_WIDS.pdf">common</a> in enterprise-grade WiFi infrastructure. (If you've ever tried to run a "rogue" WiFi router in your dorm room and receive an angry knock on your door — this is the mechanism by which you were located.)</p>
<h2 id="how-do-i-find-out-more">How do I find out more?</h2>
<p>The <a href="https://en.wikipedia.org/wiki/Family_Educational_Rights_and_Privacy_Act"><em>Family Educational Rights and Privacy Act</em></a> empowers students to request their education records from their University.</p>
<p><iframe src="https://www.youtube.com/embed/jWzBrC8dVnw" frameborder="0" allowfullscreen=""></iframe></p>
<p>If you are a current Brown student and would like to go beyond my blog post and learn <em>exactly</em> how Brown University knows your location, <a href="https://www.brown.edu/about/administration/registrar/student-information-rightsferpa">file a FERPA request</a>. Brown University is obligated to respond within 45 days. You'll need to be specific with your request. I suggest requesting:</p>
<ul>
<li>the timestamps, MAC addresses and BSSIDs associated with your devices' connections to Brown University's wireless access points</li>
<li>the timestamps and locations associated with all building accesses conducted with your ID card</li>
<li>the login audit data associated with all Google Workplace, Shibboleth, and DUO authentications conducted by your accounts</li>
</ul>
<p>Additionally, the <a href="https://en.wikipedia.org/wiki/General_Data_Protection_Regulation"><em>General Data Protection Regulation</em></a> gives EU citizens and residents expansive control over how their personally identifiable information (PII) is used, and the right to request a copy of or the destruction of collected data. I believe these requests should be directed to <a href="https://compliance.brown.edu/">Brown's compliance office</a>. You might be able to do this even if you're a Brown alumni.</p>
<p><strong>If you attempt either of these steps, <a href="mailto:jack@wrenn.fyi">please get in touch</a>!</strong> I'm very curious as to what Brown is <em>actually</em> doing.</p>
<h2 id="bonus-surveillance-cameras">Bonus: Surveillance Cameras</h2>
<p>As of February 2020, <a href="https://www.browndailyherald.com/2020/02/21/cameras-installed-hegeman-hall/#post-2838338:%7E:text=The%20University%20uses%20approximately%20800%20cameras,with%20high%20crime%20activity%2C%20Porter%20said."><em>eight hundred</em> surveillance cameras monitor campus 24/7</a>. Brown has as about as many surveillance cameras as it has full-time faculty! This map documents a <em>mere seven percent</em> of Brown University's total camera surveillance capacity:</p>

<p><small>This map displays data from <a href="https://www.openstreetmap.org/about">OpenStreetMap</a>. <a href="https://pietervdvn.github.io/Staging/surveillance.html?z=17&amp;lat=41.82681&amp;lon=-71.4016">Help improve its accuracy!</a></small></p><p>Brown University has a longstanding policy governing the appropriate uses of its surveillance cameras. <strong>Unfortunately, <a href="https://www.browndailyherald.com/2008/01/10/surveillance-cameras-on-campus-triple/#post-1679525:%7E:text=DPS%20would%20not%20release%20the%20University%E2%80%99s%20full%20policy%20on%20the%20surveillance%20camera%20system">this policy is secret</a>.</strong></p>
<p>While Brown probably does not <em>currently</em> have the capacity to both broadly and deeply inspect the firehose of data produced by these cameras, expect this to change in the near future. Axis Communications, Brown's primary supplier of surveillance cameras, <a href="https://www.axis.com/customer-story/3767">now touts cameras that can perform <em>on-board</em> facial recognition</a>. And Software House, the provider of the C•CURE 9000 access control system, has begun marketing the integration of facial recognition with its access control systems:</p>
<p><iframe src="https://www.youtube.com/embed/bk395D0tPRA" frameborder="0" allowfullscreen=""></iframe></p>

  </div></div>]]>
            </description>
            <link>https://jack.wrenn.fyi/blog/brown-location-surveillance</link>
            <guid isPermaLink="false">hacker-news-small-sites-25319392</guid>
            <pubDate>Sat, 05 Dec 2020 23:18:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Special Kind of Hell: intmax_t in C and C++]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 108 (<a href="https://news.ycombinator.com/item?id=25316933">thread link</a>) | @ingve
<br/>
December 5, 2020 | https://thephd.github.io/intmax_t-hell-c++-c | <a href="https://web.archive.org/web/*/https://thephd.github.io/intmax_t-hell-c++-c">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  
      <p>C and C++ as languages have a few things separating them from each other, mostly in their minute details and, occasionally, larger feature sets like designated initializers. But there is a disturbingly high amount of C++ that can simply do C’s job far better than C<!--more-->, including when it comes to solving some of the biggest problems facing the evolution of C and C++.</p>

<p>Let’s take a contemporary problem plaguing both C and C++, affecting everyone from standard library maintainers to project developers, that has been going on for the last 20 or so years: <code>intmax_t</code>.</p>



<p>The concept behind <code>intmax_t</code> is simple enough: it is the largest integer type that your implementation and its standard library support in conjunction. Here is a few things <code>intmax_t</code> controls inside the implementation:</p>

<ul>
  <li>numeric literals are preprocessed according to what <code>intmax_t</code> can handle (C and C++);</li>
  <li>it is the maximum number of bits that can be printed portably, e.g. with <code>printf("%j", (intmax_t)value)</code> (C and C++);</li>
  <li><code>intmax_t</code> is the largest type for which <code>std::numeric_limits</code> applies, including most types up to and including that type (C++ only);</li>
  <li><code>intmax_t</code> underpins <code>std::chrono</code>’s casts and similar (e.g. no information is lost during conversions out of and into the system) (C++ only);</li>
  <li>and, there are a set of integer operations provided by the standard library (like absolute value and quotient / remainder operations) that can be done with the maximum bit precision available to the implementation (C and C++).</li>
</ul>

<p>These properties forge the basis of <code>intmax_t</code>’s purpose. Lossless storage, pass-through operations, and more can all be achieved by relying on this implicit contract of the type. Since it is a type definition, the “real” integer type underneath it can be swapped out and people relying on it can be upgraded seamlessly!</p>



<p>We cannot upgrade seamlessly.</p>

<p>C has a much higher commitment to not breaking old code and keeping “developers close to the machine”. What this actually translates to for most Application Binary Interfaces is very simplistic “name mangling” schemes (i.e., none), <a href="https://twitter.com/__phantomderp/status/1329960075096694790">weak linkers</a>, and other shenanigans. The end result is that we expose C developers to platform details that become invisible dependencies for their code that must be preserved at all costs. For example, let’s take a C Standard function that uses <code>intmax_t</code>, <code>imaxabs</code>:</p>

<div><div><pre><code><span>intmax_t</span> <span>imaxabs</span><span>(</span><span>intmax_t</span> <span>j</span><span>);</span>
</code></pre></div></div>

<p>and, let’s try to figure out how we can upgrade someone off of this usage without breaking their code too badly. We will try fixing this in both C and C++.</p>



<p>Taking <code>intmax_t</code>, let’s do a no-brainer usage case: calling a function with <code>intmax_t</code> input and return types. The syntax and usage ends up looking like this:</p>

<div><div><pre><code><span>#include &lt;inttypes.h&gt;
</span>
<span>int</span> <span>main</span> <span>()</span> <span>{</span>
	<span>intmax_t</span> <span>original</span> <span>=</span> <span>(</span><span>intmax_t</span><span>)</span><span>-</span><span>2</span><span>;</span>
	<span>intmax_t</span> <span>val</span> <span>=</span> <span>imaxabs</span><span>(</span><span>original</span><span>);</span>
	<span>return</span> <span>(</span><span>int</span><span>)</span><span>val</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>Easy enough! But, there’s also a hidden dependency here, based on how the code is compiled. While many people compile their C standard library as a static library and only generate final binary code for what they use as to have a “self-contained” binary, the vast majority of the shared ecosystem depends on shared libraries/dynamically linked libraries for the standard. This means that when a program is milled through an operating system at program startup, the “loader” runs off to find the symbol <code>imaxabs</code> inside some system library (e.g., <code>/lib/x86_64-linux-gnu/libc-2.27.so</code> for an “amd64” system). Harmless enough, right? Well, it turns out to be a bit of a problem in practice, because the name <code>imaxabs</code> is all that’s used in C to figure out what subroutine to talk with in some shared library,</p>

<p>and that name is completely inadequate.</p>

<p>Consider the following scenario:</p>

<ol>
  <li>The glibc maintainers decide they’re going to change from <code>long long</code> as their <code>intmax_t</code> and move to <code>__int256_t</code> for most platforms, because most platforms support it and they have a lot of customers asking for it.</li>
  <li>They upgrade the <code>libc</code> to its next version for various Linux distribution, and everyone links against it when they look for the default <code>libc</code>.</li>
  <li>You have an application. Your code was not changed or updated, so it was not recompiled. It calls <code>imaxabs</code>. The argument it passes is a <code>long long</code>, because that was the type at the time you last compiled and shipped your software.</li>
  <li>The <code>imaxabs</code> used to lookup the function to call finds the version that takes a <code>__int256_t</code> in the new <code>libc</code>.</li>
  <li>Different registers are used to pass and return the function value than expected by the <code>imaxabs</code> function call in the <code>libc</code> binary, because your application is in <code>long long</code> mode but glibc expects a <code>__int256_t</code>.</li>
  <li>All hell breaks loose.</li>
</ol>

<p>This is one of the manifestations of what is called an “Application Binary Interface (ABI) Break”. ABI Breaks are generally undetectable, silent breaks that occur within the runtime of a program that completely destroy any dependency your program has on that functionality for correctness. It typically happens when a subtle detail – the registers used to negotiate a large integral value between a shared library and its application, the amount of padding a structure might have on a certain build, the ordering and layout of class members, the interpretation of bits even if the layout or passing convention of a type never changes, and even more – changes.</p>

<h2 id="but-c-is-abi-stable">“But C Is ABI-Stable?!”</h2>

<p>Not necessarily. C is a simple language, and it both sells itself on and prides itself as such. So much so, that it’s even part of the <a href="http://www.open-std.org/jtc1/sc22/wg14/www/docs/n2021.htm">language’s rolling charter</a>. There’s barely any name mangling because there’s no overloading. If you want “virtual functions” you need to hand-craft your virtual table structure and initialize it yourself. There’s barely any lookup or entity negotiation: what you write – <a href="https://twitter.com/thingskatedid/status/1328918322507706368">however scary or cursed</a> – is what you get, in a general sense. (No, it’s not “portable assembly”. Compilers tear C code apart and make it far more efficient than the code people stuff into it. It’s not even a direct model of the machine anymore: just an abstract one.)</p>

<p>Still, sometimes even C can’t get away from it. The function <code>imaxabs</code> relates to exactly one entity that, for historical reasons, was pinned to a function taking and returning a <code>long long</code>. Upgrading it means dealing with this schism between what the user expects (<code>intmax_t</code> that got upgraded and can print <code>__int128_t</code>/<code>__int256_t</code>) with old, non-recompiled code that maintains the old invariant (<code>long long</code>, a 64-bit number).</p>



<p>Okay, so symbols can be repurposed between library versions that lead to ABI breaks. What are the ways to defend against such a world, in C?</p>

<h2 id="macros">Macros?</h2>

<p>Macros! Object-like macros are fun. You could do something like this…</p>

<div><div><pre><code><span>#define imaxabs __glibc228_imaxabs
</span></code></pre></div></div>

<p>… as a way to provide the <code>imaxabs</code> function. It is a bit like artisanal, hand-crafted, free-range, and organic ABI versioning (or, as I have affectionately come to call it: personal masochism to make up for language failures). This mostly works, until… it doesn’t!</p>

<h3 id="714">§7.1.4</h3>

<p>This is the “ABI Breaks Guaranteed” section in the C Standard. It’s real name is “§7.1.4 Use of library functions”. Reproduced below is the relevant piece that condemns us, emphasis mine:</p>

<blockquote>
  <p>Any function declared in a header may be additionally implemented as a function-like macro defined in the header, so if a library function is declared explicitly when its header is included, one of the techniques shown below can be used to ensure the declaration is not affected by such a macro. <strong>Any macro definition of a function can be suppressed locally by enclosing the name of the function in parentheses</strong>, because the name is then not followed by the left parenthesis that indicates expansion of a macro function name. For the same syntactic reason, it is permitted to take the address of a library function even if it is also defined as a macro. <strong>The use of <code>#undef</code> to remove any macro definition will also ensure that an actual function is referred to</strong>.</p>
</blockquote>

<p>Not only can a user suppress a function-like macro invocation by using the same trick used on <code>&lt;windows.h&gt;</code> like <code>(max)(value0, value1)</code>, but the C Standard Library permits them to also undefine function names:</p>

<div><div><pre><code><span>// implementer code: inttypes.h</span>
<span>#define imaxabs __glibc228_imaxabs
</span></code></pre></div></div>

<div><div><pre><code><span>// user code: main.c</span>
<span>#include &lt;inttypes.h&gt;
</span>
<span>#undef imaxabs // awh geez
</span>
<span>int</span> <span>main</span> <span>()</span> <span>{</span>
	<span>intmax_t</span> <span>val</span> <span>=</span> <span>-</span><span>1</span><span>;</span>
	<span>intmax_t</span> <span>absval</span> <span>=</span> <span>imaxabs</span><span>(</span><span>val</span><span>);</span> <span>// awH GEEZ</span>
	<span>return</span> <span>(</span><span>int</span><span>)</span><span>absval</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>Mmm……</p>

<h3 id="implementation-specific-strategies">Implementation-specific strategies</h3>

<p>Alright, the C Standard basically loads a double barrel and brings our only standardized mitigation strategy out back behind the barn. What’s left? Well, implementation-specific insanity, that’s what:</p>

<div><div><pre><code><span>extern</span>
<span>intmax_t</span>
<span>__glibc228_imaxabs</span><span>(</span><span>intmax_t</span><span>);</span>

<span>__attribute</span><span>((</span><span>symbol</span><span>(</span><span>__MANGLE</span><span>(</span><span>__glibc228_imaxabs</span><span>))))</span>
<span>extern</span>
<span>intmax_t</span>
<span>imaxabs</span><span>(</span><span>intmax_t</span><span>);</span>
</code></pre></div></div>

<p>This is pseudo-code. But, wouldn’t you believe it, some implementations actually do things very similar to this to get around these problems! The things they do are far more involved, like actually dropping down to the level of the linker and creating symbol maps and other exceedingly painful workarounds. The sed scripts and the awk scripts and the bash starts coming out, people are doing lots of text processing to get symbol names and match them to versioned symbol names…</p>

<p>It’s a mess.</p>

<p>Still, given the mess, it does save us from the problem. In C code you get to use “the real name” <code>imaxabs</code> as Our Lord and Savior intended, the binary gets linked to <code>___glibc228_imaxabs</code>, and everyone’s happy. There’s only one problem with this kind of fix…</p>

<p>It’s Quality of Implementation (QoI).</p>

<p>QoI is great for the pure, theoretical standard. We get to write sexy narratives in the C standard and call them “Recommended Practice”, with little footnotes furtively implying a more wonderful world while waggling our eyebrows seductively at hot, young developers in our area. Just come along, it’s going to be so great, we’re going have soooooo much fun, just go with that lovely little implementation right over there, you’re making such fine progress, enjoy yourself and come back soon my …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thephd.github.io/intmax_t-hell-c++-c">https://thephd.github.io/intmax_t-hell-c++-c</a></em></p>]]>
            </description>
            <link>https://thephd.github.io/intmax_t-hell-c++-c</link>
            <guid isPermaLink="false">hacker-news-small-sites-25316933</guid>
            <pubDate>Sat, 05 Dec 2020 18:30:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Benefits of Walking]]>
            </title>
            <description>
<![CDATA[
Score 214 | Comments 105 (<a href="https://news.ycombinator.com/item?id=25316328">thread link</a>) | @KlimYadrintsev
<br/>
December 5, 2020 | https://klimy.co/blog/benefits-of-walking | <a href="https://web.archive.org/web/*/https://klimy.co/blog/benefits-of-walking">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="blog">
                    <h2>How long does it take to walk 1 mile?</h2>
<p>As both research and actual scientific measurements, an average adult will walk 1 mile in 15 to 18 minutes at moderate to a brisk pace. Or in other words, 3 to 4 miles per hour.</p>
<p>This is a general measure for a healthy adult between 20 and 50 years old, at dry weather, on relatively flat terrain, with no destruction from cars and other environments.</p>
<p>If you are either less healthy or subjected to any of the environmental distractions, your speed, of course, will be lower.</p>
<h2>Average walking speed by age group and gender</h2>
<p>There is little difference between male and female, with males walking on average 2% faster.</p>
<p>The table below shows the speed of walking based on age and gender:</p>
<pre><code>| Age      | Sex    | Meters per second | Miles per hour |
|----------|--------|-------------------|----------------|
| 20 to 29 | Male   | 1.36              | 3.04           |
|          | Female | 1.34              | 3.0            |
| 30 to 39 | Male   | 1.43              | 3.2            |
|          | Female | 1.34              | 3.0            |
| 40 to 49 | Male   | 1.43              | 3.2            |
|          | Female | 1.39              | 3.11           |
| 50 to 59 | Male   | 1.43              | 3.2            |
|          | Female | 1.31              | 2.93           |
| 60 to 69 | Male   | 1.34              | 3.0            |
|          | Female | 1.24              | 2.77           |
| 70 to 79 | Male   | 1.26              | 2.82           |
|          | Female | 1.13              | 2.53           |
| 80 to 89 | Male   | 0.97              | 2.17           |
|          | Female | 0.94              | 2.10           |
</code></pre>
<h2>Benefits of walking</h2>
<p>There has been a great deal of research that showed that walking brings a huge advantage to humans. To both <a href="https://journals.sagepub.com/doi/abs/10.1177/0013916518800798">physical, and mental well being.</a> The benefits are as follows:</p>
<p>Physical:</p>
<ul>
<li>Burning calories. A direct way to reduce and to control your weight.</li>
<li>Lower glucose level and blood sugar levels. <a href="https://care.diabetesjournals.org/content/early/2013/06/03/dc13-0084">Research</a> has focused on short walks, where it helped reduce glucose intolerance.</li>
<li><a href="https://bjsm.bmj.com/content/45/12/987?sid=fe62a8c5-430b-4506-b854-20b62e8a5e9e">Help deal with infection and possibly Covid.</a></li>
<li>Help boost immune function.</li>
<li>Give additional energy to do other tasks due to increased efficiency of nutrients absorption and conversion.</li>
<li>Prolonging life. There is a <a href="https://bjsm.bmj.com/content/52/12/761">research that showed</a> evidence of having a relationship between physical activity and overall life expectancy. </li>
<li>Strengthen the heart. Even 20 minutes of daily walking has shown to reduce the risk of stroke by at least 20%.</li>
</ul>
<p>Mental:</p>
<ul>
<li><a href="https://pubs.acs.org/doi/abs/10.1021/es903183r">Improving self esteem</a> by 45%.</li>
<li><a href="https://pubs.acs.org/doi/abs/10.1021/es903183r">Improving mood</a> by 54%.</li>
<li>Additional time on focusing on self-education with educational podcasts and books. <a href="https://digitalcommons.georgiasouthern.edu/nyar_savannah/2020/2020/90/">Research</a> has shown that it leads to better learning of the material, longer retention, better engagement in post-walk discussions, better behaviour and mood, AND improved health literacy.</li>
<li>Improving <a href="https://www.tandfonline.com/doi/abs/10.1080/10413200.2020.1815100">goal setting</a> in other areas by targeting non-specific goals which in consequence lead to better results.</li>
<li>Walking helps you get your thoughts in order. Whenever you are alone with yourself, and you are unable to really look at the phone, you are finally able to understand what is happening with yourself with no distractions.</li>
<li>Improve the creative part of the brain. While walking, <a href="https://psycnet.apa.org/record/2014-14435-001">research showed</a>, that it is easier to come up with great ideas.</li>
<li>Save money on medications. With the amount of food, we consume and with costly medicine, walking and doing exercises can help you save money and nerves.</li>
</ul>
<h2>Covid and sitting time</h2>
<p>In the world of pandemics and covid, it has been evident that humans are sitting more and more and do less and less exercises. There is a <a href="https://www.sciencedirect.com/science/article/pii/S221133552030214X">great research</a> that shows that 2020 has caused a sharp increase in average sitting time. The data is staggering.</p>
<p><code>Overall, 42.6% of participants reported sitting for &gt; 8 h/day (95% CI: 41.2%–44.0%) and 72.5% (71.2%–73.7%) reported being either sufficiently (150–300 MVPA minutes) or highly active (&gt;300 min).</code></p>
<p>If you want to boost your health and still to be able to keep up with a busy schedule walking or running can be the best idea for spending your free time. In the world where only entertainment inside your house is minimal. If being glued to the screen is no longer an option, than being outside can boost your health and your mental capabilities immensely.</p>
<p><img alt="walking in the park grass and women leg" src="https://i.gyazo.com/ecae9926d17ad69ded99b1a445482e9a.jpg"></p>
<h2>Tips on how to start walking</h2>
<h3>How to make walking a habit?</h3>
<p>The walk starts with the first step. It would be best if you did not put huge goals onto yourself. Start somewhere small, then later you can always adjust based on how you feel.</p>
<p>Start by putting on clothes(plus a mask) and go outside. Going back to your apartment would feel bad at that point.</p>
<p>Next, you should walk around your building or up and down the street.</p>
<p>Next, you walk around the block and later you can finally go for huge walks that can be a couple of hours long.</p>
<p>Don’t try to start at the last step that would only make you quit before you get the full benefit of the habit.</p>
<p>Peg your walking habit to something else. If you go for a coffee every morning, go to a coffee house that is further away. If you are usually riding a tube to work, start the journey at the stop further away from you</p>
<h3>Identify as a walker</h3>
<p>If you would like to start walking you need to think of <strong>how do you become a walker.</strong></p>
<p>You need to make sure you identify as someone who goes on walks, then keeping up with the habit will be much easier.</p>
<p>Next time someone asks you, whatever you do any exercises or what you love doing with your free time, you need to want to say that you love walking. At that point, you will be able to keep on walking and improving your health immensely.</p>
<h2>How much walking per week is enough?</h2>
<p>I think that it is tough to give a simple number for everyone, but if you are in the age range of 18-50, then:</p>
<ul>
<li>150 to 300 minutes per week is an ideal level if you are walking with moderate speed</li>
<li>75 to 150 minutes per week if you are walking with a brisk pace.</li>
</ul>
<p>Don’t think that doing extra physical exercise will be useless. In contrast, anything above that time limit will give even higher benefits to your health, so take the timing above as a general guideline. Do as much as you want.</p>
<h2>Personal tips on walking more</h2>
<h3>Wake up earlier</h3>
<p>Right now it is very easy to blame everything on covid and health, but not many people <a href="https://klimy.co/blog/how-to-wake-up-early">wake up very early in the morning</a>, that gives people that live in the city an ability to walk as much as they want, even in usually crowded spaces.</p>
<p>Also, your excuse of not having enough time can not be reinforced if you have an extra hour in the morning.</p>
<h3>Get a pet (dog)</h3>
<p>Even though it can seem like a lousy idea, multiple research papers show a relationship between owning a dog and the number of steps you do daily. If you are struggling to make time, your favourite pet will make you find time for walks.</p>
<p><img alt="man and dog walking in forest autumn" src="https://i.gyazo.com/5e16de8c0474f84f4285df88fab28c14.jpg"></p>
<h3>Podcasts and Audiobooks</h3>
<p>I love learning and listening to books. I do it all the time even when I am at home at my desk, so a change of pace for me is always going for an extended walk where I can do the same thing.</p>
<p>What I discovered is that I understand and remember information much better when I have consumed it while walking. That makes me spend twice as little time and getting twice the result. </p>
<p>Podcasts have been my go-to method of getting new relevant news and information in my field of expertise. Since I have started a habit of walking, I have been on top of my field and able to implement solutions that I would have never thought of otherwise.</p>
<h3>Music</h3>
<p>I also love discovering new music. Sometimes when I really need to get my head around something I go for a brisk walk with my favourite songs. This helps me to unwind and later really understand the problem.</p>
<p>Most of the time while on the walk, I solve the problem that I had, and in my experience would off taken me much more time to solve.</p>
<h3>Walking groups</h3>
<p><img alt="walking groups picture" src="https://i.gyazo.com/26609ccb0d7ae90e9f746389479a32b0.jpg"></p>
<p>Sometimes socialising can be hard and especially when all of your friends are on the lockdown and all of the socialising places, such as restaurants, are closed. </p>
<p>That is where walking groups can come into play! You can find someone who is staying healthy and being diligent with their health and walk together! That will allow you to catch up and have social interaction, that we humans require.</p>
<h5>So what this means?</h5>
<p>Now you have a social responsibility in your habit, and the whole activity can let you be more motivated to do it.</p>
<p>Also, walking groups normally allow you to meet new people and to bond better with existing relationships.</p>
<p>Also, walking groups is a great way to speed up your walking pace and improve your health.</p>
<h2>How do I get better at walking?</h2>
<p>If you would like to improve the speed at which you walk, there are multiple ways to do so:</p>
<ul>
<li>As mentioned above, walking groups are amazing for giving you a speedup of pace, just make sure to not overdo it.</li>
<li>Walking poles (tracking poles) are an easy way to speed up the pace. They are especially useful for those with back or leg injury, that immensely help reduce the stress on joints and back as well as speed up the pace. There is a lot of research behind use cases and benefits of using them.</li>
<li>Treadmills. If you are unable to properly walk in the wild or in the park, get yourself a treadmill. Although they can be expensive, some are very cheap and immensely powerful alternatives provide the same result. You don’t need something overly expensive. Treadmills are great for controlling your pace as well as letting you support yourself with the rails that are at either side of the treadmill.</li>
<li>Have an open goal. Whenever you are walking, the <a href="https://www.tandfonline.com/doi/abs/10.1080/10413200.2020.1815100">research has shown</a> that having an open goal to where you want to walk or for how long will extend the amount of walking that you will eventually do.</li>
<li>Keep track of your metrics. Understanding what your heart rate and your pace are, is vital for your well being and motivation. Seeing that you have improved over a period of time is the greatest motivator there is.</li>
<li>Strive towards a 13 minutes per mile goal. The 13 minutes per mile has been shown to be the meeting point between fast walkers and the joggers. As …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://klimy.co/blog/benefits-of-walking">https://klimy.co/blog/benefits-of-walking</a></em></p>]]>
            </description>
            <link>https://klimy.co/blog/benefits-of-walking</link>
            <guid isPermaLink="false">hacker-news-small-sites-25316328</guid>
            <pubDate>Sat, 05 Dec 2020 17:28:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Improbable Inspiration: Bayesian Networks (1996)]]>
            </title>
            <description>
<![CDATA[
Score 94 | Comments 20 (<a href="https://news.ycombinator.com/item?id=25315982">thread link</a>) | @1e
<br/>
December 5, 2020 | https://www.cs.ubc.ca/~murphyk/Bayes/la.times.html | <a href="https://web.archive.org/web/*/https://www.cs.ubc.ca/~murphyk/Bayes/la.times.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <td>

      <span face="Arial,Helvetica" color="#003366">

      <b>Improbable Inspiration</b><p>
      The future of software may lie in the obscure theories of an
      18th century cleric named Thomas Bayes.

      </p><p>

      By LESLIE HELM, Times Staff Writer

      </p><hr>
      <p>

      When Microsoft Senior Vice President Steve
      Ballmer first heard his company was planning to make a huge
      investment in an Internet service offering movie reviews and
      local entertainment information in major cities across the
      nation, he went to Chairman Bill Gates with his concerns.

      </p><p>

      &nbsp;&nbsp;&nbsp; After all, Ballmer has billions of dollars of
      his own money in Microsoft stock, and entertainment isn't
      exactly the company's strong point.

      </p><p>

      &nbsp;&nbsp;&nbsp; But Gates dismissed such
      reservations. Microsoft's competitive advantage, he responded,
      was its expertise in "Bayesian networks."

      </p><p>

      &nbsp;&nbsp;&nbsp; Asked recently when computers would finally
      begin to understand human speech, Gates began discussing the
      critical role of "Bayesian" systems.

      </p><p>

      &nbsp;&nbsp;&nbsp; Ask any other software executive about
      anything "Bayesian" and you're liable to get a blank
      stare.

      </p><p> 

      &nbsp;&nbsp;&nbsp; Is Gates onto something? Is this
      alien-sounding technology Microsoft's new secret weapon?

      </p><p>

      &nbsp;&nbsp;&nbsp; Quite possibly.
      
      </p><p>

      &nbsp;&nbsp;&nbsp; Bayesian networks are complex diagrams that
      organize the body of knowledge in any given area by mapping out
      cause-and-effect relationships among key variables and encoding
      them with numbers that represent the extent to which one
      variable is likely to affect another.

      </p><p>

      &nbsp;&nbsp;&nbsp; Programmed into computers, these systems can
      automatically generate optimal predictions or decisions even
      when key pieces of information are missing.

      </p><p>

      &nbsp;&nbsp;&nbsp; When Microsoft in 1993 hired Eric Horvitz,
      David Heckerman and Jack Breese, pioneers in the development of
      Bayesian systems, colleagues in the field were surprised. The
      field was still an obscure, largely academic enterprise.

      </p><p>
 
      &nbsp;&nbsp;&nbsp; Today the field is still obscure. But scratch
      the surface of a range of new Microsoft products and you're
      likely to find Bayesian networks embedded in the software. And
      Bayesian nets are being built into models that are used to
      predict oil and stock prices, control the space shuttle and
      diagnose disease.

      </p><p>

      &nbsp;&nbsp;&nbsp; Artificial intelligence (AI) experts, who saw
      their field discredited in the early 1980s after promising a
      wave of "thinking" computers that they ultimately
      couldn't produce, believe widening acceptance of the Bayesian
      approach could herald a renaissance in the field.

      </p><p>
      
      &nbsp;&nbsp;&nbsp; Bayesian networks provide "an
      overarching graphical framework" that brings together
      diverse elements of AI and increases the range of its likely
      application to the real world, says Michael Jordon, professor of
      brain and cognitive science at the Massachusetts Institute of
      Technology.

      </p><p>

      &nbsp;&nbsp;&nbsp; Microsoft is unquestionably the most
      aggressive in exploiting the new approach. The company offers a
      free Web service that helps customers diagnose printing problems
      with their computers and recommends the quickest way to resolve
      them. Another Web service helps parents diagnose their
      children's health problems.

      </p><p>

      &nbsp;&nbsp;&nbsp; The latest version of Microsoft Office
      software uses the technology to offer a user help based on past
      experience, how the mouse is being moved and what task is being
      done.

      </p><p>

      &nbsp;&nbsp;&nbsp; "If his actions show he is distracted,
      he is likely to need help," Horvitz says. "If he's
      been working on a chart, chances are he needs help formatting
      the chart."

      </p><p>

      &nbsp;&nbsp;&nbsp; "Gates likes to talk about how computers
      are now deaf, dumb, blind and clueless. The Bayesian stuff helps
      deal with the clueless part," says Daniel T.  Ling,
      director of Microsoft's research division and a former IBM
      scientist.

      </p><p>

      &nbsp;&nbsp;&nbsp; Bayesian networks get their name from the
      Rev. Thomas Bayes, who wrote an essay, posthumously published in
      1763, that offered a mathematical formula for calculating
      probabilities among several variables that are causally related
      but for which--unlike calculating the probability of a coin
      landing on heads or tails--the relationships can't easily be
      derived by experimentation.

      </p><p>

      &nbsp;&nbsp;&nbsp; Early students of probability applied the
      ideas to discussions about the existence of God or efforts to
      improve their odds in gambling. Much later, social scientists
      used it to help clarify the key factors influencing a particular
      event.

      </p><p>

      &nbsp;&nbsp;&nbsp; But it was the rapid progress in computer
      power and the development of key mathematical equations that
      made it possible for the first time, in the late 1980s, to
      compute Bayesian networks with enough variables that they were
      useful in practical applications.

      </p><p>

      &nbsp;&nbsp;&nbsp; The Bayesian approach filled a void in the
      decades-long effort to add intelligence to computers.

      </p><p>

      &nbsp;&nbsp;&nbsp; In the late 1970s and '80s, reacting to the
      "brute force" approach to problem solving by early
      users of computers, proponents of the emerging field of
      artificial intelligence began developing software programs using
      rule-based, if-then propositions. But the systems took time to
      put together and didn't work well if, as was frequently the
      case, you couldn't answer all the computer's questions clearly.

      </p><p>

      &nbsp;&nbsp;&nbsp; Later companies began using a technique
      called "neural nets" in which a computer would be
      presented with huge amounts of data on a particular problem and
      programmed to pull out patterns. A computer fed with a big stack
      of X-rays and told whether or not cancer was present in each
      case would pick out patterns that would then be used to
      interpret X-rays.

      </p><p>

      &nbsp;&nbsp;&nbsp; But the neural nets won't help predict the
      unforeseen. You can't train a neural net to identify an incoming
      missile or plane because you could never get sufficient data to
      train the system.

      </p><p>

      &nbsp;&nbsp;&nbsp; In part because of these limitations, a slew
      of companies that popped up in the early 1980s to sell
      artificial intelligence systems virtually all went bankrupt.

      </p><p>

      &nbsp;&nbsp;&nbsp; Many AI techniques continued to be
      used. Credit card companies, for example, began routinely using
      neural networks to pick out transactions that don't look right
      based on a consumer's past behavior. But increasingly, AI was
      regarded as a tool with limited use.

      </p><p>

      &nbsp;&nbsp;&nbsp; Then, in the late 1980s--spurred by the early
      work of Judea Pearl, a professor of computer science at UCLA,
      and breakthrough mathematical equations by <a href="http://www.hugin.dk/">Danish researchers</a>--AI
      researchers discovered that Bayesian networks offered an
      efficient way to deal with the lack or ambiguity of information
      that has hampered previous systems.

      </p><p>

      &nbsp;&nbsp;&nbsp; Horvitz and his two Microsoft colleagues, who
      were then classmates at Stanford University, began building
      Bayesian networks to help diagnose the condition of patients
      without turning to surgery.

      </p><p>

      &nbsp;&nbsp;&nbsp; The approach was efficient, says Horvitz,
      because you could combine historical data, which had been
      meticulously gathered, with the less precise but more intuitive
      knowledge of experts on how things work to get the optimal
      answer given the information available at a given time.

      </p><p>

      &nbsp;&nbsp;&nbsp; Horvitz, who with two colleagues founded
      Knowledge Industries to develop tools for developing Bayesian
      networks, says he and the others left the company to join
      Microsoft in part because they wanted to see their theoretical
      work more broadly applied.

      </p><p>

      &nbsp;&nbsp;&nbsp; Although the company did important work for
      the National Aeronautics and Space Administration and on medical
      diagnostics, Horvitz says, "It's not like your grandmother
      will use it."

      </p><p>

      &nbsp;&nbsp;&nbsp; Microsoft's activities in the field are now
      helping to build a groundswell of support for Bayesian ideas.

      </p><p>

      &nbsp;&nbsp;&nbsp; "People look up to Microsoft," says
      Pearl, who wrote one of the key early texts on Bayesian networks
      in 1988 and has become an unofficial spokesman for the
      field. "They've given a boost to the whole area."
                     
      </p><p>

      &nbsp;&nbsp;&nbsp; A researcher at German conglomerate Siemens
      says Microsoft's work has drawn the attention of his superiors,
      who are now looking seriously at applying Bayesian concepts to a
      range of industrial applications.

      </p><p>

      &nbsp;&nbsp;&nbsp; Scott Musman, a computer consultant in
      Arlington, Va., recently designed a Bayesian network for the
      Navy that can identify enemy missiles, aircraft or vessels and
      recommend which weapons could be used most advantageously
      against incoming targets.

      </p><p>

      &nbsp;&nbsp;&nbsp; Musman says previous attempts using
      traditional mathematical approaches on state-of-the-art
      computers would get the right answer but would take two to three
      minutes.

      </p><p>

      &nbsp;&nbsp;&nbsp; "But you only have 30 seconds before the
      missile has hit you," says Musman.

      </p><p>

      &nbsp;&nbsp;&nbsp; General Electric is using Bayesian techniques
      to develop a system that will take information from sensors
      attached to an engine and, based on expert opinion built into
      the system as well as vast amounts of data on past engine
      performance, pinpoint emerging problems.

      </p><p>

      &nbsp;&nbsp;&nbsp; Microsoft is working on techniques that will
      enable the Bayesian networks to "learn" or update
      themselves …</p></span></td></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cs.ubc.ca/~murphyk/Bayes/la.times.html">https://www.cs.ubc.ca/~murphyk/Bayes/la.times.html</a></em></p>]]>
            </description>
            <link>https://www.cs.ubc.ca/~murphyk/Bayes/la.times.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25315982</guid>
            <pubDate>Sat, 05 Dec 2020 16:53:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Major Flaws of Human Thinking]]>
            </title>
            <description>
<![CDATA[
Score 197 | Comments 99 (<a href="https://news.ycombinator.com/item?id=25315667">thread link</a>) | @dandanua
<br/>
December 5, 2020 | https://dandanua.github.io/posts/major-flaws-of-human-thinking/ | <a href="https://web.archive.org/web/*/https://dandanua.github.io/posts/major-flaws-of-human-thinking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>As in the lovely child’s quote found on the internet —</p><blockquote><p>I know everything. Except anything I don’t.</p></blockquote><p>— we think that we see everything around us. But we don’t. There are so many things that greatly affect our lives, yet we don’t aware of them. One type of such things is deep inside us — the flaws of our own thinking. Here is my top list of those flaws.</p><h2 id="1-wishful-thinking-conservatism-and-conformism"><strong>1. Wishful thinking, conservatism and conformism</strong></h2><p>By <em>wishful thinking</em> I don’t mean optimism, which is rather speculation about the future. Wishful thinking is when we put more weight on the present knowledge that is pleasant to us, and at the same time ignore the knowledge that is not so nice. For example, people like to ignore the knowledge that puts them in a bad light. This is clearly seen in toxic relationships, where an abuser justifies his actions by “the care” of its victim. A dictator probably thinks that he is doing the best for its nation, while completely ignoring his incapabilities and bad doings. The same is true for groups of people or even nations. An invasion is commonly portrayed as liberation.</p><p>On the other hand, anyone who had experienced an addiction probably knows how it can alter decision-making. “Vodka is an antiseptic, didn’t you know? Let’s drink those bottles so we’ll be healthier!” Gambler thinks that he is going to make money, so his family will be happy. An ordinary gamer thinks that other real affairs are not that important, so it’s ok to spend more time on the game.</p><p>This is just few examples, but such thinking is so common that I don’t think a single book will be enough to collect all different “use cases”.</p><hr><p>Another flaw of our thinking is <em>conservatism</em> — an insufficient ability to change our common views and beliefs with the new data, new evidence. This is understandable — changing basis views leads to a reconsideration of all related knowledge. An enormous amount of rebuilding is required. Our biological brains just can’t do that in a short time, also it’s much harder with age. Because of this, we give much more weight to old knowledge rather than new evidence, thus making a conservatism bias.</p><p>In our rapidly changing world, this problem will have even more impact.</p><hr><p><em>Conformism</em> is when we weigh our knowledge in accordance with our community. The effect of this is highly underrated. An ordinary human thinks that “her thoughts are her own”, without realizing to what extent they are shaped by a community. I think that we’re all conformists to some degree. And it’s hard to imagine what’s that means not to be. This is proved by numerous experiments with a group of actors and one unsuspicious testee, where actors trick the testee to make some ridiculous statements or to do some crazy actions, like the one described <a href="https://www.youtube.com/watch?v=vjP22DpYYh8">here</a>. We are social creatures.</p><p>An extreme version of conformist thinking is the one imposed by religion. I’m not against religions in general, they can be useful, but a blind belief, an unquestioning subordination to “sacred” authorities — that’s just a disaster for a clear mind. A clear mind should have the ability to stress any dogmas.</p><h2 id="2-binary-black-and-white-thinking-overgeneralization"><strong>2. Binary (black-and-white) thinking, overgeneralization</strong></h2><p>Good-evil, smart-stupid, beautiful-ugly, tall-short, fast-slow, and so on and on. We think in binary terms. Our language reflects that. And some people are stuck very hard in such thinking. The worst case of it is <em>all-or-nothing</em> thinking, when any result other than the best is considered as a failure. It causes stress and depression in people. They don’t realize anymore why the world is so mean to them. They stop seeing how many gradients are there, and also how colorful our world is.</p><p>A similar flaw is <em>overgeneralization</em>. We put into the same category very broad types of information. Prejudice, labeling, stereotypes are all related to overgeneralization.</p><h2 id="3-self-projecting-thinking"><strong>3. Self-projecting thinking</strong></h2><p>Mind reading is an ability that everyone would like to have. It would be so easier to communicate. Also, it’s an advantage if we could read the thoughts of our rivals. While we can’t do it in reality, we’re still trying to predict other people’s thoughts, both in collaboration and confrontation.</p><p>To make such predictions we use two main assumptions:</p><ol><li>Other people see the same things as we do.</li><li>Other people are like us, thus their way of thinking is similar to ours.</li></ol><p>Based on these assumptions we use our way of thinking to deduce the thoughts of others. And this is very natural since we have to model another person’s thinking somehow. But the only model that we have is ours. It’s the only model that we can use. So, we essentially project our mind into another person’s head.</p><p>This has a fatal flaw. Because both main assumptions are only half true. While we see the same bits of the world, perception is a way more complex process. From bits we see high-order patterns, but they can be very personal. People could see different patterns and focus on different things. Also, the same bits (e.g. colors) can cause different emotions. Associations are also personal. The way we do conclusions is also very different in people because every person has its own experience, principles, beliefs, preferences, etc. We do not understand how unique the mind of every human.</p><p>And this causes a lot of trouble. People are fighting because of misunderstandings. In most situations they don’t realize, that they are fighting against their own reflection (from a distorting mirror).</p><h2 id="4-human-centric-thinking"><strong>4. Human-centric thinking</strong></h2><p>Humans are extremely focused on their own businesses. Yes, we are successful as a whole, in comparison to other creatures. But we are still part of nature. We follow its laws. Despite this, we neglect nature and the life of other species at scale.</p><p>Moreover, we value leaders, rulers and heroes amongst us much more than others. Even in fiction secondary characters usually die (who cares), while all hail goes to the main performers. We think that leaders are responsible for like 99% of the job done. Thus, we are trying to analyze them, rather than abstract patterns, situations and laws of nature. For example, from the popular culture it may look like Hitler was solely responsible for WWII and the Holocaust. Yeah, sure. How about WWI? Or any other war, genocide, mass conflict in human history? It’s silly to think that all these things were mainly because of leaders. This is just how humans work. In every moment in history there is a mix of wishes, intentions, beliefs, possibilities, thoughts of a total population. It could be that nature just picks a random guy as a leader that represents the mass.</p><p>On the other hand, we think that human is a singular, indivisible unit. That’s also not true. We are a composition of attributes, that are selected by evolution. Any child has some attributes from its mother and some attributes from its father. Human is a composable organism, the same is true for its mind. I’m sure that everyone experienced competing thoughts in his head. There is a natural selection of thoughts ongoing in the mind of every human.</p><h2 id="5-false-associations-confusion-of-causation-and-correlation"><strong>5. False associations, confusion of causation and correlation</strong></h2><p>Our thinking is associative, and we can make connections very fast based on very small data. A typical example is superstition, which is clearly seen in <a href="https://www.psychologistworld.com/superstition">pigeon experiments</a>.</p><p>Survival bias and filtering are accompanying flaws that lead to false associations. In probability theory, this is related to the fact that independent events are not necessary conditionally independent.</p><p>Even when our associations are quite objective we can make false conclusions about the causes. In fact, in probability theory and statistics the notion of a <em>cause</em> is not even defined. Events can be either correlated or independent in this theory. To deduce <em>what causes what</em> we use other tools, like common sense, physics, etc. Typically, to deduce a causation from two correlated events, we check two main things:</p><ol><li>One event is earlier in time than another one.</li><li>There is no common cause that could explain the correlation.</li></ol><p>This is hard stuff even for scientists. Because you have to exclude any possible common cause. Earlier we could use physical locality of events to exclude a lot of possible common causes. But with the advance of quantum mechanics, even locality is not a reliable factor anymore.</p><h2 id="final-words"><strong>Final words</strong></h2><p>There are a lot of other flaws, if you want to learn more you can start <a href="https://en.wikipedia.org/wiki/Cognitive_bias">here</a> and <a href="https://en.wikipedia.org/wiki/Cognitive_distortion">here</a>. But those described above I find the most impactful. I feel them myself and meet them all the time.</p></div></div>]]>
            </description>
            <link>https://dandanua.github.io/posts/major-flaws-of-human-thinking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25315667</guid>
            <pubDate>Sat, 05 Dec 2020 16:22:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I Wrote a Book on Data Analysis with Rust Notebooks]]>
            </title>
            <description>
<![CDATA[
Score 99 | Comments 27 (<a href="https://news.ycombinator.com/item?id=25314170">thread link</a>) | @DataCrayon
<br/>
December 5, 2020 | https://datacrayon.com/shop/product/data-analysis-with-rust-notebooks/ | <a href="https://web.archive.org/web/*/https://datacrayon.com/shop/product/data-analysis-with-rust-notebooks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-content">
    <div id="et-boc">
			
		<!-- #end wrapper --><div>
			<div>
		<div>
				
				
				
				
					<div>
				<div>
				
				
				<div>
				
				
				
				
				<p>A practical book on Data Analysis with Rust Notebooks that teaches you the concepts and how they’re implemented in practice.</p>
			</div>
			</div> <!-- .et_pb_column --><div>
				
				
				<div>
				
				
				
				
				<div>
					<div data-columns="4">
	<figure>
		<p><a href="https://datacrayon.com/shop/wp-content/uploads/2020/02/cover_darn.jpg"><img width="480" height="679" src="https://datacrayon.com/shop/wp-content/uploads/2020/02/cover_darn.jpg" alt="" loading="lazy" title="cover_darn" data-caption="" data-src="https://datacrayon.com/shop/wp-content/uploads/2020/02/cover_darn.jpg" data-large_image="https://datacrayon.com/shop/wp-content/uploads/2020/02/cover_darn.jpg" data-large_image_width="480" data-large_image_height="679" srcset="https://datacrayon.com/shop/wp-content/uploads/2020/02/cover_darn.jpg 480w, https://datacrayon.com/shop/wp-content/uploads/2020/02/cover_darn-212x300.jpg 212w, https://datacrayon.com/shop/wp-content/uploads/2020/02/cover_darn-300x424.jpg 300w" sizes="(max-width: 480px) 100vw, 480px"></a></p>	</figure>
</div>

				</div>
			</div>
			</div> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row -->
				
				
			</div> <!-- .et_pb_section --><div>
				
				
				
				<div>
					 <!-- .et_pb_column --><div>
				
				
				 <!-- .et_pb_row_inner --><div>
				<div>
				
				
				<div>
				
				
				<ul>
					<li><a href="#">Description</a></li>
				</ul>
				<div>
					<div>
					<div>
						<p>A practical book on Data Analysis with Rust Notebooks that teaches you the concepts and how they're implemented in practice.</p>
<ul>
<li><strong>Discounted</strong>&nbsp;<strong>Price</strong> that will grow as the book does,</li>
<li>All code examples in <strong>Rust</strong>,</li>
<li><strong>Rust (Jupyter) Notebooks</strong> for each Section,</li>
<li>Supplementary <strong>Video Tutorials</strong>,</li>
<li>Format: <strong>PDF download</strong>,</li>
<li><strong>Unlimited</strong> downloads and access to updates.</li>
</ul>
<p>Get it now to enhance your work in Rust, NDArray, Data Science, Data Analysis, and Machine Learning.</p>

					</div><!-- .et_pb_tab_content" -->
				</div>
				</div> <!-- .et_pb_all_tabs -->
			</div> <!-- .et_pb_tabs -->
			</div> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row_inner -->
			</div> <!-- .et_pb_column -->
				</div> <!-- .et_pb_row -->
				
			</div> <!-- .et_pb_section --> <!-- .et_pb_section --><div>
				
				
				
				
					<div>
				<div>
				
				
				 <!-- .et_pb_text --><p><span><img src="https://store.shahinrostami.com/wp-content/uploads/2020/07/shahin_square.jpg" alt="" title="shahin_square" srcset="https://datacrayon.com/shop/wp-content/uploads/2020/07/shahin_square.jpg 288w, https://datacrayon.com/shop/wp-content/uploads/2020/07/shahin_square-150x150.jpg 150w, https://datacrayon.com/shop/wp-content/uploads/2020/07/shahin_square-100x100.jpg 100w" sizes="(max-width: 288px) 100vw, 288px"></span>
			</p>
			</div> <!-- .et_pb_column --><div>
				
				
				<div>
				
				
				<div><p>Dr. Shahin Rostami is a <a href="http://staffprofiles.bournemouth.ac.uk/display/srostami" target="_blank" rel="noopener noreferrer">Senior Academic (Associate Professor)</a> and <a href="https://www.linkedin.com/in/shahinrostami/" target="_blank" rel="noopener noreferrer">Consultant</a> in Data Science and Artificial Intelligence, with applications in the areas of Healthcare and Defence.</p>
<p>As a <a href="https://www.heacademy.ac.uk/system/files/downloads/UK%20Professional%20Standards%20Framework%20%28PSF%29_1.pdf">Senior Fellow</a> of the Higher Education Academy and <a href="https://shahinrostami.com/">Programme Leader</a> for many postgraduate programmes, he aims to contribute openly available learning resources through this website and his <a href="https://www.youtube.com/shahinrostami" target="_blank" rel="noopener noreferrer">YouTube channel</a>.</p></div>
			</div> <!-- .et_pb_text --><div>
				
				
				<p>Dr. Rostami writes and maintains the works published and offered through this website. You can expect ongoing updates and support through the communication channels listed below.</p>
			</div> <!-- .et_pb_text --> <!-- .et_pb_text --><ul>
				
				
				<li><a href="https://twitter.com/shahinrostami" title="Follow on Twitter" target="_blank"></a></li><li><a href="https://www.youtube.com/ShahinRostami" title="Follow on Youtube" target="_blank"></a></li><li><a href="https://www.linkedin.com/in/shahinrostami/" title="Follow on LinkedIn" target="_blank"></a></li><li><a href="https://www.instagram.com/stamilabs/" title="Follow on Instagram" target="_blank"></a></li>
			</ul> <!-- .et_pb_counters -->
			</div> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row -->
				
				
			</div> <!-- .et_pb_section --><div>
				
				
				
				
					<div>
				<div>
				
				
				<p><span><img src="https://store.shahinrostami.com/wp-content/uploads/2020/07/author-icon-03-2.png" alt="" title=""></span>
			</p><div>
				
				
				<div><p>The aim is to generate everything in this book through code! This means you’ll see the code for all the figures and tables, including things like flowcharts.</p>
<p>Every section is intended to be independent and <span jsslot=""><span data-dobid="hdw">reproducible</span></span>, so you’ll find some repetition as you progress from one section to another.</p></div>
			</div> <!-- .et_pb_text -->
			</div> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row -->
				
				
			</div> <!-- .et_pb_section --><div>
				
				
				
				
					<div>
				<div>
				
				
				<div>
				
				
				<div><h2>10% discount on books.</h2>
<p>Join the newsletter to receive book and software updates, as well as discounts and occasional freebies! Your email will only used for this newsletter.</p></div>
			</div> <!-- .et_pb_text --> <!-- .et_pb_code --><ul>
				
				
				<li><a href="https://twitter.com/shahinrostami" title="Follow on Twitter" target="_blank"></a></li><li><a href="https://www.youtube.com/ShahinRostami" title="Follow on Youtube" target="_blank"></a></li><li><a href="https://www.linkedin.com/in/shahinrostami/" title="Follow on LinkedIn" target="_blank"></a></li><li><a href="https://www.instagram.com/stamilabs/" title="Follow on Instagram" target="_blank"></a></li>
			</ul> <!-- .et_pb_counters -->
			</div> <!-- .et_pb_column --> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row -->
				
				
			</div> <!-- .et_pb_section -->		</div><!-- .et_builder_inner_content -->
	</div><!-- .et-l -->
	
			
		</div><!-- #et-boc -->
		    </div></div>]]>
            </description>
            <link>https://datacrayon.com/shop/product/data-analysis-with-rust-notebooks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25314170</guid>
            <pubDate>Sat, 05 Dec 2020 12:52:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Std::visit is everything wrong with modern C++ (2017)]]>
            </title>
            <description>
<![CDATA[
Score 117 | Comments 223 (<a href="https://news.ycombinator.com/item?id=25314126">thread link</a>) | @xucheng
<br/>
December 5, 2020 | https://bitbashing.io/std-visit.html | <a href="https://web.archive.org/web/*/https://bitbashing.io/std-visit.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <!--
Sorry once again for the infrequent posts.
I've been busy.
Originally, because I was supposed to get married this summer.
Then because my fiancée cheated on me while I was watching my grandfather die
and moved in with the other guy the following week.
So that's been fun, but I'm trying to get back into some more productive habits.
Hopefully that includes blogging regularly.
-->

<h2 id="sum-types-and-you">Sum Types and You</h2>

<p>Let’s talk about a simple, yet powerful concept in programming: <em>sum types</em>.<sup id="fnref:1"><a href="#fn:1">1</a></sup></p>

<p>A sum type, also called a <em>discriminated union</em>,
can hold one (and only one) of several types of things.
For example, consider some settings in an
<a href="https://en.wikipedia.org/wiki/INI_file">INI</a>-like configuration file.
Let’s say that each setting must be a string, an integer, or a Boolean value.
If we wanted to roll our own solution in C++, we might write something resembling:</p>

<div><pre><code><span>struct</span> <span>Setting</span> <span>{</span>
    <span>union</span> <span>{</span>
        <span>string</span> <span>str</span><span>;</span>
        <span>int</span> <span>num</span><span>;</span>
        <span>bool</span> <span>b</span><span>;</span>
    <span>};</span>
    <span>enum</span> <span>Type</span> <span>{</span> <span>Str</span><span>,</span> <span>Int</span><span>,</span> <span>Bool</span> <span>};</span>
    <span>Type</span> <span>tag</span><span>;</span>
<span>};</span>

<span>// Map settings to their names.
</span><span>using</span> <span>Settings</span> <span>=</span> <span>unordered_map</span><span>&lt;</span><span>string</span><span>,</span> <span>Setting</span><span>&gt;</span><span>;</span>
</code></pre>
</div>

<p>Here be dragons, though, since we must always remember to:</p>

<ul>
  <li>
    <p>Update <code>tag</code> whenever assigning a new value.</p>
  </li>
  <li>
    <p>Only retrieve the correct type from the union (according to <code>tag</code>).</p>
  </li>
  <li>
    <p>Call constructors and destructors at appropriate times for all non-trivial types.
(<code>string</code> is the only one here, but you could imagine similar
scenarios with others.)</p>
  </li>
</ul>

<p>If a step is ever forgotten, the object falls into an
inconsistent state and there shall be wailing and gnashing of teeth.
You could encapsulate all this trickery and interact with the type
through a series of methods—e.g., <code>getType()</code>, <code>asBool()</code>,
<code>asString()</code>, and so on—but this is quite verbose.
It also just shifts the problem onto whoever implements these methods; they
still need to carefully maintain the invariants with no help from the language.</p>

<p>It would be much nicer if a general-purpose sum type was provided by the standard
library.
In C++17, we finally get one!
It’s called <a href="http://en.cppreference.com/w/cpp/utility/variant"><code>std::variant</code></a>.
Let’s take a look.</p>

<h2 id="using-stdvariant">Using <code>std::variant</code></h2>

<p><code>variant</code> is a class template that takes, as template parameters, the types
it could hold.
For the example above,
we could define a setting as a <code><span>variant</span><span>&lt;</span><span>string</span><span>,</span> <span>int</span><span>,</span> <span>bool</span><span>&gt;</span></code>.
Assigning a value to a <code>variant</code> works just like you might expect:</p>
<div><pre><code><span>variant</span><span>&lt;</span><span>string</span><span>,</span> <span>int</span><span>,</span> <span>bool</span><span>&gt;</span> <span>mySetting</span> <span>=</span> <span>string</span><span>(</span><span>"Hello!"</span><span>);</span> <span>// Or,
</span><span>mySetting</span> <span>=</span> <span>42</span><span>;</span> <span>// Or,
</span><span>mySetting</span> <span>=</span> <span>false</span><span>;</span>
</code></pre>
</div>

<p>Once we put a value into a <code>variant</code>, we’ll eventually want to look at what that
value is, and just as importantly, what the type of the value is.
This is where the fun begins.
Some languages offer dedicated <em>pattern matching</em> syntax for the task,
such as:</p>
<div><pre><code><span>match</span> <span>(</span><span>theSetting</span><span>)</span> <span>{</span>
    <span>Setting</span><span>::</span><span>Str</span><span>(</span><span>s</span><span>)</span> <span>=&gt;</span>
        <span>println!</span><span>(</span><span>"A string: {}"</span><span>,</span> <span>s</span><span>),</span>
    <span>Setting</span><span>::</span><span>Int</span><span>(</span><span>n</span><span>)</span> <span>=&gt;</span>
        <span>println!</span><span>(</span><span>"An integer: {}"</span><span>,</span> <span>n</span><span>),</span>
    <span>Setting</span><span>::</span><span>Bool</span><span>(</span><span>b</span><span>)</span> <span>=&gt;</span>
        <span>println!</span><span>(</span><span>"A boolean: {}"</span><span>,</span> <span>b</span><span>),</span>
<span>};</span>
</code></pre>
</div>
<p>but this didn’t make the cut for C++17.<sup id="fnref:2"><a href="#fn:2">2</a></sup>
Instead we’re given a companion function called <code>std::visit</code>.
It takes the <code>variant</code> you want to examine, along with
some <em>visitor</em> that is callable for each type in the variant.</p>

<p>How do we define such a visitor?
One way is to create an object that overloads the call operator
for relevant types:</p>
<div><pre><code><span>struct</span> <span>SettingVisitor</span> <span>{</span>
    <span>void</span> <span>operator</span><span>()(</span><span>const</span> <span>string</span><span>&amp;</span> <span>s</span><span>)</span> <span>const</span> <span>{</span>
        <span>printf</span><span>(</span><span>"A string: %s</span><span>\n</span><span>"</span><span>,</span> <span>s</span><span>.</span><span>c_str</span><span>());</span>
    <span>}</span>

    <span>void</span> <span>operator</span><span>()(</span><span>const</span> <span>int</span> <span>n</span><span>)</span> <span>const</span> <span>{</span>
        <span>printf</span><span>(</span><span>"An integer: %d</span><span>\n</span><span>"</span><span>,</span> <span>n</span><span>);</span>
    <span>}</span>

    <span>void</span> <span>operator</span><span>()(</span><span>const</span> <span>bool</span> <span>b</span><span>)</span> <span>const</span> <span>{</span>
        <span>printf</span><span>(</span><span>"A boolean: %d</span><span>\n</span><span>"</span><span>,</span> <span>b</span><span>);</span>
    <span>}</span>
<span>};</span>
</code></pre>
</div>

<p>This seems terribly verbose, and it gets even worse
if we want our visitor to capture or modify some other state.
Hmm—<a href="https://stackoverflow.com/a/7627218">lambdas</a> are perfect
for capturing state.
What if we could build a visitor from those?</p>
<div><pre><code><span>make_visitor</span><span>(</span>
    <span>[</span><span>&amp;</span><span>](</span><span>const</span> <span>string</span><span>&amp;</span> <span>s</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"string: %s</span><span>\n</span><span>"</span><span>,</span> <span>s</span><span>.</span><span>c_str</span><span>());</span>
        <span>// ...
</span>    <span>},</span>
    <span>[</span><span>&amp;</span><span>](</span><span>const</span> <span>int</span> <span>d</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"integer: %d</span><span>\n</span><span>"</span><span>,</span> <span>d</span><span>);</span>
        <span>// ...
</span>    <span>},</span>
    <span>[</span><span>&amp;</span><span>](</span><span>const</span> <span>bool</span> <span>b</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"bool: %d</span><span>\n</span><span>"</span><span>,</span> <span>b</span><span>);</span>
        <span>// ...
</span>    <span>}</span>
<span>)</span>
</code></pre>
</div>
<p>That’s a bit better, but the standard library doesn’t provide any sort of
<code>make_visitor</code> to combine the lambdas into a callable object for us.
We’ll need to define it ourselves.</p>

<div><pre><code><span>template</span> <span>&lt;</span><span>class</span><span>...</span> <span>Fs</span><span>&gt;</span>
<span>struct</span> <span>overload</span><span>;</span>

<span>template</span> <span>&lt;</span><span>class</span> <span>F0</span><span>,</span> <span>class</span><span>...</span> <span>Frest</span><span>&gt;</span>
<span>struct</span> <span>overload</span><span>&lt;</span><span>F0</span><span>,</span> <span>Frest</span><span>...</span><span>&gt;</span> <span>:</span> <span>F0</span><span>,</span> <span>overload</span><span>&lt;</span><span>Frest</span><span>...</span><span>&gt;</span>
<span>{</span>
    <span>overload</span><span>(</span><span>F0</span> <span>f0</span><span>,</span> <span>Frest</span><span>...</span> <span>rest</span><span>)</span> <span>:</span> <span>F0</span><span>(</span><span>f0</span><span>),</span> <span>overload</span><span>&lt;</span><span>Frest</span><span>...</span><span>&gt;</span><span>(</span><span>rest</span><span>...)</span> <span>{}</span>

    <span>using</span> <span>F0</span><span>::</span><span>operator</span><span>();</span>
    <span>using</span> <span>overload</span><span>&lt;</span><span>Frest</span><span>...</span><span>&gt;::</span><span>operator</span><span>();</span>
<span>};</span>

<span>template</span> <span>&lt;</span><span>class</span> <span>F0</span><span>&gt;</span>
<span>struct</span> <span>overload</span><span>&lt;</span><span>F0</span><span>&gt;</span> <span>:</span> <span>F0</span>
<span>{</span>
    <span>overload</span><span>(</span><span>F0</span> <span>f0</span><span>)</span> <span>:</span> <span>F0</span><span>(</span><span>f0</span><span>)</span> <span>{}</span>

    <span>using</span> <span>F0</span><span>::</span><span>operator</span><span>();</span>
<span>};</span>

<span>template</span> <span>&lt;</span><span>class</span><span>...</span> <span>Fs</span><span>&gt;</span>
<span>auto</span> <span>make_visitor</span><span>(</span><span>Fs</span><span>...</span> <span>fs</span><span>)</span>
<span>{</span>
    <span>return</span> <span>overload</span><span>&lt;</span><span>Fs</span><span>...</span><span>&gt;</span><span>(</span><span>fs</span><span>...);</span>
<span>}</span>
</code></pre>
</div>

<p>Here we use C++11’s <a href="http://en.cppreference.com/w/cpp/language/parameter_pack">variadic templates</a>.
They must be defined recursively, so we create some base case <code>F0</code>,
then use that to define a cascading set of constructors for <code>overload</code>,
each of which peels off a lambda argument and adds it to the type
as a call operator.</p>

<p>If this seems troublesome, fear not! C++17 will offer a new syntax
that reduces all of the above to:</p>
<div><pre><code><span>template</span><span>&lt;</span><span>class</span><span>...</span> <span>Ts</span><span>&gt;</span> <span>struct</span> <span>overloaded</span> <span>:</span> <span>Ts</span><span>...</span> <span>{</span> <span>using</span> <span>Ts</span><span>::</span><span>operator</span><span>()...;</span> <span>};</span>
<span>template</span><span>&lt;</span><span>class</span><span>...</span> <span>Ts</span><span>&gt;</span> <span>overloaded</span><span>(</span><span>Ts</span><span>...)</span> <span>-&gt;</span> <span>overloaded</span><span>&lt;</span><span>Ts</span><span>...</span><span>&gt;</span><span>;</span>
</code></pre>
</div>
<p>Easy, right? But if don’t like any of these options, you could
use C++17’s compile-time conditionals instead:</p>
<div><pre><code><span>[](</span><span>auto</span><span>&amp;</span> <span>arg</span><span>)</span> <span>{</span>
    <span>using</span> <span>T</span> <span>=</span> <span>std</span><span>::</span><span>decay_t</span><span>&lt;</span><span>decltype</span><span>(</span><span>arg</span><span>)</span><span>&gt;</span><span>;</span>

    <span>if</span> <span>constexpr</span> <span>(</span><span>std</span><span>::</span><span>is_same_v</span><span>&lt;</span><span>T</span><span>,</span> <span>string</span><span>&gt;</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"string: %s</span><span>\n</span><span>"</span><span>,</span> <span>arg</span><span>.</span><span>c_str</span><span>());</span>
        <span>// ...
</span>    <span>}</span>
    <span>else</span> <span>if</span> <span>constexpr</span> <span>(</span><span>std</span><span>::</span><span>is_same_v</span><span>&lt;</span><span>T</span><span>,</span> <span>int</span><span>&gt;</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"integer: %d</span><span>\n</span><span>"</span><span>,</span> <span>arg</span><span>);</span>
        <span>// ...
</span>    <span>}</span>
    <span>else</span> <span>if</span> <span>constexpr</span> <span>(</span><span>std</span><span>::</span><span>is_same_v</span><span>&lt;</span><span>T</span><span>,</span> <span>bool</span><span>&gt;</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"bool: %d</span><span>\n</span><span>"</span><span>,</span> <span>arg</span><span>);</span>
        <span>// ...
</span>    <span>}</span>
<span>}</span>
</code></pre>
</div>

<p>Much better, no?</p>

<h2 id="no">No.</h2>

<p>The rigmarole needed for <code>std::visit</code> is entirely insane.
We started with a simple goal: look at the contents of a sum type.
To accomplish this meager mission, we had to:</p>

<ol>
  <li>
    <p>Define a function object, which requires a lot of
boilerplate, <em>or</em></p>
  </li>
  <li>Define our behavior with lambdas, which required:
    <ul>
      <li>An understanding of variadic templates, in all their recursively-defined fun, <em>or</em></li>
      <li>A familiarity with variadic <code>using</code> declarations, fresh on the scene from C++17.</li>
    </ul>

    <p><em>or</em></p>
  </li>
  <li>Use compile-time conditionals, which require you to know
about—and grok—the new <code><span>constexpr</span> <span>if</span></code> syntax, along with
<code>type_traits</code> fun like
<code>std::decay</code>.</li>
</ol>

<p>None of these concepts are too enigmatic if you’re an experienced C++ developer,
but several are certainly “advanced” features of the language.
Things have really gone sideways if we need to know so much
to do something so simple.</p>

<h2 id="how-did-we-get-here">How did we get here?</h2>

<p>My goal isn’t to disparage the folks on the ISO C++ committee
who picked this approach.
I’ve had beers with some of them,
and they’re smart, kind, hardworking people.
I’m sure that I’m missing important context since I’ve never sat in on a
standards meeting or read all of the relevant
<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/">committee papers</a>.
But from an outsider’s perspective, the disparity in complexity between the
problem being solved (“What’s in here?”)
and the solutions is just nuts.
How do you teach this without overwhelming a beginner with all this other…
stuff?
Is it expected to be common knowledge for your everyday programmer?
(And if the goal of adding <code>variant</code> to the standard library <em>isn’t</em> to
make it a tool for the masses, shouldn’t it be?)
The very least C++17 could do—if the committee didn’t have the time or resources
to get pattern matching into the language—is provide something akin to <code>make_visitor</code>.
But that too is left as an exercise for the user.</p>

<p>If I had to guess how we ended up this way,
I’d assume it comes down to confirmation bias.
Maybe when a bunch of really smart people who know how
<a href="http://en.cppreference.com/w/cpp/language/sfinae">SFINAE</a> works offhand
and don’t flinch when they see the likes of</p>

<div><pre><code><span>template</span> <span>&lt;</span><span>typename</span> <span>F</span><span>&gt;</span>
<span>typename</span> <span>std</span><span>::</span><span>enable_if</span><span>&lt;!</span><span>std</span><span>::</span><span>is_reference</span><span>&lt;</span><span>F</span><span>&gt;::</span><span>value</span><span>,</span> <span>int</span><span>&gt;::</span><span>type</span>
<span>foo</span><span>(</span><span>F</span> <span>f</span><span>)</span>
<span>{</span>
    <span>// ...
</span><span>}</span>
</code></pre>
</div>

<p>get together, the result is something like <code>std::visit</code>.
Nobody proclaims that the emperor has no clothes, or that it’s completely
bonkers to expect the average user to build an overloaded callable
object with recursive templates just to see if the thing they’re looking at
holds an <code><span>int</span></code> or a <code><span>string</span></code>.</p>

<p>I’m also not here to claim that C++ is too complicated for its own good,
but it’s certainly more complicated than it has to be.
Scott Meyers, the guy who wrote <em>Effective&nbsp;C++</em> and <em>Effective Modern&nbsp;C++</em>,
has made similar noises in <a href="http://www.ustream.tv/recorded/47947981">recent</a>
<a href="https://youtu.be/RT46MpK39rQ?t=29m51s">talks</a>.
To paraphrase Meyers, I’m sure each member of the committee cares very much
about avoiding needless complexity and making the language easier to use.
But if you look at the results of their work, it’s hard to tell.
The accidental complexity just keeps stacking up.</p>

<h2 id="where-are-we-headed">Where are we headed?</h2>

<p>There’s a reason C++ is so widely used, especially in systems programming.<sup id="fnref:3"><a href="#fn:3">3</a></sup>
It can be incredibly expressive, yet gives you nearly full control of your hardware.
The tooling around it is some of the most mature of any programming language
out there, bar C.
It supports a ridiculous number of platforms.</p>

<p>But even if you set aside all the historical baggage, it has some serious shortcomings.
Spend any amount of time messing with D and you’ll quickly realize that
metaprogramming needn’t require self-flagellation and insane syntax.
Play with Rust and <!-- Hi, PCJ --> you’ll feel like <code>unique_ptr</code>
and <code>shared_ptr</code>—which themselves have been a breath of fresh air—are
a bad joke.
The fact that we still handle dependencies in 2017
by literally copy-pasting files into each other with <code><span>#include</span></code>
macros is <em>obscene</em>.</p>

<p>You get the impression, based on what ends up in the ISO standards and what
you hear in conference talks,
that those driving C++ are trying to eliminate some of these shortcomings by
glomming nice bits from other languages onto it.
That’s a great idea on its face,
but these features often seem to arrive half-baked.
While C++ isn’t going away any time soon,
it feels like the language is constantly playing a clumsy game of catchup.</p>

<hr>

<p>In spite of all of this,
I’ll be busy encouraging my coworkers to use <code>variant</code> if anybody needs me.
Sum types are such a useful concept that they’re worth the pain,
and <a href="https://www.youtube.com/watch?v=wvtFGa6XJDU">to quote Jon Kalb</a>,
“If you can’t program in a language with ugly warts, maybe C++ isn’t the language
you should be programming in.”</p>

<hr>



  </article></div>]]>
            </description>
            <link>https://bitbashing.io/std-visit.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25314126</guid>
            <pubDate>Sat, 05 Dec 2020 12:44:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scaling Down Deep Learning]]>
            </title>
            <description>
<![CDATA[
Score 122 | Comments 35 (<a href="https://news.ycombinator.com/item?id=25314066">thread link</a>) | @lelf
<br/>
December 5, 2020 | https://greydanus.github.io/2020/12/01/scaling-down/ | <a href="https://web.archive.org/web/*/https://greydanus.github.io/2020/12/01/scaling-down/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
      <div>

  

  <article>
  

<div>
    <div>
    <video id="demoDisplay">
    	<source src="https://greydanus.github.io/assets/scaling-down/construction.mp4" type="video/mp4">
    </video>
    <p>Constructing the MNIST-1D dataset. As with the original MNIST dataset, the task is to learn to classify the digits 0-9. Unlike the MNIST dataset, which consists of 28x28 images, each of these examples is a one-dimensional sequence of points. To generate an example, we begin with 10 digit templates and then randomly pad, translate, add noise, and transform them as shown above.</p>
  	</div>
</div>





<p>By any scientific standard, the Human Genome Project <a href="https://deepblue.lib.umich.edu/handle/2027.42/62798">was enormous</a>: it involved billions of dollars of funding, dozens of institutions, and over a decade of accelerated research. But that was only the tip of the iceberg. Long before the project began, scientists were hard at work assembling the intricate science of human genetics. And most of the time, they were not studying humans. The foundational discoveries in genetics centered on far simpler organisms such as peas, molds, fruit flies, and mice. To this day, biologists use these simpler organisms as genetic “minimal working examples” in order to save time, energy, and money. A well-designed experiment with Drosophilia, such as <a href="https://pubmed.ncbi.nlm.nih.gov/10746727/">Feany and Bender (2000)</a>, can teach us an astonishing amount about humans.</p>

<p>The deep learning analogue of Drosophilia is the MNIST dataset. A large number of deep learning innovations including <a href="https://jmlr.org/papers/v15/srivastava14a.html">dropout</a>, <a href="https://arxiv.org/abs/1412.6980">Adam</a>, <a href="http://yann.lecun.com/exdb/publis/pdf/lecun-89e.pdf">convolutional networks</a>, <a href="https://arxiv.org/abs/1406.2661">generative adversarial networks</a>, and <a href="https://arxiv.org/abs/1312.6114">variational autoencoders</a> began life as MNIST experiments. Once these innovations proved themselves on small-scale experiments, scientists found ways to scale them to larger and more impactful applications.</p>

<p>They key advantage of Drosophilia and MNIST is that they dramatically accelerate the iteration cycle of exploratory research. In the case of Drosophilia, the fly’s life cycle is just a few days long and its nutritional needs are negligible. This makes it much easier to work with than mammals, especially humans. In the case of MNIST, training a strong classifier takes a few dozen lines of code, less than a minute of walltime, and negligible amounts of electricity. This is a stark contrast to state-of-the-art vision, text, and game-playing models which can take months and <a href="https://arxiv.org/abs/2004.08900">hundreds of thousands of dollars</a> of electricity to train.</p>

<p>Yet in spite of its historical significance, MNIST has three notable shortcomings. First, it does a poor job of differentiating between linear, nonlinear, and translation-invariant models. For example, logistic, MLP, and CNN benchmarks obtain 94, 99+, and 99+% accuracy on it. This makes it hard to measure the contribution of a CNN’s spatial priors or to judge the relative effectiveness of different regularization schemes. Second, it is somewhat large for a toy dataset. Each input example is a 784-dimensional vector and thus it takes a non-trivial amount of computation to perform hyperparameter searches or debug a metalearning loop. Third, MNIST is hard to hack. The ideal toy dataset should be procedurally generated so that researchers can smoothly vary parameters such as background noise, translation, and resolution.</p>

<p>In order to address these shortcomings, we propose the MNIST-1D dataset. It is a minimalist, low-memory, and low-compute alternative to MNIST, designed for exploratory deep learning research where rapid iteration is a priority. Training examples are 20 times smaller but they are still better at measuring the difference between 1) linear and nonlinear classifiers and 2) models with and without spatial inductive biases (eg. translation invariance). The dataset is procedurally generated but still permits analogies to real-world digit classification.</p>

<div>
  <div>
    <p><img src="https://greydanus.github.io/assets/scaling-down/overview_a.png"></p><p>Constructing the MNIST-1D dataset. Like MNIST, the classifier's objective is to determine which digit is present in the input. Unlike MNIST, each example is a one-dimensional sequence of points. To generate an example, we begin with a digit template and then randomly pad, translate, and transform it.</p>
  </div>
  <div>
    <p><img src="https://greydanus.github.io/assets/scaling-down/overview_b.png"></p><p>Visualizing the performance of common models on the MNIST-1D dataset. This dataset separates them cleanly according to whether they use nonlinear features (logistic regression vs. MLP) or whether they have spatial inductive biases (MLP vs. CNN). Humans do best of all. Best viewed with zoom.</p>
  </div>
</div>

<div>
  <p><img src="https://greydanus.github.io/assets/scaling-down/tsne.png">
  </p>
  <p>Visualizing the MNIST and MNIST-1D datasets with tSNE. The well-defined clusters in the MNIST plot indicate that the majority of the examples are separable via a kNN classifier in pixel space. The MNIST-1D plot, meanwhile, reveals a lack of well-defined clusters which suggests that learning a nonlinear representation of the data is much more important to achieve successful classification. Thanks to <a href="https://twitter.com/hippopedoid">Dmitry Kobak</a> for making this plot.</p>
</div>

<h2 id="example-use-cases">Example use cases</h2>

<p>In this section we will explore several examples of how MNIST-1D can be used to study core “science of deep learning” phenomena.</p>

<p><strong>Finding lottery tickets.</strong> It is not unusual for deep learning models to have ten or even a hundred times more parameters than necessary. This overparameterization helps training but increases computational overhead. One solution is to progressively prune weights from a model during training so that the final network is just a fraction of its original size. Although this approach works, conventional wisdom holds that sparse networks do not train well from scratch. Recent work by <a href="https://arxiv.org/abs/1803.03635">Frankle &amp; Carbin (2019)</a> challenges this conventional wisdom. The authors report finding sparse subnetworks inside of larger networks that train to equivalent or even higher accuracies. These “lottery ticket” subnetworks can be found through a simple iterative procedure: train a network, prune the smallest weights, and then rewind the remaining weights to their original initializations and retrain.</p>

<p>Since the original paper was published, a multitude of works have sought to explain this phenomenon and then harness it on larger datasets and models. However, very few works have attempted to isolate a “minimal working example” of this effect so as to investigate it more carefully. The figure below shows that the MNIST-1D dataset not only makes this possible, but also enables us to elucidate, via carefully-controlled experiments, some of the reasons for a lottery ticket’s success. Unlike many follow-up experiments on the lottery ticket, this one took just two days of researcher time to produce. The curious reader can also <a href="https://bit.ly/3nCEIaL">reproduce these results</a> in their browser in a few minutes.</p>

<div>
  <p><img src="https://greydanus.github.io/assets/scaling-down/lottery_a1.png">
  </p>
  <p><img src="https://greydanus.github.io/assets/scaling-down/lottery_a2.png">
  </p>
  <p>Finding and analyzing lottery tickets. In <b>a-b)</b>, we isolate a "minimum viable example" of the effect. Recent work by <a href="https://arxiv.org/abs/1906.02773">Morcos et al (2019)</a> shows that lottery tickets can transfer between datasets. We wanted to determine whether spatial inductive biases played a role. So we performed a series of experiments: in <b>c)</b> we plot the asymptotic performance of a 92% sparse ticket. In <b>d)</b> we reverse all the 1D signals in the dataset, effectively preserving spatial structure but changing the location of individual datapoints. This is analogous to flipping an image upside down. Under this ablation, the lottery ticket continues to win.</p>
</div>

<div>
  <p><img src="https://greydanus.github.io/assets/scaling-down/lottery_b1.png">
  </p>
  <p><img src="https://greydanus.github.io/assets/scaling-down/lottery_b2.png">
  </p>
    <p>Next, in <b>e)</b> we permute the indices of the 1D signal, effectively removing spatial structure from the dataset. This ablation hurts lottery ticket performance significantly more, suggesting that part of the lottery ticket's performance can be attributed to a spatial inductive bias. Finally, in <b>f)</b> we keep the lottery ticket sparsity structure but initialize its weights with a different random seed. Contrary to results reported in <a href="https://arxiv.org/abs/1803.03635">Frankle &amp; Carbin (2019)</a>, we see that our lottery ticket continues to outperform a dense baseline, aligning well with our hypothesis that the lottery ticket mask has a spatial inductive bias. In <b>g)</b>, we verify our hypothesis by measuring how often unmasked weights are adjacent to one another in the first layer of our model. The lottery ticket has many more adjacent weights than chance would predict, implying a local connectivity structure which helps gives rise to spatial biases.</p>
</div>

<p>You can also visualize the actual masks selected via random and lottery pruning:
<br></p>





<p><strong>Observing deep double descent.</strong> Another intriguing property of neural networks is the “double descent” phenomenon. This phrase refers to a training regime where more data, model parameters, or gradient steps can actually <em>reduce</em> a model’s test accuracy<sup id="fnref:fn1" role="doc-noteref"><a href="#fn:fn1">1</a></sup> <sup id="fnref:fn2" role="doc-noteref"><a href="#fn:fn2">2</a></sup> <sup id="fnref:fn3" role="doc-noteref"><a href="#fn:fn3">3</a></sup> <sup id="fnref:fn4" role="doc-noteref"><a href="#fn:fn4">4</a></sup>. The intuition is that during supervised learning there is an interpolation threshold where the learning procedure, consisting of a model and an optimization algorithm, is just barely able to fit the entire training set. At this threshold there is effectively just one model that can fit the data and this model is very sensitive to label noise and model mis-specification.</p>

<p>Several properties of this effect, such as what factors affect its width and location, are not well understood in the context of deep models. We see the MNIST-1D dataset as a good tool for exploring these properties. In fact, we were able to reproduce the double descent pattern after a few hours of researcher effort. The figure below shows our results for a fully-connected network and a convolutional model. We also observed a nuance that we had not seen mentioned in previous works: when using a mean square error loss, the interpolation threshold lies at \(n * K\) model parameters where \(n\) is the number of training examples and \(K\) is the number of model outputs. But when using a negative log likelihood loss, the interpolation threshold lies at \(n\) model parameters – it does not depend on the number of model outputs. This is an interesting empirical observation that may explain some of the advantage in using a log likelihood loss over a MSE loss on this type of task. You can reproduce these results <a href="https://bit.ly/2UBWWNu">here</a>.</p>

<div>
  <p><img src="https://greydanus.github.io/assets/scaling-down/ddd_a.png">
  </p>
  <p><img src="https://greydanus.github.io/assets/scaling-down/ddd_b.png">
  </p>
  <p>Observing deep double descent. MNIST-1D is a good environment for determining how to locate the interpolation threshold of deep models. This threshold is fairly easy to predict in fully-connected models but less easy to …</p></div></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://greydanus.github.io/2020/12/01/scaling-down/">https://greydanus.github.io/2020/12/01/scaling-down/</a></em></p>]]>
            </description>
            <link>https://greydanus.github.io/2020/12/01/scaling-down/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25314066</guid>
            <pubDate>Sat, 05 Dec 2020 12:30:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Your Smart TV is probably ignoring your PiHole]]>
            </title>
            <description>
<![CDATA[
Score 403 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25313776">thread link</a>) | @giuliomagnifico
<br/>
December 5, 2020 | https://labzilla.io/blog/force-dns-pihole | <a href="https://web.archive.org/web/*/https://labzilla.io/blog/force-dns-pihole">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p><span><i></i></span> <strong>Welcome Hacker News readers!</strong><br>
<strong>•</strong> Thank you to <a href="https://homepage.cs.uiowa.edu/~mmazhar/">M. Hammad Mazhar</a> for his <a href="https://arxiv.org/pdf/2001.08288.pdf">research</a> that inspired this guide.<br>
<strong>•</strong> <a href="https://twitter.com/healeyio">@healyio</a> made some great additional suggestions in this Twitter <a href="https://twitter.com/healeyio/status/1335347122649006080">thread</a> which I’ll be incorporating into a future update.<br>
<strong>•</strong> The HN <a href="https://news.ycombinator.com/item?id=25313480">comment thread</a> is full of insightful comments from individuals who work on IoT hardware and other embedded devices, and is well worth a read.<br>
<strong>•</strong> Finally, you can subscribe to the <a href="https://labzilla.io/feed.xml">RSS feed</a> or follow on <a href="https://twitter.com/labzilla">Twitter</a> for updates.</p>
<p>If you’re using PiHole on your network to block ads and prevent your various smart devices from sending tracking information to their manufacturers, <strong>you might be surprised to find out that some of these devices are using a sneaky tactic to bypass your PiHole entirely.</strong></p>
<p>Smart devices manufacturers often “hard-code” in a public DNS server, like Google’s 8.8.8.8, and their devices ignore whatever DNS server is assigned by your router - such as your PiHole.</p>
<p><a href="https://arxiv.org/pdf/2001.08288.pdf">Nearly 70% of smart TVs and 46% of game consoles</a> were found to contain hardcoded DNS settings - allowing them to simply ignore your local network’s DNS server entirely. On average, Smart TVs generate an average of 60 megabytes of outgoing Internet traffic <em>per day</em>, all the while bypassing tools like PiHole.</p>
<h2 id="force-all-dns-queries-through-pihole">Force all DNS queries through PiHole</h2>
<p>Fortunately, with a few simple firewall rules, you can intercept these hardcoded DNS queries and redirect them to your PiHole. These instructions are for pfSense, however you should be able to adapt them for Sophos XG, Ubiquiti EdgeRouter, etc.</p>
<h3 id="create-nat-rules">Create NAT Rules</h3>
<p>Log in to your pfSense admin interface, and navigate to <em>Firewall</em> &gt; <em>NAT</em> &gt; <em>Port Forward</em>.</p>
<p>We’re going to create two Port Forward NAT rules - one to redirect any DNS queries originating from devices on the LAN to PiHole, and another to allow PiHole to commmunicate with external DNS servers. We will also create an additional outbound NAT rule that will make this process invisible to any clients on the network with hardcoded DNS.</p>
<p><strong>NAT Rule 1: Redirect DNS queries to PiHole</strong></p>
<p>Click the <em>Add</em> button to create your first new NAT Port Forward rule.</p>
<ul>
<li><strong>Interface:</strong> LAN</li>
<li><strong>Protcol:</strong> TCP/UDP</li>
<li><strong>Source:</strong> LAN net (you may need to click the blue show advanced button to see this option)</li>
<li><strong>Destination - Invert match:</strong> Checked</li>
<li><strong>Destination - Type:</strong> Single host or alias</li>
<li><strong>Destination - Address/mask:</strong> Your PiHole’s IP address</li>
<li><strong>Destination Port Range - From:</strong> DNS</li>
<li><strong>Destination Port Range - To:</strong> DNS</li>
<li><strong>Redirect Target IP:</strong> Your PiHole’s IP address</li>
<li><strong>Redirect Target Port:</strong> DNS</li>
<li><strong>Description:</strong> Intercept any outgoing DNS queries and redirect them to PiHole.</li>
</ul>
<p><strong>NAT Rule 2: Exempt PiHole from DNS query redirects</strong></p>
<p>Click the <em>Add</em> button to create your second new NAT Port Forward rule.</p>
<ul>
<li><strong>No RDR (NOT):</strong> Checked</li>
<li><strong>Interface:</strong> LAN</li>
<li><strong>Protcol:</strong> TCP/UDP</li>
<li><strong>Source - Type:</strong> Single host or alias</li>
<li><strong>Source - Address/Mask:</strong> Your PiHole’s IP address</li>
<li><strong>Destination:</strong> Any</li>
<li><strong>Destination Port Range - From:</strong> DNS</li>
<li><strong>Destination Port Range - From:</strong> DNS</li>
<li><strong>Description:</strong> Allow PiHole to reach external DNS servers</li>
</ul>
<p><strong>Note:</strong> pfSense (and most other firewalls) process rules from top to bottom. Make sure you drag the second rule exempting PiHole from DNS query redirects <em>above</em> the first rule we created - otherwise PiHole will not be able to contact external DNS servers.</p>
<p><strong>NAT Rule 3: Prevent clients from giving unexpected source errors</strong></p>
<p>Finally, we need to create an outbound NAT rule. Navigate to <em>Firewall</em> &gt; <em>NAT</em> &gt; <em>Outbound</em>.</p>
<ul>
<li><strong>Interface:</strong> LAN</li>
<li><strong>Address Family:</strong> IPv4+IPv6</li>
<li><strong>Protocol:</strong> any</li>
<li><strong>Source - Type:</strong> Network</li>
<li><strong>Source - Network for the outbound NAT mapping:</strong> Your internal LAN network</li>
<li><strong>Destination - Type:</strong> Network</li>
<li><strong>Destination - Network for the outbound NAT Mappings:</strong> Your PiHole’s IP Address</li>
<li><strong>Destination Port Range:</strong> 53</li>
<li><strong>Translation:</strong> Interface Address</li>
<li><strong>Description:</strong> Prevents hardcoded DNS clients from giving unexpected source error after DNS redirected to PiHole.</li>
</ul>
<h3 id="test-it-out">Test it out</h3>
<p>You can easily test to make sure your DNS redirection is working properly.</p>
<ol>
<li>Create a new, temporary internal DNS entry on your network (“piholetest.example.com”), and point it to 10.0.1.1. You can do this right from PiHole under <em>Local DNS Records</em>.</li>
<li>Manually set your computer’s DNS server to <em>1.1.1.1</em>.</li>
<li>Open a terminal window (or command promt on Windows), and run <code>nslookup piholetest.example.com</code></li>
<li>
<p>If you set this up correctly, <code>nslookup</code> should return 10.0.1.1. Your computer <em>thinks</em> it’s receiving DNS records from 1.1.1.1, while in reality they are coming from your PiHole.</p>
<div><div><pre><code> macbookpro:~ labzilla$ nslookup piholetest.example.com
 Server:		1.1.1.1
 Address:	1.1.1.1#53
	
 Name:	piholetest.example.com
 Address: 10.0.1.1
</code></pre></div> </div>
</li>
<li>
<p>You can further demonstate this by temporarily disabling the first NAT rule we created, and running the same <code>nslookup piholetest.example.com</code> command:</p>
<div><div><pre><code> macbookpro:~ labzilla$ nslookup piholetest.example.com
 Server:		1.1.1.1
 Address:	1.1.1.1#53
	
 ** server can't find piholetest.example.com: NXDOMAIN 
</code></pre></div> </div>
<p>As “piholetest.example.com” doesn’t exist on the public Internet, the real 1.1.1.1 server has no record to provide - resulting in your <code>nslookup</code> request returning a NXDOMAIN error.</p>
</li>
</ol>
<p><strong>Don’t forget to revert your computer’s DNS settings back to their original value, and reenable any firewall rules you temporary disabled while testing.</strong></p>
<h2 id="hacker-news">Hacker News</h2>
<p>This post hit the front page of Hacker News <span><i></i></span> on Saturday December 5th, 2020. Thank you <a href="https://boramalper.org/">@boramalper</a> for submitting it, and I hope you found the information useful!</p>
<ul>
<li>If you’re curious about what the Hacker News bump looks like - this blog normally sees about 100 hits per day. Between December 5th-6th, this post had over 70,000 views.</li>
<li>The <a href="https://news.ycombinator.com/item?id=25313480">original comment thread</a> is full of insightful comments from individuals who work on IoT hardware and other embedded devices, and is well worth a read.</li>
<li>A follow up article incorporating some of the suggestion that <a href="https://twitter.com/healeyio">@healyio</a> made in this Twitter <a href="https://twitter.com/healeyio/status/1335347122649006080">thread</a> is coming soon.</li>
</ul>
</div></div>]]>
            </description>
            <link>https://labzilla.io/blog/force-dns-pihole</link>
            <guid isPermaLink="false">hacker-news-small-sites-25313776</guid>
            <pubDate>Sat, 05 Dec 2020 11:38:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[72% of smart TVs and 46% of game consoles hardcode DNS settings]]>
            </title>
            <description>
<![CDATA[
Score 516 | Comments 632 (<a href="https://news.ycombinator.com/item?id=25313480">thread link</a>) | @boramalper
<br/>
December 5, 2020 | https://labzilla.io/blog/force-dns-pihole | <a href="https://web.archive.org/web/*/https://labzilla.io/blog/force-dns-pihole">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p><span><i></i></span> <strong>Welcome Hacker News readers!</strong><br>
<strong>•</strong> Thank you to <a href="https://homepage.cs.uiowa.edu/~mmazhar/">M. Hammad Mazhar</a> for his <a href="https://arxiv.org/pdf/2001.08288.pdf">research</a> that inspired this guide.<br>
<strong>•</strong> <a href="https://twitter.com/healeyio">@healyio</a> made some great additional suggestions in this Twitter <a href="https://twitter.com/healeyio/status/1335347122649006080">thread</a> which I’ll be incorporating into a future update.<br>
<strong>•</strong> The HN <a href="https://news.ycombinator.com/item?id=25313480">comment thread</a> is full of insightful comments from individuals who work on IoT hardware and other embedded devices, and is well worth a read.<br>
<strong>•</strong> Finally, you can subscribe to the <a href="https://labzilla.io/feed.xml">RSS feed</a> or follow on <a href="https://twitter.com/labzilla">Twitter</a> for updates.</p>
<p>If you’re using PiHole on your network to block ads and prevent your various smart devices from sending tracking information to their manufacturers, <strong>you might be surprised to find out that some of these devices are using a sneaky tactic to bypass your PiHole entirely.</strong></p>
<p>Smart devices manufacturers often “hard-code” in a public DNS server, like Google’s 8.8.8.8, and their devices ignore whatever DNS server is assigned by your router - such as your PiHole.</p>
<p><a href="https://arxiv.org/pdf/2001.08288.pdf">Nearly 70% of smart TVs and 46% of game consoles</a> were found to contain hardcoded DNS settings - allowing them to simply ignore your local network’s DNS server entirely. On average, Smart TVs generate an average of 60 megabytes of outgoing Internet traffic <em>per day</em>, all the while bypassing tools like PiHole.</p>
<h2 id="force-all-dns-queries-through-pihole">Force all DNS queries through PiHole</h2>
<p>Fortunately, with a few simple firewall rules, you can intercept these hardcoded DNS queries and redirect them to your PiHole. These instructions are for pfSense, however you should be able to adapt them for Sophos XG, Ubiquiti EdgeRouter, etc.</p>
<h3 id="create-nat-rules">Create NAT Rules</h3>
<p>Log in to your pfSense admin interface, and navigate to <em>Firewall</em> &gt; <em>NAT</em> &gt; <em>Port Forward</em>.</p>
<p>We’re going to create two Port Forward NAT rules - one to redirect any DNS queries originating from devices on the LAN to PiHole, and another to allow PiHole to commmunicate with external DNS servers. We will also create an additional outbound NAT rule that will make this process invisible to any clients on the network with hardcoded DNS.</p>
<p><strong>NAT Rule 1: Redirect DNS queries to PiHole</strong></p>
<p>Click the <em>Add</em> button to create your first new NAT Port Forward rule.</p>
<ul>
<li><strong>Interface:</strong> LAN</li>
<li><strong>Protcol:</strong> TCP/UDP</li>
<li><strong>Source:</strong> LAN net (you may need to click the blue show advanced button to see this option)</li>
<li><strong>Destination - Invert match:</strong> Checked</li>
<li><strong>Destination - Type:</strong> Single host or alias</li>
<li><strong>Destination - Address/mask:</strong> Your PiHole’s IP address</li>
<li><strong>Destination Port Range - From:</strong> DNS</li>
<li><strong>Destination Port Range - To:</strong> DNS</li>
<li><strong>Redirect Target IP:</strong> Your PiHole’s IP address</li>
<li><strong>Redirect Target Port:</strong> DNS</li>
<li><strong>Description:</strong> Intercept any outgoing DNS queries and redirect them to PiHole.</li>
</ul>
<p><strong>NAT Rule 2: Exempt PiHole from DNS query redirects</strong></p>
<p>Click the <em>Add</em> button to create your second new NAT Port Forward rule.</p>
<ul>
<li><strong>No RDR (NOT):</strong> Checked</li>
<li><strong>Interface:</strong> LAN</li>
<li><strong>Protcol:</strong> TCP/UDP</li>
<li><strong>Source - Type:</strong> Single host or alias</li>
<li><strong>Source - Address/Mask:</strong> Your PiHole’s IP address</li>
<li><strong>Destination:</strong> Any</li>
<li><strong>Destination Port Range - From:</strong> DNS</li>
<li><strong>Destination Port Range - From:</strong> DNS</li>
<li><strong>Description:</strong> Allow PiHole to reach external DNS servers</li>
</ul>
<p><strong>Note:</strong> pfSense (and most other firewalls) process rules from top to bottom. Make sure you drag the second rule exempting PiHole from DNS query redirects <em>above</em> the first rule we created - otherwise PiHole will not be able to contact external DNS servers.</p>
<p><strong>NAT Rule 3: Prevent clients from giving unexpected source errors</strong></p>
<p>Finally, we need to create an outbound NAT rule. Navigate to <em>Firewall</em> &gt; <em>NAT</em> &gt; <em>Outbound</em>.</p>
<ul>
<li><strong>Interface:</strong> LAN</li>
<li><strong>Address Family:</strong> IPv4+IPv6</li>
<li><strong>Protocol:</strong> any</li>
<li><strong>Source - Type:</strong> Network</li>
<li><strong>Source - Network for the outbound NAT mapping:</strong> Your internal LAN network</li>
<li><strong>Destination - Type:</strong> Network</li>
<li><strong>Destination - Network for the outbound NAT Mappings:</strong> Your PiHole’s IP Address</li>
<li><strong>Destination Port Range:</strong> 53</li>
<li><strong>Translation:</strong> Interface Address</li>
<li><strong>Description:</strong> Prevents hardcoded DNS clients from giving unexpected source error after DNS redirected to PiHole.</li>
</ul>
<h3 id="test-it-out">Test it out</h3>
<p>You can easily test to make sure your DNS redirection is working properly.</p>
<ol>
<li>Create a new, temporary internal DNS entry on your network (“piholetest.example.com”), and point it to 10.0.1.1. You can do this right from PiHole under <em>Local DNS Records</em>.</li>
<li>Manually set your computer’s DNS server to <em>1.1.1.1</em>.</li>
<li>Open a terminal window (or command promt on Windows), and run <code>nslookup piholetest.example.com</code></li>
<li>
<p>If you set this up correctly, <code>nslookup</code> should return 10.0.1.1. Your computer <em>thinks</em> it’s receiving DNS records from 1.1.1.1, while in reality they are coming from your PiHole.</p>
<div><div><pre><code> macbookpro:~ labzilla$ nslookup piholetest.example.com
 Server:		1.1.1.1
 Address:	1.1.1.1#53
	
 Name:	piholetest.example.com
 Address: 10.0.1.1
</code></pre></div> </div>
</li>
<li>
<p>You can further demonstate this by temporarily disabling the first NAT rule we created, and running the same <code>nslookup piholetest.example.com</code> command:</p>
<div><div><pre><code> macbookpro:~ labzilla$ nslookup piholetest.example.com
 Server:		1.1.1.1
 Address:	1.1.1.1#53
	
 ** server can't find piholetest.example.com: NXDOMAIN 
</code></pre></div> </div>
<p>As “piholetest.example.com” doesn’t exist on the public Internet, the real 1.1.1.1 server has no record to provide - resulting in your <code>nslookup</code> request returning a NXDOMAIN error.</p>
</li>
</ol>
<p><strong>Don’t forget to revert your computer’s DNS settings back to their original value, and reenable any firewall rules you temporary disabled while testing.</strong></p>
<h2 id="hacker-news">Hacker News</h2>
<p>This post hit the front page of Hacker News <span><i></i></span> on Saturday December 5th, 2020. Thank you <a href="https://boramalper.org/">@boramalper</a> for submitting it, and I hope you found the information useful!</p>
<ul>
<li>If you’re curious about what the Hacker News bump looks like - this blog normally sees about 100 hits per day. Between December 5th-6th, this post had over 70,000 views.</li>
<li>The <a href="https://news.ycombinator.com/item?id=25313480">original comment thread</a> is full of insightful comments from individuals who work on IoT hardware and other embedded devices, and is well worth a read.</li>
<li>A follow up article incorporating some of the suggestion that <a href="https://twitter.com/healeyio">@healyio</a> made in this Twitter <a href="https://twitter.com/healeyio/status/1335347122649006080">thread</a> is coming soon.</li>
</ul>
</div></div>]]>
            </description>
            <link>https://labzilla.io/blog/force-dns-pihole</link>
            <guid isPermaLink="false">hacker-news-small-sites-25313480</guid>
            <pubDate>Sat, 05 Dec 2020 10:46:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Make slides with text, markdown, YAML, JSON or JavaScript, your call]]>
            </title>
            <description>
<![CDATA[
Score 131 | Comments 27 (<a href="https://news.ycombinator.com/item?id=25313347">thread link</a>) | @abusedmedia
<br/>
December 5, 2020 | https://play.presenta.cc/v2 | <a href="https://web.archive.org/web/*/https://play.presenta.cc/v2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://play.presenta.cc/v2</link>
            <guid isPermaLink="false">hacker-news-small-sites-25313347</guid>
            <pubDate>Sat, 05 Dec 2020 10:21:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Between two Lisps]]>
            </title>
            <description>
<![CDATA[
Score 138 | Comments 94 (<a href="https://news.ycombinator.com/item?id=25313311">thread link</a>) | @galfarragem
<br/>
December 5, 2020 | https://ane.github.io/2020/10/05/between-two-lisps.html | <a href="https://web.archive.org/web/*/https://ane.github.io/2020/10/05/between-two-lisps.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Out of all Lisps the ones I’ve come to appreciate the most are <a href="https://en.wikipedia.org/wiki/Scheme_(programming_language)">Scheme</a> and <a href="https://common-lisp.net/">Common
Lisp</a>. <!--break-->These two languages are fundamentally very different: Scheme
is a minimalist language built on the foundations of <a href="https://en.wikipedia.org/wiki/Lambda_calculus">lambda calculus</a>, while
Common Lisp is a multi-paradigm synthesis of many Lisps before it. Common Lisp
is a large standard with many implementations, Scheme is a collection of an
evolving but minimalistic standard with many implementations. The core of Scheme
is quite small compared to Common Lisp. The latest standard <a href="http://www.r6rs.org/final/r6rs-lib.pdf">R6RS</a> is about 65
pages, while the ANSI Common Lisp standard from 1994 is about 1100 pages. The
<a href="https://srfi.schemers.org/">Scheme Requests for Implementation</a> process aims to standardize additional
features (like <a href="https://srfi.schemers.org/srfi-64/srfi-64.html">test suites</a>) that implementations may implement.</p>

<p>Common Lisp has some wonderful features, <a href="http://www.gigamonkeys.com/book/beyond-exception-handling-conditions-and-restarts.html">conditions and restarts</a>, the <a href="https://lispcookbook.github.io/cl-cookbook/clos.html">Common
Lisp Object System (CLOS)</a>, <a href="http://www.paulgraham.com/onlisp.html">the macro system</a>, among many other things. The <a href="http://joaotavora.github.io/sly/">SLY
IDE for Emacs</a> is <em>amazing</em>, and the <a href="http://www.sbcl.org/">Steel Bank Common Lisp</a> compiler is really
great. It has <a href="https://www.quicklisp.org/index.html">Quicklisp</a> and <a href="https://common-lisp.net/project/asdf/">ASDF</a> for package and build management,
respectively. I find the developer experience of Common Lisp to be superior to
almost anything imaginable, and this is not an empty statement: having used all
sorts of IDEs and editors for over 25 years, I have seen <em>many</em>.</p>

<h3 id="tastes-differ">Tastes differ</h3>

<p>That said, Common Lisp is <em>weird</em>. What I find particularly jarring is that
functions and variables live in different namespaces: if you put a function into
a variable, you can’t just use it like a function, you have to <code>funcall</code> it.
Having programmed in lots of languages of the ML family this is just, well, odd;
but this is due to historical reasons and there are <a href="http://www.nhplace.com/kent/Papers/Technical-Issues.html">sound technical reasons for
it</a>.  There are other
oddities, some strange things like <code>(cdr '())</code> is not an error (in Scheme it
is), <code>()</code> and <code>nil</code> are equal (in Scheme <code>#f</code> and <code>()</code> are separate things), and
so on.</p>

<p>This isn’t really a fault in Common Lisp: other languages have impacted my taste
and preferences to bias me in the direction of Scheme, but that is not to say I
cannot work with Common Lisp’s idiosyncracies. Actually, I don’t mind them, I
just <em>notice</em> them.</p>

<p>I like the naming styles of Scheme more, as well. It has <code>string?</code> vs <code>string-p</code>
for predicate functions, <code>set!</code>  for state modifying functions, <code>foo-&gt;bar</code> for
conversions, these make code quite easier to read. Scheme has hygienic macros,
Guile has the traditional <code>defmacro</code> as well.</p>

<p>Many nice Scheme features are available in Common Lisp libraries. Pattern match
is available in the <a href="https://github.com/guicho271828/trivia">trivia</a> library. Named lets are easy to implement with a macro.</p>

<p>Common Lisp aficionados are quick to point out things Scheme <em>doesn’t</em> have:
keyword arguments, docstrings, rest arguments, but my Scheme implementation of
choice Guile has these built into the language.</p>

<h3 id="productivity-matters">Productivity matters</h3>

<p>Guile is in a strange niche is that its primary <em>raison d’être</em> is to be an
extension language for the GNU project. Like Emacs Lisp is for extending Emacs,
Guile is the <em>de facto</em> language for GNU programs for extension and scripting.</p>

<p>Guile doesn’t have Quicklisp and its package manager and build system is
basically nonexistent for the first and <a href="https://www.gnu.org/software/autoconf/">Autoconf</a> for the second. There is
<a href="https://lists.gnu.org/archive/html/guile-user/2017-03/msg00168.html">sentiment</a> in the Guile community to have <a href="https://guix.gnu.org/">Guix</a> as the package manager for
Guile. This might sound a bit onerous, since Guix is also a complete package
management for many other things than Guile, but consider this: as Andy Wingo
points out in his message that Guile libraries often come with C extensions,
Guile packages need some sort of managed build system for building the C
extensions. Since it doesn’t have one, to solve the problem of building a
package manager you’d also have to build a build system that can manage C code
and packages needed by the C code bits. To do this elegantly is a gargantuan
task, for instance, <a href="https://wiki.call-cc.org/man/5/Extensions#installing-eggs-that-use-libraries">chicken-install just asks you to put compiler/linker flags
on the command line before calling it</a>, so it obviously is a hard problem.</p>

<p>Now, Guix solves all that, and more, in a manner that is quite elegant and
interesting. But it’s not as lightweight as something like Quicklisp or
<a href="https://wiki.call-cc.org/man/5/Extensions"><code>chicken-install</code></a> from <a href="http://call-cc.org/">CHICKEN Scheme</a>. What is more, Guix works only on GNU/Linux
systems really, so macOS and Windows users won’t be able to do use your library
if you plan on distributing it via Guix. Duh, it’s the GNU project, but
portability is always nice.</p>

<p>But in Common Lisp I can write <code>(ql:quickload :alexandria)</code> and voilà, it will
automatically install the <a href="http://quickdocs.org/alexandria/">Alexandria</a> library that I can use. Then again, in
Common Lisp it’s somewhat rarer to have C extensions, so I don’t know how ASDF
handles that.</p>

<p>It is unfair to compare <a href="http://joaotavora.github.io/sly/">SLY</a> to <a href="https://www.nongnu.org/geiser/">Geiser</a>, the best Emacs Scheme integration
package.  SLY is based on <a href="https://common-lisp.net/project/slime/">SLIME</a> which has <em>decades</em> of man-years of work behind
it. Geiser is able to support multiple Scheme implementations and it is quite
impressive in this regard. But SLY obviously has much more (e.g. an interactive
debugger). That said, Geiser has nice Guile support, and Guile is in general the
most Common Lisp-y of all Schemes, in fact, it has</p>

<ul>
  <li>an imitation of CLOS in the form of <a href="https://www.gnu.org/software/goops/">GOOPS</a></li>
  <li>docstrings and keyword, rest, and optional arguments for function
definitions</li>
  <li>an interactive REPL and a mutable top-level (unlike many Schemes)</li>
  <li>a nice module system</li>
  <li><a href="https://www.gnu.org/software/guile/manual/html_node/Defmacros.html"><code>defmacro</code></a> and exceptions somewhat <a href="https://www.gnu.org/software/guile/manual/html_node/Raising-and-Handling-Exceptions.html">similar to Common Lisp restarts </a></li>
</ul>

<p>and some nice things Common Lisp doesn’t have like first-class
continuations. But then again I would use those rarely.</p>

<h3 id="when-would-i-pick-one-over-the-other">When would I pick one over the other?</h3>

<p>If I were to write an extensible C/C++/Rust program that I <em>know</em> will need to use
a low-level language, I might do the low level bits using a low level language
and then write the rest in Guile. Guile makes it very easy to spin up a REPL
socket to do something like <code>myprogram --repl=12345</code> that you can connect to, and
the interop between C and Guile is fantastic, it has to be, as it’s primarily an
extension language.</p>

<p>On the other hand, if were to build a wholly standalone application, the choice is
not as obvious. I could do the whole thing in either language. Common Lisp can
build native executables, although their size will be large (who cares?) since
the binary will include the whole Lisp implementation. Guile cannot compile to
native code so you’ll have to write a script executable, but that doesn’t really
matter.</p>

<p>Scenarios where I would pick Guile:</p>

<ul>
  <li>when I’m making an extensible program that has to have some C/C++ bits but I
want to make it scriptable by users</li>
  <li>when I want to write a native binary but not write too much C/C++ code</li>
  <li>I just want to write Scheme, because Scheme is a bit more elegant</li>
  <li>the project has something to do with the <a href="https://www.gnu.org/software/autoconf/">GNU project</a></li>
</ul>

<p>On the other hand, Common Lisp makes the most sense if I just want to enjoy a
seriously rapid development experience, a large standard library and language,
and I don’t mind having 50MB binaries (again, who cares?) if I were to write
standalone programs. Guile can’t do that, but it’s easy to either write Guile
scripts or a C program that essentially bootstraps a binary to load a Scheme
runtime. This is how <a href="http://lilypond.org/">LilyPond</a> is written, for example.</p>

<p>So the answer to which one is decidedly <strong>both</strong>! Both languages are really fun to
write. At the moment I don’t do Lisp at my day job so it’s all for fun
anyway. If this were for professional purposes, I don’t know. Very often a
strict requirement for professional work is to be able to be productive. In that
regard I think Common Lisp has a significant edge, not only due to its superior
development experience, but its history as a real production language. There are
actual companies doing stuff in Common Lisp. I have not heard of any
professional (in the industrial sense) uses of Guile, notwithstanding that many
projects powered by Guile (Guix, etc.)  are <em>extremely</em> professional in the way
they are written and maintained. But Common Lisp has <em>more</em> libraries and
companies behind it.</p>

<h3 id="what-about-clojure">What about Clojure?</h3>

<p>I’ve actually had the pleasure to use Clojure for personal fun, and a little bit
of professional use. I wrote a couple of libraries (<a href="https://github.com/ane/vigil">vigil</a> and <a href="https://github.com/ane/task">task</a>) and my
experience with has always been positive and its development experience is
excellent. Clojure isn’t a true Lisp, or well, it is part of the <em>Lisp
family</em>. Its ability to interface with the JVM makes it easy to leverage the
thousands of JVM libraries out there.</p>

<p>I’d gladly do it again, though I feel that Common Lisp with CLOS and its module
system makes it somewhat easier to practice <a href="https://en.wikipedia.org/wiki/Programming_in_the_large_and_programming_in_the_small"><em>programming in the large</em></a>. Clojure
explores interesting territories with <a href="https://clojure.org/guides/spec">spec</a>, so it is interesting to see what
direction the language will take in the future.</p>

<h3 id="final-words-emacs-lisp">Final words: Emacs Lisp</h3>

<p>There’s also a parenthetical elephant in the room here: Emacs Lisp! An old
descendant of <a href="https://en.wikipedia.org/wiki/Maclisp">MacLisp</a>, it’s actually quite fun to write, and the fact that Emacs
itself is the interpreter, you have superb introspectability for any Elisp
code. Most of the Lisp I write these days is probably Emacs Lisp. It’s very
close to Common Lisp. <a href="https://www.gnu.org/software/emacs/manual/html_mono/cl.html#Overview">cl-lib</a> adds a sufficient amount of convenience from
Common Lisp to make Elisp writing quite enjoyable. <a href="https://www.gnu.org/software/emacs/manual/html_mono/eieio.html#Top">EIEIO</a> adds a subset of CLOS
that can be used seamlessly with cl-lib. The condition system is missing.</p>

<p>I’ve also done a fair bit of <a href="https://fennel-lang.org/">Fennel</a>, a Lisp that compiles to Lua. I used it to
write a <a href="https://github.com/ane/mudrally">small game</a> and it was fun to write since you could develop the game in a
REPL.</p>

<p>All in all, Lisp in all its variants is the most fun I’ve ever had while
programming a computer. Guile and Common Lisp are definitely the most fun I’ve
had programming in <em>Lisp</em>.</p>

  </div></div>]]>
            </description>
            <link>https://ane.github.io/2020/10/05/between-two-lisps.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25313311</guid>
            <pubDate>Sat, 05 Dec 2020 10:16:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Maybe we shouldn't want a fully decentralized web]]>
            </title>
            <description>
<![CDATA[
Score 171 | Comments 438 (<a href="https://news.ycombinator.com/item?id=25312854">thread link</a>) | @talhah
<br/>
December 5, 2020 | https://withblue.ink/2020/11/12/maybe-we-shouldnt-want-a-fully-decentralized-web.html | <a href="https://web.archive.org/web/*/https://withblue.ink/2020/11/12/maybe-we-shouldnt-want-a-fully-decentralized-web.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>I spent a large part of 2019 working with the distributed and decentralized web, especially IPFS, also known as the “Inter-Planetary File System”. I’ve written a few articles on the topic, on how you can host a web app on IPFS, one of which even ended up on the front page of HackerNews.</p><p>For about a year, I hosted my blog and other apps through an IPFS cluster. I wrote a utility for making pinning files easier on Pinata, a third-party cloud service for IPFS. I made some small contributions to the IPFS core projects. I built some projects with it, including one that I never released–nor fully completed–that used both IPFS and Ethereum. And I even gave a talk about hosting static web apps on IPFS at Node+JS Interactive last December in Montreal.</p><p>That all changed in the Spring of 2020. I called myself out of the distributed web.</p><p>My blog and other apps I built aren’t hosted on IPFS anymore. I don’t participate in those online communities anymore. I’ve stopped writing about the distributed and researching about it. I’ve shelved all my projects that were using those technologies.</p><p>I also updated my blog posts about IPFS adding a note that my blog isn’t hosted that way anymore. More than a few people asked me why, and I always gave the same answer: a mix of technical issues and mostly personal reasons. So, I think it’s time I explain the personal reasons.</p><p>First, I need to explain why I got involved with IPFS in the first place.</p><p>When I first read about IPFS, my mind immediately saw it as an exciting new platform I could build my apps for. The premise of a fully-decentralized platform included unlimited scalability, ultra-high availability and resiliency, no single points of failure, and resistance against attacks like DDoS.</p><p>Coming from a background in which I am always thinking about SLAs, number of nines of uptime, disaster recovery, etc, IPFS sounded like a dream platform that would magically solve all my concerns. And, aside from some performance issues at times, it did. Plus, the small engineer inside me was really excited about being able to play with a new, shiny toy, that had lots of hype around it!</p><p>What happened next for me was a reckoning with the reality of what many people behind the IPFS core project and the community around it saw: the dream of a radically open, unfiltered, and by-design un-censorable platform.</p><p>I have recently opened up about my experience, over a decade ago, with building an app with good intentions but that was then misused (<a href="https://withblue.ink/2020/09/24/that-time-i-accidentally-built-a-spying-app.html"><em>That time I accidentally built a spying app</em></a>). I learned early on in my life and (pre-)professional career about the importance of ethics in software development, and I am now a proponent of the idea that just because something <em>can</em> be built, it doesn’t mean it <em>should</em> be built.</p><p>And that brings me back to why, after spending some time in the world of the decentralized web, I have called myself out, and why I think that should things like IPFS actually become mainstream, they might cause more harm than good in the world.</p><p><strong>I have seen, and I am seeing every day, the dangers of completely unrestricted speech, and I don’t want to be the one enabling that.</strong></p><p>I know that last sentence is a strong ideological statement; some might call it a <em>political</em> statement, but for me it’s more than just political, which is often used to describe extemporary beliefs.</p><p>Many of you reading this will not agree with me, and that’s fine. I’m not going to try and change your beliefs with this blog post. Rather, I’m looking to explain why, while I respect that others might have differing opinions, I stopped doing anything that would actively advance a technology whose ethics I question. To put it in other terms: your freedom of speech isn’t my obligation to enable you and give you a platform.</p><p>In short, I think that while the Internet has helped the world in countless of ways, it has also brought out the worst in people.</p><p>I do believe we need some filters on the Internet. It’s not just about stopping criminal activities, terrorism and child pornography: while I am obviously unsupportive of all them, I also think they’re not the biggest dangers coming from the Internet (yet they’re a very convenient pretext for politicians).</p><p>Instead, I think that regular people’s writings on the Internet is hurting the world on a bigger scale. And the collective sentiment is often manipulated by some “agitators” that are exploiting anonymous online speech for their own agendas: that includes online militias–for example sponsored by foreign governments–whose goal is to destabilize a society.</p><p>In the last few years, completely unregulated online speech has given rise to fake news and conspiracy theories that have actually killed people. It’s offered a megaphone to those promoting dangerous ideas like white supremacy, Islamophobia, anti-Semitism, homophobia and other anti-LGBTQ positions, and sometimes outright Nazism. It has tilted many democracies towards right-wing populism and fascism.</p><p>All these extreme ideas have divided societies and increased social tensions. And they’re responsible for a number of acts of terrorism which caused the death of too many people.</p><p>Given our experiences so far, there’s no sign that indicates that a fully decentralized and unrestrained web would be anything but a dangerous wild west.</p><p>In fact, despite being tightly centralized and controlled, social media companies are facing significant challenges regulating what people write on their platforms, and in fact they are usually at the center of every scandal of these years. Decentralization and less control won’t be the solution to this issue, but rather the opposite.</p><p>If you believe that I’m overthinking this, and that it’s not going to be bad <em>this time</em>, I urge you to think twice.</p><p>First, there’s no indication that a new Web would be better than the previous one just on virtue of being decentralized. The same actors that are using today’s Internet to wreak havoc around the world would not disappear in the new Internet, and actually, they could be even more unrestrained.</p><p>Second, while almost everyone in the communities supporting a distributed web are good people, with good intentions, seeing some names in there is concerning to me. Regarding IPFS, advocates (at least for a while) included people like Nick Lim of BitMitigate and VanwaNet, companies responsible for rescuing, among others, <a href="https://www.geekwire.com/2017/seattles-bitmitigate-now-protecting-pro-nazi-site-daily-stormer-web-attacks/">pro-nazi website</a> The Daily Stormer <a href="https://arstechnica.com/information-technology/2019/11/breaking-the-law-how-8chan-or-8kun-got-briefly-back-online/">and the platform</a> 8chan, a cesspool full of Nazi propaganda, child pornography, and other hate speech. Gatherings on 8chan have been <a href="https://en.wikipedia.org/wiki/8chan#2019_shootings">blamed</a> for at least three mass shootings in 2019 alone, including the one in the <a href="https://time.com/5648479/8chan-ban-new-zealand/">mosque in Christchurch</a>, all of them motivated by racial hatred.</p><p>The first real examples of the distributed web aren’t particularly encouraging either. Among some of the most popular apps (“popular” in relative terms, of course) for the distributed web is DTube, a sort of YouTube that is built on top of IPFS. As you can expect, the website is full of questionable content, including conspiracy theories, cryptocurrency scams, weapons, RT&nbsp;International’s <a href="https://www.theguardian.com/commentisfree/2019/jul/26/russia-disinformation-rt-nuanced-online-ofcom-fine">Russian propaganda</a>… and of course, porn.</p><p>In essence, if it’s true that <em>a good beginning makes a good ending</em>… with such a mixed beginning, the outlook isn’t too rosy.</p><p>I understand that my opinion is somehow a minority one, and people will continue to build IPFS and other technologies part of the distributed web. There’s also a chance they might become successful and potentially get mainstream adoption–although at this stage the barrier to entry is too high for the average user.</p><p>However, I feel that it’s my responsibility to not be helping to advance this technology and the beliefs of at least some advocates in the world of the distributed web hold. If the advancement occurs, it won’t be because of my help.</p><hr><p><em>PS: The idea that freedom of speech is an absolute right that should have (almost) no limitations is not a universal one. While that right is granted to people living in all democratic countries, outside of North America it’s accepted that such right comes <a href="https://www.nytimes.com/2019/08/06/world/europe/el-paso-shooting-freedom-of-speech.html">with limitations</a>, and usually that has roots in the history of those places.</em></p><p><em>For example, in Italy where I grew up, the same constitution that grants freedom of expression (speech, press, etc) also criminalizes “apology of fascism”, or propagating the ideas of fascism; it also sets other limits on speech that is hateful or discriminatory. Other European countries have similar laws, such as the outlawing of Nazi rhetoric and symbology in Germany.</em></p></article></div>]]>
            </description>
            <link>https://withblue.ink/2020/11/12/maybe-we-shouldnt-want-a-fully-decentralized-web.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25312854</guid>
            <pubDate>Sat, 05 Dec 2020 08:31:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Modern Tire-pressure monitoring system Sensors: Let's try a DoS attack]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25312714">thread link</a>) | @pabs3
<br/>
December 4, 2020 | http://www.mirider.com/weblog/2020/12/04#20201204_Modern_TPMS_Sensors_Lets_try_a_DoS_attack | <a href="https://web.archive.org/web/*/http://www.mirider.com/weblog/2020/12/04#20201204_Modern_TPMS_Sensors_Lets_try_a_DoS_attack">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <td>&nbsp; &nbsp;</td>

  <!-- left column -->
  <td>

<!--
   <p>
   <br />
   <b>About</b> <br />
   Dieter Spaar's blog, Dieter Spaar's personal Blosxom blog.<br /><br />
   Dieter Spaar<br />
   <a href="mailto:spaar@mirider.com">spaar@mirider.com</a> <br />
   </p>
-->

   <p>
   <a href="http://www.mirider.com/weblog/index.rss">RSS</a>
   </p>

   <p>
     <b>Dieter's Web</b> <br>
     <a href="http://www.mirider.com/">mirider.com</a><br>
   </p>

   <p>
   <b>Projects I am participating</b> <br>
    <a href="http://bb.osmocom.org/" target="_blank">OsmocomBB</a><br>
    <a href="http://openbsc.osmocom.org/" target="_blank">OpenBSC</a><br>
    
   </p>

   <p>
   <b>Categories</b> <br>
   </p>
   <ul>
<li><a href="http://www.mirider.com/weblog/index.html">Root</a> (24)
<ul>
<li><a href="http://www.mirider.com/weblog/automotive/index.html">automotive</a> (3)
</li>
<li><a href="http://www.mirider.com/weblog/gsm/index.html">gsm</a> (17)
</li>
<li><a href="http://www.mirider.com/weblog/misc/index.html">misc</a> (1)
</li>
<li><a href="http://www.mirider.com/weblog/sdr/index.html">sdr</a> (2)
</li>
</ul>
</li>
</ul>


   <p>
   <b>Archives</b> <br>
   </p>
   <ul>
	<li><a href="http://www.mirider.com/weblog/2020/">2020</a> (1)
		<ul>
			<li><a href="http://www.mirider.com/weblog/2020/12/index.html">December</a> (1)</li>
		</ul>
	</li>
	<li><a href="http://www.mirider.com/weblog/2018/">2018</a> (5)
		<ul>
			<li><a href="http://www.mirider.com/weblog/2018/09/index.html">September</a> (1)</li>
			<li><a href="http://www.mirider.com/weblog/2018/05/index.html">May</a> (1)</li>
			<li><a href="http://www.mirider.com/weblog/2018/03/index.html">March</a> (1)</li>
			<li><a href="http://www.mirider.com/weblog/2018/01/index.html">January</a> (2)</li>
		</ul>
	</li>
	<li><a href="http://www.mirider.com/weblog/2013/">2013</a> (3)
	</li>
	<li><a href="http://www.mirider.com/weblog/2012/">2012</a> (4)
	</li>
	<li><a href="http://www.mirider.com/weblog/2011/">2011</a> (3)
	</li>
	<li><a href="http://www.mirider.com/weblog/2010/">2010</a> (8)
	</li>
</ul>


<!--
   <p>
   <b>Flavours</b> <br />
   There's more than one way to view this weblog; try these flavours on
   for size.
    <li><a href="http://www.mirider.com/weblog/index.index">index</a></li>
    <li><a href="http://www.mirider.com/weblog/index.1993">circa 1993</a></li>
    <li><a href="http://www.mirider.com/weblog/index.rss">RSS</a></li>
   </p>
-->
   <p>
   <b>Other Bloggers</b> <br>
    <a href="http://laforge.gnumonks.org/weblog/" target="_blank">Harald Welte</a><br>
    <a href="http://openbts.blogspot.com/" target="_blank">David Burgess</a><br>
   </p>

<!--
   <p>
   
   </p>
-->

   <p>
    <br>
    <a href="http://www.blosxom.com/"><img src="http://mirider.com/weblog/pb_blosxom.gif" alt="blosxom"></a>
   </p>

   <p>
    <br>
    <a href="http://www.mirider.com/#Site%20Contact">Contact/Impressum</a>
   </p>

  </td>

  <td>&nbsp; &nbsp;</td>

  <td>&nbsp; &nbsp;</td> 

  <!-- main blog entry column -->
  <td> 

   <br>

<span>Fri, 04 Dec 2020</span>
<div>
<p><a name="20201204_Modern_TPMS_Sensors_Lets_try_a_DoS_attack"><b>Modern TPMS Sensors: Let's try a DoS attack</b></a></p><p>
TPMS (Tire-pressure monitoring system) sensors have been researched extensively
many years ago, they periodically transmit the tire pressure, temperature
and a unique ID which can be misused for tracking a vehicle. But there is
another aspect: modern TMPS sensors also have a receiver which is typically
used to trigger the data transmission when a new TPMS sensor is presented to
the vehicle ("learning procedure").
</p>

<p>
Here in Europe TPMS sensors usually transmit on the 433 MHz ISM band. The
receiver operates on 125 kHz, very similar to LF RFID. A simple way to make
use of the receiver is just to look for the presence of the 125 kHz carrier
and then trigger data transmission. Current sensors are usually more evolved
and use a modulated carrier which contains command packets and only if the
correct command is received data transmission is triggered.
</p>

<p>
If you already have a receiver you can do of course more than just trigger
data transmission: For example there might be support for different
commands, some sensors even allow firmware updates this way.
</p>

<p>
One such command which is typically supported is switching the sensor into
"Shipping" mode. Why would you need that? When the sensor is operating
normally it waits for motion (there is an acceleration/shock sensor inside)
and only starts periodic data transmission when the wheel is rotating. This
is used to safe battery life. When the TPMS sensor is not yet mounted in the
tire it should not react on motion, that’s why there is this "Shipping" mode.
In this mode the sensor only wakes up every few seconds and looks if there
is a 125 kHz signal, if yes it checks for a valid command, for example the
command to trigger data transmission which usually also leaves "Shipping"
mode and switches the sensor into normal operation.
</p>

<p>
This "Shipping" mode can be misused: If you can switch a TPMS sensor of a
vehicle’s wheel into "Shipping" mode the sensor will no longer transmit data
and the vehicle's tire pressure control light will go on after a while.
Just to make it clear: This warning light is annoying to the driver, it
does not affect safety of the car because the deactivated TMPS sensor has
not affected the actual tire pressure.
</p>

<p>
I have looked at a few TPMS sensors for different cars if this really works,
I choose sensors for BMW and Ford cars. Please note that most certainly
other car manufactures are affected too, mainly because there are only a
few manufactures of TPMS sensors which deliver their sensors to various
car manufactures. My choice for BMW and Ford came from the fact that I
found lots of cheap, used sensor for those cars.
</p>

<p>
Also I only looked at "OEM" sensors for BMW and Ford, which means that those
sensors are mounted by the car manufacturer. There are also so called
"Universal" sensors which are typically mounted by tire dealers, there
are some notes about them at the end of this text.
</p>

<p>
It is quite easy to build a tool for transmitting data on 125 kHz: There
is this cheap EL-50448 TMPS sensor activation tool which only transmits a
carrier without modulation. However the hardware can easily be modified
to modulate the carrier: Most of the time OOK (On-Off Keying) is used
for communication, which means that the carrier is just turned on and off.
The EL-50448 uses a power driver with an unused "enable" pin to generate
the carrier, you can use this "enable" pin to modulate the carrier. The
data rate is slow, a frequently used rate is 3900 baud.  Most of the time
Manchester encoding of the data bits is used, which means that the carrier
changes twice as much (7800 changes per second). This is nothing special
and can be done with probably any microcontroller you prefer to use. The
hardware costs for such a setup are below EUR 20, the transmission range
is about 20 centimeters.
</p>

<p>
How can you find the command to switch to Shipping" mode? Brute force by
trying all possible commands is only an option if the command is short.
The reason is that the sensor only looks for the LF 125 kHz signal every
few seconds. If the command is not longer than two bytes brute force is
possible (it takes a few days), for longer commands it is impractical.
Please note that you also have to find a way to detect if the command you
send causes a reaction of the TPMS sensor, e.g. by monitoring the power
consumption of the sensor or receiving the 433 MHz data signal (which of
course only works if the command you send causes a data transmission).
</p>

<p>
Another option is looking at those TPMS tools which tire dealers and
car repair workshops use to check TPMS sensors. Some of those tools
might support switching a TPMS sensor into "Shipping" mode.
</p>

<p>
Those are the results I found (I won't go into the details to avoid misuse):
</p>

<ul>
<li><b>BMW:</b>

  A certain sensor used in several car models from TPMS Sensor manufacturer
  "A" can be switched into "Shipping" mode. The deactivated TPMS sensor can
  be activated again with a different command. Also if the sensor detects a
  fast pressure change (e.g. by inflating the tire) the sensor leaves
  "Shipping" mode. The command length is four bytes so brute force is no option. 

</li>

<li><b>Ford:</b>

  A certain sensor used in several car models from TPMS Sensor manufacturer
  "A" (the same manufacture as above for the BMW sensor) can be switched
  into "Shipping" mode, it is the same command as used by the BMW sensor
  from above. The deactivated TPMS sensor can be activated again with a
  different command.
  
  A certain sensor used in several car models from TPMS Sensor manufacturer
  "B" can be switched into "Shipping" mode. The deactivated TPMS sensor can
  be activated again with a different command. The command in this case is
  only two bytes and I tried all combinations which resulted in several more
  "interesting" commands, a few examples:


    <ul>
<li>
      It is possible to completely turn off the TPMS sensor. In this case it
      will no longer react on anything, you have to break open the sensor
      case and apply a hardware reset or disconnect the battery to reactivate
      it again.
</li>

<li>
      It is possible to switch the sensor into continuous "carrier transmit"
      mode on 433 MHz. In this mode the sensor will continuously transmit
      the 433 MHz carrier until the battery is empty or you apply a hardware
      reset (see above), it will not react on anything else. There are two
      other similar commands which transmit on the upper and lower shifted
      frequency (the sensor uses FSK modulation, Frequency Shift Keying, when
      transmitting data).
</li>
</ul>      

  Those examples show that it is basically possible to destroy this specific
  sensor by transmitting the appropriate command. Also if the sensor is in
  "carrier transmit" mode it probably disturbs the remote control car
  key fob which usually uses the same frequency as the TPMS sensor.
</li>
</ul>

<p>
You have to be close to the sensor to send those LF 125 kHz signals but it
only takes a few seconds to send the signal. Using a larger antenna (which is
basically a coil) for the transmitter, e.g. large enough to fit in a suitcase,
might extend the transmission range to more than a meter. 
</p>

<p>
How can those problems be avoided? This is actually quite easy, the command
to switch into "Shipping" mode should not be allowed if the measured tire
pressure is above a certain limit, which means that the sensor is mounted in
the tire of a vehicle. This also applies to those other commands of the sensor
from manufacturer "B" which are probably some kind of factory test or developer
commands. Please note that during my tests the commands I described were
possible even when the measured tire pressure was in the range of a typical
vehicle wheel.
</p>

<p>
I contacted the car manufactures (BMW and Ford) before I published this
article, this is the experience I made:
</p>

<ul>
<li>
  <b>BMW:</b>
  The contact information for reporting security issues can be found on
  the BMW website. I had a phone call with the responsible person within
  a few days after reporting the issue. BMW already knew the problem, they
  found it during an internal review. Their latest TPMS sensors have fixed
  the issue by blocking certain commands if the tire pressure is above a
  certain limit.
</li>

<li>
  <b>Ford:</b>
  I wasn't able to find a security contact on the website of Ford Germany
  so I contacted the person responsible for "Public Relation". He promised
  to look for someone who takes care of the issue I reported, after several
  days I got a reply that it is possible to disturb the TPMS system due to
  the nature of radio transmission and that this is a known problem. I wasn't
  able to communicate directly with the responsible person and I then replied
  that the reported issue is not about disturbance but a "Denial of Service"
  and that it is even possible to destroy a certain TPMS sensor used in Ford
  cars. I didn't receive any further information about the security issue, I
  notified them again after several weeks that I am now going to publish
  the issue which was acknowledged.
</li>
</ul>

<p>
Some notes about those "Universal" sensors tire dealers normally use: Those
sensors are "Universal" because they can be programmed for different car
models. The main benefit for the tire dealer is that only a few different
kind of "Universal" sensors have to be on stock, it’s not necessary to have
lots of different "OEM" TPMS sensors for every possible car model lying
around. The programming of those …</p></div></td></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.mirider.com/weblog/2020/12/04#20201204_Modern_TPMS_Sensors_Lets_try_a_DoS_attack">http://www.mirider.com/weblog/2020/12/04#20201204_Modern_TPMS_Sensors_Lets_try_a_DoS_attack</a></em></p>]]>
            </description>
            <link>http://www.mirider.com/weblog/2020/12/04#20201204_Modern_TPMS_Sensors_Lets_try_a_DoS_attack</link>
            <guid isPermaLink="false">hacker-news-small-sites-25312714</guid>
            <pubDate>Sat, 05 Dec 2020 07:53:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reading Manpages Like a Pro (2018)]]>
            </title>
            <description>
<![CDATA[
Score 56 | Comments 32 (<a href="https://news.ycombinator.com/item?id=25311867">thread link</a>) | @woodruffw
<br/>
December 4, 2020 | https://blog.yossarian.net/2018/01/22/Reading-Manpages-Like-a-Pro | <a href="https://web.archive.org/web/*/https://blog.yossarian.net/2018/01/22/Reading-Manpages-Like-a-Pro">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<h2><em>Programming, philosophy, pedaling.</em></h2>

<ul>
    <li><a href="https://blog.yossarian.net/">Home</a></li>
    <li><a href="https://blog.yossarian.net/tags">Tags</a></li>
    <li><a href="https://blog.yossarian.net/favorites">Favorites</a></li>
    <li><a href="https://blog.yossarian.net/archive">Archive</a></li>
    
      <li><a href="https://yossarian.net/">Main Site</a></li>
    
</ul>

<hr>



<h2>
  <em>Jan 22, 2018</em>
</h2>

  <p>Tags:
  
    
    <a href="https://blog.yossarian.net/tags#programming">programming</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#workflow">workflow</a>
    
  
  </p>


<h3 id="preword">Preword</h3>

<p>I often reference the <a href="https://en.wikipedia.org/wiki/Man_page">manpages</a> when giving a development
presentation or talk, but I’ve only recently come to realize how few people are both <em>comfortable</em>
with the <code>man</code> interface and adept at discovering information through it.</p>

<p>This post is my attempt to share some of the tricks and techniques I’ve picked up over years of
reading manpages.</p>

<h2 id="a-quick-recap">A Quick Recap</h2>

<p>The manpages (short for “manual pages”) are the oldest and longest-running documentation collection
on *nix, stemming back to the
<a href="https://www.bell-labs.com/usr/dmr/www/1stEdman.html">first edition of the Unix Programmer’s Manual</a>
in 1971.</p>

<p>On a modern system, the <code>man</code> command is the most common way to access the manpages:</p>

<div><div><pre><code><span># access the first manpage named "time", which happens to be time(1)</span>
man <span>time</span>

<span># access a specific section's "time", in this case the C time function</span>
man 2 <span>time</span>

<span># attempt to access a nonexistent "time" in section 5</span>
man 5 <span>time</span>
</code></pre></div></div>

<p>Because the manpages were originally published on paper, they were (and continue to be) typeset with
<a href="https://en.wikipedia.org/wiki/Troff"><code>troff</code></a> on most systems. Today, the <code>man</code> command (and other
manpage readers) invoke <code>troff</code> internally and pipe the output to the user’s
<a href="https://en.wikipedia.org/wiki/Terminal_pager">pager</a> (like <code>more</code> or <code>less</code>).</p>

<p>In fact, a very simple manpage reader (which only works with section 1) can be implemented with
just three commands pipelined together:</p>

<div><div><pre><code><span>function </span>myman <span>{</span>
    <span># `-t` and `-e`: run `tbl` and `eqn` on the input, for tables and equations</span>
    <span># `-mandoc`: use a set of troff macros specifically for manpages</span>
    <span># `-Tutf8`: output UTF-8 text rather than PostScript</span>
    <span>gunzip</span> &lt; /usr/share/man/man1/<span>"</span><span>${</span><span>1</span><span>}</span><span>.1.gz"</span> | groff <span>-t</span> <span>-e</span> <span>-mandoc</span> <span>-Tutf8</span> | less
<span>}</span>

myman gcc
myman <span>ls</span>
</code></pre></div></div>

<p>Apart from their simplicity and adherence to the UNIX philosophy, <code>man</code> and the manpages serve a
number of important roles:</p>

<ul>
  <li>
    <p>They provide a categorization: section 1 is for system commands, 2 for system calls, 3 for library
functions, and so forth. This categorization is followed both by the system itself (which populates
several of the sections) and by programs installed by the user or package manager.</p>
  </li>
  <li>
    <p>They provide offline documentation: <code>man</code> doesn’t require an internet connection, and can provide
much of the documentation that an internet search would yield.</p>
  </li>
  <li>
    <p>They offer <em>canonical</em> information: searching for a command or function online might tell you
whether it exists, but won’t tell you the flags, arguments, or behavior specific to your system.
For example, <code>man ls</code> will tell you whether your system’s <code>ls</code> is BSD or GNU (and the differences
therebetween). The manpages (on Linux) will also tell you which feature macros you’ll need to define
in a C program in order to use a function (or a variant of a function).</p>
  </li>
</ul>

<p>So, let’s move on to some techniques.</p>

<h2 id="colorized-manpages">Colorized manpages</h2>

<p>One of the simplest things you can do to enhance the readability of manpages within <code>man</code> is to
colorize the pager’s output:</p>

<p><img src="https://blog.yossarian.net/assets/gcc_man.png" alt="A colorized version of `man gcc`"></p>

<p>In <code>less</code>, this is accomplished by setting the <code>LESS_TERMCAP_*</code> environment variables to your
preferred ANSI color codes. Here are the variables you can set:</p>

<div><div><pre><code>LESS_TERMCAP_mb <span># blinking mode (not common in manpages)</span>
LESS_TERMCAP_md <span># double-bright mode (used for boldface)</span>
LESS_TERMCAP_me <span># exit/reset all modes</span>
LESS_TERMCAP_so <span># enter standout mode (used by the less statusbar and search results)</span>
LESS_TERMCAP_se <span># exit standout mode</span>
LESS_TERMCAP_us <span># enter underline mode (used for underlined text)</span>
LESS_TERMCAP_ue <span># exit underline mode</span>
</code></pre></div></div>

<p>You may be able to set others corresponding to the
<a href="https://www.gnu.org/software/termutils/manual/termcap-1.3/html_chapter/termcap_5.html">termcap capability names</a>,
but the variables above should cover all of your manpage needs.</p>

<p>By way of example, here is the <code>bash</code> function I use to colorize my manpages:</p>

<div><div><pre><code>man<span>()</span> <span>{</span>
    <span>env</span> <span>\</span>
    <span>LESS_TERMCAP_mb</span><span>=</span><span>"</span><span>$(</span><span>printf</span> <span>"</span><span>\e</span><span>[1;31m"</span><span>)</span><span>"</span> <span>\</span>
    <span>LESS_TERMCAP_md</span><span>=</span><span>"</span><span>$(</span><span>printf</span> <span>"</span><span>\e</span><span>[1;31m"</span><span>)</span><span>"</span> <span>\</span>
    <span>LESS_TERMCAP_me</span><span>=</span><span>"</span><span>$(</span><span>printf</span> <span>"</span><span>\e</span><span>[0m"</span><span>)</span><span>"</span> <span>\</span>
    <span>LESS_TERMCAP_se</span><span>=</span><span>"</span><span>$(</span><span>printf</span> <span>"</span><span>\e</span><span>[0m"</span><span>)</span><span>"</span> <span>\</span>
    <span>LESS_TERMCAP_so</span><span>=</span><span>"</span><span>$(</span><span>printf</span> <span>"</span><span>\e</span><span>[1;44;33m"</span><span>)</span><span>"</span> <span>\</span>
    <span>LESS_TERMCAP_ue</span><span>=</span><span>"</span><span>$(</span><span>printf</span> <span>"</span><span>\e</span><span>[0m"</span><span>)</span><span>"</span> <span>\</span>
    <span>LESS_TERMCAP_us</span><span>=</span><span>"</span><span>$(</span><span>printf</span> <span>"</span><span>\e</span><span>[1;32m"</span><span>)</span><span>"</span> <span>\</span>
    man <span>"</span><span>${</span><span>@</span><span>}</span><span>"</span>
<span>}</span>
</code></pre></div></div>

<p>Note that you don’t need to use escape sequences as above — <code>tput</code> will work just fine.</p>

<h2 id="other-sections">Other sections</h2>

<p>I mentioned some of the big sections above: 1 for system commands, 2 for system calls, and so on.</p>

<p>90% of <code>man</code> lookups will be in those three, but there are a few lesser-known sections that can also
be useful:</p>

<ul>
  <li>
    <p><code>man 4</code> - Special files and devices</p>

    <p>On Linux, section 4 is used to document special files, usually representing some aspect of
  the machine or its peripherals. For example, <code>man 4 mem</code> will tell you how to use the
  <code>/dev/mem</code>, <code>/dev/kmem</code>, and <code>/dev/port</code> files to read from and write to the system’s main
  memory.</p>
  </li>
  <li>
    <p><code>man 5</code> - Configuration files and formats</p>

    <p>You probably know the <code>/etc/shadow</code> file, but do you know how its format is specified?
  <code>man 5 shadow</code> will tell you that. Similarly, <code>man 5 deb</code> describes the <code>.deb</code> package format,
  and <code>man 5 ppm</code> lists the spec for <a href="https://en.wikipedia.org/wiki/Netpbm_format">PPM images</a>.</p>
  </li>
  <li>
    <p><code>man Np</code> - POSIX pages</p>

    <p>These pages come in handy for contrasting POSIX behavior with the system’s behavior.</p>

    <p>Some examples:</p>

    <div><div><pre><code>  <span># compare the system ls (on Linux, GNU) to the POSIX ls behavior</span>
  man 1 <span>ls
  </span>man 1p <span>ls</span>

  <span># compare the read syscall to the POSIX read function</span>
  <span># note the categorization: POSIX read is a function, not a syscall!</span>
  man 2 <span>read
  </span>man 3p <span>read</span>
</code></pre></div>    </div>
  </li>
</ul>

<h2 id="searching-and-navigating">Searching and navigating</h2>

<p>Like colorization, searching is more of a general <code>less</code> feature than one specific to <code>man</code>. That
being said, <code>less</code>’s searching and navigating features can make browsing the manpages a much faster
and more pleasant experience.</p>

<p>Searches in <code>less</code> can be forwards or backwards, using the <code>/</code> and <code>?</code> commands respectively. The
search syntax is mostly POSIX ERE, but with some additions (<code>man less</code> has the details!).</p>

<p>For example, to find the first instance of “x86” in <code>man gcc</code> (watch the bottom of the screen for
the search prompt):</p>

<p><a href="https://asciinema.org/a/Wc0OiKVTrTDiP4tG9bPRWtDwM" target="_blank" rel="noopener noreferrer">
  <img src="https://blog.yossarian.net/assets/asc_Wc0OiKVTrTDiP4tG9bPRWtDwM.png">
</a></p>

<p>Observe that instances of the search term are highlighted with the standout colors from before.</p>

<p>Once a search term is entered, its results can be navigated via the <code>n</code> and <code>N</code> commands, which
move forwards and backwards in the results list respectively. For example, going through all
of the results for “Windows”:</p>

<p><a href="https://asciinema.org/a/n3S3wteHmbdPrtmyTSkCSVMiX" target="_blank" rel="noopener noreferrer">
  <img src="https://blog.yossarian.net/assets/asc_n3S3wteHmbdPrtmyTSkCSVMiX.png">
</a></p>

<p>When the last result has been jumped to, the statusbar changes to “Pattern not found”. Once that
happens, as in the video above, previous results can be returned to by hitting <code>N</code>.</p>

<p>Even this can be simplified: the <code>&amp;</code> command can be used to display only lines that match the given
pattern. For example, retrieving every line that contains either “ARM” or “ABI”:</p>

<p><a href="https://asciinema.org/a/Wh8QZ4eideLNmCMBmAkYExgEm" target="_blank" rel="noopener noreferrer">
  <img src="https://blog.yossarian.net/assets/asc_Wh8QZ4eideLNmCMBmAkYExgEm.png">
</a></p>

<p>The effect is more dramatic when searching for the definition of a flag (in this case <code>-D</code>):</p>

<p><a href="https://asciinema.org/a/17Kcnb8PBNIz8JdogOFKVeDQn" target="_blank" rel="noopener noreferrer">
  <img src="https://blog.yossarian.net/assets/asc_17Kcnb8PBNIz8JdogOFKVeDQn.png">
</a></p>

<p>These commands are just the tip of the iceberg — <code>less</code> supports searching multiple files at
once, jumping around scopes (opening and closing parentheses, braces, brackets), and marking the
current location for later return. Each of these is documented on the help screen, which you can
get to in any <code>less</code> session via the <code>h</code> command:</p>

<p><a href="https://asciinema.org/a/8i6kyFTbFttVTgDNbgnzyJvGB" target="_blank" rel="noopener noreferrer">
  <img src="https://blog.yossarian.net/assets/asc_8i6kyFTbFttVTgDNbgnzyJvGB.png">
</a></p>

<h2 id="wrapup">Wrapup</h2>

<p>Before picking up these tricks (especially searching), the manpages were an item of last resort
for me: I would search the internet or ask a friend, with mixed results. I had no real idea how to
use <code>less</code>, and would just clumsily page around until I found what I was looking for. More often
than not, I would give up entirely.</p>

<p>At the end of the day, the manpages (and the <code>man</code> interface) are not perfect — there’s no
hyperlinking or real cross-referencing, and the entire corpus is written in a 45+ year old
typesetting language designed for <em>physical</em> output, not display in a virtual terminal.</p>

<p>That being said, they’re a <em>fantastic</em> initial resource for pretty much anything concerning your
system — they remain up-to-date (unlike blogs and articles), they’re accurate and concise, and
they’re <em>very</em> UNIX-y (text files and pipelines!).</p>

<hr>

<h3 id="addendum">Addendum</h3>

<p>This post was discussed on <a href="https://news.ycombinator.com/item?id=25311867">HN</a>; a response
by <a href="https://news.ycombinator.com/item?id=25313405">‘djeiasbsbo</a> includes some additionally
useful tricks and advice.</p>


<hr>




  


  





</div>]]>
            </description>
            <link>https://blog.yossarian.net/2018/01/22/Reading-Manpages-Like-a-Pro</link>
            <guid isPermaLink="false">hacker-news-small-sites-25311867</guid>
            <pubDate>Sat, 05 Dec 2020 04:53:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No One Ever Got Fired for Choosing React]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 90 (<a href="https://news.ycombinator.com/item?id=25310462">thread link</a>) | @petercooper
<br/>
December 4, 2020 | https://jake.nyc/words/no-one-ever-got-fired-for-choosing-react/ | <a href="https://web.archive.org/web/*/https://jake.nyc/words/no-one-ever-got-fired-for-choosing-react/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>If you spend a lot of time on Hacker News, it’s easy to get taken by the allure of building a web app without a framework. There are a bunch of potential advantages (no bloat! bespoke to your project!) and being able to say you built something with minimal dependencies gets you Engineer Points.</p>
<p>That is, if you can pull it off.</p>
<p>I started a new side project recently. It’s a web-based graphics editor, so it needs to be a single page app. My time spent profiling <a href="https://songrender.com/">SongRender</a> for performance issues has made me a little wary of React for building interfaces that update at 60 frames per second, so I decided to avoid it. I’d go (mostly) vanilla and see how far that took me.</p>
<p>I installed <a href="https://lit-html.polymer-project.org/">lit-html</a> and got to work. “Components” were simply functions that returned lit-html template results. A big singleton at the top of the tree held onto all the application state, stored as a global variable within that module.</p>
<p>The first hurdle came when a component needed local state. I could have lifted it to the singleton, but that would have broken the component’s encapsulation. I noticed that lit-html directives can keep state, so I decided to use them to build a tiny component library — ignoring a warning from the lit-html developers that this wasn’t a supported use case.</p>
<p>My home-brewed library worked great… until I needed to run some code when a component appeared on the screen. I started digging through lit-html documentation and issues looking for a way to detect a directive’s lifecycle, but it became clear to me that going down that path would be painful.</p>
<p>At that point, I recalled <a href="https://tomdale.net/2015/11/javascript-frameworks-and-mobile-performance/">this quote by Tom Dale</a>:</p>
<blockquote>
<p>I have heard from many developers who have told me that they accepted the argument that vanilla JavaScript or microlibraries would let them write leaner, meaner, faster apps. After a year or two, however, what they found themselves with was a slower, bigger, less documented and unmaintained in-house framework with no community. As apps grow, you tend to need the abstractions that a framework offers. Either you or the community write the code.</p>
</blockquote>
<p>Fair enough. Let’s avoid that trap. What about a small framework? I’d heard a lot of good things about Svelte, and although I was slightly worried about the size of the Svelte community I figured it would be fine.</p>
<p>My migration attempt quickly ground to a halt when I wanted a parent component to apply some styles to a child component. In React, I’d pass a class name in from the parent as a <code>className</code> prop. In Svelte, that’s considered a workaround, and the actual feature is the subject of an <a href="https://github.com/sveltejs/rfcs/blob/master/text/0000-style-properties.md">RFC</a>.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p>
<p>Maybe this is an example of <a href="https://prog21.dadgum.com/160.html">dangling by a trivial feature</a>. But it’s so basic a capability that I’m surprised Svelte is on version three without an officially blessed way to do it. I ran into this limitation when I created my <strong>second component</strong>. Way before I got to try out any of the cool reactivity that earns Svelte all that buzz.</p>
<p>So I changed my mind and went with React. After an hour or so, I’d finished moving everything over — and my anxiety had vanished. I stopped worrying about having most efficient component system, and picked up work on the thing I wanted to build in the first place.</p>
<p>No, React isn’t perfect. It’s optimized for apps that make network requests and then display lists of things (i.e. most apps) which isn’t really what I’m doing here<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>. The performance is fine now, although I expect I’ll have to optimize as my project gets more complex.</p>
<p>But React lets me stop thinking about the framework. React gets out of my way. React is <a href="https://mcfunley.com/choose-boring-technology">boring</a>. React is actively developed. React has a giant ecosystem and a giant community. React is battle-tested on some of the most visited websites in the world.</p>
<p>I’m sure there are technically better ways to build a highly interactive interface on the web, but life is too short for me to spend hours trying to figure them out. There are things I want to create, and the only way I can actually create them is to stop spending so much time on tooling.</p>
<p>For now, I’m choosing React.</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>The solution they seem to have landed on — letting the child expose CSS custom properties as props — is actually pretty cool, though I don’t like that Svelte will silently wrap your component with an extra <code>div</code>. <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>Although Dan, if you read this, the <a href="https://twitter.com/dan_abramov/status/1133341485133438982">“animation pass” mode</a> you’ve mentioned offhandedly sounds very relevant! <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section></div></div>]]>
            </description>
            <link>https://jake.nyc/words/no-one-ever-got-fired-for-choosing-react/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25310462</guid>
            <pubDate>Sat, 05 Dec 2020 00:52:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I accidentally built a spying app]]>
            </title>
            <description>
<![CDATA[
Score 174 | Comments 59 (<a href="https://news.ycombinator.com/item?id=25310316">thread link</a>) | @akeck
<br/>
December 4, 2020 | https://withblue.ink/2020/09/24/that-time-i-accidentally-built-a-spying-app.html | <a href="https://web.archive.org/web/*/https://withblue.ink/2020/09/24/that-time-i-accidentally-built-a-spying-app.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>In the fall of 2007, my parents gave me an unforgettable gift for my sixteenth birthday: a first-generation iPhone.</p><p>I still clearly remember watching the keynote in which Steve Jobs announced the first Apple-branded phone a few months earlier. As a teenager attending high school in my hometown of Vicenza, Italy, I tuned into the livestream just before dinner, carefully listening to every word he said. That evening, Jobs started announcing a “widescreen iPod with touch controls”, a “revolutionary mobile phone” and a “breakthrough Internet communications device”–theatrically pausing before confessing that he was actually talking about one single device: the iPhone. Thousands of miles away from me, you could hear attendees exploding cheerfully through the live feed. Jobs went on demoing this amazing invention that, a decade later, would end up changing much more than the mobile phones market: it directly or indirectly impacted our society through mobile web, app stores, changing work-life balance, and social media.</p><p>October came, and so did the day I finally got my iPhone. I was really excited as I was the first one in my social circle with one. Every other teenager (and adult!) that saw my phone reacted in awe and with lots of curiosity. More than a few were also secretly envious, something I secretly did not mind. To add to the novelty, at the time the iPhone was only available for sale in the US.</p><p>To get an iPhone for me, my father had to ask a friend traveling to New York on a business trip to bring one back on the plane with her. That was not the end of it, however, as all phones were locked to the AT&amp;T network. In order for me to be able to use my iPhone in Italy, I had to unlock it.</p><p>That process required learning a variety of tools and techniques developed by hackers in the community, then documented in various blogs and forums. The first step was to <em>jailbreak</em> the phone, which gave you full access to the system and allowed you to run third-party apps. Then you’d have add one of those “hacking” apps to your phone, which patched the bootloader to remove the lock the US carrier had put on it. Despite sounding like a mouthful, the iPhone hacking community had worked hard on the User Experience (UX), making this entire process relatively easy for most people with basic tech skills.</p><hr><p>I really loved my shiny, new iPhone, and I was so excited about it that I was willing to accept many of its original limitations. It only supported slow 2G networks, didn’t have copy/paste, couldn’t transfer files via Bluetooth to my friends, and <a href="https://www.apple.com/hotnews/thoughts-on-flash/">famously</a> didn’t support Adobe Flash, which was ubiquitous on the web at the time.</p><p>However, there was one thing I really couldn’t stand: the Messages application could only store 1,000 texts (SMS).</p><p>That was 2007 — before the days of WhatsApp, Facebook Messenger, Telegram, etc. Instant messaging was something people did on their PCs only, with things like Windows Live Messenger (née MSN Messenger) or AIM.</p><p>For a high schooler like me, text messaging was the main way I kept in touch with my friends daily (<em>what was I supposed to do, call them?</em>). With my carrier giving me a whopping 100 free texts per day (seriously, we had to pay for them), between sent and received texts it would take less than a week to reach the storage limit of 1,000.</p><p>That’s when it all started.</p><p>Because my iPhone was already “hacked” (jailbroken), as a requirement for unlocking it and use it in Italy, I had full system access already. That allowed me to c extract any document I wanted, including my phone’s text message database.</p><p>It wasn’t even a month since I got my iPhone that I had already built a small “app” running on my laptop to archive my text messages forever. I would manually extract the SMS database from my iPhone, copy it to my laptop, then use a set of scripts written in PHP (the only programming language I knew at the time) to store the messages in a local database, and finally display them using a web-based interface.</p><p>This thing I put together worked just fine for me, but I immediately realized the “business potential” of what I had just created. Just like myself, I assumed many others had the same annoyance. I could have used what I learned to help them too, and maybe make some pocket change in the process. As a matter of fact, I did consider myself an enterprising teenager.</p><p>The idea had potential, and the “app” I built for myself already provided solid foundations, so I just needed to do a bit more work to turn it into a commercially-viable project.</p><p>The biggest challenge was making the solution more accessible to others, including those who were not particularly tech-savvy. That’s when I started learning about app development for iPhone.</p><p>Famously, Apple did not want the iPhone to support third-party apps at the beginning, saying developers should build web apps instead. That policy didn’t last long, and with the iPhone OS 2 update, launched in mid-2008, the official App Store came to life: the rest, as they say, is history.</p><p>However, the hacking community had already found a way to sideload apps and had even developed an “app store” called Cydia where you could find games, apps, and even mods to enhance the capabilities of the operating system itself. Cydia came preinstalled on every <em>jailbroken</em> iPhone, which meant potentially hundreds of thousands of people had access to it.</p><p>Everyone could build apps that would be published on Cydia, as long as you knew how to–something that was not remotely as easy to do as it is with today’s tools. As an enterprising teenager with quite a bit of free time on my hand during those winter afternoons and evenings, I took on that challenge.</p><hr><p>The first version of YouArchive.It came out in January 2008.</p><p>Today, you would describe YouArchive.It as a cloud service to store iPhone text messages. You could store all your messages in there, then read and search them using a web-based application.</p><p>There’s still a video left on YouTube showing the application in action (this was the third, and last, version):</p><p><iframe src="https://www.youtube-nocookie.com/embed/ps5ohEhO3S4" allowfullscreen="" title="YouTube Video"></iframe></p><p>With YouArchive.It came an iPhone application too. Published on the Cydia app store, it allowed importing messages into the “cloud service” directly from the phone.</p><p>YouArchive.It was free to use with a limit of 80,000 text messages. Because personal communications can be sensitive, all messages were stored encrypted. With a one-time payment of just €5 (about $6), you could become a VIP, remove any limit and enjoy unlimited storage.</p><p><img src="https://cdn-images-1.medium.com/max/2000/1*vTxYRljXFl3IBXGRsXOVag.png" alt="A screenshot of iTextUploader running on a first-generation iPhone"></p><figcaption>A screenshot of iTextUploader running on a first-generation iPhone</figcaption><p>For the next year and a half, YouArchive.It continued to grow organically. A few blogs and websites dedicated to iPhone “hacking” and to the underground app stores wrote about the app. Even a small radio program in the US featured it</p><p>I continued developing the app as a side project while in high school. I was also providing tech support and maintaining the infrastructure.</p><p>Listening to users' feedback, I would periodically add new features. YouArchive.It started displaying emojis as soon as the iPhone supported that (outside of Japan, it required downloading an app to enable them). Users asked for and got the ability to restore texts in another iPhone, before iCloud was available. I also implemented other privacy features such as requiring a password to open the mobile app.</p><blockquote><h3 id="what-i-didnt-realize-at-the-time-however-is-that-i-had-unknowingly-and-unwillingly-built-a-spying-tool-and-a-really-convenient-and-efficient-one">What I didn’t realize at the time, however, is that I had, unknowingly and unwillingly, built a spying tool, and a really convenient and efficient one.</h3></blockquote><p>Enough users were paying the fee to become VIP that I could cover the costs of running the service–this was before everyone was using Amazon Web Services or Microsoft Azure, so I was renting a co-located physical server which wasn’t cheap–and keep some pocket cash. Not much, but enough to pay for some hobbies and outings with friends.</p><p>Most importantly, building YouArchive.It gave me a lot of satisfaction and the opportunity to learn a lot of things about software development, business, dealing with customers and listening to their feedback.</p><hr><p>When I finally shut the service down, in June 2010, YouArchive.It had about 32,000 registered users who stored over 76 million messages.</p><p>The first, and stated, reason for the deprecation was a technical one: YouArchive.It’s iPhone app required using private APIs, which meant it could not be published on the App Store (and it still couldn’t to this day), limiting it to <em>jailbroken</em> phones only.</p><p>The second reason however was the most important to me, even though I have not revealed it until now.</p><p>About a year before the app closed, in April 2009 I implemented a new feature that was requested by many users: the ability to upload texts automatically, in background, without user intervention. For paying “VIP” users only, the mobile app could automatically send all new text messages to YouArchive.It, as often as every 15 minutes.</p><p>Automatic upload was an incredible convenience for many users that wanted to hoard their texts like me, to keep them forever, search within them, print or export them, or just liked having a backup.</p><p>What I didn’t realize at the time, however, is that I had, unknowingly and unwillingly, built a spying tool, and a really convenient and efficient one.</p><p>Thanks to background uploads, people could install the YouArchive.It app on another person’s iPhone, set it up, maybe even hide it (something possible on a <em>jailbroken</em> iPhone), and then watch as the text messages come in, almost real-time. Jealous partners, stalkers and the likes could install this tool on an unknowing victim’s phone with relative ease.</p><p>I can’t remember how I discovered that — it might have been a support request from a user or a post in a bulletin board. I also can’t know how many people were using YouArchive.It for their own archiving rather than to spy on others. Realizing what my users were doing, however, made me feel really uncomfortable and I did not want any part of that anymore.</p><p>As a senior in high school, barely eighteen years-old, I realized for the first time how technology can have a …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://withblue.ink/2020/09/24/that-time-i-accidentally-built-a-spying-app.html">https://withblue.ink/2020/09/24/that-time-i-accidentally-built-a-spying-app.html</a></em></p>]]>
            </description>
            <link>https://withblue.ink/2020/09/24/that-time-i-accidentally-built-a-spying-app.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25310316</guid>
            <pubDate>Sat, 05 Dec 2020 00:32:22 GMT</pubDate>
        </item>
    </channel>
</rss>
