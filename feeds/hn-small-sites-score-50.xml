<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Mon, 11 Jan 2021 17:21:40 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Mon, 11 Jan 2021 17:21:40 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[The Platform Is the Enemy]]>
            </title>
            <description>
<![CDATA[
Score 92 | Comments 20 (<a href="https://news.ycombinator.com/item?id=25708099">thread link</a>) | @nomdep
<br/>
January 9, 2021 | https://danielbmarkham.com/the-platform-is-the-enemy/ | <a href="https://web.archive.org/web/*/https://danielbmarkham.com/the-platform-is-the-enemy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div id="post-body">
        <p>The premise of the movie "Idiocracy" is simple: in the future mankind has de-evolved into morons. Technology does so much for everybody that nobody knows how it all works anymore. &nbsp;If we can't fix it, we're all going to die.</p><p>One character asks the other what he likes, The answer is money.</p><p>"I can't believe you like money too!" the first character says without irony, "We should hang out!"</p><figure><img src="https://cdn.danielbmarkham.com/2021/01/JRJcXbeoSOlkRRzbC7HJ_idiocracy.jpg" alt=""></figure><p>The gag here is that of course, most everybody likes money. If you reduce all of your life enough, it's just food, sex, money, and looking cool. But who would want to do that? Over the centuries, humans have created massively-complex societies because everybody has different things they like doing and thinking about, but all of that complexity can be reduced to, well, an idiocracy if you try hard enough.</p><p>The movie, however, is just a joke, right? We would never allow that to happen, of course, because that's not the goal of technology. Technology's goal is to make us better, not dumber.</p><p>Wait one. Is that true? What <em>is</em> the goal of technology, anyway? Has anybody ever clearly stated it?</p><p>Recently I've heard two goals:</p><ol><li>The goal of technology is to become a <strong>brain extension</strong>, <em>helping you to decide what to do</em> and then helping you get it done.</li><li>The goal of technology is to become a <strong>hand-held power tool</strong>, helping you accomplish the things you've <em>already decided to do</em></li></ol><p>That's not the same thing. It turns out the difference is critical.</p><p>The old goal was much simpler: make something people want. I like that goal! It boils down the job of creating technology to the most important parts, need and ability. But was that sustainable? At the end of the day, don't we always end up making some combination of stuff that either helps us <em>make decisions</em> or helps us <em>implement decisions</em> we've already made? And aren't the two fundamentally incompatible in a future society?</p><p>Yelp tells you which restaurant to go to. Your GPS automatically takes you there. These are not just different problems, they're different <em>kinds of problems</em>. Getting from point A to point B is a matter of math and geometry. Which restaurant is the best tonight? You could spend hours debating that with friends.</p><p>If you reduce anything down enough it becomes idiotic. Each piece of technology we deploy can have the goal of helping us do what we've already decided or helping us decide what to do. The first option leaves the thinking up to us. The second option "helps" us think.</p><figure><iframe width="267" height="200" src="https://www.youtube.com/embed/sZHCVyllnck?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><p>You like money too? Wow! I like money! We should hang out!</p><p>Human brains are not computers. Brains are designed to help us survive and pass on our genes using the minimum amount of energy available. If the GPS takes me where I'm going, I don't need to know how to use maps anymore. So I stop knowing how to use maps. Dump those neurons, they're not needed. If Yelp picks the restaurants for me enough, I stop having nuanced preferences about restaurants. That energy expenditure is no longer needed for survival and reproduction. Dump those neurons. Over time people stop caring about the tiny details of what the difference is between a good and a great restaurant. Yelp handles that.</p><p>For some folks, who cares? It's food. Go eat it. For other folks, picking the right place can be a serious undertaking, worthy of heavy thought and consideration. But if over the years apps like Yelp boil all of that down to four or five stars, then our collective brain is not going to bother with it. Human brains are not computers. If computers do the work for us, we turn off those neurons and save energy.</p><p>Meanwhile, on social media there's currently this huge discussion. One bunch of folks says that social media is being overbearing in its censorship of fringe and sometimes hateful opinions. The other bunch of folks says social media is a festering sore full of people who are ugly, hateful, and abusive to those weakest among us. The community has to set standards.</p><p>There doesn't have to be a right and wrong here. I think the crucial thing to to understand that both sides can be entirely correct. We are dealing with the same kind of question.</p><p>All three of these topics -- whether humanity is becoming idiots or not, what the ultimate goal of technology is or should be, and how social media should work -- are intricately related. They're related because of this: <em>the platform is the enemy</em>.</p><p>The minute we create a platform for something, whether it's rating movies, tracking projects, or chatting with friends about work, as that platform takes over mindshare, <em>the assumption becomes that this is a solved problem</em>.</p><p>The telephone was great. Once we had the telephone, people didn't have to worry about how to talk to people far away anymore. Just pick up the phone. Solved problem.</p><p>Facebook is great. Once we had Facebook, people didn't have to worry about how to interact with their friends in a social setting anymore. Just click on the little FB notification (Which seems to be always flashing for some reason to get my attention) Solved problem?</p><p>But these are entirely different things! With the phone, I know who I want to call and why. I push buttons and we are connected. The tech helps me do what I've already decided to do. With Facebook, on the other hand, they get paid to show me things in a certain order. The premise is that I'm waiting (or "exploring" if you prefer) until I find something to interact with. The phone is a tool for me to use. I am the tool Facebook is using. I am no longer acting. I am reacting.</p><p>And even if they weren't paid, interacting with friends socially is an extremely complex affair. What kind of mood are they in? What's their life history? What things are bad to bring up? How does their body language look? Facebook's gimmick is "Hey, we've reduced all of this to bits and bytes, and we'll even show you what bits and bytes to look at next!"</p><p>Solved problem.</p><p>Many, many people do not use the internet, the internet uses them. And this percentage is constantly growing.</p><figure><img src="https://cdn.danielbmarkham.com/2021/01/9EBNeUmSy6TMDUpKTLL6_terminator-robot.jpg" alt=""></figure><p>Just like the restaurant example, maybe that's fine. I have friends, I have opinions, who cares? It's all idle chat anyway.</p><p>That logic can be true for a bunch of things, but can't be true for <em>everything</em>. Otherwise, at some point 100 years from now, we're comparing our life values and end up saying something like "I like money too". Everything can't all be reduced down to the lowest common denominator. If it does, we all die.</p><p>Life is not a bit or byte, a number to be optimized. It's meaning we define ourselves, in ways we should not quantize.</p><p>Platforms, by their very nature, constantly send out the subtle message: <em>This is a solved problem. No further effort on your part is required here. No thinking needed.</em> Platforms resist change. They resist their own evolution by subtly poisoning the discussion before it even starts.</p><p>Are restaurant choices more or less important than which movie to watch tonight? There's no right or wrong answer to these questions. We have nice categories like restaurants and movies because currently people consider those things to be different kinds of choices. But why? If the algorithm is king, why shouldn't an algorithm determine both of those things for me? And if it does, why should I bother with worrying about which category is which?</p><p>Human brains are not computers. Let the platform decide. Energy not needed. Dump those neurons.</p><p>This is the more important point. It's not that the platforms turn what might be complex things into simple numbers, or even that they monetize attention. It's that by turning everything into numbers, over time they destroy the distinction between the categories entirely. Platforms are the enemy because they resist analysis in the areas they dominate.</p><p>Platforms turn into settled fact things that should be open for debate, like whether or not Taco Bell is a Mexican restaurant, or whether Milo is an artist with something useful to tell us. (I'm going with "no" and "no" for both of these.) More dangerously, they do the work of deciding <em>what categories various things go into</em>. This category over here is important. That category over there is not. We all make these decisions, and they're all different, and the categories each of us pays careful attention to and loves obsessing about are all different, and because we all have different viewpoints and priorities humankind advances in thousands of directions simultaneously. We survive. We evolve.</p><p>Twitter has to decide whether PERSON_X can speak or not because on the Twitter platform, that question has to have a yes or no answer based on the person. Twitter's category for deciding who can speak is "who is that?" Is that the right category for social conversations? For political conversations? For conversations about philosophy? Math? Who knows? Who cares? Twitter has decided. Solved problem.</p><p>Everybody has different things they like doing and thinking about. Different conversations and audiences have different criteria. Some problems should never be solved. Or rather more directly, some problems should never have a universal answer.</p><p>An aside: We see the same thing in programming. One bunch of folks creates various platforms in order to do the thinking for another bunch of folks. Sometimes these platforms take off and become industry standards. That's quite rare, however. Most of the time we end up training morons who can weakly code against the platform but can't reason effectively about the underlying architecture or reason for the platform to exist in the first place. In our desire to help, we harm the very people we're trying to assist -- by subtly giving them the impression that this is a solved problem. Programmers are just a decade or so ahead of the rest of us.</p><p>Popular platforms aren't just a danger economically because they control commerce. They're not just a danger politically because they selectively control and amplify political discourse. They're an extinction-level, existential danger to humans because they prevent people from seriously considering what kinds of categories are important in ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://danielbmarkham.com/the-platform-is-the-enemy/">https://danielbmarkham.com/the-platform-is-the-enemy/</a></em></p>]]>
            </description>
            <link>https://danielbmarkham.com/the-platform-is-the-enemy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25708099</guid>
            <pubDate>Sun, 10 Jan 2021 02:23:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a runtime reflection system for Rust (Part 3)]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25704707">thread link</a>) | @lukastyrychtr
<br/>
January 9, 2021 | https://www.osohq.com/post/runtime-reflection-pt-3 | <a href="https://web.archive.org/web/*/https://www.osohq.com/post/runtime-reflection-pt-3">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2><strong>Part 3: <code>dyn Method</code></strong></h2>
<h3>Introduction</h3>
<p>Welcome to the third and final installment of our series on how we implemented a runtime reflection system in Rust.</p>
<p>So far, we've shown how we came up with a fairly simple <code>Class</code> and <code>Instance</code> model for thinking about runtime Rust classes. In <a href="https://www.osohq.com/post/rust-reflection-pt-1">Part 1</a>, we used these for type checking, and in <a href="https://www.osohq.com/post/runtime-reflection-pt-2">Part 2</a> we added support for reading attributes off of a struct.</p>
<p>In this post, we pick up where we left off with attribute getters, and expand into <strong>method calls</strong>. In some ways, the same techniques we used for attributes work just as well here. We can store a map from method name to functions implementing them. However, there's a curveball: the Rust <code>Fn*</code> traits. We'll talk through the wrong turns we took, and the tidbits of Rust knowledge we picked up along the way.</p>
<h2>Method Calls</h2>
<p>Now that we have classes, instances, and attributes, the next obvious step is to add methods.</p>
<p>In oso policies, it is possible to call both class and instance methods, with and without arguments.</p>
<p>So given the struct:</p>
<pre><code>struct Cat;

impl Cat {
    /// A class method (note lack of `self`).
    fn meow() -&gt; String {
       "meowww".to_string()
    }

    /// An instance method.
    fn feed(&amp;self, food: &amp;str) -&gt; String {
        if food == "tuna" { "purr".to_string() } else { Self::meow() }
    }
}
</code></pre>

<p>We should be able to write policy logic:</p>
<pre><code>favourite_food(cat: Cat, food) if cat.feed(food) != Cat.meow();
</code></pre>

<p>Which says that the input <code>food</code> is the cat's favourite food if the result of feeding the cat is not the same as the result of the cat meowing.</p>
<h3>Step 1: Zero arguments</h3>
<p>Let's start with a simple implementation for methods that take <em>zero</em> arguments. The approach for implementing zero-argument methods is extremely similar to how we'd implement attribute getters, and we've actually done this already in Part 2:</p>
<pre><code>/// Class definitions
struct Class {
    ...

    /// Map from attribute name to the attribute lookup
    methods: HashMap&lt;&amp;'static str, InstanceMethod&gt;
}

struct InstanceMethod(Arc&lt;dyn Fn(&amp;Instance) -&gt; PolarValue);
</code></pre>

<p>Similarly, we need to add a method onto our <code>ClassBuilder</code> struct to allow us to register new methods:</p>
<pre><code>pub fn add_method&lt;F, R&gt;(mut self, name: &amp;'static str, f: F) -&gt; Self
where
    F: Fn(&amp;T) -&gt; R,
    R: crate::ToPolar,
{
    self.class.methods.insert(name, InstanceMethod::new(f));
    self
}
</code></pre>

<p>Super easy! End of blog post. See you next time üòé </p>
<p>But wait, what about methods with multiple arguments?</p>
<h3>Step 2: Multiple Arguments and the <code>Fn*</code> traits</h3>
<p>Let's take what we have above and add in support for multiple arguments.</p>
<pre><code>struct InstanceMethod(Arc&lt;dyn Fn(&amp;Instance, Vec&lt;PolarValue&gt;) -&gt; PolarValue&gt;);
</code></pre>

<p>This mostly works for what we need! Polar doesn't care about method arities (how many arguments the method accepts) ‚Äì it will send over however many arguments it has as a vector. Polar supports both variable number of arguments (varargs) and keyword arguments (kwargs). The latter is only supported for host languages that also have that concept, and Rust does not.</p>
<p>But this isn't the end of the story. The crucial part of the <code>AttributeGetter</code> interface was that you could pass in any method or closure for the attribute getter, and the <code>AttributeGetter::new</code> method handled all the type-conversions transparently. This hid the messy, error-prone details from the user and kept the interface clean.</p>
<p>So let's do the same for <code>InstanceMethod</code>!</p>
<pre><code>impl InstanceMethod {
    pub fn new&lt;T, F, ???&gt;(f: F) -&gt; Self
    where
        F: Fn(&amp;T, ???)
        F::Result: ToPolarResult,
        T: 'static,
    {
        Self(Arc::new(
            move |receiver: &amp;Instance, args: Vec&lt;PolarValue&gt;| {
                let receiver = receiver
                    .downcast()
                    .map_err(|e| e.invariant().into());
                // ermm.... what next?
            },
        ))
    }
}
</code></pre>

<p>We've hit our first problem.</p>
<p>The input to an attribute getter never accepted any arguments, and we only needed it to work for all <code>Fn(&amp;T)</code>. In order to support <em>multiple arguments</em>, we now need to cover <code>Fn(&amp;T)</code>, <code>Fn(&amp;T, A)</code>, <code>Fn(&amp;T, A, B)</code>, and so on.</p>
<p>The first problem is how to convert <code>A</code>, <code>B</code>, etc. into <code>PolarValue</code>s.</p>
<p>The second problem is that these are all <em>completely distinct traits</em>. There is no trait capturing "functions of arity 2, 3, 4...". ‚Äì&nbsp;at least not until the feature is available in stable Rust. In the future, this <em>might</em> be represented with the syntax <code>Fn&lt;Args, Output=T&gt;</code>, but right now using this syntax results in:</p>
<pre><code>error[E0658]: the precise format of `Fn`-family traits' type parameters is subject to change
 --&gt; src/main.rs:2:14
  |
2 |     where F: Fn&lt;(u32,), Output=u32&gt; {
  |              ^^^^^^^^^^^^^^^^^^^^^^ help: use parenthetical notation instead: `Fn(u32) -&gt; u32`
  |
  = note: see issue #29625 &lt;https://github.com/rust-lang/rust/issues/29625&gt; for more information
</code></pre>

<p>We could opt to use Rust nightly to get these features, but it's not a huge stretch to implement them ourselves.</p>
<h3>Implementing our own <code>Method</code> trait</h3>
<p>This is where as the writer it's tempting to unveil my newly-created trait, perfectly matching what we needed, and make it look like I just put fingers to keyboard to get to the definition.</p>
<p>In reality, we spent a sizeable chunk of our engineering effort for this project on this one trait. We made mistakes. We wrote code that we threw out. And a lot of that is because we didn't understand some of the nuances of Rust functions and the trait resolution system. Instead of papering over all of that, we thought it would be more interesting to show you what we tried. </p>
<p><strong>Attempt #1</strong></p>
<p>The first thing we tried was, in hindsight, a little greedy. Why not just skip straight to writing a trait to encapsulate precisely what we need?</p>
<pre><code>pub trait Method {
   fn invoke(&amp;self, receiver: Instance, args: Vec&lt;PolarValue&gt;) -&gt; PolarValue;
}
</code></pre>

<p>This looks great, let's try implementing it for one of our <code>Fn</code> variants:</p>
<pre><code>impl&lt;F, T, R&gt; Method for F
where
   F: Fn(&amp;T) -&gt; R,
   T: 'static,
   R: ToPolarValue,
{
    fn invoke(&amp;self, instance: Instance, args: Vec&lt;PolarValue&gt;) -&gt; PolarValue {
        debug_assert!(args.is_empty());
        let receiver = instance.downcast::&lt;T&gt;().unwrap();
        self(receiver).to_polar()
    }
}
</code></pre>

<p>Results in:</p>
<pre><code>impl&lt;F, T, R&gt; Method for F
        ^ unconstrained type parameter
the type parameter `T` is not constrained by the impl trait, self type, or predicates

impl&lt;F, T, R&gt; Method for F
           ^ unconstrained type parameter
the type parameter `R` is not constrained by the impl trait, self type, or predicates
</code></pre>

<p>It's likely that most people have hit some variation of this error in their Rust adventures! What is going on here? <code>T</code> and <code>R</code> <em>look</em> pretty constrained to me? They are right there inside the definition of <code>F: Fn(&amp;T) -&gt; R</code>. </p>
<p>Our mistake was reading those trait bounds as: <code>F</code> is a function from <code>&amp;T</code> to <code>R</code>, whereas in reality this is a regular old trait bound with slightly different syntax for the trait itself. And one function might implement multiple of these trait bounds.</p>
<p>E.g.</p>
<pre><code>// do nothing
fn ident&lt;T&gt;(t: T) -&gt; T { t }

let _ = &amp;ident as &amp;dyn Fn(u32) -&gt; u32;
let _ = &amp;ident as &amp;dyn Fn(String) -&gt; String;
</code></pre>

<p>So which trait should we use for the implementation of <code>Method</code> for <code>ident</code>?</p>
<p>Here's another way of looking at this problem. Suppose instead we decided to exhaustively implement our <code>Method</code> trait for all types we care about:</p>
<pre><code>impl&lt;F&gt; Method for F
where
   F: Fn(&amp;u32) -&gt; u32,
{
    fn invoke(&amp;self, instance: Instance, args: Vec&lt;PolarValue&gt;) -&gt; PolarValue {
        debug_assert!(args.is_empty());
        let receiver = instance.downcast::&lt;u32&gt;().unwrap();
        self(receiver).to_polar()
    }
}

impl&lt;F&gt; Method for F
where
   F: Fn(&amp;String) -&gt; String,
{
    fn invoke(&amp;self, instance: Instance, args: Vec&lt;PolarValue&gt;) -&gt; PolarValue {
        debug_assert!(args.is_empty());
        let receiver = instance.downcast::&lt;String&gt;().unwrap();
        self(receiver).to_polar()
    }
}
</code></pre>

<p>Ignoring for now just how bad an idea this is, it doesn't even work! We get:</p>
<pre><code>conflicting implementations of trait `Method`:
</code></pre>

<p>Look back to <code>ident</code>. That one function implements both <code>Fn(String) -&gt; String</code> and <code>Fn(u32) -&gt; u32</code> traits. Similarly, in the above case, a function that implements both <code>Fn(&amp;String) -&gt; String</code> and <code>Fn(&amp;u32) -&gt; u32</code> would have two possible implementations for <code>Method</code>. So we get conflicting implementations.  </p>
<p><em>Actually</em>, it goes even further than that. Implementing a blanket trait implementation over <em>any</em> two function trait bounds results in conflicting implementations. Even though such a function couldn't exist:</p>
<pre><code>trait Test {}

impl&lt;F: Fn()&gt; Test for F { }
impl&lt;F: Fn(String) -&gt; String&gt; Test for F { }
</code></pre>

<p>Results in:</p>
<pre><code>error[E0119]: conflicting implementations of trait `Test`:
  |
4 | impl&lt;F: Fn()&gt; Test for F { }
  | ------------------------ first implementation here
5 | impl&lt;F: Fn(String) -&gt; String&gt; Test for F { }
  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ conflicting implementation
</code></pre>

<p>One day (or today, if you're on Rust nightly), Rust might let you implement <code>Fn</code> for your own types, support variadic functions (what do you mean Rust already supports <a href="https://doc.rust-lang.org/nomicon/ffi.html#variadic-functions">variadic functions</a>?), and do all kinds of fun things of the sort. But for now we're not going to get much farther with this approach.</p>
<p><strong>Attempt #2</strong></p>
<p>This <code>Method</code> trait looks too convenient to throw away entirely at the first sign of complication. Let's try something different. If our original mistake was thinking of <code>Fn</code> as a function instead of a trait, perhaps we can heed the wisdom of the Rust docs and use <code>fn</code> instead.</p>
<p><img alt="Building%20a%20runtime%20reflection%20system%20for%20Rust%20(Par%20e9d46e4c771847e7ba119df92cf2a8b9/Untitled.png" src="https://images.osohq.com/runtime-reflection-pt-3/Building%20a%20runtime%20reflection%20system%20for%20Rust%20%28Par%20e9d46e4c771847e7ba119df92cf2a8b9/Untitled.png"></p>
<p>Based on the docs, we can use <code>fn</code> with both regular functions and closures! Great, let's do just that:</p>
<pre><code>impl&lt;T, R&gt; Method for fn(&amp;T) -&gt; R
where
    T: 'static,
    R: ToPolarValue,
{
     fn invoke(&amp;self, instance: Instance, args: Vec&lt;PolarValue&gt;) -&gt; PolarValue {
        debug_assert!(args.is_empty());
        let receiver = instance.downcast().unwrap();
        self(receiver).to_polar()
    }
}
</code></pre>

<p>Works fine! Let's try it out:</p>
<pre><code>let clone = |receiver: &amp;String| -&gt; String { receiver.clone() };
let clone_method: Box&lt;dyn Method&gt; = Box::new(clone);
let ‚Ä¶</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.osohq.com/post/runtime-reflection-pt-3">https://www.osohq.com/post/runtime-reflection-pt-3</a></em></p>]]>
            </description>
            <link>https://www.osohq.com/post/runtime-reflection-pt-3</link>
            <guid isPermaLink="false">hacker-news-small-sites-25704707</guid>
            <pubDate>Sat, 09 Jan 2021 21:03:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What is happening to Lazada is happening to all companies acquired by Alibaba]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 30 (<a href="https://news.ycombinator.com/item?id=25703505">thread link</a>) | @7d7n
<br/>
January 9, 2021 | https://thelowdown.momentum.asia/what-is-happening-to-lazada-is-happening-to-all-companies-acquired-by-alibaba/ | <a href="https://web.archive.org/web/*/https://thelowdown.momentum.asia/what-is-happening-to-lazada-is-happening-to-all-companies-acquired-by-alibaba/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://thelowdown.momentum.asia/what-is-happening-to-lazada-is-happening-to-all-companies-acquired-by-alibaba/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25703505</guid>
            <pubDate>Sat, 09 Jan 2021 19:12:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Next Gen Static Blogging]]>
            </title>
            <description>
<![CDATA[
Score 219 | Comments 168 (<a href="https://news.ycombinator.com/item?id=25701053">thread link</a>) | @mmackh
<br/>
January 9, 2021 | https://inoads.com/articles/2020-01-09-Next-Gen-Static-Blogging | <a href="https://web.archive.org/web/*/https://inoads.com/articles/2020-01-09-Next-Gen-Static-Blogging">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://inoads.com/articles/2020-01-09-Next-Gen-Static-Blogging</link>
            <guid isPermaLink="false">hacker-news-small-sites-25701053</guid>
            <pubDate>Sat, 09 Jan 2021 15:25:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Holiday Hacking ‚Äì Tracking my heart rate while playing Call of Duty]]>
            </title>
            <description>
<![CDATA[
Score 74 | Comments 36 (<a href="https://news.ycombinator.com/item?id=25700872">thread link</a>) | @lukastyrychtr
<br/>
January 9, 2021 | https://jcdav.is/2021/01/04/Holiday-Hacking-COD-HR/ | <a href="https://web.archive.org/web/*/https://jcdav.is/2021/01/04/Holiday-Hacking-COD-HR/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
  
  <p><span>04 Jan 2021</span></p><p>Over the holidays, I got a <a href="https://www.polar.com/us-en/products/accessories/oh1-optical-heart-rate-sensor">Polar OH1+</a> as a Christmas present. Its an optical heart rate monitor with similar tech to those found in smart watches (including my Garmin running watch), but much more accurate (at least for running) due to being smaller &amp; lighter, as well as fitting against the fleshier upper arm:</p>

<p><img src="https://jcdav.is/public/oh1-small.jpg" alt="Polar OH1"></p>

<p>Like any modern gadget these days, it supports Bluetooth (specifically Bluetooth Low Energy, or BLE/BTLE) for talking to your phone and/or smart watch. Which got me wondering, will it pair with a computer?</p>

<p><img src="https://jcdav.is/public/bluetooth.jpg" alt="It pairs"></p>

<p>This piqued my curiosity. I had long been at least somewhat curious about tracking my heart rate while say playing video games, if nothing else for curiosity. So how easy is it to grab data from this thing? As with the last few years, I had spent a bit of December doing a bunch of <a href="https://adventofcode.com/">Advent of Code</a> in rust, only to forget and have to re-learn everything the next year. So figured I could maybe try my hand at a ‚Äúreal‚Äù project.</p>

<p>Some quick googling later, I found the promising-looking <a href="https://crates.io/crates/btleplug">btleplug</a> crate. Lets dump data from all nearby devices‚Ä¶</p>

<div><div><pre><code><span>extern</span> <span>crate</span> <span>btleplug</span><span>;</span>

<span>use</span> <span>std</span><span>::</span><span>thread</span><span>;</span>
<span>use</span> <span>std</span><span>::</span><span>time</span><span>::</span><span>Duration</span><span>;</span>

<span>#[cfg(target_os</span> <span>=</span> <span>"linux"</span><span>)]</span>
<span>use</span> <span>btleplug</span><span>::</span><span>bluez</span><span>::{</span><span>adapter</span><span>::</span><span>ConnectedAdapter</span><span>,</span> <span>manager</span><span>::</span><span>Manager</span><span>};</span>
<span>#[cfg(target_os</span> <span>=</span> <span>"windows"</span><span>)]</span>
<span>use</span> <span>btleplug</span><span>::</span><span>winrtble</span><span>::{</span><span>adapter</span><span>::</span><span>Adapter</span><span>,</span> <span>manager</span><span>::</span><span>Manager</span><span>};</span>
<span>#[cfg(target_os</span> <span>=</span> <span>"macos"</span><span>)]</span>
<span>use</span> <span>btleplug</span><span>::</span><span>corebluetooth</span><span>::{</span><span>adapter</span><span>::</span><span>Adapter</span><span>,</span> <span>manager</span><span>::</span><span>Manager</span><span>};</span>
<span>use</span> <span>btleplug</span><span>::</span><span>api</span><span>::{</span><span>UUID</span><span>,</span> <span>Central</span><span>,</span> <span>Peripheral</span><span>};</span>

<span>#[cfg(any(target_os</span> <span>=</span> <span>"windows"</span><span>,</span> <span>target_os</span> <span>=</span> <span>"macos"</span><span>))]</span>
<span>fn</span> <span>get_central</span><span>(</span><span>manager</span><span>:</span> <span>&amp;</span><span>Manager</span><span>)</span> <span>-&gt;</span> <span>Adapter</span> <span>{</span>
    <span>let</span> <span>adapters</span> <span>=</span> <span>manager</span><span>.adapters</span><span>()</span><span>.unwrap</span><span>();</span>
    <span>adapters</span><span>.into_iter</span><span>()</span><span>.nth</span><span>(</span><span>0</span><span>)</span><span>.unwrap</span><span>()</span>
<span>}</span>

<span>#[cfg(target_os</span> <span>=</span> <span>"linux"</span><span>)]</span>
<span>fn</span> <span>get_central</span><span>(</span><span>manager</span><span>:</span> <span>&amp;</span><span>Manager</span><span>)</span> <span>-&gt;</span> <span>ConnectedAdapter</span> <span>{</span>
    <span>let</span> <span>adapters</span> <span>=</span> <span>manager</span><span>.adapters</span><span>()</span><span>.unwrap</span><span>();</span>
    <span>let</span> <span>adapter</span> <span>=</span> <span>adapters</span><span>.into_iter</span><span>()</span><span>.nth</span><span>(</span><span>0</span><span>)</span><span>.unwrap</span><span>();</span>
    <span>adapter</span><span>.connect</span><span>()</span><span>.unwrap</span><span>()</span>
<span>}</span>

<span>fn</span> <span>main</span><span>()</span> <span>{</span>
    <span>let</span> <span>manager</span> <span>=</span> <span>Manager</span><span>::</span><span>new</span><span>()</span><span>.unwrap</span><span>();</span>
    <span>let</span> <span>central</span> <span>=</span> <span>get_central</span><span>(</span><span>&amp;</span><span>manager</span><span>);</span>

    <span>central</span><span>.start_scan</span><span>()</span><span>.unwrap</span><span>();</span>
    <span>thread</span><span>::</span><span>sleep</span><span>(</span><span>Duration</span><span>::</span><span>from_secs</span><span>(</span><span>2</span><span>));</span>

    <span>for</span> <span>per</span> <span>in</span> <span>&amp;</span><span>central</span><span>.peripherals</span><span>()</span> <span>{</span>
        <span>println!</span><span>(</span><span>"{:?}"</span><span>,</span> <span>per</span><span>);</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>(Note that though this part should work cross-platform, I couldn‚Äôt get bluetooth working from WSL, so this was all done natively on Windows).</p>

<p>Sure enough, among the shockingly large list of nearby devices is my new toy:</p>

<div><div><pre><code>A0:9E:1A:XX:XX:XX properties: PeripheralProperties { address: A0:9E:1A:XX:XX:XX, address_type: Public, local_name: Some("Polar OH1 XXXXXXXX"), tx_power_level: Some(-64), manufacturer_data: Some([]), discovery_count: 6, has_scan_response: true }, characteristics: {}
</code></pre></div></div>

<p>Let‚Äôs see what characteristics it supports:</p>

<div><div><pre><code>    <span>let</span> <span>ohr</span> <span>=</span> <span>central</span><span>.peripherals</span><span>()</span><span>.into_iter</span><span>()</span><span>.find</span><span>(|</span><span>p</span><span>|</span> <span>{</span>
        <span>p</span><span>.properties</span><span>()</span><span>.local_name</span><span>.map</span><span>(|</span><span>n</span><span>|</span> <span>n</span><span>.starts_with</span><span>(</span><span>"Polar OH1"</span><span>))</span>
            <span>.unwrap_or</span><span>(</span><span>false</span><span>)</span>
    <span>})</span><span>.unwrap</span><span>();</span>

    <span>ohr</span><span>.connect</span><span>();</span>
    <span>println!</span><span>(</span><span>"{:?}"</span><span>,</span> <span>ohr</span><span>.discover_characteristics</span><span>()</span><span>.unwrap</span><span>());</span>
</code></pre></div></div>

<p>Turns out..a lot?</p>

<div><div><pre><code>[Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 00:00:2A:00:00:00:10:00:80:00:00:80:5F:9B:34:FB, properties: READ }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 00:00:2A:01:00:00:10:00:80:00:00:80:5F:9B:34:FB, properties: READ }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 00:00:2A:04:00:00:10:00:80:00:00:80:5F:9B:34:FB, properties: READ }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 00:00:2A:A6:00:00:10:00:80:00:00:80:5F:9B:34:FB, properties: READ }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 00:00:2A:05:00:00:10:00:80:00:00:80:5F:9B:34:FB, properties: INDICATE }, Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 00:00:2A:29:00:00:10:00:80:00:00:80:5F:9B:34:FB, properties: READ }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 00:00:2A:24:00:00:10:00:80:00:00:80:5F:9B:34:FB, properties: READ }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 00:00:2A:25:00:00:10:00:80:00:00:80:5F:9B:34:FB, properties: READ }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 00:00:2A:27:00:00:10:00:80:00:00:80:5F:9B:34:FB, properties: READ }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 00:00:2A:26:00:00:10:00:80:00:00:80:5F:9B:34:FB, properties: READ }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 00:00:2A:28:00:00:10:00:80:00:00:80:5F:9B:34:FB, properties: READ }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 00:00:2A:23:00:00:10:00:80:00:00:80:5F:9B:34:FB, properties: READ }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: FB:00:5C:51:02:E7:F3:87:1C:AD:8A:CD:2D:8D:F0:C8, properties: WRITE_WITHOUT_RESPONSE | WRITE | NOTIFY },
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: FB:00:5C:52:02:E7:F3:87:1C:AD:8A:CD:2D:8D:F0:C8, properties: NOTIFY }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: FB:00:5C:53:02:E7:F3:87:1C:AD:8A:CD:2D:8D:F0:C8, properties: WRITE_WITHOUT_RESPONSE | WRITE },
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 00:00:2A:37:00:00:10:00:80:00:00:80:5F:9B:34:FB, properties: NOTIFY }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 00:00:2A:19:00:00:10:00:80:00:00:80:5F:9B:34:FB, properties: READ | NOTIFY }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: FB:00:5C:21:02:E7:F3:87:1C:AD:8A:CD:2D:8D:F0:C8, properties: READ }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: FB:00:5C:22:02:E7:F3:87:1C:AD:8A:CD:2D:8D:F0:C8, properties: WRITE | INDICATE }, Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: FB:00:5C:26:02:E7:F3:87:1C:AD:8A:CD:2D:8D:F0:C8, properties: NOTIFY }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 62:17:FF:4C:C8:EC:B1:FB:13:80:3A:D9:86:70:8E:2D, properties: READ }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 62:17:FF:4D:91:BB:91:D0:7E:2A:7C:D3:BD:A8:A1:F3, properties: WRITE | INDICATE }, Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: FB:00:5C:81:02:E7:F3:87:1C:AD:8A:CD:2D:8D:F0:C8, properties: READ | WRITE | INDICATE }, Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: FB:00:5C:82:02:E7:F3:87:1C:AD:8A:CD:2D:8D:F0:C8, properties: NOTIFY }]
</code></pre></div></div>

<p>Which of these do I want? The <a href="https://btprodspecificationrefs.blob.core.windows.net/assigned-values/16-bit%20UUID%20Numbers%20Document.pdf">Bluetooth UUID specifications</a> lists a bunch of different potentially interesting IDs, but they are all 16 bits, whereas are 128 bit. Making matters more confusing, <code>btleplug</code> ‚Äòs UUID definition seems to allow for either:</p>

<div><div><pre><code><span>pub</span> <span>enum</span> <span>UUID</span> <span>{</span>
    <span>B16</span><span>(</span><span>u16</span><span>),</span>
    <span>B128</span><span>([</span><span>u8</span><span>;</span> <span>16</span><span>]),</span>
<span>}</span>
</code></pre></div></div>

<p>However it seems like a lot of them seem to only differ in the 3rd and 4th bytes <sup><a href="#suff1">1</a></sup>, and those to roughly correspond to GATT Characteristic Ids, and in there is a <code>2A:37</code>, which represents Heart Rate Measurement - sounds promising. Lets see if we can listen &amp; dump that data:</p>

<div><div><pre><code>    <span>let</span> <span>mut</span> <span>bytes</span><span>:</span> <span>[</span><span>u8</span><span>;</span> <span>16</span><span>]</span> <span>=</span> <span>[</span><span>0x00</span><span>,</span><span>0x00</span><span>,</span><span>0x2A</span><span>,</span><span>0x37</span><span>,</span><span>0x00</span><span>,</span><span>0x00</span><span>,</span><span>0x10</span><span>,</span><span>0x00</span><span>,</span><span>0x80</span><span>,</span><span>0x00</span><span>,</span><span>0x00</span><span>,</span><span>0x80</span><span>,</span><span>0x5F</span><span>,</span><span>0x9B</span><span>,</span><span>0x34</span><span>,</span><span>0xFB</span><span>];</span>
    <span>bytes</span><span>.reverse</span><span>();</span>
    <span>let</span> <span>uuid</span> <span>=</span> <span>UUID</span><span>::</span><span>B128</span><span>(</span><span>bytes</span><span>);</span>
    <span>let</span> <span>chars</span> <span>=</span> <span>ohr</span><span>.discover_characteristics</span><span>()</span>
        <span>.expect</span><span>(</span><span>"Couldn't discover characteristics"</span><span>);</span>
    <span>let</span> <span>hr_char</span> <span>=</span> <span>chars</span><span>.iter</span><span>()</span><span>.find</span><span>(|</span><span>c</span><span>|</span> <span>c</span><span>.uuid</span> <span>==</span> <span>uuid</span><span>)</span>
        <span>.expect</span><span>(</span><span>"couldn't find HR characteristic"</span><span>);</span>

    <span>ohr</span><span>.on_notification</span><span>(</span><span>Box</span><span>::</span><span>new</span><span>(|</span><span>not</span><span>|</span> <span>{</span>
        <span>println!</span><span>(</span><span>"{:?}"</span><span>,</span> <span>not</span><span>.value</span><span>);</span>
    <span>}));</span>
    <span>ohr</span><span>.subscribe</span><span>(</span><span>hr_char</span><span>)</span><span>.expect</span><span>(</span><span>"Couldn't subscribe"</span><span>);</span>
    <span>loop</span> <span>{</span>
    <span>}</span>
</code></pre></div></div>

<p>Endianness issues out of the way this‚Ä¶.seems to be working?</p>

<div><div><pre><code>C:\Users\jackson\Dev\hroverlay&gt;cargo run
    Finished dev [unoptimized + debuginfo] target(s) in 0.14s
     Running `target\debug\hroverlay.exe`
[0, 59]
[0, 58]
[0, 58]
[0, 59]
[0, 60]
[0, 61]
[0, 62]
</code></pre></div></div>

<p>At least that second number sure looks like a heart rate reading. To confirm this, I hopped over to the technical specifications for the Heart Rate Service (downloadable <a href="https://www.bluetooth.com/specifications/gatt/">here</a>). Sure enough, byte 0 represents various flags and byte 1 is a heart rate measurement. The spec authors have even figured out support for heart rates &gt;255 on off chance you ever slap one of these bad boys on a hummingbird:</p>

<blockquote>
  <p>3.1.1.2Heart Rate Measurement Value Field</p>

  <p>The Heart Rate Measurement Value field shall be included in the Heart Rate Measurement characteristic. While most human applications require support for only 255 bpm or less, special applications (e.g. animals) may require support for higher bpm values. If the Heart Rate Measurement Value is less than or equal to 255 bpm a UINT8 format should be used for power savings. If the Heart Rate Measurement Value exceeds 255 bpm a UINT16 format shall be used. See 3.1.1.1.1for additional requirements on the Heart Rate Value format change.</p>
</blockquote>

<p>Other potentially interesting bit flags include a way to indicate if the sensor thinks it has lost skin contact.</p>

<h2 id="displaying-things">Displaying things</h2>

<p>Now its time to figure out a UI. Faced with a <a href="https://www.areweguiyet.com/">large number of different options</a>, I ended up settling on the not-even-listed-there <a href="https://crates.io/crates/native-windows-gui">native-windows-gui crate</a> , throwing cross-platform support into the wind on the suspicion I would need easy access to the underlying win32 APIs, since it is largely just a series of nice convenience abstractions over those. Using the associated native-windows-derive macro crate, I had a basic UI setup working fairly quickly:</p>

<div><div><pre><code><span>#[derive(Default,</span> <span>NwgUi)]</span>
<span>pub</span> <span>struct</span> <span>BasicApp</span> <span>{</span>
    <span>#[nwg_control(size:</span> <span>(</span><span>300</span><span>,</span> <span>115</span><span>),</span> <span>flags:</span> <span>"WINDOW|VISIBLE"</span><span>)]</span>
    <span>#[nwg_events(OnWindowClose:</span> <span>[</span><span>BasicApp::exit]</span><span>)]</span>
    <span>window</span><span>:</span> <span>nwg</span><span>::</span><span>Window</span><span>,</span>

    <span>#[nwg_layout(parent:</span> <span>window)]</span>
    <span>grid</span><span>:</span> <span>nwg</span><span>::</span><span>GridLayout</span><span>,</span>

    <span>#[nwg_control(text:</span> <span>"--"</span><span>,</span> <span>readonly:</span> <span>true</span><span>)]</span>
    <span>#[nwg_layout_item(layout:</span> <span>grid,</span> <span>row:</span> <span>0</span><span>,</span> <span>col:</span> <span>0</span><span>)]</span>
    <span>hr</span><span>:</span> <span>nwg</span><span>::</span><span>TextInput</span><span>,</span>

    <span>#[nwg_control(parent:</span> <span>window,</span> <span>interval:</span> <span>500</span><span>,</span> <span>stopped:</span> <span>false</span><span>)]</span>
    <span>#[nwg_events(OnTimerTick:</span> <span>[</span><span>BasicApp::draw_hr]</span><span>)]</span>
    <span>timer</span><span>:</span> <span>nwg</span><span>::</span><span>Timer</span><span>,</span>
<span>}</span>

<span>impl</span> <span>BasicA‚Ä¶</span></code></pre></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jcdav.is/2021/01/04/Holiday-Hacking-COD-HR/">https://jcdav.is/2021/01/04/Holiday-Hacking-COD-HR/</a></em></p>]]>
            </description>
            <link>https://jcdav.is/2021/01/04/Holiday-Hacking-COD-HR/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25700872</guid>
            <pubDate>Sat, 09 Jan 2021 15:03:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ray Tracing in pure CMake]]>
            </title>
            <description>
<![CDATA[
Score 272 | Comments 142 (<a href="https://news.ycombinator.com/item?id=25700038">thread link</a>) | @networked
<br/>
January 9, 2021 | https://64.github.io/cmake-raytracer/ | <a href="https://web.archive.org/web/*/https://64.github.io/cmake-raytracer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    
    

    <div>
      <p>Without further ado, I present: a basic whitted ray tracer, complete with multicore rendering, written in 100% pure CMake. If you don't care about the details, and just want to see the code, you can <a href="https://github.com/64/cmake-raytracer">find it here</a>.</p>
<figure>
    <img src="https://github.com/64/cmake-raytracer/raw/master/render.png">
</figure>
<p>At this point, those familiar with CMake may have some questions, so keep reading to find out how it all works.</p>

<p><strong>Good news:</strong> CMake has a <a href="https://cmake.org/cmake/help/latest/command/math.html?highlight=math"><code>math</code></a> command. <strong>Bad news:</strong> it only supports integers. If you've written a ray tracer before, you probably did it with floating point numbers. So how do you go from representing signed integers to representing something-resembling-floating-point numbers? One answer is to use <a href="https://en.wikipedia.org/wiki/Fixed-point_arithmetic"><strong>fixed-point arithmetic</strong></a>.</p>
<p>The basic idea with fixed point is simple. We define some large integer to represent the number 1.0; let's choose <strong>1000</strong>. Then we can represent 2.0 as 2000, 0.5 as 500, -3.0 as -3000 etc. When we want to add two numbers, we simply add their fixed-point representations. Here's how that looks in CMake:</p>
<pre><span>function(add a b res)
    math(EXPR tmp </span><span>"(${</span><span>a</span><span>}) + (${</span><span>b</span><span>})"</span><span>)
    set(</span><span>"${</span><span>res</span><span>}" "${</span><span>tmp</span><span>}" </span><span>PARENT_SCOPE)
endfunction()
</span></pre>
<p>This takes two values <code>a</code> and <code>b</code> to be added and stored in the variable <code>res</code>. I use <code>PARENT_SCOPE</code> so that the variable we create is actually visible from the calling function, otherwise CMake will destroy it when the function ends.</p>
<p>To multiply two numbers, we simply multiply their fixed-point representations, and then divide by the thing we chose to represent 1.0:
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1.5</mn><mo>√ó</mo><mn>4.0</mn><mo>‚Ü¶</mo><mfrac><mrow><mn>1500</mn><mo>√ó</mo><mn>4000</mn></mrow><mn>1000</mn></mfrac><mo>=</mo><mn>6000</mn><mo>‚Ü¶</mo><mn>6.0</mn></mrow><annotation encoding="application/x-tex">1.5 \times 4.0 \mapsto \frac{1500 \times 4000}{1000} = 6000 \mapsto 6.0</annotation></semantics></math></span></span></span></p>
<p>Division is similar:
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1.5</mn><mo>√∑</mo><mn>4.0</mn><mo>‚Ü¶</mo><mfrac><mrow><mn>1500</mn><mo>√ó</mo><mn>1000</mn></mrow><mn>4000</mn></mfrac><mo>=</mo><mn>375</mn><mo>‚Ü¶</mo><mn>0.375</mn></mrow><annotation encoding="application/x-tex">1.5 \div 4.0 \mapsto \frac{1500 \times 1000}{4000} = 375 \mapsto 0.375</annotation></semantics></math></span></span></span>
We could have multiplied by 1000 after doing the division, but as integer division rounds towards zero this would wipe out all our precision (as <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1500</mn><mn>4000</mn></mfrac><mo>√ó</mo><mn>1000</mn><mo>=</mo><mn>0</mn><mo>√ó</mo><mn>1000</mn><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\frac{1500}{4000}\times 1000 = 0 \times 1000 = 0</annotation></semantics></math></span></span>). Multiplying first gives us better results, as long as the dividend isn't too huge (which would cause overflow).</p>
<p>CMake's <code>math</code> command only supports basic integer arithmetic. For more complicated operations, like square root, we use <a href="https://en.wikipedia.org/wiki/Newton%27s_method">Newton-Raphson iteration</a>. You can read more about this <a href="https://en.wikipedia.org/wiki/Methods_of_computing_square_roots#Babylonian_method">here</a>, but the basic idea is to make a 'guess' as to what the output should be then iteratively refine the guess towards the answer. This gives a surprisingly accurate result within only three or four iterations, subject to the quality of the initial guess:</p>
<pre><span>function(sqrt x res)
    div_by_2(${x} guess)

    </span><span>foreach</span><span>(counter RANGE 4)
        </span><span>if</span><span>(${guess} EQUAL 0)
            set(</span><span>"${</span><span>res</span><span>}" </span><span>0 PARENT_SCOPE)
            return()
        </span><span>endif</span><span>()

        div(${x} ${guess} tmp)
        add(${tmp} ${guess} tmp)
        div_by_2(${tmp} guess)
    </span><span>endforeach</span><span>()

    set(</span><span>"${</span><span>res</span><span>}" "${</span><span>guess</span><span>}" </span><span>PARENT_SCOPE)
endfunction()

</span><span># sqrt(123) = 11.09072626, actual answer is 11.0905365064
</span></pre>
<p>I also implemented a similar function for computing <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><msqrt><mi>x</mi></msqrt></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{\sqrt{x}}</annotation></semantics></math></span></span> separately as I found that it lead to better numerical stability, as opposed to computing the square root as above and then doing the reciprocal. This comes in handy when we need to normalize vectors.</p>
<p>Almost everything in computer graphics is done with vectors, so I started implementing vector operations: <code>vec3_add</code>, <code>vec3_mul</code>, <code>vec3_div</code>, <code>vec3_dot</code> etc. These make use of CMake built-in lists, which are pretty horrible, but save me from having to use three separate variables to keep track of the individual components of each vector. For example, here's what the dot product looks like:</p>
<pre><span>function(vec3_dot x y res)
    list(GET ${x} 0 x_0)
    list(GET ${x} 1 x_1)
    list(GET ${x} 2 x_2)
    list(GET ${y} 0 y_0)
    list(GET ${y} 1 y_1)
    list(GET ${y} 2 y_2)
    mul(${x_0} ${y_0} z_0)
    mul(${x_1} ${y_1} z_1)
    mul(${x_2} ${y_2} z_2)
    add(${z_0} ${z_1} tmp)
    add(${tmp} ${z_2} tmp)
    set(</span><span>"${</span><span>res</span><span>}" </span><span>${tmp} PARENT_SCOPE)
endfunction()
</span></pre>
<p>And here's how we'd use it to normalize a vector:</p>
<pre><span>function(vec3_normalize x res)
    vec3_dot(${x} ${x} x_2)
    rsqrt(${x_2} one_over_length)
    vec3_mulf(${x} ${one_over_length} tmp)
    set(</span><span>"${</span><span>res</span><span>}" </span><span>${tmp} PARENT_SCOPE)
endfunction()
</span></pre>
<p>As well a few other bits and bobs, like <code>clamp</code> and <code>truncate</code>, that's all the arithmetic that's needed.</p>

<p>If you're new to ray tracing, I'd refer you to <a href="https://twitter.com/peter_shirley">Peter Shirley's</a> wonderful book series '<a href="https://raytracing.github.io/">Ray Tracing in One Weekend</a>', which my code is loosely based on. The general intuition is to trace rays out from the camera into the scene and see what they intersect. Since we represent all our scene geometry and rays as mathematical objects, computing intersections between rays and geometry is just a case of solving equations. Once we have found an intersection, we compute the color of the point we intersected with, which may itself be computed by tracing rays towards light sources or towards other scene geometry.</p>
<figure>
    <img src="https://developer.nvidia.com/sites/default/files/pictures/2018/RayTracing/ray-tracing-image-1.jpg">
    <figcaption><i>The ray tracing algorithm.</i>  Credit: <a href="https://developer.nvidia.com/discover/ray-tracing">https://developer.nvidia.com</a></figcaption>
</figure> 
<p>To keep it simply I went with a simple scene consisting of a sphere sitting atop an infinite plane in a checkerboard color. I also ended up faking the shadow underneath the sphere, simply drawing a black circle (well done if you spotted it from the image). I had implemented whitted ray tracing and even path tracing at one point, but they were much more complicated and performed a lot worse for the same result. In theory, though, there's no reason why I couldn't do it properly, it would just require some additional effort and patience.</p>
<p>Here's what the main 'trace' function looks like, with some of the unnecessary bits stripped out for clarity:</p>
<pre><span># Traces a ray into the scene, computes the color returned along the ray
</span><span>function(trace ray_origin ray_dir depth color)
    </span><span># Base case for recursion
    </span><span>if</span><span>(${depth} GREATER_EQUAL 3)
        return()
    </span><span>else</span><span>()
        math(EXPR depth </span><span>"${</span><span>depth</span><span>} + 1"</span><span>)
    </span><span>endif</span><span>()

    </span><span># Calculate intersection points with the sphere and plane
    </span><span>sphere_intersect(${ray_origin} ${ray_dir} hit_t_1 hit_point_1 hit_normal_1)
    plane_intersect(${ray_origin} ${ray_dir} hit_t_2 hit_point_2 hit_normal_2)

    </span><span># Did we hit the sphere?
    </span><span>if</span><span>(${hit_t_1} GREATER ${ray_epsilon})
        </span><span># Calculate reflected ray direction
        </span><span>offset_origin(hit_point_1 hit_normal_1 new_origin)
        vec3_dot(hit_normal_1 ${ray_dir} scalar)
        mul_by_2(${scalar} scalar)
        vec3_mulf(hit_normal_1 ${scalar} refl_a)
        vec3_sub(${ray_dir} refl_a new_dir)

        </span><span># Recursively trace the new ray into the scene
        </span><span>trace(new_origin new_dir ${depth} traced_col)

        </span><span># Calculate contribution from lights
        </span><span>set(col 0 0 0)
        light_contrib(hit_point_1 hit_normal_1 light1_pos light1_col out_col1)
        light_contrib(hit_point_1 hit_normal_1 light2_pos light2_col out_col2)
        vec3_add(col out_col1 col)
        vec3_add(col out_col2 col)
        vec3_add(col traced_col col)

        set(base_col ${sphere_color})
        vec3_mul(base_col col col)

    </span><span># Did we hit the plane?
    </span><span>elseif</span><span>(${hit_t_2} GREATER ${ray_epsilon})
        </span><span># ...snip: Use equation of a circle to fake shadow, if we're within range
        # ...snip: Calculate checkerboard pattern
    </span><span>else</span><span>()
        </span><span># We hit nothing, return black
        </span><span>set(col 0 0 0)
    </span><span>endif</span><span>()

    set(</span><span>"${</span><span>color</span><span>}" </span><span>${col} PARENT_SCOPE)
endfunction()
</span></pre>
<p>When I started, I wouldn't sure if it would be possible to do in pure CMake, but with a little trickery we can manage it.</p>
<p>For <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span></span> processes, the basic plan is to divide up the image vertically and let each sub-process render a few rows. We can invoke sub-processes with the <a href="https://cmake.org/cmake/help/v3.0/command/execute_process.html"><code>execute_process</code></a> command, passing arguments (such as the worker index) via <code>-D</code>. Each process then spits their row data into a text file, which gets merged together by the master process once they've all finished.</p>
<p>One subtlety is that as we need all the sub-processes to run in parallel, we can't simply call <code>execute_process</code> <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span></span> times, as it would run them sequentially. Luckily, we can specify multiple processes to run simultaneously in one command (I think this is intended to be used for long chains where one program is piped into the next), but in order to avoid hardcoding <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span></span> we have to programmatically construct the call to <code>execute_process</code> with CMake's <a href="https://cmake.org/cmake/help/git-stage/command/cmake_language.html"><code>EVAL CODE</code></a> feature (thanks to <a href="https://github.com/martty/vuk">martty</a> for this idea):</p>
<pre><span>    message(STATUS </span><span>"Launching ray tracer with ${</span><span>num_procs</span><span>} processes, ${</span><span>image_width</span><span>}x${</span><span>image_height</span><span>} image..."</span><span>)

    set(exec_command </span><span>"execute_process(</span><span>\n</span><span>"</span><span>)
    </span><span>foreach</span><span>(worker_index RANGE 1 ${num_procs})
        set(exec_command </span><span>"${</span><span>exec_command</span><span>}COMMAND cmake . -Wno-dev -Dworker_index=${</span><span>worker_index</span><span>} -Dimage_width=${</span><span>image_width</span><span>} -Dimage_height=${</span><span>image_height</span><span>} -Dnum_procs=${</span><span>num_procs</span><span>}</span><span>\n</span><span>"</span><span>)
    </span><span>endforeach</span><span>()
    set(exec_command </span><span>"${</span><span>exec_command</span><span>} )"</span><span>)

    </span><span># Begin the worker processes
    </span><span>cmake_language(EVAL CODE ${exec_command})

    message(STATUS </span><span>"Finished ray tracing, gathering results..."</span><span>)
</span></pre>
<p>As per <a href="https://raytracing.github.io/">Ray Tracing in One Weekend</a>, I use the <a href="https://en.wikipedia.org/wiki/Netpbm#PPM_example">PPM image format</a>. This is a really simple text-based format which is perfect for my purposes as I don't have to bother with compression. Once we're done rendering we simply read all the data that the workers have spat out, write the PPM header, and print everything to <code>stderr</code>:</p>
<pre><span>    set(image_contents </span><span>"P3 ${</span><span>image_width</span><span>} ${</span><span>image_height</span><span>}</span><span>\n</span><span>255</span><span>\n\n</span><span>"</span><span>)

    </span><span>foreach</span><span>(worker_index RANGE 1 ${num_procs})
        file(READ </span><span>"worker-${</span><span>worker_index</span><span>}.txt" </span><span>file_contents)
        set(image_contents </span><span>"${</span><span>image_contents</span><span>}${</span><span>file_contents</span><span>}"</span><span>)
    </span><span>endforeach</span><span>()

    message(</span><span>"${</span><span>image_contents</span><span>}"</span><span>)
</span></pre>
<p>The division of work among the worker processes is pretty sub-optimal as the rows towards the top of the image are mostly empty whereas the rows at the bottom are entirely full, which means that some processes finish very fast while others take much longer. Fixing this problem is left as an exercise to the reader.</p>

<p>If you made it this far, thanks for reading! Feel free to create issues, send pull requests or star <a href="https://github.com/64/cmake-raytracer">the code on GitHub</a>.</p>

    </div>

    
    

    

    
        
            
              
        
    
</article></div>]]>
            </description>
            <link>https://64.github.io/cmake-raytracer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25700038</guid>
            <pubDate>Sat, 09 Jan 2021 13:04:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Haskell is a Bad Programming Language (2020)]]>
            </title>
            <description>
<![CDATA[
Score 331 | Comments 286 (<a href="https://news.ycombinator.com/item?id=25699574">thread link</a>) | @fpoling
<br/>
January 9, 2021 | https://blog.shitiomatic.tech/post/haskell-is-a-bad-programming-language/#üëæ | <a href="https://web.archive.org/web/*/https://blog.shitiomatic.tech/post/haskell-is-a-bad-programming-language/#üëæ">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://blog.shitiomatic.tech/post/haskell-is-a-bad-programming-language/#üëæ</link>
            <guid isPermaLink="false">hacker-news-small-sites-25699574</guid>
            <pubDate>Sat, 09 Jan 2021 11:40:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deep neck flexor exercises ‚Äì Back and neck]]>
            </title>
            <description>
<![CDATA[
Score 181 | Comments 110 (<a href="https://news.ycombinator.com/item?id=25699510">thread link</a>) | @whereistimbo
<br/>
January 9, 2021 | https://www.sprintphysio.co.uk/patient-exercises/back-and-neck/deep-neck-flexor-exercises.html | <a href="https://web.archive.org/web/*/https://www.sprintphysio.co.uk/patient-exercises/back-and-neck/deep-neck-flexor-exercises.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="mainContent">
	<div>
        <div id="leftCol_normal">

<h2>Deep neck flexor exercises</h2>
<br>
<h3>Why train them?</h3>
<p>
<img src="https://www.sprintphysio.co.uk/images/patient-exercises/deep_neck_1.jpg"></p><p>The deep neck flexor muscles sit deep in the front of the neck, behind the trachea (windpipe). Because of their close proximity to the vertebrae (spine) and their short length, they have an important role in providing stability to the neck. People with a history of neck or upper back injury, such as whiplash, can show great improvement in pain and function if they strengthen these muscles. Those with postural neck pain often have weakness in these muscles and overuse in the muscles on the top of the shoulders. They too can show a great response to retraining the deep neck flexor muscle group.
</p><br>

<h3>How do I exercise them?</h3>
<h5>Exercise 1</h5>
<p>
<img src="https://www.sprintphysio.co.uk/images/patient-exercises/deep_neck_2.jpg"></p><ul>
<li>Lie on your back with knees comfortably bent. Find your neutral spine position, as explained by your physiotherapist. Use a small rolled towel under the head if needed.</li>
<li>Lift your head off the towel and feel the muscles on the front of the neck. These are NOT the deep neck flexor muscles - these muscles often overwork to try and help with stability, they are not designed for this purpose.</li>
<li>Perform a small nodding movement, as if to look towards your toes. Don't lift your head up. You should not feel the muscles on the front of the neck moving, but rather you should be using the muscles deep behind them.</li>
<li>Hold for 5 seconds. Repeat 10 times.</li>
</ul>
<h5>Exercise 2</h5>
<p>
<img src="https://www.sprintphysio.co.uk/images/patient-exercises/deep_neck_3.jpg"></p><ul>
<li>Position as above.</li>
<li>Place your hand on the side of your head and provide gentle resistance, as if you are bending your head to one side.</li>
<li>Hold for 5 seconds. Repeat 10 times.</li>
<li>Use hand to resist small rotation movement.</li>
<li>Hold for 5 seconds. Repeat 10 times.</li>
</ul>
<h5>Exercise 3</h5>
<p>
<img src="https://www.sprintphysio.co.uk/images/patient-exercises/deep_neck_4.jpg"></p><ul>
<li>Lie on your tummy with hands supporting the forehead.</li>
<li>Perform the small nodding movement and float the head and breastbone off the floor.</li>
<li>Hold for 5 seconds. Repeat 10 times.</li>
</ul>
<h5>Exercise 4a:</h5>
<p>
<img src="https://www.sprintphysio.co.uk/images/patient-exercises/deep_neck_5.jpg"></p><ul>
<li>Stand with your back to the wall and your feet slightly in front, hip width apart. Perform the small nodding movement, while sliding the base of the skull up the wall. You should feel the neck lengthen.</li>
<li>Hold for 5 seconds. Repeat 10 times.</li>
</ul>
<h5>Exercise 4b:</h5>

<ul>
<li>Same as exercise above.</li>
<li>From the lengthened position, move your head away from the wall so that you're looking at the floor.</li>
<li>Then return to the starting position.</li>
<li>Do not allow your chin to poke forward through either movement.</li>
</ul>

<h5>Exercise 4c:</h5>
<p>
<img src="https://www.sprintphysio.co.uk/images/patient-exercises/deep_neck_8.jpg"></p><ul>
<li>Sitting in a chair, look up at the ceiling.</li>
<li>When returning the head back to the neutral position, do not let the chin poke forward.</li>
<li>Curl forward one level at a time, starting from the top.</li>
<li>Do not allow your chin to poke forward.</li>
</ul>
<br>

<h3>Where do I go from here?</h3>
<p>
Once you have mastered these exercises, you should feel more aware of your neck posture and how to position yourself correctly. You can use this knowledge:</p>
<ul>
<li>When sitting at your desk/computer or on the couch.</li>
<li>Performing any weights in the gym or doing exercise classes.</li>
</ul>

<p>

Please <a href="https://www.sprintphysio.co.uk/contact-us/index.html">contact us</a> to book an appointment or for more information on any of the services available at our clinic in Kensington.</p>
<p>
<a href="#top" title="Back To Top">‚Üë Back To Top</a></p>






        </div>
        
		



				
				<p><b>Insurance providers...</b></p><p><img src="https://www.sprintphysio.co.uk/images/insurance-logos.png">
				</p>
				<br>


	</div>
</div><div id="jumpsContainer">
	<div>
			<div id="j1">
				<p><a>Physiotherapy</a></p><p><a href="https://www.sprintphysio.co.uk/services/physiotherapy.html"><img src="https://www.sprintphysio.co.uk/images/physiotherapy-jump.jpg" alt="Physiotherapy" title="Physiotherapy"></a></p>
				<div><p>
					Our physiotherapists specialise in restoring your normal function and movement patterns so you can get on with everyday life. </p></div>
				<p>Read more ¬ª</p>
			</div>
			<div id="j2">
 				<p><a>Pilates</a></p><p><a href="https://www.sprintphysio.co.uk/services/pilates.html"><img src="https://www.sprintphysio.co.uk/images/pilates-jump.jpg" alt="Pilates" title="Pilates"></a></p>
				<div><p>
					Pilates focuses on building the body???s core strength and improving posture through a series of low repetition, low impact stretching and conditioning exercises. </p></div>
				<p>Read more ¬ª</p>
			</div>

            <div id="j3">
            	<p><a>Sports injuries</a></p><p><a href="https://www.sprintphysio.co.uk/services/sports-assessments.html"><img src="https://www.sprintphysio.co.uk/images/sports-injuries-jump.jpg" alt="Sports injuries" title="Sports injuries"></a></p>
				<div><p>
					At Sprint Physiotherapy we are experts at treating a variety of sporting injuries, including; swimming, running, golfing, etc.</p></div>
				<p>Read more ¬ª</p>
			</div>

            <div id="j4">
				<p><a>Massage Therapy</a></p><p><a href="https://www.sprintphysio.co.uk/services/massage.html"><img src="https://www.sprintphysio.co.uk/images/massage-therapy-jump.jpg" alt="Massage Therapy" title="Massage Therapy"></a></p>
				<div><p>
					Our massage therapists specalise in a range of massage techniques; remedial, sports, pregnancy, etc.</p></div>
				<p>Read more ¬ª</p>
			</div>
			

	</div>
</div></div>]]>
            </description>
            <link>https://www.sprintphysio.co.uk/patient-exercises/back-and-neck/deep-neck-flexor-exercises.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25699510</guid>
            <pubDate>Sat, 09 Jan 2021 11:27:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: DevBooks ‚Äì Help Developers find indy books]]>
            </title>
            <description>
<![CDATA[
Score 113 | Comments 31 (<a href="https://news.ycombinator.com/item?id=25698707">thread link</a>) | @simon-holdorf
<br/>
January 9, 2021 | https://thesmartcoder.dev/books/ | <a href="https://web.archive.org/web/*/https://thesmartcoder.dev/books/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-server-rendered="true" id="__nuxt"><!----><div id="__layout"><div data-app="true" id="app" data-v-8b44678a=""><div> <main data-v-8b44678a=""><div><div data-v-405cec28="" data-v-8b44678a=""><div><div data-v-405cec28=""><div data-v-405cec28=""><div> <p data-v-405cec28="">
        Find the best books for developers.
      </p></div></div></div></div></div> <div data-v-8b44678a=""><div data-v-58ecdbbb="" data-v-8b44678a=""><div data-v-58ecdbbb=""><div data-v-58ecdbbb=""><div data-v-58ecdbbb=""><div data-v-58ecdbbb=""><div data-v-58ecdbbb=""><div data-v-58ecdbbb=""><h2>What is DevBooks?</h2> <p>DevBooks helps developers to find the best books for developers and authors to showcase their amazing work. </p></div></div> </div> <div data-v-58ecdbbb=""><div data-v-58ecdbbb=""><div xs="12"><div> <div><h2>
        A React Developer‚Äôs Guide to Hooks
      </h2> <p>by Sebastien Castiel</p> <p>
        React Hooks are awesome, but they are not easy to use every day.
In my experience with React and hooks, I have faced a lot of issues, spent some time debugging to understand where these issues came fr...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Practical Test Automation
      </h2> <p>by Panos Matsinopoulos</p> <p>
        Learn the principles behind test-driven development (TDD) and behavior-driven development (BDD) and see how Jasmine, RSpec and Cucumber can be used to your advantage. This book examines some of the le...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        The Jest Handbook
      </h2> <p>by Hugo Di Francesco</p> <p>
        Learn Advanced JavaScript Testing patterns with Jest.

Take your JavaScript testing to the next level by learning the ins and outs of Jest, the top JavaScript testing library.
      </p></div>  </div></div><div xs="12"><div> <div><h2>
        Practical Bootstrap
      </h2> <p>by Panos Matsinopoulos</p> <p>
        Learn to use one of the most popular CSS frameworks and build mobile-friendly web pages. Used for numerous websites and applications, Bootstrap is a key tool for modern web development.
      </p></div>  </div></div><div xs="12"><div> <div><h2>
        The Coding Career Handbook
      </h2> <p>by Shawn Swyx Wang</p> <p>
        10 hours of audio. 40 chapters. 450+ pages. 1,400+ links to original sources curated over 3 years. Priceless insights from dozens of developers at the top of their fields. Proven ideas, tested by pers...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        The Tech Resume Inside Out
      </h2> <p>by Gergely Orosz</p> <p>
        What a good developer resume looks like, and how to write one. I've reviewed hundreds of developer resumes at tech companies like Microsoft, Skype, and Uber. This guide helps you craft a developer res...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Code Your Way Up
      </h2> <p>by Greg Thomas</p> <p>
        Code Your Way Up is the book for new developers looking to get started in software and asks the hard questions on growth, delivery, and initiative and what you need to think of in order to succeed.  I...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Lean from the Trenches
      </h2> <p>by Henrik Kniberg</p> <p>
        You know the Agile and Lean development buzzwords, you‚Äôve read the books. But when systems need a serious overhaul, you need to see how it works in real life, with real situations and people. Lean fro...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        How to Get a Job in Web Development
      </h2> <p>by RealToughCandy</p> <p>
        "How to Get a Job in Web Development" is designed for junior web developers. 
In this book, you will learn how to:

‚Ä¢ Expertly craft the ‚Äòholy clover‚Äô of application materials: your resume, cover lett...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Master HTML &amp; CSS
      </h2> <p>by Panos Matsinopoulos</p> <p>
        Want to become a Web developer? HTML and CSS are a must for your foundation. And this book takes you from zero to advanced level. From classical hello world things to how you can position elements on ...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Letters To a New Developer
      </h2> <p>by Dan Moore</p> <p>
        Learn what you need to succeed as a developer beyond the code. The lessons in this book will supercharge your career by sharing lessons and mistakes from real developers. 

Wouldn‚Äôt it be nice to lear...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        How To Host, Secure, and Deliver Static Websites on Amazon Web Services
      </h2> <p>by Kyle Galbraith</p> <p>
        "How To Host, Secure, and Deliver Static Websites on Amazon Web Services" is a book and video course that cuts through the sea of information to accelerate your learning of AWS. Giving you a learning ...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        The Road to GraphQL
      </h2> <p>by Robin Wieruch</p> <p>
        The Road to GraphQL is your personal journey to master pragmatic GraphQL in JavaScript. The book is full with applications you are going to build along the way with React.js and Node.js. Afterward, yo...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Portfolio Surgery
      </h2> <p>by RealToughCandy</p> <p>
         In Portfolio Surgery, you'll start with a massive upgrade of the look and feel of your portfolio. You'll learn about common pitfalls, dos and don'ts, and portfolio optimization techniques. Then, in t...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Pure React
      </h2> <p>by Dave Ceddia</p> <p>
        Learning new skills is one of the best ways to invest in yourself.

Knowing React can be the deciding factor in getting hired for a new job, or set you up for a promotion at your current one.

You cou...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        The Good Parts of AWS
      </h2> <p>by Daniel Vassallo</p> <p>
        This is a book by Daniel Vassallo and Josh Pschorr. Between us, we have worked with AWS for 15 years, including 11 years working inside AWS. We have worked on all sorts of web applications, from small...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Practical Vavr
      </h2> <p>by Alexandre Grison</p> <p>
        Practical Vavr is all about making you want to use Vavr in your day to day Java programming.

If you want to improve the quality of your code by using a well-thought and beautifully designed functiona...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Your First Year in Code
      </h2> <p>by Isaac Lyman</p> <p>
        Starting a career in programming can be intimidating. Whether you're switching careers, joining a boot camp, starting a C.S. degree, or learning on your own, Your First Year in Code can help, with pra...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Building an Effective Dev Portfolio
      </h2> <p>by Josh Comeau</p> <p>
        I got so many replies! A couple hundred developers were willing to share their portfolios with me, and I went through as many as I could over the next couple of weeks. I found I kept giving the same f...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        PHP Mentors - Advice from PHP Experts around the world
      </h2> <p>by Fl√°vio Silveira</p> <p>
        Answers from PHP masters around the world for your questions.
Code, Career, Team work, Working environment, Logs, Tests, Future and much more.

PHP Mentors Book is a set of questions with topics that ...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        The Case of IBM 386 PC: A Detective Story for Techies
      </h2> <p>by Jim Grep</p> <p>
        Take a break, have some fun reading a tech mystery story on programming--a first of its kind. A nostalgic story from the early days of IBM PC when some programmers get together to play detective and h...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Freelance Newbie
      </h2> <p>by RealToughCandy</p> <p>
        Are you ready to jump-start your freelance web development career? Freelance Newbie has you covered! In this book, you‚Äôll learn practical, actionable steps you can start using TODAY to get your first ...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        14 Habits of Highly  Productive Developers
      </h2> <p>by Zeno Rocha</p> <p>
        You can learn the most popular frameworks, use the best programming languages, and work at the biggest tech companies, but if you cultivate bad habits, it will be hard for you to become a top develope...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Content for Developers
      </h2> <p>by Maedah Batool</p> <p>
        A whole new workflow to Write. Publish. Market. Authentic &amp; professional content writing meant for developers. Zero bull-shit and to-the-point tips to improve your technical content writing skills. Le...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        A Smart Guide for Your Career as a Software Engineer
      </h2> <p>by Mike Nikles</p> <p>
        I started my software engineer career 20 years ago. Since then, I have interviewed hundreds of candidates and reviewed even more resumes. This book is a guide for your own career, whether you are new ...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        The Outstanding Developer
      </h2> <p>by Sebastien Castiel</p> <p>
        Being a developer is not only about writing code. And improving as a developer is not only about improving in writing code. This book explores how to become an outstanding developer through several ax...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        5 Little Potions
      </h2> <p>by Mark Wilbur</p> <p>
        In 5 Little Potions, you'll begin your journey into Elixir programming by creating increasingly complex games.

You'll start with a simple guessing game. Next you'll work with Elixir Structs in a boar...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Distributed Systems with Node.js
      </h2> <p>by Thomas Hunter II</p> <p>
        In this hands-on guide, author Thomas Hunter II proves that Node.js is just as capable as traditional enterprise platforms for building services that are observable, scalable, and resilient. Intermedi...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Data Analysis with Rust Notebooks
      </h2> <p>by Dr. Shahin Rostami</p> <p>
        A practical book on Data Analysis with Rust Notebooks that teaches you the concepts and how they're implemented in practice.

- All code examples in Rust,
- Rust (Jupyter) Notebooks for each Section,
...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Python re(gex)?
      </h2> <p>by Sundeep Agarwal</p> <p>
        This book will help you learn Python Regular Expressions, a mini-programming language for all sorts of text processing needs.

The book heavily leans on examples to present features of regular express...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        The Road to React
      </h2> <p>by Robin Wieruch</p> <p>
        In "The Road to React" you will learn about all the fundamentals of React.js with Hooks while building a full-blown React application step by step. While you create the React application, every chapte...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Cloud Native Web Development
      </h2> <p>by Mike Nikles</p> <p>
        In this book, we will walk through the end-to-end process of developing a cloud-native web application. You will learn technologies, processes, tips &amp; tricks and gain hands-on experience. You will fin...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        The Road to Firebase
      </h2> <p>by Robin Wieruch</p> <p>
        The Road to React with Firebase is your personal journey to master advanced React for business web applications in JavaScript whereas Firebase is used to replace everything that you would want from a ...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        The Standout Developer
      </h2> <p>by Randall Kanna</p> <p>
        If you‚Äôre tired of the endless job search and feeling like your resume isn‚Äôt being seen, this book will help you craft a great resume that stands out and get it seen by the companies you want. I‚Äôll sh...

 ‚Ä¶</p></div></div></div></div></div></div></div></div></div></div></div></main></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thesmartcoder.dev/books/">https://thesmartcoder.dev/books/</a></em></p>]]>
            </description>
            <link>https://thesmartcoder.dev/books/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25698707</guid>
            <pubDate>Sat, 09 Jan 2021 08:43:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pfizer vaccine appears effective against mutation in new coronavirus variants]]>
            </title>
            <description>
<![CDATA[
Score 629 | Comments 227 (<a href="https://news.ycombinator.com/item?id=25696577">thread link</a>) | @awnird
<br/>
January 8, 2021 | https://www.cbc.ca/news/health/pfizer-biontech-vaccine-appears-effective-against-mutation-in-new-coronavirus-variants-study-suggests-1.5865885 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/health/pfizer-biontech-vaccine-appears-effective-against-mutation-in-new-coronavirus-variants-study-suggests-1.5865885">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Pfizer Inc. and BioNTech's COVID-19 vaccine appeared to work against a key mutation in the highly transmissible new variants of the coronavirus discovered in Britain and South Africa, according to a laboratory study conducted by the U.S. drugmaker.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5852149.1608672062!/cumulusImage/httpImage/image.jpg_gen/derivatives/16x9_780/covid-vaccinations-toronto.jpg"></p></div><figcaption>A nurse prepares a dose of the Pfizer-BioNTech COVID-19 vaccine for care home workers at St. Michael‚Äôs Hospital in Toronto on Dec. 22, 2020.<!-- --> <!-- -->(Evan Mitsui/CBC)</figcaption></figure><p><span><p>Pfizer Inc. and BioNTech's COVID-19 vaccine appeared to work against a key mutation in the highly transmissible new variants of the coronavirus discovered in Britain and South Africa, according to a laboratory study conducted by the U.S. drugmaker.</p>  <p>The study by Pfizer and scientists from the University of Texas Medical Branch, which has not yet been peer-reviewed, indicated the vaccine was effective in neutralizing virus with the so-called N501Y mutation of the spike protein.</p>  <p>The mutation could be responsible for greater transmissibility and there had been concern it could also make the virus escape antibody neutralization elicited by the vaccine, said Phil Dormitzer, one of Pfizer's top viral vaccine scientists.</p>  <p>The first results of tests on the variants offer a glimmer of hope while more studies are carried out as Britain and other countries try to tame the more infectious variants that&nbsp;authorities believe are driving a surge in infections that could overwhelm health-care systems.</p>  <p>The Pfizer-BioNTech study was conducted on blood taken from people who had been given the vaccine. Its findings are limited because it does not look at the full set of mutations found in either of the new variants of the rapidly spreading virus.</p>  <p>Dormitzer said it was encouraging that the vaccine appears effective against the mutation, as well as 15 other mutations the company has previously tested against.</p>  <p>"So we've now tested 16 different mutations, and none of them have really had any significant impact. That's the good news," he said. "That doesn't mean that the 17th won't."</p>  <p><em><strong>WATCH | What scientists know about the new coronavirus variant:</strong></em></p>  <p><span><span><div><div title="What scientists know about the new coronavirus variant" role="button" tabindex="0"><div><div aria-labelledby="1842141251676-metadata-" title="What scientists know about the new coronavirus variant"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/643/819/COVID-VARIANT-SCI-BIRAK-080121.jpg" alt="" loading="lazy"></p></div></div></div></div></div><span>The B1-17 coronavirus variant, first discovered in the U.K., is now in at least 40 countries, including Canada. It has 23 mutations, including one that attaches to healthy cells like a key going into a lock.<!-- --> <!-- -->1:56</span></span></span></p>  <p>Dormitzer said another mutation found in the South African variant, called the E484K mutation, was also concerning.</p>  <p>The researchers plan to run similar tests to establish whether the vaccine is effective against other mutations found in the British and South African variants and hope to have more data within weeks.</p>  <p>The variants are said by scientists to be more transmissible than previously dominant ones, but they are not thought to cause more serious illness.</p>  <p>The virus's spikes act as a key that must unlock our cells to cause the infection.&nbsp;The variant first identified in the U.K. has a mutation that appears to make it easier for the coronavirus to grab hold of the lock more tightly, scientists say.</p>    <p>Scientists said the results of the study would help calm concerns that people will not be protected by vaccines being given to millions of people around the world in the fight against the pandemic, which has killed more than 1.8 million people and roiled economies.</p>  <p>But they cautioned that more clinical tests and data are still needed to come to a definitive conclusion.</p>  <p>"This is good news, mainly because it is not bad news," said Stephen Evans, professor of pharmacoepidemiology at the&nbsp;London School of Hygiene &amp; Tropical Medicine.</p>  <p>"So, yes this is good news, but it does not yet give us total confidence that the Pfizer (or other) vaccines will definitely give protection."</p>  <h2>AstraZeneca, Moderna, CureVac testing against variants</h2>  <p>AstraZeneca, Moderna and CureVac are also testing whether their shots work against the fast-spreading variants. They have said they expect them to be effective, but the timing of those studies is not known.</p>  <p>A senior British lawmaker expressed concerns in an interview on Friday that COVID-19 vaccines might not work properly against the South African variant. He was not responding to questions about Friday's data.</p>  <p>The Pfizer-BioNTech vaccine and the one from Moderna Inc., which use synthetic messenger RNA technology, can be quickly tweaked to address new mutations of a virus if necessary. Scientists have suggested the changes could be made in as little as six weeks.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5866498.1610132224!/cpImage/httpImage/image.jpg_gen/derivatives/original_300/virus-outbreak-new-variants.jpg 300w,https://i.cbc.ca/1.5866498.1610132224!/cpImage/httpImage/image.jpg_gen/derivatives/original_460/virus-outbreak-new-variants.jpg 460w,https://i.cbc.ca/1.5866498.1610132224!/cpImage/httpImage/image.jpg_gen/derivatives/original_620/virus-outbreak-new-variants.jpg 620w,https://i.cbc.ca/1.5866498.1610132224!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/virus-outbreak-new-variants.jpg 780w,https://i.cbc.ca/1.5866498.1610132224!/cpImage/httpImage/image.jpg_gen/derivatives/original_1180/virus-outbreak-new-variants.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5866498.1610132224!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/virus-outbreak-new-variants.jpg"></p></div><figcaption>Graphic shows a diagram of the COVID-19 virus.<!-- --> <!-- -->(AP)</figcaption></figure></span></p>  <p>Some other vaccines to protect against COVID-19 also use the spike protein to show our immune system what the enemy looks like.</p>  <p>Canadian microbiologist Benjamin tenOever, a professor at the&nbsp;Icahn School of Medicine at Mount Sinai in New York,&nbsp;said our immune system learns to recognize and attack the viral attachment protein at many different sites.</p>  <p>"It would require many many mutations to render our vaccines non-effective,"&nbsp;tenOever&nbsp;said.</p>  <p>The variant is also not the first of the pandemic to emerge and Eleanor Riley, professor of immunology and infectious disease at the University of Edinburgh, said these types of studies&nbsp;will be needed as they appear.</p>  <p>"It may be necessary to tweak the vaccine over time," she said.</p>  <p>Dr. Theresa Tam, Canada's chief public health officer, said Friday that 14 cases of the variant first reported in the U.K. have been reported in Canada.</p>  <p>Researchers in Ontario have developed a faster test to identify variants.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/health/pfizer-biontech-vaccine-appears-effective-against-mutation-in-new-coronavirus-variants-study-suggests-1.5865885</link>
            <guid isPermaLink="false">hacker-news-small-sites-25696577</guid>
            <pubDate>Sat, 09 Jan 2021 03:48:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing an iRacing SDK Implementation in F#]]>
            </title>
            <description>
<![CDATA[
Score 80 | Comments 26 (<a href="https://news.ycombinator.com/item?id=25696493">thread link</a>) | @sanesmith
<br/>
January 8, 2021 | https://markjames.dev/2021-01-08-writing-an-iracing-sdk-implementation-fsharp/ | <a href="https://web.archive.org/web/*/https://markjames.dev/2021-01-08-writing-an-iracing-sdk-implementation-fsharp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article role="main">
        <p>In my <a href="https://markjames.dev/2021-01-04-why-learning-fsharp-2021/">previous post</a>, I discussed how I‚Äôve decided to learn F# in 2021 for a number of reasons. Around the same time, I also happened to setup my Sim Racing rig so that I could continue to play <a href="https://www.iracing.com/" target="_blank">iRacing</a> with my VR headset (HTC Vive). Its been several years since I‚Äôve last played, but with COVID-related curfews being implemented here in Montreal tomorrow, I‚Äôve been increasingly taking up home-based pursuits which I didn‚Äôt always have the time for pre-lockdown. Since the last time I played iRacing, I‚Äôm running a PC with a much better processor, motherboard, and only SSDs. The VR performance has been a huge leap forward since I used to play with my old machine and I was quite impressed. After spending a couple of hours setting up, here‚Äôs what my current humble racing setup looks like:</p>

<p><img src="https://markjames.dev/img/posts/irsdk-fsharp/racing-rig.jpg" width="650" height="488" alt="Photo of my current iRacing VR setup"></p>

<p>Having a dedicated table really helps, as in my old apartment it was fairly difficult to setup a station with limited space, but now I can fortunately just jump in. Despite the past limitations, I was able to get fairly competitive and still remember the thrill of my first win agaisnt a field of real racers in a Mazda MX-5:</p>

<p><img src="https://markjames.dev/img/posts/irsdk-fsharp/iracing-win.jpg" width="500" height="279" alt="Photo of my iRacing first win certificate"></p>

<p>Inspired by setting everything up and doing some laps to practice for an eventual return to comeptition, I started thinking about how I once experimented with using the <a href="https://github.com/kutu/pyirsdk" target="_blank">Python implementation</a> of the iRacing SDK to connect to an arduino and display a speedometer readout in realtime on a small screen. In reminiscing about the experience, I thought about how I could look into writing an F# implementation of the SDK as a learning project. In addition to learning through the project, it also has the benefit of being of use in a future project involving an iRacing stats tracker web app that I‚Äôve been thinking about writing as a project for my upcoming <a href="https://markjames.dev/2020-12-09-back-to-school/">cloud computing courses</a>.</p>

<h2 id="getting-started">Getting Started</h2>

<p>I tend to learn best when projects are slightly outside of my comfort zone, and this would be both my first time writing a library, as well as writing one in a functional language! Having used an array of libraries at this point, I had some confidence in choosing an organizational structure, and the Python implementation is only <a href="https://github.com/kutu/pyirsdk/blob/master/irsdk.py" target="_blank">739 lines of code</a> which felt doable compared to some of the larger libraries out there.</p>

<p>Moreover, the python implementation of the SDK has the ability to:</p>

<ul>
  <li>Get session data (WeekendInfo, SessionInfo, etc‚Ä¶)</li>
  <li>Get live telemetry data (Speed, FuelLevel, etc‚Ä¶)</li>
  <li>Broadcast messages (camera, replay, chat, pit and telemetry commands)</li>
</ul>

<p>and I figured that this would be a good featureset to aim for in the final version of the F# SDK. Out of these features, the session data and live telemetry data would be the ones I plan to implement first.</p>

<h2 id="creating-the-library">Creating the Library</h2>

<p>After coming up with some desired features, the first step was to create a new FSharp solution called iRacingFSharp. Inside the solution, I created two projects. One was our actual library, called iRacingFSharp, and the other was a basic console app called SDKReader (located in the Examples Folder) to test the functionality of the library as I worked on it. Note, if you‚Äôd like to see the full codebase you can <a href="https://github.com/markjamesm/irsdk-fsharp" target="_blank">here on github</a>.</p>

<h2 id="the-first-function">The First Function</h2>

<p>Starting small, I decided that a good first function would be to find out the state of the simulator. Fortunately, the iRacing SDK allows you to check if the sim is running using the following URL which points to a localhost server:</p>

<div><div><pre><code>http://127.0.0.1:32034/get_sim_status?object=simStatus
</code></pre></div></div>
<p>Getting this URL in Postman returns a JSON object which looks like this:</p>

<div><div><pre><code>var simStatus={
   running:0 // 1 if the sim is running
};
</code></pre></div></div>

<p>I decided to make use of the <a href="https://fsharp.github.io/FSharp.Data/library/Http.html" target="_blank">F# Data HTTP library</a> in order to download the response and so I installed it from NuGet at this point.</p>

<p>Next, inside my iRacingFSharp project I created a file called Irsdk.fs and wrote the following code:</p>

<div><div><pre><code><span>namespace</span> <span>IrsdkFS</span>

<span>open</span> <span>FSharp</span><span>.</span><span>Data</span>

<span>///&lt;summary&gt;F# implementation of the iRacing SDK.&lt;/summary&gt;</span>
<span>module</span> <span>IrsdkFS</span> <span>=</span>

    <span>///&lt;summary&gt;Returns the simStatus in string format&lt;/summary&gt;</span>
    <span>let</span> <span>SimStatus</span><span>()</span> <span>=</span>
        <span>let</span> <span>simStatusURL</span> <span>=</span> <span>"http://127.0.0.1:32034/get_sim_status?object=simStatus"</span>
        <span>let</span> <span>simStatusObject</span> <span>=</span> <span>Http</span><span>.</span><span>RequestString</span><span>(</span><span>simStatusURL</span><span>)</span>
        <span>simStatusObject</span>
</code></pre></div></div>

<p>In the above code, I‚Äôve created a module which contains a function called SimStatus that takes no parameters. It then binds the JSON response to simStatusURL and passes it to the HTTP library via Http.RequestString(). Finally, simStatusObject is returned in string format which can be parsed further by another function in a later step.</p>



<p>With this simple function in place, the next step was to create SDKReader.fs inside my SDKReader console app. This file contained code to call the SimStatus() function and print the output:</p>

<div><div><pre><code><span>[&lt;</span><span>EntryPoint</span><span>&gt;]</span>
<span>let</span> <span>main</span> <span>argv</span> <span>=</span>
    <span>let</span> <span>test</span> <span>=</span> <span>IrsdkFS</span><span>.</span><span>SimStatus</span><span>()</span>
    <span>printf</span> <span>"%s"</span> <span>test</span>
    <span>0</span> <span>// return an integer exit code</span>
</code></pre></div></div>

<p>Running dotnet build inside the SDKReader folder displayed the following output while iRacing was running:</p>

<div><div><pre><code><span>"var simStatus={
   running:1
};
"</span><span>
</span></code></pre></div></div>

<p>Success! With this method working, we now have the very beginnings of an F# implementation of the iRacing SDK! Although it is a small step, we were also able to create and structure the project. Lastly, I also setup a a basic .NET build through Github Actions for CI.</p>



<p>iRacing‚Äôs API telemetry comes in three variations; data written to a .ibt file 60 times a second, live data exposed to the telemetry API 60 times per second, and a session string in YAML format that contains more or less static information about the session. The YAML string is appended to the end of the .ibt file but only a small portion of that data is exposed. This means that going forward, I‚Äôll need to look into parsing the YAML as well as mapping more of the API endpoints. The iRacing API appears to be nonstandard and so it may take a little more work than just a typical REST API.</p>

<p>Stay tuned for Part Two where I plan to implement some telemetry functions and look into parsing the aforementioned YAML. In addition, be sure to follow along with the <a href="https://github.com/markjamesm/irsdk-fsharp" target="_blank">Github Repo here</a> if you‚Äôre interested in seeing how to project progresses (or would like to contribute)!</p>

      </article></div>]]>
            </description>
            <link>https://markjames.dev/2021-01-08-writing-an-iracing-sdk-implementation-fsharp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25696493</guid>
            <pubDate>Sat, 09 Jan 2021 03:42:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Archive of 43k+ Donald Trump Twitter Screenshots]]>
            </title>
            <description>
<![CDATA[
Score 92 | Comments 30 (<a href="https://news.ycombinator.com/item?id=25693054">thread link</a>) | @soheilpro
<br/>
January 8, 2021 | https://pikaso.me/blog/donald-trump-twitter-archive | <a href="https://web.archive.org/web/*/https://pikaso.me/blog/donald-trump-twitter-archive">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <div>


    <section>
      <p>
        <h2>Donald Trump Twitter Screenshot Archive</h2>
      </p>
      
        
      

      <div><p>Donald Trump loves to tweet and everyone knows that.
Twitter is his favorite medium to express his ideas and to communicate with the world.
He has been an active Twitter user since 2009. Much longer than many other world leaders.</p>
<p>Last month (May 2020) he tweeted 845 times √¢‚Ç¨‚Äù that's 28 tweets per day on average!</p>
<center>
  <a href="https://twitter.com/realDonaldTrump/status/491324429184823296"><img src="https://pikaso.me/blog/files/pikaso.me-realDonaldTrump-20140721_205046-491324429184823296.png" alt="Trump Tweet" width="500" height="244"></a>
</center>
<p>A while ago we received a request from one of our users who was looking for a way to screenshot all Donald Trump tweets.
We realized that's a good opportunity to put <a href="https://pikaso.me/">Pikaso</a> into test and see if it can perform such a task without any problems.
It went smoothly and there was only an issue with one of his tweets which included a deleted image.</p>
<p>Today, we are releasing the resulting files to the public.
This archive contains screenshots of 43,475 Donald Trump tweets from May 2009 to May 2020.
Whether you are pro- or anti- Trump, this is an important part of Internet history that we believe should be preserved.</p>
<h3 id="download">Download</h3>
<p>The Donald Trump Twitter Screenshot Archive can be downloaded through the following links:</p>
<ul>
<li><a href="https://pikaso.me/go/trump-twitter-archive-v1.zip">trump_twitter_archive_v1.zip</a> (Direct download, 2.6 GB)</li>
<li><a href="https://pikaso.me/go/trump-twitter-archive-v1.torrent">trump_twitter_archive_v1.torrent</a> (Torrent download, 28.2 KB)</li>
</ul>
<h3 id="howthiswasmade">How This Was Made?</h3>
<p>To create this archive, we first extracted all tweet ids from the realDonaldTrump.csv file that was provided to us.
That file only contained Donald Trump tweets up to March 29, 2020. To get the later tweets, we used <a href="http://trumptwitterarchive.com/">trumptwitterarchive.com</a>.</p>
<p>We then used the <a href="https://pikaso.me/api">Pikaso API</a> to screenshot each individual tweet.</p>
<h3 id="updates">Updates</h3>
<p>We have no plans to keep this archive up to date after the initial release.
However, if you are interested in doing so, you can use <a href="https://pikaso.me/">Pikaso</a>.
You can even <a href="https://pikaso.me/automate">automate</a> it so that each time he tweets, an automatic screenshot is taken.</p>
<h3 id="credit">Credit</h3>
<p>All the tweets are copyright https://twitter.com/realdonaldtrump.<br>
All the media embedded in tweets are copyright their respective owners.<br>
Original tweets data provided by <a href="https://twitter.com/twentysox">@twentysox</a>.</p>
<h3 id="copyrightlicense">Copyright &amp; License</h3>
<p>Copyright ¬© 2020 https://pikaso.me.<br>
This work by https://pikaso.me is licensed under <a href="https://creativecommons.org/licenses/by/4.0">CC BY 4.0</a>.</p>
<h3 id="contact">Contact</h3>
<p>If you have any feedback or questions regarding this work, please <a href="https://pikaso.me/contact">contact us</a>.</p></div>
    </section>

    

    
      <section>
        <h2>More from the Blog</h2>

        
      </section>
    

      </div>
  
</div></div>]]>
            </description>
            <link>https://pikaso.me/blog/donald-trump-twitter-archive</link>
            <guid isPermaLink="false">hacker-news-small-sites-25693054</guid>
            <pubDate>Sat, 09 Jan 2021 00:14:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Semantic Web, Syllogism, and Worldview (2003)]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 11 (<a href="https://news.ycombinator.com/item?id=25691623">thread link</a>) | @cratermoon
<br/>
January 8, 2021 | https://www.karmak.org/archive/2004/06/semantic_syllogism.html | <a href="https://web.archive.org/web/*/https://www.karmak.org/archive/2004/06/semantic_syllogism.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.karmak.org/archive/2004/06/semantic_syllogism.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25691623</guid>
            <pubDate>Fri, 08 Jan 2021 22:58:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ruby 3, Concurrency and the Ecosystem]]>
            </title>
            <description>
<![CDATA[
Score 235 | Comments 58 (<a href="https://news.ycombinator.com/item?id=25690212">thread link</a>) | @ksec
<br/>
January 8, 2021 | https://kirshatrov.com/2021/01/06/ruby-concurrency-and-ecosystem/ | <a href="https://web.archive.org/web/*/https://kirshatrov.com/2021/01/06/ruby-concurrency-and-ecosystem/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <p><span>06 Jan 2021</span></p><p>With the <a href="http://www.ruby-lang.org/en/news/2020/12/25/ruby-3-0-0-released/" target="\_blank">Ruby 3.0 release</a>, there‚Äôs been a lot of chatter about concurrency, parallelism, and async IO.</p>

<p>For my own reflection, I wanted to write down what that means for performance and capacity/costs of apps, and what would be the impact on the Ruby ecosystem.</p>

<p>I will assume that the audience already knows the difference between <a href="https://en.wikipedia.org/wiki/Thread_(computing)#Threads_vs._processes_pros_and_cons" target="\_blank">threads vs processes model in UNIX</a> and the <a href="https://en.wikipedia.org/wiki/Little%27s_law" target="\_blank">Little‚Äôs law</a>.</p>

<p>
Updated on Jan 9, 2021: thanks to the feedback from <a href="https://github.com/ioquatix" target="_blank">Samuel Williams</a>, I‚Äôve revised the post with findings from <a href="https://github.com/socketry/falcon" target="_blank">Falcon</a>, the async web server written in Ruby.</p>

<h2 id="learning-from-python">Learning from Python</h2>

<p>It‚Äôs always good to take learnings from other languages. There‚Äôs an excellent <a href="http://calpaterson.com/async-python-is-not-faster.html" target="\_blank">write-up ‚ÄúAsync Python is not faster‚Äù by Cal Paterson</a>.</p>

<p>It argues that process-based (aka forking) web servers <strong>show better latencies for web requests</strong> when they are compared to async IO-powered servers.</p>

<p>But why? That‚Äôs because async IO brings co-operative scheduling, which means that the execution is only yielded upon language keywords like <code>await</code>.</p>

<p>Quoting the author, this means that execution time is not distributed ‚Äúfairly‚Äù and one thread can inadvertently starve another of CPU time while it is working. This is why latency is more erratic.</p>

<blockquote>
  <p>In contrast, traditional sync webservers use the pre-emptive multi-processing of the kernel scheduler, which works to ensure fairness by periodically swapping processes out from execution. This means that time is divided more fairly and that latency variance is lower.</p>
</blockquote>

<h2 id="learning-from-falcon">Learning from Falcon</h2>

<p>
(added on Jan 9, 2021)
</p>

<p><a href="https://github.com/socketry/falcon">Falcon</a> is a multi-process, multi-fiber HTTP server written in Ruby that is already utilizing async IO.</p>

<p>It has a great <a href="https://github.com/socketry/falcon-benchmark">set of benchmarks</a> that let us compare Falcon‚Äôs async IO with other non-async web servers like Passenger, Puma and Unicorn. Those benchmarks have been showing that <strong>async IO-powered server like Falcon</strong> provides better latencies on web requests.</p>

<p>Interestingly, that‚Äôs a very different story than Python! Looking at Python, I‚Äôve expected that the thread driven server should be more ‚Äúbalanced‚Äù but it turns out the opposite.</p>

<p>Falcon‚Äôs authors explain that the fiber scheduler naturally scales according to load much better than the worker pool implementation in Puma. When fibers are busy handling requests, they don‚Äôt call <code>accept</code> so the requests are naturally picked up by other workers who are less busy.</p>

<h3 id="what-does-that-mean-for-us-ruby-developers">What does that mean for us Ruby developers?</h3>

<p>Scheduling threads and fibers is nuanced, and you can see that similar approaches demonstrate different results on Python and Ruby/Falcon examples.</p>

<p>In the first revision of this post, I‚Äôve argued that async IO may often increase the latency. Thanks to the data <a href="https://github.com/socketry/falcon-benchmark">shown</a> by Samuel Williams, we can see that‚Äôs not the case.</p>

<p>One of the benefits of async IO is that concurrency is archived by the <code>yield</code>/<code>await</code> instruction, not by the constant interrupt of threads. Every interrupt causes the context switch - and it‚Äôs nice to reduce context switching where we can because scheduler switching from one task to another always adds a little overhead. Since that happens thousands of times every second, <strong>less context switching would mean fewer CPU cycles wasted</strong>.</p>

<h2 id="where-does-ractor-fit-in">Where does Ractor fit in?</h2>

<p>The Ractor pattern allows parallel execution (which wasn‚Äôt possible in Ruby before) of more than one Ruby thread by limiting the shared state of a block of code that you want to execute in parallel. Those ‚Äúblocks of code‚Äù (aka ‚Äúactors‚Äù) can also talk to each other through messages. This is the <a href="https://en.wikipedia.org/wiki/Actor_model">Actor model</a> used in other languages.</p>

<p>There are two ways we could leverage Ractors for modern apps: from the top (wrap every worker into a Ractor) and from the bottom (selectively use Ractors within existing code to parallelize CPU-intensive work).</p>

<p>While I see more to be gained from the top way, it seems like there‚Äôs so much shared and mutable state in Ruby libraries that it‚Äôs going to be quite tricky, although not impossible. It will likely take some efforts and at least a year of work from the community to push libraries towards less shared state. For the next year, we‚Äôll mostly see Ractor maturing and getting adopted in the ‚Äúbottom‚Äù use cases.</p>

<h2 id="impact-on-the-ruby-ecosystem">Impact on the Ruby ecosystem</h2>

<p><strong>By itself, async IO will help to use CPU more efficiently by reducing context switching.</strong></p>

<p>Better support for async IO in Ruby 3.0 will increase community‚Äôs adoption of async web servers like Falcon, and will hopefully give birth to async background job systems.</p>

<p>Having Sidekiq execute jobs concurrently through the async IO and event loop instead of threads could increase the throughput and save CPU work, especially for IO-bound workloads like webhook delivery.</p>

<p><strong>We‚Äôll need to push the Ruby ecosystem to have less shared state to fully leverage the Ractor pattern.</strong> That will take us some time.</p>

<p>If you‚Äôve enjoyed reading this, I highly recommend to read <em><a href="http://wjwh.eu/posts/2020-12-28-ruby-fiber-scheduler-c-extension.html" target="\_blank">Ruby 3.0 and the new FiberScheduler interface</a></em> by Wander Hillen.</p>

<p>Thanks to Samiel Williams and to Julik Tarkhanov for providing early feedback on this post.</p>

<p>I‚Äôm looking forward to hearing your thoughts on this in the comments!</p>

</div></div>]]>
            </description>
            <link>https://kirshatrov.com/2021/01/06/ruby-concurrency-and-ecosystem/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25690212</guid>
            <pubDate>Fri, 08 Jan 2021 20:44:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Smooth Voxel Terrain, Part 2 (2012)]]>
            </title>
            <description>
<![CDATA[
Score 142 | Comments 19 (<a href="https://news.ycombinator.com/item?id=25690189">thread link</a>) | @fanf2
<br/>
January 8, 2021 | https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/ | <a href="https://web.archive.org/web/*/https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<p><a href="https://0fps.wordpress.com/2012/07/10/smooth-voxel-terrain-part-1/">Last time</a> we formulated the problem of isosurface extraction and discussed some general approaches at a high level.&nbsp; Today, we‚Äôre going to get very specific and look at meshing in particular.</p>
<p>For the sake of concreteness, let us suppose that we have approximated our potential field <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="f" title="f"> by sampling it onto a cubical grid at some fixed resolution.&nbsp; To get intermediate values, we‚Äôll just interpolate between grid points using the standard <a href="http://paulbourke.net/miscellaneous/interpolation/">trilinear interpolation</a>.&nbsp; This is like a <img src="https://s0.wp.com/latex.php?latex=C%5E0&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="C^0" title="C^0"> generalization of Minecraft-style voxel surfaces.&nbsp; Our goal in this article is to figure out how to extract a mesh of the implicit surface (or zero-crossings of <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="f" title="f">).&nbsp; In particular, we‚Äôre going to look at three different approaches to this problem:</p>
<h2>Marching Cubes</h2>
<p>By far the most famous method for extracting isosurfaces is the <a href="http://en.wikipedia.org/wiki/Marching_cubes">marching cubes</a> algorithm. &nbsp;In fact, it is so popular that the term `marching cubes‚Äô is even more popular than the term `isosurface‚Äô (at least according to Google)!&nbsp;&nbsp; It‚Äôs quite a feat when an algorithm becomes more popular than the problem which it solves!&nbsp; The history behind this method is very interesting.&nbsp; It was originally <a href="http://dl.acm.org/citation.cfm?id=37422">published back in SIGGRAPH 87</a>, and then summarily patented by the Lorensen and Cline. &nbsp;This fact has caused a lot of outrage, and is been widely cited as one of the classic examples of patents hampering innovation.&nbsp; Fortunately, the patent on marching cubes expired back in 2005 and so today you can freely use this algorithm in the US with no fear of litigation.</p>
<p>Much of the popularity of marching cubes today is due in no small part to a famous article written by <a href="http://paulbourke.net/">Paul Bourke</a>. &nbsp;Back in 1994 he made a webpage called <a href="http://paulbourke.net/geometry/polygonise/">‚ÄúPolygonizing a Scalar Field‚Äù</a>, which presented a short, self-contained reference implementation of marching cubes (derived from some earlier work by Cory Gene Bloyd.)&nbsp; That tiny snippet of a C program is possibly <strong><em>the most copy-pasted code of&nbsp;<span>all time</span></em></strong>. &nbsp;I have seen some variation of Bloyd/Bourke‚Äôs code in <strong>every</strong> implementation of marching cubes that I‚Äôve ever looked at, without exception.&nbsp; There are at least a couple of reasons for this:</p>
<ol>
<li>Paul Bourke‚Äôs exposition is really good. &nbsp;Even today, with many articles and tutorials written on the technique, none of them seem to explain it quite as well.&nbsp; (And I don‚Äôt have any delusions that I will do any better!)</li>
<li>Also their implementation is very small and fast. &nbsp;It uses some clever tricks like a precalculated edge table to speed up vertex generation.&nbsp; It is difficult to think of any non-trivial way to improve upon it.</li>
<li>Finally, marching cubes is incredibly difficult to code from scratch.</li>
</ol>
<p>This last point needs some explaining, &nbsp;Conceptually, marching cubes is rather simple. &nbsp;What it does is sample the implicit function along a grid, and then checks the sign of the potential function at each point (either +/-). &nbsp;Then, for every edge of the cube with a sign change, it finds the point where this edge intersects the volume and adds a vertex (this is just like ray casting a bunch of tiny little segments between each pair of grid points).&nbsp; The hard part is figuring out how to stitch some surface between these intersection points.&nbsp; Up to the position of the zero crossings, there are&nbsp;<img src="https://s0.wp.com/latex.php?latex=2%5E8+%3D+256&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="2^8 = 256" title="2^8 = 256"> different possibilities, each of which is determined by the sign of the function at the 8 vertices of the cube:</p>
<p><a href="http://en.wikipedia.org/wiki/File:MarchingCubes.svg"><img loading="lazy" data-attachment-id="561" data-permalink="https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/marchingcubes/" data-orig-file="https://0fps.files.wordpress.com/2012/07/marchingcubes.png" data-orig-size="501,236" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="marchingcubes" data-image-description="<p>Some of the marching cubes special cases.  (c) WIkipedia, created by Jean-Marie Favreau.</p>
" data-medium-file="https://0fps.files.wordpress.com/2012/07/marchingcubes.png?w=300" data-large-file="https://0fps.files.wordpress.com/2012/07/marchingcubes.png?w=501" title="marchingcubes" alt="" src="https://0fps.files.wordpress.com/2012/07/marchingcubes.png?w=300&amp;h=141" height="141" width="300" srcset="https://0fps.files.wordpress.com/2012/07/marchingcubes.png?w=300&amp;h=141 300w, https://0fps.files.wordpress.com/2012/07/marchingcubes.png?w=150&amp;h=71 150w, https://0fps.files.wordpress.com/2012/07/marchingcubes.png 501w" sizes="(max-width: 300px) 100vw, 300px"></a></p>
<p>Some of the marching cubes special cases. &nbsp;(c) Wikipedia, created by Jean-Marie Favreau.</p>
<p>Even worse, some of these cases are ambiguous!&nbsp; The only way to resolve this is to somewhat arbitrarily break the symmetry of the table based on a case-by-case analysis. What a mess!&nbsp; Fortunately, if you just download Bloyd/Bourke‚Äôs code, then you don‚Äôt have to worry about any of this and everything will just work. &nbsp;No wonder it gets used so much!</p>
<h2>Marching Tetrahedra</h2>
<p>Both the importance of isosurface extraction and the perceived shortcomings of marching cubes motivated the search for alternatives. &nbsp;One of the most popular was the <a href="http://search.ieice.org/bin/summary.php?id=e74-d_1_214">marching tetrahedra</a>, introduced by Doi and Koide.&nbsp; Besides the historical advantage that marching tetrahedra was not patented, it does have a few technical benefits:</p>
<ol>
<li>Marching tetrahedra does not have ambiguous topology, unlike marching cubes.&nbsp; As a result, surfaces produced by marching tetrahedra are always manifold.</li>
<li>The amount of geometry generated per tetrahedra is much smaller, which might make it more suitable for use in say a geometry shader.</li>
<li>Finally, marching tetrahedra has only <img src="https://s0.wp.com/latex.php?latex=2%5E4+%3D+16&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="2^4 = 16" title="2^4 = 16"> cases, a number which can be further reduced to just 3 special cases by symmetry considerations. &nbsp;This is enough that you can work them out by hand.</li>
</ol>
<p><strong>Exercise:&nbsp; </strong>Try working out the cases for marching tetrahedra yourself. &nbsp;(It is really not bad.)</p>
<p>The general idea behind marching tetrahedra is the same as marching cubes, only it uses a tetrahedral subdivision. &nbsp;Again, the standard reference for practical implementation is Paul Bourke (<a href="http://local.wasp.uwa.edu.au/~pbourke/geometry/polygonise/">same page as before</a>, just scroll down a bit.) &nbsp;While there is a lot to like about marching tetrahedra, it does have some draw backs. &nbsp;In particular, the meshes you get from marching tetrahedra are typically about 4x larger than marching cubes. &nbsp;This makes both the algorithm and rendering about 4x slower. &nbsp;If your main consideration is performance, you may be better off using a cubical method. &nbsp;On the other hand, if you really need a manifold mesh, then marching tetrahedra could be a good option. &nbsp;The other nice thing is that if you are obstinate and like to code everything yourself, then marching tetrahedra may be easier since there aren‚Äôt too many cases to check.</p>
<h2>The Primal/Dual Classification</h2>
<p>By now, both marching cubes and tetrahedra are quite old. &nbsp;However, research into isosurface extraction hardly stopped in the 1980s.&nbsp; In the intervening years, many new techniques have been developed. &nbsp;One general class of methods which has proven very effective are the so-called `dual‚Äô schemes. &nbsp;The first dual method, surface nets, was proposed by Sarah Frisken Gibson in 1999:</p>
<p>S.F. Gibson, (1999) ‚Äú<a href="http://www.merl.com/papers/docs/TR99-24.pdf" target="_blank">Constrained Elastic Surface Nets</a>‚Äù&nbsp; Mitsubishi Electric Research Labs, Technical Report.</p>
<p>The main distinction between dual and primal methods (like marching cubes) is the way they generate surface topology.&nbsp; In both algorithms, we start with the same input: a volumetric mesh determined by our samples, which I shall take the liberty of calling a&nbsp;<em>sample complex</em> for lack of a better term.&nbsp; If you‚Äôve never heard of the word&nbsp;<a href="http://www.inperc.com/wiki/index.php?title=Cell_complex">cell complex</a>&nbsp;before, you can think of it as an n-dimensional generalization of a triangular mesh, where the `cells‚Äô or facets don‚Äôt have to be simplices.</p>
<p>In the sample complex, vertices (or 0-cells) correspond to the sample points; edges (1-cells) correspond to pairs of nearby samples; faces (2-cells) bound edges and so on:</p>
<p><img loading="lazy" data-attachment-id="534" data-permalink="https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/samplecomplex/" data-orig-file="https://0fps.files.wordpress.com/2012/07/samplecomplex.png" data-orig-size="533,419" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="samplecomplex" data-image-description="" data-medium-file="https://0fps.files.wordpress.com/2012/07/samplecomplex.png?w=300" data-large-file="https://0fps.files.wordpress.com/2012/07/samplecomplex.png?w=533" title="samplecomplex" alt="" src="https://0fps.files.wordpress.com/2012/07/samplecomplex.png?w=300&amp;h=235" height="235" width="300" srcset="https://0fps.files.wordpress.com/2012/07/samplecomplex.png?w=300&amp;h=235 300w, https://0fps.files.wordpress.com/2012/07/samplecomplex.png?w=150&amp;h=118 150w, https://0fps.files.wordpress.com/2012/07/samplecomplex.png 533w" sizes="(max-width: 300px) 100vw, 300px"></p>
<p>Here is an illustration of such a complex. &nbsp;I‚Äôve drawn the vertices where the potential function is negative black, and the ones where it is positive white.</p>
<p>Both primal and dual methods walk over the sample complex, looking for those cells which cross the 0-level of the potential function. &nbsp;In the above illustration, this would include the following faces:</p>
<p><img loading="lazy" data-attachment-id="535" data-permalink="https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/boundarycells/" data-orig-file="https://0fps.files.wordpress.com/2012/07/boundarycells.png" data-orig-size="533,419" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="boundarycells" data-image-description="" data-medium-file="https://0fps.files.wordpress.com/2012/07/boundarycells.png?w=300" data-large-file="https://0fps.files.wordpress.com/2012/07/boundarycells.png?w=533" title="boundarycells" alt="" src="https://0fps.files.wordpress.com/2012/07/boundarycells.png?w=300&amp;h=235" height="235" width="300" srcset="https://0fps.files.wordpress.com/2012/07/boundarycells.png?w=300&amp;h=235 300w, https://0fps.files.wordpress.com/2012/07/boundarycells.png?w=150&amp;h=118 150w, https://0fps.files.wordpress.com/2012/07/boundarycells.png 533w" sizes="(max-width: 300px) 100vw, 300px"></p>
<h3>Primal Methods</h3>
<p>Primal methods, like marching cubes, try to turn the cells crossing the bounary into an isosurface using the following recipe:</p>
<ul>
<li>Edges crossing the boundary become vertices in the isosurface mesh.</li>
<li>Faces crossing the boundary become edges in the isosurface mesh.</li>
<li>‚Ä¶</li>
<li>n-cells crossing the boundary become (n-1)-cells in the isosurface mesh.</li>
</ul>
<p>One way to construct a primal mesh for our sample complex would be the following:</p>
<p><img loading="lazy" data-attachment-id="536" data-permalink="https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/primalcomplex/" data-orig-file="https://0fps.files.wordpress.com/2012/07/primalcomplex.png" data-orig-size="533,424" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="primalcomplex" data-image-description="" data-medium-file="https://0fps.files.wordpress.com/2012/07/primalcomplex.png?w=300" data-large-file="https://0fps.files.wordpress.com/2012/07/primalcomplex.png?w=533" title="primalcomplex" alt="" src="https://0fps.files.wordpress.com/2012/07/primalcomplex.png?w=300&amp;h=238" height="238" width="300" srcset="https://0fps.files.wordpress.com/2012/07/primalcomplex.png?w=300&amp;h=238 300w, https://0fps.files.wordpress.com/2012/07/primalcomplex.png?w=150&amp;h=119 150w, https://0fps.files.wordpress.com/2012/07/primalcomplex.png 533w" sizes="(max-width: 300px) 100vw, 300px"></p>
<p>This is pretty nice because it is easy to find intersection points along edges. &nbsp;Of course, there is some topological ambiguity in this construction.&nbsp; For non-simplicial cells crossing the boundary it is not always clear how you would glue the cells together:</p>
<p><img loading="lazy" data-attachment-id="537" data-permalink="https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/primalcell/" data-orig-file="https://0fps.files.wordpress.com/2012/07/primalcell.png" data-orig-size="929,198" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="primalcell" data-image-description="" data-medium-file="https://0fps.files.wordpress.com/2012/07/primalcell.png?w=300" data-large-file="https://0fps.files.wordpress.com/2012/07/primalcell.png?w=640" title="primalcell" alt="" src="https://0fps.files.wordpress.com/2012/07/primalcell.png?w=300&amp;h=63" height="63" width="300" srcset="https://0fps.files.wordpress.com/2012/07/primalcell.png?w=296&amp;h=63 296w, https://0fps.files.wordpress.com/2012/07/primalcell.png?w=591&amp;h=126 591w, https://0fps.files.wordpress.com/2012/07/primalcell.png?w=150&amp;h=32 150w, https://0fps.files.wordpress.com/2012/07/primalcell.png?w=300&amp;h=64 300w" sizes="(max-width: 300px) 100vw, 300px"></p>
<p>As we have seen, these ambiguities lead to exponentially many special cases, and are generally a huge pain to deal with.</p>
<h3>Dual Methods</h3>
<p>Dual methods on the other hand use a very different topology for the surface mesh.&nbsp; Like primal methods, they only consider the cells which intersect the boundary, but the rule they use to construct surface cells is very different:</p>
<ul>
<li>For every edge crossing the boundary, create an (n-1) cell.&nbsp; (Face in 3D)</li>
<li>For every face crossing the boundary, create an (n-2) cell. (Edge in 3D)</li>
<li>‚Ä¶</li>
<li>For every d-dimensional cell, create an (n-d) cell.</li>
<li>‚Ä¶</li>
<li>For every n-cell, create a vertex.</li>
</ul>
<p>This creates a much simpler topological structure:</p>
<p><img loading="lazy" data-attachment-id="538" data-permalink="https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/dualcomplex/" data-orig-file="https://0fps.files.wordpress.com/2012/07/dualcomplex.png" data-orig-size="537,419" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="dualcomplex" data-image-description="" data-medium-file="https://0fps.files.wordpress.com/2012/07/dualcomplex.png?w=300" data-large-file="https://0fps.files.wordpress.com/2012/07/dualcomplex.png?w=537" title="dualcomplex" alt="" src="https://0fps.files.wordpress.com/2012/07/dualcomplex.png?w=300&amp;h=234" height="234" width="300" srcset="https://0fps.files.wordpress.com/2012/07/dualcomplex.png?w=300&amp;h=234 300w, https://0fps.files.wordpress.com/2012/07/dualcomplex.png?w=150&amp;h=117 150w, https://0fps.files.wordpress.com/2012/07/dualcomplex.png 537w" sizes="(max-width: 300px) 100vw, 300px"></p>
<p>The nice thing about this construction is that unlike primal methods, the topology of the dual isosurface mesh is completely determined by the sample complex (so there are no ambiguities).&nbsp; The disadvantage is that you may sometimes get non-manifold vertices:</p>
<p><img loading="lazy" data-attachment-id="465" data-permalink="https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/dualmesh/" data-orig-file="https://0fps.files.wordpress.com/2012/07/dualmesh.png" data-orig-size="589,245" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="dualmesh" data-image-description="" data-medium-file="https://0fps.files.wordpress.com/2012/07/dualmesh.png?w=300" data-large-file="https://0fps.files.wordpress.com/2012/07/dualmesh.png?w=589" title="dualmesh" alt="" src="https://0fps.files.wordpress.com/2012/07/dualmesh.png?w=300&amp;h=124" height="124" width="300" srcset="https://0fps.files.wordpress.com/2012/07/dualmesh.png?w=298&amp;h=124 298w, https://0fps.files.wordpress.com/2012/07/dualmesh.png?w=150&amp;h=62 150w, https://0fps.files.wordpress.com/2012/07/dualmesh.png 589w" sizes="(max-width: 300px) 100vw, 300px"></p>
<h2>Make Your Own Dual Scheme</h2>
<p>To create your own dual method, you just have to specify two things:</p>
<ol>
<li>A sample complex.</li>
<li>And a rule to assign vertices to every n-cell intersecting the boundary.</li>
</ol>
<p>The second item is the tricky part, and much of the research into dual methods has focused on exploring the possibilities. &nbsp;It is interesting to note that this is the opposite of primal methods, where finding vertices was pretty easy, but gluing them together consistently turned out to be quite hard.</p>
<h3>Surface Nets</h3>
<p>Here‚Äôs a neat puzzle: what happens if we apply the dual recipe to a regular, cubical grid&nbsp;(like we did in marching cubes)? &nbsp;Well, it turns out that you get the same boxy, cubical meshes that you‚Äôd make in a Minecraft game (topologically speaking)!</p>
<p><a href="https://0fps.files.wordpress.com/2012/07/exampledualmesh.png"><img title="exampledualmesh" alt="" src="https://0fps.files.wordpress.com/2012/07/exampledualmesh.png?w=150&amp;h=145" height="145" width="150"></a><a href="https://0fps.files.wordpress.com/2012/07/spheresmoothed.png"><img title="spheresmoothed" alt="" src="https://0fps.files.wordpress.com/2012/07/spheresmoothed.png?w=150&amp;h=138" height="138" width="150"></a></p>
<p>Left: A dual mesh with vertex positions snapped to integer coordinates.&nbsp; Right: A dual mesh with smoothed vertex positions.</p>
<p>So if you know how to <a href="https://0fps.wordpress.com/2012/06/30/meshing-in-a-minecraft-game/">generate Minecraft meshes</a>, then you already know how to make smooth shapes! &nbsp;All you have to do is squish your vertices down onto the isosurface somehow. &nbsp;How cool is that?</p>
<p>This technique is called ‚Äúsurface nets‚Äù (remember when we mentioned them before?) &nbsp;Of course the trick is to figure out where you place the vertices. &nbsp;In Gibson‚Äôs original paper, she formulated the process of vertex ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/">https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/</a></em></p>]]>
            </description>
            <link>https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25690189</guid>
            <pubDate>Fri, 08 Jan 2021 20:43:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apache Beam for Search: Getting Started by Hacking Time]]>
            </title>
            <description>
<![CDATA[
Score 85 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25686936">thread link</a>) | @clandry94
<br/>
January 8, 2021 | https://shopify.engineering/apache-beam-for-search-getting-started-by-hacking-time | <a href="https://web.archive.org/web/*/https://shopify.engineering/apache-beam-for-search-getting-started-by-hacking-time">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
  <p>To create relevant search, processing clickstream data is key: you frequently want to promote search results that are being clicked on and purchased, and demote those things users don‚Äôt love.</p>
<p>Typically search systems think of processing clickstream data as a batch job run over historical data, perhaps using a system like Spark. But on Shopify‚Äôs Discovery team, we ask the question: What if we could auto-tune relevance in real-time as users interact with search results‚Äînot having to wait days for a large batch job to run?</p>
<p>At Shopify‚Äîthis is what we‚Äôre doing! We‚Äôre using streaming data processing systems that can process both real-time and historic data to enable real-time use cases ranging from simple auto boosting or down boosting of documents, to computing aggregate click popularity statistics, building <a href="https://elasticsearch-learning-to-rank.readthedocs.io/en/latest/core-concepts.html#judgments-expression-of-the-ideal-ordering" target="_blank" rel="nofollow noopener noreferrer">offline search evaluation sets</a>, and on to more complex reinforcement learning tasks.</p>
<p>But this article is introducing you to the streaming system themselves. In particular, to Apache Beam. And the most important thing to think about is <em>time</em> with those streaming systems. So let‚Äôs get started!</p>
<h2>What Exactly is Apache Beam?</h2>
<p><a href="https://beam.apache.org/" target="_blank" title="Apache Beam" rel="nofollow noopener noreferrer">Apache Beam</a> is a unified batch and stream processing system. This lets us potentially unify historic and real-time views of user search behaviors in one system. Instead of a batch system, like Spark, to churn over months of old data, and a separate streaming system, like Apache Storm, to process the live user traffic, Beam hopes to keep these workflows together.</p>
<p>For search, this is rather exciting. It means we can build search systems that both rely on historic search logs while perhaps being able to live-tune the system for our users‚Äô needs in various ways.</p>
<p>Let‚Äôs walk through an early challenge everyone faces with Beam: that of <strong><em>time!</em></strong> Beam is a kind of time machine that has to reorder events in their right spot after getting annoyingly delayed by lots of intermediate processing and storage step. This is one of the core complications of a streaming system - how long do we wait? How do we deal with late or out of order data?</p>
<p>So to get started with Beam, the first thing you‚Äôll need to do is Hack Time!</p>
<h2>The Beam Time Problem</h2>
<p>At the core of Apache Beam are <a href="https://beam.apache.org/documentation/programming-guide/#creating-a-pipeline" target="_blank" rel="nofollow noopener noreferrer">pipelines</a>. They connect a source through various processing steps to finally a sink.&nbsp;&nbsp;</p>
<p>Data flowing through a pipeline is timestamped. When you consider a streaming system, this makes sense. We have various delays as events flow from browsers, through APIs, and other data systems. Finally the events arrive at our Beam pipeline. They can easily be out-of-order or delayed. Beam source APIs, like the one for <a href="https://beam.apache.org/releases/javadoc/2.5.0/org/apache/beam/sdk/io/kafka/KafkaIO.html" target="_blank" rel="nofollow noopener noreferrer">Kafka</a>, maintain a moving view of the event data to emit well-ordered events known as a <a href="https://beam.apache.org/documentation/programming-guide/#watermarks-and-late-data" target="_blank" rel="nofollow noopener noreferrer">watermark</a>.</p>
<p>If we don‚Äôt give our Beam source good information on how to build a timestamp, we‚Äôll drop events or receive them in the wrong order. But even more importantly for search, we likely must combine different streams of data to build a single view on a search session or query, like below:</p>
<figure><img alt="combine different streams of data to build a single view on a search session or query, like below" data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/Beam_for_Search__Getting_started_with_the_Beam_time_machine.png?format=jpg&amp;quality=90&amp;v=1610128718" src="https://cdn.shopify.com/s/files/1/0779/4361/files/Beam_for_Search__Getting_started_with_the_Beam_time_machine.png?format=jpg&amp;quality=90&amp;v=1610128718"></figure>
<p>Joining (a Beam topic for another day!) needs to look back over each source‚Äôs watermark and ensure they‚Äôre aligned in time before deciding that sufficient time has elapsed before moving on. But before you get to the complexities of streaming joins, replaying with accurate timestamps is the first milestone on your Beam-for-clickstream journey.</p>
<h2>Configuring the Timestamp Right at the Source</h2>
<p>Let‚Äôs set up a simple Beam pipeline to explore Beam. Here we‚Äôll use Kafka in Java as an example. You can see the full source code <a href="https://gist.github.com/geekigirl/738ead73033ae673483ab9690452f10f" target="_blank" title="Timestamp policy example with Kafka source with Apache BEAM" rel="nofollow noopener noreferrer">in this gist</a>.</p>
<p>Here we‚Äôll set up a Kafka source, the start of a pipeline producing a custom SearchQueryEvent stored in a search_queries_topic.</p>

<p>You‚Äôll notice we have information on the topic/servers to retrieve the data, along with how to deserialize the underlying binary data. We might add further processing steps to transform or process our SearchQueryEvents, eventually sending the final output to another system.</p>
<p>But nothing about <strong>time</strong> yet. By default, the produced SearchQueryEvents will use Kafka <em>processing</em> time. That is, when they‚Äôre read from Kafka. This is the least interesting for our purposes. We care about when users actually searched and clicked on results.</p>
<p>More interesting is when the event was created in a Kafka client. Which we can add here:</p>
<p><code>.withCreateTime(Duration.<em>standardMinutes</em>(5))</code></p>
<p>You‚Äôll notice above, when we use create time below, we need to give the source‚Äôs Watermark a tip for how out of order event times might be. For example, below we instruct the Kafka source to use create time, but with a possible 5 minutes of discrepancy.&nbsp;</p>
<h2>Appreciating The Beam Time Machine</h2>
<p>Let‚Äôs reflect on what such a 5 minute possible delay actually means from the last snippet. Beam is kind of a time machine‚Ä¶ How Beam bends space-time is where your mind can begin to hurt.</p>
<p>As you might be picking up, <em>event time </em>&nbsp;is quite different from <em>processing time</em>! So in the code snippet above, we‚Äôre *not* telling the computer to wait for 5 minutes of execution time for more data. No, the event time might be replayed from historical data, where 5 minutes of event time is replayed through our pipeline in mere milliseconds. Or it could be event time is really now, and we‚Äôre actively streaming live data for processing. So we DO indeed wait 5 real minutes!&nbsp;</p>
<p>Let‚Äôs take a step back and use a silly example to understand this. It‚Äôs really crucial to your Beam journey.&nbsp;</p>
<p>Imagine we‚Äôre super-robot androids that can watch a movie at 1000X speed. Maybe like Star Trek The Next Generation‚Äôs Lt Commander Data. If you‚Äôre unfamiliar, he could process input as fast as a screen could display! Data might say ‚ÄúHey look, I want to watch the classic 80s movie, The Goonies, so I can be a cultural reference for the crew of the Enterprise.‚Äù&nbsp;</p>
<p>Beam is like watching a movie in super-fast forward mode with chunks of the video appearing possibly delayed or out of order relative to other chunks in movie time. In this context we have two senses of time:</p>
<ul>
<li>Event Time: the timestamp in the actual 1h 55 minute runtime of The Goonies aka movie time.</li>
<li>Processing Time: the time we actually experience The Goonies (perhaps just a few minutes if we‚Äôre super-robot androids like Data).</li>
</ul>
<p>So Data tells the Enterprise computer ‚ÄúLook, play me The Goonies as fast as you can recall it from your memory banks.‚Äù And the computer has various hiccups where certain frames of the movie aren‚Äôt quite getting to Data‚Äôs screen to keep the movie in order.&nbsp;</p>
<p>Commander Data can tolerate missing these frames. So Data says ‚ÄúLook, don‚Äôt wait more than 5 minutes in *movie time* (aka event time) before just showing me what you have so far of that part of the movie. This lets Data watch the full movie in a short amount of time, dropping a tolerable number of movie frames.</p>
<p>This is just what Beam is doing with our search query data. Sometimes it‚Äôs replaying days worth of historic search data in milliseconds, and other times we‚Äôre streaming live data where we truly must wait 5 minutes for reality to be processed. Of course, the right delay might not be 5 minutes, it might be something else appropriate to our needs.&nbsp;</p>
<p>Beam has other primitives such as <a href="https://beam.apache.org/releases/javadoc/2.0.0/org/apache/beam/sdk/transforms/windowing/Window.html" target="_blank" rel="nofollow noopener noreferrer">windows</a> which further inform, beyond the source, how data should be buffered or collected in units of time. Should we collect our search data in daily windows? Should we tolerate late data? What does subsequent processing expect to work over? Windows also work with the same time machine concepts that must be appreciated deeply to work with Beam.</p>
<h2>Incorporating A Timestamp Policy</h2>
<p>Beam might know a little about Kafka, but it really doesn‚Äôt know anything about <strong>our</strong> data model. Sometimes we need even more control over the definition of time in the Beam time machine.</p>
<p>For example, in our previous movie example, movie frames perhaps have some field informing us of how they should be arranged in movie time. If we examine our SearchQueryEvent, we also see a specific timestamp embedded in the data itself:</p>
<p><code>public class SearchQueryEvent {</code></p>
<p><code>&nbsp;&nbsp;&nbsp;public final String queryString;</code></p>
<p><code>&nbsp;&nbsp;&nbsp;public final Instant searchTimestamp;</code></p>
<p><code>‚Ä¶</code></p>
<p><code>}</code></p>
<p>Well Beam sources can often be configured to use a custom event time like our searchTimestamp. We just need to make a TimestampPolicy. We simply provide a simple function-class that takes in our record (A key-value of Long-&gt;SearchQueryEvent) and returns a timestamp:</p>

<p>We can use this to create our own timestamp policy:</p>

<p>Here, we‚Äôve passed in our own function, and we‚Äôve given the same allowed delay (5 minutes). This is all wrapped up in a factory class TimestampPolicyFactory SearchQueryTimestampPolicyFactory (now if that doesn‚Äôt sound like a Java class name, I don‚Äôt know what does ;) )</p>
<p>We can add our timestamp policy to the builder:</p>
<p><code>.withTimestampPolicyFactory(new SearchQueryTimestampPolicyFactory())</code></p>
<h2>Hacking Time!</h2>
<p>Beam is about hacking time, I hope you‚Äôve appreciated this walkthrough of some of Beam‚Äôs capabilities. If you‚Äôre interested in joining me on building Shopify‚Äôs future in search and discovery, please check out these great job postings!</p>
<p>Doug Turnbull is a Sr. Staff Engineer in Search Relevance at Shopify. He is known for writing the book ‚ÄúRelevant Search‚Äù, contributing to ‚ÄúAI Powered Search‚Äù, and creating relevance tooling for Solr and Elasticsearch like Splainer, Quepid, and the Elasticsearch Learning to Rank plugin. Doug‚Äôs team at Shopify helps Merchants make their products and brands more discoverable. If you‚Äôd like to work with Doug, send him a Tweet at <a href="https://twitter.com/softwaredoug" target="_blank" title="Doug Turnbull on Twitter" rel="nofollow noopener noreferrer">@softwaredoug</a>!</p>
</div></div>]]>
            </description>
            <link>https://shopify.engineering/apache-beam-for-search-getting-started-by-hacking-time</link>
            <guid isPermaLink="false">hacker-news-small-sites-25686936</guid>
            <pubDate>Fri, 08 Jan 2021 17:13:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[India could get nasal vaccine against Covid-19 soon]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 11 (<a href="https://news.ycombinator.com/item?id=25685187">thread link</a>) | @jangid
<br/>
January 8, 2021 | https://www.indiatoday.in/coronavirus-outbreak/story/india-nasal-coronavirus-vaccine-soon-trials-begin-nagpur-1756780-2021-01-07 | <a href="https://web.archive.org/web/*/https://www.indiatoday.in/coronavirus-outbreak/story/india-nasal-coronavirus-vaccine-soon-trials-begin-nagpur-1756780-2021-01-07">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>A nasal Covid-19 vaccine could be a reality in India soon with Bharat Biotech, the Indian vaccine maker, all set to start phase 1 and 2 trials of a nasal vaccine at Gillurkar Multi Speciality Hospital in Nagpur.</p><p>Bharat Biotech‚Äôs head Dr Krishna Ella said on Thursday, "We are working on a nasal vaccine and have partnered with the Washington University School of Medicine. We are working on a single dose vaccine compare to two-dose inactivated vaccine. Research has proven that the nasal vaccine is the best choice. Coronavirus also attacks through the nose."</p><p>"We are <a href="https://www.indiatoday.in/coronavirus-outbreak/vaccine-updates/story/bharat-biotech-founder-assures-safety-of-covaxin-nasal-vaccine-1755712-2021-01-04" target="_blank">all set to host the trials for the nasal Covaxin in the next two weeks</a>. Enough scientific evidence is available that vaccines given through nasal route are more effective than injected ones. Bharat Biotech is in the process to submit a proposal to the DCGI shortly," said Dr Chandrashekar Gillurkar.</p><p>The trials will be conducted on at least 30-45 healthy volunteers above the age of 18 till the age of 65 years at four trial sites in the country -- Bhuvneshwar, Pune, Nagpur and Hyderabad.</p><p>Presently, Bharat Biotech is working on two intranasal vaccines -- one with US-based vaccine maker FluGen and scientists from the University of Wisconsin Madison and the other with the University of Washington School of Medicine.</p><p>Experts say that the nasal variant of the Covid-19 vaccine, which is currently under trial in the US, could play a major role in stopping transmission of the virus.</p><p><em><strong>Read: <a href="https://www.indiatoday.in/coronavirus-outbreak/vaccine-updates/story/confused-about-covid-19-vaccines-this-is-for-you-1756786-2021-01-07" target="_blank" title="Confused about Covid-19 vaccines? This is for you">Confused about Covid-19 vaccines? This is for you</a></strong></em></p><h3><span><strong>WHAT IS NASAL VACCINE?</strong></span></h3><p>Unlike other Covid-19 vaccines that are administered intramuscularly (or through the muscles), this one is delivered via the nose, which is also an initial point of infection in humans.</p><p>A study done by the University of Washington School of Medicine in St Louis found that the nasal delivery route created a strong immune response throughout the body, but it was particularly effective in the nose and respiratory tract, preventing the infection from taking hold in the body.</p><p><em><strong>Read: <a href="https://www.indiatoday.in/coronavirus-outbreak/story/vaccination-doesn-t-guarantee-100-protection-wearing-mask-is-must-experts-1756766-2021-01-07" target="_blank" title="Vaccination doesn't guarantee 100% protection, wearing mask is must: Experts">Vaccination doesn't guarantee 100% protection, wearing mask is must: Experts</a></strong></em></p><h3><span><strong>ARE NASAL VACCINES BETTER THAN INJECTIONS?</strong></span></h3><p>Experts say the nasal Covid-19 vaccine has the potential to become a game-changer because injecting the vaccine intramuscularly only protects the lower lung. A nasal vaccine can protect both the upper and lower lung and can prevent transmission of the virus as well as an infection.</p><p>Dr Samiran Panda, senior epidemiologist at Indian Council of Medical Research said nasal vaccine provides benefits such as faster absorption, lesser volume and no use of syringes.</p><p> <img data-src="https://akm-img-a-in.tosshub.com/indiatoday/images/bodyeditor/202101/PHOTO-2021-01-07-23-05-59-x1280.jpg?CsWamucYQxVXvG9OqXSQo33RxTxirvDo" src="https://akm-img-a-in.tosshub.com/indiatoday/images/bodyeditor/202101/PHOTO-2021-01-07-23-05-59-x1280.jpg?CsWamucYQxVXvG9OqXSQo33RxTxirvDo" alt=""></p><p>"There are two arms of the immune system in the body - one is antibody or protein and one is cellular immunity. <a href="https://www.indiatoday.in/coronavirus-outbreak/story/mucosal-immunity-prevent-covid-outbreak-1745369-2020-11-30" target="_blank">The mucosal immunity is created</a> when administered a nasal vaccine against those infections that enter our body through the nose or respiratory tract. Coronavirus impacts the respiratory tract the most. Therefore, the nasal vaccine is much better. Antibodies will be secreted directly into the nasal mucous membrane, where you need more concentration of the antibody because it is where the infection begins from."</p><p><strong>Faster absorption:</strong></p><p>When administered orally or nasally, the antigen is presented to the mucous membrane, the absorption is much better and it quickly goes to the lymph nodes. There is an effective presentation of the viral antigen directed at the infection.</p><p><strong>Lesser volume:</strong></p><p>Earlier rabies vaccine used to be given in the subcutaneous fat and now is being given intra-dermal injection route (through the skin). A similar immune response can be generated with a much smaller dose.</p><h3><span><strong>INTERNATIONAL TRIALS</strong></span></h3><p>An influenza vaccine called FLUmist, delivered via the nose, uses the weakend form of live influenza virus but can‚Äôt be administered to certain groups including those whose immune systems are compromised by cancer, HIV and diabetes.</p><p>In contrast, the new coronavirus intranasal vaccine does not use a live virus capable of replication, presumably making it safer.</p><p>The United Kingdom's Medicines and Healthcare Products Regulatory Agency (MHRA), has approved Open Orphan and Codagenix to conduct a phase 1 study of its nasal Covid-19 vaccine in the country.</p><p><strong>Also Read | <a href="https://www.indiatoday.in/coronavirus-outbreak/vaccine-updates/story/bharat-biotech-founder-assures-safety-of-covaxin-nasal-vaccine-1755712-2021-01-04" target="_blank" title="Bharat Biotech founder assures safety of Covaxin, pins hopes on its new nasal vaccine">Bharat Biotech founder assures safety of Covaxin, pins hopes on its new nasal vaccine</a></strong></p><p><strong>Also Read | <a href="https://www.indiatoday.in/coronavirus-outbreak/video/covishield-covaxin-vaccines-will-be-available-in-india-soon-health-minister-harsh-vardhan-1756772-2021-01-07">Covishield, Covaxin vaccines will be available in India soon: Health minister Harsh Vardhan</a></strong></p><p><strong>Also Read | <a href="https://www.indiatoday.in/coronavirus-outbreak/story/vaccination-doesn-t-guarantee-100-protection-wearing-mask-is-must-experts-1756766-2021-01-07">Vaccination doesn't guarantee 100% protection, wearing mask is must: Experts</a></strong></p></div></div>]]>
            </description>
            <link>https://www.indiatoday.in/coronavirus-outbreak/story/india-nasal-coronavirus-vaccine-soon-trials-begin-nagpur-1756780-2021-01-07</link>
            <guid isPermaLink="false">hacker-news-small-sites-25685187</guid>
            <pubDate>Fri, 08 Jan 2021 14:45:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Over 100 Scientists and Doctors Call for Increased Vitamin D to Combat Covid-19]]>
            </title>
            <description>
<![CDATA[
Score 119 | Comments 110 (<a href="https://news.ycombinator.com/item?id=25680282">thread link</a>) | @kpfleger
<br/>
January 7, 2021 | https://vitamindforall.org/letter.html | <a href="https://web.archive.org/web/*/https://vitamindforall.org/letter.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span>#VitaminDforAll </span><span>(for questions or fact checking assistance, contact press@vitaminDforAll.org)</span></p><p id="h.mjz6soj7f435"><span>Over 100 </span><span>Scientists, Doctors, &amp; Leading Authorities</span><span>&nbsp;Call For </span><span>Increased</span><span>&nbsp;Vitamin D Use To Combat COVID-19</span></p><p><span>[Residents of the USA: Text ‚ÄúVitaminDforAll‚Äù to 50409 to send this to your state‚Äôs governor.]</span></p><p><span>Research shows low vitamin D levels almost certainly promote COVID-19 infections, hospitalizations, and deaths. Given its safety, </span><span>w</span><span>e call for immediate widespread increased vitamin D intakes</span><span>.</span></p><p><span>Vitamin D modulates thousands of genes and many aspects of immune function, both innate and adaptive. The scientific evidence</span><span>1</span><span>&nbsp;shows that:</span></p><p><span>Vitamin D is well known to be essential, but most people do not get enough. Two common definitions of inadequacy are deficiency &lt; 20ng/ml (50nmol/L), the target of most governmental organizations, and insufficiency &lt; 30ng/ml (75nmol/L), the target of several medical societies &amp; experts.</span><span>2</span><span>&nbsp;Too many people have levels below these targets. </span><span>Rates of vitamin D deficiency &lt;20ng/ml exceed 33% of the population in most of the world, and most estimates of insufficiency &lt;30ng/ml are well over 50% (but much higher in many countries).</span><span>3</span><span>&nbsp;Rates are even higher in winter, and several groups have notably worse deficiency: the overweight, those with dark skin (especially far from the equator), and care home residents. These same groups face increased COVID-19 risk.</span></p><p><span>It has been shown that 3875 IU (97mcg) daily is required for 97.5% of people to reach 20ng/ml, and 6200 IU (155mcg) for 30ng/ml,</span><span>4</span><span>&nbsp;intakes far above all national guidelines. Unfortunately, the report that set the US RDA included an admitted statistical error in which required intake was calculated to be ~10x too low.</span><span>4</span><span>&nbsp;Numerous calls in the academic literature to raise official recommended intakes had not yet resulted in increases by the time SARS-CoV-2 arrived. Now, many papers indicate that vitamin D affects COVID-19 more strongly than most other health conditions, with increased risk at levels &lt; 30ng/ml (75nmol/L) and severely greater risk &lt; 20ng/ml (50nmol/L).</span><span>1</span></p><p><span>Evidence to date </span><span>suggests </span><span>the possibility that the COVID-19 pandemic sustains itself in large part &nbsp;through infection of those with low vitamin D, and that deaths are concentrated largely in those with deficiency. The mere possibility that this is so should compel urgent gathering of more vitamin D data. </span><span>Even without more data</span><span>, </span><span>the </span><span>preponderance </span><span>of evidence indicates that </span><span>increased vitamin D would help reduce infections, hospitalizations, ICU admissions, &amp; deaths</span><span>.</span></p><p><span>Decades of safety data show that vitamin D has very low risk: </span><span>Toxicity would be extremely rare with the recommendations here. The risk of insufficient levels far outweighs any risk from levels that seem to provide most of the protection against COVID-19, and this is notably different from drugs. Vitamin D is much safer than steroids, such as dexamethasone, the most widely accepted treatment to have also demonstrated a large COVID-19 benefit. Vitamin D‚Äôs safety is more like that of face masks. </span><span>There is no need to wait for further clinical trials to increase use of something so safe, </span><span>especially when remedying high rates of deficiency/insufficiency should already be a priority</span><span>.</span></p><p><span>Therefore, we call on all governments, doctors, and healthcare workers worldwide to immediately recommend and implement efforts appropriate to their adult populations to increase vitamin D, at least until the end of the pandemic. Specifically to:</span></p><p><span>Many factors are known to predispose individuals to higher risk from exposure to SARS-CoV-2, such as age, being male, comorbidities, etc., but </span><span>inadequate</span><span>&nbsp;v</span><span>itamin D is by far the most easily and quickly </span><span>modifiable</span><span>&nbsp;risk factor with abundant evidence to support a large effect</span><span>. Vitamin D is inexpensive and has negligible risk compared to the considerable risk of COVID-19.</span></p><p><span>5</span><span>&nbsp;The following include 4000 IU within their tolerable intakes in official guidelines: NAM (US, Canada), SACN (UK), EFSA (Europe), Endocrine Society (international), Nordic countries, The Netherlands, Australia &amp; New Zealand, UAE, and the American Geriatrics Soc. (USA, elderly). No major agency specifies a lower tolerable intake limit. The US NAM said 4000 IU ‚Äúis likely to pose no risk of adverse health effects to almost all individuals.‚Äù See also [</span><span><a href="https://pubmed.ncbi.nlm.nih.gov/32180081/">Giustina et al ‚Äò20</a></span><span>].</span></p><p><span>The signatories below endorse this letter. Affiliations do not imply endorsement of the letter by the institutions themselves.</span></p><p><span>This letter takes no position on other public health measures besides vitamin D. Personal views of individual signatories on any other matter do not represent the group as a whole.</span></p><p><span>All signatories declare no conflicts of interest except as noted.</span></p><p><span>To emphasize: </span><span>The organizing signatories have no conflicts of interest in this area (financial or otherwise)</span><span>, nor have they done research in this area prior to 2020.</span></p><div><tbody><tr><td colspan="1" rowspan="1"><p><span>Signatories (185)</span></p></td><td colspan="1" rowspan="1"><p><span>recom- mended intake</span></p></td><td colspan="1" rowspan="1"><p><span>personal daily intake</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Karl Pfleger</span><span>, PhD AI &amp; Computer Science, Stanford. Former Google Data Scientist. Biotechnology Investor, AgingBiotech.info, San Francisco, CA, USA. (organizing signatory)</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>7000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Gareth Davies</span><span>, PhD Medical Physics, Imperial College, London, UK. Codex World‚Äôs Top 50 Innovator 2019. Independent Researcher. Lead author of ‚Äú</span><span><a href="https://www.medrxiv.org/content/10.1101/2020.05.01.20087965v3">Evidence Supports a Causal Role for Vitamin D Status in COVID-19 Outcomes</a></span><span>.‚Äù (organizing signatory)</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>10,000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Bruce W Hollis</span><span>, PhD. Professor of Pediatrics, Medical University of South Carolina, USA.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>6000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Barbara J Boucher</span><span>, MD, FRCP (London). </span><span>Honorary Professor (Medicine), Blizard Institute, Bart's &amp; The London School of Medicine and Dentistry, Queen Mary University of London, UK. </span><span>(significantly contributing signatory)</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>2000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Ashley Grossman</span><span>, MD FRCP FMedSci. Emeritus Professor of Endocrinology, University of Oxford, UK. Professor of Neuroendocrinology, Barts and the London School of Medicine. 2020 Endocrine Society Laureate Award.</span></p></td><td colspan="1" rowspan="1"><p><span>2000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>2200 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Gerry Schwalfenberg</span><span>, MD, CCFP, FCFP. Assistant Clinical Professor in Family Medicine, University of Alberta, Canada.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>5000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Giovanna Muscogiuri</span><span>, MD PhD. Associate Editor, European Journal of Clinical Nutrition. </span><span>Department of Clinical Medicine and Surgery, Section of Endocrinology, University "Federico II" of Naples, Naples, Italy.</span><span>.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>1000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Michael F. Holick</span><span>, PhD MD. Professor Medicine, Physiology and Biophysics and Molecular Medicine, Director Vitamin D, Skin and Bone Research Laboratory, Boston University Medical Center, USA. (6000 IU) </span><span>Disclosure: Consultant Biogena and speaker's Bureau Abbott Inc.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>6000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. John Umhau</span><span>, MD, MPH. CDR, USPHS (ret). </span><span>President, Academy of Medicine of Washington, DC, USA. Ex-NIH: c</span><span>o-author of the first peer-reviewed report linking vitamin D deficiency with acute respiratory infection.</span><span>&nbsp;</span><span>(significantly contributing signatory)</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>5000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. </span><span>Pawel</span><span>&nbsp;</span><span>Pludowski</span><span>, MD, dr hab. Associate Professor, Biochemistry, Radioimmunology and Experimental Medicine, Children‚Äôs Memorial Health Institute, Warsaw, Poland. Chair, European Vitamin D Association (EVIDAS) [non-profit].</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>2000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Cedric F. Garland</span><span>, DrPH. Professor Emeritus, Department of Family Medicine and Public Health, University of California, San Diego, USA.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>6000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Jose M. Benlloch</span><span>, Professor, Director of the Institute for Instrumentation on Molecular Imaging, CSIC-UPV, Valencia, Spain.</span></p></td><td colspan="1" rowspan="1"><p><span>2000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>3000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Samantha Kimball</span><span>, PhD, MLT. Professor, St. Mary's University, Calgary, Alberta, Canada. Research Director, GrassrootsHealth Nutrient Research Institute [non-profit].</span><span>&nbsp;</span><span>(significantly contributing signatory)</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>6000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. William B. Grant</span><span>, PhD Physics, U. of California, Berkeley. Director at Sunlight, Nutrition, and Health Research Center [non-profit], San Francisco, CA, USA. </span><span>Disclosure: Receives funding from Bio-Tech Pharmacal, Inc.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>5300 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Carol L. Wagner,</span><span>&nbsp;MD. Professor, Medical University of South Carolina, USA.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>5000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Paul Marik</span><span>, MD, FCCP, FCCM. </span><span>Chief of Pulmonary and Critical Care Medicine and Professor of Medicine</span><span>, Eastern Virginia Medical School, Norfolk, VA, USA.</span></p></td><td colspan="1" rowspan="1"><p><span>2000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>2000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Morry Silberstein</span><span>, MD. Associate Professor, Curtin University, Australia.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Vatsal Thakkar</span><span>, MD. Founder, Reimbursify, NY, USA. &nbsp;Former faculty, NYU and Vanderbilt. &nbsp;Op-Ed writer on Vitamin D and COVID-19.</span><span>&nbsp;</span><span>(significantly contributing signatory)</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>10,000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Peter H Cobbold</span><span>, PhD. Emeritus Professor, Cell Biology, University of Liverpool, UK.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Afrozul Haq</span><span>, PhD. Professor Dept of Food Technology, Jamia Hamdard University, New Delhi, India.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>2000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Barry H. Thompson</span><span>, MD, FAAP, FACMG. Clinical Associate Professor (Pediatrics), Uniformed Services University of the Health Sciences, Bethesda, MD, USA.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>5000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Reinhold Vieth</span><span>, PhD, FCACB. Professor, Departments of Nutritional Sciences and Laboratory Medicine &amp; Pathobiology, University of Toronto, Canada. Director (retired), Bone and Mineral Group Laboratory, Mt Sinai Hospital. </span><span>Disclosure: </span><span>Receives patent royalties from Ddrops (an infant vitamin D supplement).</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Linda Benskin</span><span>, PhD, RN, SRN(Ghana), CWCN, CWS, DAPWCA. Independent Researcher for Tropical Developing Countries and Ferris Mfg. Corp, Texas, USA. </span><span>(significantly contributing signatory)</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Jim O‚ÄôNeill</span><span>, CEO, SENS Research Foundation. Former principal associate deputy secretary of Health and Human Services, USA.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>6000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Eric Feigl-Ding</span><span>, PhD. Epidemiologist &amp; Health Economist. Senior Fellow, Federation of American Scientists. USA.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>5000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Rt Hon David Davis MP</span><span>, Member of Parliament (Conservative Party). BSc, Joint Hons Molecular Science / Computer Science, Warwick University, UK.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>6000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Rupa Huq MP,</span><span>&nbsp;Member of Parliament (Labour Party). PhD, Cultural Studies, University of East London, UK.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Susan J Whiting</span><span>, PhD. Professor Emerita, University of Saskatchewan, Canada.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Richard Mazess</span><span>. PhD. Emeritus Professor, University of Wisconsin, Madison, USA.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>5000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Helga Rhein</span><span>, MD (retired). </span><span>Sighthill‚Ä¶</span></p></td></tr></tbody></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vitamindforall.org/letter.html">https://vitamindforall.org/letter.html</a></em></p>]]>
            </description>
            <link>https://vitamindforall.org/letter.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25680282</guid>
            <pubDate>Fri, 08 Jan 2021 01:34:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Avoiding instruction cache misses (2019)]]>
            </title>
            <description>
<![CDATA[
Score 68 | Comments 18 (<a href="https://news.ycombinator.com/item?id=25680125">thread link</a>) | @nkurz
<br/>
January 7, 2021 | https://paweldziepak.dev/2019/06/21/avoiding-icache-misses/ | <a href="https://web.archive.org/web/*/https://paweldziepak.dev/2019/06/21/avoiding-icache-misses/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div role="main"><div><article><p>Modern processors are quite complex, with many parts having the potential to become a bottleneck. It is relatively easy to reason about the performance of short pieces of code, especially if memory effects are kept to a minimum. Both static analysis tools like LLVM MCA and microbenchmarks can provide a lot of information in such cases. However, the behaviour of the whole program is not just the sum of those small parts. As the code becomes larger and more complex other effects start appearing. One of such potential problems are excessive instruction cache misses.</p><p>Every program has different properties, and those large-scale effects will affect it differently. However, if its job is to execute complex logic on a small amount of data, the instruction cache is likely to become a problem at some point. The actual impact may vary significantly from codebase to codebase, which is why I won‚Äôt show any numbers in this article. Let‚Äôs consider this just a collection of ideas, but it is not easy to tell how much any of them will help for a given application.</p><p>First, let‚Äôs have a quick look at the processor front end. Below is a simplified diagram of how it is arranged in Skylake, the numbers between units are the maxima per cycle.</p><p><img loading="lazy" width="630" height="860" src="https://paweldziepak.dev/static/icache-front-end.min.2e73578fff.svg" alt="CPU front end"></p><p>Each cycle the processor fetches up to 16 bytes from the instruction cache using information from the Branch Prediction Unit to predict the control flow. The pre-decode unit determines instruction lengths and puts up to five of them in the Instruction Queue. From the Instruction Queue, up to 5 instructions (with macro-fusion) are brought each cycle to the decoders. There is one complex decoder that can handle instructions that translate to up to 4 ¬µops and 3 simple decoders that can handle only single-¬µop instructions. In total, all decoders are limited to producing no more than 5 ¬µops each cycle. Instructions that require more than 4 ¬µops go through Microcode Sequence ROM, which emits 4 ¬µops per cycle, and while it is active, the decoders are disabled. There is also Decoded ICache (<abbr title="Decoded Stream Buffer">DSB</abbr>) which caches decoded ¬µops. It can emit up to 6 ¬µops each cycle. All ¬µops, regardless of their source, end up in the Instruction Decode Queue (IDQ). The Loop Stream Detector (LSD) detects small loops and keeps them in the queue, so that no fetched, decodes or reads from the DSB are needed during the duration of the loop. IDQ is the last part of the front end, and the queued ¬µops continue to the back end.</p><p>From the instruction cache point of view, the front end has two weaknesses. Firstly, instructions are processed in-order which can severely limit the processor ability to hide latencies of cache misses. HyperThreading can make sure that this part of the processor still does some useful work, but it is also the source of the second problem ‚Äì all resources, including the L1 instruction cache and ¬µop cache are shared between the hardware threads.</p><p>Modern processors provide various metrics that help monitor their behaviour. However, the task of extracting the relevant data requires a proper approach if it is to be done efficiently. Top-down analysis is invaluable with helping to understand microarchitectural phenomena in large codebases. The idea is to monitor program behaviour with the <abbr title="Performance Monitoring Unit">PMU</abbr> counters and identify the bottleneck starting with the major functional parts of the CPU and then digging deeper narrowing down on the exact source of the problem. It can be done in an automated way by tools like VTune or toplev.</p><pre><code>FE    Frontend_Bound:                                      39.48 +-  0.00 % Slots
BE    Backend_Bound:                                       16.19 +-  0.00 % Slots
    This category represents fraction of slots where no uops are
    being delivered due to a lack of required resources for
    accepting new uops in the Backend...
FE    Frontend_Bound.Frontend_Latency:                     24.92 +-  0.00 % Slots
FE    Frontend_Bound.Frontend_Bandwidth:                   13.45 +-  0.00 % Slots
FE    Frontend_Bound.Frontend_Latency.ICache_Misses:       14.45 +-  0.00 % Clocks &lt;==
    This metric represents fraction of cycles the CPU was
    stalled due to instruction cache misses...
    Sampling events:  frontend_retired.l2_miss:pp frontend_retired.l1i_miss:pp
FE    Frontend_Bound.Frontend_Latency.ITLB_Misses:          8.71 +-  0.00 % Clocks
    This metric represents fraction of cycles the CPU was
    stalled due to instruction TLB misses...
    Sampling events:  frontend_retired.stlb_miss:pp frontend_retired.itlb_miss:pp
FE    Frontend_Bound.Frontend_Latency.Branch_Resteers:      8.42 +-  0.00 % Clocks_Est
    This metric represents fraction of cycles the CPU was
    stalled due to Branch Resteers...
    Sampling events:  br_misp_retired.all_branches:u
FE    Frontend_Bound.Frontend_Bandwidth.MITE:              31.93 +-  0.00 % CoreClocks
    This metric represents Core fraction of cycles in which CPU
	was likely limited due to the MITE pipeline (Legacy Decode
    Pipeline)...
</code></pre><p>Above is an example of a toplev result. We can see that the instruction cache misses were the dominating bottleneck. Unsurprisingly instruction TLB misses also show up. On the front end bandwidth side of things, toplev points to the legacy decode pipeline. That makes perfect sense if the instructions are supplied from DSB or LSD, then there are no instruction fetches, and no cache misses.</p><p>Sometimes, the final summary may not provide sufficient information if there are changes in the code behaviour during the test. When that‚Äôs the case, a graph is likely to be a much more helpful way of presenting the results.</p><p><img loading="lazy" width="950" height="950" src="https://paweldziepak.dev/static/icache-toplev.min.2b465fdb6f.svg" alt="toplev"></p><p>Tools like toplev are great for initial identification of the problem, but once that‚Äôs done what we need is a right way for comparing different solutions. Ultimately, the most important metric is the actual performance of the program in a real-life workload. toplev still can be helpful as it shows the balance between different performance-limiting factors. What also can be useful is <code>perf stat</code> which can show the performance counter statistics. The event most relevant for us is <code>L1-icache-load-misses</code>, though there are more model-specific registers that may be of interest.</p><p>Now, that we know how to diagnose excessive instruction cache misses, let‚Äôs see what can be done to deal with this problem.</p><h2 id="avoiding-work">Avoiding work</h2><p>If the number of executed instructions is the problem, the most obvious solution is to try to reduce that number. Obviously, that‚Äôs much easier said than done, but there are some common patterns for dealing with this issue. One example would be prepared statements in databases. The general idea is that if a client knows it will send requests that have some commonality, it can tell the database engine early that the requests are going to match specific templates. This information allows the server to do as much work as possible during the preparation stage, thus reducing the amount of logic that needs to be executed for each individual request.</p><p>Extracting common patterns doesn‚Äôt have to be explicit. A server or any other kind of an application which actions depend on the user input could attempt to look for repeating patterns and cache some common parts. This is a very vague idea and most likely won‚Äôt be easily implementable in a lot of applications, but in some cases may be quite a natural solution. It also shows the main problem with the ‚Äújust do less‚Äù approach ‚Äì it is very application specific. On the plus, side, if this can be done, it is likely to help with the overall performance, not just the instruction cache misses.</p><p>Another potential problem is making sure that the preparation phase can really do something to help during the execution phase. If that means pre-computing some values, then it‚Äôs simple. However, if the only thing that preparation gives us is the knowledge which code paths are going to be exercised and which branches taken during the execution, it is going to be harder to take benefit from it. One option is to have some specialised code for the most common paths, C++ templates may come in handy here. If it is not easy to determine what may be the most common paths, then a just-in-time compiler may be used to generate code in the preparation stage.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p><h2 id="batching-work">Batching work</h2><p>So far, we have been trying to reduce the number of executed instructions, by taking advantage of some earlier knowledge to avoiding repeating the same work. In other words, we have introduced two stages:</p><ul><li>preparation, which is performed rarely and, consequently, less performance critical</li><li>execution, which is done many times and is expected to dominate overall performance</li></ul><p>The way this can help with the instruction cache misses is that the execution stage, being smaller, is more likely to fit in the instruction cache. Whether this brings any measurable benefits depends highly on the type of the application and how much logic can be moved from execution to preparation stages.</p><p>We have already split our processing pipeline into preparation and execution stage. If the execution stage can fit in the instruction cache, we are done. However, often, that‚Äôs not the case. What we can do to improve the situation more is to split the execution into more stages. This time the goal is not to reuse work as it was with the preparation, but to group entities that need to have the same code executed for them. In other words, if the processing pipeline consists of steps A, B and C the idea is to separate them, add a queue in front of each of those stages, and then cycle through those stages each time handling multiple elements from the queue. Connections between the stages don‚Äôt have to be one-to-one, any directed graph is fine.</p><p><img loading="lazy" width="756" height="331" src="https://paweldziepak.dev/static/icache-seda.min.7259b25adc.svg" alt="SEDA diagram"></p><p>In the diagram above, there is one stage that feeds tasks to one of two stages. This could be, for example, a front-end of a database server. The first stage does some initial request processing and then, depending on whether it is a read or write, puts it in the appropriate queue. Each stage processes requests in batches, the first one warms up the instruction ‚Ä¶</p></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://paweldziepak.dev/2019/06/21/avoiding-icache-misses/">https://paweldziepak.dev/2019/06/21/avoiding-icache-misses/</a></em></p>]]>
            </description>
            <link>https://paweldziepak.dev/2019/06/21/avoiding-icache-misses/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25680125</guid>
            <pubDate>Fri, 08 Jan 2021 01:15:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CO2 already emitted will warm Earth beyond climate targets, study finds]]>
            </title>
            <description>
<![CDATA[
Score 336 | Comments 248 (<a href="https://news.ycombinator.com/item?id=25679618">thread link</a>) | @colinprince
<br/>
January 7, 2021 | https://www.cbc.ca/news/technology/climate-targets-1.5861537 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/technology/climate-targets-1.5861537">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The amount of baked-in global warming, from carbon pollution already in the air, is enough to blow past international agreed upon goals to limit climate change, a new study finds. But it can be delayed for centuries if governments takes action.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.4922800.1543350548!/cpImage/httpImage/image.jpg_gen/derivatives/16x9_780/us-coal-s-decline.jpg"></p></div><figcaption>Smoke and steam rise from the smokestack of a coal-fired power plant near Ordos in northern China's Inner Mongolia Autonomous Region in 2015.  A new study estimates that 2.3 C of warming is inevitable, but can be delayed for centuries if the world quickly stops emitting extra greenhouse gases from the burning of coal, oil and natural gas, the study's authors say.<!-- --> <!-- -->(Mark Schiefelbein/Associated Press)</figcaption></figure><p><span><p>The amount of baked-in global warming, from carbon pollution already in the air, is enough to blow past international agreed upon goals to limit climate change, a new study finds.</p>  <p>But it's not game over because, while that amount of warming may be inevitable, it can be delayed for centuries if the world quickly stops emitting extra greenhouse gases from the burning of coal, oil and natural gas, the study's authors say.</p>  <p>For decades, scientists have talked about so-called "committed warming" or the increase in future temperature based on past carbon dioxide emissions that stay in the atmosphere for well over a century. It's like the distance a speeding car travels after the brakes are applied.</p>  <p>But Monday's <a href="https://www.nature.com/articles/s41558-020-00955-x">study in the journal Nature Climate Change</a> calculates that a bit differently and now figures the carbon pollution already put in the air will push global temperatures to about 2.3 degrees Celsius (4.1 degrees Fahrenheit) of warming since pre-industrial times.</p>  <p>Previous estimates, including those accepted by international science panels, were about a degree Celsius (1.8 degrees Fahrenheit) less than that amount of committed warming.</p>  <p>International climate agreements set goals of limiting warming to 2 C&nbsp;(3.6 F) since pre-industrial times, with the more ambitious goal of limiting it to 1.5 C&nbsp;(2.7 F) added in Paris in 2015. The world has already warmed about 1.1 C&nbsp;(2 F).</p>  <p>"You've got some ... global warming inertia that's going to cause the climate system to keep warming, and that's essentially what we're calculating," said study co-author Andrew Dessler, a climate scientist at Texas A&amp;M University. "Think about the climate system like the Titanic. It's hard to turn the ship when you see the icebergs."</p>  <p>Dessler and colleagues at the Lawrence Livermore National Lab and Nanjing University in China calculated committed warming to take into account that the world has warmed at different rates in different places and that places that haven't warmed as fast are destined to catch up.</p>    <p>Places such as the Southern Ocean, surrounding Antarctica are a bit cooler, and that difference creates low-lying clouds that reflect more sun away from earth, keeping these places cooler. But this situation can't keep going indefinitely because physics dictates that cooler locations will warm up more and when they do, the clouds will dwindle and more heating will occur, Dessler said.</p>  <p>Previous studies were based on the cooler spots staying that way, but Dessler and colleagues say that's not likely.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5693652.1597940952!/cpImage/httpImage/image.jpg_gen/derivatives/original_300/greenland-record-melt.jpg 300w,https://i.cbc.ca/1.5693652.1597940952!/cpImage/httpImage/image.jpg_gen/derivatives/original_460/greenland-record-melt.jpg 460w,https://i.cbc.ca/1.5693652.1597940952!/cpImage/httpImage/image.jpg_gen/derivatives/original_620/greenland-record-melt.jpg 620w,https://i.cbc.ca/1.5693652.1597940952!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/greenland-record-melt.jpg 780w,https://i.cbc.ca/1.5693652.1597940952!/cpImage/httpImage/image.jpg_gen/derivatives/original_1180/greenland-record-melt.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5693652.1597940952!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/greenland-record-melt.jpg"></p></div><figcaption>In this Aug. 16, 2019 file photo, icebergs float away as the sun rises near Kulusuk, Greenland. Greenland lost a record amount of ice that year. The world has already warmed 1.1 C since pre-industrial times.<!-- --> <!-- -->(Felipe Dana/The Associated Press)</figcaption></figure></span></p>  <h2>More research needed, outside experts say</h2>  <p>Outside experts said the work is based on compelling reasoning, but want more research to show that it's true. Breakthrough Institute climate scientist Zeke Hausfather said the new work fits better with climate models than observational data.</p>  <p>Just because the world is bound to get more warming than international goals, that doesn't mean all is lost in the fight against global warming, said Dessler, who cautioned against what he called "climate doomers."</p>  <p>If the world gets to net zero carbon emissions soon, 2 degrees of global warming could be delayed enough so that it won't happen for centuries, giving society time to adapt or even come up with technological fixes, he said.</p>  <p>"If we don't, we're going to blow through (climate goals) in a few decades," Dessler said. "It's really the rate of warming that makes climate change so terrible. If we got a few degrees over 100,000 years, that would not be that big a deal. We can deal with that. But a few degrees over 100 years is really bad."</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/technology/climate-targets-1.5861537</link>
            <guid isPermaLink="false">hacker-news-small-sites-25679618</guid>
            <pubDate>Fri, 08 Jan 2021 00:23:20 GMT</pubDate>
        </item>
    </channel>
</rss>
