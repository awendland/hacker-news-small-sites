<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Tue, 03 Nov 2020 20:17:35 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Tue, 03 Nov 2020 20:17:35 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[You might not need to store plaintext email addresses]]>
            </title>
            <description>
<![CDATA[
Score 58 | Comments 31 (<a href="https://news.ycombinator.com/item?id=24965671">thread link</a>) | @danielskogly
<br/>
November 2, 2020 | https://blog.klungo.no/2020/11/01/you-might-not-need-to-store-plaintext-emails/ | <a href="https://web.archive.org/web/*/https://blog.klungo.no/2020/11/01/you-might-not-need-to-store-plaintext-emails/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Earlier this year, when I went from having only Facebook-login on <a href="https://wishy.gift/">Wishy.gift</a> to allow registrations with email address and password, one of my concerns was how to implement this is a way that protects the data and privacy of my users. I don’t have any ads or analytics on the site, the users can select whatever display name they want, and I never stored the email addresses I got from Facebook when a user registered or logged in - only a hashed<sup><a href="#fn1" id="fnref1">[1]</a></sup> version of the ID. Email addresses and passwords, on the other hand, are a whole other beast, and the consequences of a database breach much worse.</p>
<p>Considering that the only kind of emails I ever need to send out are transactional - no newsletters or other kinds of notifications - the only thing I need to store them for are as identifiers, and can safely be hashed.</p>
<p>For every transactional email I need to send out - registration, account recovery, and email change verification - the user always initiates this by submitting their email address, and it will at that time be available to the backend to perform the needed action.</p>
<p>In conclusion, if you only use email addresses for transactional emails, you might be able to only store hashed versions of them. For <a href="https://wishy.gift/">Wishy.gift</a> I use SHA512 with a fixed salt, and this has been working perfectly since implementation in June.</p>
<p>Thank you for reading this! I would love to hear your thoughts and ideas too. Join the discussion on <a href="https://news.ycombinator.com/item?id=24959734">Hacker News</a>, or feel free to email me at <code>daniel</code> at the domain this blog is on.</p>
<hr>
<section>
<ol>
<li id="fn1"><p>I discovered that, even though the ID was unique to my FB-app, it was still possible to go to <a href="http://facebook.com/%7Bid%7D">facebook.com/{id}</a> and be redirected to the user’s FB-profile. <a href="#fnref1">↩︎</a></p>
</li>
</ol>
</section>
</div></div>]]>
            </description>
            <link>https://blog.klungo.no/2020/11/01/you-might-not-need-to-store-plaintext-emails/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24965671</guid>
            <pubDate>Mon, 02 Nov 2020 08:11:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rendering photo-realistic glass in the browser]]>
            </title>
            <description>
<![CDATA[
Score 151 | Comments 46 (<a href="https://news.ycombinator.com/item?id=24965005">thread link</a>) | @anonytrary
<br/>
November 1, 2020 | https://domenicobrz.github.io/webgl/projects/SSRefractionDepthPeeling/ | <a href="https://web.archive.org/web/*/https://domenicobrz.github.io/webgl/projects/SSRefractionDepthPeeling/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://domenicobrz.github.io/webgl/projects/SSRefractionDepthPeeling/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24965005</guid>
            <pubDate>Mon, 02 Nov 2020 05:13:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Names are not type safety]]>
            </title>
            <description>
<![CDATA[
Score 186 | Comments 71 (<a href="https://news.ycombinator.com/item?id=24963821">thread link</a>) | @azhenley
<br/>
November 1, 2020 | http://lexi-lambda.github.io/blog/2020/11/01/names-are-not-type-safety/ | <a href="https://web.archive.org/web/*/http://lexi-lambda.github.io/blog/2020/11/01/names-are-not-type-safety/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section role="main">
        <!-- Main column -->
        <div>



          <article>
  <header>
    
    
  </header>

<p>Haskell programmers spend a lot of time talking about <em>type safety</em>. The Haskell school of program construction advocates “capturing invariants in the type system” and “making illegal states unrepresentable,” both of which sound like compelling goals, but are rather vague on the techniques used to achieve them. Almost exactly one year ago, I published <a href="http://lexi-lambda.github.io/blog/2019/11/05/parse-don-t-validate/">Parse, Don’t Validate</a> as an initial stab towards bridging that gap.</p>

<p>The ensuing discussions were largely productive and right-minded, but one particular source of confusion quickly became clear: Haskell’s <code>newtype</code> construct. The idea is simple enough—the <code>newtype</code> keyword declares a wrapper type, nominally distinct from but representationally equivalent to the type it wraps—and on the surface this <em>sounds</em> like a simple and straightforward path to type safety. For example, one might consider using a <code>newtype</code> declaration to define a type for an email address:</p>

<div>
 <div>
  <pre><span></span><span>newtype</span> <span>EmailAddress</span> <span>=</span> <span>EmailAddress</span> <span>Text</span>
</pre></div>

</div>

<p>This technique can provide <em>some</em> value, and when coupled with a smart constructor and an encapsulation boundary, it can even provide some safety. But it is a meaningfully distinct <em>kind</em> of type safety from the one I highlighted a year ago, one that is far weaker. On its own, a newtype is just a name.</p>

<p>And names are not type safety.</p>
<!-- more-->



<p>To illustrate the difference between constructive data modeling (discussed at length in my <a href="http://lexi-lambda.github.io/blog/2020/08/13/types-as-axioms-or-playing-god-with-static-types/">previous blog post</a>) and newtype wrappers, let’s consider an example. Suppose we want a type for “an integer between 1 and 5, inclusive.” The natural constructive modeling would be an enumeration with five cases:</p>

<div>
 <div>
  <pre><span></span><span>data</span> <span>OneToFive</span>
  <span>=</span> <span>One</span>
  <span>|</span> <span>Two</span>
  <span>|</span> <span>Three</span>
  <span>|</span> <span>Four</span>
  <span>|</span> <span>Five</span>
</pre></div>

</div>

<p>We could then write some functions to convert between <code>Int</code> and our <code>OneToFive</code> type:</p>

<div>
 <div>
  <pre><span></span><span>toOneToFive</span> <span>::</span> <span>Int</span> <span>-&gt;</span> <span>Maybe</span> <span>OneToFive</span>
<span>toOneToFive</span> <span>1</span> <span>=</span> <span>Just</span> <span>One</span>
<span>toOneToFive</span> <span>2</span> <span>=</span> <span>Just</span> <span>Two</span>
<span>toOneToFive</span> <span>3</span> <span>=</span> <span>Just</span> <span>Three</span>
<span>toOneToFive</span> <span>4</span> <span>=</span> <span>Just</span> <span>Four</span>
<span>toOneToFive</span> <span>5</span> <span>=</span> <span>Just</span> <span>Five</span>
<span>toOneToFive</span> <span>_</span> <span>=</span> <span>Nothing</span>

<span>fromOneToFive</span> <span>::</span> <span>OneToFive</span> <span>-&gt;</span> <span>Int</span>
<span>fromOneToFive</span> <span>One</span>   <span>=</span> <span>1</span>
<span>fromOneToFive</span> <span>Two</span>   <span>=</span> <span>2</span>
<span>fromOneToFive</span> <span>Three</span> <span>=</span> <span>3</span>
<span>fromOneToFive</span> <span>Four</span>  <span>=</span> <span>4</span>
<span>fromOneToFive</span> <span>Five</span>  <span>=</span> <span>5</span>
</pre></div>

</div>

<p>This would be perfectly sufficient for achieving our stated goal, but you’d be forgiven for finding it odd: it would be rather awkward to work with in practice. Because we’ve invented an entirely new type, we can’t reuse any of the usual numeric functions Haskell provides. Consequently, many programmers would gravitate towards a newtype wrapper, instead:</p>

<div>
 <div>
  <pre><span></span><span>newtype</span> <span>OneToFive</span> <span>=</span> <span>OneToFive</span> <span>Int</span>
</pre></div>

</div>

<p>Just as before, we can provide <code>toOneToFive</code> and <code>fromOneToFive</code> functions, with identical types:</p>

<div>
 <div>
  <pre><span></span><span>toOneToFive</span> <span>::</span> <span>Int</span> <span>-&gt;</span> <span>Maybe</span> <span>OneToFive</span>
<span>toOneToFive</span> <span>n</span>
  <span>|</span> <span>n</span> <span>&gt;=</span> <span>1</span> <span>&amp;&amp;</span> <span>n</span> <span>&lt;=</span> <span>5</span> <span>=</span> <span>Just</span> <span>$</span> <span>OneToFive</span> <span>n</span>
  <span>|</span> <span>otherwise</span>        <span>=</span> <span>Nothing</span>

<span>fromOneToFive</span> <span>::</span> <span>OneToFive</span> <span>-&gt;</span> <span>Int</span>
<span>fromOneToFive</span> <span>(</span><span>OneToFive</span> <span>n</span><span>)</span> <span>=</span> <span>n</span>
</pre></div>

</div>

<p>If we put these declarations in their own module and choose not to export the <code>OneToFive</code> constructor, these APIs might appear entirely interchangeable. Naïvely, it seems that the newtype version is both simpler and equally type-safe. However—perhaps surprisingly—this is not actually true.</p>

<p>To see why, suppose we write a function that consumes a <code>OneToFive</code> value as an argument. Under the constructive modeling, such a function need only pattern-match against each of the five constructors, and GHC will accept the definition as exhaustive:</p>

<div>
 <div>
  <pre><span></span><span>ordinal</span> <span>::</span> <span>OneToFive</span> <span>-&gt;</span> <span>Text</span>
<span>ordinal</span> <span>One</span>   <span>=</span> <span>"first"</span>
<span>ordinal</span> <span>Two</span>   <span>=</span> <span>"second"</span>
<span>ordinal</span> <span>Three</span> <span>=</span> <span>"third"</span>
<span>ordinal</span> <span>Four</span>  <span>=</span> <span>"fourth"</span>
<span>ordinal</span> <span>Five</span>  <span>=</span> <span>"fifth"</span>
</pre></div>

</div>

<p>The same is not true given the newtype encoding. The newtype is opaque, so the only way to observe it is to convert it back to an <code>Int</code>—after all, it <em>is</em> an <code>Int</code>. An <code>Int</code> can of course contain many other values besides <code>1</code> through <code>5</code>, so we are forced to add an error case to satisfy the exhaustiveness checker:</p>

<div>
 <div>
  <pre><span></span><span>ordinal</span> <span>::</span> <span>OneToFive</span> <span>-&gt;</span> <span>Text</span>
<span>ordinal</span> <span>n</span> <span>=</span> <span>case</span> <span>fromOneToFive</span> <span>n</span> <span>of</span>
  <span>1</span> <span>-&gt;</span> <span>"first"</span>
  <span>2</span> <span>-&gt;</span> <span>"second"</span>
  <span>3</span> <span>-&gt;</span> <span>"third"</span>
  <span>4</span> <span>-&gt;</span> <span>"fourth"</span>
  <span>5</span> <span>-&gt;</span> <span>"fifth"</span>
  <span>_</span> <span>-&gt;</span> <span>error</span> <span>"impossible: bad OneToFive value"</span>
</pre></div>

</div>

<p>In this highly contrived example, this may not seem like much of a problem to you. But it nonetheless illustrates a key difference in the guarantees afforded by the two approaches:</p>

<ul>
 <li>
  <p>The constructive datatype captures its invariants in such a way that they are <em>accessible</em> to downstream consumers. This frees our <code>ordinal</code> function from worrying about handling illegal values, as they have been made unutterable.</p></li>
 <li>
  <p>The newtype wrapper provides a smart constructor that <em>validates</em> the value, but the boolean result of that check is used only for control flow; it is not preserved in the function’s result. Accordingly, downstream consumers cannot take advantage of the restricted domain; they are functionally accepting <code>Int</code>s.</p></li></ul>

<p>Losing exhaustiveness checking might seem like small potatoes, but it absolutely is not: our use of <code>error</code> has punched a hole right through our type system. If we were to add another constructor to our <code>OneToFive</code> datatype,<sup><a href="#2020-11-01-names-are-not-type-safety-footnote-1-definition" name="2020-11-01-names-are-not-type-safety-footnote-1-return">1</a></sup> the version of <code>ordinal</code> that consumes a constructive datatype would be immediately detected non-exhaustive at compile-time, while the version that consumes a newtype wrapper would continue to compile yet fail at runtime, dropping through to the “impossible” case.</p>

<p>All of this is a consequence of the fact that the constructive modeling is <em>intrinsically</em> type-safe; that is, the safety properties are enforced by the type declaration itself. Illegal values truly are unrepresentable: there is simply no way to represent <code>6</code> using any of the five constructors. The same is not true of the newtype declaration, which has no intrinsic semantic distinction from that of an <code>Int</code>; its meaning is specified extrinsically via the <code>toOneToFive</code> smart constructor. Any semantic distinction intended by a newtype is thoroughly invisible to the type system; it exists only in the programmer’s mind.</p>

<h2 id="revisiting-non-empty-lists">Revisiting non-empty lists</h2>

<p>Our <code>OneToFive</code> datatype is rather artificial, but identical reasoning applies to other datatypes that are significantly more practical. Consider the <code>NonEmpty</code> datatype I’ve repeatedly highlighted in recent blog posts:</p>

<div>
 <div>
  <pre><span></span><span>data</span> <span>NonEmpty</span> <span>a</span> <span>=</span> <span>a</span> <span>:|</span> <span>[</span><span>a</span><span>]</span>
</pre></div>

</div>

<p>It may be illustrative to imagine a version of <code>NonEmpty</code> represented as a newtype over ordinary lists. We can use the usual smart constructor strategy to enforce the desired non-emptiness property:</p>

<div>
 <div>
  <pre><span></span><span>newtype</span> <span>NonEmpty</span> <span>a</span> <span>=</span> <span>NonEmpty</span> <span>[</span><span>a</span><span>]</span>

<span>nonEmpty</span> <span>::</span> <span>[</span><span>a</span><span>]</span> <span>-&gt;</span> <span>Maybe</span> <span>(</span><span>NonEmpty</span> <span>a</span><span>)</span>
<span>nonEmpty</span> <span>[]</span> <span>=</span> <span>Nothing</span>
<span>nonEmpty</span> <span>xs</span> <span>=</span> <span>Just</span> <span>$</span> <span>NonEmpty</span> <span>xs</span>

<span>instance</span> <span>Foldable</span> <span>NonEmpty</span> <span>where</span>
  <span>toList</span> <span>(</span><span>NonEmpty</span> <span>xs</span><span>)</span> <span>=</span> <span>xs</span>
</pre></div>

</div>

<p>Just as with <code>OneToFive</code>, we quickly discover the consequences of failing to preserve this information in the type system. Our motivating use case for <code>NonEmpty</code> was the ability to write a safe version of <code>head</code>, but the newtype version requires another assertion:</p>

<div>
 <div>
  <pre><span></span><span>head</span> <span>::</span> <span>NonEmpty</span> <span>a</span> <span>-&gt;</span> <span>a</span>
<span>head</span> <span>xs</span> <span>=</span> <span>case</span> <span>toList</span> <span>xs</span> <span>of</span>
  <span>x</span><span>:</span><span>_</span> <span>-&gt;</span> <span>x</span>
  <span>[]</span>  <span>-&gt;</span> <span>error</span> <span>"impossible: empty NonEmpty value"</span>
</pre></div>

</div>

<p>This might not seem like a big deal, since it seems unlikely such a case would ever happen. But that reasoning hinges entirely on trusting the correctness of the module that defines <code>NonEmpty</code>, while the constructive definition only requires trusting the GHC typechecker. As we generally trust that the typechecker works correctly, the latter is a much more compelling proof.</p>



<p>If you are fond of newtypes, this whole argument may seem a bit troubling. It may seem like I’m implying newtypes are scarcely better than comments, albeit comments that happen to be meaningful to the typechecker. Fortunately, the situation is not quite that grim—newtypes <em>can</em> provide a sort of safety, just a weaker one.</p>

<p>The primary safety benefit of newtypes is derived from abstraction boundaries. If a newtype’s constructor is not exported, it becomes opaque to other modules. The module that defines the newtype—its “home module”—can take advantage of this to create a <em>trust boundary</em> where internal invariants are enforced by restricting clients to a safe API.</p>

<p>We can use the <code>NonEmpty</code> example from above to illustrate how this works. We refrain from exporting the <code>NonEmpty</code> constructor, and we provide <code>head</code> and <code>tail</code> operations that we trust to never actually fail:</p>

<div>
 <div>
  <pre><span></span><span>module</span> <span>Data.List.NonEmpty.Newtype</span>
  <span>(</span> <span>NonEmpty</span>
  <span>,</span> <span>cons</span>
  <span>,</span> <span>nonEmpty</span>
  <span>,</span> <span>head</span>
  <span>,</span> <span>tail</span>
  <span>)</span> <span>where</span>

<span>newtype</span> <span>NonEmpty</span> <span>a</span> <span>=</span> <span>NonEmpty</span> <span>[</span><span>a</span><span>]</span>

<span>cons</span> <span>::</span> <span>a</span> <span>-&gt;</span> <span>[</span><span>a</span><span>]</span> <span>-&gt;</span> <span>NonEmpty</span> <span>a</span>
<span>cons</span> <span>x</span> <span>xs</span> <span>=</span> <span>NonEmpty</span> <span>(</span><span>x</span><span>:</span><span>xs</span><span>)</span>

<span>nonEmpty</span> <span>::</span> <span>[</span><span>a</span><span>]</span> <span>-&gt;</span> <span>Maybe</span> <span>(</span><span>NonEmpty</span> <span>a</span><span>)</span>
<span>nonEmpty</span> <span>[]</span> <span>=</span> <span>Nothing</span>
<span>nonEmpty</span> <span>xs</span> <span>=</span> <span>Just</span> <span>$</span> <span>NonEmpty</span> <span>xs</span>

<span>head</span> <span>::</span> <span>NonEmpty</span> <span>a</span> <span>-&gt;</span> <span>a</span>
<span>head</span> <span>(</span><span>NonEmpty</span> <span>(</span><span>x</span><span>:</span><span>_</span><span>))</span> <span>=</span> <span>x</span>
<span>head</span> <span>(</span><span>NonEmpty</span> <span>[]</span><span>)</span>    <span>=</span> <span>error</span> <span>"impossible: empty NonEmpty value"</span>

<span>tail</span> <span>::</span> <span>NonEmpty</span> <span>a</span> <span>-&gt;</span> <span>[</span><span>a</span><span>]</span>
<span>tail</span> <span>(</span><span>NonEmpty</span> <span>(</span><span>_</span><span>:</span><span>xs</span><span>))</span> <span>=</span> <span>xs</span>
<span>tail</span> <span>(</span><span>NonEmpty</span> <span>[]</span><span>)</span>     <span>=</span> <span>error</span> <span>"impossible: empty NonEmpty value"</span>
</pre></div>

</div>

<p>Since the only way to construct or consume <code>NonEmpty</code> values is to use the functions in <code>Data.List.NonEmpty.Newtype</code>’s exported API, the above implementation makes it impossible for clients to violate the non-emptiness invariant. In a sense, values of opaque newtypes are like <em>tokens</em>: the implementing module issues tokens via its constructor functions, and those tokens have no intrinsic value. The only way to do anything useful with them is to “redeem” them to the issuing module’s accessor functions, in this case <code>head</code> and <code>tail</code>, to obtain the values contained within.</p>

<p>This approach is significantly weaker than using a constructive datatype, since it is theoretically possible to screw up and accidentally provide a means to construct an invalid <code>NonEmpty []</code> value. For this reason, the newtype approach to type safety does not on its own constitute a <em>proof</em> that a desired invariant holds. However, it restricts the “surface area” where an invariant violation can occur to the defining module, so reasonable confidence the invariant really does hold can be achieved by thoroughly testing the module’s API using fuzzing or property-based testing techniques.<sup><a href="#2020-11-01-names-are-not-type-safety-footnote-2-definition" name="2020-11-01-names-are-not-type-safety-footnote-2-return">2</a></sup></p>

<p>This tradeoff may not seem all that bad, and indeed, it is often a very good one! Guaranteeing invariants using …</p></article></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://lexi-lambda.github.io/blog/2020/11/01/names-are-not-type-safety/">http://lexi-lambda.github.io/blog/2020/11/01/names-are-not-type-safety/</a></em></p>]]>
            </description>
            <link>http://lexi-lambda.github.io/blog/2020/11/01/names-are-not-type-safety/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24963821</guid>
            <pubDate>Mon, 02 Nov 2020 00:27:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Collision]]>
            </title>
            <description>
<![CDATA[
Score 128 | Comments 14 (<a href="https://news.ycombinator.com/item?id=24963131">thread link</a>) | @vijayr02
<br/>
November 1, 2020 | https://fiftytwo.in/story/collision/ | <a href="https://web.archive.org/web/*/https://fiftytwo.in/story/collision/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-154a69ab=""><div data-v-154a69ab=""><p>
              T
            </p> <div data-v-154a69ab=""><p>hat November evening, the people of Charkhi Dadri town, about 100km west of Delhi, were done with the day’s work out in the fields. Some of them heard the sky detonate with thunder and erupt into flames. On the ground, doors and windows crumbled. Glass shards flew through the air.</p><p>Mistaking it for an earthquake, residents streamed out of their homes, only to find over 500 tonnes of material pouring out from the sky—what an <em>India Today</em> story vividly described as “the equivalent of 600 Maruti cars”. The planes plunged into the mustard and cotton fields, miraculously hitting no one on the ground. There were rumours of a few survivors found in the wreckage, but none were ever brought to a hospital.&nbsp;</p></div></div><p>At about 9pm, as Prannoy Roy finished reading for <em>The News Tonight</em>, the daily English bulletin on Doordarshan, wire services broke the story of a mid-air collision just outside Delhi. Most journalists had already left for the day, and the crowd at the studios of NDTV, a private news production company, was thinning. Writer and film-maker Natasha Badhwar, then a 25-year-old cameraperson two years out of Jamia Millia Islamia University, quickly volunteered herself for the story. Along with reporter Radhika Bordia and camera assistant Kanan Patra, she got into an office vehicle and headed towards Charkhi Dadri. As they approached the site, they saw a massive inferno raging in the distance, ringed by smaller fires. </p><p>They got out of the car and began to walk through the debris and darkness. When Badhwar struck something, the group stopped and switched on the camera light. A stiff body swam into view, dead, but not burnt or broken. The man looked in death as he might have in life. How do you film a dead body, Badhwar wondered. “There was a sense of horror I could not shut out,” she said. “There was a sense of incredulity: How could this happen? How could two planes collide?”</p><p>Through the night, journalists arrived to scenes of damage and disarray. Passports, bags of food, toys, slippers, wallets, wrenched-open suitcases and airplane seats were flung around. Disembodied human limbs lay scattered like confetti. The full horror would not be apparent until sunrise, but the acrid stench of burning fuselage and singed remains had already begun choking the air.</p><p>At one point, the grandson of a prominent politician waltzed in,<a href="" onclick="return!1"><sup id="2pzmabfu9t5s">[4]</sup></a> chaperoned by a group of sidekicks and handlers. He had no reason to be there but quickly became the centre of attention. When asked what he was doing there, he smarmily replied, “Plane curiosity.”&nbsp;</p><p>Through the night, villagers tried to find survivors as emergency services arrived. By the morning, several bodies were moved into a school which had been converted to a makeshift morgue. Debris had scattered over a radius of several kilometres, complicating search and rescue operations. </p><p>KPS Nair was among the first team of investigators and diplomats to reach the scene as dawn broke. Then a Deputy Director with the Directorate General of Civil Aviation (DGCA), Nair had been in a meeting on air safety when news filtered in the previous evening. The irony was inescapable. “My first thought was, my god!” he recalled over the phone in June 2020. “Why do such things happen in spite of the efforts of human beings to make better flying machines and systems?”</p><p>As lead investigator, his first impulse was to locate the “black boxes”, vermilion-coloured crash-proof casings that held the cockpit voice recorder (CVR) and the flight data recorder (FDR). The CVR, which saved the last 30 minutes of cockpit conversation, could provide precious insight into what the crew had said to each other. The FDR would provide readings on altitude, speed, flight path and engine power to help build a picture of both planes’ vital parameters. “This,” Nair explained, “is the most important tool in the hands of an investigator from the accident site.”</p><div data-v-154a69ab=""><p>Both black boxes were found before nightfall on the day following the accident. The cockpit of the Saudi aircraft was stuck deeper in the ground, irrevocably damaged, none of its instruments readable. All three of its altimeters were destroyed in the fire.&nbsp;</p><p>The Kazakh plane had suffered less damage and yielded four altimeters. Two of them, curiously, showed different readings: 4,443m (14,576 feet) and 4,540m (14,895 feet). The other two were unreadable.&nbsp;</p></div><p>Nair scoured the fields, analysing the debris scattered across two sites seven kilometres apart, searching for clues in the carcasses of the two planes. “We approach any accident with an open mind,” he said. “We ask, did everyone involved apply the necessary procedures? The contributing factors we look at include the ATC communications, pilot error, engineering and maintenance aspects.” </p><p>AK Chopra, then head of air safety for the North region at the DGCA, also reached the site with his team. Chopra sensed something puzzling, even counter-intuitive. The frontal structure of the Kazakh flight was mostly intact, which indicated that this hadn’t been a head-on collision. If the Kazakh plane was supposed to have been higher (15,000 feet), why did a primary assessment suggest that it had hit the Saudi plane from below? </p><p>By mid-afternoon, just 19 bodies had been claimed from the morgue. Rescue workers tried to pick through the debris, retrieving limbs and luggage. Badhwar even encountered the studio in-charge from Jamia’s Mass Communication Research Centre, mourning the loss of a younger brother who had been on the flight.&nbsp;</p><p>For at least 15 hours after the crash, there was little sense of sanctity about the site, which was only cordoned off much later.<a href="" onclick="return!1"><sup id="z5s3bz6hivmy">[5]</sup></a> Some people rifled through the wreckage and corpses, trying to make off with the spoils. But for the most part, people were kind and helpful, bringing sheets from their homes for the bodies, volunteering tractors in search efforts, and offering tea to families. </p><p>Over time, the horror of losing a loved one morphed into the numbing pain of dealing with paperwork. Relatives scrambling to apply for compensation and obtain death certificates shuttled from one office to another. The Saudis announced compensation of up to GBP 12,000 for the families of passengers, and some compensation<a href="" onclick="return!1"><sup id="k4yf7bl2nlj4">[6]</sup></a> for the villagers in whose fields the flights had crashed.&nbsp;</p><p>In the end, 94 bodies were charred beyond recognition or totally mutilated. They lay piled up in the morgue, their limbs on ice. Many of the dead were from mofussil areas. Their families would hear about the tragedy only much later, particularly since some didn’t even know their relatives were on board.<a href="" onclick="return!1"><sup id="xjunwbq7ccht">[7]</sup></a> Others, perhaps, never found out at all, given the underhand manner in which agents and touts recruited people for jobs abroad.<a href="" onclick="return!1"><sup id="am1u2ycez0x2">[8]</sup></a></p><p>After 15 days in the morgue, the unclaimed bodies were divided in proportion to the Hindus and Muslims on board according to the passenger manifest, a compromise between community leaders following an initial dispute. First, everyone went to the Muslim burial ground; later they went to the crematorium. Badhwar, still processing the disaster she had covered, attended the mass funerals and filmed them. “The smell of burning flesh still haunted me,” she said. “I felt I had some undone mourning to do.”</p></div></div>]]>
            </description>
            <link>https://fiftytwo.in/story/collision/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24963131</guid>
            <pubDate>Sun, 01 Nov 2020 22:33:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Algebraic Effects for React Developers]]>
            </title>
            <description>
<![CDATA[
Score 122 | Comments 72 (<a href="https://news.ycombinator.com/item?id=24962842">thread link</a>) | @reesew
<br/>
November 1, 2020 | https://reesew.io/posts/react-algebraic-effects | <a href="https://web.archive.org/web/*/https://reesew.io/posts/react-algebraic-effects">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><blockquote>
<p>It’s in words that the magic is—Abracadabra, Open Sesame, and the rest—but the magic words in one story aren’t magical in the next.
The real magic is to understand which words work, and when, and for what; the trick is to learn the trick.</p>
<p>- John Barth, <em>Chimera</em></p>
</blockquote>
<p>It’s been quite some time since Hooks were officially stabilized in <a href="https://reactjs.org/blog/2019/02/06/react-v16.8.0.html" target="_blank" rel="nofollow noopener noreferrer">React 16.8</a>, and with them came a fundamentally different way of understanding the way our applications work.
This is both a blessing and a curse: Hooks are much closer to the React programming model and help avoid a certain class of subtle and confusing bugs, but some developers have also expressed concerns that <a href="https://jaredpalmer.com/blog/react-is-becoming-a-black-box" target="_blank" rel="nofollow noopener noreferrer">React is becoming a black box</a>.
These concerns are completely valid; Hooks can often seem “magical,” since most of the complexities are hidden away in React’s internals.</p>
<p>Much of that “magical” feeling is simply due to the fact that Hooks are based on some <a href="https://reactjs.org/docs/hooks-faq.html#what-is-the-prior-art-for-hooks" target="_blank" rel="nofollow noopener noreferrer">prior art</a> and programming language research that many developers simply aren’t familiar with.
Understanding some of the motivations and inspirations for Hooks can help build a mental model for what’s happening behind the scenes.
While there are several sources of influence on the original Hooks proposal, arguably the most important is the notion of algebraic effects.</p>
<blockquote>
<p>❗❗ Note that this article is <em>not</em> an introduction into how to <em>use</em> Hooks or how Hooks work internally.
This is merely a way to <em>think</em> about Hooks. For more information about how to use them, I suggest
starting with <a href="https://reactjs.org/docs/hooks-intro.html" target="_blank" rel="nofollow noopener noreferrer">the docs</a>.</p>
</blockquote>
<p>Before diving into the details of algebraic effects, let’s first take a step back.</p>
<h2 id="why-do-we-need-hooks"><a href="#why-do-we-need-hooks" aria-label="why do we need hooks permalink"></a>Why Do We Need Hooks?</h2>
<p>Class components seemed to be working well enough, why add <em>another</em> way of writing components that, at least at face value, do the same thing?</p>
<p><img src="https://reesew.io/media/DysfunctionalClassComponents.png" alt="First tweet by @rickhanlonii: &quot;The existence of functional components implies the existence of dysfunctional components&quot;. Reply tweet by @sebmarkbage: &quot;We call those 'class components'.&quot;"></p>
<p>One of React’s core principles is the idea that an application’s user interface is a pure function of that application’s state.
Here, “state” can refer to any combination of local component state and global state, such as a Redux store.
When that state changes and propagates through your component tree, the output represents your new UI after that state change.
This is, of course, an abstraction over the nuts and bolts of how that update actually happens, since React handles the actual reconciliation and DOM updates that are necessary, but this core principle means, at least in theory, that our UI is always synchronized with our data.</p>
<p>Of course, this isn’t always true.
Class components expose certain scenarios that allow us to ignore changes in state if we don’t effectively handle those state changes in our lifecycle methods.
Dan Abramov wrote an <a href="https://overreacted.io/writing-resilient-components/#dont-stop-the-data-flow-in-side-effects" target="_blank" rel="nofollow noopener noreferrer">excellent article</a> on some common pitfalls related to this that’s worth a read for more detail.
In short, class components use different lifecycle methods to handle side effects, but that maps side effects to DOM operations, <em>not</em> state changes.
This means that while the visual elements of our UI may respond to state changes, our side effects might not.</p>
<p>Because class components have to do these internal updates to synchronize their internal state when props change, they are by definition <em>impure</em>.
<em>But wait</em>, you say, <em>I thought we said that UI was a <em>pure</em> function of state</em>.</p>
<p><em>Precisely</em>.
This is where Hooks come into play.</p>
<p>Hooks represent a different way of thinking about effects.
Instead of thinking about the entire lifecycle of a component, Hooks allow us to narrow our focus to only the current state.
We can then <em>declare</em> the states in which we want our effects to run, ensuring that those state changes are reflected in our effects.
Of course, an “effect” can be many things, from handling state with <code>useState</code>, making network requests or manually updating the DOM with <code>useEffect</code>, or calculating expensive callback functions with <code>useCallback</code>.</p>
<p>But how do we reason about those side effects within a pure function?
I’m glad you asked!</p>
<h2 id="an-introduction-to-algebraic-effects"><a href="#an-introduction-to-algebraic-effects" aria-label="an introduction to algebraic effects permalink"></a>An Introduction to Algebraic Effects</h2>
<p><em>Algebraic effects</em> are a generalized approach to reasoning about computational effects in pure contexts by defining an <em>effect</em>, a set of operations, and an effect <em>handler</em>, which is responsible for handling the semantics of how to implement effects.<sup id="fnref-1"><a href="#fn-1">1</a></sup>
Algebraic effects generalize over a whole host of potential uses, like input and output, handling state, <code>async</code>/<code>await</code>, and many more.</p>
<p>This is a little abstract, so let’s write some code to see how this works in practice.
Unfortunately, JavaScript doesn’t actually support algebraic effects, although React might mimic them internally.
While there are a few different languages<sup id="fnref-2"><a href="#fn-2">2</a></sup> that support algebraic effects, we’re going to use <a href="https://github.com/matijapretnar/eff" target="_blank" rel="nofollow noopener noreferrer">Eff</a>, a functional programming language designed specifically around algebraic effects.
Don’t worry, <em>most</em> people won’t know Eff, so I’ll explain some syntax as we go along<sup id="fnref-3"><a href="#fn-3">3</a></sup>.</p>
<p>A common use case for algebraic effects is handling stateful computations.
Remember that effects are just in an interface with a set of operations.
In Eff, we defined effects with the <code>effect</code> keyword and a type signature:</p>
<!---
I'm using OCaml tags in the markdown here because there's obviously
no highlighting options for Eff.
-->
<div data-language="ocaml"><pre><code>


<span>type</span> user <span>=</span> string <span>*</span> int

effect <span>Get</span><span>:</span> user
effect <span>Set</span><span>:</span> user <span>-&gt;</span> unit</code></pre></div>
<p>Once we’ve defined what effects our effects will look like, we can define how our effects are handled by using the <code>handler</code> keyword.</p>
<div data-language="ocaml"><pre><code><span>let</span> state <span>=</span> handler
  <span>|</span> y <span>-&gt;</span> <span>fun</span> currentState <span>-&gt;</span> <span>(</span>y<span>,</span> currentState<span>)</span>
  <span>|</span> effect <span>Get</span> k <span>-&gt;</span> <span>(</span><span>fun</span> currentState <span>-&gt;</span> <span>(</span>continue k currentState<span>)</span> currentState<span>)</span>
  <span>|</span> effect <span>(</span><span>Set</span> newState<span>)</span> k <span>-&gt;</span> <span>(</span><span>fun</span> <span>_</span> <span>-&gt;</span> <span>(</span>continue k <span>(</span><span>)</span><span>)</span> newState<span>)</span>
<span>;</span><span>;</span></code></pre></div>
<p>Hmm, this looks a little trickier — let’s break it down a bit.
We have a <code>handler</code> with three branches, and all of them return a function.
That function will be used to handle some effect (or lack thereof).</p>
<p>The first branch, <code>y -&gt; fun currentState -&gt; (y, currentState)</code>, represents <em>no</em> effect, which happens when we reach the end of the block we’re handling (which we’ll see shortly). <code>y</code> here is the return value of the function, so this simply returns a tuple of the inner return and the state.</p>
<p>The second and third branches match our effects, but there’s a suspicious argument <code>k</code>.
<code>k</code> here is a <em>continuation</em>, which represents the rest of the computation <em>after</em> where we perform an effect.</p>
<div><p>GOTO, but better</p><div><blockquote>
<p>At my heart, I am something like the goto instruction; my creation sets the label, and my methods do the jump. However, this is a really powerful kind of goto instruction. If your hair is turning green at this point, don’t worry as you will probably only deal with users of continuations, rather than with the concept itself.</p>
</blockquote><p>This little gem comes from the GNU Smalltalk <a href="https://www.gnu.org/software/smalltalk/manual-base/html_node/Continuation.html" target="_blank" rel="nofollow noopener noreferrer"><code>Continuation</code> documentation</a>.
For some of you, the reference to <code>GOTO</code> might make you a little nauseated, but there’s a reason that continuations still have their place as a control flow, which is about <em>context</em>.
One of the more treacherous aspects of <code>GOTO</code> is getting plopped into an invalid context, but with continuations, you’re really storing an in-flight <em>process</em>, so the variables, pointers, and so on will all be valid.<sup id="fnref-5"><a href="#fn-5">5</a></sup></p></div></div>
<p>Because continuations represent the entire process in action, they’re essentially a snapshot of the call stack at the time of the effect.
When we get to an effect, it’s almost as if we hit a giant pause button on the computation until we properly handle the effect.
Calling <code>continue k</code><sup id="fnref-4"><a href="#fn-4">4</a></sup> is like hitting the play button again.</p>
<p>Alright, I think we’re ready to see our effect handlers in action.
Right now, we have a user in state; let’s wish them well on their birthday:</p>
<div data-language="ocaml"><pre><code><span>let</span> celebrate <span>=</span> <span>with</span> state handle
  <span>let</span> <span>(</span>name<span>,</span> age<span>)</span> <span>=</span> perform <span>Get</span> <span>in</span>

  print<span>_</span>string <span>"Happy Birthday, "</span><span>;</span>
  print<span>_</span>string name<span>;</span>
  print<span>_</span>endline <span>"!"</span><span>;</span>

  perform <span>(</span><span>Set</span> <span>(</span>name<span>,</span> age<span>+</span><span>1</span><span>)</span><span>)</span><span>;</span>
  perform <span>Get</span>
<span>;</span><span>;</span>

celebrate<span>(</span><span>(</span><span>"Henry"</span><span>,</span> <span>39</span><span>)</span><span>)</span><span>;</span><span>;</span></code></pre></div>
<p>When we start off this computation, we first <code>Get</code> our user from state, which runs the second branch in our handler.
At this point, we’ve hit the pause button, so the function has stopped running while we get this from state.
The handler gives us back a function, which calls <code>continue k currentState</code>, resuming our computation with the value of <code>currentState</code>.</p>
<p>This same flow happens every time we <code>perform</code> an effect.
Hit pause, do some work, hit play.</p>
<p><img src="https://reesew.io/media/CelebrateToBeContinued.png" alt="Our code for the celebrate function, overlaid with the &quot;To Be Continued&quot; meme from Jojo's Bizarre Adventure."></p>
<!-- markdownlint-disable MD033 -->
<figcaption>I'm so sorry</figcaption>
<p>And here, dear reader, is where the power of algebraic effects really shines.
You see, it doesn’t really <em>matter</em> how we hold state.
Sure, right now it’s just an object in memory, but what if it was in a database?
What if it was stored in a browser’s <code>localStorage</code>?
As far as <code>celebrate</code> knows, these are <em>all the same</em>.
If we wanted, we could swap out our <code>state</code> handler with a <code>redisState</code> handler that stored state in a key-value store.</p>
<p>In JavaScript, your code has to be aware of what’s synchronous and what’s not.
If this were to change in the future, and state was handled asynchronously, we would need to start handling Promises, which would require changes across <em>everything</em> that touches this function.
But with algebraic effects, instead of maintaining a running process that holds a reference to a <em>different</em> process, we can simply stop the current process altogether until our effects are finished.</p>
<p>Of course, state isn’t the only thing that we can handle with algebraic effects.
Let’s say we have some network request we want to make or cleanup we want to execute, but we only want to do it <em>after</em> our function is done.
We’ll call it a <code>Defer</code> effect.</p>
<div data-language="ocaml"><pre><code>effect <span>Defer</span><span>:</span> <span>(</span>unit <span>-&gt;</span> unit<span>)</span> <span>-&gt;</span> unit

<span>let</span> defer <span>=</span> handler
    <span>|</span> y <span>-&gt;</span> <span>fun</span> <span>(</span><span>)</span> <span>-&gt;</span> <span>(</span><span>)</span>
    <span>|</span> effect <span>(</span><span>Defer</span> effectFunc<span>)</span> k <span>-&gt;</span>
        <span>(</span><span>fun</span> <span>(</span><span>)</span> <span>-&gt;</span>
            continue k <span>(</span><span>)</span><span>;</span>
            effectFunc <span>(</span><span>)</span>
        <span>)</span>
<span>;</span><span>;</span></code></pre></div>
<p>Notice that <code>continue k ()</code> doesn’t have to be the last part of the handler, as it was in our <code>state</code> handler.
We can call continuations <em>whenever</em> we want and however many times we want — remember, they’re just representations of a process.</p>
<p>To make sure this works as intended, let’s make a quick sketch of how this might work in practice:</p>
<div data-language="ocaml"><pre><code><span>let</span> runWithCleanup <span>=</span> <span>with</span> defer handle
    print<span>_</span>endline <span>"Starting our computation"</span><span>;</span>
    perform <span>(</span><span>Defer</span> <span>fun</span> <span>(</span><span>)</span> <span>-&gt;</span> print<span>_</span>endline <span>"Running cleanup"</span><span>)</span><span>;</span>
    
    print<span>_</span>endline <span>"Finishing computation"</span>
<span>;</span><span>;</span>

runWithCleanup<span>(</span><span>)</span><span>;</span><span>;</span></code></pre></div>
<p>When we run this, we get the following in our terminal:</p>
<div data-language="shell"><pre><code>$ eff defer.eff</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://reesew.io/posts/react-algebraic-effects">https://reesew.io/posts/react-algebraic-effects</a></em></p>]]>
            </description>
            <link>https://reesew.io/posts/react-algebraic-effects</link>
            <guid isPermaLink="false">hacker-news-small-sites-24962842</guid>
            <pubDate>Sun, 01 Nov 2020 21:51:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Winamp for Windows 10]]>
            </title>
            <description>
<![CDATA[
Score 261 | Comments 136 (<a href="https://news.ycombinator.com/item?id=24962823">thread link</a>) | @zindera
<br/>
November 1, 2020 | http://www.mywinamp.com/winamp-for-windows-10-download/ | <a href="https://web.archive.org/web/*/http://www.mywinamp.com/winamp-for-windows-10-download/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>



<p>Last updated: November 01, 2020<br>
File Size: 22.00 MB</p>
<p>Winamp has remained a firm favourite for many tech geeks and music lovers alike. It had appeared to lose its way for a while, as it was slow in coming forward with newer versions, which could be supported by more modern software. This all looks set to change and could be the revival that Winamp truly deserves. The new update, BETA version 5.8, seems to have found its way onto the internet, hinting that this could be a step towards this fan favourite being supported by Windows 10. Although its Belgian owners, Radionomy, are yet to make a formal release statement.</p>
<p><a href="http://www.mywinamp.com/wp-content/uploads/2015/07/Winamp-Windows-101.jpg"><img loading="lazy" src="http://www.mywinamp.com/wp-content/uploads/2015/07/Winamp-Windows-101-300x225.jpg" alt="Download Winamp for Windows 10" width="300" height="225" srcset="http://www.mywinamp.com/wp-content/uploads/2015/07/Winamp-Windows-101-300x225.jpg 300w, http://www.mywinamp.com/wp-content/uploads/2015/07/Winamp-Windows-101.jpg 1024w, http://www.mywinamp.com/wp-content/uploads/2015/07/Winamp-Windows-101-541x406.jpg 541w" sizes="(max-width: 300px) 100vw, 300px"></a></p>
<p>Support for Windows Audio seems to be one of the key developments and this change allows for complete compatibility with Windows 10. No doubt, it will have the usual teething problems, but as has been shown before, it’s the fans and enthusiasts who have helped to push the software in the right direction when it comes to tweaks and apps. Winamp has launched their own forum for just this purpose and it’s great to see fans new and old being able to discuss both their excitement and, as to be expected at this early stage, some of their frustrations.</p>
<p>The goal of this new set of developers has been clearly defined as, the intention to make Winamp the player of today and provide an up to date and complete listening experience. One of the best things they’ve done so far is to remove any old pro licences, making Winamp 100% free to use again. There are also some other current fixes which have been included in the new version, these fixes include, resolved – slow loading issue, improved – updated scroll bar and buttons, fixed – various memory leaks. There are tons more additions and you can see the complete list of updates, fixes and resolutions within the new BETA version.</p>
<p>The go-to functions of customisable skins, visualisation, plugins and the ability to design and make your media player unique to you, are all still high on the agenda and remain some of the software’s key features. The fact that it can now be supported by Windows 10 has also opened up other new avenues. There are more advanced video plugins which can now be supported whereas previously there were some issues with this. There is no multinational version available with Lang packs as yet, but they’re working on the language packs, with Spanish and Polish currently available on the BETA version.</p>
<p>For more avid users of Winamp, they’ll be pleased to know the CD playback and ripping functions now use native Windows API instead of Sonic. The AAC decoder now uses Media foundation, Vista and higher and the H.264 decoder is now also using Media foundation, Vista and higher. These technical changes demonstrate that Winamp is taking itself seriously and has finally understood there is still a huge legion of fans who will willingly support and promote this unequalled media player. There is still nothing as flexible, yet as technically delightful as Winamp when it comes to creating and building your own individual home for music.</p>
<p>Back in October 2018, Radionomy’s CEO, Alexandre Saboundjan hinted that we could expect to see a version 6 available in 2019. 5 months into the year there have been no further corporate updates, including whether or not it will be able to support newer services or how it might integrate with the big players such as Apple Music and Spotify. However, the fact that the owners of Winamp are starting to understand the true potential behind this awesome media player can surely be nothing but good a sign for hardcore Winamp enthusiasts.</p>
<p>The beauty of Winamp is that you experience all of your music in a single place and this makes it a singular experience. There’s no need to go switching between platforms and getting lost in remembering where dedicated playlists are saved. The visualization aspect of Winamp and its spectrum analyser has always allowed people to bring their music to life. To see and feel it. It’s fantastic to see the BETA version available, and the input this is allowing fans and users alike to generate.</p>
<p>We’ve touched on some of the updates but there are a few others that deserve a mention. You can slow down the pop-up buttons, so they don’t overtake the screen and they’ve also improved the browse path and edit title functions in Editor. The OpenMPT-base module player has also been improved and they’ve replaced the MikMod player. The added functionality which can now be supported by Windows 10 is set to continue and we can expect to see more and advances over the coming months.</p>
<p>With only the BETA version being released so far, it’s safe to say, this is a work in progress, but I for one look forward to being a part of the continuing journey to restoring Winamp to its former and well-deserved glory.</p>
<p>Here you can find the Winamp for Windows 10 (Windows media player) with contain required update patches. Windows 10 had backward compatibility with Winamp skins and popular plugins. Compatibility Winamp updates for security&nbsp;support are have already installed. Winamp works perfectly well with Windows 10.</p>
<p><a href="http://www.mywinamp.com/downloads/Winamp-5.666-MULTI.zip">Download Winamp for Windows 10</a></p>
<p>Winamp Essentials Pack 5.6 &amp; 5.7 <a href="http://www.mywinamp.com/winamp-essentials-pack/">Download page</a></p>
 </div></div>]]>
            </description>
            <link>http://www.mywinamp.com/winamp-for-windows-10-download/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24962823</guid>
            <pubDate>Sun, 01 Nov 2020 21:48:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Flutter Web: A Fractal of Bad Design]]>
            </title>
            <description>
<![CDATA[
Score 104 | Comments 71 (<a href="https://news.ycombinator.com/item?id=24962504">thread link</a>) | @adrian_mrd
<br/>
November 1, 2020 | https://hugotunius.se/2020/10/31/flutter-web-a-fractal-of-bad-design.html | <a href="https://web.archive.org/web/*/https://hugotunius.se/2020/10/31/flutter-web-a-fractal-of-bad-design.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main"><article>
  
  <div><p>The web has a long and rich history dating back to the nineties at CERN. Back then <a href="https://twitter.com/timberners_lee">Tim Berners-Lee</a> laid the foundation of HTML that is still around today. There have been attempts to replace it with varying success but none have been successful, for good reason. HTML and the later invention of CSS are a remarkably powerful set of tools to build all kinds of experiences on the web. People are still trying to replace HTML, which brings us to the topic of this post: Flutter Web.</p>

<p><a href="https://flutter.dev/web">Flutter Web</a> is part of Google’s <a href="https://flutter.dev/">Flutter</a> framework for building cross platform UI. Hailed by many developers as the best thing since sliced bread, my opinion of it lacks the rose coloured glasses. I haven’t looked at Flutter for other platforms than web so I cannot comment on it other than that the general principle of Flutter is a terrible idea. Flutter works by throwing away the native UI toolkits provided by the platform and rendering everything from scratch using OpenGL et al. This translates extremely poorly to the web platform in particular. It’s worth noting that Flutter for Web is currently in beta and the problems I am about to detail could be addressed. However, I believe these issues are fundamental to Flutter’s design choices so I feel confident in my criticism.</p>

<h2 id="semantic-html">Semantic HTML</h2>

<p>Anyone learning HTML these days would have encountered the term “Semantic HTML” because it is such an important part of modern web. <a href="https://www.petelambert.com/">Pete Lambert</a> describes why this is important in the excellent blog post <a href="https://www.petelambert.com/journal/html-is-the-web">HTML is the Web</a>. In short, the visible portion of a website, i.e. presentation, is only half the story. To take an example Pete used, a <code>div</code> with an <code>onClick</code> handler might be clickable and can be styled to look like a button, but that doesn’t make it a button. The semantic structure of a document matters because that’s how machines, not humans, understand the web. A <code>div</code> with an <code>onClick</code> handler doesn’t look like a link or a button to a screen reader, search engine crawler, or accessibility extension, it looks like a <code>div</code>.</p>

<p>Most importantly, semantic HTML is key for accessibility and other tools that let a user experience the web as they wish.</p>

<h2 id="a-fractal-of-bad-design">A Fractal of Bad Design</h2>

<p>Does Flutter Web generate semantic HTML? Not even close. It generates a patchwork of <code>canvas</code> elements, custom elements, and a few other HTML elements. In the demo app <a href="https://gallery.flutter.dev/#/reply">Reply</a>, how many buttons and links are there? If you guessed <strong>zero</strong>, congratulations you are as jaded and cynical as me. Let me reiterate that, an email app with no buttons and links! Because there are no links in particular, features like cmd/ctrl clicking to open a new tab, hovering links to see the URL, and using the context menu do not work.</p>

<p>I use the browser extension <a href="https://vimium.github.io/">Vimium</a> to navigate the web, it’s an amazingly powerful tool that relies on, you guessed it, semantic HTML. Does it work on pages built with Flutter Web? Fuck no. It doesn’t work because it tries to find things that are semantically clickable, like <code>button</code> or <code>a</code> elements, of which, as we have established, Flutter Web generates none. Vimium works on almost all websites I use because most developers, thankfully, don’t just stick <code>onClick</code> handlers on <code>div</code>s. However, whatever crazy shit Flutter Web does, doesn’t look clickable. Things being clickable that don’t look clickable is a good proxy for poor accessibility. For example, screen readers can navigate by landmarks, such as headings, <strong>links</strong>, forms, and other semantic elements, does any of this work with Flutter Web? Fuck no.</p>

<p>Even worse, unless you use special “selectable” text, Flutter Web doesn’t even support selecting text. No joke, their own code examples have a “copy all” button to get around this.</p>

<p><a href="https://hugotunius.se/img/flutter-web-a-fractal-of-bad-design/code-example.png"><img src="https://hugotunius.se/img/flutter-web-a-fractal-of-bad-design/code-example.png?1604348346" alt="Screenshot of Flutter's Navigation Bar component with preview, code, and &quot;copy all&quot; button"></a></p>

<p>How did anyone look at this and say “yeah nah, selecting text isn’t an important use case on the web”? Why does selecting text matter you ask? Some people use it to aid with reading by selecting the text they are currently reading, other people use it to(and I know this is wild) copy parts of the text, people with dyslexia use tools that read out selected portions of the text to help them read. Does any of this work with Flutter’s default, unselectable text? Fuck no!</p>

<p>While we are talking about dyslexia, another useful feature that help people who suffer from it is the ability to change the fonts of web pages to one they find easier to read, such as <a href="https://www.opendyslexic.org/">OpenDyslexic</a>. There are many tools that help with this and they all rely on the ability to inject custom CSS in a web page, to my surprise this actually looked to work when I tried it on some of the Flutter Web demos. However, looks deceive and while the font does apply it causes text to get cut off in almost all instances because of the terrible HTML Flutter generates. For example, in the “Reply” email client here’s the tag for the word “Reply” in the upper right</p>

<figure><pre><code data-lang="html"><span>&lt;p</span> <span>style=</span><span>"font-size: 18px; font-weight: normal; font-family: WorkSans_regular, -apple-system, BlinkMacSystemFont, sans-serif; color: rgb(255, 255, 255); letter-spacing: 0px; position: absolute; white-space: pre-wrap; overflow-wrap: break-word; overflow: hidden; height: 27px; width: 54px; transform-origin: 0px 0px 0px; transform: matrix(1, 0, 0, 1, 59, 3.5); left: 0px; top: 0px;"</span><span>&gt;</span>REPLY<span>&lt;/p&gt;</span></code></pre></figure>

<p>Cleaned up a bit and these are the attributes</p>

<figure><pre><code data-lang="plain">font-size: 18px;
font-weight: normal;
font-family: WorkSans_regular, -apple-system, BlinkMacSystemFont, sans-serif; color: rgb(255, 255, 255);
letter-spacing: 0px;
position: absolute;
white-space: pre-wrap;
overflow-wrap: break-word;
overflow: hidden;
height: 27px;
width: 54px;
transform-origin: 0px 0px 0px;
transform: matrix(1, 0, 0, 1, 59, 3.5);
left: 0px;
top: 0px;</code></pre></figure>

<p>Flutter Web generates absolutely positioned fixed sized HTML which instead of adopting to the text layout specified by the browser just cuts the text off.</p>

<p>Another useful feature that is common in accessibility extensions is making links stand out more. This works by injecting global CSS rules that target <code>a</code> tags on the page.</p>

<p><a href="https://hugotunius.se/img/flutter-web-a-fractal-of-bad-design/link-underlines.png"><img src="https://hugotunius.se/img/flutter-web-a-fractal-of-bad-design/link-underlines.png?1604348346" alt="Screenshot of links with link emphasis turned on which underlines them in multiple colours"></a></p>

<p>Does this work with Flutter Web (this questions is starting to feel redundant because the answer is almost always “No”)? Fuck no! In general, users use custom stylesheets for a multitude of reasons not limited to accessibility. As a “fun” exercise try this <a href="https://ssb22.user.srcf.net/css/">low vision stylesheet</a> on one of the <a href="https://gallery.flutter.dev/">Flutter Web demos</a> and see how readable the content is.</p>

<p>Another one of the <a href="https://gallery.flutter.dev/#/fortnightly">demos</a> in the Flutter Web Gallery is a news site. On news sites, I like to use the built-in “reader mode” in my browser to get a reading experience that is free from clutter and better suites me. For example, when reading in bed late at night (which I know I shouldn’t do) it’s nice to have a soft, dark mode experience instead of the glaring black text on pure white that many publications use. Does reader mode work with Flutter Web website? Nope. It doesn’t work because, you guessed it, it relies on semantic HTML.</p>

<p><a href="https://hugotunius.se/img/flutter-web-a-fractal-of-bad-design/enable-accessibility.png"><img src="https://hugotunius.se/img/flutter-web-a-fractal-of-bad-design/enable-accessibility.png?1604348346" alt="Screenshot of Firefox accessibility inspector showing a single button with the text &quot;Enable accessibility&quot;"></a></p>

<p>Like any good writer, I’ve saved the best for last: the screen reader experience with Flutter Web. When you first focus on  one of the Flutter Web demos with a screen reader you are greeted with a “button” that says “Enable accessibility”. Admittedly, when you click this button there is a resemblance of screen reader content but it’s terrible. In the “Reply” app things are read out with unnecessarily high detail in the list view, things that can be clicked aren’t identified as such, you cannot even get to the menu as far as I can tell, and as previously identified there are almost no landmarks which are used for navigation.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Flutter is a misguided attempt to achieve the impossible: quality cross platform experiences. Flutter Web in particular is fundamentally flawed and needs to be rebuilt from the ground up if it has any hopes of being viable tech that generates semantic, accessible, and modern web experiences. I have serious doubt that when Flutter Web leaves beta any of this will be addressed properly, unless the whole approach is reconsidered. If you see Flutter Web, turn around and run in the opposite direction.</p>

<p>Developers, designers, and product people all love cross platform solutions because it saves them time and energy while achieving the “same” outcome as the costlier alternatives. Flutter Web nicely illustrates that the outcomes aren’t the same, the visible part of a product is only one part of the puzzle.</p>

<p>I’m merely an accessibility novice and I didn’t even mention SEO in this post. I didn’t stop writing because I stopped finding flaws, but because this post was getting too long and I have other things to do. I’m sure accessibility users and experts can find even more issues than I have presented here(feel free to DM me on <a href="https://twitter.com/k0nserv">Twitter</a> and I’ll include them).</p>

<p>To end I’d like to leave you with a <a href="https://www.youtube.com/watch?v=mRNX6XJOeGU">quote</a> from <a href="https://www.imdb.com/title/tt0107290/characters/nm0000156?ref_=tt_cl_t3">Dr. Ian Malcolm</a>.</p>

<blockquote>
  <p>Your scientists were so preoccupied with whether or not they could, they didn’t stop to think if they should.</p>
</blockquote>
</div>
  
    
</article>
</div></div>]]>
            </description>
            <link>https://hugotunius.se/2020/10/31/flutter-web-a-fractal-of-bad-design.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24962504</guid>
            <pubDate>Sun, 01 Nov 2020 21:06:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The missing explanation of ZK-SNARKs: Part 1]]>
            </title>
            <description>
<![CDATA[
Score 66 | Comments 10 (<a href="https://news.ycombinator.com/item?id=24962049">thread link</a>) | @gbrown_
<br/>
November 1, 2020 | https://www.cryptologie.net/article/507/the-missing-explanation-of-zk-snarks/ | <a href="https://web.archive.org/web/*/https://www.cryptologie.net/article/507/the-missing-explanation-of-zk-snarks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<p>What are ZK-SNARKs and how do they work? This is a question I’ve had for years, and always felt like the resources I found gave no clear intuition as to how all of that stuff worked. So today, after a breakthrough in my own understanding, I thought it would be good to re-share what I’ve learned in a more understandable picture. Something that tells you what is the right way of thinking about these things, and what are the gaps that you can fill for yourself if you want to.</p>
<h2>Getting terminology out of the way</h2>
<p>The first part of the question is pretty easy to answer. ZK-SNARKs, no matter what their funny name might imply, are simply <strong>zero-knowledge proofs</strong> that are:</p>
<ul>
<li><strong>non interactive</strong></li>
<li><strong>general purpose</strong></li>
<li>and <strong>succinct</strong></li>
</ul>
<p>Huh, what are all these words? you ask, intimidated by their vagueness.</p>
<p>Well first, <strong>zero-knowledge proofs</strong> are cryptographic proofs that you know something, without revealing the something (zero-knowledgeness). That “something” is usually called the <strong>witness</strong>, but this detail doesn’t matter much. There are a lot of resources about zero-knowledge proofs so I won’t explain much about how they work, or what their exact cryptographic properties are (completeness, soundness, zero-knowledgeness).
Zero-knowledge proofs are often seen used to prove that you know the discrete logarithm in some base of an element of some group (e.g. what is $x$ in $g^x \mod p$), or similarly-limited statements.<br>
“<em>Limited yes, but still useful!</em>” yells Schnorr, inventor of the Schnorr signature scheme which is fabricated by taking a zero-knowledge proof of the knowledge of a discrete logarithm, and making it <strong>non-interactive</strong>. A zero-knowledge proof or <strong>ZKP</strong> is an interactive protocol between a prover (who knows the <strong>witness</strong>) and a verifier (who has to be convinced). An interactive protocol sucks in the real world, as it often limits the number of potential use-cases of the primitive, and slows down protocols depending on the number of round trips that need to happen between the prover and the verifier. Fortunately, some ZKPs can be constructed without interaction with a verifier. In other words, a prover can simply create a proof, and that proof can be verified by anyone at any point in time later without further help from the prover. When ZKPs are made non-interactive, we simply call them non-interactive zero-knowledge proofs or <strong>NIZKs</strong>. I talk more about <a href="https://www.cryptologie.net/article/193/schnorrs-signature-and-non-interactive-protocols/">the link between signatures and zero-knowledge proofs here</a>.<br>
ZKPs and NIZKs can also be constructed on much more general statements like “I know an input to some function such that the execution gives some output”, or more specifically “I know $a$ in $f(a, b) = c$”. If this still doesn’t make sense think about the usual example given to illustrate general-purpose ZKPs: “I know the solution of the sudoku”. <br>
We’re almost there: <strong>ZK-SNARKs</strong> are general-purpose non-interactive zero-knowledge proofs, and more! They are also <strong>succinct</strong>, meaning that the proofs they produce are small in size and are fast to verify, which makes them so special they deserve to be called ZK-SNARKs. Not every modern proof systems deserve that special classification, for example STARKs don’t :(</p>
<p>As a recap:</p>
<ul>
<li>zero-knowledge proof: a cryptographic proof that you know something, without revealing the something</li>
<li>non interactive: a proof that was constructed without the help of a verifier</li>
<li>general purpose: a proof of a more general statement, like the knowledge of secret inputs or outputs of a program</li>
<li>succinct: a small proof that is fast to verify</li>
</ul>
<p>But not only did you ask, what are ZK-SNARKs, but you also asked about how they work.</p>
<h2>The actual stuff</h2>
<p>And oh boy, this is a complex subject to answer. First and foremost, there are many many schemes, too many of them, and so I’m not sure exactly how to answer that question. But I have some idea of how some of them work, and so I imagine that most of them follow that pattern, or improve on it, so let me explain…</p>
<p>There’s two parts to your typical ZK-SNARK: </p>
<ol>
<li>The proving system, which I'll explain in this post.</li>
<li>The translation or compilation of a program to something the proving system can prove, which I'll explain in part 2 of this post.</li>
</ol>
<p>The first part is not too hard to understand, while the second sort of requires a graduate course into the subject…</p>
<h3>Proving your knowledge of a constrained polynomial</h3>
<p>Here it is, remember that one: ZK-SNARKs are all about proving that you know some polynomial $f(x)$ that has some roots.
By roots I mean that the verifier has some values in mind (e.g. $1$ and $2$) and the prover must prove that the secret polynomial they have in mind evaluates to $0$ for this values (e.g. $f(1) = f(2) = 0$).
By the way, a polynomial that has 1 and 2 as roots (in our example) can be written as $f(x)=(x-1)(x-2)h(x)$ for some polynomial $h(x)$. (If you’re not convinced try to evaluate that at $x=1$ and $x=2$.)
So we say that the prover must prove that they know an $f(x)$ and $h(x)$ such that $f(x) = t(x)h(x)$ for some target polynomial $t(x) = (x-1)(x-2)$ (in the example that $1$ and $2$ are the roots that the verifier wants to check).</p>
<p>But that’s it, that’s what ZK-SNARKs proving systems usually provide: something to prove that you know some polynomial. I’m repeating this because the first time I learned about that it made no sense to me: how can you prove that you know some secret input to a program, if all you can prove is that you know a polynomial. Well, that’s why part 2 of this explanation is so difficult: it’s about translating a program into a polynomial. But more on that later.</p>
<p>Back to our proving system, how does one prove that they know such a function $f(x)$? Well they just have to prove that they know an $h(x)$ such that you can write $f(x)$ as $f(x) = t(x)h(x)$. Ugh… Not so fast here. We’re talking about <strong>zero-knowledge</strong> proofs right? How can we prove this without giving out $f(x)$? Well, by using three tricks!</p>
<ol>
<li><strong>homomorphic commitments</strong></li>
<li><strong>bilinear pairings</strong></li>
<li><strong>different polynomials evaluate to different values most of the time</strong></li>
</ol>
<p>So let's go through each of them shall we?</p>
<h3>Homomorphic commitments</h3>
<p>The first trick is to use <strong>commitments</strong> to hide the values that we’re sending to the prover. But not only do we hide them, we also want to allow the <strong>verifier</strong> to perform some operations on them so that they can verify the proof. Specifically verify that if the prover commits on their polynomial $f(x)$ as well as $h(x)$, then we have
$$
com(f(x)) = com(t(x)) com(h(x)) = com(t(x)h(x))
$$ </p>
<p>where $com(t(x))$ is computed by the verifier as these are the known constraints on the polynomial.
These operations are called <strong>homomorphic operations</strong> and we can’t perform them if we use hash functions as commitment mechanisms. Instead, we can simply “hide the values in the exponent” (e.g. for a value $v$ then send the commitment $g^v \mod{p}$) as these are commitments that allow for these homomorphic operations. (To convince yourself, observe that if $a = bc$ then $g^a = g^b g^c = g^{b+c}$. </p>
<p>Wait, this is not what we wanted… we wanted $g^a = g^{bc}$.</p>
<h3>Bilinear pairings</h3>
<p>$g^a = (g^b)^c = g^{bc}$ gets us there, but only if $c$ is a known value and not a commitment (e.g. $g^c$). Unfortunately this is a limitation for our proving protocol, as there will be multiplication operations between commitments. This is where <strong>bilinear pairings</strong> can be used to unblock us, and this is the <em>sole reason</em> why we use bilinear pairings in a ZK-SNARK (really just to be able to multiply the values inside the commitments).
I don’t want to go too deep into what bilinear pairings are, but just know that it is just another tool in our toolkit that:</p>
<ul>
<li>Takes two values of our group (the values generates by $g$ raised to different powers modulo $p$) and place them in another group.</li>
<li>By moving stuff from one group to the other, <strong>we can multiply things that couldn't be multiplied previously</strong>.</li>
</ul>
<p>So using $e$ as the typical way of writing a bilinear pairing, we have $e(g_1, g_2) = h_3$ and we can use it to perform multiplications hidden in the exponent via this one equation:</p>
<p>$$
e(g^b, g^c) = e(g)^{bc}
$$</p>
<p>But no more about bilinear pairings! Again that’s the only reason why we use these in ZK-SNARKs. It’s just a trick to make our homomorphic commitments more homomorphic, to allow us to do:</p>
<p>$$
com(f(x)) = com(t(x)) com(h(x)) = com(t(x)h(x))
$$</p>
<h3>Where does the succinctness comes from?</h3>
<p>Finally, the <strong>succinctness</strong> of ZK-SNARKs come from the fact that two functions that differ will evaluate to different points most of the time.
What this means for us is that if my $f(x)$ is not really equal to $t(x)h(x)$, meaning that I don’t have a polynomial $f(x)$ that really has the roots we’ve chosen with the verifier, then evaluating $f(x)$ and $t(x)h(x)$ at a random point $r$ will not give out the same result (most of the time). In other words for almost all $r$, $f(r) \neq t(r)h(r)$.</p>
<p>This is known as the <strong>Schwartz-Zippel lemma</strong>, which I pictured in the following illustration.</p>
<p><img alt="schwartz zippel lemma" src="https://www.cryptologie.net/upload/Screen_Shot_2020-11-01_at_11.48_.47_AM_.png"></p>
<p>Knowing this, it is enough to prove that $com(f(r)) = com(t(r)h(r))$ for some random point $r$. This is why ZK-SNARKs are so small; by comparing points in a group you end up comparing entire polynomials!</p>
<p>But this is also why there is a “trusted setup” needed before most ZK-SNARKs can work. If a prover learns the random point $r$, then they can forge bad polynomials that will verify. So a trusted setup is about:</p>
<ol>
<li>creating a random value $r$</li>
<li>committing different exponentiation of it $g^r, g^{r^2}, g^{r^3}, \ldots$ so that they can be used by the prover to compute their polynomial without knowing the point $r$</li>
<li>destroying the value $r$</li>
</ol>
<p>Does the second point makes sense? If my polynomial as the prover is $f(x) = x^2 + x$ then all I have to do is compute $g^{r^2} g^r$ to obtain a commitment of my polynomial evaluated at that random point $r$.</p>
<p>Next, I'll write the second part of this blogpost and you'll have to wait until I'm done.</p>
</article></div>]]>
            </description>
            <link>https://www.cryptologie.net/article/507/the-missing-explanation-of-zk-snarks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24962049</guid>
            <pubDate>Sun, 01 Nov 2020 20:03:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SQL X-to-Y]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 27 (<a href="https://news.ycombinator.com/item?id=24961028">thread link</a>) | @panda17
<br/>
November 1, 2020 | https://www.damirsystems.com/sql-x-to-y/ | <a href="https://web.archive.org/web/*/https://www.damirsystems.com/sql-x-to-y/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2056">

<div>
<p>What is the correct way to model one-to-one, one-to-many, many-to-many? Where do foreign keys go? What criteria to use? How to decide? I see these questions repeated on StackOverflow time and again.</p>
<p>The particular implementation should be based on <em>logic</em>. In most cases, <em>verbalizing</em> the constraint in <em>natural language</em> reveals the correct solution.</p>
<p>The following example uses two entities: <em>thing</em> <strong>T</strong>, and <em>category</em> <strong>C</strong>. Defining relationship with four most common multiplicities results in <tt>4x4=16</tt> possible constraints.</p>
<pre>Term                    Multiplicity
------------------------------------
is     in exactly one       [1]
is     in at most one       [0,1]
is     in at least one      [1,*]
may be in more than one     [0,*]
</pre>
<h2>Easy</h2>
<p>The following 11 cases can be declaratively defined in SQL using standard constraints <tt>(FK, PK, AK)</tt>. No need for triggers, deferred constraints, stored procedures, nor special application code.</p>
<hr>
<p><strong>T</strong> <tt>|-[1]------------[1]-|</tt> <strong>C</strong></p>
<p>1. Each thing <em>is</em> in <em>exactly one</em> category;<br>
for each category: <em>exactly one</em> thing <em>is</em> in that category.</p>
<pre>thing {T, C}
   PK {T}
   AK {C}
</pre>
<hr>
<p><strong>T</strong> <tt>|-[0,1]----------[1]-|</tt> <strong>C</strong></p>
<p>2. Each thing <em>is</em> in <em>exactly one</em> category;<br>
for each category: <em>at most one</em> thing <em>is</em> in that category.</p>
<pre>thing {T, C}
   PK {T}
   AK {C}

   FK {C} REFERENCES category {C}


category {C}
      PK {C}
</pre>
<hr>
<p><strong>T</strong> <tt>|-[1]----------[0,1]-|</tt> <strong>C</strong></p>
<p>3. Each thing <em>is</em> in <em>at most one</em> category;<br>
for each category: <em>exactly one</em> thing <em>is</em> in that category.</p>
<pre>thing {T}
   PK {T}


category {C, T}
      PK {C}
      AK {T}

      FK {T} REFERENCES thing {T}
</pre>
<hr>
<p><strong>T</strong> <tt>|-[0,*]----------[1]-|</tt> <strong>C</strong></p>
<p>4. Each thing <em>is</em> in <em>exactly one</em> category;<br>
for each category: <em>more than one</em> thing <em>may be</em> in that category.</p>
<pre>thing {T, C}
   PK {T}

   FK {C} REFERENCES category {C}


category {C}
      PK {C}
</pre>
<hr>
<p><strong>T</strong> <tt>|-[1]----------[0,*]-|</tt> <strong>C</strong></p>
<p>5. Each thing <em>may be</em> in <em>more than one</em> category;<br>
for each category: <em>exactly one</em> thing <em>is</em> in that category.</p>
<pre>thing {T}
   PK {T}


category {C, T}
      PK {C}

      FK {T} REFERENCES thing {T}
</pre>
<hr>
<p><strong>T</strong> <tt>|-[0,*]--------[0,*]-|</tt> <strong>C</strong></p>
<p>6. Each thing <em>may be</em> in <em>more than one</em> category;<br>
for each category: <em>more than one</em> thing <em>may be</em> in that category.</p>
<pre>thing {T}
   PK {T}


category {C}
      PK {C}


thing_category {T, C}
            PK {T, C}

           FK1 {T} REFERENCES thing    {T}
           FK2 {C} REFERENCES category {C}
</pre>
<hr>
<p><strong>T</strong> <tt>|-[0,*]--------[0,1]-|</tt> <strong>C</strong></p>
<p>7. Each thing <em>is</em> in <em>at most one</em> category;<br>
for each category: <em>more than</em> one thing <em>may be</em> in that category.</p>
<pre>thing {T}
   PK {T}


category {C}
      PK {C}


thing_category {T, C}
            PK {T}

           FK1 {T} REFERENCES thing    {T}
           FK2 {C} REFERENCES category {C}
</pre>
<hr>
<p><strong>T</strong> <tt>|-[0,1]--------[0,*]-|</tt> <strong>C</strong></p>
<p>8. Each thing <em>may be</em> in <em>more than one</em> category;<br>
for each category: <em>at most one</em> thing <em>is</em> in that category.</p>
<pre>thing {T}
   PK {T}


category {C}
      PK {C}


thing_category {T, C}
            PK {C}

           FK1 {T} REFERENCES thing    {T}
           FK2 {C} REFERENCES category {C}
</pre>
<hr>
<p><strong>T</strong> <tt>|-[0,1]--------[0,1]-|</tt> <strong>C</strong></p>
<p>9. Each thing <em>is</em> in <em>at most one</em> category;<br>
for each category: <em>at most one</em> thing <em>is</em> in that category.</p>
<pre>thing {T}
   PK {T}


category {C}
      PK {C}


thing_category {T, C}
            PK {T}
            AK {C}

           FK1 {T} REFERENCES thing    {T}
           FK2 {C} REFERENCES category {C}
</pre>
<hr>
<p><strong>T</strong> <tt>|-[1,*]--------[0,*]-|</tt> <strong>C</strong></p>
<p>10. Each thing <em>may be</em> in <em>more than one</em> category;<br>
for each category: <em>at least one</em> thing <em>is</em> in that category.</p>
<pre>thing {T}
   PK {T}


category {C, T}
      PK {C}

      FK {T} REFERENCES thing {T}


thing_cat {T, C}
       PK {T, C}

      FK1 {T} REFERENCES thing    {T}
      FK2 {C} REFERENCES category {C}


VIEW thing_category {T, C}
AS
category  {T, C}
UNION
thing_cat {T, C}
</pre>
<hr>
<p><strong>T</strong> <tt>|-[0,*]--------[1,*]-|</tt> <strong>C</strong></p>
<p>11. Each thing <em>is</em> in <em>at least one</em> category;<br>
for each category: <em>more than one</em> thing <em>may be</em> in that category.</p>
<pre>thing {T, C}
   PK {T}

   FK {C} REFERENCES category {C}


category {C}
      PK {C}


thing_cat {T, C}
       PK {T, C}

      FK1 {T} REFERENCES thing    {T}
      FK2 {C} REFERENCES category {C}


VIEW thing_category {T, C}
AS
thing {T, C}
UNION
thing_cat {T, C}
</pre>
<h2>Not Easy</h2>
<p>Cases from 12 to 16 require use of triggers, stored procedures, deferred constraints, or application code to enforce the constraint.</p>
<p>12. <strong>T</strong> <tt>|-[1,*]----------[1]-|</tt> <strong>C</strong><br>
Each thing <em>is</em> in <em>exactly one</em> category;<br>
for each category: <em>at least one</em> thing <em>is</em> in that category.</p>
<p>13. <strong>T</strong> <tt>|-[1]----------[1,*]-|</tt> <strong>C</strong><br>
Each thing <em>is</em> in <em>at least one</em> category;<br>
for each category: <em>exactly one</em> thing <em>is</em> in that category.</p>
<p>14. <strong>T</strong> <tt>|-[1,*]--------[0,1]-|</tt> <strong>C</strong><br>
Each thing <em>is</em> in <em>at most one</em> category;<br>
for each category: <em>at least one</em> thing <em>is</em> in that category.</p>
<p>15. <strong>T</strong> <tt>|-[0,1]--------[1,*]-|</tt> <strong>C</strong><br>
Each thing <em>is</em> in <em>at least one</em> category;<br>
for each category: <em>at most one</em> thing <em>is</em> in that category.</p>
<p>16. <strong>T</strong> <tt>|-[1,*]--------[1,*]-|</tt> <strong>C</strong><br>
Each thing <em>is</em> in <em>at least one</em> category;<br>
for each category: <em>at least one</em> thing <em>is</em> in that category.</p>
<h3>The Problem</h3>
<p>The main problem is lack of assertions (DB-wide constraints) in main SQL implementations. SQL standard actually defines them (<tt>CREATE ASSERTION</tt>), but no luck yet. Hence, not every business constraint can be elegantly defined in SQL. Often some creativity, compromise, and awkwardness is required.</p>
<hr>
<p>Note:</p>
<pre>All attributes (columns) NOT NULL

PK = Primary Key
AK = Alternate Key (Unique)
FK = Foreign Key
</pre>
</div>

</article></div>]]>
            </description>
            <link>https://www.damirsystems.com/sql-x-to-y/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24961028</guid>
            <pubDate>Sun, 01 Nov 2020 17:34:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Danish military intelligence uses XKEYSCORE to tap cables in co-op with the NSA]]>
            </title>
            <description>
<![CDATA[
Score 575 | Comments 190 (<a href="https://news.ycombinator.com/item?id=24960994">thread link</a>) | @XzetaU8
<br/>
November 1, 2020 | https://www.electrospaces.net/2020/10/danish-military-intelligence-uses.html | <a href="https://web.archive.org/web/*/https://www.electrospaces.net/2020/10/danish-military-intelligence-uses.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-7080478453343339184" itemprop="description articleBody">
<p>
Last August, it came out that a whistleblower accused the Danish military and signals intelligence service (<a href="https://en.wikipedia.org/wiki/Danish_Defence_Intelligence_Service" target="_blank"><i>Forsvarets Efterretningstjeneste</i></a> or FE) of unlawful activities and deliberately misleading the intelligence oversight board. </p><p>

Meanwhile, the Danish press was able to paint a surprisingly comprehensive and detailed picture of how the FE cooperated with the NSA in <a href="#cabletapping"><b>cable tapping</b></a> on Danish soil.</p><p>

It was further revealed that the Americans provided Denmark with a sophisticated <a href="#spysystem"><b>new spy system</b></a> which includes the NSA's data processing system <a href="#xkeyscore"><b>XKEYSCORE</b></a>.</p><p>

A Danish paper also disclosed that the accusation of <a href="#unlawful"><b>unlawful collection</b></a> came from a young FE employee who reminds of Edward Snowden. A newly established investigation commission now has to clarify whether he was driven by fears or by facts.</p><p><a href="https://1.bp.blogspot.com/-FEhoYi_a0EI/X3lHJbfeSlI/AAAAAAAAEyk/urOidzARWswgJstbeNFiU8CRo38JQMufACPcBGAYYCw/s800/fe-xks-header.jpg"><img alt="" data-original-height="420" data-original-width="800" src="https://1.bp.blogspot.com/-FEhoYi_a0EI/X3lHJbfeSlI/AAAAAAAAEyk/urOidzARWswgJstbeNFiU8CRo38JQMufACPcBGAYYCw/s800/fe-xks-header.jpg" width="600"></a></p>
<p><span size="2">
The Sandagergård complex of the FE on the island of Amager, where a new<br> 
data center was built for its deployment of the XKEYSCORE system<br>
</span>
</p>


<p><span size="+2">Cable tapping</span></p><p>

In an extensive piece from September 13, the renowned Danish newspaper <a href="https://www.berlingske.dk/samfund/et-pengeskab-paa-kastellet-har-i-aartier-gemt-paa-et-dybt-fortroligt" target="_blank"><i>Berlingske</i></a> (founded in 1749) describes how the FE, in cooperation with the NSA, started to tap an international telecommunications cable in order to gather foreign intelligence.</p><p>
  
  In the mid-1990s, the NSA had found out that somewhere under Copenhagen there was a backbone cable containing phone calls, e-mails and text messages from and to countries like China and Russia, which was of great interest for the Americans.</p><p>
  
Tapping that cable, however, was almost impossible without the help of the Danes, so the NSA asked the FE for access to the cable, but this request was denied, according to Berlingske.</p><p>
  
  
  <b>Agreement with the United States</b></p><p>
  
  The US government did not give up, and in a letter sent directly to the Danish prime minister Poul Nyrup Rasmussen, US president Clinton asked his Danish colleague to reconsider the decision. And Nyrup, who was a sworn supporter of a close relationship with the US, said yes. </p><p>
  
  The cooperation was laid down in a document, which, according to Berlingske, all Danish defense ministers had to sign "so that any new minister could see that his predecessor - and his predecessors before his predecessors - with their signatures had been part of this small, exclusive circle of people who knew one of the kingdom's biggest secrets."</p><p> 
    
  The code name for this cooperation is not known, but it's most likely part of the NSA's umbrella program <a href="https://www.electrospaces.net/2014/10/the-german-operation-eikonal-as-part-of.html#rampart-a">RAMPART-A</a>. Under this program, which started in 1992, foreign partners <a href="https://s3.amazonaws.com/s3.documentcloud.org/documents/1200864/tssinframpartaoverview-v1-0-redacted-information.pdf" target="_blank">provide</a> access to high-capacity international fiber-optic cables, while the US provides the equipment for transport, processing and analysis:</p><p><a href="https://1.bp.blogspot.com/-VQv_x5OW4VM/VD2MIOzUWkI/AAAAAAAAB8o/rxZgVvQ4hmI/s1600/rampart-a-2010-diagram.jpg" imageanchor="1" target="_blank"><img src="https://1.bp.blogspot.com/-VQv_x5OW4VM/VD2MIOzUWkI/AAAAAAAAB8o/rxZgVvQ4hmI/s1600/rampart-a-2010-diagram.jpg" title="Slide from an NSA presentation about the RAMPART-A program" width="450"></a></p>
   
  <p>

  <b>Agreement with a cable operator</b></p><p>
  
To make sure that tapping the cable was as legal as possible, the government asked approval of the private Danish company that operated the cable. The company agreed, but only when it was approved at the highest level, and so the agreement was signed by prime minister Rasmussen, minister of defense Hækkerup and head of department Troldborg. </p><p>
  
  Because the cable contained international telecommunications it was considered to fall within the FE's foreign intelligence mandate. The agreement was prepared in only one copy, which was shown to the company and then locked in a safe at the FE's headquarters at the <a href="https://web.archive.org/web/20200811152740/https://fe-ddis.dk/om-os/Organisation/lokaliteter-i-dk/Pages/Kastellet.aspx" target="_blank">Kastellet</a> fortress in Copenhagen, according to Berlingske.</p><p>

 This Danish agreement is very similar to the <a href="http://download.krone.at/pdf/VertragWZschwarz.pdf" target="_blank">Transit Agreement</a> between the German foreign intelligence service BND and Deutsche Telekom, in which the latter agreed to provide access to international transit cables at its switching center in Frankfurt am Main. The BND then tapped these cables with help from the NSA under <a href="https://www.electrospaces.net/2015/05/new-details-about-joint-nsa-bnd.html">operation Eikonal</a> (2004-2008).</p><p>
  
  
    <b>Processing at Sandagergård</b></p><p>
  
  Berlingske reported that the communications data that were extracted from the backbone cable in Copenhagen were sent from the Danish company's technical hub to the <a href="https://web.archive.org/web/20200811153920/https://fe-ddis.dk/om-os/Organisation/lokaliteter-i-dk/Pages/Sandagergaard.aspx" target="_blank">Sandagergård complex</a> of the FE on the island of <a href="https://en.wikipedia.org/wiki/Amager" target="_blank">Amager</a>. The US had paid for a cable between the two locations.</p><p>
  
  At Sandagergård, the "NSA made sure to install the technology that made it possible to enter keywords and translate the huge amount of information, so-called raw data from the cable tapping, into "readable" information."</p><p>
  
The filter system was not only fed by keywords from the FE, but the NSA also provided "the FE with a series of keywords that are relevant to the United States. The FE then reviews them - and checks that there are basically no Danes among them - and then enters the keywords" according to sources cited by Berlingske.</p><p>
  
  Besides this filtering with keywords and selectors, the FE and the NSA will also have used the metadata for <a href="https://edwardsnowden.com/docs/doc/B17-TDB-Knowledge-Sharing.pdf" target="_blank">contact-chaining</a>, which means reconstructing which phone numbers and e-mail addresses had been in contact with each other, in order to create social network graphs - something the sources apparently didn't want to disclose to Berlingske.</p><p><a href="https://1.bp.blogspot.com/-zFJ49f56CXY/X5PXqIaouqI/AAAAAAAAEzY/TJwURx3Jn6oCxN9s4I3LqKKu1EhtLPEAACPcBGAYYCw/s1351/dk-cables.JPG"><img alt="" data-original-height="830" data-original-width="1351" src="https://1.bp.blogspot.com/-zFJ49f56CXY/X5PXqIaouqI/AAAAAAAAEzY/TJwURx3Jn6oCxN9s4I3LqKKu1EhtLPEAACPcBGAYYCw/s1351/dk-cables.JPG" width="550"></a></p>
  <p><span size="2">
  Map of the current backbone cables around the Danish capital Copenhagen<br>
  and the Sandagergård complex of the FE on the island of Amager<br>
  (source: <a href="https://live.infrapedia.com/app" target="_blank">Infrapedia</a> - click to enlarge)<br>
</span>
</p>

  <p>
  
      <b>Trusted partners</b></p><p>
  
  Part of the agreement between the US and Denmark was that "the USA does not use the system against Danish citizens and companies. And the other way around". Similar words can be found in an <a href="https://www.documentcloud.org/documents/1200860-odd-s3-overviewnov2011-v1-0-redacted-information.html" target="_blank">NSA presentation</a> from 2011: "No US collection by Partner and No Host Country collection by US" - although this is followed by "there ARE exceptions!"</p><p>
  
  The latter remark may have inspired Edward Snowden to accuse the NSA of abusing these cooperations with foreign partner agencies to spy on European citizens, but as a source told Berlingske: </p><p>
  
  "I can not at all imagine in my imagination that the NSA would betray that trust. I consider it completely and utterly unlikely. If the NSA had a desire to obtain information about Danish citizens or companies, the United States would simply turn to [the domestic security service] PET, which would then provide the necessary legal basis."</p><p>
  
The source also said that "the NSA wanted to jump and run for Denmark. The agency did everything Denmark asked for, without discussion. The NSA continuously helped Denmark - because of this cable access. [...] Denmark was a very, very close and valued partner."</p><p>
    
This close and successful cooperation was apparently one of the reasons for the visit of president Bill Clinton to Denmark in July 1997, according to Berlingske.</p><p><a href="https://1.bp.blogspot.com/-1-v3T8EQqk0/X3gIQLWgChI/AAAAAAAAEyE/j-yGk3qiStcS3Y692bc25UT6WG1_B_2BACLcBGAsYHQ/s0/clinton-rasmussen.jpg"><img alt="" src="https://1.bp.blogspot.com/-1-v3T8EQqk0/X3gIQLWgChI/AAAAAAAAEyE/j-yGk3qiStcS3Y692bc25UT6WG1_B_2BACLcBGAsYHQ/s0/clinton-rasmussen.jpg" width="550"></a></p>
  <p><span size="2">
Danish prime minister Poul Nyrup Rasmussen and US president Bill Clinton<br>
  during his visit to Denmark in July 1997 (photo: Linda Kastrup)<br>
</span>
</p>

<p><span size="+2">A new spy system</span></p><p>
  
  In the wake of the FE scandal even more recent developments have been revealed: a <a href="https://www.dr.dk/nyheder/indland/ny-afsloering-fe-masseindsamler-oplysninger-om-danskere-gennem-avanceret-spionsystem" target="_blank">report</a> by the Danish broadcaster DR from September 24, 2020 provides interesting details about how the Americans provided Denmark with a sophisticated new "spy system".</p><p>
  
After the FE got a new head of procurement in 2008, NSA employees frequently traveled to Denmark for quite some time to build the necessary hardware and install the required software for the new system, which DR News describes as extremely advanced. It also has a special internal code name, which the broadcaster decided not to publish. It's also this new system through which the alleged illegal collection of Danish data took place.</p><p>
  
  According to DR News, the NSA technicians were also involved in the construction of a new data center at the FE's <a href="https://web.archive.org/web/20200811153920/https://fe-ddis.dk/om-os/Organisation/lokaliteter-i-dk/Pages/Sandagergaard.aspx" target="_blank">Sandagergård complex</a> on Amager that was specifically built to house the new spy system, which was taken into use somewhere between 2012 and 2014. The cooperation between the FE and the NSA on this specific system was based upon a Memorandum of Understanding (MoU) signed by then FE chief <a href="https://da.wikipedia.org/wiki/Thomas_Ahrenkiel" target="_blank">Thomas Ahrenkiel</a>.</p><p>

  
  
  <b>Filter systems</b></p><p>
  
The DR News <a href="https://www.dr.dk/nyheder/indland/ny-afsloering-fe-masseindsamler-oplysninger-om-danskere-gennem-avanceret-spionsystem" target="_blank">report</a> also goes into more detail about the interception process. It says that first, the intelligence service identifies a data stream that may be interesting, after which they "mirror" the light that passes through the particular fiber-optic cables. In this way, they copy both metadata and content, like text messages, chat conversations, phone calls and e-mails, and send them to the FE's data center at Sandagergård.</p><p>

  
According to DR News, the FE tried to develop a number of filters to ensure that data from Danish citizens and companies is sorted out and not made searchable by the new spy system. The former Danish minister of defense Claus Hjort Frederiksen recently <a href="http://www.weekendavisen.dk/2020-37/samfund/landsskadeligt" target="_blank">said</a> that there was indeed an attempt to develop such filters, but at the same time he admitted that there can be no guarantee that no Danish information will pass through.</p><p><span size="+2">XKEYSCORE</span></p><p>

  DR News also reported that the heart of the new spy system is formed by <a href="https://en.wikipedia.org/wiki/XKeyscore" target="_blank">XKEYSCORE</a>, which was developed by the NSA and the existence of which was first <a href="https://www.theguardian.com/world/2013/jul/31/nsa-top-secret-program-online-data" target="_blank">revealed</a> by The Guardian in June 2013.</p><p> 
  
  The NSA's British counterpart GCHQ incorporated XKEYSCORE in its own system for processing bulk internet data codenamed <a href="https://en.wikipedia.org/wiki/Tempora" target="_blank">TEMPORA</a> and it can be assumed that the other <a href="https://www.electrospaces.net/2014/09/nsas-foreign-partnerships.html#2ndparty">Second Party</a> partners (also known as the Five Eyes) also use this system, whether or not under a different codename.</p><p><a href="https://1.bp.blogspot.com/-t6LWjnPz3Wo/X3LLi61rZzI/AAAAAAAAExc/-F5vREaIi4oBCAZ_LNhvOOJFVnHnLlFbgCLcBGAsYHQ/s0/xks%2Bintro.JPG" target="_blank"><img alt="" src="https://1.bp.blogspot.com/-t6LWjnPz3Wo/X3LLi61rZzI/AAAAAAAAExc/-F5vREaIi4oBCAZ_LNhvOOJFVnHnLlFbgCLcBGAsYHQ/s0/xks%2Bintro.JPG" width="500"></a></p>
  <p>
  
From the Snowden documents we know that the NSA also provided XKEYSCORE to some of its <a href="https://www.electrospaces.net/2014/09/nsas-foreign-partnerships.html#3rdparty">Third Party</a> partners: the German <a href="https://www.electrospaces.net/2016/09/secret-report-reveals-german-bnd-also.html">foreign intelligence service BND</a> and domestic security service BfV, the Swedish signals intelligence service FRA and the Japanese Directorate for SIGINT. It is new though that the Danish military intelligence service FE uses the system too.</p><p>

  
Some press reports seem to suggest that these partner agencies "gain access to XKEYSCORE" as if it would allow them to connect to a huge global mass surveillance system. The latter may be the case for the NSA's Second Party partners, but the Third Party partners are using XKEYSCORE only to process and analyze data from their own tapping points and are not able to access data from Five Eyes collection platforms.</p><p>
  
  Likewise, NSA analysts using XKEYSCORE don't have direct …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.electrospaces.net/2020/10/danish-military-intelligence-uses.html">https://www.electrospaces.net/2020/10/danish-military-intelligence-uses.html</a></em></p>]]>
            </description>
            <link>https://www.electrospaces.net/2020/10/danish-military-intelligence-uses.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24960994</guid>
            <pubDate>Sun, 01 Nov 2020 17:30:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[C/C++ vs. Rust Performance]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 125 (<a href="https://news.ycombinator.com/item?id=24960108">thread link</a>) | @krizhanovsky
<br/>
November 1, 2020 | http://tempesta-tech.com/blog/fast-programming-languages-c-c++-rust-assembly | <a href="https://web.archive.org/web/*/http://tempesta-tech.com/blog/fast-programming-languages-c-c++-rust-assembly">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div> <p><i>Posted on October 28, 2020</i></p><p>This article isn't about which programming language is better, instead it discusses the most powerful tool set for development of the fastest server-side system software, such as database engines and HTTPS servers. There are several specific properties of this type of software: </p><ul><li>Relatively large code base, 100,000 lines of C or C++ code and more. While it's possible to write particular, the most 'hot' functions, in Assembly language, it's impractical to write the whole program in Assembly. </li><li>Databases and web servers are mission-critical software - we all got used that our Linux systems with MySQL and Nginx processes work for months and years. There are <a href="https://github.com/tempesta-tech/tempesta/wiki/High-availability">simple high availability</a> best practices mitigating the downtime due to possible crashes, but they're the subject for another article. Meantime, it's worth mentioning that if you really-really care about high availability, then you should build you infrastructure with an assumption that any component of your system may crash at any time, just like <a href="https://lwn.net/Articles/801871/">Facebook does this</a> -the company deploys the recent versions of the Linux kernel as soon as they're available. </li></ul><p>We've been developing the <a href="http://tempesta-tech.com/c++-services">fastest software in C, C++, and Assembly</a> for ages. It's not a surprise that since Rust is <a href="https://en.wikipedia.org/wiki/Rust_(programming_language)">"focused on performance"</a> we're very interested in it. With a bit of skepticism though. Just remember the rise of Java programming language: there were a lot of reports that the JIT compilation produced code faster than C++. Now it's hard to find a case, when C++ is slower than Java, see for example the <a href="https://benchmarksgame-team.pages.debian.net/benchmarksgame/fastest/java.html">benchmark game</a>. It's also worth mentioning that the memory garbage collection (GC) in Java leads to high tail latencies and it's hard or even impossible to do anything with the problem. Golang can not be considered for high performance programming also due to the GC. </p><h2>C or C++? Or both of them?</h2><p> The C programming language dominates in the system programming. An operating system kernel is an example of one of the most sophisticated system software, not only because it deals with hardware directly, but also due to strict performance requirements. The Linux and FreeBSD kernels are written in C, as well as the other UNIX'es and Windows kernels. Let's start the discussion from this bright example of high-performance system software. </p><h3>C++ for operating systems kernel development</h3><p> FreeBSD <a href="https://forums.freebsd.org/threads/driver-building-in-c.35701/">has been supporting C++ modules</a> for a while. While the Linux kernel never supported C++, there was <a href="https://pdos.csail.mit.edu/papers/click:tocs00/paper.pdf">the Click modular router</a> written in C++ and working as a Linux kernel module. If you're interested in C++ applicability for the operating systems kernel development, then you can find quite good discussions in the <a href="https://wiki.osdev.org/C++">C++</a> and <a href="https://wiki.osdev.org/C++_Bare_Bones">Bare bones</a> articles. However, there are fundamental reasons against using C++ for operating system kernel development: </p><ul><li>You do not have <code>libstdc++</code> with <a href="https://en.wikipedia.org/wiki/Run-time_type_information">RTTI</a> and exceptions in the kernel space. Actually, <code>dynamic_cast</code> isn't so frequently used and there are a lot of C++ projects compiled without RTTI. If you need exceptions, then you have to port them into the kernel. <code>libstdc++</code> uses basic C allocations, so it must be significantly reworked for the kernel. </li><li>You can't use the STL and Boost libraries and, in fact, all kernels already have their own libraries. C++ introduces filesystem, threading and networking libraries, which are senseless in an OS kernel. From the other hand, the modern OSes provide advanced synchronization primitives, which are still not available in standard C++ (e.g. there is still no read-write spinlocks in C++). </li><li>The Linux kernel provides number of memory allocators (SLAB, page, <code>vmalloc()</code>, <code>kmalloc()</code>, and so on), thus you have to use <a href="https://en.cppreference.com/w/cpp/language/new"><code>placement new</code></a> and/or just use the C functions for memory allocation and freeing. Aligned memory is crucial for the performance, but you need to write special wrappers to get aligned memory with <code>new</code>. </li><li>Strong type safety isn't so comfortable for system programming when raw memory pointers are frequently casted to some data structures. This is debatable though: while some people are uncomfortable with frequent <code>reinterpret_cast&lt;Foo *&gt;(ptr)</code> instead of short <code>(Foo *)ptr</code>, the others are good with more typing and more type safety. </li><li>C++ <a href="https://en.wikipedia.org/wiki/Name_mangling">name mangling</a>, required for namespaces and function overloading, makes function hard to call from Assembly, so you need to use <code>extern "C"</code>. </li><li>You have to make special code sections for static objects constructors and destructors, <code>.ctor</code> and <code>.dtor</code> correspondingly. </li><li>C++ exceptions can not cross <i>context</i> boundaries, i.e. you can not throw an exception in one thread and catch it in another. The operating system kernel deals with much more complex context model: there are kernel threads, user space processes entering into the kernel, deferred and hardware interruptions. The contexts can preempt each other in voluntarily or cooperative manner, so exception handling of current context could be preempted by another context. There are also memory management and contexts switching code which could conflict with exception handling code. Just like for RTTI, it's possible to implement the mechanism in kernel, but the current standard library can not be used. </li><li>While Clang and G++ support <code>__restrict__</code> extension, the official C++ standard <a href="https://www.quora.com/Why-doesnt-C++-have-an-equivalent-of-Cs-restrict-specifier">does not support</a> it. </li><li>Variable length arrays (VLA) are <a href="https://lwn.net/Articles/749064/">discouraged</a> in the Linux kernel, they are still handy in some scenarios, but are <a href="https://groups.google.com/g/comp.std.c++/c/K_4lgA1JYeg?pli=1">completely unavailable in C++</a>. </li></ul><p> Thus, with C++ in the kernel space you basically have only templates, classes inheritance and some syntax sugar like lambda functions. Since system code is quite rarely requires complicated abstractions and inheritances, then does it still have sense to make effort to use C++ in the kernel space? </p><h3>C++ exceptions</h3><p> This is one of the most <a href="https://herbsutter.com/2010/03/13/trip-report-march-2010-iso-c-standards-meeting/">debatable</a> C++ feature and it deserves a separate chapter. For example, the MySQL project, following to the <a href="https://google.github.io/styleguide/cppguide.html#Exceptions">Google coding style</a>, <a href="https://dev.mysql.com/doc/dev/mysql-server/latest/PAGE_CODING_GUIDELINES.html">doesn't use exceptions</a>. The Google coding style provides the good lists of pros and cons of using exceptions. Here we focus on performance aspects only. </p><p>Exceptions can improve performance when we have to handle error codes in too may places, e.g. (let the functions be inlined and very small) </p><pre><code>
        if (func_1())
            return -EINVAL;
        if (func_2())
            return -EINVAL;
        ....
        if (func_100())
            return -EINVAL;
    </code></pre><p> The problem with the code is that there are extra conditional jumps. Modern CPU are pretty good with branch prediction, but it still hurts performance. In C++ we can just write </p><pre><code>
        try {
            func_1();
            func_2();
            ...
            func_100();
        } catch (...) {
            return -EINVAL;
        }
    </code></pre><p> , so there are no extra conditions in the <i>hot</i> path. However, this isn't for free: most of the functions in your C++ code have to have extra epilogues with a table of exceptions, which these functions can catch, and an appropriate cleanup table. The function epilogues aren't executed in normal workflow, but they increase the size of code causing extra pollution in the CPU instruction cache. You can find great details about C++ exception handling internals in the <a href="https://monoinfinito.wordpress.com/series/exception-handling-in-c/">Nico Brailovsky's blog</a>. </p><h3>Is C++ still good?</h3><p> Yes, it is. Firstly, not the whole code actually must be as fast as possible and in most of the places we don't need custom memory allocation and don't care about exceptions overhead. The most of the projects are developed in the user space and benefit, especially the new ones, from relatively rich C++ standard and Boost libraries (not so rich as Java's though). </p><p>Secondly, the killing feature of C++ is that <b>it is C</b>. If you don't want to use exceptions or RTTI, then you can just switch the features off. Most of C programs can be just compiled with a C++ compiler with very small changes or without any changes at all. As an example, we need only this trivial change </p><pre><code>
    $ diff -up nbody.c nbody-new.cc
        @@ -112,9 +112,9 @@ static void advance(body bodies[]){
             // ROUNDED_INTERACTIONS_COUNT elements to simplify one of the following
             // loops and to also keep the second and third arrays in position_Deltas
             // aligned properly.
        -    static alignas(__m128d) double
        -      position_Deltas[3][ROUNDED_INTERACTIONS_COUNT],
        -      magnitudes[ROUNDED_INTERACTIONS_COUNT];
        +    static double
        +      position_Deltas[3][ROUNDED_INTERACTIONS_COUNT] __attribute__((aligned(16))),
        +      magnitudes[ROUNDED_INTERACTIONS_COUNT] __attribute__((aligned(16)));

             // Calculate the position_Deltas between the bodies for each interaction.
             for(intnative_t i=0, k=0; i &lt; BODIES_COUNT-1; ++i)
    </code></pre><p> to compile <a href="https://benchmarksgame-team.pages.debian.net/benchmarksgame/program/nbody-clang-8.html">the C program</a> with G++ compiler. The modern C++ compilers provide C compatibility extensions like the <code>__restrict__</code> keyword. You always can write the most performance critical code of a C++ program in C style. If you don't like the <a href="https://250bpm.com/blog:8/">STL containers with an overhead</a>, then you can use <a href="https://www.boost.org/doc/libs/1_74_0/doc/html/intrusive.html">Boost.intrusive</a> or even port a similar container from the Linux kernel or other fast C project -in most of the cases this won't be painful. See for example how a hash table from PostgreSQL, HTrie from <a href="https://github.com/tempesta-tech/tempesta/tree/master/tempesta_db">Tempesta DB</a>, and the Linux kernel read/write spinlocks (all are written in C) were used in a C++ <a href="https://github.com/tempesta-tech/blog/tree/master/htrie">benchmark</a>. </p><p>The last thing which must be mentioned about development of high performance programs in C++ is <a href="https://en.wikipedia.org/wiki/Template_metaprogramming">template metaprogramming</a>. It's very exciting about the modern C++ standards that using templates you can write quite sophisticated logic which is fully computed in the compile time and costs nothing in the run time. </p><h2>GOTO - the power of C</h2> <p><b>A professional tool must allow you to work with it in the most efficient way.</b> The goal of the high-level and high-performance programming languages is to generate the most efficient machine code. Each hardware architecture supports <i>jumps</i>, which means that you can jump to any address by any condition. The closest abstraction for the jumps in the C and C++ programming languages is <code>goto</code> operator. It's not so flexible …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://tempesta-tech.com/blog/fast-programming-languages-c-c++-rust-assembly">http://tempesta-tech.com/blog/fast-programming-languages-c-c++-rust-assembly</a></em></p>]]>
            </description>
            <link>http://tempesta-tech.com/blog/fast-programming-languages-c-c++-rust-assembly</link>
            <guid isPermaLink="false">hacker-news-small-sites-24960108</guid>
            <pubDate>Sun, 01 Nov 2020 15:33:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: A JavaScript SDK to reduce video streaming costs]]>
            </title>
            <description>
<![CDATA[
Score 64 | Comments 50 (<a href="https://news.ycombinator.com/item?id=24959519">thread link</a>) | @Anil1331
<br/>
November 1, 2020 | https://api.peervadoo.com/test | <a href="https://web.archive.org/web/*/https://api.peervadoo.com/test">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p><label for="url">Url:</label>
                    
		</p>
                </div></div>]]>
            </description>
            <link>https://api.peervadoo.com/test</link>
            <guid isPermaLink="false">hacker-news-small-sites-24959519</guid>
            <pubDate>Sun, 01 Nov 2020 13:57:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[7GUIs]]>
            </title>
            <description>
<![CDATA[
Score 455 | Comments 51 (<a href="https://news.ycombinator.com/item?id=24958725">thread link</a>) | @dsego
<br/>
November 1, 2020 | https://eugenkiss.github.io/7guis/tasks/ | <a href="https://web.archive.org/web/*/https://eugenkiss.github.io/7guis/tasks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The tasks were selected by the following criteria. The task set should be as small as possible yet reflect as many typical (or fundamental or representative) challenges in GUI programming as possible. Each task should be as simple and self-contained as possible yet not too artificial. Preferably, a task should be based on existing examples as that gives the task more justification to be useful and there already will be at least one reference implementation.</p><p>Below, a description of each task highlighted with the challenges it reflects and a screenshot of the resulting GUI application in Java/Swing is given.</p><p>For a live version of the tasks see my<!-- --> <a target="_blank" href="https://eugenkiss.github.io/7guis-React-TypeScript-MobX/">React/MobX</a> <!-- -->implementation.</p><h2>Counter</h2><p><em>Challenge:</em> Understanding the basic ideas of a language/toolkit.</p><p><img src="https://eugenkiss.github.io/7guis/static/counter.9cd92091.png"></p><p>The task is to build a frame containing a label or read-only textfield<!-- --> <em>T</em> and a button <em>B</em>. Initially, the value in <em>T</em> is “0” and each click of <em>B</em> increases the value in <em>T</em> by one.</p><p>Counter serves as a gentle introduction to the basics of the language, paradigm and toolkit for one of the simplest GUI applications imaginable. Thus, Counter reveals the required scaffolding and how the very basic features work together to build a GUI application. A good solution will have almost no scaffolding.</p><h2>Temperature Converter</h2><p><em>Challenges:</em> bidirectional data flow, user-provided text input.</p><p><img src="https://eugenkiss.github.io/7guis/static/tempconv.de9aff1f.png"></p><p>The task is to build a frame containing two textfields <em>T<sub>C</sub></em> <!-- -->and <em>T<sub>F</sub></em> representing the temperature in Celsius and Fahrenheit, respectively. Initially, both <em>T<sub>C</sub></em> and <em>T<sub>F</sub></em> are empty. When the user enters a numerical value into <em>T<sub>C</sub></em> the corresponding value in <em>T<sub>F</sub></em> is automatically updated and vice versa. When the user enters a non-numerical string into <em>T<sub>C</sub></em> the value in <em>T<sub>F</sub></em> is <em>not</em> updated and vice versa. The formula for converting a temperature <em>C</em> in Celsius into a temperature <em>F</em> in Fahrenheit is <em>C = (F - 32) * (5/9)</em> and the dual direction is <em>F = C * (9/5) + 32</em>.</p><p>Temperature Converter increases the complexity of Counter by having bidirectional data flow between the Celsius and Fahrenheit inputs and the need to check the user input for validity. A good solution will make the bidirectional dependency very clear with minimal boilerplate code.</p><p>Temperature Converter is inspired by the<!-- --> <a target="_blank" href="https://www.artima.com/pins1ed/gui-programming.html#32.4">Celsius/Fahrenheit converter</a> <!-- -->from the book <em>Programming in Scala</em>. It is such a widespread example—sometimes also in the form of a currency converter—that one could give a thousand references. The same is true for the Counter task.</p><h2>Flight Booker</h2><p><em>Challenge:</em> Constraints.</p><p><img src="https://eugenkiss.github.io/7guis/static/bookflight.a5434663.png"></p><p>The task is to build a frame containing a combobox <em>C</em> with the two options “one-way flight” and “return flight”, two textfields <em>T<sub>1</sub></em> and<!-- --> <em>T<sub>2</sub></em> representing the start and return date, respectively, and a button <em>B</em> for submitting the selected flight. <em>T<sub>2</sub></em> is enabled iff <em>C</em>’s value is “return flight”. When <em>C</em> has the value “return flight” and <em>T<sub>2</sub></em>’s date is strictly before <em>T<sub>1</sub></em>’s then <em>B</em> is disabled. When a non-disabled textfield <em>T</em> has an ill-formatted date then <em>T</em> is colored red and <em>B</em> is disabled. When clicking <em>B</em> a message is displayed informing the user of his selection (e.g. “You have booked a one-way flight on 04.04.2014.”). Initially, <em>C</em> has the value “one-way flight” and <em>T<sub>1</sub></em> as well as <em>T<sub>2</sub></em> have the same (arbitrary) date (it is implied that <em>T<sub>2</sub></em> is disabled).</p><p>The focus of Flight Booker lies on modelling constraints between widgets on the one hand and modelling constraints within a widget on the other hand. Such constraints are very common in everyday interactions with GUI applications. A good solution for Flight Booker will make the constraints clear, succinct and explicit in the source code and not hidden behind a lot of scaffolding.</p><p>Flight Booker is directly inspired by the<!-- --> <a target="_blank" href="http://blog.reactiveprogramming.org/?p=21">Flight Booking Java example in Sodium</a> <!-- -->with the simplification of using textfields for date input instead of specialized date picking widgets as the focus of Flight Booker is not on specialized/custom widgets.</p><h2>Timer</h2><p><em>Challenges:</em> concurrency, competing user/signal interactions, responsiveness.</p><p><img src="https://eugenkiss.github.io/7guis/static/timer.ed46b6b4.png"></p><p>The task is to build a frame containing a gauge <em>G</em> for the elapsed time <em>e</em>, a label which shows the elapsed time as a numerical value, a slider <em>S</em> by which the duration <em>d</em> of the timer can be adjusted while the timer is running and a reset button <em>R</em>. Adjusting<!-- --> <em>S</em> must immediately reflect on <em>d</em> and not only when<!-- --> <em>S</em> is released. It follows that while moving <em>S</em> the filled amount of <em>G</em> will (usually) change immediately. When <em>e ≥ d</em> is true then the timer stops (and <em>G</em> will be full). If, thereafter, <em>d</em> is increased such that <em>d &gt; e</em> will be true then the timer restarts to tick until <em>e ≥ d</em> is true again. Clicking <em>R</em> will reset <em>e</em> to zero.</p><p>Timer deals with concurrency in the sense that a timer process that updates the elapsed time runs concurrently to the user’s interactions with the GUI application. This also means that the solution to competing user and signal interactions is tested. The fact that slider adjustments must be reflected immediately moreover tests the responsiveness of the solution. A good solution will make it clear that the signal is a timer tick and, as always, has not much scaffolding.</p><p>Timer is directly inspired by the timer example in the paper<!-- --> <a target="_blank" href="http://cs.brown.edu/~sk/Publications/Papers/Published/ick-adapt-oo-fwk-frp/paper.pdf">Crossing State Lines: Adapting Object-Oriented Frameworks to Functional Reactive Languages</a>.</p><h2>CRUD</h2><p><em>Challenges:</em> separating the domain and presentation logic, managing mutation, building a non-trivial layout.</p><p><img src="https://eugenkiss.github.io/7guis/static/crud.515ce94b.png"></p><p>The task is to build a frame containing the following elements: a textfield<!-- --> <em>T<sub>prefix</sub></em>, a pair of textfields <em>T<sub>name</sub></em> and<!-- --> <em>T<sub>surname</sub></em>, a listbox <em>L</em>, buttons <em>B<sub>C</sub></em>,<!-- --> <em>B<sub>U</sub></em> and <em>B<sub>D</sub></em> and the three labels as seen in the screenshot. <em>L</em> presents a view of the data in the database that consists of a list of names. At most one entry can be selected in <em>L</em> at a time. By entering a string into <em>T<sub>prefix</sub></em> the user can filter the names whose surname start with the entered prefix—this should happen immediately without having to submit the prefix with enter. Clicking <em>B<sub>C</sub></em> <!-- -->will append the resulting name from concatenating the strings in<!-- --> <em>T<sub>name</sub></em> and <em>T<sub>surname</sub></em> to <em>L</em>.<!-- --> <em>B<sub>U</sub></em> and <em>B<sub>D</sub></em> are enabled iff an entry in <em>L</em> is selected. In contrast to <em>B<sub>C</sub></em>, <em>B<sub>U</sub></em> <!-- -->will not append the resulting name but instead replace the selected entry with the new name. <em>B<sub>D</sub></em> will remove the selected entry. The layout is to be done like suggested in the screenshot. In particular, <em>L</em> must occupy all the remaining space.</p><p>CRUD (Create, Read, Update and Delete) represents a typical graphical business application. The primary challenge is the separation of domain and presentation logic in the source code that is more or less forced on the implementer due to the ability to filter the view by a prefix. Traditionally, some form of MVC pattern is used to achieve the separation of domain and presentation logic. Also, the approach to managing the mutation of the list of names is tested. A good solution will have a good separation between the domain and presentation logic without much overhead (e.g. in the form of toolkit specific concepts or language/paradigm concepts), a mutation management that is fast but not error-prone and a natural representation of the layout (layout builders are allowed, of course, but would increase the overhead).</p><p>CRUD is directly inspired by the crud example in the blog post<!-- --> <a target="_blank" href="http://apfelmus.nfshost.com/blog/2012/03/29-frp-three-principles-bidirectional-gui.html">FRP - Three principles for GUI elements with bidirectional data flow</a>.</p><h2>Circle Drawer</h2><p><em>Challenges:</em> undo/redo, custom drawing, dialog control*.</p><p><img src="https://eugenkiss.github.io/7guis/static/circledraw.235dfd8b.png"></p><p>The task is to build a frame containing an undo and redo button as well as a canvas area underneath. Left-clicking inside an empty area inside the canvas will create an unfilled circle with a fixed diameter whose center is the left-clicked point. The circle nearest to the mouse pointer such that the distance from its center to the pointer is less than its radius, if it exists, is filled with the color gray. The gray circle is the selected circle <em>C</em>. Right-clicking <em>C</em> will make a popup menu appear with one entry “Adjust diameter..”. Clicking on this entry will open another frame with a slider inside that adjusts the diameter of <em>C</em>. Changes are applied immediately. Closing this frame will mark the last diameter as significant for the undo/redo history. Clicking undo will undo the last significant change (i.e. circle creation or diameter adjustment). Clicking redo will reapply the last undoed change unless new changes were made by the user in the meantime.</p><p>Circle Drawer’s goal is, among other things, to test how good the common challenge of implementing an undo/redo functionality for a GUI application can be solved. In an ideal solution the undo/redo functionality comes for free resp. just comes out as a natural consequence of the language / toolkit / paradigm. Moreover, Circle Drawer tests how dialog control*, i.e. keeping the relevant context between several successive GUI interaction steps, is achieved in the source code. Last but not least, the ease of custom drawing is tested.</p><p><small>* Dialog control is explained in more detail in the paper<!-- --> <a target="_blank" href="http://ceur-ws.org/Vol-610/paper11.pdf">Developing GUI Applications: Architectural Patterns Revisited</a> <!-- -->starting on page seven. The term describes the challenge of retaining context between successive GUI operations.</small></p><h2>Cells</h2><p><em>Challenges:</em> change propagation, widget customization, implementing a more authentic/involved GUI application.</p><p><img src="https://eugenkiss.github.io/7guis/static/cells.9544a72f.png"></p><p>The task is to create a simple but usable spreadsheet application. The spreadsheet should be scrollable. The rows should be numbered from 0 to 99 and the columns from A to Z. Double-clicking a cell <em>C</em> lets the user change <em>C</em>’s formula. After having finished editing the formula is parsed and evaluated and its updated value is shown in <em>C</em>. In addition, all cells which depend on <em>C</em> must be reevaluated. This process repeats until there are no more changes in the values of any cell (change propagation). Note that one should not just recompute the value of every cell but only of those cells that depend on another cell’s changed value. If there is an already provided spreadsheet widget it should not be used. Instead, another similar widget (like JTable in Swing) should be customized to become a reusable spreadsheet widget.</p><p>Cells is a more authentic and involved task that tests if a particular …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://eugenkiss.github.io/7guis/tasks/">https://eugenkiss.github.io/7guis/tasks/</a></em></p>]]>
            </description>
            <link>https://eugenkiss.github.io/7guis/tasks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24958725</guid>
            <pubDate>Sun, 01 Nov 2020 11:20:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building Containers Without Docker]]>
            </title>
            <description>
<![CDATA[
Score 95 | Comments 18 (<a href="https://news.ycombinator.com/item?id=24957887">thread link</a>) | @kiyanwang
<br/>
November 1, 2020 | https://blog.alexellis.io/building-containers-without-docker/ | <a href="https://web.archive.org/web/*/https://blog.alexellis.io/building-containers-without-docker/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>

        

        <section>
            <div><p>In this post I'll outline several ways to build containers without the need for Docker itself. I'll use <a href="https://github.com/openfaas/">OpenFaaS</a> as the case-study, which uses OCI-format container images for its workloads. The easiest way to think about OpenFaaS is as a CaaS platform for <a href="https://kubernetes.io/">Kubernetes</a> which can run microservices, and add in FaaS and event-driven tooling for free.</p>
<p>See also <a href="https://openfaas.com/">OpenFaaS.com</a></p>
<p>The first option in the post will show how to use the built-in buildkit option for Docker's CLI, then <a href="https://github.com/moby/buildkit">buildkit</a> stand-alone (on Linux only), followed by Google's container builder, <a href="https://github.com/GoogleContainerTools/kaniko">Kaniko</a>.</p>
<p>This post covers tooling which can build an image from a Dockerfile, and so anything which limits the user to only Java (jib) or Go (ko) for instance is out of scope. I'll then wrap things up and let you know how to get in touch with suggestions, feedback and your own stories around wants and needs in container tooling.</p>
<h2 id="sowhatswrongwithdocker">So what's wrong with Docker?</h2>
<p>Nothing as such, Docker runs well on armhf, arm64, and on <code>x86_64</code>. The main Docker CLI has become a lot more than build/ship/run, and also lugs around several years of baggage, it now comes bundled with Docker Swarm and EE features.</p>
<blockquote>
<p>Update for Nov 2020: anyone using Docker's set of official base-images should also read: <a href="https://inlets.dev/blog/2020/10/29/preparing-docker-hub-rate-limits.html">Preparing for the Docker Hub Rate Limits</a></p>
</blockquote>
<h3 id="alternativestodocker">Alternatives to Docker</h3>
<p>There are a few efforts that attempt to strip "docker" back to its component pieces, the original UX we all fell in love with:</p>
<ul>
<li>
<p><a href="https://github.com/docker/docker">Docker</a> - docker itself now uses containerd to run containers, and has support for enabling buildkit to do highly efficient, caching builds.</p>
</li>
<li>
<p><a href="https://podman.io/">Podman</a> and <a href="https://github.com/containers/buildah">buildah</a> combination - RedHat / IBM's effort, which uses their own OSS toolchain to generate OCI images. Podman is marketed as being daemonless and rootless, but still ends up having to mount overlay filesystems and use a UNIX socket.</p>
</li>
<li>
<p><a href="https://github.com/alibaba/pouch">pouch</a> - from Alibaba, pouch is billed as "An Efficient Enterprise-class Container Engine". It uses containerd just like Docker, and supports both container-level isolation with <a href="https://github.com/opencontainers/runc">runc</a> and "lightweight VMs" such as <a href="https://github.com/hyperhq/runv">runV</a>. There's also more of a <a href="https://github.com/alibaba/pouch/blob/master/docs/architecture.md">focus on image distribution and strong isolation</a>.</p>
</li>
<li>
<p>Stand-alone buildkit - buildkit was started by <a href="https://twitter.com/tonistiigi?lang=en">Tõnis Tiigi</a> from Docker Inc as a brand new container builder with caching and concurrency in mind. buildkit currently only runs as a daemon, but you will hear people claim otherwise. They are forking the daemon and then killing it after a build.</p>
</li>
<li>
<p><a href="https://github.com/genuinetools/img">img</a> - img was written by <a href="https://github.com/jessfraz">Jess Frazelle</a> and is often quoted in these sorts of guides and is a wrapper for buildkit. That said, I haven't seen traction with it compared to the other options mentioned. The project was quite active <a href="https://github.com/genuinetools/img/commits/master">until late 2018 and has only received a few patches since</a>. img claims to be daemonless, but it uses buildkit so is probably doing some trickery there. I hear that <code>img</code> gives a better UX than buildkit's own CLI <code>buildctr</code>, but it should also be noted that img is only released for <code>x86_64</code> and there are no binaries for armhf / arm64.</p>
</li>
</ul>
<blockquote>
<p>An alternative to <code>img</code> would be <code>k3c</code> which also includes a runtime component and plans to support ARM architectures.</p>
</blockquote>
<ul>
<li><a href="https://github.com/ibuildthecloud/k3c">k3c</a> - Rancher's latest experiment which uses containerd and buildkit to re-create the original, classic, vanilla, lite experience of the original Docker version.</li>
</ul>
<p>Out of all the options, I think that I like k3c the most, but it is very nascient and bundles everything into one binary which is likely to conflict with other software, at present it runs its own embedded containerd and buildkit binaries.</p>
<blockquote>
<p>Note: If you're a RedHat customer and paying for support, then you really should use their entire toolchain to get the best value for your money. I checked out some of the examples and saw one that used my "classic" blog post on multi-stage builds. See for yourself which style you prefer <a href="https://github.com/containers/buildah/blob/master/demos/buildah_multi_stage.sh">the buildah example</a> vs. <a href="https://blog.alexellis.io/mutli-stage-docker-builds">Dockerfile example</a>.</p>
</blockquote>
<p>So since we are focusing on the "build" piece here and want to look at relativelt stable options, I'm going to look at:</p>
<ul>
<li>buildkit in Docker,</li>
<li>buildkit stand-alone</li>
<li>and kaniko.</li>
</ul>
<p>All of the above and more are now possible since the OpenFaaS CLI can output a standard "build context" that any builder can work with.</p>
<h2 id="buildatestapp">Build a test app</h2>
<p>Let's start with a Golang HTTP middleware, this is a cross between a function and a microservice and shows off how versatile OpenFaaS can be.</p>
<pre><code>faas-cli template store pull golang-middleware

faas-cli new --lang golang-middleware \
  build-test --prefix=alexellis2
</code></pre>
<ul>
<li><code>--lang</code> specifies the build template</li>
<li><code>build-test</code> is the name of the function</li>
<li><code>--prefix</code> is the Docker Hub username to use for pushing up our OCI image</li>
</ul>
<p>We'll get the following created:</p>
<pre><code>./
├── build-test
│   └── handler.go
└── build-test.yml

1 directory, 2 files
</code></pre>
<p>The handler looks like this, and is easy to modify. Additional dependencies can be added through vendoring or <a href="https://blog.golang.org/using-go-modules">Go modules</a>.</p>
<pre><code>package function

import (
	"fmt"
	"io/ioutil"
	"net/http"
)

func Handle(w http.ResponseWriter, r *http.Request) {
	var input []byte

	if r.Body != nil {
		defer r.Body.Close()

		body, _ := ioutil.ReadAll(r.Body)

		input = body
	}

	w.WriteHeader(http.StatusOK)
	w.Write([]byte(fmt.Sprintf("Hello world, input was: %s", string(input))))
}
</code></pre>
<h3 id="buildthenormalway">Build the normal way</h3>
<p>The normal way to build this app would be:</p>
<pre><code>faas-cli build -f build-test.yml
</code></pre>
<p>A local cache of the template and Dockerfile is also available at <code>./template/golang-middleware/Dockerfile</code></p>
<p>There are three images that are pulled in for this template:</p>
<pre><code>FROM openfaas/of-watchdog:0.7.3 as watchdog
FROM golang:1.13-alpine3.11 as build
FROM alpine:3.12
</code></pre>
<p>With the traditional builder, each of the images will be pulled in sequentially.</p>
<p>The wait a few moments and you're done, we now have that image in our local library.</p>
<p>We can also push it up to a registry with <code>faas-cli push -f build-test.yml</code>.</p>
<p><img src="https://blog.alexellis.io/content/images/2020/01/seq.png" alt="seq"></p>
<h3 id="buildwithbuildkitanddocker">Build with Buildkit and Docker</h3>
<p>This is the easiest change of all to make, and gives a fast build too.</p>
<pre><code>DOCKER_BUILDKIT=1 faas-cli build -f build-test.yml
</code></pre>
<p>We'll see that with this approach, the Docker daemon automatically switches out its builder for buildkit.</p>
<p>Buildkit offers a number of advantages:</p>
<ul>
<li>More sophisticated caching</li>
<li>Running later instructions first, when possible - i.e. downloading the "runtime" image, before the build in the "sdk" layer is even completed</li>
<li>Super fast when building a second time</li>
</ul>
<p>With buildkit, all of the base images can be pulled in to our local library at once, since the FROM (download) commands are not executed sequentially.</p>
<pre><code>FROM openfaas/of-watchdog:0.7.3 as watchdog
FROM golang:1.13-alpine3.11 as build
FROM alpine:3.11
</code></pre>
<p>This option works even on a Mac, since buildkit is proxied via the Docker daemon running in the VM.</p>
<p><img src="https://blog.alexellis.io/content/images/2020/01/dkit.png" alt="dkit"></p>
<h3 id="buildwithbuildkitstandalone">Build with Buildkit standalone</h3>
<p>To build with Buildkit in a stand-alone setup we need to run buildkit separately on a Linux host, so we can't use a Mac.</p>
<p><code>faas-cli build</code> would normally execute or fork <code>docker</code>, because the command is just a wrapper. So to bypass this behaviour we should write out a build context, that's possible via the following command:</p>
<pre><code>faas-cli build -f build-test.yml --shrinkwrap

[0] &gt; Building build-test.
Clearing temporary build folder: ./build/build-test/
Preparing ./build-test/ ./build/build-test//function
Building: alexellis2/build-test:latest with golang-middleware template. Please wait..
build-test shrink-wrapped to ./build/build-test/
[0] &lt; Building build-test done in 0.00s.
[0] Worker done.

Total build time: 0.00
</code></pre>
<p>Our context is now available in the <code>./build/build-test/</code> folder with our function code and the template with its entrypoint and Dockerfile.</p>
<pre><code>./build/build-test/
├── Dockerfile
├── function
│   └── handler.go
├── go.mod
├── main.go
└── template.yml

1 directory, 5 files
</code></pre>
<p>Now we need to run buildkit, we can build from source, or grab upstream binaries.</p>
<pre><code>curl -sSLf https://github.com/moby/buildkit/releases/download/v0.6.3/buildkit-v0.6.3.linux-amd64.tar.gz | sudo tar -xz -C /usr/local/bin/ --strip-components=1
</code></pre>
<p>If you checkout the releases page, you'll also find buildkit available for armhf and arm64, which is great for multi-arch.</p>
<p>Run the buildkit daemon in a new window:</p>
<pre><code>sudo buildkitd 
WARN[0000] using host network as the default            
INFO[0000] found worker "l1ltft74h0ek1718gitwghjxy", labels=map[org.mobyproject.buildkit.worker.executor:oci org.mobyproject.buildkit.worker.hostname:nuc org.mobyproject.buildkit.worker.snapshotter:overlayfs], platforms=[linux/amd64 linux/386] 
WARN[0000] skipping containerd worker, as "/run/containerd/containerd.sock" does not exist 
INFO[0000] found 1 workers, default="l1ltft74h0ek1718gitwghjxy" 
WARN[0000] currently, only the default worker can be used. 
INFO[0000] running server on /run/buildkit/buildkitd.sock 
</code></pre>
<p>Now let's start a build, passing in the shrink-wrapped location as the build-context. The command we want is <code>buildctl</code>, buildctl is a client for the daemon and will configure how to build the image and what to do when it's done, such as exporting a tar, ignoring the build or pushing it to a registry.</p>
<pre><code>buildctl build --help
NAME:
   buildctl build - build

USAGE:
   
  To build and push an image using Dockerfile:
    $ buildctl build --frontend dockerfile.v0 --opt target=foo --opt build-arg:foo=bar --local context=. --local dockerfile=. --output type=image,name=docker.io/username/image,push=true
  

OPTIONS:
   --output value, -o value  Define exports for build result, e.g. --output type=image,name=docker.io/username/image,push=true
   --progress value          Set type of progress (auto, plain, tty). Use plain to show container output (default: "auto")
   --trace value             Path to trace file. Defaults to no tracing.
   --local value             Allow build access to the local directory
   --frontend value          Define frontend used for build
   --opt value               Define custom options for frontend, e.g. --opt target=foo --opt build-arg:foo=bar
   --no-cache                Disable cache for all the vertices
   --export-cache value      Export build cache, e.g. --export-cache type=registry,ref=example.com/foo/bar, or …</code></pre></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.alexellis.io/building-containers-without-docker/">https://blog.alexellis.io/building-containers-without-docker/</a></em></p>]]>
            </description>
            <link>https://blog.alexellis.io/building-containers-without-docker/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24957887</guid>
            <pubDate>Sun, 01 Nov 2020 07:54:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I No Longer Tell My Friends about Anki/SuperMemo]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 82 (<a href="https://news.ycombinator.com/item?id=24957617">thread link</a>) | @kioleanu
<br/>
October 31, 2020 | https://www.masterhowtolearn.com/2020-10-31-why-i-no-longer-tell-my-friends-about-anki-supermemo/ | <a href="https://web.archive.org/web/*/https://www.masterhowtolearn.com/2020-10-31-why-i-no-longer-tell-my-friends-about-anki-supermemo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>This article <a href="https://www.lesswrong.com/posts/6NvbSwuSAooQxxf7f/beware-of-other-optimizing">Beware of Other-Optimizing</a> by Eliezer Yudkowsky is highly illuminating. I recommend you read it through the lens of “recommending Anki to a friend.” This article is about the problems of giving advice on how to learn.</p>
<h2>Spreading the “gospel” to the world</h2>
<p>If you deeply believe something, along the lines of “if everyone did it, the world would be much better off.” and have tried convincing other people to do that thing, then you will realize it’s almost impossible to change others’ opinions or behaviors.</p>
<p>Maybe you’re not that ambitious to convince everyone, so you start small: you share it with your friends, but then discovered nobody actually cares or realizes its significance. A mild version is like <a href="https://www.deathbulge.com/comics/206">showing your favorite TV show and they don’t care</a>:</p>
<p><span>
      <a href="https://www.masterhowtolearn.com/static/26c8c80614f9b9a1a0a8f6e2ff1e17c2/acb04/deathbulge.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="deathbulge" title="deathbulge" src="https://www.masterhowtolearn.com/static/26c8c80614f9b9a1a0a8f6e2ff1e17c2/1c72d/deathbulge.jpg" srcset="https://www.masterhowtolearn.com/static/26c8c80614f9b9a1a0a8f6e2ff1e17c2/a80bd/deathbulge.jpg 148w,
https://www.masterhowtolearn.com/static/26c8c80614f9b9a1a0a8f6e2ff1e17c2/1c91a/deathbulge.jpg 295w,
https://www.masterhowtolearn.com/static/26c8c80614f9b9a1a0a8f6e2ff1e17c2/1c72d/deathbulge.jpg 590w,
https://www.masterhowtolearn.com/static/26c8c80614f9b9a1a0a8f6e2ff1e17c2/acb04/deathbulge.jpg 750w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>My faith in evidence-based learning strategies is informed by my personal experience and <a href="https://www.masterhowtolearn.com/2020-02-25-how-to-learn-about-meta-learning-my-resource-list">my meta-learning list</a>. I wholeheartedly believe Spaced Repetition Software (SRS) like SuperMemo and Anki is the key to effective and efficient learning. If you believe education is the future, then the knowledge about evidence-based learning strategies is one big key to unlocking that future, both individually and collectively.</p>
<h2>“Doing this every day seems very tiring.”</h2>
<p>Two years ago I was doing my Anki reps. One friend glanced over and was interested in what I was doing.</p>
<p><span>
      <a href="https://www.masterhowtolearn.com/static/443ff24d4c08fb6e97f3db4438a49b2e/ee745/myTime.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="My time has come" title="My time has come" src="https://www.masterhowtolearn.com/static/443ff24d4c08fb6e97f3db4438a49b2e/1c72d/myTime.jpg" srcset="https://www.masterhowtolearn.com/static/443ff24d4c08fb6e97f3db4438a49b2e/a80bd/myTime.jpg 148w,
https://www.masterhowtolearn.com/static/443ff24d4c08fb6e97f3db4438a49b2e/1c91a/myTime.jpg 295w,
https://www.masterhowtolearn.com/static/443ff24d4c08fb6e97f3db4438a49b2e/1c72d/myTime.jpg 590w,
https://www.masterhowtolearn.com/static/443ff24d4c08fb6e97f3db4438a49b2e/ee745/myTime.jpg 660w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>We ate lunch together while I was giving her a little presentation. I talked <em>very enthusiastically</em> about spaced repetition, basic memory science and Anki operations. Of course I had to show her the infamous forgetting curve:</p>
<p><span>
      <a href="https://www.masterhowtolearn.com/static/2abe95310027f94ad36981994f56c65d/8aab1/forgetting-curve-wired-wozniak.webp" target="_blank" rel="noopener">
    <span></span>
  <img alt="forgetting-curve" title="forgetting-curve" src="https://www.masterhowtolearn.com/static/2abe95310027f94ad36981994f56c65d/5ca24/forgetting-curve-wired-wozniak.webp" srcset="https://www.masterhowtolearn.com/static/2abe95310027f94ad36981994f56c65d/cbe2e/forgetting-curve-wired-wozniak.webp 148w,
https://www.masterhowtolearn.com/static/2abe95310027f94ad36981994f56c65d/3084c/forgetting-curve-wired-wozniak.webp 295w,
https://www.masterhowtolearn.com/static/2abe95310027f94ad36981994f56c65d/5ca24/forgetting-curve-wired-wozniak.webp 590w,
https://www.masterhowtolearn.com/static/2abe95310027f94ad36981994f56c65d/8aab1/forgetting-curve-wired-wozniak.webp 630w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>She sounded excited about the possibility of finally mastering a second language. But at one point she was confused:</p>
<blockquote>
<p>“If I hadn’t learned it how could I recall it from memory?”</p>
</blockquote>
<p>So I explained that assessment <strong>for</strong> learning (testing as a means of learning) is different from assessment <strong>of</strong> learning (finding out what you’ve learned). The act of “recalling from memory” is itself a learning process. Then I was aware that her confusion was probably due to a common misconception about memory: human memory works like computer memory:</p>
<blockquote>
<p>The functional architecture of how humans forget, remember, and learn is <strong>unlike</strong> the corresponding processes in man-made devices […] We think of ourselves as working like computers, we become prone to assuming that exposing ourselves to information and procedures will lead to storage (i.e., recording) of such information or procedures in our memories—that the information will write itself in one’s memory.</p>
<p>If we think of human memory equals to memory in a computer, we are unlikely to appreciate that retrieving information from our memory increases the subsequent accessibility of that information, while retrieving information from computer memory leaves the status of that information unperturbed. <a href="https://www.taylorfrancis.com/books/e/9780203842539/chapters/10.4324%2F9780203842539-6">On the Symbiosis of Remembering, Forgetting, and Learning</a></p>
</blockquote>
<p>Side note: this story might give you the impression that I liked to show off what I know. No not really. I like to be convinced with evidence, and I thought others were the same. I was wrong. Also, I included the above quotes for the sake of convincing you, the reader. I didn’t obfuscate the subject matter further with phrases like assessment <strong>for</strong> learning and assessment <strong>of</strong> learning.</p>
<p>She looked… befuddled. Sort of like this:</p>
<p><span>
      <a href="https://www.masterhowtolearn.com/static/e459a547d1aa99ea034a06ea3f4f1f13/c08c5/AwkwardSmile.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="awkwardSmile" title="awkwardSmile" src="https://www.masterhowtolearn.com/static/e459a547d1aa99ea034a06ea3f4f1f13/1c72d/AwkwardSmile.jpg" srcset="https://www.masterhowtolearn.com/static/e459a547d1aa99ea034a06ea3f4f1f13/a80bd/AwkwardSmile.jpg 148w,
https://www.masterhowtolearn.com/static/e459a547d1aa99ea034a06ea3f4f1f13/1c91a/AwkwardSmile.jpg 295w,
https://www.masterhowtolearn.com/static/e459a547d1aa99ea034a06ea3f4f1f13/1c72d/AwkwardSmile.jpg 590w,
https://www.masterhowtolearn.com/static/e459a547d1aa99ea034a06ea3f4f1f13/c08c5/AwkwardSmile.jpg 640w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>I remember I was so excited and nervous at the same time that I was fumbling for words, trying to simplify it as much as I could. In retrospect, I was making things worse.</p>
<p>She’d listen to me quite intently, signaling that she was thinking and trying to figure it out, but I could tell she was still confused. And the more I explained, the deeper the rabbit hole went (like keep clicking hyperlinks in Wikipedia), and the more confused she became, so I stopped talking to stop making the whole situation uncomfortable. The following monologue is how I imagine what she was thinking at the time:</p>
<blockquote>
<p>“He’s so passionate about this stuff and so sure of himself that I guess he’s right.”</p>
</blockquote>
<blockquote>
<p>“I’m not really sure what he means. I do want to learn Japanese but the stuff he’s talking about is so confusing…”</p>
</blockquote>
<blockquote>
<p>“I was indeed interested in the beginning, but I don’t really care at this point. I’m just going to pretend I understand and end this whole conversation asap.”</p>
</blockquote>
<p>I will never forget what she said at one point,</p>
<blockquote>
<p>“Doing this every day seems very tiring.”</p>
</blockquote>
<p>I was like “Yeah…” I never followed up on her progress. I figured if she was truly interested, when she bumped into problem she would ask for my help. As expected, we never talked about it and I never mentioned Anki again.</p>
<p><span>
      <a href="https://www.masterhowtolearn.com/static/7a936abffcd1a452478dca75a9f1ec62/0b533/sadFrog.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="sadFrog" title="sadFrog" src="https://www.masterhowtolearn.com/static/7a936abffcd1a452478dca75a9f1ec62/0b533/sadFrog.png" srcset="https://www.masterhowtolearn.com/static/7a936abffcd1a452478dca75a9f1ec62/12f09/sadFrog.png 148w,
https://www.masterhowtolearn.com/static/7a936abffcd1a452478dca75a9f1ec62/e4a3f/sadFrog.png 295w,
https://www.masterhowtolearn.com/static/7a936abffcd1a452478dca75a9f1ec62/0b533/sadFrog.png 500w" sizes="(max-width: 500px) 100vw, 500px" loading="lazy">
  </a>
    </span></p>
<p>These has happened countless times. I usually look nonchalant on the outside but dying on the inside. People looked interested (probably due to my enthusiasm and it’s impolite to look otherwise) and then never actually bothered to use Anki. Some would actually try, make a few cards, do the reps for a few days and then say, “I tried and Anki doesn’t work.”</p>
<p>I’m probably over my head, but sometimes it feels like I’m personally attacked, that what I’m saying is not valuable. I understand it’s not true, but it took me years to study the learning science and to gain the experience with Anki/SuperMemo. The fact that they’re dismissing the software feels like they’re dismissing my knowledge and experience.</p>
<h2>The problems of giving advice on how to learn</h2>
<h3>#1. Nobody cares <em>that</em> much, alright?</h3>
<p>When I first discovered Anki I was like, “How come no one around me knows this?! I need to share this to everyone!” So I would tell my friends about Anki but nobody was interested. I’ve introduced Anki to people and every time it’s a very frustrating experience. (Surprise surprise, not SuperMemo. The learning curve of Anki is much lower. What chance do I have if I preached SuperMemo when they even think Anki is too hard to use?)</p>
<p>Update: I was never a missionary and randomly went out my way to tell people about Anki all the time like this:</p>
<p><span>
      <a href="https://www.masterhowtolearn.com/static/e160326dcc1a72ba87b79f26f888d457/737f1/thejenkinscomicVim.webp" target="_blank" rel="noopener">
    <span></span>
  <img alt="vim" title="vim" src="https://www.masterhowtolearn.com/static/e160326dcc1a72ba87b79f26f888d457/737f1/thejenkinscomicVim.webp" srcset="https://www.masterhowtolearn.com/static/e160326dcc1a72ba87b79f26f888d457/cbe2e/thejenkinscomicVim.webp 148w,
https://www.masterhowtolearn.com/static/e160326dcc1a72ba87b79f26f888d457/3084c/thejenkinscomicVim.webp 295w,
https://www.masterhowtolearn.com/static/e160326dcc1a72ba87b79f26f888d457/737f1/thejenkinscomicVim.webp 585w" sizes="(max-width: 585px) 100vw, 585px" loading="lazy">
  </a>
    </span></p>
<p><a href="https://thejenkinscomic.wordpress.com/">Source</a></p>
<p>Very early on I did give unsolicited advice once to my best friend by intentionally bringing up Anki. Then I did bring up Anki on multiple occasions, but only when the opportunity presented itself, like the story above.</p>
<p>People may be interested in how you’ve developed a skill or become fluent in a foreign language, but just not <strong>that</strong> interested. And they certainly don’t expect to be suddenly lectured on how learning and memory work.</p>
<p>I never liked following up to people with questions like “So how’s Anki? Have you used it?” It feels like pushing an agenda to them. Also, since most would not even bother buying and downloading the app, their response is usually, “I forgot about it. I’ll do it later.” and the conversation would end in an awkward tone.</p>
<h3>#2. I’m not sure if I actually want it, alright?</h3>
<p>Sometimes people keep lamenting “I want to learn X or I want to get better grades.” How many times do you hear people say they want to learn a second language? This is like that friend who keeps saying “I want to lose weight”. Probably after all, they’re just lamenting and not yet ready to put in the effort to change.</p>
<p>Trying to convince others to use Anki/SuperMemo is like trying to convince your friends to go to the gym regularly. You can talk about the benefits of exercising/weight-lifting, how good you’ll feel afterwards, how much more productive you’ll be and so on. But nothing will work if they don’t try it in the first place, and it doesn’t help that spaced repetition doesn’t work in the short-term since using Spaced Repetition Software is a life-long pursuit (just as learning is):</p>
<blockquote>
<p>This long term focus may explain why explicit spaced repetition is an uncommon studying technique: the pay-off is distant &amp; counterintuitive, the cost of self-control near &amp; vivid. <a href="https://www.gwern.net/Spaced-repetition">Gwern’s Spaced Repetition for Efficient Learning</a></p>
</blockquote>
<h3>#3. Why are you so hyped about it?</h3>
<p>It’s rare if people could understand and realize the significance and application of Spaced Repetition Software in a casual 10-min chat. It’s not about the complexity (it’s not rocket science after all), but rather it’s about awareness: problems with current learning approaches and how Anki/SuperMemo could solve the problems. In other words, if I don’t see the problems, why bother changing?</p>
<p>I have a friend who was learning German. She copied German vocabulary on one side and the equivalent English on the other in a notebook. I showed her my Korean Anki cards: “Take a look at these beautiful images! Gifs! Sentence cards! Audio clips! Mass Immersion Approach! (Former: All Japanese All The Time (AJATT)), Stephen Krashen’s Input Hypothesis!” Then I had another friend who was studying to become a nurse. I told him about Anki: “Image occlusion for anatomy!” It felt wrong of me to be hiding Anki (<a href="https://ankiweb.net/shared/info/1374772155">Image Occlusion</a> to be specific) from him. Deep down I want to shove their faces to this table:</p>
<p><span>
      <a href="https://www.masterhowtolearn.com/static/50f60f43bbd89353f63423035d211043/91608/UtilityAssessment.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="UtilityAssessment" title="UtilityAssessment" src="https://www.masterhowtolearn.com/static/50f60f43bbd89353f63423035d211043/fcda8/UtilityAssessment.png" srcset="https://www.masterhowtolearn.com/static/50f60f43bbd89353f63423035d211043/12f09/UtilityAssessment.png 148w,
https://www.masterhowtolearn.com/static/50f60f43bbd89353f63423035d211043/e4a3f/UtilityAssessment.png 295w,
https://www.masterhowtolearn.com/static/50f60f43bbd89353f63423035d211043/fcda8/UtilityAssessment.png 590w,
https://www.masterhowtolearn.com/static/50f60f43bbd89353f63423035d211043/efc66/UtilityAssessment.png 885w,
https://www.masterhowtolearn.com/static/50f60f43bbd89353f63423035d211043/c83ae/UtilityAssessment.png 1180w,
https://www.masterhowtolearn.com/static/50f60f43bbd89353f63423035d211043/91608/UtilityAssessment.png 1251w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>(Image source: <a href="https://journals.sagepub.com/stoken/rbtfl/Z10jaVH/60XQM/full">Improving Students’ Learning With Effective Learning Techniques</a>)</p>
<p>I was exaggerating but you get the point: it’s not possible to convey the significance and application of it all in a casual 10-min chat. With the benefit of hindsight, all my attempts could’ve been a lot better:</p>
<ul>
<li>Maybe I was so convinced and have so much faith in Spaced Repetition Software that I came off as condescending, giving off the impression like “you don’t know how to study; let me teach you.”</li>
<li>Maybe it’s the bold claims: “You’ll get 2x results with half the study time.” (How many are really true whenever you hear such claim?)</li>
<li>Maybe it’s the situation: all he or she wants is someone to listen about the difficulty of studying, not some real advice or suggestions.</li>
</ul>
<p>Here’s the guy from <a href="http://brianjx.altervista.org/">How I Passed the Demanding […] Italian Language Exam Without Going to Italy – Here’s a Hint: the 326,538 Flashcard Reviews Helped a Lot.</a></p>
<blockquote>
<p>Like many language teachers, V. had never heard of Anki (but she did know Reverso Context). I showed her how I studied Italian …</p></blockquote></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.masterhowtolearn.com/2020-10-31-why-i-no-longer-tell-my-friends-about-anki-supermemo/">https://www.masterhowtolearn.com/2020-10-31-why-i-no-longer-tell-my-friends-about-anki-supermemo/</a></em></p>]]>
            </description>
            <link>https://www.masterhowtolearn.com/2020-10-31-why-i-no-longer-tell-my-friends-about-anki-supermemo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24957617</guid>
            <pubDate>Sun, 01 Nov 2020 06:33:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Visualizing Git Concepts with D3]]>
            </title>
            <description>
<![CDATA[
Score 241 | Comments 25 (<a href="https://news.ycombinator.com/item?id=24957280">thread link</a>) | @gilad
<br/>
October 31, 2020 | https://onlywei.github.io/explain-git-with-d3/ | <a href="https://web.archive.org/web/*/https://onlywei.github.io/explain-git-with-d3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div id="ExplainGitCommit-Container">
      <p>
        We are going to skip instructing you on how to add your files for commit in this explanation.
        Let's assume you already know how to do that. If you don't, go read some other tutorials.
      </p>
      <p>
        Pretend that you already have your files staged for commit and enter <span>git commit</span>
        as many times as you like in the terminal box.
      </p>
      
    </div>
    <div id="ExplainGitTag-Container">
      <p>
        <span>git tag name</span> will create a new tag named "name".
        Creating tags just creates a new tag pointing to the currently checked out commit.
      </p>
      <p>
        Tags can be deleted using the command <span>git tag -d name</span> (coming soon).
      </p>
      <p>
        Type <span>git commit</span> and <span>git tag</span> commands
        to your hearts desire until you understand this concept.
      </p>
      
    </div>
    <div id="ExplainGitBranch-Container">
      <p>
        <span>git branch name</span> will create a new branch named "name".
        Creating branches just creates a new tag pointing to the currently checked out commit.
      </p>
      <p>
        Branches can be deleted using the command <span>git branch -d name</span>.
      </p>
      <p>
        Type <span>git commit</span> and <span>git branch</span> commands
        to your hearts desire until you understand this concept.
      </p>
      
    </div>
    <div id="ExplainGitCheckout-Container">
      <p>
        <span>git checkout</span> has many uses,
        but the main one is to switch between branches.<br>
        For example, to switch from master branch to dev branch,
        I would type <span>git checkout dev</span>.
        After that, if I do a git commit, notice where it goes. Try it.
      </p>
      <p>
        In addition to checking out branches, you can also checkout individual commits. Try it.<br>
        Make a new commit and then type <span>git checkout bb92e0e</span>
        and see what happens.
      </p>
      <p>
        Type <span>git commit</span>, <span>git branch</span>,
        and <span>git checkout</span> commands to your hearts desire
        until you understand this concept.
      </p>
      
    </div>
    <div id="ExplainGitCheckout-b-Container">
      <p>
        You can combine <span>git branch</span> and <span>git checkout</span>
        into a single command by typing <span>git checkout -b branchname</span>.
        This will create the branch if it does not already exist and immediately check it out.
      </p>
      
    </div>
    <div id="ExplainGitReset-Container">
      <p>
        <span>git reset</span> will move HEAD and the current branch back to wherever
        you specify, abandoning any commits that may be left behind. This is useful to undo a commit
        that you no longer need.
      </p>
      <p>
        This command is normally used with one of three flags: "--soft", "--mixed", and "--hard".
        The soft and mixed flags deal with what to do with the work that was inside the commit after
        you reset, and you can read about it <a href="http://git-scm.com/2011/07/11/reset.html">here</a>.
        Since this visualization cannot graphically display that work, only the "--hard" flag will work
        on this site.
      </p>
      <p>
        The ref "HEAD^" is usually used together with this command. "HEAD^" means "the commit right
        before HEAD. "HEAD^^" means "two commits before HEAD", and so on.
      </p>
      <p>
        Note that you must <b>never</b> use <span>git reset</span> to abandon commits
        that have already been pushed and merged into the origin. This can cause your local repository
        to become out of sync with the origin. Don't do it unless you really know what you're doing.
      </p>
      
    </div>
    <div id="ExplainGitRevert-Container">
      <p>
        To undo commits that have already been pushed and shared with the team, we cannot use the
        <span>git reset</span> command. Instead, we have to use <span>git revert</span>.
      </p>
      <p>
        <span>git revert</span> will create a new commit that will undo all of the work that
        was done in the commit you want to revert.
      </p>
      
    </div>
    <div id="ExplainGitMerge-Container">
      <p>
        <span>git merge</span> will create a new commit with two parents. The resulting
        commit snapshot will have the all of the work that has been done in both branches.
      </p>
      <p>
        If there was no divergence between the two commits, git will do a "fast-forward" method merge.<br>
        To see this happen, checkout the 'ff' branch and then type <span>git merge dev</span>.
      </p>
      
    </div>
    <div id="ExplainGitRebase-Container">
      <p>
        <span>git rebase</span> will take the commits on this branch and "move" them so that their
        new "base" is at the point you specify.
      </p>
      <p>
        You should pay close attention to the commit IDs of the circles as they move when you do this exercise.
      </p>
      <p>
        The reason I put "move" in quotations because this process actually generates brand new commits with
        completely different IDs than the old commits, and leaves the old commits where they were. For this reason,
        you never want to rebase commits that have already been shared with the team you are working with.
      </p>
      
    </div>
    <div id="ExplainGitFetch-Container">
      <p>
        <span>git fetch</span> will update all of the "remote tracking branches" in your local repository.
        Remote tracking branches are tagged in grey.
      </p>
      
    </div>
    <div id="ExplainGitPull-Container">
      <p>
        A <span>git pull</span> is a two step process that first does a <span>git fetch</span>,
        and then does a <span>git merge</span> of the remote tracking branch associated with your current branch.
        If you have no current branch, the process will stop after fetching.
      </p>
      <p>
        If the argument "--rebase" was given by typing <span>git pull --rebase</span>, the second step of
        pull process will be a rebase instead of a merge. This can be set to the default behavior by configuration by typing:
        <span>git config branch.BRANCHNAME.rebase true</span>.
      </p>
      
    </div>
    <div id="ExplainGitPush-Container">
      <p>
        A <span>git push</span> will find the commits you have on your local branch that the corresponding branch
        on the origin server does not have, and send them to the remote repository.
      </p>
      <p>
        By default, all pushes must cause a fast-forward merge on the remote repository. If there is any divergence between
        your local branch and the remote branch, your push will be rejected. In this scenario, you need to pull first and then
        you will be able to push again.
      </p>
      
    </div>
    <div id="ExplainGitClean-Container">
      <p>
        One simple example of the use of <span>git reset</span> is to completely restore your local repository
        state to that of the origin.<br>
        You can do so by typing <span>git reset origin/master</span>.
      </p>
      <p>
        Note that this won't delete untracked files, you will have to delete those separately with
        the command <span>git clean -df</span>.
      </p>
      
    </div>
    <div id="ExplainGitFetchRebase-Container">
      <p>
        Below is a situation in which you are working in a local branch that is all your own. You want to receive the latest code
        from the origin server's master branch. To update your local branch, you can do it without having to switch branches!
      </p>
      <p>
        First do a <span>git fetch</span>, then type <span>git rebase origin/master</span>!
      </p>
      
    </div>
    <div id="ExplainGitDeleteBranches-Container">
      <p>
        <span>git branch -d</span> is used to delete branches.
        I have pre-created a bunch of branches for you to delete in the playground below.
        Have at it.
      </p>
      
    </div>
    <div id="ExplainGitFree-Container">
      <p>
        Do whatever you want in this free playground.
      </p>
      
    </div>
  </div></div>]]>
            </description>
            <link>https://onlywei.github.io/explain-git-with-d3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24957280</guid>
            <pubDate>Sun, 01 Nov 2020 04:43:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Toronto-area lawyer had to flee Canada after taking on the tow truck industry]]>
            </title>
            <description>
<![CDATA[
Score 416 | Comments 232 (<a href="https://news.ycombinator.com/item?id=24957200">thread link</a>) | @walterbell
<br/>
October 31, 2020 | https://www.ctvnews.ca/w5/this-toronto-area-lawyer-had-to-flee-the-country-after-taking-on-the-tow-truck-industry-1.5167869 | <a href="https://web.archive.org/web/*/https://www.ctvnews.ca/w5/this-toronto-area-lawyer-had-to-flee-the-country-after-taking-on-the-tow-truck-industry-1.5167869">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>TORONTO -- 
	Lisa Carr never thought her work would lead to armed threats, a firebombing, a shooting and a conspiracy to kill her.</p>
<p>
	The Carr Law office is in a nondescript strip mall in Vaughan, Ont., north of Toronto. It’s closed now, after the litigation lawyer says police told her they could no longer protect her.</p>
<p>
	She was shuttled to another country where she spent five long months in hiding. Carr has never before told her story, but agreed to meet for an interview as part of a W5 investigation into the shady underbelly of an industry that forced her to give up her business and almost cost her, her life: The tow truck industry.</p>
<p>
	Over the last number of years, criminal elements have been battling for lucrative control of the major highways around the Toronto area. It has resulted in more than 50 arsons, multiple shootings and at least four murders.</p>
<p>
	So why is there so much violence over a couple of hundred-dollar tows at the side of the road? Because that one tow can net tens of thousands of dollars.</p>
<p>
	Here’s how it works: The tow truck driver gets a kickback from an unscrupulous auto body shop, which then submits wildly inflated repair fees to an insurance company.</p>
<p>
	<img alt="york police" src="https://www.ctvnews.ca/polopoly_fs/1.4954903!/httpImage/image.jpg_gen/derivatives/landscape_960/image.jpg"></p>
<p>
	The insurance industry estimates that fake repair bills tally up to $2 billion a year in Canada. And that’s why Carr was in the crosshairs. She was hired by an insurance company to challenge bogus claims.</p>
<p>
	Over the course of a number of months, Carr’s law firm was the target of increasingly violent attacks. First a firebombing and then her office was set on fire.</p>
<p>
	Months later, in broad daylight, a colleague leaving work had a gun put to her head and was told, “Stop suing our friends.” Shortly after that, again in broad daylight, someone opened fire through the front door of the busy office.</p>
<p>
	Carr says it is incredible no one was struck by the flurry of bullets.</p>
<p>
	“I looked down the hall and I saw my receptionist on her hands and knees surrounded by glass. And one of the other girls came running at me saying, ‘Shots fired, shots fired. Call 911.’”</p>
<p>
	While the violence surrounding the tow truck industry has made headlines in the Greater Toronto Area, the story that has never been told is that York Regional Police (YRP) uncovered a plot to kill Carr.</p>
<p>
	It was such a credible threat that they gave her an hour to pack up her belongings and leave her home. Carr and her husband were then whisked out of the country and spent five months in hiding.</p>
<p>
	Three separate police services – YRP, Toronto Police Service and Ontario Provincial Police – joined forces to launch Project Platinum to investigate the violence associated with the tow truck industry.</p>
<p>
	They carried out a series of raids this past spring, which netted dozens of high-powered weapons and led to the arrests of 35 people who face almost 500 charges, including the attempted murder of Carr.</p>
<p>
	<img alt="weapon" src="https://www.ctvnews.ca/polopoly_fs/1.4954983!/httpImage/image.jpg_gen/derivatives/landscape_960/image.jpg"></p>
<p>
	Now back in Canada, Carr says police have told her she is likely no longer in danger, but with one caveat.</p>
<p>
	“The police said we believe the risk is low. As long as you don't go back to work, as long as you don't restart the firm,” she says.</p>
<p>
	“So they have effectively ended my career. We lost everything. They won.”</p>
                                              </div></div>]]>
            </description>
            <link>https://www.ctvnews.ca/w5/this-toronto-area-lawyer-had-to-flee-the-country-after-taking-on-the-tow-truck-industry-1.5167869</link>
            <guid isPermaLink="false">hacker-news-small-sites-24957200</guid>
            <pubDate>Sun, 01 Nov 2020 04:20:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Simple Image Vectorization]]>
            </title>
            <description>
<![CDATA[
Score 124 | Comments 14 (<a href="https://news.ycombinator.com/item?id=24957120">thread link</a>) | @thesephist
<br/>
October 31, 2020 | https://wordsandbuttons.online/simple_image_vectorization.html | <a href="https://web.archive.org/web/*/https://wordsandbuttons.online/simple_image_vectorization.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
    <p>
Vectorization is when you take some minecraft-style raster image and make a crisp vector picture out of it.
    </p>
    <img src="https://upload.wikimedia.org/wikipedia/commons/6/6b/Bitmap_VS_SVG.svg">
    
    <p>
It's especially useful when you want to turn a satellite photo into a map. Or if you want to scan some blueprint and turn it into a CAD model. Or if you want to reissue an old game and you don't want to redraw all the artwork from scratch.
    </p>
    <p>
The algorithm I'm going to show you has nothing to do with all these things. It's a basic vectorization technique which, in its original form, has little to none applications in the industry.
    </p>
    <p>
On the plus side, it illustrates the approach rather well. It shows how things like bilinear interpolation, gradient descent, and parametric splines work together to solve a real-world problem. At the very least, it makes learning about all these things a little more compelling.
    </p>

    <h2>
An input image
    </h2>
    <p>
A raster image is essentially a rectangular table of things. If it's a full-color RGB, then it's a table of color pixels. Color pixels are the triplets of 8-bit integer values where each value represents an amount of red, green, and blue color.
    </p>
    <p>
Medical images, such as obtained from computed tomography, are usually the tables of 12-bit or 16-bit integers. It's not a color really since the values come from invisible X-ray radiation, but they are called gray values nevertheless.
    </p>
    <p>
Satellite images may have a lot of channels. Apart from the colors of the visible specter they may contain ultra-violet and infra-red luminosity. Channels may be represented by integers or floating point values.
    </p>
    <p>
Our image will be a simple gray-scale bitmap.
    </p>
    <canvas id="greyscale_canvas" width="640" height="640"></canvas>
    <p>
Technically, we can already turn it into vectors rather easily. Let's just agree on some threshold, and mark the contour of all the pixels that have the values exceeding this threshold.
    </p>
    <canvas id="greyscale_canvas_contour" width="640" height="640"></canvas>
    <p>
Well, it's simple, but it's not what we wanted. We want curves, not corners. And for that, we have to make our image less cornery.
    </p>
    <h2>
<span id="index_image_interpolation">Image interpolation</span>
    </h2>
    <p>
Let's say our image is not a table of values. Let's say we only know the values in the centers of the pixels, and we have to guess the values between them somehow.
    </p>
    <p>
This is called interpolation. The simplest case would be the nearest neighbor interpolation, where for every point on an image, the value is the value from the nearest pixel's center. But this simply turns it back into a table.
    </p>
    <p>
A little more advanced is the <span id="index_bilinear_interpolation">bilinear interpolation</span>. The value is the linear sum of the four neighboring values. It looks like this.
    </p>
    <div>
    <pre id="code_1">// pixel value with out of bounds checks
function pixel_in(pixels, i, j) {
    if(i &gt;= pixels.length)
        return pixel_in(pixels, pixels.length-1, j);
    if(i &lt; 0)
        return pixel_in(pixels, 0, j);
    if(j &gt;= pixels[0].length)
        return pixel_in(pixels, i, pixels[0].length-1);
    if(j &lt; 0)
        return pixel_in(pixels, i, 0);
    return pixels[i][j];
}

// linear interpolation
function value_in(pixels, x, y) {
    var j = Math.floor(x - 0.5);
    var tj = x - 0.5 - j;
    var i = Math.floor(y - 0.5);
    var ti = y - 0.5 - i;
    return pixel_in(pixels, i, j) * (1 - ti) * (1 - tj)
         + pixel_in(pixels, i, j+1) * (1 - ti) * (tj)
         + pixel_in(pixels, i+1, j+1) * (ti) * (tj)
         + pixel_in(pixels, i+1, j) * (ti) * (1 - tj);
}
    </pre>
    </div>
    <p>
If we darken the pixels where the interpolated value meets the threshold, we'll get some kind of a contour.
    </p>
    <canvas id="interpolation_canvas" width="640" height="640"></canvas>
    
    <p>
There are other methods. Plenty of them. But linear interpolation solves the cornery border problem just fine. Although, the border we see is just the borderline of some threshold. It's not a vector representation yet.
    </p>

    <h2>
Turning an interpolated image into a contour
    </h2>
    <p>
We can borrow an idea from the <a href="https://wordsandbuttons.online/the_simplest_possible_smooth_contouring_algorithm.html">simplest possible smooth contouring</a> algorithm. We'll build an initial border from the source pixels, and then we'll use our linearly interpolated image to find the best place to put each contour point so the image value will meet the threshold value.
    </p>
    <p>
When you have a <span id="index_distance_field">distance field</span>, it's easy. A distance field is when for any point in space you can tell how far it lies from the surface you want. It's basically a function from point in space to distance.
    </p>
    <p>
You take its gradient, take the difference between the value you have and the threshold value. Since it's the distance field, the value difference is exactly the distance you should move your point for. And the gradient is the exact opposite direction. You just inverse, multiply, add — and you're there.
    </p>
    <p>
Unfortunately, we don't have a distance field. We have a continuous image which only resembles one.
    </p>
    <p>
But the principle still works. If you traverse against the gradient, you will get closer to the threshold value. And the more the difference, the further you have to go. It's just you wouldn't always get there in one try.
    </p>
    <p>
So let's try several times then. Let's make an <a href="https://wordsandbuttons.online/interactive_introduction_to_iterative_algorithms.html">iterative algorithm</a> out of it.
    </p>
    <div>
    <pre id="code_2">// gradient
function gradient(pixels, x, y) {
    const eps = 1e-5;
    return [(value_in(pixels, x + eps, y) - value_in(pixels, x, y)) / eps,
            (value_in(pixels, x, y + eps) - value_in(pixels, x, y)) / eps];
}

// how far should you shift the point to meet the isoline
// if value_in were a distance function
function gradient_shift(pixels, threshold, x, y) {
    var g = gradient(pixels, x, y);
    var g_norm = Math.sqrt(g[0]*g[0] + g[1]*g[1]);
    var d = threshold - value_in(pixels, x, y);
    return [g[0] * d / g_norm / g_norm, g[1] * d / g_norm / g_norm];
}

// brings a point closer to the threshold isoline
function fit_point_better(pixels, threshold, point) {
    const ok_error = 1/255;
    if(Math.abs(value_in(pixels, point[0], point[1]) - threshold) &lt; ok_error)
        return point;
    gs = gradient_shift(pixels, threshold, point[0], point[1])
    var new_point = [point[0] + gs[0], point[1] + gs[1]];
    return fit_point_better(pixels, threshold, new_point);
}
    </pre>
    </div>
    <p>
We'll move our contour points against the gradient until we're close enough to the threshold
    </p>
    <canvas id="fitting_canvas" width="640" height="640"></canvas>
        
    <p>
That's good but we can do better. Let's make the contour smooth.
    </p>

    <h2>
Cubic splines
    </h2>
    <p>
All we have to do to make the contour smooth is to turn each line segment into a parametric cubic curve.
    </p>
    <p>
It's probably sounds more complicated than it is. A parametric cubic curve is just a pair of polynomials. If you have the points and partial derivatives in this points, you can get the coefficients for them from this pair of <a href="https://wordsandbuttons.online/programmers_introduction_to_linear_equations.html">linear systems</a>:
    </p>
    <div><p>
Px(t<sub>1</sub>)' = 3a<sub>x</sub>t<sub>1</sub><sup>2</sup> + 2b<sub>x</sub>t<sub>1</sub> + c = dx<sub>1</sub>/dt
<br>
Px(t<sub>1</sub>) = a<sub>x</sub>t<sub>1</sub><sup>3</sup> + b<sub>x</sub>t<sub>1</sub><sup>2</sup> + c<sub>x</sub>t<sub>1</sub> + d = x<sub>1</sub>
<br>
Px(t<sub>2</sub>) = a<sub>x</sub>t<sub>2</sub><sup>3</sup> + b<sub>x</sub>t<sub>2</sub><sup>2</sup> + c<sub>x</sub>t<sub>2</sub> + d = x<sub>2</sub>
<br>
Px(t<sub>2</sub>)' = 3a<sub>x</sub>t<sub>2</sub><sup>2</sup> + 2b<sub>x</sub>t<sub>2</sub> + c = dx<sub>2</sub>/dt
    </p><p>
    
Py(t<sub>1</sub>)' = 3a<sub>y</sub>t<sub>1</sub><sup>2</sup> + 2b<sub>y</sub>t<sub>1</sub> + c = dy<sub>1</sub>/dt
<br>
Py(t<sub>1</sub>) = a<sub>y</sub>t<sub>1</sub><sup>3</sup> + b<sub>y</sub>t<sub>1</sub><sup>2</sup> + c<sub>y</sub>t<sub>1</sub> + d = y<sub>1</sub>
<br>
Py(t<sub>2</sub>) = a<sub>y</sub>t<sub>2</sub><sup>3</sup> + b<sub>y</sub>t<sub>2</sub><sup>2</sup> + c<sub>y</sub>t<sub>2</sub> + d = y<sub>2</sub>
<br>
Py(t<sub>2</sub>)' = 3a<sub>y</sub>t<sub>2</sub><sup>2</sup> + 2b<sub>y</sub>t<sub>2</sub> + c = dy<sub>2</sub>/dt
    </p></div>
    <p>
The curve itself will then look like this.
    </p>
    <canvas id="cubic_canvas" width="640" height="640"></canvas>
    <p>
Even more, since we get to choose the parameter range, we can make it [0..1]. This greatly simplifies our system and makes it really easy to solve.
    </p>
    <p>
Here is the function that makes one array of polynomial coefficients from two pairs of point and tangent values.
    </p>
    <div>
    <pre id="code_3">// solver specific to [0..1] parametrized splines
function spline_for(p1, p1d, p2, p2d) {
//     A = [
//         [1, 0, 0, 0],
//         [0, 1, 0, 0],
//         [1, 1, 1, 1],
//         [0, 1, 2, 3]];
//     B = [p1, p1d, p2, p2d]
    return [
        p1,
        p1d,
        3*p2 - p2d - 3*p1 - 2*p1d,
        p2d + p1d - 2*p2 + 2*p1
    ];
}
    </pre>
    </div>
    <p>
The polynomial is then computed in every <i>t</i> with this function.
    </p>
    <div>
    <pre id="code_4">// polynomial
function polynomial_in_t(A, t){
    var pt = 0.0;
    for(var i = 0; i &lt; A.length; ++i){
        pt += A[i] * Math.pow(x, i);
    }
    return pt;
}
    </pre>
    </div>
    <p>
So for every line segment with tangents, we can make a parametric polynomial. There is one problem though. We don't have tangents.
    </p>
    <p>
We have the gradient, which is orthogonal to the tangent, but there are two possible tangents in every point. The tangent can be oriented left or right from the gradient.
    </p>
    <p>
But this is solvable. Let's just pick the direction we like and keep it consistent.
    </p>
    <p>
Let the curves that originally come from horizontally oriented segments always have both tangents that way that <i>dx &gt; 0</i>. And the ones that come from vertically oriented segments, will have <i>dy &gt; 0</i>.
    </p>
    <p>
It looks like we have enough parts to assemble an algorithm.
    </p>
    <h2>
Creating splines from the pixels
    </h2>
    <p>
Let's split our vectorization into two parts. First, we'll get points and tangents for every line segment from the pixels. Then we'll turn it all into polynomial splines.
    </p>
    <p>
The function that does the first part looks like this.
    </p>
    <div>
    <pre id="code_5">function turn_pixels_into_points_and_tangents(pixels, threshold) {
    var points = [];
    var tangents = [];

    // "horizontal" pieces
    for(var i = 0; i &lt;= pixels.length; i += 1) {
        var old_point = [];
        var old_tangent = [];
        for(var j = 0; j &lt;= pixels[0].length; j += 1) {
            // if right, left, top, and bottom pixels have a sign change,
            // there should be a spline there
            var sign_change_on_the_right  =
                (pixel_in(pixels, i-1, j+0) - threshold) *
                (pixel_in(pixels, i+0, j+0) - threshold) &lt; 0;
            var sign_change_on_the_left   =
                (pixel_in(pixels, i-1, j-1) - threshold) *
                (pixel_in(pixels, i+0, j-1) - threshold) &lt; 0;
            var sign_change_on_the_bottom =
                (pixel_in(pixels, i+0, j-1) - threshold) *
                (pixel_in(pixels, i+0, j+0) - threshold) &lt; 0;
            var sign_change_on_the_top    =
                (pixel_in(pixels, i-1, j-1) - threshold) *
                …</pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wordsandbuttons.online/simple_image_vectorization.html">https://wordsandbuttons.online/simple_image_vectorization.html</a></em></p>]]>
            </description>
            <link>https://wordsandbuttons.online/simple_image_vectorization.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24957120</guid>
            <pubDate>Sun, 01 Nov 2020 03:57:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[NAT Slipstreaming]]>
            </title>
            <description>
<![CDATA[
Score 511 | Comments 160 (<a href="https://news.ycombinator.com/item?id=24955891">thread link</a>) | @todsacerdoti
<br/>
October 31, 2020 | https://samy.pl/slipstream/ | <a href="https://web.archive.org/web/*/https://samy.pl/slipstream/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><a href="https://samy.pl/slipstream/">NAT Slipstreaming</a> allows an attacker to remotely access any TCP/UDP service bound to a victim machine, bypassing the victim's NAT/firewall (arbitrary firewall pinhole control), just by the victim visiting a website.</p><p><em>animation generated with my <a target="_blank" href="https://github.com/samyk/drawio">fork</a> of <a target="_blank" href="https://draw.io/">draw.io</a>, allowing exportable edge context flow &amp; control in animations</em></p><p>NAT Slipstreaming exploits the user's browser in conjunction with the Application Level Gateway (ALG) connection tracking mechanism built into NATs, routers, and firewalls by chaining internal IP extraction via timing attack or WebRTC, automated remote MTU and IP fragmentation discovery, TCP packet size massaging, TURN authentication misuse, precise packet boundary control, and protocol confusion through browser abuse. As it's the NAT or firewall that opens the destination port, this bypasses any browser-based port restrictions.</p><p>This attack takes advantage of arbitrary control of the data portion of some TCP and UDP packets <i>without</i> including HTTP or other headers; the attack performs this new packet injection technique across all major modern (and older) browsers, and is a modernized version to my original <a target="_blank" href="https://samy.pl/natpin/">NAT Pinning technique from 2010</a> (presented at DEFCON 18 + Black Hat 2010). Additionally, new techniques for local IP address discovery are included.</p><p>This attack requires the NAT/firewall to support ALG (Application Level Gateways), which are mandatory for protocols that can use multiple ports (control channel + data channel) such as SIP and H323 (VoIP protocols), FTP, IRC DCC, etc.</p><div>
  <li>victim visits malicious site (or site with malicious advertisement)<!-- eg <a target=_blank href="https://samy.pl/slipstream/server">https://samy.pl/slipstream/server</a>--></li>
<li>internal IP of victim first must be extracted by browser and sent to server

<ul>
<li>internal IP attempted to be extracted via <a target="_blank" href="https://www.w3.org/TR/webrtc/">WebRTC</a> data channel over https</li>
<ul>
<li>some browsers (Chrome) only divulge the local IP via WebRTC over HTTPS but some of our attacks require HTTP so we first redirect to the HTTPS version of the attack software to extract the local IP</li>
<li>we then redirect to the HTTP version with the local IP included in the URL if we were able to obtain it to bypass other cross-origin protection mechanisms (the <code>.local</code> mDNS/Bonjour address presented will not be useful for the attack)</li>
</ul>
<li>if internal IP not divulged by WebRTC (Safari) or no WebRTC (&lt;= IE11), <strong>web-based TCP timing attack performed</strong>

<ul>
<li>hidden <code>img</code> tags to all common gateways (eg <code>192.168.0.1</code>) are loaded in background</li>
<li><code>onerror/onsuccess</code> events attached to <code>img</code> tags</li>
<li>if any TCP RST (oneror) returned by gateway, or SYN + HTTP response (onsuccess), within a few seconds (before TCP timeout triggers onerror), we've detected valid subnet</li>
<li>re-perform timing attack across all IPs on detected subnets (/24), measuring time to onerror/onsuccess firing</li>
<li>fastest response is likely internal IP, though all responses are considered victim internal IP candidates and attacked</li>
</ul></li>
</ul></li>
<li>large TCP beacon sent via hidden form and automatic HTTP POST to attacker "HTTP server" bound to a non-standard port to force TCP segmentation and maximum MTU size discovery of the victim's IP stack
<ul>
<li>attacker TCP server sends <a target="_blank" href="https://tools.ietf.org/html/rfc793#section-3.1">Maximum Segment Size</a> TCP Option to massage victim outbound packet sizes (<a target="_blank" href="https://tools.ietf.org/html/rfc793#section-3.1">RFC 793 x3.1</a>), allowing control of how large browser TCP packets will be</li>
</ul></li>
<li>large UDP beacon sent from browser via WebRTC TURN authentication mechanism to non-standard port to attacker's server to force IP fragmentation with TURN <code>username</code> field stuffed
<ul>
<li>we perform a similar attack as our TCP segmentation, but over UDP as IP fragmentation will occur and provide different values than TCP segmentation</li>
<li>victim MTU size, IP header size, IP packet size, TCP header size, TCP segment sizes detected by server and sent back to victim's browser, used later for packet stuffing</li>
</ul></li>
<li>"SIP packet" in new hidden form generated, containing internal IP to trigger Application Level Gateway connection tracking
<ul>
<li>"HTTP POST" to server on TCP port 5060 (SIP port) initiated, avoiding <a target="_blank" href="https://github.com/samyk/chromium/blob/2d57e5b8afc6d01b344a8d95d3470d46b35845c5/net/base/port_util.cc#L20-L90">restricted browser ports</a></li>
<li>POST data is "stuffed" to exact TCP segment size / packet boundary, then “SIP packet” appended and posted via web form</li>
<li><b>victim IP stack breaks the POST into multiple TCP packets, leaving the "SIP packet" (as part of POST data) in its own TCP packet without any accompanying HTTP headers</b></li>
<li>if browser alters size of multipart/form boundary (Firefox) or packet size changes for any other reason, size change is communicated back to client and client auto-resends with new size</li>
<li>when opening UDP port, SIP packet is sent over TURN protocol inside specially crafted <code>username</code> field forcing IP fragmentation and precise boundary control</li>
</ul></li>
<li>victim NAT sees proper SIP REGISTER packet on SIP port (with no HTTP data), triggering ALG to open any TCP/UDP port defined in packet back to victim
<ul>
<li>victim NAT rewrites SIP packet, replacing internal IP with public IP, hinting to attacker exploit was successful</li>
<li>even if victim NAT normally rewrites source ports, the ALG will still be forced to port forward to the attacker's port of choice as it believes victim machine opened that port and attacker sees new source port in arriving SIP packet </li>
<li><b>attacker can now bypass victim NAT and connect directly back to any port on victim's machine, exposing previously protected/hidden services</b></li>
</ul></li>
<li><i>to investigate...perhaps by you?</i>
<ul>
  <li>non-malicious usage: this technique essentially gives browsers full TCP and UDP socket capability to communicate to any protocol locally on the system; the connection can be abstracted through a cloud server that connects back but the browser just talks to the cloud server as if it's the socket and makes browsers much more powerful to communicate on non-web-friendly protocols</li>
  <li>if testing in a virtual machine (VM) using shared networking (used to protect a host from attacks by routing it through the host, not letting it directly onto the network), if the packets make it out, the parent host machine is where the ports end up getting opened, not the VM ;)</li>
  <li>IP fragmentation allows full control of all data in the IP data section, meaning full control of the <b>UDP header</b>, including source/dest ports in the overflowed packet...what else could this abuse?</li>
</ul></li>

<p><a target="_blank" href="https://raw.githubusercontent.com/samyk/slipstream/main/img/pinpkt2.png"><img src="https://raw.githubusercontent.com/samyk/slipstream/main/img/pinpkt2.png" alt="successful packet broken into valid SIP packet"></a></p>



<h2 id="network-address-translation-nat">Network Address Translation (NAT)</h2>

<p>We use NATs (Network Address Translation) for several reasons. The most useful feature of NAT is that it allows a single public IP address to be shared among multiple systems. It does this by creating a local network, providing local IP addresses to all machines that connect, and when one of those systems reaches out to the Internet, it rewrites packets going out to use the public IP so responses come back to the NAT, and vice versa, rewriting desination IP to specific client's IP. </p>

<p>It's the responsibility of the NAT to differentiate connections to the same addresses/ports (google.com:443) from internal hosts as ultimately their outbound port, destination ip and source ip will all be the same. If two different internal peers attempt to connect from the same source port, modern NATs will alter one of the source ports (some networks do this to all TCP/UDP source ports).</p>

<p><img src="https://raw.githubusercontent.com/samyk/slipstream/main/img/lan.png" alt="NAT"></p>

<h3 id="connection-tracking">Connection Tracking</h3>

<p>From <a target="_blank" href="https://www.wikiwand.com/en/Netfilter">Wikipedia ala Wikiwand</a>:</p>

<div><pre><code>One of the important features built on top of the Netfilter 
framework is connection tracking. Connection tracking 
allows the kernel to keep track of all logical network 
connections or sessions, and thereby relate all of the packets
which may make up that connection. NAT relies on this 
information to translate all related packets in the same way, 
and iptables can use this information to act as a stateful 
firewall.</code></pre></div>

<p>If a machine behind your NAT sends a packet out and your router expects the remote host may respond, it keeps track of information, specifically the source and destination ports, source and destination IP addresses, and your internal IP, then returns any packets matching it back to your internal IP.</p>

<p>If another host on your LAN attempts to make the same connection with the same source and destination ports + IPs, your NAT wouldn't be able to discriminate it (the source IPs are different on your LAN but are rewritten to the same public IP on the WAN side), so it alters the source port, but rewrites it when sending back to you.</p>

<h3 id="application-level-gateway">Application Level Gateway</h3>

<p>ALGs allow NAT to track a multi-port protocol like FTP to go out from your system to an FTP server, then track when you request a file to be sent to your internal IP on a specific port, the ALG can rewrite the packet to include your public IP, then forward the FTP's server connection back to you. Had it not rewritten your IP, the FTP server would try to connect back to you on your internal IP (or not try at all if it expects the source IP to be the same as the signaling connection).</p>

<p>From <a target="_blank" href="https://www.wikiwand.com/en/Application-level_gateway">Wikipedia</a>:</p>

<div><pre><code>In the context of computer networking, an application-level 
gateway consists of a security component that augments a 
firewall or NAT employed in a computer network. It allows 
customized NAT traversal filters to be plugged into the 
gateway to support address and port translation for certain 
application layer "control/data" protocols such as FTP, 
BitTorrent, SIP, RTSP, file transfer in IM applications, etc. 
In order for these protocols to work through NAT or a 
firewall, either the application has to know about an address/
port number combination that allows incoming packets, or the 
NAT has to monitor the control traffic and open up port 
mappings (firewall pinhole) dynamically as required. 
Legitimate application data can thus be passed through the 
security checks of the firewall or NAT that would have 
otherwise restricted the traffic for not meeting its limited 
filter criteria.</code></pre></div>

<h2 id="router-investigation--firmware-dumping">Router Investigation / Firmware Dumping</h2>

<p>I'd first like to see how common gateways actually treat packets and multi-port protocols like FTP, SIP, etc. To do this, we’ll want to reverse engineer the firmware from common routers. We could dump the flash from physical routers, however if we can get unencrypted firmware from the manufacturers, we’ll be able to investigate more router models and much faster.</p>

<p>We'll start with a common router, the Netgear Nighthawk R7000. A <a target="_blank" href="http://bfy.tw/NjZh">quick search</a> helps us …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://samy.pl/slipstream/">https://samy.pl/slipstream/</a></em></p>]]>
            </description>
            <link>https://samy.pl/slipstream/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24955891</guid>
            <pubDate>Sat, 31 Oct 2020 22:57:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Homicide victim found in burnt-out SUV ID'd as man behind spam-email empire]]>
            </title>
            <description>
<![CDATA[
Score 159 | Comments 91 (<a href="https://news.ycombinator.com/item?id=24955454">thread link</a>) | @goodcanadian
<br/>
October 31, 2020 | https://www.cbc.ca/news/canada/british-columbia/davis-wolfgang-hawke-missing-dead-1.5782107 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/british-columbia/davis-wolfgang-hawke-missing-dead-1.5782107">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>More than three years after his death, a man who was shot dead and found in a burnt-out SUV near Squamish, B.C., has been identified as a U.S. citizen known for spreading racist, neo-Nazi ideologies&nbsp;and for a massive spam email campaign that led to a $12.8-million US lawsuit.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5782212.1604017727!/fileImage/httpImage/image.jpeg_gen/derivatives/16x9_780/davis-wolfgang-hawke.jpeg"></p></div><figcaption>Davis Wolfgang Hawke was found dead in a burnt-out SUV in Squamish, B.C., on June 14, 2017. Police said his death was a homicide.<!-- --> <!-- -->(IHIT)</figcaption></figure><p><span><p>More than three years after his death, a man who was shot dead and found in a burnt-out SUV near Squamish, B.C., has been identified as a U.S. citizen known for spreading racist, neo-Nazi ideologies&nbsp;and for a massive spam email campaign that led to a $12.8-million US lawsuit.</p>  <p>Police found Davis Wolfgang Hawke dead on the Cheekye Forest Road, off the Sea to Sky Highway east of&nbsp;Paradise Valley, around 9:30 a.m. on June 14, 2017. Officers had been called about a burnt,&nbsp;red&nbsp;2000&nbsp;GMC&nbsp;Yukon XL on the side of the road.</p>  <p>An autopsy later confirmed the man had been shot dead,&nbsp;but&nbsp;for years&nbsp;the RCMP could not confirm his real name.</p>  <p>The Integrated Homicide Investigation Team (IHIT) only knew he&nbsp;went by the alias&nbsp;Jesse James, and that he was well known as an&nbsp;avid climber&nbsp;in Squamish, which is around 50 kilometres north of Vancouver.</p>  <p>But with IHIT's confirmation of his identity on Thursday, details about Hawke's past —&nbsp;including his fascist sympathies and a lucrative&nbsp;spam empire he built hawking loans, pornography, jewelry and prescription drugs — have come to light thanks to the work of an investigative journalist.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5782321.1604000520!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/britt-greenbaum.jpg 300w,https://i.cbc.ca/1.5782321.1604000520!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/britt-greenbaum.jpg 460w,https://i.cbc.ca/1.5782321.1604000520!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/britt-greenbaum.jpg 620w,https://i.cbc.ca/1.5782321.1604000520!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/britt-greenbaum.jpg 780w,https://i.cbc.ca/1.5782321.1604000520!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/britt-greenbaum.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5782321.1604000520!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/britt-greenbaum.jpg"></p></div><figcaption>Andrew Britt Greenbaum (aka Davis Hawke) at his grandparents' home in the U.S. in this undated picture. In posts online, his late mother said her son had been missing for years and that this was a cherished photo of her lost boy.<!-- --> <!-- -->(Facebook)</figcaption></figure></span></p>  <p>Brian McWilliams, author of the book <em>Spam Kings</em>, spent years tracking the young man, who&nbsp;he says lived a nomadic, risk-taking existence. He often travelled with half-wolf dogs, which were the only thing he appeared to be loyal to, according to McWilliams.</p>  <p>"It doesn't surprise me that this guy died in an inglorious and maybe a violent way. He was always living on the edge," McWilliams said.</p>    <p>McWilliams said Hawke,&nbsp;born Andrew Britt Greenbaum, changed his name many times and was&nbsp;evasive when the journalist was chasing him for a story on his junk-email&nbsp;empire.</p>  <p>He said Hawke and his associates bragged about making up to $300,000 in a year in the spam business, after dropping out of college.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5782537.1604017307!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/andrew-britt-greenbaum.jpg 300w,https://i.cbc.ca/1.5782537.1604017307!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/andrew-britt-greenbaum.jpg 460w,https://i.cbc.ca/1.5782537.1604017307!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/andrew-britt-greenbaum.jpg 620w,https://i.cbc.ca/1.5782537.1604017307!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/andrew-britt-greenbaum.jpg 780w,https://i.cbc.ca/1.5782537.1604017307!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/andrew-britt-greenbaum.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5782537.1604017307!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/andrew-britt-greenbaum.jpg"></p></div><figcaption>Greenbaum, who would later change his name to Hawke, grew up in a suburb of Boston and excelled at chess, before he branched into online spamming and vanished.<!-- --> <!-- -->(Facebook)</figcaption></figure></span></p>  <p>While IHIT&nbsp;said they had little information on Hawke, other than he was 38 when he died and was originally from the U.S.,&nbsp;McWilliams&nbsp;has gathered a lot of information about the "puzzling" young man who grew up in an affluent Boston suburb and was a chess prodigy.</p>  <p>McWilliams, who interviewed Hawke and his family, learned how he was bullied as a child&nbsp;for being small and Jewish —&nbsp;before he rejected&nbsp;his Jewish background,&nbsp;changed&nbsp;his name to Hawke&nbsp;and soon after became known to anti-racism groups as a neo-Nazi.</p>  <p>"At some point, he just became infatuated with this white supremacy notion," said McWilliams.</p>  <p>"He brought that mentality of everybody being inferior to him into the rest of his life," he said.</p>  <p>He organized a failed anti-government march in Washington, D.C., in 1999, and was written about in the New York Times and Rolling Stone magazine.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5782374.1604017399!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/davis-wolfgang-hawke-forest-road.jpg 300w,https://i.cbc.ca/1.5782374.1604017399!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/davis-wolfgang-hawke-forest-road.jpg 460w,https://i.cbc.ca/1.5782374.1604017399!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/davis-wolfgang-hawke-forest-road.jpg 620w,https://i.cbc.ca/1.5782374.1604017399!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/davis-wolfgang-hawke-forest-road.jpg 780w,https://i.cbc.ca/1.5782374.1604017399!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/davis-wolfgang-hawke-forest-road.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5782374.1604017399!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/davis-wolfgang-hawke-forest-road.jpg"></p></div><figcaption>The entrance to the Cheekye Forest Road as seen from the Sea to Sky Highway in Squamish, B.C. Hawke was found dead inside a burnt-out SUV along the road on June 14, 2017.<!-- --> <!-- -->(Google Street View)</figcaption></figure></span></p>  <p>Later he used his writing talents to trick people into sending him cash, and his spam email venture took off,&nbsp;according to court documents.</p>  <p>"He was a con man. He felt that he could convince anybody to buy herbal Viagra, just writing some clever email text. This guy was super intelligent and thought there was a sucker born every minute — and he was real good at finding them," said McWilliams.</p>    <p>In 2005, internet company AOL won a $12.8-million US judgment in federal court in Virginia against Hawke, who was accused of breaking federal law by sending massive amounts of unwanted spam emails to its customers. Hawke never showed for the trial.</p>  <p>Investigators believed he and his partners earned more than $600,000 on the spam sales pitches.</p>  <p>AOL also won a court order to dig up two properties owned by Hawke's relatives&nbsp;in Massachusetts to recoup costs, because&nbsp;Hawke had&nbsp;once bragged he buried gold and platinum in the yards, according to U.S. district court documents.</p>  <p>The company&nbsp;ultimately decided&nbsp;not to search the properties, which belonged to Hawke's grandmother and parents.</p>  <p>The family said no money was ever there.</p>    <p>A warrant for Hawke's arrest remained active.</p>  <p>Lawyers who worked on the case for AOL told CBC&nbsp;News on Thursday they hunted Hawke for years, and learned he'd escaped the&nbsp;U.S. by sneaking on board fishing trawlers, spending time in Belize.</p>  <p>After warrants for his arrest expired, the search wound down.&nbsp;But Hawke kept living like a fugitive and never returned home, according to his family.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.4172626.1498106495!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/ihit-truck-stock.jpg 300w,https://i.cbc.ca/1.4172626.1498106495!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/ihit-truck-stock.jpg 460w,https://i.cbc.ca/1.4172626.1498106495!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/ihit-truck-stock.jpg 620w,https://i.cbc.ca/1.4172626.1498106495!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/ihit-truck-stock.jpg 780w,https://i.cbc.ca/1.4172626.1498106495!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/ihit-truck-stock.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.4172626.1498106495!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/ihit-truck-stock.jpg"></p></div><figcaption>A stock photo of a 2000 red GMC Yukon XL, the same type of vehicle where the body of Hawke was found.<!-- --> <!-- -->(IHIT)</figcaption></figure></span></p>  <p>McWilliams said he always wondered if Hawke would settle down one day and "sell insurance," but said, "It sounds like he stayed kind of a wild man."</p>  <p>Hawke's uncle Raleigh Davis said his nephew's death was communicated to the family last week. He said nobody had seen Hawke in 20 years, and confirmation of his death at least offered some closure.</p>  <p>"He was really smart and really&nbsp;clever and really confident in a lot of ways.&nbsp;I think he had a really insecure side, though," said Davis.</p>  <p>"It's just sad."</p>  <p>Anyone with more information about Hawke's death is asked to phone IHIT&nbsp;at 1-877-551-4448&nbsp;or email ihitinfo@rcmp-grc.gc.ca&nbsp;or call Crime Stoppers at 1-800-222-8477&nbsp;if they want to remain anonymous.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5782109.1604017467!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/davis-wolfgang-hawke.jpg 300w,https://i.cbc.ca/1.5782109.1604017467!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/davis-wolfgang-hawke.jpg 460w,https://i.cbc.ca/1.5782109.1604017467!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/davis-wolfgang-hawke.jpg 620w,https://i.cbc.ca/1.5782109.1604017467!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/davis-wolfgang-hawke.jpg 780w,https://i.cbc.ca/1.5782109.1604017467!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/davis-wolfgang-hawke.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5782109.1604017467!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/davis-wolfgang-hawke.jpg"></p></div><figcaption>IHIT Sgt. Frank Jang holds a photo of Hawke.<!-- --> <!-- -->(CBC)</figcaption></figure></span></p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/canada/british-columbia/davis-wolfgang-hawke-missing-dead-1.5782107</link>
            <guid isPermaLink="false">hacker-news-small-sites-24955454</guid>
            <pubDate>Sat, 31 Oct 2020 21:47:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[FreeCAD BIM development news]]>
            </title>
            <description>
<![CDATA[
Score 80 | Comments 23 (<a href="https://news.ycombinator.com/item?id=24951311">thread link</a>) | @buovjaga
<br/>
October 31, 2020 | https://yorik.uncreated.net/blog/2020-011-freecad-september | <a href="https://web.archive.org/web/*/https://yorik.uncreated.net/blog/2020-011-freecad-september">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">

        
    

    <div id="main">

         
        

        <div>
            
            
            <p><img src="https://yorik.uncreated.net/images/2020/freecad-09-01.jpg" alt=""></p>
<p>Hi all,</p>
<p>After a very, very long delay, here comes finally another development report about the <a href="https://github.com/yorikvanhavre/BIM_Workbench">BIM tools</a> for <a href="https://www.freecadweb.org/">FreeCAD</a>. Awfully sorry about the black-out during these last months, lots of things <a href="https://www.rtbf.be/info/regions/liege/detail_circuit-de-spa-francorchamps-80-millions-d-investissements-et-le-retour-de-la-moto?id=10604892">happened</a> (all the 3D&amp;BIM done with FreeCAD and Blender) and  of course the pandemic didn't ease things either. Anyway, that doesn't mean nothing happened on the FreeCAD front, on the contrary, bugs still get addressed, things get fin-tuned, ideas get discussed, and FreeCAD gets everyday better.</p>
<p>This last month we also had a hectic turnover, because Autodesk changed the terms of the free version of  their <a href="https://www.autodesk.com/products/fusion-360/overview">Fusion360</a>. There is a full load of new limitations that restrain much the use for personal/hobby users. For example, the g-code you export from Fusion360 to CNC machines (that cut objects out of a block of material), is now making the machine running slower (and therefore raising the production costs), for no apparent reason other than nagging the users into buying a subscription. As a result, we saw a massive migration of users to FreeCAD, and it's really thrilling to see people discovering FreeCAD and learning it and liking it.</p>
<p>Thanks once more to everybody who contributes to my <a href="https://www.patreon.com/yorikvanhavre">Patreon</a> or <a href="https://liberapay.com/yorik/">Liberapay</a> campaigns, I'm really grateful you guys didn't just drop me away when I fail to write for 3 months.</p>
<p>Also, for who didn't notice, FreeCAD now has a proper <a href="https://liberapay.com/FreeCAD/">Liberapay teams account</a> where all money received is divided equally between the FreeCAD developers registered there (currently 7). This account has seen a huge raise of donations these last weeks (it receives around 1000 USD/month at the moment), thanks to the flow of new ex-Fusion360 users, and the impressive job Kunda1 is doing on <a href="https://twitter.com/FreeCADNews">the official FreeCAD twitter account</a> (subscribe to it if you are a twitter user, that account used to be just a mirror of the FreeCAD Facebook page, but is now very, very well maintained) and the campaigning of other people (special thanks to my <a href="https://www.twitter.com/beatnikqueen">girlfriend</a>, the most awesome person in the world).</p>
<p>So, no more loitering, to the news! Here is what we got this month:</p>
<h3>Customizable section color</h3>
<p><img src="https://yorik.uncreated.net/images/2020/freecad-09-02.jpg" alt=""></p>
<p><a href="https://wiki.freecadweb.org/Arch_SetMaterial">Materials</a> now have a new <strong>Section Color</strong> property, which allows to give a different color when the material is viewed and when it is cut through. So for example you can now have your walls appear white when viewed, but black when cut and seen on a TechDraw page.</p>
<p>This is a small improvement so far, but it laid the structure to have more advanced things, such as supporting hatch patterns. The main problem for this, is that, although the SVG format has an excellent support for hatch patterns (anything can become a hatch pattern, even bitmap images), the Qt implementation of the SVG format lacks support for it (it has its own <a href="https://doc.qt.io/Qt-5/qbrush.html#details">system</a> but it's not very practical to make that compatible with SVG). Therefore at the moment we have no clear idea of how to go further.</p>
<p><a href="https://wiki.freecadweb.org/TechDraw_Module">TechDraw</a>'s implementation of hatch patterns internally recreates OpenCasCade geometry, which works very well but might be heavy for large BIM models. In any case, that's a track I'm <a href="https://github.com/yorikvanhavre/FreeCAD/tree/td-makedrawgeomhatch">exploring</a> too.</p>
<h3>Default windows are now openable</h3>
<p><img src="https://yorik.uncreated.net/images/2020/freecad-09-03.jpg" alt=""></p>
<p>Another very small fix, but the default door and windows created with the <a href="https://wiki.freecadweb.org/Arch_Window">Door and windows tools</a> now have a hinge edge defined, so their <strong>Opening</strong> property now works out-of-the-box. It might not open in the direction you want, though, so you might still need to tweak this. But next items on my list are adding a couple of controls to easily switch opening directions.</p>
<h3>Default pattern size option</h3>
<p><img src="https://yorik.uncreated.net/images/2020/freecad-09-04.jpg" alt=""></p>
<p>The Draft patterns system is now working again (hatch patterns can be added to all closed Draft objects such as rectangles, polylines, circles, etc). I also added a preferences option under <em>Edit -&gt; Preferences -&gt; Draft -&gt; Visual settings</em> to set a default hatch pattern scale, which is useful when you always work with objects of a similar size range, for example building plans. I still have to experiment a bit (0.0025 seems like a very good default setting for BIM), but will add that to the BIM setup screen once I found a couple of good settings.</p>
<h3>Section plane label</h3>
<p><img src="https://yorik.uncreated.net/images/2020/freecad-09-05.jpg" alt=""></p>
<p><a href="https://wiki.freecadweb.org/Arch_SectionPlane">Section planes</a> now have a <strong>Show Label</strong> property, which, when turned on, show the section plane label on the plane in the 3D view. This is useful to easily identify these section planes when there are many in your document. The text size currently depends on the arrow size, but I'll make all this better customizable later on.</p>
<p>We have further plans too for the section planes, such as be able to double-click or activate them somehow, and find yourself in a separate 2D view with all needed geometry cut or turned off, where you can still work on the model in a 2D environment. This would be a bit like an intermediary step between the full 3D model and a TechDraw view. You can see a first draft of that coded by Carlo Pavan on the experimental tools palette in the BIM workbench.</p>
<h3>TechDraw tools in BIM workbench</h3>
<p><img src="https://yorik.uncreated.net/images/2020/freecad-09-06.jpg" alt=""></p>
<p>Among the annotation tools on the BIM workbench, you'll now find two TechDraw tools, <strong>Create page</strong> and <strong>Create view</strong>. The first one is the same of the <a href="https://wiki.freecadweb.org/TechDraw_PageTemplate">Create page from template</a> TechDraw tool, except that it remembers the last template you used and gets you right there when you use the tool again, so it gives a little bit faster workflow. The second tool is currently the same as the <a href="https://wiki.freecadweb.org/TechDraw_ArchView">TechDraw ArchView tool</a> but I plan to make it a bit more flexible in the future so it would become a mix of TechDraw's ArchView and DraftView tools, depending on the selected objects.</p>
<h3>TSV export</h3>
<p>The <a href="https://wiki.freecadweb.org/Arch_Schedule">Schedule</a> tool has been extended to now allow to export results to the .tsv (Tab-Separated Values) format, which is basically the same as the .csv (Comma-Separated Values) format, but using tab characters to separate columns, instead of commas. The big problem of csv, of course, is if there are commas in the columns texts. Usually spreadsheet apps are pretty tolerant with .csv files, they will usually ask you what character to consider as column separator on import, but others (for example GitHub) doesn't display them correctly if they don't use a comma as separator. So from now on there is a correct way to please everybody <i></i></p>
<h3>Blender exporter upgrade</h3>
<p><img src="https://yorik.uncreated.net/images/2020/freecad-09-07.jpg" alt=""></p>
<p>The <a href="https://gist.github.com/yorikvanhavre/029f6fcce9f4d0e62fb6163804b7f80d">FreeCAD exporter for Blender</a> has seen several small fixes, it now automatically adds the .FCStd extension to the generated file if you haven't added it yourself, it now correctly handles object rotation and scaling, and it applies modifiers before exporting. It now also supports faceless objects (wireframe objects).</p>
<p>This coupled with the <a href="https://blenderbim.org/">BlenderBIM</a> improvements, it now becomes increasingly easy to work on BIM models in Blender, or parts of BIM models, and when needed, integrate everything seamlessly in FreeCAD. There are many more joint FreeCAD/Blender developments going on, such as the new <a href="https://forum.freecadweb.org/viewtopic.php?style=4&amp;t=51069&amp;p=438881">Sverchok nodes</a> that use FreeCAD internally, literally creating a kind of new interface for FreeCAD withing Blender.</p>
<h3>Detect and suggest development version</h3>
<p>The BIM workbench will now detect your FreeCAD version on the setup screen, and suggest you to install a development version if you are not using one. This will help people to be aware of the existence of development versions, and become more used to them and how to install and mange them.</p>
<h3>Grid extension setting in Working Plane panel</h3>
<p>The overall size of the grid is now settable directly from the <a href="https://wiki.freecadweb.org/Draft_SelectPlane">Working Plane</a> task panel.</p>
<h3>Multiple custom folders on start page</h3>
<p><img src="https://yorik.uncreated.net/images/2020/freecad-09-08.jpg" alt=""></p>
<p>The <a href="https://wiki.freecadweb.org/Start_Workbench">start page</a> can now show multiple custom folders. To achieve that, go to the start page preferences under menu <em>Edit -&gt; Preferences -&gt; Start</em> and instead of choosing one custom folder, type manually several folder paths, separated by ;;</p>
<p>For example: <code>/home/yorik;;/home/yorik/Examples;;/home/yorik/FreeCAD/Examples</code></p>
<h3>Image Plane scaling</h3>
<p><img src="https://yorik.uncreated.net/images/2020/freecad-09-09.jpg" alt=""></p>
<p>The <a href="https://wiki.freecadweb.org/Draft_Scale">Draft Scale</a> tool now support image planes created with the <a href="https://wiki.freecadweb.org/Image_Module">Image workbench</a>. So it is now easy to import reference images such as scanned floor plans, position them on a common reference point, and scale them to the desired size.</p>
<h3>Unit and Show Unit in Draft dimension preferences</h3>
<p>You can now set default value for these two settings under <em>Edit -&gt; Preferences -&gt; Draft -&gt; Dimensions and Texts</em>, that will affect all newly created dimensions.</p>
<h3>Manual upgrade</h3>
<p>And last but not least, I started upgrading the <a href="https://wiki.freecadweb.org/Manual">manual</a> to FreeCAD 0.19, and this time I intend well to produce a printed book with it. To be continued!</p>
<p>That's it for this month I guess, I promise to do everything I can to resume posting once per month!</p>
<p>Cheers</p>
<p>Yorik</p>
            
        </div>

                
            </div>


        
    
    </div></div>]]>
            </description>
            <link>https://yorik.uncreated.net/blog/2020-011-freecad-september</link>
            <guid isPermaLink="false">hacker-news-small-sites-24951311</guid>
            <pubDate>Sat, 31 Oct 2020 13:30:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Spectre Is Haunting Unicode]]>
            </title>
            <description>
<![CDATA[
Score 317 | Comments 126 (<a href="https://news.ycombinator.com/item?id=24951130">thread link</a>) | @polm23
<br/>
October 31, 2020 | https://www.dampfkraft.com/ghost-characters.html | <a href="https://web.archive.org/web/*/https://www.dampfkraft.com/ghost-characters.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In 1978 Japan's <a href="https://ja.wikipedia.org/wiki/%E7%B5%8C%E6%B8%88%E7%94%A3%E6%A5%AD%E7%9C%81">Ministry of Economy, Trade and
Industry</a>
established the encoding that would later be known as JIS X 0208, which still
serves as an important reference for all Japanese encodings. However, after the
JIS standard was released people noticed something strange - several of the
added characters had no obvious sources, and nobody could tell what they meant
or how they should be pronounced. Nobody was sure where they came from. These
are what came to be known as the ghost characters
(<a href="https://ja.wikipedia.org/wiki/%E5%B9%BD%E9%9C%8A%E6%96%87%E5%AD%97">幽霊文字</a>).</p>
<figure><a href="https://www.dampfkraft.com/by-id/a824aa10/ghostcanvas.jpg"><img src="https://www.dampfkraft.com/by-id/a824aa10/img/ghostcanvas.jpg.l.jpg"></a><figcaption>Be careful what you write. <a href="http://dl.ndl.go.jp/info:ndljp/pid/1312837">via the NDL</a>
</figcaption></figure>
<p>For a long time the ghost characters remained an unexplained and mostly
forgotten curiosity, but in 1997 an investigation was launched to discover
where they had come from.  While all characters in the JIS standard were
supposed to have a record of their sources, even when it existed it
wasn't very specific, typically just listing the document it was sourced from.</p>
<p>You'd think that listing the source would make tracking down the origins of the
characters easy, but it's important to clarify what counts as a "source" - one
of the more common sources for the ghost characters was the "Overview of
National Administrative Districts" (国土行政区画総覧), a comprehensive list of
place names in Japan. You might, as I initially did, imagine this to be a kind
of atlas, an oversize book with at most a few hundred pages. It turns out the
<a href="http://kokudo.or.jp/books/index.html">latest edition</a> is a seven volume set
with each volume having roughly nine hundred pages. Imagine tracking down a
single character without a page reference.</p>
<p>Despite the difficulty, the investigation into the ghost characters was
successful in discovering their origins - mostly. By interviewing the
catalogers involved in the creation of the standard, the investigators
established that some characters were inadvertently invented as mistakes in the
cataloging process. For example, 妛 was an error introduced while trying to
record "山 over 女". "山 over 女" occurs in the name of a particular place and
was thus suitable for inclusion in the JIS standard, but because they couldn't
print it as one character yet, 山 and 女 were printed separately, cut out, and
pasted onto a sheet of paper, and then copied. When reading the copy, the line
where the two little pieces of paper met looked like a stroke and was added to
the character by mistake. The original character
(<a href="https://ja.wiktionary.org/wiki/%F0%A1%9A%B4">𡚴</a>) was not added to JIS or
Unicode until much later and doesn't display on most sites for me.</p>
<figure><a href="https://www.dampfkraft.com/by-id/a824aa10/yuureimoji.png"><img src="https://www.dampfkraft.com/by-id/a824aa10/img/yuureimoji.png.l.png"></a><figcaption>The core ghost characters: 妛挧暃椦槞蟐袮閠駲墸壥彁
</figcaption></figure>
<p>In the end only one character had neither a clear source nor any historical
precedent: 彁. The most likely explanation is that it was created as a
misreading of the 彊 character, but no specific incident was uncovered.</p>
<p>Following the general adoption of the JIS standards these characters all made
their way into Unicode, which has its own <a href="https://ja.wikipedia.org/wiki/CJK%E7%B5%B1%E5%90%88%E6%BC%A2%E5%AD%97#%E5%B9%BD%E9%9C%8A%E6%BC%A2%E5%AD%97">separate set of ghost
characters</a>
introduced during CJK unification.</p>
<p>To sum up - in 1978 a series of small mistakes created some characters out of
nothing. The errors went undiscovered just long enough to be set in stone, and
now these ghosts are, at least in potential, a part of every computer on the
planet, lurking in the dark corners of character tables.</p>
<p>At this rate they'll presumably be with humanity forever. Ψ</p>
<p>References / related links:</p>
<ul>
<li><a href="https://www.wdic.org/w/WDIC/%E5%B9%BD%E9%9C%8A%E6%96%87%E5%AD%97">幽霊文字 ‐ 通信用語の基礎知識</a> - the most thorough online source, with citations from the 1997 investigation.</li>
<li><a href="http://www.asahi.com/special/kotoba/archive2015/moji/2011082400019.html">大正十二年の幽霊文字 - ことばマガジン：朝日新聞デジタル</a> - an example of 彁 mistakenly used in a digitized Taisho newspaper due to a faded printing of 彊.</li>
<li><a href="http://dic.nicovideo.jp/a/%E5%B9%BD%E9%9C%8A%E6%96%87%E5%AD%97">Nico Nico Douga's Wiki</a> treats each of them as the name of a youkai.</li>
<li><a href="http://www.xubing.com/cn/work/details/206?year=1991&amp;type=year#206">天书</a> or <a href="https://en.wikipedia.org/wiki/A_Book_from_the_Sky">A Book from the Sky</a>, a hand-printed book by Xu Bing using only made-up Chinese characters.</li>
</ul>
</div></div>]]>
            </description>
            <link>https://www.dampfkraft.com/ghost-characters.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24951130</guid>
            <pubDate>Sat, 31 Oct 2020 13:07:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Overcoming Writer's Block]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 34 (<a href="https://news.ycombinator.com/item?id=24950777">thread link</a>) | @thecodrr
<br/>
October 31, 2020 | https://blog.streetwriters.co/overcoming-writers-block/ | <a href="https://web.archive.org/web/*/https://blog.streetwriters.co/overcoming-writers-block/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><blockquote><p>Who is more to be pitied, a writer bound and gagged by policemen or one living in perfect freedom who has nothing more to say?</p><p><em><span data-preserver-spaces="true">― </span></em>Kurt Vonnegut</p></blockquote><p><span data-preserver-spaces="true">I remember June of 2015. I came back from University, sat down to write in my daily journal, and picked up my pen. I stared at the blank page with a sense of impending doom. Writer's block. It was here. For so long, I had evaded its dark clutches, but it had caught up to me. I knew one day it would.</span></p><p><span data-preserver-spaces="true">Writer's block. It is one of those things that writers dread the most. Something they cannot avoid.</span></p><h2><span data-preserver-spaces="true">What is Writer's Block?</span></h2><p><span data-preserver-spaces="true">Imagine the most delicious food cooked by the best chefs in town. Now imagine yourself sitting down to eat all that food but not being able to.</span></p><p><span data-preserver-spaces="true">For various reasons, the writer's block has been the most hated enemy among writers. You sit down to write but nothing comes out. You sit there staring at the blank page for hours, days, or even months. The right words, the right idea, the right passion always evades you. Welcome to writer's block.</span></p><h2><span data-preserver-spaces="true">How to Overcome Writer's Block?</span></h2><p><span data-preserver-spaces="true">I remember going to the gym, going to the park, and even going to a nearby swamp to watch little frogs jump around. Nothing worked. I came back to my room, picked up the pen, but still the same feeling of doom.</span></p><p><span data-preserver-spaces="true">I could not <em>bleed</em> as Hemingway said. My ink had dried. It seemed I would never be able to write. I had forgotten my language.</span></p><p><span data-preserver-spaces="true">Overcoming writer's block is providential. What may trigger the inspiration in your soul is unknown. All you can do is try.</span></p><h2><span data-preserver-spaces="true">Finding the Cause</span></h2><p><em><span data-preserver-spaces="true">Alright. Therapy time.</span></em></p><p><span data-preserver-spaces="true">Try answering these questions to yourself (or in the comments below):</span></p><ol><li><span data-preserver-spaces="true">Do I criticize myself too much? Do I see faults and imperfections in whatever I write?</span></li><li><span data-preserver-spaces="true">Am I comparing myself to other writers, envying their creativity?</span></li><li><span data-preserver-spaces="true">Am I afraid of criticism?</span></li><li><span data-preserver-spaces="true">Do I depend upon compliments and praise from others?&nbsp;</span></li><li><span data-preserver-spaces="true">Am I losing my desire to write? Am I tired, overworked, or demotivated?</span></li><li><span data-preserver-spaces="true">Am I waiting for the perfect story to come flashing down on me like a lightning bolt?</span></li></ol><p><span data-preserver-spaces="true">Do not be demotivated if your answers are yes. No one is perfect. The real question is, what can you do about it? You found the cause, but you still have no remedy.</span></p><p><span data-preserver-spaces="true">Here is a list of a few things I tried. Remember, though, what may trigger your inspiration depends on you.</span></p><h2><span data-preserver-spaces="true">1. Make a Routine</span></h2><p><span data-preserver-spaces="true">I slept at 4 AM, woke around noon. My lunch was my breakfast. I never set a fixed time for anything, much less writing. And one day, it stopped.</span></p><p><span data-preserver-spaces="true">Set a fixed time every day for writing. It will help you find focus. I found the morning to be the best time. If this works for you, you will look forward to the time you spend writing.</span></p><h2><span data-preserver-spaces="true">2. Write Imperfectly</span></h2><blockquote><p>There is no such thing as good writing, only good rewriting.</p><p><em><span data-preserver-spaces="true">― </span></em>Robert Graves</p></blockquote><p><span data-preserver-spaces="true">I imagine perfection to be a disease. When I am born imperfect, destined to make mistakes, how am I supposed to find perfection in writing? Nowadays, I pick my pen and let it do its work.</span></p><p><span data-preserver-spaces="true">Stop thinking about perfection. Just let everything flow. It may be a horrible piece, but you did it. Keep writing.</span></p><h2><span data-preserver-spaces="true">3. Do Something Else</span></h2><p><span data-preserver-spaces="true">If you are feeling stuck, demotivated, and finding writing to be a chore. It is time for a change.</span></p><p><span data-preserver-spaces="true">Monotony is the bane of creativity. Just leave everything, and find something else to do. You will find your creativity and passion renewed.</span></p><figure><img loading="lazy" data-pagespeed-lazy-src="https://blog.streetwriters.co/media/posts/24//L08116-13-lr-1-1.jpg" sizes="(max-width: 1200px) 100vw, 1200px" data-pagespeed-lazy-srcset="https://blog.streetwriters.co/media/posts/24//responsive/L08116-13-lr-1-1-xs.jpg 300w, https://blog.streetwriters.co/media/posts/24//responsive/L08116-13-lr-1-1-sm.jpg 480w, https://blog.streetwriters.co/media/posts/24//responsive/L08116-13-lr-1-1-md.jpg 768w, https://blog.streetwriters.co/media/posts/24//responsive/L08116-13-lr-1-1-xl.jpg 1200w, https://blog.streetwriters.co/media/posts/24//responsive/L08116-13-lr-1-1-xxl.jpg 1600w, https://blog.streetwriters.co/media/posts/24//responsive/L08116-13-lr-1-1-xxxl.jpg 2560w" alt="" width="1977" height="1533" src="https://blog.streetwriters.co/pagespeed_static/1.JiBnMqyl6S.gif" onload="pagespeed.lazyLoadImages.loadIfVisibleAndMaybeBeacon(this);" onerror="this.onerror=null;pagespeed.lazyLoadImages.loadIfVisibleAndMaybeBeacon(this);"><figcaption>A representation of writer's block by&nbsp;<a href="https://en.wikipedia.org/wiki/Leonid_Pasternak" title="Leonid Pasternak">Leonid Pasternak</a>&nbsp;(1862 – 1945)</figcaption></figure><h2><span data-preserver-spaces="true">4. Force Yourself to Write</span></h2><blockquote><p>The only cure for not being able to write is to write.</p><p>― Kaylin R. Boyd</p></blockquote><p><span data-preserver-spaces="true">Procrastination may be a reason you are not writing anything. Fix a time, ten, fifteen, or thirty minutes. And then write without pause.&nbsp;</span></p><p><span data-preserver-spaces="true">Forcing yourself may be difficult. For this, you can try&nbsp;</span><a target="_blank" href="https://callofwriting.com/" rel="noopener"><span data-preserver-spaces="true">the Call of Writing app</span></a><span data-preserver-spaces="true">:&nbsp;</span></p><ol><li><span data-preserver-spaces="true">You can fix the time or number of words in the app.</span></li><li><span data-preserver-spaces="true">It awards you a score whenever you complete a challenge.</span></li><li><span data-preserver-spaces="true">You can compete with other writers.&nbsp;</span></li></ol><h2><span data-preserver-spaces="true">5. Start Writing from the Middle of a Story</span></h2><p><span data-preserver-spaces="true">It is a daunting task to start a story. The beginnings are the most difficult. Try starting a story from a fight scene, or a dialogue. Beginning a story abruptly will create suspense, opening up a thousand possibilities. You will see your pen flow.</span></p><h2><span data-preserver-spaces="true">6. Write with a Pen</span></h2><p><span data-preserver-spaces="true">Having a pen in your hand will give you a sense of purpose. Pen, ink, and paper have been tools of writing for centuries. They have a history.</span></p><p><span data-preserver-spaces="true">I have written on paper and my phone. There is something novel about writing with a pen; in watching the words materialize in front of you.</span></p><p><span data-preserver-spaces="true">Nothing beats the feel of a pen dragging on paper.</span></p><h2><span data-preserver-spaces="true">7. Make an Outline</span></h2><p><span data-preserver-spaces="true">Writer's block in the middle of your story is the most demotivating experience ever. Your protagonist is in the middle of a fight, but you are stuck. His sword is raised in the air, poised to strike upon the antagonist, but you cannot find the words.</span></p><p><span data-preserver-spaces="true">It is time to outline your story. Take a birds-eye view of the entire plot. Highlight the critical points, and continue the story.</span></p><h2><span data-preserver-spaces="true">8. Write Something Else</span></h2><p><span data-preserver-spaces="true">I have about ten side projects going on simultaneously. Never do I find myself bored and demotivated. If one piece is not working out, I pick up another.</span></p><p><span data-preserver-spaces="true">If the story is boring you, try writing a new one. Come back to it after a week. You will find new inspiration to continue the story.</span></p><div><p><strong><a href="https://blog.streetwriters.co/top-short-story-ideas/">Top 25 Short Story Writing Ideas</a></strong></p><p>Sometimes you want to write a story. You have energy, motivation, the right frame of mind, but the right story idea or the right topic remains out of your reach. You get stuck in a state where you are throwing the net in your sub-consciousness and trying to catch the right fish, but the catch always eludes you. If you are stuck in such a cycle, you are not alone. The best way to overcome this condition is to r...</p><p><a href="https://blog.streetwriters.co/top-short-story-ideas/">Continue reading</a></p></div><h2><span data-preserver-spaces="true">9. You are too Conscious About Public Opinion</span></h2><p><span data-preserver-spaces="true">The first time I presented a poem of mine, I basked in the praise. I did not realize the problem until it had become a problem. I always sought others' approval for my ideas before I published any piece.</span></p><p><span data-preserver-spaces="true">Pause. Breathe. Bring into focus your purpose for writing. Is it for yourself or others? Are you going to let others dictate your creativity?</span></p><p><span data-preserver-spaces="true">You have incomparable potential waiting for your pen to move. Forget others. Forget the audience. Focus on how you want your story to be.&nbsp;</span><em><span data-preserver-spaces="true">Write.</span></em></p><h2><span data-preserver-spaces="true">10. Move away from Distractions</span></h2><p><span data-preserver-spaces="true">Your mind is your biggest enemy. You find it wandering. You bring it back only for it to get lost again. It is the most stubborn organ in humans.</span></p><p><span data-preserver-spaces="true">Find a distraction-free place, and sit down. Close your eyes, and try to focus on what you have to write. What is your idea? Concentrate.</span></p><p><em><span data-preserver-spaces="true">Write.</span></em></p><h2><span data-preserver-spaces="true">11. Start Keeping Notes</span></h2><p><span data-preserver-spaces="true">Driving, walking, eating, in the bathroom, or at a party; ideas can come anywhere. When they arrive, jot them down.</span></p><p><span data-preserver-spaces="true">Your story will be born at the most unexpected time. You do not want to be without a pen at that moment.</span></p><h2><span data-preserver-spaces="true">Conclusion</span></h2><p><span data-preserver-spaces="true">If you cannot write today, do not be discouraged. Your time will come. Do not give up. Words not flowing today will flow tomorrow.</span></p><p>If you have already tried all of the above, you can check these resources for further help:</p><p>1. <a href="https://blog.bookbaby.com/2016/04/21-tips-to-beat-writers-block/">21 Tips to Beat Writer's Block (Has a really cool infographic)</a><br>2. <a href="https://www.writingroutines.com/overcome-writers-block/">What Great Writers Do About Writer's Block</a></p></div></div>]]>
            </description>
            <link>https://blog.streetwriters.co/overcoming-writers-block/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24950777</guid>
            <pubDate>Sat, 31 Oct 2020 12:13:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Extreme Debugging]]>
            </title>
            <description>
<![CDATA[
Score 164 | Comments 45 (<a href="https://news.ycombinator.com/item?id=24950120">thread link</a>) | @merlinscholz
<br/>
October 31, 2020 | https://squanderingti.me/blog/2020/10/28/extreme-debugging.html | <a href="https://web.archive.org/web/*/https://squanderingti.me/blog/2020/10/28/extreme-debugging.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    



    <div role="main">
      <div>
        




<article>
  <p>There’s debugging and there’s <em>debugging</em>.
This is a story of the latter.
Before we get into this jaunt I’d like to add that I’ve written this piece to mimic how we actually got to the conclusion.
If you’re experienced in strange stuff you might see a faster route or use a different tool.
There’s more than one way to do most of this and this was what I had at hand when I needed it.</p>

<h2 id="all-stories-start-somewhere">All stories start somewhere</h2>

<p>Some background first.
I’m currently working in a bioinformatics lab that works on the functional identification of proteins.
One of our projects requires that we benchmark against an older tool that performs a similar function.
I’m not going to throw the particular tool under the bus, but needless to say, it’s charming in a way that only academic software can be.</p>

<ul>
  <li>Documentation ranges from “poor” to “nonexistent.”</li>
  <li>It’s held together with an unholy amalgamation of Perl, awk, tsch, and yes, <strong>Fortran</strong>.</li>
  <li>It includes/distributes binaries to other programs that the internet has <em>forgotten</em>.</li>
  <li>Some of the copyright headers are from when I was in elementary school- others before even that.</li>
</ul>

<p>So… “charming.”
A web-based version is available but is limited to how many proteins you can submit (via cgi-bin!) within a 24 hour window (it’s a low number- say ~100) and we need to process well over 100k.
So the naive, innocent question that started this was:</p>

<blockquote>
  <p>“Well, can we run it locally?”</p>
</blockquote>

<p>After all, all the pieces are available for download so it would seem simple enough, right?
You can probably already surmise the answer since you’re reading an article called “extreme debugging.”</p>

<p>I’m going to focus on a small pieces of a much larger puzzle called <code>netNGlyc</code>.
This handy, dandy little program is used to predict <a href="https://en.wikipedia.org/wiki/N-linked_glycosylation">N-glycosylation</a> sites in proteins.
It’s distributed as a tarball.
Easy enough!</p>

<p>We can unpack it, and then perform setup by editing its main file <code>netNglyc</code> (written in <code>tsch</code>) by specifying the path to the unpacked dir.
Easy peazy.
And then we run the quick test and…</p>

<p><img src="https://squanderingti.me/img/nGlyc/seg_faults.gif" alt="">
<em>All the segfaults</em></p>

<h2 id="what-process-is-actually-segfaulting">What process is actually segfaulting?</h2>
<p>The entry point into this program is a <code>tsch</code> script that calls numerous additional <code>awk</code> and <code>tsch</code> files.
We have a few options we can try.</p>

<p>If kernel logging is enabled, then <code>dmesg</code> logs might include the offender like the following.</p>

<div><div><pre><code>[30590535.213144] how98_Linux[1560171]: segfault at 8000000 ip 00000000080744f7 sp 00000000ffb8a114 error 4 in how98_Linux[8048000+5a000]
</code></pre></div></div>

<p>A second option, assuming <code>dmesg</code> doesn’t include this or doesn’t help, is to use <code>strace</code>.
If you don’t have much experience with <code>strace</code> and you work on Linux frequently, it’s very much worth your while to learn this tool.
We’re going to use it with <code>-f</code> for “follow process forking” so we can see everything that ends up being called.
We’re also invoking it with <code>-o</code> so we can write the output to a file and go through it.</p>

<div><div><pre><code>strace -f -o /tmp/debugging ./netNglyc test/LEUK_RAT.fsa
</code></pre></div></div>

<p>And then look through the output:</p>

<div><div><pre><code>grep SIGSEGV /tmp/debugging
</code></pre></div></div>

<p>Looking for <code>SIGSEGV</code> will show us everywhere a segfault signal was handled.
We’ll hopefully see lines like the following, where the left-most integer is the PID of the process.</p>

<div><div><pre><code>1560785 +++ killed by SIGSEGV (core dumped) +++
</code></pre></div></div>

<p>Now we can grep for both the PID and the <code>execve</code> syscall<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> to see what program was launched.</p>

<div><div><pre><code>grep 1560785 /tmp/debugging | grep exec
</code></pre></div></div>

<p>Lo and behold:</p>

<div><div><pre><code>1560785 execve("/mnt/home/cchandler/ceph/Programs/netNglyc-1.0-broken/how/how98_Linux", ["/mnt/home/cchandler/ceph/Program"...], [/* 89 vars */]) = 0
</code></pre></div></div>

<h2 id="exploring-the-target">Exploring the target</h2>

<p>We have our culprit.
It’s whatever <code>how98_Linux</code> is.
First question: what exactly is it?</p>

<div><div><pre><code>$ file how98_Linux
how98_Linux: ELF 32-bit LSB executable, Intel 80386, version 1 (SYSV), statically linked, for GNU/Linux 2.0.0, stripped
</code></pre></div></div>

<p>Oh.
So the thing crashing is an <em>old</em> statically linked binary that’s been fully stripped<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>.</p>

<p>A quick run of <code>nm</code> will confirm the awful truth and yield the same result.</p>

<div><div><pre><code>$nm how98_Linux
nm: how98_Linux: no symbols
</code></pre></div></div>

<p>So let’s quickly recap what we learned:</p>

<ol>
  <li>We have a 32-bit ELF binary</li>
  <li>Statically linked with glibc</li>
  <li>Against Linux ABI 2.0.0 (for the record: that’s from 1996)</li>
  <li>And it has no symbol table</li>
</ol>

<h2 id="maybe-recreate-its-input">Maybe recreate its input?</h2>

<p>The question at hand is now: is there something wrong with this ancient program, or is there something wrong with our environment?
After all, it’s been in use for years and years (right??).
Inspecting the binary is going to take some effort, so maybe the best approach is to make sure that the input files are correct.
Previously, we’ve run into problems with other programs like this thanks to subtle differences between shells or between <code>gawk</code> vs <code>awk</code> etc.</p>

<p>From the <code>strace</code> output for <code>exec</code> we can see the program didn’t actually take any arguments.
Right after the name of the program there’re square brackets indicating the arguments.
If I make up an argument like “asdf” and pass it to the program you can see it.</p>

<div><div><pre><code>$strace -f -eexecve ~/ceph/Programs/netNglyc-1.0-broken/how/how98_Linux asdf

execve("/mnt/home/cchandler/ceph/Programs/netNglyc-1.0-broken/how/how98_Linux", ["/mnt/home/cchandler/ceph/Program"..., "asdf"], [/* 65 vars */]) = 0
</code></pre></div></div>

<p>It would be a fairly logical deduction to say that it must be reading from <code>stdin</code>.
Indeed, the <code>strace</code> output contains a <code>read(0)</code>.</p>

<div><div><pre><code>1560785 read(0,  &lt;unfinished ...&gt;
1560785 &lt;... read resumed&gt; "********************************"..., 4096) = 4096
</code></pre></div></div>

<p>On Linux, file descriptor 0 is always <code>stdin</code><sup id="fnref:5" role="doc-noteref"><a href="#fn:5">3</a></sup>.
It’s starting to look like we’re not going to get out of digging through all the <code>tsch</code> and <code>awk</code>.
Secondly, that line of stars “*****” is actually a preview of the what the process read, and we can find a matching call above to <code>write</code>.</p>

<div><div><pre><code>1560675 write(1, "********************************"..., 4096 &lt;unfinished ...&gt;
</code></pre></div></div>

<p>Yup. Here we have the file descriptor 1 which is always <code>stdout</code>.</p>

<p>Everything is being redirected via pipes.
Unfortunately, reconstructing the movement of data through pipes is extremely non-trivial.
<em>Somewhere</em> in the <code>strace</code> output we’re going to find some calls to <code>open()</code> which will reveal the paths to the specific files we’re looking for.
Double unfortunately, if they’re interleaved with <code>chdir</code> calls we might only have relative paths.
There’s also the problem of just a <strong>ton</strong> of data.
A quick run of <code>strace</code> tracking only <code>open()</code> calls yields thousands of results.</p>

<div><div><pre><code>strace -f -eopen -o /tmp/opens ./netNglyc test/LEUK_RAT.fsa
*output omitted*

wc -l /tmp/opens
5489 /tmp/opens
</code></pre></div></div>

<p>Ugh.
Even if we filter out all the <code>open</code> calls to library files we’re still left with north of 2k results.
An alternate approach might be needed.</p>

<h2 id="a-break--a-very-surprising-twist">A break &amp; a very surprising twist</h2>

<p>Break time.</p>

<p>Time to switch gears and deal with a few other things.
How about making a copy of <code>netNGlyc</code> in my home directory so I can do some more analysis later.
Let’s give it a run to make sure the error is reproducible.</p>

<p><img src="https://squanderingti.me/img/nGlyc/working.gif" alt="">
<em>Excuse me?</em></p>

<p><em>Of course</em> it ran correctly.
No segfaults. No goofy messages.</p>

<p>Somehow, copying the files to my home directory fixes everything.
No permissions were modified in the process.
The only difference between the working copy and broken copy are which filesystem they’re running on<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">4</a></sup>.
It’s suddenly starting to appear that this segfault is somehow filesystem related.</p>

<p>But that’s nonsense.
What could it possibly be doing that would interfere with the underlying filesystem?</p>

<h2 id="sleep--the-inputs-at-last">Sleep &amp; the inputs at last</h2>

<p>The next morning.</p>

<p>Part of the problem with locating the errant inputs is that the <code>netNGlyc</code> script cleans up after itself.
It’s doing this via <code>rm -rf</code> on its temp directory.
Commenting that out we now have a <code>tmp</code> directory full of subdirectories.
We can combine our sequence of asterisks from the <code>strace</code> output with <code>grep</code> to finally locate the files in question.</p>

<div><div><pre><code>$ grep -H '^\*\*\*\*' * | sort | uniq
how.test.dat:**************************************************************************
tmp.dat.1576058:**************************************************************************
tmp.dat.1576071:**************************************************************************
tmp.dat.1576086:**************************************************************************
tmp.dat.1576098:**************************************************************************
tmp.dat.1576110:**************************************************************************
tmp.dat.1576153:**************************************************************************
tmp.dat.1576192:**************************************************************************
tmp.dat.1576235:**************************************************************************
tmp.dat.1576258:**************************************************************************
</code></pre></div></div>

<p>The input files are all named something like <code>tmp.dat.123456</code>.
The trailing number in the filename (<code>-H</code> to <code>grep</code>) is likely the PID of the process that originally created it.</p>

<p>Let’s pipe one of these files to our friend <code>how98_Linux</code>.</p>
<div><div><pre><code>$ ../../how/how98_Linux &lt; tmp.dat.1576192
open: can't stat file
apparent state: unit 3 named test.how
lately reading sequential formatted external IO
Segmentation fault (core dumped)
</code></pre></div></div>

<p>Fantastic! We finally have a small chunk of iterable work that we can play with.
The copy in my home directory works the same way, except of course that it outputs the correct result.</p>

<h2 id="a-hammer-named-gdb">A hammer named GDB</h2>

<p>Maybe there’s <em>something</em> we can learn from this binary.
Every time in my career that I’ve had to reach for <code>strace</code> and <code>gdb</code> to fix third-party code it has been a tale of woe.</p>

<p>This case is probably no different.</p>

<p>Remember that stripped symbol table?
Normally we could run <code>where</code> inside <code>gdb</code> and it would return all the frames on the stack.</p>

<div><div><pre><code>(gdb) run &lt; tmp.dat.1576058
Starting program: /mnt/ceph/users/cchandler/Programs/netNglyc-1.0-broken/tmp/netNglyc-1576032/../../how/how98_Linux &lt; tmp.dat.1576058
open: can't stat file
apparent state: unit 3 named test.how
lately reading sequential formatted external IO

Program received signal SIGSEGV, Segmentation fault.
0x080744f7 in ?? ()
(gdb) where
#0  0x080744f7 in ?? ()
#1  …</code></pre></div></div></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://squanderingti.me/blog/2020/10/28/extreme-debugging.html">https://squanderingti.me/blog/2020/10/28/extreme-debugging.html</a></em></p>]]>
            </description>
            <link>https://squanderingti.me/blog/2020/10/28/extreme-debugging.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24950120</guid>
            <pubDate>Sat, 31 Oct 2020 09:49:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Complexity in Operating Systems]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 17 (<a href="https://news.ycombinator.com/item?id=24949983">thread link</a>) | @quyleanh
<br/>
October 31, 2020 | https://x86.lol/generic/2020/10/30/complexity-in-operating-systems.html | <a href="https://web.archive.org/web/*/https://x86.lol/generic/2020/10/30/complexity-in-operating-systems.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Over the last years I’ve been working on very different operating
systems. Operating systems are usually incredibly complex beasts. I
think there are mainly three drivers of this complexity. Surprisingly
enough, neither of these is having to deal with hardware.</p>

<p>The first one is resource <strong>discovery</strong>, i.e. figuring out how the
computer the OS is running on actually looks like. On x86, this
involves parsing countless bitfields, tables, executing byte code
provided by the firmware, probing individual features, etc. The most
painful example of this I’ve seen so far is figuring out which
interrupt a particular PCI interrupt line is routed to. It’s worth a
set of posts, but until then, feel free to checkout <a href="https://habr.com/en/post/501912/">this
description</a>. (If it’s down, it’s
also cached by
<a href="https://webcache.googleusercontent.com/search?q=cache:CXZUV61m7hwJ:https://habr.com/en/post/501912/+&amp;cd=1&amp;hl=en&amp;ct=clnk">Google</a>.)</p>

<p>The second issue is <strong>resource management</strong>. Essentially, how do you
hand out and eventually reclaim all the resources you discovered. For
some workloads performance matters here, so this code is usually
written with speed in mind.</p>

<p>The third reason is that at compile time the <strong>workload</strong> is
unclear. So the kernel has to assume the worst. It must be ready to
start a couple of hundred VMs or create a thousand TCP sockets in a
blink of an eye, because there is no way to know what’s going to
happen or what the actual requirements are.</p>

<p>A fun exercise is to checkout the <a href="https://elixir.bootlin.com/linux/v5.9.1/source/virt/kvm/kvm_main.c#L739">KVM code for creating
VMs</a>. Try
to follow
<a href="https://elixir.bootlin.com/linux/v5.9.1/source/arch/x86/kvm/x86.c#L9904">the</a>
<a href="https://elixir.bootlin.com/linux/v5.9.1/source/arch/x86/kvm/vmx/vmx.c#L7059">code</a>
to where the actual VM is created in hardware. <em>Spoiler:</em> There is
none. It’s all figuring out what the platform can do and then setting
up a bunch of spinlock, mutexes, lists, arrays, structs, …</p>

<p>I don’t want to pick on KVM in particular. I think it’s pretty ok as
far as Linux kernel code goes. Operating System kernel code is mostly
like this: A lot of really mind numbing platform discovery and
resource management code written for speed assuming the worst case
requirements in a language that doesn’t do parsing, resource
management or concurrency well (among other things).</p>

<p>People take this all for granted. But when I look around, I see many
systems that don’t need this complexity and where it is only a safety
and security burden. Consider most appliance-type products, e.g. a
Wi-Fi router. Or a system that runs one service on a cloud VM. You
know everything in advance!</p>

<p>If you read until this point, you are probably asking yourself, where
I am going with this. If you think <a href="https://en.wikipedia.org/wiki/Separation_kernel">separation
kernel</a>, you are
right. My rough plan to write a couple of more posts to flesh out the
idea of doing all the complicated OS parts at compile time and how
this results in an incredibly simple, secure, and efficient system at
runtime. There will be <a href="https://riscv.org/">RISC-V</a>,
<a href="https://www.haskell.org/">Haskell</a>, <a href="https://dhall-lang.org/">Dhall</a>,
and <a href="https://www.rust-lang.org/">Rust</a> content.</p>

<p>Stay tuned.</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://x86.lol/generic/2020/10/30/complexity-in-operating-systems.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24949983</guid>
            <pubDate>Sat, 31 Oct 2020 09:06:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reproducible Machine Learning in production]]>
            </title>
            <description>
<![CDATA[
Score 78 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24949736">thread link</a>) | @benkoller
<br/>
October 31, 2020 | https://blog.maiot.io/12-factors-of-ml-in-production/ | <a href="https://web.archive.org/web/*/https://blog.maiot.io/12-factors-of-ml-in-production/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="post-content">
    <div id="blogpost">
        <p>The last two decades have yielded us some great understandings about Software Development. A big part of that is due to the emergence of DevOps and itâ€™s wide adoption throughout the industry.</p>

<p>Leading software companies follow identical patterns: Fast iterations in software development followed by Continuous Integration, Continuous Delivery, Continuous Deployment. Every artefact is tested on its ability to provide value, always has a state of readiness and is deployed through automation.</p>

<p>As a field, Machine Learning differs from traditional software development, but we can still borrow many learnings and adapt them to â€œourâ€� industry. For the last few years, weâ€™ve been doing Machine Learning projects in production, so beyond proof-of-concepts, and our goals where the same is in software development: reproducibility. So we built a pipeline orchestrator, strong automations and established a workflow to achieve exactly that.</p>

<p>Why not just Jupyter Notebooks? Well, how long does it take to construct a Notebook from scratch, with all processing steps, from scratch? And how easy is it to onboard new members to the team? Can you reproduce the results youâ€™ve had two months ago, now, fast? Can you compare todayâ€™s results against historic oneâ€™s? Can you give provenance over your data throughout training? And what happens if your model goes stale?</p>

<p>Weâ€™ve faced all of these issues, and more, and now took our experience to deduce 12 factors (as a nod to the <a href="https://12factor.net/">12 factor app</a>) that build the backbone of successful ML in production.</p>

<h2 id="1-versioning">1. Versioning</h2>

<p>While obvious to basically all Software Engineers, version control is not an universally accepted methodology among Data Scientists. Let me quote the folks at Gitlab as a quick primer:</p>

<blockquote>
  <p>Version control facilitates coordination, sharing, and collaboration across the entire software development team. Version control software enables teams to work in distributed and asynchronous environments, manage changes and versions of code and artifacts, and resolve merge conflicts and related anomalies.</p>
</blockquote>

<p>In short, versioning lets you safely manage the moving parts of Software Development.</p>

<p>As a special form of Software Development, Machine Learning has unique requirements. First, it has not one but two moving parts: Code and Data. Second, model trainings happen in (fast) iterations and introduce a high variance of code (e.g. splitting, preprocessing, models).</p>

<p>As soon as data can be subject to change it needs to be versioned to be able to reproducibly and repeatably conduct experiments and train models. Cruder forms of versioning (read: hard-copies) can go a long way, but especially in team scenarios shared, immutable version control becomes critical.</p>

<p>Version control of code is even more key. In addition to aboveâ€™s quote, preprocessing code is not just relevant at training but also at serving time and needs to be immutably correlatable with models. Serverless functions can provide an easy-access way to achieve a middle ground between the workflow of Data Scientists and production-ready requirements.</p>

<p><strong>TL;DR:</strong> You need to version your code, and you need to version your data.</p>

<h2 id="2-explicit-feature-dependencies">2. Explicit feature dependencies</h2>

<p>In a perfect world, whatever produces your input data will forever produce exactly the same data, at least structurally. But the world is not perfect, youâ€™re consuming data from an upstream service thatâ€™s built by humans and might be subject to change. Features will change, eventually. At best, your models fail outright, but at worst theyâ€™ll just silently start to produce garbage results.</p>

<p>Explicitly defined feature dependencies allow for transparent failure as early as possible. Well-designed systems will accommodate feature dependencies both in continuous training as well as at serving time.</p>

<p><strong>TL;DR:</strong> Make your feature dependencies explicit in your code.</p>

<h2 id="3-descriptive-training-and-preprocessing">3. Descriptive training and preprocessing</h2>

<p>Good software is descriptive - it can be read and understood easily without reading every line of code.</p>

<p>And while Machine Learning is a unique flavor of Software Development it doesnâ€™t exempt practitioners from following established coding guidelines. Basic understanding of coding standard essentials can be picked up with very little effort and in a short amount of time.</p>

<p>Code for both preprocessing and models should follow <a href="https://www.python.org/dev/peps/pep-0008/">PEP8</a>. It should consist of meaningful object names and contain helpful comments. Following PEP8 will improve code legibility, reduce complexity and speed up debugging. Programming paradigms such as <a href="https://en.wikipedia.org/wiki/SOLID">SOLID</a> provide thought frameworks to make code more maintainable, understandable and flexible for future use cases.</p>

<p>Configuration should be separated from code. Donâ€™t hardcode your split ratios, provide them at runtime through configuration. As known from hyperparameter tuning, a well-separated configuration increases speed of iterations significantly and makes codebases reusable.</p>

<p><strong>TL;DR:</strong> Write readable code and separate code from configuration.</p>

<h2 id="4-reproducibility-of-trainings">4. Reproducibility of trainings</h2>

<p>If you canâ€™t reproduce training results you canâ€™t trust the results. While this is somewhat the overarching theme of this blogpost, there are nuances to reproducibility. Not just do you need to be able to reproduce a training yourself, the entire team should be able to do so. Obscuring trainings in Jupyter Notebooks on someones PC or on some VM on AWS is the literal inverse of a reproducible training.</p>

<p>By using pipelines to train models entire teams gain both access and transparency over conducted experiments and training runs. Bundled with a reusable codebase and a separation from configuration, everyone can successfully relaunch any training at any point in time.</p>

<p><strong>TL;DR:</strong> Use pipelines and automation.</p>

<h2 id="5-testing">5. Testing</h2>

<p>Testing comes in many shapes and forms. To give two examples:</p>

<ul>
  <li><a href="https://en.wikipedia.org/wiki/Unit_testing">Unit testing</a> is testing on an atomic level - every function is tested individually on itâ€™s own specific criteria.</li>
  <li><a href="https://en.wikipedia.org/wiki/Integration_testing">Integration testing</a> is taking an inverse approach - all elements of a codebase are tested as a group, in conjunction and with clones/mocks of up- and downstream services.</li>
</ul>

<p>Both paradigms are good starting points for Machine Learning. Preprocessing code is predestined for unit testing - do transforms yield the right results given various inputs? Models are a great use case for integration tests - does your model produce comparable results to evaluation at serving time in a production environment?</p>

<p><strong>TL;DR:</strong> Test your code, test your models.</p>

<h2 id="6-drift--continuous-training">6. Drift / Continuous training</h2>

<p>Drift is a legit problem for production scenarios. You need to account for drift as soon as there is even a slight possibility that data might change (e.g. user input, upstream service volatility). Two measures can mitigate risk exposure:</p>

<ul>
  <li>Data monitoring for production systems. Establish automated reporting mechanisms to alert teams of changing data, even beyond explicitly defined feature dependencies.</li>
  <li>Continuous training on newly incoming data. Well-automated pipelines can be rerun on newly recorded data and offer comparability to historic training results to show performance degradation as well as offer a quick way to promote newly trained models into production, given better model performance.</li>
</ul>

<p><strong>TL;DR:</strong> If you data can change run a continuous training pipeline.</p>

<h2 id="7-tracking-of-results">7. Tracking of results</h2>

<p>Excel is not a good way to track experiment results. And not just Excel, any decentralized, manual form of tracking will yield non-authoritative and therefore untrustworthy information.</p>

<p>The right approach are automated methods to record training results in a centralized data store. Automation ensures the reliable tracking of every training run, and allows for a later comparability of training runs against each other. Centralized storage of results give transparency across teams and allows for continuous analysis.</p>

<p><strong>TL;DR:</strong> Track results via automation.</p>

<h2 id="8-experimentation-vs-production-models">8. Experimentation vs Production models</h2>

<p>Understanding datasets requires effort. Commonly, this understanding is gathered through experimentation, especially when operating in fields with a lot of hidden domain knowledge. Start a Jupyter Notebook, get some/all of the data into a Pandas Dataframe, do some hours of out-of-sequence magic, train a first model, evaluate results - Job done. Well, unfortunately not.</p>

<p>Experiments serve a purpose in the lifecycle of Machine Learning. The results of these Experiments are however not models, but understanding. Models from explorative Jupyter Notebooks are proof for understanding, not production-ready artefacts. Gained understanding will need more molding and fitting into production-ready training pipelines.</p>

<p>All understandings unrelated to domain-specific knowledge can however be automated. Generate statistics on each data version youâ€™re using to skip any one-time, ad-hoc exploratory work you might have had to do in Jupyter Notebooks, and move straight to the first pipelines. The earlier you experiment in pipelines, the earlier you can collaborate on intermediate results and the earlier youâ€™ll receive production-ready models.</p>

<p><strong>TL;DR:</strong> Notebooks are not production-ready, so experiment in pipelines early on.</p>

<h2 id="9-training-serving-skew">9. Training-Serving-Skew</h2>

<p>The avoidance of skewed training and serving environments is often reduced to correctly embedding all data preprocessing into the model serving environments. This is absolutely correct, and you need to adhere to this rule. However, it is also a too narrow interpretation of Training-Serving-Skew.</p>

<p>A little detour to ancient DevOps history: In 2006 the CTO of Amazon, Werner Vogels, coined the term â€œYou build it, you run itâ€�. Itâ€™s a descriptive phrase for extending the responsibility of Developers to not only writing but also running the software they build.</p>

<p>A similar dynamic is required for Machine Learning projects - an understanding of both the upstream generation of data and the downstream usage of generated Models is within the responsibility of Data Scientists. What system generates your data for …</p></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.maiot.io/12-factors-of-ml-in-production/">https://blog.maiot.io/12-factors-of-ml-in-production/</a></em></p>]]>
            </description>
            <link>https://blog.maiot.io/12-factors-of-ml-in-production/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24949736</guid>
            <pubDate>Sat, 31 Oct 2020 07:38:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[LIL: Little Interpreted Language]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24949515">thread link</a>) | @marttt
<br/>
October 30, 2020 | http://runtimeterror.com/tech/lil/ | <a href="https://web.archive.org/web/*/http://runtimeterror.com/tech/lil/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">



<p><b>LIL</b> (stands for <b>L</b>ittle <b>I</b>nterpreted <b>L</b>anguage)
is a small highly dynamic scripting language inspired by Tcl and
unix shells. LIL has two implementations, one written in <b>C</b>,
which consists of a pair of <tt>.c</tt> and <tt>.h</tt> files
and one in <b><a href="http://freepascal.org/">Free Pascal</a></b>,
which consists of a single <tt>pas</tt> file (a unit). Also a
<a href="http://lazarus-ide.org/">Lazarus</a> package for the
latter is provided.</p>

<h2>Contents</h2>

<menu>
  <li><a href="#downloads">Downloads</a>
  <menu>
    <li><a href="#latestversion">Latest version</a>
    </li><li><a href="#olderversions">Older versions</a>
    </li><li><a href="#winlil">WinLIL</a>
    </li><li><a href="#lilgui">LILGUI</a>
  </li></menu>
  </li><li><a href="#stability">API stability and compatibility</a>
  </li><li><a href="#documentation">Documentation</a>
  </li><li><a href="#status">Status</a>
  </li><li><a href="#license">License</a>
</li></menu>

<h2><a name="downloads"></a>Downloads</h2>

<p>LIL is currently available as source code snapshots of both
the C and the Free Pascal version combined in a single ZIP file.
These snapshots are versioned using their release date. Note that
the interpreter's reflect version command will report <i>0.1</i>
regardless of date versioning. Both of these will change at some
point in the future to provide proper versioned releases.</p>

<h3><a name="latestversion"></a>Latest version</h3>

<p>The latest version of LIL is <a href="http://runtimeterror.com/tech/lil/lil20190821.zip">lil20190821.zip</a>
(159KB). This is an extract from my private Fossil repository
(the files are mostly the same as the older archives, but this
also includes a full changelog from the repository going back
to 2010 and the LIL logo as an XCF image which can be opened with
GIMP).</p>

<p>Please note that <b>20190821</b> contains slightly altered
behavior for line breaking during list parsing that <i>could</i>
affect some scripts, especially with lists that contain code inside
square brackets, however the previous behavior was completely
broken (e.g. having multiple commands inside brackets in a list
would merge all commands into a single one and if a semicolon
was used for the multiple commands, the entire command wouldn't
be parsed properly). Because of that i expect any reliance on
the previous behavior to be accidental (and in practice i do not
really expect any such script to even exist). Also in the same
version a Bash script is introduced to check the differences between
different executables by running the same scripts under both and
comparing the results, which show that FPLIL contains a few incompatibilities
with C LIL. At this moment FPLIL doesn't implement the changes
mentioned so far - all these incompatibilities and changes will
be fixed in a later release.</p>

<h3><a name="olderversions"></a>Older versions</h3>

<p>Some older versions are also available in case you need them.
LIL should be mostly backwards compatible (see below), but right
now there is no promise for strict API or ABI compatibility.</p>

<ul>
  <li><a href="http://runtimeterror.com/tech/lil/lil20190819.zip">lil20190819.zip</a> (155KB)<a href="http://runtimeterror.com/tech/lil/lil20190818.zip"></a>
  </li><li><a href="http://runtimeterror.com/tech/lil/lil20190818.zip">lil20190818.zip</a> (154KB)
  </li><li><a href="http://runtimeterror.com/tech/lil/lil20190114.zip">lil20190114.zip</a> (91KB)
  </li><li><a href="http://runtimeterror.com/tech/lil/lil20161129.zip">lil20161129.zip</a> (88KB)
  </li><li><a href="http://runtimeterror.com/tech/lil/lil20160812.zip">lil20160812.zip</a> (88KB)
  </li><li><a href="http://runtimeterror.com/tech/lil/lil20160603.zip">lil20160603.zip</a> (88KB)
</li></ul>

<h3><a name="winlil"></a>WinLIL</h3>

<p>If you are using Windows you can also download <b>WinLIL</b>,
a small Windows-based environment with editor, console and extra
graphics functions that can be used to experiment with LIL. It
is self-contained in a single executable, including the LIL documentation.</p>

<p>The latest version is <a href="http://runtimeterror.com/tech/lil/winlil14.zip">WinLIL 1.4</a>
(204KB) based on <i>C LIL 20190821</i>. <a href="http://runtimeterror.com/tech/lil/winlil.png">Here
is a screenshot</a> of it in action. Also a small doodle program
can be <a href="http://runtimeterror.com/tech/lil/doodle.lil">downloaded here</a> and a <a href="http://runtimeterror.com/tech/lil/doodle.gif">screenshot
seen here</a>. <a href="http://runtimeterror.com/tech/lil/winlil20190821231511.zip">This archive</a>
(45KB) contains the source code, but note that it uses the original
Borland C++ Builder and to compile with a newer version (such
as the free Community Edition) you'll need to recreate the project
file and make a few modifications to the code.</p>

<p>Older versions of WinLIL can be found in these files: <a href="http://runtimeterror.com/tech/lil/winlil13.zip">winlil13.zip</a>
(1.3 binary), <a href="http://runtimeterror.com/tech/lil/winlil20190524200539.zip">winlil20190524200539.zip</a>
(1.3 source), <a href="http://runtimeterror.com/tech/lil/winlil20170425.zip">winlil20170424.zip</a>
(binary), <a href="http://runtimeterror.com/tech/lil/winlilsrc20161220.7z">winlilsrc20161220.7z</a>
(source).</p>

<h3><a name="lilgui"></a>LILGUI</h3>

<p><b>LILGUI</b> is an experimental API specification for GUI
applications that provide scripting functionality through LIL
to expose a simple GUI API. It is mainly intended for creating
embeddable GUIs (e.g. a panel in a sidebar) although it can also
be used for popup windows and dialogs. Currently the only implementation
for LILGUI is <b>LazLILGUI</b>, which is a component for Lazarus
that uses LCL to provide the actual GUI functionality.</p>

<p>The latest version of LILGUI files (which include the API spec,
LazLILGUI and a couple of examples) can be <a href="http://runtimeterror.com/tech/lil/lilgui20190708215135.zip">downloaded
here</a> (85KB). A 64bit windows binary for <b>LazLILGUI Notepad</b>,
a text editor that provides a sidebar to try out LILGUI code,
can be <a href="http://runtimeterror.com/tech/lil/llgnotepad20190708.zip">downloaded here</a> (1.3MB).
Also you can see the screenshots of program in action under <a href="http://runtimeterror.com/tech/lil/llgnotepadwin.png">Windows</a>, <a href="http://runtimeterror.com/tech/lil/llgnotepadlin.png">Linux</a>
and <a href="http://runtimeterror.com/tech/lil/llgnotepadosx.png">Mac OS X</a> and also the <a href="http://runtimeterror.com/tech/lil/llgcce.png">Custom Control Example</a> under Windows.</p>

<h2><a name="stability"></a>API stability and compatibility</h2>

<p>Generally speaking, both the C and Free Pascal implementation
APIs are stable <i>for the most part</i>. The <b>C API</b> was
broken only once in middle 2010 when <code>lil_command_t</code>
was renamed to <code>lil_func_t</code> and the <b>C ABI</b> for
the Windows DLL is also backwards compatible since late 2010.
The <b>Free Pascal</b> implementation has a less stable API but
as Free Pascal itself does not support ABI stability, this is
less of a concern.</p>

<p>In the foreseeable future the C API should be stable, but i'd
recommend <i>against</i> building a system-wide shared version
of the library before a proper versioned release is made. Once
a versioned release is made, both the API and ABI will remain
stable for as long as it is technically possible.</p>

<p>Script code should be backwards compatible even as new commands
are introduced since scripts and host applications will redefine
any conflicting functions anyway. The only time script code was
broken was in 2012 when the multiline comments were introduced
so any script that used a comment line like <code>#####</code>
was broken. This was addressed in a fix in 2014 that added a special
check for such cases so that multiline comments can only start
and end with two <code>#</code>s but not three or more (while
this could have broken any script that used three or more <code>#</code>s
to start and end multiline comments, the chances for such a script
are very slim).</p>

<p>Like with the C API, the script backwards compatibility currently
is mostly stable, but minor changes (like the multiline comment
changes mentioned above) might be made until a versioned release
is made or fixes to the script behavior to be closer to what is
described in the documentation or simply fix broken behavior.
At that point no changes will be made that may affect backwards
compatibility.</p>

<p>LILGUI and LazLILGUI are more experimental and may see backwards
incompatible changes in the future.</p>

<h2><a name="documentation"></a>Documentation</h2>

<p>Currently the only documentation is the (lengthy) <tt>readme.txt</tt>
file that <a href="http://runtimeterror.com/tech/lil/readme.txt">you can read here</a> or as part
of the archive containing the source code. At some point i'll
write better formatted documentation. Free Pascal has its own
API documentation <a href="http://runtimeterror.com/tech/lil/pasreadme.txt">readable here</a> and
also as a part of the archive containing the source code.</p>

<p>The LILGUI API can be <a href="http://runtimeterror.com/tech/lil/api.txt">found here</a> and
the documentation for LazLILGUI can be <a href="http://runtimeterror.com/tech/lil/llgreadme.txt">found
here</a>. Both are also part of the LILGUI archive.</p>

<p>Also <a href="http://www.slideshare.net/badsectoracula/lil-presentation">an
old LIL presentation can be found on SlideShare</a>. Please note
that the URLs in the presentation are not valid anymore.</p>

<h2><a name="status"></a>Status</h2>

<p>LIL is practically <i>feature-complete</i> and i do very little
development of it. I do not plan on making it a big and bloated
library that tries to provide everything - if anything, in the
future i might add some conditionals to remove bits of the library
for users who do not need, e.g, the string or list functions.</p>

<p>Further work is mostly "around" LIL and not on the
language itself: improving the documentation, writing a test suite
(currently there are several examples which i run after making
changes and almost half of them come from bug fixes, but i'd like
somethnig more automated), fixing some issues with the Free Pascal
implementation, adding more functions on the C API to access LIL's
state, etc.</p>

<h2><a name="license"></a>License</h2>

<p>Both the C and Free Pascal implementations as well as WinLIL
are licensed under the zlib license below:</p>

<blockquote>
  <pre>LIL - Little Interpreted Language
Copyright (C) 2010-2019 Kostas Michalopoulos

This software is provided 'as-is', without any express or implied
warranty.  In no event will the authors be held liable for any damages
arising from the use of this software.

Permission is granted to anyone to use this software for any purpose,
including commercial applications, and to alter it and redistribute it
freely, subject to the following restrictions:

1. The origin of this software must not be misrepresented; you must not
   claim that you wrote the original software. If you use this software
   in a product, an acknowledgment in the product documentation would be
   appreciated but is not required.
2. Altered source versions must be plainly marked as such, and must not be
   misrepresented as being the original software.
3. This notice may not be removed or altered from any source distribution.</pre>
</blockquote>



</div>]]>
            </description>
            <link>http://runtimeterror.com/tech/lil/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24949515</guid>
            <pubDate>Sat, 31 Oct 2020 06:20:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Everything you need to know about windsocks]]>
            </title>
            <description>
<![CDATA[
Score 98 | Comments 38 (<a href="https://news.ycombinator.com/item?id=24949514">thread link</a>) | @oftenwrong
<br/>
October 30, 2020 | https://www.hollandaviation.nl/en/windsock-everything-you-need-to-know-about-windsocks/ | <a href="https://web.archive.org/web/*/https://www.hollandaviation.nl/en/windsock-everything-you-need-to-know-about-windsocks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.hollandaviation.nl/en/windsock-everything-you-need-to-know-about-windsocks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24949514</guid>
            <pubDate>Sat, 31 Oct 2020 06:19:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Better Mousetrap – Converting WebPages to Web APIs]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 21 (<a href="https://news.ycombinator.com/item?id=24948779">thread link</a>) | @shanselman
<br/>
October 30, 2020 | https://turnerj.com/blog/a-better-mousetrap | <a href="https://web.archive.org/web/*/https://turnerj.com/blog/a-better-mousetrap">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="article">
<p>Today is a big day for me as after many months (or years depending how you look at it), I've <a href="https://www.producthunt.com/posts/brandvantage">finally launched the first product for my business, BrandVantage</a>.
This post is the story of how I started with one idea and ended up launching with a different one.</p>
<h2>The Original Idea: Let's build a digital brand expert!</h2>
<p>I worked as a web developer for a local web development agency for a number of years and in that time, I learnt a lot about how a variety of different businesses operated online.</p>
<p>There were a few key "problems" I found in common across many of those businesses:</p>
<ul>
<li>Under-utilising analytics</li>
<li>Misunderstanding analytics</li>
<li>Not keeping on top of industry information</li>
<li>Lack of competitor analysis/understanding</li>
<li>Difficulty with Search Engine Optimization (SEO)</li>
</ul>
<p>In moderate-to-large companies where you have marketing departments, most of this stuff can be covered by one or more staff dedicated to these things.
In smaller companies, the business owner is normally the one where these tasks fall on to, but they are already wearing many different hats.
It felt like something was here - if I could automate some of these tasks in different ways, I could both help business owners and earn myself some money along the way.</p>
<p>Automation of tasks, especially ones in analytics or SEO spaces, isn't a new idea.
In fact, I've seen many businesses in a similar space launch on Product Hunt over the years since starting, but that didn't deter me.
I was building <a href="https://idioms.thefreedictionary.com/a+better+mousetrap"><em>a better mousetrap</em></a> and wanting to launch it at a lower price, not something truly innovative so it was going to be an uphill battle.
This area though, helping small businesses online be as efficient in tasks as some bigger businesses can, is something I felt passionately about so I proceeded anyway.</p>
<h3>Attempt One: Very Hacky (in PHP)</h3>
<p>Way back in 2015/16/17, while still at my full-time job, I spent nights and weekends building and tinkering on solutions to the problems business owners face.
It was a hacky PHP solution pulling real-time information from sources like Twitter, Google Analytics and Facebook.
A hacky approach seemed like a good idea as that seemed to be the way people launched things, do the quickest and hackiest thing you can to get it out the door.</p>
<p>While working on it, I had a few interested parties though what I built could barely be considered a prototype.
The thing was a mess.
I could do some basic queries, but it wasn't what I considered sellable and definitely not user-friendly, something I considered key to the product.
I was also running into technical problems with scale - any sufficiently complex query was performed real-time, which was getting more complicated.
Real-time processing had to be out.
I needed to pre-compute and store it in a database.</p>
<p>I wanted to take this more seriously and I didn't feel like a "quick and hacky" approach to building a product was right for me.
With this in mind, it seemed like a good opportunity to change the tech stack to something that would be better long term.</p>
<h3>Attempt Two: Slightly Less Hacky (in .NET)</h3>
<p>Moving to .NET felt like the smart move for me as at my job I had spent a lot more time working in .NET than PHP, plus I vastly prefered the tooling in .NET vs PHP.
That said, the .NET code I had worked on to-date would definitely be considered "legacy code".</p>
<p>My first version in .NET (specifically .NET Framework), predating my use of version control, was trying to keep costs low by using MySQL through Entity Framework.
After a lot of pain and suffering with that, I had a short stint of MSSQL before I settled upon MongoDB.</p>
<p>MongoDB might seem like a weird choice - there are some people that have very strong opinions about which type of database you should use.
Honestly it came down to a gut feel after messing around with it - it seemed more compatible to the way I was approaching problems than a relational database would.
I liked the code-first approach to Entity Framework so much though that I recreated the "feel" of Entity Framework for MongoDB with some custom code.
This later became an open source project of mine called <a href="https://www.mongoframework.com/">MongoFramework</a>.</p>
<p>I'm not going to lie, progress was... slow.
While I was putting quite a lot of time into working on it, it was still an extremely ambitious project.
I have strong feelings about building "MVPs" where some people focus too much on the "minimum" without enough focus on the "viable".
At the end of the day people buy products that meet their needs, and cutting too much out would meet no-ones needs.
If someone was going to use this, in a market with many competitors of varying quality, it had to do its job well.
There didn't seem much I could reasonably cut to make it any more minimal if I wanted people to buy it.</p>
<p>I kept working at it every night, building pieces to extract and store data from a variety of sources.
I was pulling in data from Google Analytics, Google Webmaster Tools (now called Google Search Console), Twitter, Facebook, IP Geolocation, DNS information and also from news articles.
What I thought I could do is once I had the different data sources together, I would write custom rules that could infer insights from individual or combined data sets.
These insights would form the basis of the "digital brand expert".
After all, that was the goal of the idea, something that could help out small business owners.</p>
<p>After 2 years of working on this in my spare time, it felt the right time to leave my job and go into this full time.
I felt like I was <em>so close</em> to launching and I just needed something more than the same day-to-day work.
So I did it - <a href="https://turnerj.com/blog/i-left-my-job-today-after-seven-years">I left my job after 7 years</a>.</p>
<h3>Going Full-time into the Idea</h3>
<p>Right out of the gate, I had moved from .NET Framework to .NET Core, was working on UI/UX improvements for the application and launched the website for it.
I worked with an accountant and a lawyer to setup the business, bought a trade mark for the product name, and I felt good like I was only a few months away from launching.
This feeling didn't last though...</p>
<p>Over time, it felt like I was taking two steps forward then one step back - some technical, some business related.
Sure, that is still progress, but having new issues crop up every day or so can really crush your motivation.</p>
<p>My best/happiest/most productive days were days I ignored or avoided different issues I had.
If I had a problem with the login system, I would focus on how the UX of the menus worked.
If I had a problem with data gathering, I would add more tests to the codebase.
While I didn't entirely ignore the problem, I would wait a week or two before I looked at it again, somewhat hoping it would solve itself - unfortunately that isn't how things work.</p>
<p>In time though, I got to a stage where it felt like I could launch and was hyping myself up until reality struck: I didn't actually build what I set out to build.</p>
<p>The UI/UX was good, I had strategies for deployment and plans for next steps, but it wasn't a "digital brand expert".
It was instead a glorified data store for information that people could better access through existing tools.
That's kinda a big problem!</p>
<p><img src="https://turnerj.com/blog/2020/images/a-better-mousetrap-ive-made-a-huge-mistake.gif" alt="Gob Bluth saying &quot;I've made a huge mistake.&quot; from the TV Show &quot;Arrested Development&quot;"></p>
<p>When realising this I poured time into fixing that huge lapse in judgement, but I couldn't do it.
No matter how I tried, I just couldn't figure out how to build this rules engine.
It was like my entire thought process was just clouded.
I couldn't see the solution to the problem like I can for most other things.</p>
<p>This was depressing and I ended up having a month or so hiatus from working on it.
When I have had stints of not feeling like or not being able to do programming in the past, I try and spur it on again by watching some show or movie which has some strong relation to technology (fictional or not).
My go-to is usually something like <a href="https://www.imdb.com/title/tt0371746/">Iron Man</a>, but this time I was rewatching <a href="https://www.imdb.com/title/tt2543312/">Halt and Catch Fire</a> where I found some inspiration.</p>
<h2>The Pivot: An API to the Internet</h2>
<p>Later in the series a lot of the focus is around the Web, and it was in these episodes where my thoughts about the Internet and the data on it have changed.
There is a quote from one of the main characters at the end of Season 3 that resonates with me:</p>
<div>
<blockquote>
<p>"The moment we decide what the Web is, we've lost. The moment we try to tell people what to do with it, we've lost.
All we have to do is build a door and let them inside."</p>
<p>- Joe MacMillan (Season 3, Episode 10)</p>
</blockquote>
</div>
<p>The Internet is a treasure trove of information, it is searchable but generally unstructured.
People have managed to create all sorts of different pages in HTML, but in the process of making a website everything is designed for a human user.
It is this way for obvious reasons, <em>we</em> are the consumers of web pages after all... aren't we?</p>
<p>Behind these user-friendly web pages are usually other specific bits of markup, providing some level of structured data for specific situations.
Sometimes it is a description metatag for search engines, other times it might be <a href="https://ogp.me/">Open Graph</a> metatags for social media links.
We build these things to help aid computers processing our web pages.</p>
<p>In 2011, <a href="https://schema.org/">Schema.org</a> was created.
This was a collaborative effort between Google, Bing and Yahoo (later that year, Yandex as well) with the mission to "create, maintain, and promote schemas for structured data on the Internet, on web pages, in email messages, and beyond".
Through 3 different encodings (<a href="https://turnerj.com/blog/what-is-microdata-and-why-should-i-care">Microdata</a>, <a href="http://rdfa.info/">RDFa</a> and <a href="https://json-ld.org/">JSON-LD</a>), websites could express detailed structured data.</p>
<p>There is another quote from Halt and Catch Fire which I like:</p>
<div>
<blockquote>
<p>"Computers aren't the thing. They're the thing that gets us to the thing."</p>
<p>- Joe MacMillan (Season 1, Episode 1)</p>
</blockquote>
</div>
<p>As much as I like computers and programming, they are used to help us achieve other goals.
From my attempts of trying to build a "digital brand expert", I knew that data is fundamental to help build more advanced systems and give new insights.
Having easier access to other forms of data from web pages around the world may allow new and different tools to be built.</p>
<p>So I decided rather than try and solve a problem that I was clouded by, I …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://turnerj.com/blog/a-better-mousetrap">https://turnerj.com/blog/a-better-mousetrap</a></em></p>]]>
            </description>
            <link>https://turnerj.com/blog/a-better-mousetrap</link>
            <guid isPermaLink="false">hacker-news-small-sites-24948779</guid>
            <pubDate>Sat, 31 Oct 2020 02:49:19 GMT</pubDate>
        </item>
    </channel>
</rss>
