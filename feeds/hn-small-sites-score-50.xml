<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Thu, 24 Sep 2020 04:24:42 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Thu, 24 Sep 2020 04:24:42 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Bypassing ESP32 Encrypted Secure Boot]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24552482">thread link</a>) | @mleonhard
<br/>
September 22, 2020 | https://raelize.com/posts/espressif-esp32-bypassing-encrypted-secure-boot-cve-2020-13629/ | <a href="https://web.archive.org/web/*/https://raelize.com/posts/espressif-esp32-bypassing-encrypted-secure-boot-cve-2020-13629/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>We arrived at the last post about our <strong>Fault Injection</strong> research on the <strong>ESP32</strong>. Please read our previous posts as it provides context to the results described in this post.</p>
<ul>
<li><a href="https://raelize.com/posts/espressif-systems-esp32-bypassing-sb-using-emfi/">Espressif ESP32: Bypassing Secure Boot using EMFI</a></li>
<li><a href="https://raelize.com/posts/espressif-systems-esp32-controlling-pc-during-sb/">Espressif ESP32: Controlling PC during Secure Boot</a></li>
<li><a href="https://raelize.com/posts/espressif-systems-esp32-bypassing-flash-encryption/">Espressif ESP32: Bypassing Flash Encryption (CVE-2020-15048)</a></li>
</ul>
<p>During our <strong>Fault Injection</strong> research on the <strong>ESP32</strong>, we gradually took steps forward in order to identify the required vulnerabilities that allowed us to bypass <strong>Secure Boot</strong> and <strong>Flash Encryption</strong> with a single <strong>EM</strong> glitch. Moreover, we did not only achieve <strong>code execution</strong>, we also extracted the <strong>plain-text flash</strong> data from the chip.</p>
<p><strong>Espressif</strong> requested a <strong>CVE</strong>  for the attack described in this post: <a href="https://www.espressif.com/sites/default/files/advisory_downloads/Security%20Advisory%20CVE-2020-15048%2C%2013629%20EN%26CN.pdf" target="_blank">CVE-2020-13629</a>. Please note, that the attack as described in this post, is only applicable to <strong>ESP32</strong> silicon revision 0 and 1. The newer <strong>ESP32 V3</strong> silicon supports functionality to disable the <strong>UART bootloader</strong> that we leveraged for the attack.</p>

<p>The <strong>ESP32</strong> implements an <strong>UART bootloader</strong> in its <strong>ROM code</strong>. This feature allows, among other functionality, to program the external flash. It's not uncommon that such functionality is implemented in the <strong>ROM code</strong> as it's quite robust as the code cannot get corrupt easily. If this functionality would be implemented by code stored in the external flash, any corruption of the flash may result in a bricked device.</p>
<p>Typically, this type of functionality is accessed by booting the chip in a special <strong>boot mode</strong>. The <strong>boot mode</strong> selection is often done using one or more external strap pin(s) which are set before resetting the chip. On the <strong>ESP32</strong> it works exactly like this pin <code>G0</code> which is exposed externally.</p>
<p>The <strong>UART bootloader</strong> supports many interesting <a href="https://github.com/espressif/esptool/wiki/Serial-Protocol#command-opcodes" target="_blank">commands</a> that can be used to read/write memory, read/write registers and even execute a stub from <strong>SRAM</strong>.</p>
<h4 id="executing-arbitrary-code">Executing arbitrary code</h4>
<p>The <strong>UART bootloader</strong> supports loading and executing arbitrary code using the <code>load_ram</code> command. The <strong>ESP32</strong>'s SDK includes all the tooling required to compile the code that can be executed from <strong>SRAM</strong>. For example, the following code snippet will print <code>SRAM CODE\n</code> on the serial interface.</p>
<div><pre><code data-lang="C"><span>void</span> <span>__attribute__</span><span>((</span><span>noreturn</span><span>))</span> <span>call_start_cpu0</span><span>()</span>
<span>{</span>
    <span>ets_printf</span><span>(</span><span>"SRAM CODE</span><span>\n</span><span>"</span><span>);</span>
    <span>while</span> <span>(</span><span>1</span><span>);</span>
<span>}</span>
</code></pre></div><p>The <code>esptool.py</code> tool, which is part of the <strong>ESP32</strong>'s SDK, can be used to load the compiled binary into the <strong>SRAM</strong> after which it will be executed.</p>
<pre><code>esptool.py --chip esp32 --no-stub --port COM3 load_ram code.bin
</code></pre><p>Interestingly, the <strong>UART bootloader</strong> cannot disabled and therefore always accessible, even when <strong>Secure Boot</strong> and <strong>Flash Encryption</strong> are enabled.</p>
<h4 id="additional-measures">Additional measures</h4>
<p>Obviously, if no additional security measures would be taken, leaving the <strong>UART bootloader</strong> always accessible would render <strong>Secure Boot</strong> and <strong>Flash Encryption</strong> likely useless. Therefore, <strong>Espressif</strong> implemented additional security measures which are enabled using dedicated <strong>eFuses</strong>.</p>
<p>These are security configuration bits implemented in special memory, often referred to as <strong>OTP memory</strong>, which can typically only change from 0 to 1. This guarantees, that once enabled, is enabled forever. The following <strong>OTP memory</strong> bits are used to disable specific functionality when the <strong>ESP32</strong> is in the <strong>UART bootloader</strong> boot mode.</p>
<ul>
<li><strong>DISABLE_DL_ENCRYPT</strong>: disables flash encryption operation</li>
<li><strong>DISABLE_DL_DECRYPT</strong>: disables transparent flash decryption</li>
<li><strong>DISABLE_DL_CACHE</strong>: disables the entire MMU flash cache</li>
</ul>
<p>The most relevant <strong>OTP memory</strong> bit is <strong>DISABLE_DL_DECRYPT</strong> as it disables the transparent decryption of the flash data.</p>
<p>If not set, it would be possible to simply access the plain-text flash data while the <strong>ESP32</strong> is in its <strong>UART bootloader</strong> boot mode.</p>
<p>If set, any access to the flash, when the chip is in <strong>UART bootloader</strong> boot mode, will yield just the encrypted data. The <strong>Flash Encryption</strong> feature, which is fully implemented in hardware and transparent to the processor,  is only enabled in when the <strong>ESP32</strong> is in <strong>Normal</strong> boot mode.</p>
<p>The attacks described in this post have all these bits set to 1.</p>

<p>The <strong>SRAM</strong> memory that's used by the <strong>ESP32</strong> is typical technology that's used by many chips. It's commonly used to the <strong>ROM</strong>'s stack and executing the first bootloader from flash. It's convenient to use at early boot as it typically require no configuration before it can be used.</p>
<p>We know from previous experience that the data stored in <strong>SRAM</strong> memory is persistent until it's overwritten or the required power is removed from the physical cells. After a <strong>cold reset</strong> (i.e. power-cycle) of the chip, the <strong>SRAM</strong> will be reset to its default state. This often semi-random and unique per chip as the default value for each bit (i.e. 0 or 1) is different.</p>
<p>However, after a <strong>warm reset</strong>, where the entire chip is reset without removing the power, it may happen that the data stored in <strong>SRAM</strong> remains unaffected. This persistence of the data is visualized in the picture below.</p>
<p>
    <a href="https://raelize.com/img/esp32/esp32-sram-persistence.png">
        <img src="https://raelize.com/img/esp32/esp32-sram-persistence.png" width="700px">
    </a>
</p>
<p>We decided to figure out if this behavior holds up for the <strong>ESP32</strong> as well. We identified that the hardware <a href="https://docs.espressif.com/projects/esp-idf/en/latest/esp32/api-reference/system/wdts.html" target="_blank">watchdog</a> can be used to issue a <strong>warm reset</strong> from software. This <strong>watchdog</strong> can also be issued when the chip is in <strong>UART bootloader</strong> boot mode and therefore we can use it to reset the <strong>ESP32</strong> back into <strong>Normal</strong> boot mode.</p>
<p>Using some test code, loaded and executed in <strong>SRAM</strong> using the <strong>UART bootloader</strong>, we determined that the data in <strong>SRAM</strong> is indeed persistent after issuing a <strong>warm reset</strong> using the <strong>watchdog</strong>. Effectively this means we can boot the <strong>ESP32</strong> in <strong>Normal</strong> boot mode with the <strong>SRAM</strong> filled with controlled data.</p>
<p>But… how can we (ab)use this?</p>

<p>We envisioned that we may be able to leverage the persistence of data in <strong>SRAM</strong> across <strong>warm resets</strong> for an attack. The first attack we came up with is to fill the <strong>SRAM</strong> with code using the <strong>UART bootloader</strong> and issue a <strong>warm reset</strong> using the <strong>watchdog</strong>. Then, we inject a glitch while the <strong>ROM code</strong> is overwriting this code with the <strong>flash bootloader</strong> during a normal boot.</p>
<p>We got this ideas as during our previous experiments, where we <a href="">turned data transfers into code execution</a>, we noticed that for some experiments the chip started executing from the entry address before the bootloader was finished copying.</p>
<p>Sometimes you just need to try it…</p>
<h4 id="attack-code">Attack code</h4>
<p>The code that we load into the <strong>SRAM</strong> using the <strong>UART bootloader</strong> is shown below.</p>
<div><pre><code data-lang="C"><span>#define a "addi a6, a6, 1;"
</span><span>#define t a a a a a a a a a a
</span><span>#define h t t t t t t t t t t
</span><span>#define d h h h h h h h h h h
</span><span></span>
<span>void</span> <span>__attribute__</span><span>((</span><span>noreturn</span><span>))</span> <span>call_start_cpu0</span><span>()</span> <span>{</span>
    <span>uint8_t</span> <span>cmd</span><span>;</span>

    <span>ets_printf</span><span>(</span><span>"SRAM CODE</span><span>\n</span><span>"</span><span>);</span>

    <span>while</span> <span>(</span><span>1</span><span>)</span> <span>{</span>

        <span>cmd</span> <span>=</span> <span>0</span><span>;</span>
        <span>uart_rx_one_char</span><span>(</span><span>&amp;</span><span>cmd</span><span>);</span>

        <span>if</span><span>(</span><span>cmd</span> <span>==</span> <span>'A'</span><span>)</span> <span>{</span>                                    <span>// 1
</span><span></span>            <span>*</span><span>(</span><span>unsigned</span> <span>int</span> <span>*</span><span>)(</span><span>0x3ff4808c</span><span>)</span> <span>=</span> <span>0x4001f880</span><span>;</span>
            <span>*</span><span>(</span><span>unsigned</span> <span>int</span> <span>*</span><span>)(</span><span>0x3ff48090</span><span>)</span> <span>=</span> <span>0x00003a98</span><span>;</span>
            <span>*</span><span>(</span><span>unsigned</span> <span>int</span> <span>*</span><span>)(</span><span>0x3ff4808c</span><span>)</span> <span>=</span> <span>0xc001f880</span><span>;</span>
        <span>}</span>
    <span>}</span>

    <span>asm</span> <span>volatile</span> <span>(</span> <span>d</span> <span>);</span>                                     <span>// 2
</span><span></span>
    <span>"movi a6, 0x40; slli a6, a6, 24;"</span>                       <span>// 3
</span><span></span>    <span>"movi a7, 0x00; slli a7, a7, 16;"</span>
    <span>"xor a6, a6, a7;"</span>
    <span>"movi a7, 0x7c; slli a7, a7, 8;"</span>
    <span>"xor a6, a6, a7;"</span>
    <span>"movi a7, 0xf8;"</span>
    <span>"xor a6, a6, a7;"</span>

    <span>"movi a10, 0x52; callx8  a6;"</span> <span>// R
</span><span></span>    <span>"movi a10, 0x61; callx8  a6;"</span> <span>// a            
</span><span></span>    <span>"movi a10, 0x65; callx8  a6;"</span> <span>// e               
</span><span></span>    <span>"movi a10, 0x6C; callx8  a6;"</span> <span>// l               
</span><span></span>    <span>"movi a10, 0x69; callx8  a6;"</span> <span>// i               
</span><span></span>    <span>"movi a10, 0x7A; callx8  a6;"</span> <span>// z               
</span><span></span>    <span>"movi a10, 0x65; callx8  a6;"</span> <span>// e               
</span><span></span>    <span>"movi a10, 0x21; callx8  a6;"</span> <span>// !               
</span><span></span>    <span>"movi a10, 0x0a; callx8  a6;"</span> <span>// \n               
</span><span></span>
    <span>while</span><span>(</span><span>1</span><span>);</span>
<span>}</span>
</code></pre></div><p>To summarize, the above code implements the following:</p>
<ol>
<li>Command handler with a single command to perform a <strong>watchdog</strong> reset</li>
<li>NOP-like padding using <code>addi</code> instructions</li>
<li>Assembly for printing <code>Raelize!</code> on the serial interface</li>
</ol>
<p>Please note, the listing's numbers match the numbers in the code.</p>
<h4 id="timing">Timing</h4>
<p>We target a reasonably small attack window at the start of <strong>F</strong> which is shown in the picture below. We know from previous experiments that during this moment the <strong>flash bootloader</strong> is copied.</p>
<p>
    <a href="https://raelize.com/img/esp32/esp32-spi-pin1-during-boot.png">
        <img src="https://raelize.com/img/esp32/esp32-spi-pin1-during-boot.png" width="600px">
    </a>
</p>
<p>The glitch must be injected before our code in <strong>SRAM</strong> is entirely overwritten by the valid <strong>flash bootloader</strong>.</p>
<h4 id="attack-cycle">Attack cycle</h4>
<p>We took the following steps for each experiment to determine if the attack idea actually works. A successful glitch will print <code>Raelize!</code> on the serial interface.</p>
<ol>
<li>Set pin <strong>G0</strong> to low and perform a <strong>cold reset</strong> to enter <strong>UART bootloader</strong> boot mode</li>
<li>Use the <code>load_ram</code> command to execute our <strong>attack code</strong> from <strong>SRAM</strong></li>
<li>Send an <code>A</code> to the program to issue a <strong>warm reset</strong> into <strong>normal</strong> boot mode</li>
<li>Inject a glitch while the <strong>flash bootloader</strong> is being copied by the <strong>ROM code</strong></li>
</ol>
<h4 id="results">Results</h4>
<p>After running these experiments for more than a day, resulting in more than 1 million experiments, we did not observe any successful glitch…</p>
<h4 id="an-unexpected-result">An unexpected result</h4>
<p>Nonetheless, while analyzing the results, we noticed something unexpected.</p>
<p>The <strong>serial interface</strong> output for one of the experiments, which is shown below, indicated that the glitch caused an <strong>illegal instruction</strong> exception.</p>
<pre><code>ets Jun  8 2016 00:22:57
rst:0x10 (RTCWDT_RTC_RESET),boot:0x13 (SPI_FAST_FLASH_BOOT)
configsip: 0, SPIWP:0xee
clk_drv:0x00,q_drv:0x00,d_drv:0x00,cs0_drv:0x00,hd_drv:0x00,wp_drv:0x00
mode:DIO, clock div:2
load:0x3fff0008,len:4
load:0x3fff000c,len:3220
load:0x40078000,len:4816
load:0x40080400,len:18640
entry 0x40080740
Fatal exception (0): IllegalInstruction
epc1=0x661b661b, epc2=0x00000000, epc3=0x00000000, 
excvaddr=0x00000000, depc=0x00000000
</code></pre><p>These type of exceptions happened quite often when glitches are injected in a chip. This was not different for the <strong>ESP32</strong>. For most the exceptions the <code>PC</code> register is set to a value that's expected (i.e. a valid address). It does not happen often the <code>PC</code> register is set to such an interesting value.</p>
<p>The <code>Illegal Instruction</code> exception is caused as there is no valid instruction stored at the <code>0x661b661b</code> address. We conclude this value must come from somewhere and that is cannot magically end up in the <code>PC</code> register.</p>
<p>We analyzed the code that we load into the <strong>SRAM</strong> in order to find an explanation. The …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://raelize.com/posts/espressif-esp32-bypassing-encrypted-secure-boot-cve-2020-13629/">https://raelize.com/posts/espressif-esp32-bypassing-encrypted-secure-boot-cve-2020-13629/</a></em></p>]]>
            </description>
            <link>https://raelize.com/posts/espressif-esp32-bypassing-encrypted-secure-boot-cve-2020-13629/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24552482</guid>
            <pubDate>Tue, 22 Sep 2020 09:16:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mainline Linux on the MikroTik RB3011]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 27 (<a href="https://news.ycombinator.com/item?id=24550846">thread link</a>) | @pabs3
<br/>
September 21, 2020 | https://www.earth.li/~noodles/blog/2020/09/rb3011-mainline.html | <a href="https://web.archive.org/web/*/https://www.earth.li/~noodles/blog/2020/09/rb3011-mainline.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <p>I upgraded my home internet connection to fibre (FTTP) <a href="https://www.earth.li/~noodles/blog/2019/10/native-ipv6-fttp.html">last October</a>. I’m still on an 80M/20M service, so it’s no faster than my old VDSL FTTC connection was, and as a result for a long time I continued to use my HomeHub 5A running <a href="https://openwrt.org/">OpenWRT</a>. However the FTTP ONT meant I was using up an additional ethernet port on the router, and I was already short, so I ended up with a GigE switch in use as well. Also my wifi is handled by a <a href="https://unifi-network.ui.com/">UniFi</a>, which takes its power via Power-over-Ethernet. That mean I had a router, a switch and a PoE injector all in close proximity. I wanted to reduce the number of devices, and ideally upgrade to something that could scale once I decide to upgrade my FTTP service speed.</p>

<p>Looking around I found the <a href="https://mikrotik.com/product/RB3011UiAS-RM">MikroTik RB3011UiAS-RM</a>, which is a rack mountable device with 10 GigE ports (plus an SFP slot) and a dual core <a href="https://www.qualcomm.com/products/ipq8064">Qualcomm IPQ8064</a> ARM powering it. There’s 1G RAM and 128MB NAND flash, as well as a USB3 port. It also has PoE support. On paper it seemed like an ideal device. I wasn’t particularly interested in running RouterOS on it (the provided software), but that’s based on Linux and there was some work going on within OpenWRT to add support, so it seemed like a worthwhile platform to experiment with (what, you expected this to be about me buying an off the shelf device and using it with only the supplied software?). As an added bonus a friend said he had one he wasn’t using, and was happy to sell it to me for a bargain price.</p>

<p><img alt="RB3011 router in use" src="https://www.earth.li/~noodles/blog/images/2020/rb3011.jpg"></p>

<p>I did try out RouterOS to start with, but I didn’t find it particularly compelling. I’m comfortable configuring firewalling and routing at a Linux command line, and I run some additional services on the router like my <a href="https://www.earth.li/~noodles/blog/2018/05/mqtt-broker.html">MQTT</a> broker, and <a href="https://www.earth.li/~noodles/blog/2018/09/netlink-arp-presence.html">mqtt-arp</a>, my wifi device presence monitor. I could move things around such that they ran on the <a href="https://www.earth.li/~noodles/blog/2019/07/upgrading-the-house-server.html">house server</a>, but I consider them core services and as a result am happier with them on the router.</p>

<p>The first step was to get something booting on the router. Luckily it has an RJ45 serial console port on the back, and a reasonably featured bootloader that can manage to boot via tftp over the network. It wants an ELF binary rather than a plain kernel, but Sergey Sergeev had done the hard work of getting <a href="https://github.com/adron-s/uboot-ipq806x">u-boot working for the IPQ8064</a>, which mean I could just build normal u-boot images to try out.</p>

<p>Linux upstream already had basic support for a lot of the pieces I was interested in. There’s a slight fudge around <code>AUTO_ZRELADDR</code> because the network coprocessors want a chunk of memory at the start of RAM, but there’s ongoing discussions about how to handle this cleanly that I’m hopeful will eventually mean I can drop that hack. Serial, ethernet, the QCA8337 switches (2 sets of 5 ports, tied to different GigE devices on the processor) and the internal NOR all had drivers, so it was a matter of crafting an appropriate DTB to get them working. That left niggles.</p>

<p>First, the second switch is hooked up via SGMII. It turned out the IPQ806x <code>stmmac</code> driver didn’t initialise the clocks in this mode correctly, and neither did the <code>qca8k</code> switch driver. So I need to fix up both of those (Sergey had handled the stmmac driver, so I just had to clean up and submit his patch). Next it turned out the driver for talking to the Qualcomm firmware (SCM) had been updated in a way that broke the old method needed on the IPQ8064. Some git archaeology figured that one out and provided a solution. Ansuel Smith helpfully provided the DWC3 PHY driver for the USB port. That got me to the point I could put a Debian armhf image onto a USB stick and mount that as root, which made debugging much easier.</p>

<p>At this point I started to play with configuring up the device to actually act as a router. I make use of a number of VLANs on my home network, so I wanted to make sure I could support those. Turned out the stmmac driver wasn’t happy reconfiguring its MTU because the IPQ8064 driver doesn’t configure the FIFO sizes. I found what seem to be the correct values and plumbed them in. Then the <code>qca8k</code> driver only supported port bridging. I wanted the ability to have a trunk port to connect to the upstairs switch, while also having ports that only had a single VLAN for local devices. And I wanted the switch to handle this rather than requiring the CPU to bridge the traffic. Thankfully it’s easy to find a copy of the QCA8337 datasheet and the kernel <a href="https://www.kernel.org/doc/html/latest/networking/dsa/index.html">Distributed Switch Architecture</a> is pretty flexible, so I was able to implement the necessary support.</p>

<p>I stuck with Debian on the USB stick for actually putting the device into production. It makes it easier to fix things up if necessary, and the USB stick allows for a full Debian install which would be tricky on the 128M of internal NAND. That means I can use things like <a href="https://wiki.nftables.org/">nftables</a> for my firewalling, and use the standard Debian packages for things like <a href="https://collectd.org/">collectd</a> and <a href="https://mosquitto.org/">mosquitto</a>. Plus for debug I can fire up things like tcpdump or tshark. Which ended up being useful because when I put the device into production I started having weird IPv6 issues that turned out to be a lack of proper Ethernet multicast filter support in the IPQ806x ethernet device. The driver would try and setup the multicast filter for the IPv6 NDP related packets, but it wouldn’t actually work. The fix was to fall back to just receiving all multicast packets - this is what the vendor driver does.</p>

<p>Most of this work will be present once the 5.9 kernel is released - the basics are already in 5.8. Currently not queued up that I can think of are the following:</p>

<ul>
  <li>stmmac IPQ806x FIFO sizes. I sent out an RFC patch for these, but didn’t get any replies. I probably just need to submit this.</li>
  <li>NAND. This is missing support for the QCOM ADM DMA engine. I’ve sent out the patch I found to enable this, and have had some feedback, so I’m hopeful it will get in at some point.</li>
  <li>LCD. AFAICT LCD is an ST7735 device, which has kernel support, but I haven’t spent serious effort getting the SPI configuration to work.</li>
  <li>Touchscreen. Again, this seems to be a zt2046q or similar, which has a kernel driver, but the basic attempts I’ve tried don’t get any response.</li>
  <li>Proper SFP functionality. The IPQ806x has a PCS module, but the stmmac driver doesn’t have an easy way to plumb this in. I have ideas about how to get it working properly (and it can be hacked up with a fixed link config) but it’s not been a high priority.</li>
  <li>Device tree additions. Some of the later bits I’ve enabled aren’t yet in the mainline RB3011 DTB. I’ll submit a patch for that at some point.</li>
</ul>

<p>Overall I consider the device a success, and it’s been entertaining getting it working properly. I’m running a mostly mainline kernel, it’s handling my house traffic without breaking a sweat, and the fact it’s running Debian makes it nice and easy to throw more things on it as I desire. However it turned out the RB3011 isn’t as perfect device as I’d hoped. The PoE support is passive, and the UniFi wants 802.1af. So I was going to end up with 2 devices. As it happened I picked up a cheap <a href="https://eu.dlink.com/uk/en/products/dgs-1210-series-gigabit-smart-plus-switches">D-Link DGS-1210-10P</a> switch, which provides the PoE support as well as some additional switch ports. Plus it runs Linux, so more on that later…</p>

  </article></div>]]>
            </description>
            <link>https://www.earth.li/~noodles/blog/2020/09/rb3011-mainline.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24550846</guid>
            <pubDate>Tue, 22 Sep 2020 04:27:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When feature flags do and don’t make sense (2019)]]>
            </title>
            <description>
<![CDATA[
Score 84 | Comments 34 (<a href="https://news.ycombinator.com/item?id=24549917">thread link</a>) | @nomdep
<br/>
September 21, 2020 | https://software.rajivprab.com/2019/12/19/when-feature-flags-do-and-dont-make-sense/ | <a href="https://web.archive.org/web/*/https://software.rajivprab.com/2019/12/19/when-feature-flags-do-and-dont-make-sense/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<div><figure><a href="https://www.redbubble.com/i/canvas-print/If-Else-Software-Developer-Joke-Beer-Lover-by-VaSkoy/33140544.5Y5V7" target="_blank"><img data-attachment-id="282" data-permalink="https://software.rajivprab.com/flag/" data-orig-file="https://softwarerajivprab.files.wordpress.com/2019/12/flag.png" data-orig-size="896,1480" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="flag" data-image-description="" data-medium-file="https://softwarerajivprab.files.wordpress.com/2019/12/flag.png?w=182" data-large-file="https://softwarerajivprab.files.wordpress.com/2019/12/flag.png?w=620" src="https://softwarerajivprab.files.wordpress.com/2019/12/flag.png?w=182" alt="" srcset="https://softwarerajivprab.files.wordpress.com/2019/12/flag.png?w=182 182w, https://softwarerajivprab.files.wordpress.com/2019/12/flag.png?w=364 364w, https://softwarerajivprab.files.wordpress.com/2019/12/flag.png?w=91 91w" sizes="(max-width: 182px) 100vw, 182px"></a></figure></div>



<p>Over the past years, I’ve worked in multiple teams adopting very different strategies when it comes to feature flags. I’ve seen the pros and cons of both, and over time, I found myself disagreeing with any fundamentalist position on their use. There is a lot of nuance to this topic, and I think it is worth considering more carefully the various scenarios where feature flags do and do not make sense.</p>



<h2>The Reasons For</h2>



<p>There are a few major scenarios where feature flags make a lot of sense. The first is when it’s used for <a rel="noreferrer noopener" aria-label="A/B testing (opens in a new tab)" href="https://en.wikipedia.org/wiki/A/B_testing" target="_blank">A/B testing</a>, where you absolutely do want different behaviors for different users, based on their randomly assigned treatment. I’ve seen this strategy employed extremely well at Amazon where new features are gated by a “feature flag” that is actually controlled by an internal A/B testing framework. The framework randomly exposes some Amazon customers to the new feature, and then monitors their subsequent behavior in order to estimate the business impact of launching the feature.&nbsp;</p>



<p>I was initially skeptical, but was soon won over by how easy the framework was to use, and the valuable insights it provided on the benefits (or drawbacks) of certain features. “Flavor of the month” decisions were replaced with real data. And none of this is possible without the use of “feature flags” to dynamically toggle new features.</p>



<hr>



<p>Another great use case for feature flags, is when you’re working on a very complex epic that require many different sub-tasks to be completed in different parts of the system. Sub-tasks that are too numerous and invasive to be done in a single pull-request. </p>



<p>In such cases, trying to keep all these disparate changes in side-branches and coordinating a simultaneous merge and deployment, is a recipe for disaster. It’s far more manageable to gate any disruptive changes behind a master flag, merge and deploy all the sub-commits incrementally, and do a flag-flip once all the pieces are in place.</p>



<hr>



<p>One last use case for feature flags, is when you do not have control over your deployments. For example, consider the Facebook Android app, which contains code contributed by hundreds of different teams, all combined and deployed as a single binary. In such scenarios, performing rollbacks can be infeasible. For practical, political, bureaucratic or even marketing reasons. In such cases, feature flags allow your team to toggle new functionality or mitigate risky changes, without having to rollback or deploy any new binaries.</p>



<p><em><a href="https://www.reddit.com/r/programming/comments/i5zbvk/when_feature_flags_do_and_dont_make_sense/" target="_blank" rel="noreferrer noopener">Someone on Reddit pointed out</a> a similar use-case for feature flags: targeting a very specific launch date for marketing reasons, while still deploying your code much earlier, in order to ensure stability. You can then have a “dynamic” feature flag that automatically enables itself at a specific time. This is also a great use-case for similar reasons – changing functionality in situations where deploying a new binary is impractical.</em></p>



<h2>Risk Aversion</h2>



<p>The above are all fantastic use cases for feature flags, but I’ve also seen teams get bogged down by policies that overreach in their use. For example, mandating that every single code change should be behind a feature flag, <em>“just in case we made a mistake”</em>.</p>



<p>Risk management should indeed be a priority for all teams. But there are better ways of doing this than relying on feature flags, especially if your team has control over its own deployments. The <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://software.rajivprab.com/2019/04/28/rethinking-software-testing-perspectives-from-the-world-of-hardware/" target="_blank">vast majority of your bugs should be caught by your automated test suite</a> and/or QA process. And the last few stragglers should be handled using <a rel="noreferrer noopener" aria-label="incremental deployments, production alarms and rollbacks (opens in a new tab)" href="https://software.rajivprab.com/2019/11/25/the-birth-of-legacy-software-how-change-aversion-feeds-on-itself/" target="_blank">incremental deployments, production alarms and rollbacks</a>.</p>



<p>Besides, as soon as any problem is detected, the recommendation at places like Google is to <a rel="noreferrer noopener" aria-label="rollback first and ask questions later (opens in a new tab)" href="https://cloud.google.com/blog/products/gcp/reliable-releases-and-rollbacks-cre-life-lessons" target="_blank">rollback first and investigate the problem later</a>:</p>



<blockquote><p><em>We have seen this at Google any number of times, where a hastily deployed roll-forward fix either fails to fix the original problem, or indeed makes things worse. Even if it fixes the problem it may then uncover other latent bugs in the system; you’re taking yourself further from a known-good state, into the wilds of a release that hasn’t been subject to the regular strenuous QA testing. At Google, our philosophy is that “rollbacks are normal.” When an error is found or reasonably suspected in a new release, the releasing team rolls back first and investigates the problem second</em></p></blockquote>



<p> When things are on fire, the last thing you want to do is root-cause the bug and figure out which flag-flip will safely fix the problem. And that may not even fix things – there’s no guarantee that even if your teammate tried to put his changes behind a feature flag, he didn’t inadvertently introduce a bug that cannot be solved by a flag-flip.</p>



<p>Feature flags are a poor man’s alternative to binary rollbacks, and they definitely aren’t a substitute for having a great automated test suite and a robust QA process. If you’re relying on feature flags to remedy production bugs, you should stop and evaluate your team’s practices. Risk aversion is often a smell of your team <a rel="noreferrer noopener" aria-label="entering into a doom loop which will only get worse and worse with time (opens in a new tab)" href="https://software.rajivprab.com/2019/11/25/the-birth-of-legacy-software-how-change-aversion-feeds-on-itself/" target="_blank">entering into a doom loop which will only get worse and worse with time</a>.</p>



<h2>Death By Feature Flags</h2>



<p>You may be wondering at this point why we shouldn’t use feature flags anyway. After all, <em>“defense in depth” …</em> and it never hurts to have more fine-grain flexibility right?</p>



<p>While feature flags are great in some cases, we should also keep in mind their costs. Software engineering is primarily an exercise in managing complexity. And each feature flag immediately doubles the universe of corner cases that your programmers have to understand, and your code is required to handle. <em>“But what would happen if Foo is enabled, Bar is disabled, and we do independent A/B tests on Baz and Kaz on the same day?”</em> In my experience, this combinatorial explosion in complexity can and <strong>will</strong> lead to bugs. Not to mention slowing down the speed at which your team can make any changes.</p>



<p><a rel="noreferrer noopener" href="https://news.ycombinator.com/item?id=24549917" target="_blank">To quote an amusing anecdote shared online</a>: <em>“A flag that hasn’t been set to off in a year can be masking a major regression. At my last job we had two major outages in as many years from defunct flags defaulting to ‘off’ when the feature flag system failed to return flag states.”</em></p>



<p><em>“But these feature flags are only temporary. You should be removing them as soon as possible!”</em></p>



<p>Sure, and we should also not allow our tech debt to accumulate and we should follow every single best-practice religiously. Unfortunately, this never happens in any corporate environment. Even in great teams, tech debt often gets de-prioritized in the face of new requests. Newcomers to the team or those on their way out, aren’t always disciplined enough to clean up their flags after a successful rollout. And sometimes, these tasks simply slip through the cracks and get forgotten.</p>



<p><a rel="noreferrer noopener" href="https://news.ycombinator.com/item?id=24549917" target="_blank">Someone on HackerNews has pointed out</a> that as of Sept-2020, the release version of Windows <em>“has roughly 2500 feature flags. Some are permanently jammed into the on position, some off position, and the rest are configurable by its experimentation frameworks and hackers”</em>.</p>



<p>There is no better illustration of this than the KCG debacle where a financial firm lost half a billion dollars and almost went bankrupt in 30 minutes, partly due to dead code that was behind a feature flag.</p>



<blockquote><p><a href="https://www.bugsnag.com/blog/bug-day-460m-loss"><em>The cause of the failure</em></a><em> was due to multiple factors. However, one of the most important was that a flag which had previously been used to enable Power Peg… Power Peg had been obsolete since 2003, yet still remained in the codebase some eight years later.</em></p><p><em>In 2005, an alteration was made to the Power Peg code which inadvertently disabled safety-checks which would have prevented such a scenario. However, this update was deployed to a production system at the time, despite no effort having been made to verify that the Power Peg functionality still worked</em></p></blockquote>



<hr>



<p>Feature flags are a powerful tool that can help you experiment with new features, manage the rollout of complex epics, and mitigate the problems associated with not controlling your team’s deployments. </p>



<p>But they come at a significant cost, in the form of code complexity, tech debt, slower development speeds, and inevitably, bugs. </p>



<p>As tempting as it may be, there is no silver bullet here. Weigh the pros against the cons, and use this tool judiciously when it makes sense to do so.</p>



<hr>



<p><a rel="noreferrer noopener" href="https://www.reddit.com/r/programming/comments/i5zbvk/when_feature_flags_do_and_dont_make_sense/" target="_blank"><em>Discussion thread on /r/programming</em></a><br><em><a href="https://news.ycombinator.com/item?id=24549917" target="_blank" rel="noreferrer noopener">Discussion thread on Hacker News</a></em></p>
	</div></div>]]>
            </description>
            <link>https://software.rajivprab.com/2019/12/19/when-feature-flags-do-and-dont-make-sense/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24549917</guid>
            <pubDate>Tue, 22 Sep 2020 01:11:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Things we learned running Postgres 13]]>
            </title>
            <description>
<![CDATA[
Score 351 | Comments 48 (<a href="https://news.ycombinator.com/item?id=24544881">thread link</a>) | @lfittl
<br/>
September 21, 2020 | https://pganalyze.com/blog/postgres13-better-performance-monitoring-usability | <a href="https://web.archive.org/web/*/https://pganalyze.com/blog/postgres13-better-performance-monitoring-usability">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span>
      <a href="https://pganalyze.com/static/c19e088b51f042e5749d96ace57df97b/aa440/postgres_13.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="postgres 13" title="Astronaut writing Postgres 13" src="https://pganalyze.com/static/c19e088b51f042e5749d96ace57df97b/8c557/postgres_13.png" srcset="https://pganalyze.com/static/c19e088b51f042e5749d96ace57df97b/4edbd/postgres_13.png 175w, https://pganalyze.com/static/c19e088b51f042e5749d96ace57df97b/13ae7/postgres_13.png 350w, https://pganalyze.com/static/c19e088b51f042e5749d96ace57df97b/8c557/postgres_13.png 700w, https://pganalyze.com/static/c19e088b51f042e5749d96ace57df97b/e996b/postgres_13.png 1050w, https://pganalyze.com/static/c19e088b51f042e5749d96ace57df97b/2cefc/postgres_13.png 1400w, https://pganalyze.com/static/c19e088b51f042e5749d96ace57df97b/aa440/postgres_13.png 1500w" sizes="(max-width: 700px) 100vw, 700px" loading="lazy">
  </a>
    </span>
</p>
<p>Postgres 13 is almost here. It's been in beta since May, and the general availability release is
coming any day. We've been following Postgres 13 closely here at pganalyze, and have been running
the beta in one of our staging environments for several months now.</p>
<p>There are no big new features in Postgres 13, but there are a lot of small but important incremental
improvements. Let's take a look.</p>

<h2 id="performance"><a href="#performance" aria-label="performance permalink"></a>Performance</h2>
<p>Postgres 13 performance improvements include both built-in optimizations and heuristics that will make
your database run better out of the box, as well as additional features to give you more flexibility
in optimizing your schema and queries.</p>
<h3 id="smaller-indexes-with-b-tree-deduplication"><a href="#smaller-indexes-with-b-tree-deduplication" aria-label="smaller indexes with b tree deduplication permalink"></a>Smaller Indexes with B-Tree Deduplication</h3>
<!-- -->

<svg xmlns:xl="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" xmlns:dc="http://purl.org/dc/elements/1.1/" version="1.1" viewBox="222 230.5 630.072 116" width="630.072" height="116">
  <defs>
    <font-face font-family="Avenir Next" font-size="16" panose1="2 11 5 3 2 2 2 2 2 4" units-per-em="1000" underline-position="-75" underline-thickness="50" slope="0" x-height="468" cap-height="708" ascent="1000" descent="-365.9973" font-weight="400">
      <font-face-src>
        <font-face-name name="AvenirNext-Regular"></font-face-name>
      </font-face-src>
    </font-face>
    <font-face font-family="Avenir Next" font-size="16" panose1="2 11 8 3 2 2 2 2 2 4" units-per-em="1000" underline-position="-75" underline-thickness="50" slope="0" x-height="498" cap-height="708" ascent="1000" descent="-365.9973" font-weight="700">
      <font-face-src>
        <font-face-name name="AvenirNext-Bold"></font-face-name>
      </font-face-src>
    </font-face>
  </defs>
  <metadata> Produced by OmniGraffle 7.17.2\n2020-09-20 19:29:10 +0000</metadata>
  <g id="Canvas_1" strokedasharray="none" stroke-opacity="1" stroke="none" fill="none" fill-opacity="1">
    <title>Canvas 1</title>
    <g id="Canvas_1_Layer_1">
      <title>Layer 1</title>
      <g id="Graphic_2">
        <rect x="232" y="240.5" width="250.5" height="39.5" fill="#d8d5df"></rect>
      </g>
      <g id="Graphic_3">
        <rect x="232" y="297" width="89.5" height="39.5" fill="#d8eef0"></rect>
      </g>
      <g id="Graphic_9">
        <text transform="translate(244.128 251.026)" fill="black">
          <tspan font-family="Avenir Next" font-size="16" font-weight="400" fill="black" x="0" y="16"></tspan>
        </text>
      </g>
      <g id="Graphic_10">
        <text transform="translate(244.128 309.013)" fill="black">
          <tspan font-family="Avenir Next" font-size="16" font-weight="400" fill="black" x="0" y="16"></tspan>
        </text>
      </g>
      <g id="Graphic_13">
        <text transform="translate(502 251.026)" fill="black">
          <tspan font-family="Avenir Next" font-size="16" font-weight="400" fill="black" x="0" y="16">deduplicate_items=off</tspan>
        </text>
      </g>
      <g id="Graphic_14">
        <text transform="translate(502 307.526)" fill="black">
          <tspan font-family="Avenir Next" font-size="16" font-weight="400" fill="black" x="0" y="16">deduplicate_items=on   </tspan>
          <tspan font-family="Avenir Next" font-size="16" font-weight="700" fill="black" y="16">(new in Postgres 13)</tspan>
        </text>
      </g>
    </g>
  </g>
</svg>
<p>Postgres 13 introduces a way for B-Tree indexes to <a href="https://www.postgresql.org/docs/13/btree-implementation.html#BTREE-DEDUPLICATION">avoid storing duplicate entries in some situations</a>.
In general, a B-Tree index consists of a tree of indexed values, with each leaf node pointing to a
particular row version. Because each leaf points to one row version, if you are indexing non-unique
values, those values need to be repeated.</p>
<p>The de-duplication mechanism avoids that by having a leaf node point to several row versions if possible,
which leads to smaller indexes.</p>
<p>Here is an example from our own pganalyze application schema: We have a <code>queries</code> table to
track all the queries we monitor, and a <code>database_id</code> field to track which database they belong to. We
index <code>database_id</code> (so we can quickly fetch queries for a specific database), and because each database
typically has more than one query, there is a lot of duplication in this index.</p>
<p>New B-Tree indexes in Postgres 13 use the deduplication feature by default, but if for some reason,
you need to turn it off, you can control it with the <code>deduplicate_items</code> storage parameter. Here we
create the same index in two different ways, with deduplication explicitly on and off (though again,
you don't need to specify <code>on</code>—this is the default):</p>
<div data-language="sql"><pre><code><span>CREATE</span> <span>INDEX</span> CONCURRENTLY queries_db_id_idx_no_dedup <span>ON</span> queries<span>(</span>database_id<span>)</span>
<span>WITH</span> <span>(</span>deduplicate_items<span>=</span><span>off</span><span>)</span><span>;</span>

<span>CREATE</span> <span>INDEX</span> CONCURRENTLY queries_db_id_idx_yes_dedup <span>ON</span> queries<span>(</span>database_id<span>)</span>
<span>WITH</span> <span>(</span>deduplicate_items<span>=</span><span>on</span><span>)</span><span>;</span>

<span>SELECT</span> relname<span>,</span> pg_size_pretty<span>(</span>pg_relation_size<span>(</span>oid<span>)</span><span>)</span> <span>FROM</span> pg_class
<span>WHERE</span> relname <span>IN</span> <span>(</span><span>'queries_db_id_idx_no_dedup'</span><span>,</span> <span>'queries_db_id_idx_yes_dedup'</span><span>)</span><span>;</span></code></pre></div>
<div data-language="text"><pre><code>           relname           | pg_size_pretty 
-----------------------------+----------------
 queries_db_id_idx_no_dedup  | 218 MB
 queries_db_id_idx_yes_dedup | 67 MB
(2 rows)</code></pre></div>
<p>With deduplication, the new index is more than <strong>three times smaller</strong>! Smaller indexes are faster to load
from disk, and take up less space in memory, meaning there's more room for your data.</p>
<p>One interesting note here is that the index entries point to row <em>versions</em> (as in, a row the way it
exists in one specific <a href="https://www.postgresql.org/docs/13/mvcc.html">MVCC</a> state), not rows themselves,
so this feature <strong>can improve index size even for unique indexes</strong>, where one would not expect any duplication
to occur.</p>
<p>Note that deduplication is not possible in all cases (see above link for details), and that you
will need to reindex before you can take advantage of it if upgrading via <code>pg_upgrade</code>.</p>
<h3 id="extended-statistics-improvements-in-postgres-13"><a href="#extended-statistics-improvements-in-postgres-13" aria-label="extended statistics improvements in postgres 13 permalink"></a>Extended Statistics Improvements in Postgres 13</h3>
<p>Postgres 10 introduced the concept of <a href="https://www.postgresql.org/docs/13/planner-stats.html#PLANNER-STATS-EXTENDED">extended statistics</a>. Postgres keeps some statistics about the "shape" of your data to ensure it can plan queries efficiently,
but the statistics kept by default cannot track things like inter-column dependencies. Extended statistics
were introduced to address that: These are database objects (like indexes) that you create manually with
<code>CREATE STATISTICS</code> to give the query planner more information for more specific situations. These would be
expensive for Postgres to determine automatically, but armed with an understanding of the semantics of your
schema, you can provide that additional info. Used carefully, this can lead to
<a href="https://build.affinity.co/how-we-used-postgres-extended-statistics-to-achieve-a-3000x-speedup-ea93d3dcdc61">massive performance improvements</a>.</p>
<p>Postgres 13 brings a number of small but important improvements to extended statistics, including
support for using them with <code>OR</code> clauses and in <code>IN</code>/<code>ANY</code> constant lists, allowing consideration
of multiple extended statistics objects in planning a query, and support for
<a href="https://www.postgresql.org/docs/13/sql-alterstatistics.html">setting a statistics target</a> for
extended statistics:</p>
<div data-language="sql"><pre><code><span>ALTER</span> <span>STATISTICS</span> table_stx <span>SET</span> <span>STATISTICS</span> <span>1000</span><span>;</span></code></pre></div>
<p>Like with the regular statistics target, this is a trade-off between additional planning time (and longer <code>ANALYZE</code> runs), versus having more precise plans. We recommend using this in a targeted manner using EXPLAIN plans to confirm plan changes.</p>
<h3 id="parallel-vacuum--better-support-for-append-only-workloads"><a href="#parallel-vacuum--better-support-for-append-only-workloads" aria-label="parallel vacuum  better support for append only workloads permalink"></a>Parallel VACUUM &amp; Better Support for Append-only Workloads</h3>
<p>Postgres multi-version concurrency control means you need to run <code>VACUUM</code> regularly (usually you can rely
on the autovacuum process, though it may need some tuning). In Postgres 13, one notable improvement is
that multiple indexes for a single table can be vacuumed in parallel. This can lead to big performance
improvements in <code>VACUUM</code> work. Parallel <code>VACUUM</code> is the default and can be controlled with the <code>PARALLEL</code> option:</p>
<div data-language="sql"><pre><code>VACUUM <span>(</span>PARALLEL <span>2</span><span>,</span> VERBOSE<span>)</span> queries<span>;</span></code></pre></div>
<div data-language="text"><pre><code>INFO:  vacuuming "public.queries"
INFO:  launched 2 parallel vacuum workers for index vacuuming (planned: 2)
INFO:  scanned index "index_queries_on_database_id" to remove 1403418 row versions by parallel vacuum worker
DETAIL:  CPU: user: 0.98 s, system: 0.15 s, elapsed: 2.37 s
INFO:  scanned index "index_queries_on_last_occurred_at" to remove 1403418 row versions by parallel vacuum worker
DETAIL:  CPU: user: 0.88 s, system: 0.27 s, elapsed: 2.60 s
...</code></pre></div>
<p>Parallel VACUUM occurs when the following is true:</p>
<ul>
<li>Sufficient parallel workers are available, based on the system-wide limit set by <a href="https://www.postgresql.org/docs/13/runtime-config-resource.html#GUC-MAX-PARALLEL-WORKERS-MAINTENANCE"><code>max_parallel_maintenance_workers</code></a> (defaults to 2)</li>
<li>There are multiple indexes on the table (one index can be processed by one worker at a time)</li>
<li>Index types support it (all built-in index types support parallelism to some extent)</li>
<li>The indexes are large enough to exceed <a href="https://www.postgresql.org/docs/13/runtime-config-query.html#GUC-MIN-PARALLEL-INDEX-SCAN-SIZE"><code>min_parallel_index_scan_size</code></a> (defaults to 512 kB)</li>
</ul>
<p>Be aware that <strong>parallel VACUUM is currently not supported for autovacuum.</strong> This new feature is intended for use in manual VACUUM runs that need to complete quickly, such as when insufficient autovacuum tuning has lead to an imminent TXID wraparound, and you need to intervene to fix it.</p>
<p>On that note, an important <code>autovacuum</code> improvement in Postgres 13 is that the autovacuum background process can now be triggered by <code>INSERT</code> statements for append-only tables. The main purpose of VACUUM is to clean up old versions of updated and deleted rows, but it is also essential to set pages as all-visible for MVCC bookkeeping. All-visible pages allow index-only scans to avoid checking visibility status row-by-row, making them faster.</p>
<p>We make extensive use of append-only tables at pganalyze for our timeseries data, and this improvement will make our lives considerably easier, avoiding the occasional manual VACUUM run on these tables. This new behavior can be controlled by the <code>autovacuum_vacuum_insert_threshold</code> and <code>autovacuum_vacuum_insert_scale_factor</code> variables.</p>
<h3 id="incremental-sorting"><a href="#incremental-sorting" aria-label="incremental sorting permalink"></a>Incremental Sorting</h3>
<p>Sorting data is a common database task, and Postgres has a number of features to avoid unnecessary work
here. For example, if you have a B-Tree index on a column, and you query your table ordered by that column,
it can just scan that index in order to get sorted data.</p>
<p>In Postgres 13, this is improved to handle partially sorted data. If you have an index on <code>(a, b)</code> (or
the data is already sorted by <code>(a, b)</code> for another reason), and you issue a query to order by <code>(a, b, c)</code>,
Postgres understands that the input data is already partially sorted, and can avoid re-sorting the whole
dataset. This is especially useful if you have a <code>LIMIT</code> in your query, since this can avoid even more
work.</p>
<h2 id="monitoring"><a href="#monitoring" aria-label="monitoring permalink"></a>Monitoring</h2>
<p>Monitoring improvements in Postgres 13 include more details on <code>WAL</code> usage, more options for logging your
queries, and more information on query planning.</p>
<h3 id="wal-usage-stats"><a href="#wal-usage-stats" aria-label="wal usage stats permalink"></a>WAL Usage Stats</h3>
<p>The write-ahead log (<code>WAL</code>) ensures your data stays consistent in the event of a crash, even mid-write. Consistency
is a fundamental property of databases—it ensures your transaction either committed or did not commit; you don't
have to worry about in-between states. But on a busy system, <code>WAL</code> writes can often be a bottleneck. To help
diagnose this, Postgres 13 includes more information on <code>WAL</code> usage from your queries.</p>
<p><code>EXPLAIN</code> now supports information about <code>WAL</code> records generated during execution:</p>
<div data-language="sql"><pre><code><span>EXPLAIN</span> <span>(</span><span>ANALYZE</span><span>,</span> WAL<span>)</span> <span>DELETE</span> <span>FROM</span> users<span>;</span></code></pre></div>
<div data-language="text"><pre><code>                                                    QUERY PLAN                                                     
-------------------------------------------------------------------------------------------------------------------
 Delete on users  (cost=0.00..5409.00 rows=100000 width=6) (actual time=108.910..108.911 rows=0 loops=1)
   WAL: records=100000 fpi=741 bytes=11425721
   -&gt;  Seq Scan on users  (cost=0.00..5409.00 rows=100000 width=6) (actual time=8.519..51.850 rows=100000 loops=1)
 Planning Time: 6.083 ms
 Execution Time: 108.955 ms
(5 rows)</code></pre></div>
<p>You can see that the <code>WAL</code> line includes the number of records generated, the number of full page images (fpi), and
the number of <code>WAL</code> bytes generated. Only non-zero values are printed in the default text format.</p>
<p>This is also available in <code>pg_stat_statements</code>. For example, on our staging environment, here is what we ran to get
the statement that produced the most <code>WAL</code> records:</p>
<div data-language="sql"><pre><code><span>SELECT</span> query<span>,</span> calls<span>,</span> wal_records<span>,</span> wal_fpi<span>,</span> wal_bytes <span>FROM</span> pg_stat_statements
  <span>ORDER</span> <span>BY</span> wal_records <span>DESC</span> <span>LIMIT</span> <span>1</span><span>;</span></code></pre></div>
<div data-language="text"><pre><code>-[ RECORD 1 ]---------------------------------------------------------------------------------------------
query       | CREATE TEMPORARY TABLE upsert_data (server_id uuid NOT NULL, backend_id uuid NOT NULL,
            | query_start timestamp NOT NULL, query_fingerprint bytea NOT NULL, query_text text NOT NULL)
calls       | 7974948
wal_records | 966960816
wal_fpi     | 1018412
wal_bytes   | 100086092097</code></pre></div>
<p>Like many other values in <code>pg_stat_statements</code>, the <code>wal_records</code>, <code>wal_fpi</code>, and <code>wal_bytes</code> values here are
cumulative since the last <code>pg_stat_statements_reset</code> call.</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pganalyze.com/blog/postgres13-better-performance-monitoring-usability">https://pganalyze.com/blog/postgres13-better-performance-monitoring-usability</a></em></p>]]>
            </description>
            <link>https://pganalyze.com/blog/postgres13-better-performance-monitoring-usability</link>
            <guid isPermaLink="false">hacker-news-small-sites-24544881</guid>
            <pubDate>Mon, 21 Sep 2020 15:57:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is revenue model more important than culture?]]>
            </title>
            <description>
<![CDATA[
Score 219 | Comments 111 (<a href="https://news.ycombinator.com/item?id=24543510">thread link</a>) | @Ozzie_osman
<br/>
September 21, 2020 | https://somehowmanage.com/2020/09/20/revenue-model-not-culture-is-the-dominant-term/ | <a href="https://web.archive.org/web/*/https://somehowmanage.com/2020/09/20/revenue-model-not-culture-is-the-dominant-term/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-101">

	

	
	<div>
		
<p>I always loved getting problems of the type “What is the limit as x approaches infinity” type in high-school/college. You’re given an equation (of the classic y=x format), and asked to derive what the value of y will be as x grows to infinity.</p>



<p>One thing you learn pretty quickly about these types of problems is that often it doesn’t matter where the function “starts” (or where it is at small values of x). It could start at zero, or at negative infinity, but its limit might be infinity, and vice versa (it could start large but have a limit of zero or negative infinity).</p>



<p>In fact, for many equations, there’s usually one <strong>dominant term</strong>. This is the term that dominates the limit. There might be countless other factors or parts of the equation that matter initially, but eventually it’s that dominant term that wins. This is sometimes known as the <strong>dominant term rule</strong>. We’ll get back to this in a second.</p>



<h3>Ads vs. Search</h3>



<p>Google had a little press kerfuffle a few months ago. You can read a summary in the New York Times <a href="https://www.nytimes.com/2020/01/31/technology/google-search-results.html">here</a>, but the short of it is that the company launched a design change that made search results and ads look very similar. Presumably, this increased revenue for Google, since many people ignore ads when they can easily identify them, the same way you’d ignore stepping in dog crap if you can identify it in the mud (and yes, given the state of online ads and content I pick this analogy deliberately). But there was a pretty strong backlash against this as a “dark pattern” designed to trick users. After the negative press, Google walked back the change.</p>



<p>If you’ve been following the news around big tech companies these past couple of years, this type of behavior is not surprising at all. These companies have grown really large, are arguably monopolistic, and hyper-focused on growth and revenue. Over and over, they have made decisions that have resulted in backlash from the press and from their users.</p>



<p>On the other hand, if I ignore the past ten years, and jump back to when I worked at Google as an entry-level Software Engineer, it is a <em>little</em> surprising to me. I worked at Google from 2006-2009. At the time, it was already a rapidly-growing public company (I think I joined when there were around 8,000 employees, and left when there were 20,000). I initially worked on the team responsible for AdWords, so I had some exposure to the culture and decisions that were made at the time (of course it wasn’t <em>deep</em> exposure, since I was an entry-level Software Engineer on the lowest rung of the ladder… but it was exposure nonetheless).</p>



<p><em>Note: I’m going to pick on Google a little bit here, but I do love that company. I think there’s a lot it can improve on, but it’s still one of my favorite and least “evil” large tech company. I chose them simply because I’m more familiar with them.</em></p>



<p>At the time, Google employees might have argued against making a change because it was “evil”. The “don’t be evil” motto was still around, and as engineers who were building parts of the product and making decisions, we were pretty ideological about it. One of the company’s values was also to put users first, employees second, and shareholders third. By any of these lenses, the type of design change that Google got flak for recently would have been highly unlikely at the time.</p>



<h3>Revenue is the Dominant Term</h3>



<p>Let’s take a dominant term view of this problem. When a company is first built, several variables dictate its decisions:</p>



<ul><li>The <em>implicit </em>values/culture of the early team. As Ben Horowitz would say, “what you do is who you are.”&nbsp;</li><li>The <em>explicit </em>values/culture of the early team. Are we user-centric? Data-driven? …</li><li>The revenue model.</li></ul>



<p>I think that over time, the revenue model is the dominant term. The limit of a product towards infinity, so to speak, is based on its revenue model. If your revenue model is ads, it doesn’t matter if your stated mission is “to organize the world’s knowledge and make it universally accessible and useful”, “to give people the power to build community and bring the world closer together”, or anything else. If your revenue model is ads, you are an ads company.</p>



<p>I’m not diminishing the role of culture and values. I think those are critical. Part of me would love to believe the hundreds of books written on how culture determines everything. But I don’t. At least not for companies that can hire some of the smartest people in the world, gather massive amounts of data, and build technology more sophisticated than ever. And be trying to “maximize shareholder value”.</p>



<p>I’ve actually agonized over whether culture or revenue are the dominant term. In fact, I agonized so much that I’ve had this article in my head for years, and in a Google Doc for months, but I couldn’t get myself to write it / publish it. Because part of me believes culture always wins. Actually, <em>all</em> of me <em>wants </em>to believe culture <em>always</em> wins. But I’ve had my idealism crushed enough times by hard realities.&nbsp;</p>



<p>Yes, having and espousing a positive culture and set of values are important. And they may shape how and how quickly the revenue model dominates (for example, companies like Enron or pre-IPO Uber show how bad things can get if you have a terrible culture). But regardless of your mission statement, your culture, your values, and so on, if you choose the wrong revenue model, it will dominate them in a shareholder-value-driven, capitalistic society. Culture can only dominate if it’s negative. A positive culture <em>is </em>necessary, but it’s not sufficient.</p>



<p><em>In other words, over the long term, a company (and its product) will morph to take the shape of its revenue streams.</em></p>



<h3>Charlie Munger Knew It</h3>



<p>Charlie Munger, Warren Buffet’s business partner, has a pretty famous speech where he talks about the power of incentives.</p>



<blockquote><p>“Well I think I’ve been in the top 5% of my age cohort all my life in understanding the power of incentives, and all my life I’ve underestimated it. And never a year passes, but I get some surprise that pushes my limit a little farther.” —<a href="https://fs.blog/2013/02/the-psychology-of-human-misjudgement/">Charlie Munger</a></p></blockquote>



<p>Charlie gives several examples: for instance, FedEx needed to move/sort their packages more quickly, so instead of paying employees per hour, they paid them per shift: productivity increased dramatically (employees now had less incentive to take longer hours to do the same amount of work). Charlie’s model of human behavior is pretty simple: we follow incentives. He makes people sound almost coin-operated.</p>



<p>Now, this isn’t entirely true—there are plenty of examples and research showing that our behavior is more complicated than simple incentives would predict. But Charlie is arguably one of the best investors in the world, and he’s onto something. Even though there might be other variables that influence our behavior, you can still simplify things down to incentives. Incentives are his dominant term.</p>



<p>That incentives are dominant is actually pretty obvious to a lot of people. Somehow in the tech industry, we seem to have just clouded our own judgement through some sense of moral superiority. We care about the impact we’re having on the world. We have noble missions that we rally around and try to hire people who are excited by them. So far, so good. But then we shoot ourselves in the foot by setting up business models with misaligned incentives.</p>



<h3>Look for Aligned Business Models</h3>



<p>So what does this mean in practice? Well, if you only care about making money, it doesn’t mean much. But if you do care about more than money, if you care about the impact your work has and you want to be proud of what you do, it’s worth thinking through this a little more deeply.</p>



<p>Whether you’re starting a company or joining one, look for a business model <em>without</em> perverse incentives. A business model that sets things up so that the better a product is, the better off the company is and its users are.</p>



<p>Sometimes, counterintuitively, a business model may seem aligned at first glance, but end up being quite harmful. The classic example that we’re all now aware of is free products. Free seems great at first glance. But companies have to make money somehow. So they sell ads, or data, or some mix of the two that their users don’t quite understand. And so now, success for the company means more time spent on the product (which may or may not be a good thing for users), less privacy (definitely not a good thing for users), and ultimately more ads.*</p>



<p>So often, paid is better than free*.  At <a href="https://www.monarchmoney.com/">Monarch Money</a>, my current startup, we’ve chosen to go with a paid model, with a hope that we’ll be more aligned in creating value for our users (who we can now call customers… notice how there’s a word for “customer service”, but no “user service”?). There will still be plenty of forks in the road where we can decide whether we help our customers, or take advantage of them, and I hope our values will help us navigate those forks, but at least the revenue model is in our favor.</p>



<p>Another layer to consider is whether your product and revenue model help people with just short-term goals, or a mix of both short and long-term goals. Products that are great and helpful, help their users with both. Good products might help with one or the other. The products with the most potential for damage provide some short-term benefit at the <em>expense</em> of longer-term goals.</p>



<p>So when you consider starting or joining a company, look at the business model, and do the “limit math”. Think about what things might look like if you become massively successful, because you might be.</p>



<hr>



<p><em>*This is an opinion piece. I had to draw a lot of simplifications to keep this article short. A lot of statements are definitely not universally true, but are true enough that they’re worth using as examples.</em></p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://somehowmanage.com/2020/09/20/revenue-model-not-culture-is-the-dominant-term/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24543510</guid>
            <pubDate>Mon, 21 Sep 2020 13:58:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Designed in Minecraft, Built IRL]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24542830">thread link</a>) | @donohoe
<br/>
September 21, 2020 | https://restofworld.org/2020/rebuilding-gaza-with-minecraft/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/rebuilding-gaza-with-minecraft/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>Most Sundays, Somia Hamdan visits her local park with her two friends, Amal and Laima. They sit on a picnic bench opposite one another and chat neurotically about Twitter and local gossip. Hamdan is there to socialize but also to supervise. “Since I created the space,” Hamdan said, “I like to take care of it.”</p>



<p>At 23, living in Gaza, Hamdan has been blighted by three brutal conflicts with Israel, decades of protests, a cycle of rocket fire between Israel and Gaza’s rulers, Hamas, and infighting between Palestinian factions. She faces one of the <a href="https://www.unrwa.org/where-we-work/gaza-strip">worst employment rates</a> in the world, <a href="https://www.unrwa.org/activity/education-gaza-strip">oversubscribed schools</a>, and a territory in which movement is tightly controlled and more than half the population <a href="https://www.theyworkforyou.com/wrans/?id=2020-01-23.7154.h&amp;p=11132">lives on less than $5.50 per day.</a> Live concerts and movie theaters are rare, imports and exports restricted, and <a href="https://www.un.org/unispal/humanitarian-situation-in-the-gaza-strip-fast-facts-ocha-factsheet/">children often used, and killed, for smuggling.</a></p>



<p>Though Hamdan and most of her peers have mobile phones — a lifeline for connecting with the outside world — power cuts are relentless: Az-Zawayda, her home in Deir al-Balah of some 25,000, often has barely <a href="https://www.hrw.org/news/2017/08/20/gaza-we-get-four-hours-electricity-day-if-were-lucky">four hours of electricity a day</a>. “There’s little to do here,” Hamdan said.</p>



<p>Before 2018, Hamdan had certainly never played a video game. That year, she learned to play Minecraft, the wildly popular computer game<strong> </strong>in which players make things out of blocks — but not purely for fun. In 2012, U.N.-Habitat, Microsoft, and Mojang, the company that made Minecraft, teamed up on <a href="https://www.blockbyblock.org/about">Block by Block</a>, a venture that aims to improve marginalized areas by actively engaging community members in public projects. According to the U.N., more than 17,000 people have participated in Block by Block initiatives in around 100 different countries — including three<strong> </strong>projects in Gaza — improving hundreds of thousands of lives in the process.&nbsp;</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/2017-08-23_12.58.05-40x29.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/2017-08-23_12.58.05-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/2017-08-23_12.58.05-400x286.jpg 400w, https://restofworld.org/wp-content/uploads/2020/09/2017-08-23_12.58.05-600x429.jpg 600w, " sizes="(max-width: 640px) 100vw, 600px(max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<p>Using Minecraft’s building blocks, community groups design a virtual public space, later made into concrete reality. From parks to beaches and even streets themselves, these spaces are a key indicator of the health and sustainability of cities.<strong> </strong>“If made safe, accessible, and welcoming, they can be drivers of civic cohesion, biodiversity, livelihood, and economic growth,” Christelle Lahoud, 30, a program management officer for U.N.-Habitat, told <em>Rest of World</em>. “If not, we tend to see more crime and pollution, reduced productivity, and general social disparities.”&nbsp;</p>



<p>Participants in the Gaza experiment were selected by the Aisha Association for Women and Child Protection, an independent organization and project partner working to achieve gender integration in Gaza. Promising candidates were motivated, interested, and hungry for change.&nbsp;</p>



<p>Hamdan was one of 42 others — young women, mostly — given the chance to imagine a virtually designed town center through the game.<strong> </strong>The project aimed to design and build a community garden for Az-Zawayda — a modest goal.</p>



<p>Fatma Zoqlam, 18, and her sister, Ghada, 17, also made the cut, much to the approval of their mother. “She was all, like, ‘You have to do it! It will improve your confidence! And communication!’” Fatma, wearing a floral hijab and bright-purple dress, told <em>Rest of World</em> over Skype. “Not that I needed persuading.”&nbsp;</p>



<p>But Ghada, a tad more shy, wasn’t quite as up for it. “It made me feel nervous, working in a team with strangers,” she said. The first day, the group visited the space, which was only sand, ruins, and unlit roads. “I stood there and thought, This isn’t going to work,” Fatma said.&nbsp;</p>



<p>The architects introduced the world of Minecraft. “Most of us had never played a video game before,” Hamdan said, “but it was surprisingly user-friendly.” They were split into groups of four. “We took turns figuring out the keys, playing around,” Ghada said. “Once I got going, I didn’t want to stop.”&nbsp;</p>



<p>On the second day, things got heated. Keen to impress teammates, the decision-making adults in the room, and their family and friends, things got competitive. “I wanted to have the optimal design. … Because then my work could be reflected in the actual space!” Fatma said. She leaned forward, “I wanted to be able to say to everyone I knew, I made that!”</p>


    <figure>
      <div>
				<ul>
					<li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/1-41-40x29.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/1-41-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/1-41-400x286.jpg 400w, https://restofworld.org/wp-content/uploads/2020/09/1-41-600x429.jpg 600w, https://restofworld.org/wp-content/uploads/2020/09/1-41-1000x714.jpg 1000w, https://restofworld.org/wp-content/uploads/2020/09/1-41-1600x1143.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/09/1-41-2800x2000.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li><li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/2-21-40x29.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/2-21-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/2-21-400x286.jpg 400w, https://restofworld.org/wp-content/uploads/2020/09/2-21-600x429.jpg 600w, https://restofworld.org/wp-content/uploads/2020/09/2-21-1000x714.jpg 1000w, https://restofworld.org/wp-content/uploads/2020/09/2-21-1600x1143.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/09/2-21-2800x2000.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li>
				</ul>
			</div>
      <figcaption>Az-Zawayda Community Garden officially opened on December 31, 2018. Photos courtesy of Project Team.</figcaption>
    </figure>


<p>“I wanted technical approval,” Ghada said. “My group was, er, leader-heavy, though. A boy took charge. He was like, ‘We need to do this, this, and this.’”</p>



<p>What the group concluded was that protective measures were a priority. “We discussed safety a lot,” Hamdan said. “Me and my friends feel scared to leave the house alone. The threat of sexual assault is too much.” (Around 51% of women in Gaza are victims of gender-based violence.) They needed lighting, fencing, security (including a guard), and a separate area for women and families. “The fence was my input,” Ghada said.&nbsp;</p>



<p>For Fatma, aesthetics mattered — plants, trees, a proud fountain. Her team also made a cafeteria and installed<strong> </strong>municipal Wi-Fi to keep residents connected, along with solar panels.&nbsp;</p>



<p>Three female Palestinian architects brought the park to fruition. One of them, Tasneem Omar, 29, described the process as “genuinely eye-opening.” Despite Minecraft’s limitations — the game allows players to use only blocks, no curved shapes — the women’s 3D efforts made her job far simpler.&nbsp;</p>



<p>As the workshop came to a close, Omar drew up a schematic<strong> </strong>for a park based on the team’s work and handed it over to a group of selected contractors. Save for the Wi-Fi — which was costly and might detract from the community experience of the park — they used almost everything in the team’s design.</p>



<p>On December 31, 2018, Az-Zawayda Community Garden opened. Representatives from civil society organizations in the Gaza Strip, local and international NGOs, local universities, and workshop participants attended the launch. “It was a great feeling,” said Hamdan. “I gave a speech, something I wouldn’t have had the confidence to do before.”&nbsp;</p>



<p>Since then, additional projects have begun in Kosovo, Nepal, Lebanon, and Guinea; initiatives in Mozambique, South Africa, Ethiopia, Vietnam, Bangladesh, and Kyrgyzstan are currently underway. The Block by Block Foundation is also supporting coronavirus relief projects in ten affected countries.&nbsp;</p>



<p>For participants, the work is transformative. “We saw our work on the ground,” Fatma said, her eyes wide. “Nothing like this had been done before,” she added. “The municipality had never put us — the public — in charge.”</p>
		</div></div>]]>
            </description>
            <link>https://restofworld.org/2020/rebuilding-gaza-with-minecraft/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24542830</guid>
            <pubDate>Mon, 21 Sep 2020 13:04:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to catch a spy that is using a numbers station – The KGB Experience]]>
            </title>
            <description>
<![CDATA[
Score 141 | Comments 68 (<a href="https://news.ycombinator.com/item?id=24541163">thread link</a>) | @Shaddox
<br/>
September 21, 2020 | https://www.numbers-stations.com/how-to-catch-a-spy-who-uses-numbers-stations-the-kgb-experience/ | <a href="https://web.archive.org/web/*/https://www.numbers-stations.com/how-to-catch-a-spy-who-uses-numbers-stations-the-kgb-experience/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<div id="attachment_166048"><p><a href="https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135547-scaled.jpg?ssl=1"><img aria-describedby="caption-attachment-166048" src="https://i2.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135547.jpg?resize=183%2C300&amp;ssl=1" alt="" width="183" height="300" srcset="https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135547-scaled.jpg?resize=183%2C300&amp;ssl=1 183w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135547-scaled.jpg?resize=624%2C1024&amp;ssl=1 624w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135547-scaled.jpg?resize=768%2C1261&amp;ssl=1 768w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135547-scaled.jpg?resize=935%2C1536&amp;ssl=1 935w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135547-scaled.jpg?resize=1247%2C2048&amp;ssl=1 1247w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135547-scaled.jpg?w=1559&amp;ssl=1 1559w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135547-scaled.jpg?w=1500&amp;ssl=1 1500w" sizes="(max-width: 183px) 100vw, 183px" data-recalc-dims="1"></a></p><p id="caption-attachment-166048">Cover of the KGB manual. Mobile screen grab from Latvian national archive</p></div>


<p>From 2019 onwards the Latvian National Archive offers access to various KGB documents. The author had already previously shown the very detailed efforts of the Latvian KGB counterintelligence to monitor and study the CIA and BND numbers stations broadcasts, or what they called – “one directional communications”.<a href="#_ftn1" name="_ftnref1"><sup>[1]</sup></a> These are one of the most definitive archival sources which prove that foreign intelligence actively used shortwave in the USSR and that the KGB was aware of it. The documents showed that the KGB had monitored these broadcasts from at least 1978, but the files spoke very vaguely if the monitoring effort led to any apprehension and capture of a foreign agent. We, however, know that there were such cases like Alexander Ogorodnik<a href="#_ftn2" name="_ftnref2"><sup>[2]</sup></a>, and others where the use of shortwave signals was determined.</p>
<p>The Latvian National Archive digitized operational cases and also special KGB training manuals. These manuals were published for inner agency use and were never issued in public because they contained secret information. One such manual called “<em>Некоторые вопросы организаций работы по сигналам и делам оперативного учета лиц причастий в шпионажу”</em> published in 1985 by KGB of F. E Dzherzhinsky in Moscow.<a href="#_ftn3" name="_ftnref3"><sup>[3]</sup></a> (A few issues on organizing work on signals and cases recognizing persons taking part in espionage”). The manual was credited to major general A. A Fabrichinikov and colonel V.V Holopov The word “signal” in the title does not mean just a radio signal. In the KGB terminology “signal” meant a sign or report of a foreign intelligence or anti Soviet activity. If this “signal” indicated that the person is taking part in espionage he had to be investigated and evidence to be collected. The manual showed various historical cases as examples on how to apprehend and capture a foreign agent.</p>



<p>One such case was called” Case on Filatov”. Starting from page 41 the manual examples this case as one of the cases where radio communication was used between the agency and agent and how it was uncovered by counter intelligence. <strong>Anatoly N. Filatov</strong> was according to a 1981 Washington Post report sentenced in 1978 to be shot by a firing squad, though the sentence was commuted later to 15 years in prison.<a href="#_ftn4" name="_ftnref4"><sup>[4]</sup></a> A New York Times article in 1980 had rumored that A. Filatov was the same “Trigon” who is now commonly known as Alexandr Ogorodnik. The article states that A. Filatov was suspected of being discovered by the KGB counterintelligence and forced to send the CIA false information. The reasoning behind this hypothesis was that in 1977 “Trigon” went dark at the same time as A. Filatov sent a very questionable cable about Secretary of State Henry Kissinger, where he questioned the “bargaining position of president Carter” during the 1977 missile control talks.<a href="#_ftn5" name="_ftnref5"><sup>[5]</sup></a> Alexander Ogorodnik aka “Trigon” died on June 22 1977 after swallowing cyanide pills during a KGB break in.<a href="#_ftn6" name="_ftnref6"><sup>[6]</sup></a></p>
<p>David E. Hoffman, author of the book “The Million Dollar Spy” states that Filatov was arrested during a “car toss”, where a package is quickly swapped between two passing cars.<a href="#_ftn7" name="_ftnref7"><sup>[7]</sup></a> Russian author Aleksandr Kolpakidi in his book “The GRU Empire” writes that Filatov was born in 1940 in the Saratov district, joined the GRU in 1973. (GRU – the Main Intelligence Directorate – Soviet military intelligence agency) and served in Algiers where in 1974 he established contact with the CIA. Filatov had stated that his involvement with the adversary CIA happened as a result of being lured into a honey trap with a woman called Nadia, as similar happened to&nbsp; A. Ogorodnik. Either so or A. Filatov himself decided to become a double agent and started meeting CIA agent Edward Kane. In 1976 A. Filatov was called back to Moscow and the CIA had instructed him to receive shortwave coded broadcasts in German numbers from Frankfurt near Main, the broadcasts were to be carried out twice a week. Operative broadcast would be started with uneven numbers and training with even numbers. The broadcasts on precaution were carried out before A. Filatov returned to Moscow. The return message was to be carried out in a dead drop in an area near Dinamo sports stadium.</p>
<p>As the author states the coded messages contained such instructions: “Do not contain yourself with gathering information within your service only. Gain trust of friends and relatives. Visit them at their workplaces, their homes, invite them to restaurants, and with careful, clever talking gain information you could not get yourself”<a href="#_ftn8" name="_ftnref8"><sup>[8]</sup></a>. The instructions also stated that the agency is not just interested in documents with “Top Secret” on it but also common information about his department and situation in it. Filatov was arrested on the 2nd of September 1977. As A. Kolpakidi states he was first sentenced to death in 1978 but instead was sent to labor camp 389/35 near Perm. In 1989 Filatov was visited by French journalists to whom he stated that he took very high stakes risks in his life which he lost and now naturally pays for it.</p>
<p>After release he demanded compensation from the US embassy, but was denied as a non citizen. The Russian TV company TV Center in 2014 made the documentary series “Завербуй меня, если сможешь” (Contract me if you can) and featured the A. Filatov case showing various pictures of him and accounts from his colleagues, such as Anatoly Tereshchenko, colonel of the military counter intel. Tereshchenko stated that if A. Filatov had come to the GRU and reported that he was lured into cooperation with the CIA, they could outplay the CIA, and Filatov would be a hero.<a href="#_ftn9" name="_ftnref9"><sup>[9]</sup></a> What became of Filatov after his release, is not known, the TV documentary showed his picture after his release. Possibly A. Filatov is dead now.</p>
<div id="attachment_166050"><p><a href="https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/A_Filatov.png?ssl=1"><img aria-describedby="caption-attachment-166050" src="https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/A_Filatov.png?resize=300%2C177&amp;ssl=1" alt="" width="300" height="177" srcset="https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/A_Filatov.png?resize=300%2C177&amp;ssl=1 300w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/A_Filatov.png?resize=768%2C453&amp;ssl=1 768w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/A_Filatov.png?w=873&amp;ssl=1 873w" sizes="(max-width: 300px) 100vw, 300px" data-recalc-dims="1"></a></p><p id="caption-attachment-166050">Anatoly Filatov</p></div>
<div id="attachment_166051"><p><a href="https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/A_Filatov_2.png?ssl=1"><img aria-describedby="caption-attachment-166051" src="https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/A_Filatov_2.png?resize=300%2C173&amp;ssl=1" alt="" width="300" height="173" srcset="https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/A_Filatov_2.png?resize=300%2C173&amp;ssl=1 300w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/A_Filatov_2.png?resize=768%2C442&amp;ssl=1 768w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/A_Filatov_2.png?w=871&amp;ssl=1 871w" sizes="(max-width: 300px) 100vw, 300px" data-recalc-dims="1"></a></p><p id="caption-attachment-166051">Anatoly Filatov years after the arrest</p></div>
<p>What will follow is a translation from Russian to English from the mentioned KGB manual, where the case about Filatov is described as an example of apprehending and capturing foreign spies who use radio signals and codes. With photo scans of included photo evidence.</p>

<p><em>Start of the original translation</em></p>
<div id="attachment_166052"><p><a href="https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135640-scaled.jpg?ssl=1"><img aria-describedby="caption-attachment-166052" src="https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135640.jpg?resize=225%2C300&amp;ssl=1" alt="" width="225" height="300" srcset="https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135640-scaled.jpg?resize=225%2C300&amp;ssl=1 225w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135640-scaled.jpg?resize=768%2C1024&amp;ssl=1 768w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135640-scaled.jpg?resize=1152%2C1536&amp;ssl=1 1152w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135640-scaled.jpg?resize=1536%2C2048&amp;ssl=1 1536w, https://i1.wp.com/www.numbers-stations.com/wp-content/uploads/2020/09/20200224_135640-scaled.jpg?w=1920&amp;ssl=1 1920w" sizes="(max-width: 225px) 100vw, 225px" data-recalc-dims="1"></a></p><p id="caption-attachment-166052">First page in the manual about A.FIlatov case</p></div>
<p>The case regarding American agent Filatov is particularly useful for agency and operative workers. Two agents who worked on this case had limited, but clear objectives: one controlled his work shifts, the other one lured him to a position within a GRU object (facility), where he was arrested. Secondary events were mostly carried out by the workers of the operational staff.</p>
<p>In the case materials the use of operational technical and criminal resources is very clearly displayed. The workers of the operational services had a clear objective: gain information about practical espionage activity.</p>
<p>A lot of support for apprehending the spy was provided by the GRU radio counterintelligence. During the first phase of the operation the counter radio intelligence played a helpful, but mostly backseat role, in terms of gaining radio information. However, after Filatov was discovered in possession of multiple ciphers the RCI<a href="#_ftn11" name="_ftnref11"><sup>[11]</sup></a> played the most active role in gaining information about the adversary’s plans for their agent. It must be asserted that the RCI data about the new communication line only gained importance after comprehensive analysis about known agents and data gained from agency postal communication lines.</p>
<p>It is useful to take note of the surveillance tactics used to monitor&nbsp; FIlatov, during all phases of the operation. Here the artistic use of surveillance, determination of the personality of the object, working out on his work conditions and living place (such an approach is essential for any future attempts for apprehending an adversary agent).</p>
<p>Finally it’s important to point out the very high level of secrecy is required to successfully&nbsp; carry out the operation, with minimal numbers&nbsp; of agents and operative staff workers as reglamented by the authority of KGB, and adjusted fully to the set parameters.</p>
<p>All this taken to an account assured that the case was carried out in highest quality the tasks were carried out decisively.</p>
<p>“””</p>
<p>The investigation into the incoming signals, and the timeline for the search for the CIA agent Filatov took place in the following order.</p>
<p>At the start of 1977 the second chief directorate of the KGB had received data that led to the belief that a new agent from American intelligence had become active within Soviet Union.</p>
<p>On January 21 and February 6 1977 the RCI had detected the transmission of operational (combat)<a href="#_ftn12" name="_ftnref12"><sup>[12]</sup></a> radiograms on the communication line sent from Frankfurt CIA radio center, that had appeared already in the first half of 1976.<a href="#_ftn13" name="_ftnref13"><sup>[13]</sup></a> With that the general reception of the radiograms was possible within the central part of European side of the USSR. <a href="#_ftn14" name="_ftnref14"><sup>[14]</sup></a></p>
<p>In this same timeframe espionage activity within CIA station inside the US embassy in Moscow, was observed to have increased, showing signs of preparing for creating operational dead drop communications, it was determined that these activities could not be part of the ongoing cases and operational games.</p>
<p>It was expected that the agent, after receiving operational radiograms, will likely make contact with the Frankfurt radio center using postal telegraph, telephone, dead drop, radio transmission or make a meeting with his handler, usually from US diplomatic service.</p>
<p>Taking this into account together with Operative-technical and Seventh authority of the KGB, extra measures were made to control the agency channels within Moscow and eavesdrop on CIA actions.</p>
<p>On February 9 1977 a postal parcel coming from Moscow to the US, a suspicious letter was identified which had signs which made its purpose likely being for espionage uses. This letter had a date indicating it was sent on February 7 and was written in the in English language “from English tourist”<a href="#_ftn15" name="_ftnref15"><sup>[15]</sup></a>. By using a physical-chemical method on the blank side of the letter, a cipher of 353 five number …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.numbers-stations.com/how-to-catch-a-spy-who-uses-numbers-stations-the-kgb-experience/">https://www.numbers-stations.com/how-to-catch-a-spy-who-uses-numbers-stations-the-kgb-experience/</a></em></p>]]>
            </description>
            <link>https://www.numbers-stations.com/how-to-catch-a-spy-who-uses-numbers-stations-the-kgb-experience/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24541163</guid>
            <pubDate>Mon, 21 Sep 2020 08:50:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We need young programmers; We need old programmers]]>
            </title>
            <description>
<![CDATA[
Score 269 | Comments 244 (<a href="https://news.ycombinator.com/item?id=24540919">thread link</a>) | @mrcsharp
<br/>
September 21, 2020 | https://blog.ploeh.dk/2020/09/14/we-need-young-programmers-we-need-old-programmers/ | <a href="https://web.archive.org/web/*/https://blog.ploeh.dk/2020/09/14/we-need-young-programmers-we-need-old-programmers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post">
	<p>
		<em>The software industry loves young people, but old-timers serve an important purpose, too.</em>
	</p>
	<p>
		Our culture idolises youth. There's several reasons for this, I believe. Youth seems synonymous with vigour, strength, beauty, and many other desirable qualities. The cynical perspective is that young people, while rebellious, also tend to be easy to manipulate, if you know which buttons to push. A middle-aged man like me isn't susceptible to the argument that I should buy a particular pair of Nike shoes because they're named after Michael Jordan, but for a while, one pair wasn't enough for my teenage daughter.
	</p>
	<p>
		In intellectual pursuits (like software development), youth is often extolled as the source of innovation. You're often confronted with examples like that of <a href="https://en.wikipedia.org/wiki/%C3%89variste_Galois">Évariste Galois</a>, who made all his discoveries before turning 21. <a href="https://en.wikipedia.org/wiki/Ada_Lovelace">Ada Lovelace</a> was around 28 years when she produced what is considered the 'first computer program'. <a href="https://en.wikipedia.org/wiki/Alan_Turing">Alan Turing</a> was 24 when he wrote <a href="https://en.wikipedia.org/wiki/Turing%27s_proof">On Computable Numbers, with an Application to the Entscheidungsproblem</a>.
	</p>
	<p>
		Clearly, young age is no detriment to making ground-breaking contributions. It has even become folklore that everyone past the age of 35 is a has-been whose only chance at academic influence is to write a textbook.
	</p>
	<h3 id="800321a74c054ea0b75815c86f4ce18d">
		The story of the five monkeys <a href="#800321a74c054ea0b75815c86f4ce18d" title="permalink">#</a>
	</h3>
	<p>
		You may have seen a story called <em>the five monkeys experiment</em>. It's most likely a fabrication, but it goes like this:
	</p>
	<p>
		A group of scientists placed five monkeys in a cage, and in the middle, a ladder with bananas on the top. Every time a monkey went up the ladder, the scientists soaked the rest of the monkeys with cold water. After a while, every time a monkey went up the ladder, the others would beat it up.
	</p>
	<p>
		After some time, none of the monkeys dared go up the ladder regardless of the temptation. The scientists then substituted one of the monkeys with a new one, who'd immediately  go for the bananas, only to be beaten up by the others. After several beatings, the new member learned not to climb the ladder even though it never knew why.
	</p>
	<p>
		A second monkey was substituted and the same occurred. The first monkey participated in beating the second. A third monkey was exchanged and the story repeated. The fourth was substituted and the beating was repeated. Finally the fifth monkey was replaced.
	</p>
	<p>
		Left was a group of five monkeys who, even though they never received a cold shower, continued to beat up any monkey who attempted to climb the ladder. If it was possible to ask the monkeys why they would beat up all who attempted to go up the ladder, the answer would probably be:
	</p>
	<p>
		"That's how we do things here."
	</p>
	<p>
		While the story is probably just that: a story, it tells us something about the drag induced by age and experience. If you've been in the business for decades, you've seen numerous failed attempts at something you yourself tried when you were young. You know that it can't be done.
	</p>
	<p>
		Young people don't know that a thing can't be done. If they can avoid the monkey-beating, they'll attempt the impossible.
	</p>
	<h3 id="4add8a9af0424d7e889d3125837ed611">
		Changing circumstances <a href="#4add8a9af0424d7e889d3125837ed611" title="permalink">#</a>
	</h3>
	<p>
		Is attempting the impossible a good idea?
	</p>
	<p>
		In general, no, because it's... impossible. There's a reason older people tell young people that a thing can't be done. It's not just because they're stodgy conservatives who abhor change. It's because they see the effort as wasteful. Perhaps they're even trying to be kind, guiding young people off a path where only toil and disappointment is to be found.
	</p>
	<p>
		What old people don't realise is that sometimes, circumstances change.
	</p>
	<p>
		What was impossible twenty years ago may not be impossible today. We see this happening in many fields. Producing a commercially viable electric car was impossible for decades, until, with the advances made in battery technology, it became possible.
	</p>
	<p>
		Technology changes rapidly in software development. People trying something previously impossible may find that it's possible today. Once, if you had lots of data, you had to store it in fully normalised form, because storage was expensive. For a decade, relational databases were the only game in town. Then circumstances changed. Storage became cheaper, and a new movement of NoSQL storage emerged. What was before impossible became possible.
	</p>
	<p>
		Older people often don't see the new opportunities, because they 'know' that some things are impossible. Young people push the envelope driven by a combination of zest and ignorance. Most fail, but a few succeed.
	</p>
	<h3 id="4272a069588e47f796646bd282b9de02">
		Lottery of the impossible <a href="#4272a069588e47f796646bd282b9de02" title="permalink">#</a>
	</h3>
	<p>
		I think of this process as a lottery. Imagine that every impossible thing is a red ball in an urn. Every young person who tries the impossible draws a random ball from the urn.
	</p>
	<p>
		The urn contains millions of red balls, but every now and then, one of them turns green. You don't know which one, but if you draw it, it represents something that was previously impossible which has now become possible.
	</p>
	<p>
		This process produces growth, because once discovered, the new and better way of doing things can improve society in general. Occasionally, the young discoverer may even gain some fame and fortune.
	</p>
	<p>
		It seems wasteful, though. Most people who attempt the impossible will reach the predictable conclusion. What was deemed impossible was, indeed, impossible.
	</p>
	<p>
		When I'm in a cynical mood, I don't think that it's youth in itself that is the source of progress. It's just the <a href="https://en.wikipedia.org/wiki/Law_of_large_numbers">law of large numbers</a> applied. If there's a one in million chance that something will succeed, but ten million people attempt it, it's only a matter of time before one succeeds.
	</p>
	<p>
		Society at large can benefit from the success of the few, but ten million people still wasted their efforts.
	</p>
	<h3 id="016744f0ea77495c958a7914f08187db">
		We need the old, too <a href="#016744f0ea77495c958a7914f08187db" title="permalink">#</a>
	</h3>
	<p>
		If you accept the argument that young people are more likely to try the impossible, we need the young people. Do we need the old people?
	</p>
	<p>
		I'm turning fifty in 2020. You may consider that old, but I expect to work for many more years. I don't know if the software industry needs fifty-year-olds, but that's not the kind of old I have in mind. I'm thinking of people who have retired, or are close to retirement.
	</p>
	<p>
		In our youth-glorifying culture, we tend to dismiss the opinion and experiences of old people. <em>Oh, well, it's just a codgy old man</em> (or woman), we'll say.
	</p>
	<p>
		We ignore the experience of the old, because we believe that they haven't been keeping up with times. Their experiences don't apply to us, because we live under new circumstance. Well, see above.
	</p>
	<p>
		I'm not advocating that we turn into a gerontocracy that venerates our elders solely because of their age. Again, according to the law of large numbers, some people live to old age. There need not be any correlation between survivors and wisdom.
	</p>
	<p>
		We need the old to tell us the truth, because they have little to lose.
	</p>
	<h3 id="8b5c613ba6c44bb4b4e6dbba7ae7d19a">
		Nothing to lose <a href="#8b5c613ba6c44bb4b4e6dbba7ae7d19a" title="permalink">#</a>
	</h3>
	<p>
		In the last couple of years, I've noticed a trend. A book comes out, exposing the sad state of affairs in some organisation. This has happened regularly in Denmark, where I live. One book may expose the deplorable conditions of the Danish tax authorities, one may describe the situation in the ministry of defence, one criticises the groupthink associated with the climate crisis, and so on.
	</p>
	<p>
		Invariably, it turns out that the book is written by a professor emeritus or a retired department head.
	</p>
	<p>
		I don't think that these people, all of a sudden, had an epiphany after they retired. They knew all about the rot in the system they were part of, while they were part of it, but they've had too much to lose. You could argue that they should have said something before they retired, but that requires a moral backbone we can't expect most people to have.
	</p>
	<p>
		When people retire, the threat of getting fired disappears. Old people can speak freely to a degree most other people can't.
	</p>
	<p>
		Granted, many may simply use that freedom to spew bile or shout <em>Get off my lawn!</em>, but many are in the unique position to reveal truths no-one else dare speak. Many are, perhaps, just bitter, but some may possess knowledge that they are in a unique position to reveal.
	</p>
	<p>
		When that grumpy old guy on Twitter writes something that makes you uncomfortable, consider this: he may still be right.
	</p>
	<h3 id="2d64bd2c7ccb4b7ca2418802ed82689e">
		Being unreasonable <a href="#2d64bd2c7ccb4b7ca2418802ed82689e" title="permalink">#</a>
	</h3>
	<p>
		In a way, you could say that we need young and old people for the same fundamental reason. Not all of them, but enough of them, are in a position to be unreasonable.
		</p><blockquote>
			<p>
				"The reasonable man adapts himself to the world: the unreasonable one persists in trying to adapt the world to himself. Therefore all progress depends on the unreasonable man."
			</p>
			
		</blockquote><p>
		Young people and old people are unreasonable in each their own way, and we need both.
	</p>
	<h3 id="df88f595ec814e2bafcbd018ff5f5ad2">
		Conclusion <a href="#df88f595ec814e2bafcbd018ff5f5ad2" title="permalink">#</a>
	</h3>
	<p>
		We need young people in the software development industry. Because of their vigour and inexperience, they'll push the envelope. Most will fail to do the impossible, but a few succeed.
	</p>
	<p>
		This may seem like a cynical view, but we've all been young, and most of us have been through such a phase. It's like a rite of passage, and even if you fail to make your mark on the world, you're still likely to have learned a lot.
	</p>
	<p>
		We need old people because they're in a position to speak truth to the world. Notice that I didn't make my argument about the <em>experience</em> of old-timers. Actually, I find that valuable as well, but that's the ordinary argument: <em>Listen to old people, because they have experience and wisdom.</em>
	</p>
	<p>
		Some of them do, at least.
	</p>
	<p>
		I didn't make much out of that argument, because you already know it. There'd be no reason to write this essay if that was all I had to say. Old people have less on the line, so they can speak more freely. If someone you used to admire retires and all of a sudden starts saying or writing unpleasant and surprising things, there might be a good explanation, and it might be a good idea to pay attention.
	</p>
	<p>
		Or …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.ploeh.dk/2020/09/14/we-need-young-programmers-we-need-old-programmers/">https://blog.ploeh.dk/2020/09/14/we-need-young-programmers-we-need-old-programmers/</a></em></p>]]>
            </description>
            <link>https://blog.ploeh.dk/2020/09/14/we-need-young-programmers-we-need-old-programmers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24540919</guid>
            <pubDate>Mon, 21 Sep 2020 08:05:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Microsoft Teams as a Platform]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 104 (<a href="https://news.ycombinator.com/item?id=24540799">thread link</a>) | @homarp
<br/>
September 21, 2020 | https://jukkaniiranen.com/2020/09/microsoft-teams-as-a-platform/ | <a href="https://web.archive.org/web/*/https://jukkaniiranen.com/2020/09/microsoft-teams-as-a-platform/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article aria-label="Microsoft Teams as a platform" itemref="hero-page-title"><div>
<p>2020 became the year of #WFH (work from home) and for many organizations also the turning point when Microsoft Teams became the primary place where being “at work” happens. This is accelerating the evolution of Teams from being merely a communication tool that connects human beings into a foundational service layer for many types of business applications.</p>



<p>How the concept of Teams as a platform contrasts with Microsoft’s Power Platform suite of technology is something I’ve been thinking about a lot lately. In this post I’ll first reflect on the relatively short history of where Teams came from. I’ll then examine how the recent feature announcements are brining apps front &amp; center in Teams. Finally, a few words on the possible future for Teams as part of Microsoft’s broader strategy.</p>



<h2>The road that lead to Teams</h2>



<p>Looking back ~10 years, the real-time communication &amp; instant messaging tools from MS seemed to be going through an endless renaming cycle: from OCS to Lync to Skype for Business. The core feature set presented to the end user didn’t seem to evolve nearly as much as product branding did. On a broader level, the communication activities of information workers within an organization still typically took place within Outlook’s inbox, and different servers like SharePoint and Dynamics CRM all packed their own features for posting short messages to other users.</p>



<figure></figure>



<p>4 years ago, when the first images of what was then called “Skype Teams” started to leak out, we were already waiting for MS to create something a bit more ambitious than just another online meeting tool. Office Groups had began to emerge in various different places inside the MS Cloud, but they were primarily a technical construct with no sensible UX for everyday people to approach them. Even Dynamics CRM had it’s own solution that attempted to bring together the dicussion, calendars, notes, documents and team memberships from under an Office 365 Group associated with a record like account or opportunity:</p>



<div><figure><a href="https://docs.microsoft.com/en-us/dynamics365/customerengagement/on-premises/basics/collaborate-with-colleagues-using-office-365-groups" target="_blank" rel="noopener noreferrer"><img src="https://docs.microsoft.com/en-us/dynamics365/customerengagement/on-premises/basics/media/office-groups-dashboard.png" alt=""></a></figure></div>



<p>I remember having many discussions with our CRM customers where I attempted to steer people away from deploying this Groups solution. Instead I wanted to encourage them to wait for something a bit more polished that I knew had to be on it’s way sooner or later.</p>



<p>At one point there was a clear &amp; present danger of another “Yammer moment” taking place, as Microsoft was reportedly quite serious about their plans to acquire Slack. In retrospect it was a blessing for both parties that MS decided to keep investing in building their own product, instead of trying to retrofit an established service like Slack into their existing software offering.</p>



<p>I would argue that this “build over buy” strategy which Microsoft has since then followed across their business software stack has been a key success factor for BizApps in particular.  It has enabled MS to move from merely chasing CRM competitors like Salesforce into redefining the business apps playing field with Power Platform. There’s a stark difference between acquiring companies and bundling them as “X Cloud” versus engineering your own software stack to act as a true platform.</p>



<h2>Teams: the collaboration chapter</h2>



<p>Initially the first version of the Microsoft Teams product that became generally available in Spring 2017 was pretty much focused on being three things: </p>



<ol><li>Replacement for Skype for Business</li><li>Alternative to Slack</li><li>UI layer for Office 365 Groups</li></ol>



<p>From a business applications perspective there wasn’t all that much you could do to hook Teams up with Dynamics 365, until Fall 2018 when the previews for the first integrated features were launched. In particular the integrated file sharing experience that Teams offered seemed almost like the Holy Grail for many CRM professionals, offering to fix the glaring hole in the SharePoint integration story that lacked any security model synchronization. The roadmap image below presents the plans from 2 years ago on how Teams and Dynamics 365 were going to be integrated:</p>



<figure></figure>







<p>The last item on the roadmap has still not been delivered, which is the visibility of Teams conversations inside the Dynamics 365 record form. Why this hasn’t been a higher priority for MS to implement seems to me like a sign of how Microsoft Teams is nowadays positioned as the primary UI for all information work. MS probably would prefer if everything always started from inside Teams. You pin record tabs into channels, you show previews of records inside teams discussions, you interact with records via bot interfaces and so on. As long as Teams is that big umbrella under which all work takes place.</p>



<p>The lack of a deep 2-way integration does not therefore mean that investments aren’t being made into the products involved. It can simply be a reflection of the new vision that is being built, by aligning many existing services to form a whole that aims to be greater than the sum of its parts.</p>



<p>As an example, if you look at Microsoft’s task management story, you’ll see that features and data from across various apps like To Do, Planner and Outlook tasks / flagged emails are currently being collapsed into a central location that is the <a href="https://docs.microsoft.com/en-us/microsoftteams/manage-tasks-app" target="_blank" rel="noreferrer noopener">Tasks app for Teams</a>. Tasks as a generic construct don’t necessarily need to be fully controlled by a single database, yet they very much need to be logically represented within “the hub for teamwork” that Teams is positioned as.</p>



<p>Going forward, when new apps appear into the MS cloud product portfolio and they need to offer task management features to users, the logical integration point to focus on would be Teams. For activity feed type of functionality the choice is even more clear for product development: choose to piggyback on Teams instead of inventing yet another stream of short messages.</p>



<h2>Teams: the platform chapter</h2>



<p>Moving beyond simply integrating Teams with products X, Y and Z, we’re now seeing the rise of a model where apps are built specifically to be used in Teams. This has of course been possible for a long time already, by developing custom web services and using the SDKs. Now there are many features coming up that will amplify the platform story around Teams on the no-code/low-code front specifically.</p>



<figure><img src="https://techcommunity.microsoft.com/t5/image/serverpage/image-id/215495iAC8095B3BF8D5E46/image-size/large?v=1.0&amp;px=999" alt="lists in teams1.png"></figure>



<p>Microsoft Lists app has been the  first to <a href="https://techcommunity.microsoft.com/t5/microsoft-teams-blog/microsoft-lists-in-microsoft-teams-is-now-generally-available/ba-p/1621979" target="_blank" rel="noreferrer noopener">reach GA</a> and offers an ultra low barrier for users to process data in a single table through a configurable, readymade UI. When accessed via Teams, the list data gains one more special dimension: discussions to be had regarding a list item. This is pretty much the same as the usage pattern offered for a Dynamics 365 record with the integration mentioned earlier.</p>



<p>Underneath the new covers of MS Lists is the technology familiar from SharePoint lists. If we were to only examine the UI layer, there is actually a remarkable similarity to a popular no-code service called Airtable. So much that the <a rel="noreferrer noopener" href="https://mspoweruser.com/airtable-accuses-microsoft-of-copying-its-service/" target="_blank">accusations</a> of MS simply copying the visuals and core features from this competitor don’t seem entirely unjustified. </p>



<figure><img loading="lazy" src="https://jukkaniiranen.com/wp-content/uploads/2020/09/Airtable_for_teams.png" alt="" width="583" height="729" srcset="https://jukkaniiranen.com/wp-content/uploads/2020/09/Airtable_for_teams.png 777w, https://jukkaniiranen.com/wp-content/uploads/2020/09/Airtable_for_teams-240x300.png 240w, https://jukkaniiranen.com/wp-content/uploads/2020/09/Airtable_for_teams-768x961.png 768w" sizes="(max-width: 583px) 100vw, 583px"></figure>



<p>Comparing these two offerings gives us some perspective on what exactly is the market position these tools are aiming to conquer. Simple lists themselves are not a particularly unique feature, rather it’s the team collaboration capabilities and ease of data sharing that turns these tables into what you’d call an actual app. Incidentally, just this week Airtable <a href="https://blog.airtable.com/airtable-platform-launch-automations-sync-apps/" target="_blank" rel="noreferrer noopener">announced</a> they were building a full platform with apps offering JavaScript based extensibility, a marketplace for sharing apps, automations for executing business logic, and finally a sync service to transfer data across environments (“bases”).</p>



<p>Collaboration scenarios around semi-structured data like lists and Excel style tables can be seen as a  gateway drug. They allow turning email or paper based manual processes into a quick first draft of what the digital process could be like. If there are indeed clear business benefits in automating the said process, the requirements for more complex app features will soon begin to emerge from the user base. Hence the collaboration platform should offer an obvious path to grow these pre-built app experiences into more advanced no-code/low-code apps.</p>



<h2>Project Oakdale a.k.a bringing CDS to Teams</h2>



<p>If Microsoft Lists is the equivalent of an Excel table within the Teams context, then <a href="https://jukkaniiranen.com/2020/07/dataflex-is-more-and-less-than-cds/">Project Oakdale</a> / “CDS Lite” could be though of as bringing SQL Server inside Teams. Now, obviously Microsoft has zero intent on actually replacing Excel nor SQL with features built into Teams. They only need to introduce those parts that make sense from a team collabocation perspective.</p>



<p>Microsoft Lists is a far cry from what a real Excel workbook can do, yet it can offer much more value in a collaboration scenarios that those lone .xlsx files ever could. Similarly, the version of CDS that will very soon be available for building Power Apps within Teams is nowhere near as powerful as the services powering enterprise CRM systems like Dynamics 365 (or the raw power offered by SQL). Still, the fact that it can be found from within every team and used by a much larger audience than what Power Apps citizen developer tools could hope to capture – those are the factors that can truly make CDS a mainstream service that most information workers in the Microsoft 365 cloud interact it.</p>



<figure><img loading="lazy" width="1024" height="576" src="https://jukkaniiranen.com/wp-content/uploads/2020/09/Oakdale_Teams_table_design-1024x576.jpg" alt="" srcset="https://jukkaniiranen.com/wp-content/uploads/2020/09/Oakdale_Teams_table_design-1024x576.jpg 1024w, https://jukkaniiranen.com/wp-content/uploads/2020/09/Oakdale_Teams_table_design-300x169.jpg 300w, https://jukkaniiranen.com/wp-content/uploads/2020/09/Oakdale_Teams_table_design-768x432.jpg 768w, https://jukkaniiranen.com/wp-content/uploads/2020/09/Oakdale_Teams_table_design.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>The experience of defining the CDS data model in Project Oakdale will be very different from the path that Power Apps makers have gone through – let alone the XRM veterans. In fact, you could easily mistake the table design and row entry UX to be that of Microsoft Lists rather than CDS. This highlights a key aspect that not all Power Platform experts may yet have grasped: for MS this “CDS Lite” is not so much about deciding what premium features of the full Power Platform to give away for free to Teams subscibers – rather it’s about how to best simplify the enterprise CRM features of CDS into a new product that Teams users could adopt on their own.</p>



<p>This doesn’t mean that …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jukkaniiranen.com/2020/09/microsoft-teams-as-a-platform/">https://jukkaniiranen.com/2020/09/microsoft-teams-as-a-platform/</a></em></p>]]>
            </description>
            <link>https://jukkaniiranen.com/2020/09/microsoft-teams-as-a-platform/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24540799</guid>
            <pubDate>Mon, 21 Sep 2020 07:36:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Little Things: Speeding up C++ compilation]]>
            </title>
            <description>
<![CDATA[
Score 128 | Comments 80 (<a href="https://news.ycombinator.com/item?id=24537231">thread link</a>) | @ingve
<br/>
September 20, 2020 | https://codingnest.com/the-little-things-speeding-up-c-compilation/ | <a href="https://web.archive.org/web/*/https://codingnest.com/the-little-things-speeding-up-c-compilation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">

    <article>

        

        <section>
            <p><em>The Little Things</em> is a new series of posts based on Locksley's internal training sessions. Often the contents are either proprietary (e.g. the inner workings of specific master key platforms) or not generally interesting (e.g. our internal libraries and tooling), but sometimes the contents are suitable for a wider audience, in which case I want to share them.</p>
<hr>
<p>This post will be about some source-level techniques for speeding up C++ compilation, and their (dis)advantages. It will <strong>not</strong> talk about things external to C++, such as buying better hardware, using a better build system, or using smarter linker<sup><a href="#fn1" id="fnref1">[1]</a></sup>. It will also not talk about the tooling that can find compilation bottlenecks, as that will be a subject of a later post.</p>
<h2 id="overviewofccompilationmodel">Overview of C++ compilation model</h2>
<p>I will start with a quick overview of the C++ compilation model, to provide context for some of the tricks I will show later. Note that this overview will be very coarse, if you want a detailed look at the subtleties of the <em>9</em> phase compilation model defined in the C++ standard, look elsewhere.</p>
<p>We will consider the compilation of C++ binary to happen in 3 steps:</p>
<ol>
<li>Preprocessing</li>
<li>Compilation</li>
<li>Linking</li>
</ol>
<h3 id="preprocessing">Preprocessing</h3>
<p>The first step is preprocessing. During it, the preprocessor takes a .cpp file and parses it, looking for <em>preprocessor directives</em>, such as <code>#include</code>, <code>#define</code>, <code>#ifdef</code>, etc.</p>
<p>Let's take this super simple file as an example</p>
<pre><code>// tiny.cpp
#define KONSTANTA 123

int main() {
    return KONSTANTA;
}
</code></pre>
<p>It contains one preprocessor directive, <code>#define</code>. It says that any following occurence of <code>KONSTANTA</code> should be replaced with <code>123</code>. Running the file through a preprocessor leads to output like this one:</p>
<pre><code>$ clang++ -E tiny.cpp
# 1 "tiny.cpp"
# 1 "&lt;built-in&gt;" 1
# 1 "&lt;built-in&gt;" 3
# 383 "&lt;built-in&gt;" 3
# 1 "&lt;command line&gt;" 1
# 1 "&lt;built-in&gt;" 2
# 1 "tiny.cpp" 2


int main() {
    return 123;
}
</code></pre>
<p>We can see that in <code>return KONSTANTA</code> the <code>KONSTANTA</code> part was replaced with <code>123</code>, as it should be. We also see that the compiler left itself a bunch of other notes, that we do not care about that much<sup><a href="#fn2" id="fnref2">[2]</a></sup>.</p>
<p>The big problem with the preprocessor model is that the <code>#include</code> directive literally means "copy-paste all of this file's contents here". Of course, if that file's contents contain further <code>#include</code> directives, then more files will be opened, their contents copied out, and in turn, the compiler will have more code to deal with. In other words, preprocessing increases the size of the input, usually significantly so.</p>
<p>The following is a simple "Hello World" in C++, using streams.</p>
<pre><code>// hello-world.cpp
#include &lt;iostream&gt;

int main() {
    std::cout &lt;&lt; "Hello World\n";
}
</code></pre>
<p>After preprocessing, the file will have <strong>28115</strong><sup><a href="#fn3" id="fnref3">[3]</a></sup> lines for the next step, compilation, to deal with.</p>
<pre><code>$ clang++ -E hello-world.cpp | wc -l
28115
</code></pre>
<h3 id="compilation">Compilation</h3>
<p>After a file is preprocessed, it is compiled into an <em>object file</em>. Object files contain the actual code to run, but cannot be run without linking. One of the reasons for this is that object files can refer to symbols (usually functions) that they do not have the definition (code) for. This happens, e.g. if a .cpp file uses a function that has been declared, but not defined, like so:</p>
<pre><code>// unlinked.cpp
void bar(); // defined elsewhere (hopefully)

void foo() {
    bar();
}
</code></pre>
<p>You can look inside a compiled object file to see what symbols it provides and what symbols it needs, using <code>nm</code> (Linux) or <code>dumpbin</code> (Windows). If we look at the output for the <code>unlinked.cpp</code> file, we get this:</p>
<pre><code>$ clang++ -c unlinked.cpp &amp;&amp; nm -C unlinked.o
                 U bar()
0000000000000000 T foo()
</code></pre>
<p><code>U</code> means that the symbol is not defined in this object file. <code>T</code> means that the symbol is in the text/code section and that it is exported, which means that other object files can get <code>foo</code> from this <code>unlinked.o</code>. It is important to know that symbols might also be present in an object file, but not be available to other object files. Such symbols are marked with <code>t</code>.</p>
<h3 id="linking">Linking</h3>
<p>After all the files have been compiled into object files, they have to be <em>linked</em> into the final binary artefact. During linking, all the various object files are smashed together in a specific format, e.g. ELF, and the various references to undefined symbols in object files are resolved with the address of the symbol, as provided by a different object file (or library).</p>
<p>With this overview done, we can start tackling the different ways to speed up the compilation of your code. Let's start simple.</p>
<h2 id="includeless"><code>#include</code> less</h2>
<p>Including a file usually brings in a <em>lot</em> of extra code, which the compiler then needs to parse and check. Thus the simplest, and usually also the biggest, way to speed up the compilation of your code, is to just <code>#include</code> fewer files. Reducing the include set is especially beneficial in header files, as they are likely to be included from other files, thus amplifying the impact of your improvements.</p>
<p>The easiest way to do this is to remove any unused includes. Unused includes shouldn't happen often, but sometimes they are left behind during refactoring, and using a tool like <a href="https://include-what-you-use.org/">IWYU</a> <em>can</em><sup><a href="#fn4" id="fnref4">[4]</a></sup> make it simple to do. However, just cleaning up unused includes is unlikely to provide many benefits, and so you will have to reach for bigger guns, forward declarations and manual outlining.</p>
<p>But before explaining forward declarations and manual outlining, I want to go over the costs of header inclusion quickly, so we can build up intuition on what sort of speed-ups we can expect from pruning down include graphs.</p>

<p>The table below shows the time required by Clang<sup><a href="#fn5" id="fnref5">[5]</a></sup> to compile a file that <em>only</em> includes some stdlib headers.</p>

<table>
<thead>
<tr>
<th>header(s) included</th>
<th>time to compile (ms)</th>
<th>difference from baseline (ms)</th>
</tr>
</thead>
<tbody>
<tr>
<td>none</td>
<td>11.3  ± 0.2</td>
<td>-</td>
</tr>
<tr>
<td><code>&lt;vector&gt;</code></td>
<td>68.8  ± 0.3</td>
<td>57.5 ±  0.36</td>
</tr>
<tr>
<td><code>&lt;string&gt;</code></td>
<td>136.3  ± 0.8</td>
<td>125.0 ±  0.82</td>
</tr>
<tr>
<td><code>&lt;stdexcept&gt;</code></td>
<td>137.0  ± 0.8</td>
<td>125.7 ±  0.82</td>
</tr>
<tr>
<td><code>&lt;vector&gt;</code>, <code>&lt;string&gt;</code></td>
<td>155.3  ± 0.9</td>
<td>144.0 ±  0.92</td>
</tr>
<tr>
<td><code>&lt;string&gt;</code>, <code>&lt;stdexcept&gt;</code></td>
<td>136.7  ± 0.7</td>
<td>125.4 ±  0.73</td>
</tr>
<tr>
<td><code>&lt;vector&gt;</code>, <code>&lt;string&gt;</code>, <code>&lt;stdexcept&gt;</code></td>
<td>156.1  ± 0.8</td>
<td>144.8 ±  0.82</td>
</tr>
</tbody>
</table>
<p>The first row shows the time needed to compile a completely empty file, to provide a baseline time required by the compiler to start, read the file, and do nothing. The other lines are more interesting. As the second line says, just including <code>&lt;vector&gt;</code> adds 57 ms to compilation times, even though there will be no actual line emitted. As we can see, the cost to include <code>&lt;string&gt;</code> is more than double of <code>&lt;vector&gt;</code>, and the cost to include <code>&lt;stdexcept&gt;</code> is about the same as for <code>&lt;string&gt;</code>.</p>
<p>More interesting are the rows for combinations of headers, because no combination of headers is as expensive as compiling each of them on its own. The reason is quite simple: their internal include overlap. The most extreme case is <code>&lt;string&gt;</code> + <code>&lt;stdexcept&gt;</code>, because <code>&lt;stdexcept&gt;</code> is basically <code>&lt;string&gt;</code> + couple of types deriving from <code>std::exception</code>.</p>
<p>What you should take away from this are two things:</p>
<ul>
<li>Even if you do not use anything from a header, you still have to pay for it.</li>
<li>Include costs do not neatly sum, nor subtract.</li>
</ul>
<p>Now let's go through techniques we can use to include fewer files.</p>
<h3 id="forwarddeclarations">Forward declarations</h3>
<p>Quite often, when we mention a type, we only need to know that it exists but do not need to know its definition. The common case is creating a pointer or a reference to a type, in which case you need a knowledge that the type exists (a <em>forward declaration</em>), but not what it looks like (a <em>definition</em>).</p>
<p>As an example, this header is valid:</p>
<pre><code>class KeyShape; // forward declaration

size_t count_differences(KeyShape const&amp; lhs, KeyShape const&amp; rhs);
</code></pre>
<p>as long as the implementation file includes the appropriate headers:</p>
<pre><code>#include "key-shape.hpp" // provides the full definition of KeyShape

size_t count_differences(KeyShape const&amp; lhs, KeyShape const&amp; rhs) {
    assert(lhs.positions() == rhs.positions());
    ...
}
</code></pre>
<p>You can also use forward declaration together with some templated classes, whose size does not change depending on the template argument, e.g. <code>std::unique_ptr</code> and <code>std::vector</code><sup><a href="#fn6" id="fnref6">[6]</a></sup>. However, doing so can force you to outline your constructors, destructors and other special member functions (<em>SMFs</em>), as those usually need to see the full definition of the type. Your code then ends up looking like this:</p>
<pre><code>// foo.hpp
#include &lt;memory&gt;

class Bar;

class Foo {
    std::unique_ptr&lt;Bar&gt; m_ptr;
public:
    Foo(); // = default;
    ~Foo(); // = default;
};
</code></pre>
<pre><code>// foo.cpp
#include "bar.hpp"

Foo::Foo() = default;
Foo::~Foo() = default;
</code></pre>
<p>Notice that we still use the compiler-generated default constructor and destructor, but do so in the <code>.cpp</code> file, where we see the full definition of <code>Bar</code>. I also like to use the <code>// = default;</code> comment to signal to other programmers reading the code that the SMF is explicitly declared but will be defaulted, and thus there won't be any special logic in it.</p>
<p>When using this technique, please remember that the outlined functions cannot be inlined without LTO. In other words, you probably do not want to outline <em>every</em> function just because you can, because calling trivial functions can be much more expensive than inlining their code directly.</p>
<h3 id="explicitoutlining">Explicit outlining</h3>
<p>The idea underlying explicit outlining is quite simple: sometimes we get better results if a piece of code is explicitly split away from a function. One of the most common reasons is, perhaps ironically, improving inlining by making the common path of a function small. However, in our case, the reason for doing this is to improve the compilation times.</p>
<p>If a piece of code is expensive to compile, and inlining it is not crucial for performance, only one TU has to pay for compiling it. The canonical example of this is throwing an exception in general, and exceptions from <code>&lt;stdexcept&gt;</code> in particular. Throwing an exception generates quite a lot of code, and throwing more complex standard exception types, such as <code>std::runtime_error</code>, also requires an expensive<sup><a href="#fn7" id="fnref7">[7]</a></sup> header, <code>&lt;stdexcept&gt;</code> to be included.</p>
<p>By instead replacing all <code>throw foo;</code> statements with calls to a helper function along the lines of <code>[[noreturn]] void throw_foo(char const* msg)</code>, the call sites become …</p></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://codingnest.com/the-little-things-speeding-up-c-compilation/">https://codingnest.com/the-little-things-speeding-up-c-compilation/</a></em></p>]]>
            </description>
            <link>https://codingnest.com/the-little-things-speeding-up-c-compilation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24537231</guid>
            <pubDate>Sun, 20 Sep 2020 20:41:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why aren’t you more serious?]]>
            </title>
            <description>
<![CDATA[
Score 114 | Comments 70 (<a href="https://news.ycombinator.com/item?id=24537147">thread link</a>) | @luu
<br/>
September 20, 2020 | https://rubenerd.com/why-arent-you-more-serious/ | <a href="https://web.archive.org/web/*/https://rubenerd.com/why-arent-you-more-serious/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div property="articleBody">
<p>I get more hits to my site and RSS feed in a typical month now than I used to get in a given year. For a fifteen year old blog that started life as a Perl CGI script in high school, it’s been wild to see. Whether you’re coming here from Hacker News, Reddit, Twitter, Discord, newsgroups, or the BSD Now podcast, hi! Sometimes I talk about tech here.</p>
<p>This marked increase in traffic corresponds with more feedback email, a not altogether insignificant number of which are negative. I’ll address some recurring themes here, because they’re Jason Bourne of the same misunderstanding of the kind of site people have come across.</p>
<p>Once you filter out the obvious trolls saying BSD is dead, Apple computers are for posers who value form over function, and that we’re all sheep for wearing a mask, most of the remainder concern the tone of my posts, and what they consider the ancillary topics I cover. They claim that my writing is too jovial, my site <a href="https://rubenerd.com/about/#mascot">mascot</a> drawn by Clara is inappropriate, and inclusion of posts about <a href="https://rubenerd.com/josh-on-how-to-peel-garlic/" title="Josh on how to peel garlic">cooking garlic</a> are a waste of time and somehow detract from my serious technical and political posts.</p>
<p><em>(One gentleman spent an inordinate amount of time criticising Rubi’s skirt in such lurid detail I felt but the tiniest twinge of what women must feel as creepy men ogle them walking past).</em></p>
<p>I appreciate—most of—the feedback, but respectfully disagree. There may not be many of us doing this anymore, but this is specifically a personal blog. This site has always been a labour of love for me since I started it in high school in 2004, and will necessarily be about stuff that’s on my mind and that I’m interested in. There are drier technical blogs by people I respect out there, but that’s not my style.</p>
<p>I’m also unsure how one can quantify detraction in this context. I remember having a similar debate with a WikiProject Albums contributor, who claimed compilation album articles similarly detracted from the quality of Wikipedia. In a finite space like a newspaper or book that might make sense, but in an electronic medium it seems to me the easiest solution is to ignore things in which you have no interest. Your also free to find an anime mascot drawn by my girlfriend offensive, just as I’m free to include her to make the world a slightly nicer place.</p>
<p>Which dovetails to the third comment which I take more seriously. I haven’t received permission to quote their email, but in summary they said my serious posts about COVID, social security, and attitudes in open source software communities are valuable, but sporadic. The implication is it’s incumbent upon me to only discuss important topics, and that by including what amounts to sidebars I’m trivialising them.</p>
<p>This one, selfishly, comes down to self-preservation. I need to write about the intricacies of BSD text editors and fun engineering or cooking videos to afford me sufficient mental fortitude to discuss serious topics. Sometimes we all need a break, and this is how I do it.</p>
<p>As I wrote on my <a href="https://rubenerd.com/the-first-post/">first post</a> fifteen years ago:</p>
<blockquote>
<p>… it’s a blog site with random stuff on it that I think is groovy, weird etc … maybe one percent of it, or maybe two, might be useful to someone, especially with respect to some of the tech problems I’ve had and solved over the years. So here it is.</p>
</blockquote>
<p>Thanks for reading.</p>
</div></div>]]>
            </description>
            <link>https://rubenerd.com/why-arent-you-more-serious/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24537147</guid>
            <pubDate>Sun, 20 Sep 2020 20:30:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Not Rust?]]>
            </title>
            <description>
<![CDATA[
Score 305 | Comments 317 (<a href="https://news.ycombinator.com/item?id=24536645">thread link</a>) | @dochtman
<br/>
September 20, 2020 | https://matklad.github.io/2020/09/20/why-not-rust.html | <a href="https://web.archive.org/web/*/https://matklad.github.io/2020/09/20/why-not-rust.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <article>
  
  <p>Sep 20, 2020</p>
  <p>I’ve recently read an article criticizing Rust, and, while it made a bunch of good points, I didn’t enjoy it — it was an easy to argue with piece.
In general, I feel that I can’t recommend an article criticizing Rust.
This is a shame — confronting drawbacks is important, and debunking low effort/miss informed attempts at critique sadly inoculates against actually good arguments.</p>
<p>So, here’s my attempt to argue <em>against</em> Rust:</p>
<div>
<dl>
<dt>Not All Programming is Systems Programming</dt>
<dd>
<div>
<div>
<p>Rust is a systems programming language.
It offers precise control over data layout and runtime behavior of the code, granting  you maximal performance and flexibility.
Unlike other systems programming languages, it also provides memory safety — buggy programs terminate in a well-defined manner, instead of unleashing (potentially security-sensitive) undefined behavior.</p>
<p>However, in many (most) cases, one doesn’t need ultimate performance or control over hardware resources.
For these situations, modern managed languages like Kotlin or Go offer decent speed, enviable
<a href="https://qconlondon.com/london-2017/system/files/presentation-slides/highperformancemanagedlanguages.pdf">time to performance</a>, and are memory safe by virtue of using a garbage collector for dynamic memory management.</p>
</div>
</div>
</dd>
<dt>Complexity</dt>
<dd>
<div>
<div>
<p>Programmer’s time is valuable, and, if you pick Rust, expect to spend some of it on learning the ropes.
Rust community poured a lot of time into creating high-quality teaching materials, but the Rust language <em>is</em> big.
Even if a Rust implementation would provide value for you, you might not have resources to invest into growing the language expertise.</p>
<p>Rust’s price for improved control is the curse of choice:</p>
<div>
<div>
<pre><code data-lang="rust"><table><tbody><tr><td><pre>1
2
3
4
5
6
</pre></td><td><pre><span>struct</span> <span>Foo</span>     <span>{</span> <span>bar</span><span>:</span> <span>Bar</span>         <span>}</span>
<span>struct</span> <span>Foo</span><span>&lt;</span><span>'a</span><span>&gt;</span> <span>{</span> <span>bar</span><span>:</span> <span>&amp;</span><span>'a</span> <span>Bar</span>     <span>}</span>
<span>struct</span> <span>Foo</span><span>&lt;</span><span>'a</span><span>&gt;</span> <span>{</span> <span>bar</span><span>:</span> <span>&amp;</span><span>'a</span> <span>mut</span> <span>Bar</span> <span>}</span>
<span>struct</span> <span>Foo</span>     <span>{</span> <span>bar</span><span>:</span> <span>Box</span><span>&lt;</span><span>Bar</span><span>&gt;</span>    <span>}</span>
<span>struct</span> <span>Foo</span>     <span>{</span> <span>bar</span><span>:</span> <span>Rc</span><span>&lt;</span><span>Bar</span><span>&gt;</span>     <span>}</span>
<span>struct</span> <span>Foo</span>     <span>{</span> <span>bar</span><span>:</span> <span>Arc</span><span>&lt;</span><span>Bar</span><span>&gt;</span>    <span>}</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>In Kotlin, you write <code>class Foo(val bar: Bar)</code>, and proceed with solving your business problem.
In Rust, there are choices to be made, some important enough to have dedicated syntax.</p>
<p>All this complexity is there for a reason — we don’t know how to create a simpler memory safe low-level language.
But not every task requires a low-level language to solve it.</p>

</div>
</div>
</dd>
<dt>Compile Times</dt>
<dd>
<div>
<div>
<p>Compile times are a multiplier for everything.
A program written in a slower to run but faster to compile programming language can be <em>faster</em> to run because the programmer will have more time to optimize!</p>
<p>Rust intentionally picked slow compilers in the <a href="https://research.swtch.com/generic">generics dilemma</a>.
This is not necessary the end of the world (the resulting runtime performance improvements are real), but it does mean that you’ll have to fight tooth and nail for reasonable build times in larger projects.</p>
<p><code>rustc</code> implements what is probably the most advanced <a href="https://rustc-dev-guide.rust-lang.org/queries/incremental-compilation.html">incremental compilation</a> algorithm in production compilers, but this feels a bit like fighting with language compilation model.</p>
<p>Unlike C++, Rust build is not embarrassingly parallel; the amount of parallelism is limited by length of the critical path in the dependency graph.
If you have 40+ cores to compile, this shows.</p>
<p>Rust also lacks an analog for the <a href="https://en.cppreference.com/w/cpp/language/pimpl">pimpl</a> idiom, which means that changing a crate requires recompiling (and not just relinking) all of its reverse dependencies.</p>
</div>
</div>
</dd>
<dt>Maturity</dt>
<dd>
<div>
<div>
<p>Five years old, Rust is definitely a young language.
Even though its future looks bright, I will bet more money on “C will be around in ten years” than on “Rust will be around in ten years”
(See <a href="https://en.wikipedia.org/wiki/Lindy_effect">Lindy Effect</a>).
If you are writing software to last decades, you should seriously consider risks associated with picking new technologies.
(But keep in mind that picking Java over Cobol for banking software in 90s retrospectively turned out to be the right choice).</p>
<p>There’s only one complete implementation of Rust — the <a href="https://github.com/rust-lang/rust/"><code>rustc</code></a> compiler.
The most advanced alternative implementation, <a href="https://github.com/thepowersgang/mrustc"><code>mrustc</code></a>, purposefully omits many static safety checks.
<code>rustc</code> at the moment supports only a single production-ready backend — LLVM.
Hence, its support for CPU architectures is narrower than that of C, which has GCC implementation as well as a number of vendor specific proprietary compilers.</p>
<p>Finally, Rust lacks an official specification.
<a href="https://doc.rust-lang.org/reference/">The reference</a> is a work in progress, and does not yet document all the fine implementation details.</p>
</div>
</div>
</dd>
<dt>Alternatives</dt>
<dd>
<div>
<div>
<p>There are other languages besides Rust in systems programming space, notably, C, C++, and Ada.</p>
<p>Modern C++ provides <a href="https://www.viva64.com/en/pvs-studio/">tools</a> and <a href="https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines">guidelines</a> for improving safety.
There’s even a proposal for a Rust-like <a href="https://github.com/isocpp/CppCoreGuidelines/blob/master/docs/Lifetime.pdf">lifetimes</a> mechanism!
Unlike Rust, using these tools does not <em>guarantee</em> the absence of memory safety issues.
However, if you already maintain a large body of C++ code, it makes sense to check if following best practices and using <a href="https://clang.llvm.org/docs/UndefinedBehaviorSanitizer.html">sanitizers</a> helps with security issues.
This is hard, but clearly is easier than rewriting in another language!</p>
<p>If you use C, you can use formal methods to <a href="https://sel4.systems/Info/FAQ/proof.pml">prove</a> the absence of undefined behaviors, or just <a href="https://sqlite.org/testing.html">exhaustively test</a> everything.</p>
<p>Ada is memory safe if you don’t use dynamic memory (never call <code>free</code>).</p>
<p>Rust is an interesting point on the cost/safety curve, but is far from the only one!</p>
</div>
</div>
</dd>
<dt>Tooling</dt>
<dd>
<div>
<div>
<p>Rust tooling is a bit of a hit and miss.
The baseline tooling, the compiler and the build system
(<a href="https://doc.rust-lang.org/cargo/index.html">cargo</a>), are often cited as best in class.</p>
<p>But, for example, some runtime-related tools (most notably, heap profiling) are just absent — it’s hard to reflect on the runtime of the program if there’s no runtime!
Additionally, while IDE support is decent, it is nowhere near the Java-level of reliability.
Automated complex refactors of multi-million line programs are not possible in Rust today.</p>
</div>
</div>
</dd>
<dt>Integration</dt>
<dd>
<div>
<div>
<p>Whatever the Rust promise is, it’s a fact of life that today’s systems programming world speaks C, and is inhabited by C and C++.
Rust intentionally doesn’t try to mimic these languages — it doesn’t use C++-style classes or C ABI.</p>
<p>That means that integration between the worlds needs explicit bridges.
These are not seamless.
They are <code>unsafe</code>, not always completely zero-cost and need to be synchronized between the languages.
While the general promise of <a href="http://adventures.michaelfbryan.com/posts/how-to-riir/">piece-wise integration</a> holds up and the <a href="https://github.com/dtolnay/cxx">tooling</a> catches up, there is accidental complexity along the way.</p>
<p>One specific gotcha is that Cargo’s opinionated world view (which <em>is</em> a blessing for pure Rust projects) might make it harder to integrate with a bigger build system.</p>
</div>
</div>
</dd>
<dt>Performance</dt>
<dd>
<div>
<div>
<p>“Using LLVM” is not a universal solution to all performance problems.
While I am not aware of benchmarks comparing performance of C++ and Rust at scale, it’s not to hard to come up with a list of cases where Rust leaves some performance on the table relative to C++.</p>
<p>The biggest one is probably the fact that Rust’s move semantics is based on values (<code>memcpy</code> at the machine code level).
In contrast, C++ semantics uses special references you can steal data from (pointers at the machine code level).
In theory, compiler should be able to see through chain of copies; in practice it often doesn’t: <a href="https://github.com/rust-lang/rust/issues/57077">#57077</a>.
A related problem is the absence of placement new — Rust sometimes need to copy bytes to/from the stack, while C++ can construct the thing in place.</p>
<p>Somewhat amusingly, Rust’s default ABI (which is not stable, to make it as efficient as possible) is sometimes worse than that of C: <a href="https://github.com/rust-lang/rust/issues/26494#issuecomment-619506345">#26494</a>.</p>
<p>Finally, while in theory Rust code should be more efficient due to the significantly richer aliasing information, enabling aliasing-related optimizations triggers LLVM bugs and miscompilations: <a href="https://github.com/rust-lang/rust/issues/54878">#54878</a>.</p>
<p>But, to reiterate, these are cherry-picked examples, sometimes the field is tilted the other way.
For example, <code>std::unique_ptr</code> <a href="https://www.youtube.com/watch?v=rHIkrotSwcc&amp;feature=youtu.be&amp;t=1261">has a performance problem</a> which Rust’s <code>Box</code> lacks.</p>
<p>A potentially bigger issue is that Rust, with its definition time checked generics, is less expressive than C++.
So, some C++ <a href="http://eigen.tuxfamily.org/index.php?title=Expression_templates">template tricks</a> for high performance are not expressible in Rust using a nice syntax.</p>
</div>
</div>
</dd>
<dt>Meaning of Unsafe</dt>
<dd>
<div>
<div>
<p>An idea which is even more core to Rust than ownership &amp; borrowing is perhaps that of <code>unsafe</code> boundary.
That, by delineating all dangerous operations behind <code>unsafe</code> blocks and functions and insisting on providing a safe higher-level interface to them, it is possible to create a system which is both</p>
<div>
<ol>
<li>
<p>sound (non-<code>unsafe</code> code can’t cause undefined behavior),</p>
</li>
<li>
<p>and modular (different <code>unsafe</code> blocks can be checked separately).</p>
</li>
</ol>
</div>
<p>It’s pretty clear that the promise works out in practice: <a href="https://github.com/rust-fuzz/trophy-case">fuzzing Rust code</a> unearths panics, not buffer overruns.</p>
<p>But the theoretical outlook is not as rosy.</p>
<p><em>First</em>, there’s no definition of Rust memory model, so it is impossible to formally check if a given unsafe block is valid or not.
There’s informal definition of “things rustc does or might rely on” and in in-progress <a href="https://github.com/rust-lang/miri">runtime verifier</a>, but the actual model is in flux.
So there might be some <code>unsafe</code> code somewhere which works OK in practice today, might be declared invalid tomorrow, and broken by a new compiler optimization next year.</p>
<p><em>Second</em>, there’s also an observation that <code>unsafe</code> blocks are not, in fact, modular.
Sufficiently powerful <code>unsafe</code> blocks can, in effect, extend the language.
Two such extensions might be fine in isolation, but lead to undefined behavior if used simultaneously:
<a href="https://smallcultfollowing.com/babysteps/blog/2016/10/02/observational-equivalence-and-unsafe-code/">Observational equivalence and unsafe code</a>.</p>

</div>
</div>
</dd>
</dl>
</div>
<p>Here are some thing I’ve deliberately omitted from the list:</p>
<div>
<ul>
<li>
<p>Economics (“it’s harder to hire Rust programmers”) — I feel that the “maturity” section captures the essence of it which is not reducible to chicken and egg problem.</p>
</li>
<li>
<p>Dependencies (“stdlib is too small / everything has too many deps”) — given how good Cargo and the relevant parts of the language are, I personally don’t see this as a problem.</p>
</li>
<li>
<p>Dynamic linking (“Rust should have stable ABI”) — I don’t think this is a strong argument. Monomorphization is pretty fundamentally incompatible with dynamic linking and there’s C ABI if you really need to. I do think that the situation here can be improved, <a href="https://internals.rust-lang.org/t/a-stable-modular-abi-for-rust/12347/10?u=matklad">but I don’t think that improvement needs to be Rust-specific</a>.</p>
</li>
</ul>
</div>

</article>

  </div></div>]]>
            </description>
            <link>https://matklad.github.io/2020/09/20/why-not-rust.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24536645</guid>
            <pubDate>Sun, 20 Sep 2020 19:27:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We need physical audio kill switches]]>
            </title>
            <description>
<![CDATA[
Score 444 | Comments 430 (<a href="https://news.ycombinator.com/item?id=24535408">thread link</a>) | @stargrave
<br/>
September 20, 2020 | https://rubenerd.com/we-need-physical-audio-kill-switches/ | <a href="https://web.archive.org/web/*/https://rubenerd.com/we-need-physical-audio-kill-switches/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div property="articleBody">
<p>(Update: I didn’t mention this concerned <strong>wired</strong> headphones).</p>
<p>I aggressively disagree with any computer design decisions that detract from ergonomics or health, and nowhere does this continue to remain bafflingly true than audio output. Strap in, I’m about to get a bit ranty!</p>
<p>If we encounter an unwanted audio signal emanating from our computers, especially an uncomfortably-loud one over headphones, we should <em>immediately</em> be able to terminate it. No exceptions. If there is any latency <em>whatsoever</em> between us hitting a mute button and the audio not cutting out, the hardware or software has failed. Crypton Future Media’s Hatsune Miku wouldn’t tolerate latency with her headphones, and neither should we.</p>
<p><img src="https://rubenerd.com/files/2020/miku-headphones@1x.jpg" srcset="https://rubenerd.com/files/2020/miku-headphones@1x.jpg 1x, https://rubenerd.com/files/2020/miku-headphones@2x.jpg 2x" alt=""></p>
<p>I was in a conference call last Friday where I’d adjusted the volume up to compensate for the client’s quiet microphone, only to be audibly shot in the ears by an auto-playing video on a website. There is a <em>lot</em> of problematic stuff to unpack there, much of which is not the fault of the audio hardware or OS. But shocked in the moment, I hit the mute button on my MacBook Pro Touchbar, and it took a solid two seconds for it to register. My ears were ringing throughout the whole call. <em>This is unacceptable.</em></p>
<p>Well-engineered mute buttons on keyboards shouldn’t need to go to software, they should immediately send a signal to the motherboard’s DAC—ideally on a separate wire or connection—to say <em>terminate this signal</em>. Then it’s less of a concern if it takes the OS a few seconds to react to the change, because our ears have been spared.</p>
<p id="just-ackchyually">The <em>just ackchyually</em> crowd would don their Captain Obvious capes and brightly-coloured underwear to proclaim that people could <em>just</em> unplug their headphones, or rip them off ones head when suddenly inundated with loud audio. Sure, and if you start getting electric shocks from your keyboard you could <em>just</em> use an external one, bro. Or if you get your hand caught in a mixer, <em>just</em> use your other hand, that’s why you have two of them. There are so many reasons why this dismissive attitude is specious, but even if it weren’t, it would still take more physical effort <em>than a button</em>. And if a mute button doesn’t fulfill the function for which it’s labelled and designed, what’s the point of it? But then, these people know all that, they’re just being obtuse.</p>
<p>We have valid privacy arguments advocating for physical Wi-Fi, camera, and microphone buttons; I’d say audio should be voiced in these discussions too. They should be heard. Sound ideas should be reverberated. Miku.</p>
</div></div>]]>
            </description>
            <link>https://rubenerd.com/we-need-physical-audio-kill-switches/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24535408</guid>
            <pubDate>Sun, 20 Sep 2020 17:19:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Basic Printing on OpenBSD]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 27 (<a href="https://news.ycombinator.com/item?id=24535357">thread link</a>) | @paedubucher
<br/>
September 20, 2020 | https://paedubucher.ch/articles/2020-09-20-basic-printing-on-openbsd.html | <a href="https://web.archive.org/web/*/https://paedubucher.ch/articles/2020-09-20-basic-printing-on-openbsd.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I have a roughly ten year old Brother HL-5370DW printer on the shelf next to me.
This printer is mostly used by my wife to print sewing patterns. When I was
studying computer science, I sometimes printed documents I've written for
proofreading. I often was able to find typos that I didn't see on the screen
even after proofreading the document two or three times. However, I didn't
bother to print out my bachelor thesis. Printing 120 pages just for proofreading
just seemed a waste to me. I did my proofreading on the screen extra carefully,
and nobody complained about typos. (Which doesn't mean that there were none.)</p>
<p>Having finished my studies, I hardly ever print out documents. However, I still
prefer to read long texts on paper rather than on the screen. Therefore I often
buy technical books as paperbacks or hardcovers rather than ebooks. And if I buy
an ebook with demanding content, I print out those sections for offline reading.</p>
<p>Having switched to OpenBSD for my private computing shifted my reading habits
more towards manpages. When I need to figure out how something works on
OpenBSD, <code>apropos(1)</code> beats Google as a starting point in many cases. Some
manpages are really long, for example <code>ksh(1)</code>. I have a book on the Korn Shell
in my basement, which covers <code>ksh93</code>.  However, there are some differences
between <code>ksh93</code> and OpenBSD's <code>pdksh</code>. So reading the manpage not only gives me
more accurate information, but also <em>less</em> to read.</p>
<p>So why not printing out the manpage <code>ksh(1)</code>? I can do so even nicely formatted
using PostScript:</p>
<pre><code>$ man -T ps -O paper=a4 ksh &gt;ksh.1.ps
</code></pre>
<p>Now <code>ksh.1.ps</code> can be read with <code>zathura(1)</code>, given that the package
<code>zathura-ps</code> is installed:</p>
<pre><code># pkg_add zathura zathura-ps
$ zathura ksh.1.ps
</code></pre>
<p>But why using PostScript and not PDF like anybody else for the last twenty five
years? Because PostScript is the least common denominator and, thus, supported
out of the box by OpenBSD. (For fancier printing options, check out <code>cups</code>, but
I'd like to keep it minimalistic for the moment.)</p>

<p>I figured out how to configure my printer by reading the section <em>The lpd
Printing Daemon</em> in the 16th chapter of <a href="https://nostarch.com/obenbsd2e">Absolute OpenBSD (2nd
Edition)</a> (p. 306-307) by <a href="https://mwl.io/">Michael W
Lucas</a>. This is how I applied the configuration to my local
setup.</p>
<p>First, I created the file <code>/etc/printcap</code> with the following content:</p>
<pre><code>lp|brother:\
    :sh=:\
    :rm=192.168.178.52:\
    :sd=/var/spool/output/brother:\
    :lf=/var/log/lpd-errs:\
    :rp=brother
</code></pre>
<p>There must be a newline at the end of the file. The line breaks are escaped
using backslashes, except for the last line. The options are defined as follows:</p>
<ul>
<li>The first line defines two names for my printer: <code>lp</code>, which should always be
  there, and <code>brother</code>, which is my arbitrary name for the printer.</li>
<li>The second line (<code>sh</code>) defines that no <em>burst page</em> (summarizing the last
  print job on a special page) should be printed.</li>
<li>The third line (<code>rm</code>) refers to the printer on the network. My FritzBox always
  gives the same IP to my printer. It's also possible to use the printer's
  hostname.</li>
<li>The fourth line (<code>sd</code>) defines the spooler directory for this printer. Print
  jobs are written into that directory.</li>
<li>The fifth line (<code>lf</code>) defines a log file for error messages, which you hopefully
  never need to check.</li>
<li>The sixth line (<code>rp</code>) defines the remote printer name.</li>
</ul>
<p>Next, the spooler directory needs to be created. It must be owned by the user
<code>root</code> and the group <code>daemon</code>. Regular users need write access to this directory
in order to print documents:</p>
<pre><code># mkdir /var/spool/output/brother
# chown -R root:daemon /var/spool/output/brother
# chmod 770 /var/spool/output/brother
</code></pre>
<p>Now the printer daemon <code>lpd</code> needs to be activated. To do so on system startup,
add the following line to <code>/etc/rc.conf/local</code>:</p>
<pre><code>lpd_flags=""
</code></pre>
<p>Then start the service:</p>
<pre><code># /etc/rc.d/lpd restart
</code></pre>
<p><strong>Update (2020-09-21)</strong>: As one reader on
<a href="https://news.ycombinator.com/item?id=24535357#24538879">Hacker News</a> pointed
out, the last two steps can be performed using <code>rcctl(8)</code>:</p>
<pre><code># rcctl enable lpd
# rcctl restart lpd
</code></pre>
<p>The manpage says that <code>rcctl(8)</code> was introduced in OpenBSD 5.7 back in 2015.
<em>Absolute OpenBSD (2nd Edition)</em> is from 2013 and, thus, older than that. (At
the time of this writing, I'm using Version 6.7.)</p>
<p>Another reader pointed out that setting the access rights to <code>777</code> is a bad
practice. That's true, and I actually got the reasoning behind this wrong: I
thought any user must be able to write to the spooler, because any user is
supposed to print. However, it's <code>lpd</code> that is writing to the spooler, which of
course runs under the <code>daemon</code> group. Therefore, the access rights for
<code>/var/spool/output/brother</code> should be set to <code>770</code>, not to <code>777</code> (as corrected
above).</p>

<p>Now the printer is ready to accept jobs. In order to print the PostScript file
generated before, just run <code>lpr</code> on the file:</p>
<pre><code>$ lpr ksh.1.ps
</code></pre>
<p>It's also possible to send the PostScript output directly to the printer (this
is Unix, after all), if no preview is needed:</p>
<pre><code>$ man -T ps -O paper=a4 ksh | lpr
</code></pre>
<p>Printing plain text files behaved strange on my setup, but could to using the
<code>pr</code> formatter with <code>lpr</code> as follows:</p>
<pre><code>$ lpr -p plain.txt
</code></pre>
<p>Instead, I also convert plain text files to PostScript, which looks quite nice
on paper. I use <code>enscript(1)</code> for this task:</p>
<pre><code># pkg_add enscript
$ enscript plain.txt -o plain.ps
$ lpr plain.ps
</code></pre>
<p>PDFs can also be converted to PostScript using <code>pdf2ps(1)</code>, which comes with
GhostScript, i.e. the <code>ghostscript</code> package:</p>
<pre><code>$ pdf2ps document.pdf document.ps
</code></pre>
<p>Unfortunately, this doesn't work with all PDFs. But for the time being, I have
enough manpages to read. Printing PostScript works extremely fast, by the way.
When I press return at the end of a <code>lpr</code> command, I can see the status LED on
my printer start blinking almost immediately.</p></div></div>]]>
            </description>
            <link>https://paedubucher.ch/articles/2020-09-20-basic-printing-on-openbsd.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24535357</guid>
            <pubDate>Sun, 20 Sep 2020 17:15:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tarsnap – cleaning up old backups]]>
            </title>
            <description>
<![CDATA[
Score 74 | Comments 24 (<a href="https://news.ycombinator.com/item?id=24535046">thread link</a>) | @tosh
<br/>
September 20, 2020 | https://dan.langille.org/2020/09/10/tarsnap-cleaning-up-old-backups/ | <a href="https://web.archive.org/web/*/https://dan.langille.org/2020/09/10/tarsnap-cleaning-up-old-backups/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<div>
<p>I use <a href="https://www.tarsnap.com/">Tarsnap</a> for my critical data. Case in point, I use it to backup my Bacula database dump. I use Bacula to backup my hosts. The database in question keeps track of what was backed up, from what host, the file size, checksum, where that backup is now, and many other items. Losing this data is annoying but not a disaster. It can be recreated from the backup volumes, but that is time consuming. As it is, the file is dumped daily, and rsynced to multiple locations.</p>
<p>I also backup that database daily via <span>tarsnap</span>. I’ve been doing this since at least 2015-10-09.</p>
<p>The uncompressed dump of this PostgreSQL database is now about 117G. </p>
<pre># ls -l bacula.dump 
-rw-r-----  1 10839  10839  125497737071 Sep  8 03:29 bacula.dump
</pre>
<p>Let’s look at recent usage by that host:</p>
<div id="attachment_6180"><p><a href="https://dan.langille.org/wp-content/uploads/2020/09/tarsnap-usage.png"><img aria-describedby="caption-attachment-6180" loading="lazy" src="https://dan.langille.org/wp-content/uploads/2020/09/tarsnap-usage-634x1024.png" alt="tarsnap recent usaage" width="634" height="1024" srcset="https://dan.langille.org/wp-content/uploads/2020/09/tarsnap-usage-634x1024.png 634w, https://dan.langille.org/wp-content/uploads/2020/09/tarsnap-usage-186x300.png 186w, https://dan.langille.org/wp-content/uploads/2020/09/tarsnap-usage.png 747w" sizes="(max-width: 634px) 100vw, 634px"></a></p><p id="caption-attachment-6180">tarsnap recent usaage</p></div>
<p>The latest <span>Daily storage</span> value is 96G.</p>
<p>Using this command, I obtained a list of the archives stored:</p>
<pre>tarsnap --list-archives -vv &gt; ~/tarsnap-knew-archive-list
</pre>
<p>See <a href="https://www.tarsnap.com/man-tarsnap.1.html">man 1 tarsnap</a></p>
<p>I found 1751 archives, the oldest one was created on 2015-10-08 19:01:17.</p>
<p>This is a great example of <a href="https://www.tarsnap.com/deduplication-examples.html">Tarsnap deduplication and compression</a>.  I have 5 years of backups taking up only 96G and the latest backup is 113G.</p>
<p>By comparison, my other <span>tarsnap</span> backups take up this amount of space:</p>
<hr>
<table>
<tbody><tr>
<th>backup</th>
<th>size</th>
</tr>
<tr>
<td>bacula dump</td>
<td>96G</td>
</tr>
<tr>
<td>bacula configuration</td>
<td>13.7G</td>
</tr>
<tr>
<td>subversion</td>
<td>8G</td>
</tr>
<tr>
<td>supernews</td>
<td>32.5G</td>
</tr>
<tr>
<td>zuul-postgresql</td>
<td>0.18G</td>
</tr>
<tr>
<td>zuul-mysql</td>
<td>0.57G</td>
</tr>
<tr>
<td>zuul-pg02</td>
<td>5.7G</td>
</tr>
</tbody></table>
<hr>
<p>I’m going to trim down the dump archives, for sure.</p>
<p>I’m curious about that bacula configuration archive.  The Bacula configuration is only about 600K:</p>
<pre>$ cd /usr/local/etc/bacula
$ sudo du -ch .
608K	.
608K	total
$ </pre>
<p>Checking the archive list for that machine, I find 6 database backups from early October 2015.</p>
<p>Let’s delete those backups first. The names of those archives are:</p>
<pre title="">bacula.int.BaculaDatabase.2015-10-02
bacula.int.BaculaDatabase.2015-10-03
bacula.int.BaculaDatabase.2015-10-05
bacula.int.BaculaDatabase.2015-10-06
bacula.int.BaculaDatabase.2015-10-07
bacula.int.BaculaDatabase.2015-10-08
</pre>
<p>Let’s delete one:</p>
<pre># tarsnap -d -f bacula.int.BaculaDatabase.2015-10-02
                                       Total size  Compressed size
All archives                         196056412740      57482749453
  (unique data)                       50147278933      14694175940
This archive                          48831544077      14324291125
Deleted data                              2073099          1672760
# 
</pre>
<p>Let’s delete the rest (based on <a href="https://www.tarsnap.com/improve-speed.html">Delete multiple archives faster</a>:</p>
<pre>[dan@bacula:~] $ sudo tarsnap -d \
&gt; -f bacula.int.BaculaDatabase.2015-10-03 \
&gt; -f bacula.int.BaculaDatabase.2015-10-05 \
&gt; -f bacula.int.BaculaDatabase.2015-10-06 \
&gt; -f bacula.int.BaculaDatabase.2015-10-07 \
&gt; -f bacula.int.BaculaDatabase.2015-10-08
                                       Total size  Compressed size
All archives                         147224869967      43158468600
  (unique data)                       50147260360      14694156775
bacula.int.BaculaDatabase.2015-10-03      48831542773      14324280853
Deleted data                                18573            19165
                                       Total size  Compressed size
All archives                          98393327194      28834187747
  (unique data)                       50147241787      14694137610
bacula.int.BaculaDatabase.2015-10-05      48831542773      14324280853
Deleted data                                18573            19165
                                       Total size  Compressed size
All archives                          49561784421      14509906894
  (unique data)                       49265856159      14448990041
bacula.int.BaculaDatabase.2015-10-06      48831542773      14324280853
Deleted data                            881385628        245147569
                                       Total size  Compressed size
All archives                            314745728         65670242
  (unique data)                          19214507          4841679
bacula.int.BaculaDatabase.2015-10-07      49247038693      14444236652
Deleted data                          49246641652      14444148362
                                       Total size  Compressed size
All archives                            314744195         65668842
  (unique data)                          19212974          4840279
bacula.int.BaculaDatabase.2015-10-08             1533             1400
Deleted data                                 1533             1400
[dan@bacula:~] $ [dan@bacula:~] $ sudo tarsnap -d \
</pre>
<p>I won’t see the change in the ‘Recent account usage by machine’ page because that ‘updates shortly after midnight UTC’.  I’ll come back tomorrow.</p>
<p>In the meantime, I think I can delete all my old Bacula database backups from before 2020.  For fun, I will keep each backup from 01-01, and the oldest backup.</p>
<p>Here is how I can get that list from the existing file:</p>
<pre>[dan@knew:~] $ head /root/tarsnap-knew-archive-list 
bacula.int.BaculaDatabase.2020-08-13	2020-08-13 13:25:00	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2020-08-13 bacula.dump
bacula.int.BaculaDatabase.2018-08-17	2018-08-17 13:25:00	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2018-08-17 bacula.dump
bacula.int.BaculaDatabase.2018-11-08	2018-11-08 13:25:01	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2018-11-08 bacula.dump
bacula.int.BaculaDatabase.2020-07-08	2020-07-08 13:25:00	/usr/local/bin/tarsnap -c -f ˜tarbacula.int.BaculaDatabase.2020-07-08 bacula.dump
bacula.int.BaculaDatabase.2016-05-25	2016-05-25 13:25:02	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2016-05-25 bacula.dump
bacula.int.BaculaDatabase.2018-08-09	2018-08-09 13:25:02	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2018-08-09 bacula.dump
bacula.int.BaculaDatabase.2016-10-12	2016-10-12 13:25:00	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2016-10-12 bacula.dump
bacula.int.BaculaDatabase.2016-01-20	2016-01-20 13:25:00	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2016-01-20 bacula.dump
bacula.int.BaculaDatabase.2019-02-06	2019-02-06 13:25:00	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2019-02-06 bacula.dump
bacula.int.BaculaDatabase.2016-03-18	2016-03-18 13:25:04	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2016-03-18 bacula.dump
[dan@knew:~] $ cut -f 1 -w /root/tarsnap-knew-archive-list  | head
bacula.int.BaculaDatabase.2020-08-13
bacula.int.BaculaDatabase.2018-08-17
bacula.int.BaculaDatabase.2018-11-08
bacula.int.BaculaDatabase.2020-07-08
bacula.int.BaculaDatabase.2016-05-25
bacula.int.BaculaDatabase.2018-08-09
bacula.int.BaculaDatabase.2016-10-12
bacula.int.BaculaDatabase.2016-01-20
bacula.int.BaculaDatabase.2019-02-06
bacula.int.BaculaDatabase.2016-03-18
[dan@knew:~] $ 
</pre>
<p>Oh wait, let’s sort that to get a proper range:</p>
<pre>[dan@knew:/root] $ sort tarsnap-knew-archive-list | tail -2
bacula.int.BaculaDatabase.2020-09-05	2020-09-05 13:25:00	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2020-09-05 bacula.dump
bacula.int.BaculaDatabase.2020-09-07	2020-09-07 13:25:00	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2020-09-07 bacula.dump
[dan@knew:/root] $ 
</pre>
<pre>[dan@knew:/root] $ sort tarsnap-knew-archive-list | head -2
bacula.int.BaculaDatabase.2015-10-08	2015-10-08 19:01:17	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2015-10-08 bacula.dump
bacula.int.BaculaDatabase.2015-10-09	2015-10-09 13:25:00	/usr/local/bin/tarsnap -c -f bacula.int.BaculaDatabase.2015-10-09 bacula.dump
</pre>
<p>Backups going back 5 years. Yeah, that might be a bit excessive, even for me. I usually keep them for three years at home.</p>
<p>Knowing that, let’s select the entries I want to keep:</p>
<pre>[dan@knew:~] $ cut -f 1 -w /root/tarsnap-knew-archive-list  | egrep -e '-01-01|2015-10-08' | sort
bacula.int.BaculaDatabase.2015-10-08
bacula.int.BaculaDatabase.2016-01-01
bacula.int.BaculaDatabase.2017-01-01
bacula.int.BaculaDatabase.2019-01-01
bacula.int.BaculaDatabase.2020-01-01
[dan@knew:~] $ 
</pre>
<p>I sorted the output just to make it easier.</p>
<p>Now, dump everything else, by using <span>-v</span>, into a file:</p>
<pre>[dan@knew:~] $ cut -f 1 -w /root/tarsnap-knew-archive-list  | egrep -ve '-01-01|2015-10-08' &gt; tarsnap-volumes-to-delete
[dan@knew:~] $ wc -l tarsnap-volumes-to-delete 
    1746 tarsnap-volumes-to-delete
</pre>
<p>Oh wait, I forgot to exclude 2020</p>
<pre>[dan@knew:~] $ cut -f 1 -w /root/tarsnap-knew-archive-list  | egrep -ve '-01-01|2015-10-08|bacula.int.BaculaDatabase.2020' &gt; tarsnap-volumes-to-delete
[dan@knew:~] $ wc -l tarsnap-volumes-to-delete 
    1503 tarsnap-volumes-to-delete
[dan@knew:~] $ 
</pre>
<p>I used an editor to quickly modify that file to look like this:</p>
<pre>[dan@knew:~] $ head tarsnap-volumes-to-delete 
#!/bin/sh
-f bacula.int.BaculaDatabase.2018-08-17 \
-f bacula.int.BaculaDatabase.2018-11-08 \
-f bacula.int.BaculaDatabase.2016-05-25 \
-f bacula.int.BaculaDatabase.2018-08-09 \
-f bacula.int.BaculaDatabase.2016-10-12 \
-f bacula.int.BaculaDatabase.2016-01-20 \
-f bacula.int.BaculaDatabase.2019-02-06 \
-f bacula.int.BaculaDatabase.2016-03-18 \
-f bacula.int.BaculaDatabase.2018-01-15 \
[dan@knew:~] $ 
</pre>
<p>This delete will take a while so I started a <span>tmux</span> session.  I did a <span>chmod +x</span> on the file.</p>
<p>I started the command and went on to do other lines.  It is deleting 1500 archives. It will be a few hours at least I think.</p>
<pre>[dan@knew:~] $ time sudo ./tarsnap-volumes-to-delete
</pre>
<p>I wish I sorted that list. I’d know easily where we were.</p>
<p>I know we are on <span>bacula.int.BaculaDatabase.2018-08-19</span> which is line 836 of 1505.</p>
<pre> $ ps auwwx | grep tmux
dan        78234   0.0  0.0   14344    5872  -  Is   13:15       0:00.36 tmux: server (/tmp//tmux-1001/default) (tmux)
</pre>
<p><span>tmux</span> was started at 13:15 and it is now 20:49 – so that’s 7.5 hours to get about half-way through. This should finish overnight.</p>
<p>Night passes….</p>
<p>The next morning I found:</p>
<pre>real    819m10.118s
user    372m34.315s
sys     3m23.045s
</pre>
<p>That is 13 hours and 40 minutes, or about 18 every 10 minutes.</p>
<p>I want to compare before and after disk usage, but I may have to wait until 0000 UTC when the statistics are updated.</p>
<p>The next day (2020-09-10), I found these …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dan.langille.org/2020/09/10/tarsnap-cleaning-up-old-backups/">https://dan.langille.org/2020/09/10/tarsnap-cleaning-up-old-backups/</a></em></p>]]>
            </description>
            <link>https://dan.langille.org/2020/09/10/tarsnap-cleaning-up-old-backups/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24535046</guid>
            <pubDate>Sun, 20 Sep 2020 16:43:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Laid Off, Now What?]]>
            </title>
            <description>
<![CDATA[
Score 395 | Comments 355 (<a href="https://news.ycombinator.com/item?id=24534685">thread link</a>) | @bbhat
<br/>
September 20, 2020 | https://bharathpbhat.github.io/2020/09/19/laid-off-now-what.html | <a href="https://web.archive.org/web/*/https://bharathpbhat.github.io/2020/09/19/laid-off-now-what.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>As an immigrant on an H1B, you have exactly 60 days to find a new job when you are laid-off. This is a very short window of time to explore and land any job, let alone a job that matches your skills and interests. I found myself in this situation along with many others when Uber announced <a href="https://www.theverge.com/2020/5/18/21262337/uber-layoff-3000-employees-covid-19-coronavirus">layoffs</a> earlier this year. The following is a recollection of some things that worked well for me during my eventually successful job hunt.</p>
<ul>
<li><a href="#always-be-prepping">Always be Prepping</a></li>
<li><a href="#reach-out-to-everyone">Reaching Out</a></li>
<li><a href="#interview-preparation">Interview Preparation</a></li>
<li><a href="#closing-thoughts">Closing Thoughts</a></li>
</ul>
<h3 id="always-be-prepping">Always be prepping</h3>
<p>Coding interviews are hard to crack if you haven't been prepping, so I was lucky that I had been spending roughly 3-4 hours every week on <a href="http://leetcode.com/">leetcode</a>, from about 2 months before the layoff rumours broke. I was lucky that</p>
<ul>
<li>I knew that I wanted to change jobs in any case and</li>
<li>Rumours of layoffs broke approximately a month before the actual layoffs happened, giving me more lead time to prepare and send out emails to recruiters and friends.</li>
</ul>
<p>Whenever there's an economic downturn, I think it's critical to be acutely aware of what's happening at the company and start preparing for job interviews right away.</p>
<h3 id="reach-out-to-everyone">Reach out to everyone</h3>
<p>One of the hardest things to do when you are laid off is to write to your friends and family seeking help. But if there's ever a time to swallow your pride, then this is it. I reached out to everyone I knew, and told them plainly about my situation, and asked to be recommended to specific roles at their companies, or to tell their friends who may be hiring. I am extremely grateful to the help I got from my network, and the kind messages that I received. So many friends wrote to make sure I was okay, and kept checking in throughout the interview process, and they all have my immense gratitude.</p>
<p>It is tempting to just apply on the careers page when you find relevant roles at a company instead of spending time on finding connections and reaching out to them, but in my experience, it was very much worth it. Response times from recruiters was roughly 1-2 days when I was referred by an employee, whereas applying on the careers page was a hit or miss. One BigCo. took 40 days to respond, while some smaller companies were much quicker (3-4 days).</p>
<h4 id="the-process">The Process</h4>
<p>In terms of companies, cast a wide net because you absolutely need <em>a</em> job before a deadline. The steps are the obvious ones:</p>
<ol>
<li>Make a list of companies</li>
<li>For each company, compile a list of open job profiles that are relevant.</li>
<li>Email/Text a connection at the company, or apply on the careers page if all else fails.</li>
</ol>
<p>I think I reached out to an initial list of 10 companies or so on the day news of the layoffs broke. This worked well because there's at least a week's time before you speak to a hiring manager or interviewer from when you reach out, so there's ample time to prepare.</p>
<p>What companies to reach out to? In my case, it was the usual suspects (FAANG), and then some domain specific ones such as autonomous vehicle companies. The two most common roles that I applied to were:</p>
<ul>
<li><strong>Machine Learning Engineer</strong> - This is a hybrid role with ML + Software Engineering skills needed, and job roles usually talk about some specific domain such as recommendation systems, or in the case of autonomous vehicles, things such as perception or object detection. I typically looked for some mention of Computer Vision, NLP and deep learning.</li>
<li><strong>Machine Learning Infra Engineer</strong> - This role tends to be more on the software systems side, and deals with the infra for training and serving ML models for production workloads.</li>
</ul>
<h3 id="interview-preparation">Interview Preparation</h3>
<ul>
<li><a href="#an-initial-screen-with-the-hiring-manager">Hiring Manager Screen</a></li>
<li><a href="#coding-interviews-phone--onsite">Coding Interviews</a></li>
<li><a href="#machine-learning-interviews">Machine Learning Interviews</a></li>
<li><a href="#behavioral-interviews">Behavioral Interviews</a></li>
</ul>
<p>Interviewing for ML specific roles typically involves a few different kinds of interviews, each of which needs specific preparation. I'm outlining the most common ones I saw below:</p>
<h3 id="an-initial-screen-with-the-hiring-manager">An initial screen with the hiring manager</h3>
<p>Companies that do general interviews (Google / Facebook) don't have this step, but most others do. I personally like this, because it means that you are interviewing for a specific position in a specific team, and there's a high level of engagement from the beginning. Most of these calls were about getting to know me, and making sure I have relevant work experience, while some of them also were rapid fire technical questions. The latter ones were rare, and I encountered them when the manager wasn't certain that I was the right person for the job. In my experience, the introduction is the most important part of this interview (<strong>Tell me about yourself</strong>), and it helps to have prepared intros for each type of role that you are applying to. The idea is to tailor your story to highlight aspects of your work experience that are relevant to the job role. The next most important question is "<strong>What would you like to do in your next role?</strong>". Again, it helps immensely to be prepared to answer this question, and ideally, in a way so that there's reasonable overlap between your answer and what the role offers. Being able to answer this question also provides clarity to the job search process. For example, a consistent theme for me was to be (a) in an impactful / critical role for the company and (b) continue to work with the latest in ML.</p>
<p>Writing and rehearsing your stories often seems unimportant when compared to more tangible preparation steps such as spending time on leetcode, but I believe that it was critical, because it sets the tone and gives you confidence that you have done this in the past, and done it well, and there's no reason for the interviewer to doubt your abilities.</p>
<h3 id="coding-interviews-phone--onsite">Coding Interviews (Phone / Onsite)</h3>
<p>These are the standard leetcode style coding interviews, done using coderpad, or some similar service. The template for these is consistent across all companies, and involves 1 or 2 coding questions (or 1 question with follow-ups) that you are expected to implement and test. Some tips that were helpful for me preparation:</p>
<ol>
<li><strong>Get a premium subscription with leetcode</strong> - It is nice to be able to filter by companies and have access to the entire question bank, and it is good karma. The service is valuable and the creators should be compensated.</li>
<li><strong>Simulate the interview setting as much as possible</strong> - For example, I would set aside a 3 hour block of time for leetcode, shut myself in a room, and do 4 questions, 45 minutes each. If you are unable to solve a question in 45 minutes, you still move on to the next one. No extensions or looking at the solution. Think of it like moving on to the next interviewer. After the 3 hour session is done, go back to the questions as needed, either to look at solutions or to understand them better. A question is <code>Done</code> when your solution passes all the tests on leetcode and is <code>Accepted</code>.</li>
<li><strong>Talk out loud</strong> - This is big. Again, assuming that you are in an actual interview, talk out loud about the process you are using during these practice sessions. Talking out loud helps massively because you are forced to put your current train of thought into words, and it is often evident when a solution isn't justifiable.</li>
<li><strong>How to pick questions?</strong> - I filtered for questions that were tagged <code>Hard</code>, and then picked at random. No filter for company, or problem type. I went from doing all Mediums to a mix of Mediums and Hard to all Hards over a span of 4-5 weeks.</li>
<li><strong>How many questions to do?</strong> - In the first 2-3 weeks of my prep, I was doing 4 questions on one of the weekend days, and once I had more time post the lay-off news, it was 4 questions every 3 days or so. Overall, my stats look so:</li>
</ol>
<p><img src="https://bharathpbhat.github.io/assets/images/leetcode_xp.png" alt="Leetcode stats"></p>
<h3 id="machine-learning-interviews">Machine Learning Interviews</h3>
<p>These typically come in two flavors:</p>
<h4 id="concepts--basics">Concepts / Basics</h4>
<p>These are kind of like rapid fire questions where the interviewer will quiz you about ML basics. Some questions that I recall right now, to give a flavor of things:</p>
<pre><code>- What are some unsupervised learning methods?
- What is underfitting / overfitting?
- What is batch normalization? What's the motivation behind it?
- What is dropout? 
- What optimizers have you used? And typically some follow-up like, why does momentum make sense?
- What are some object detection techniques / papers that you are familiar with? (Computer Vision specific)
- What are decision trees? 
- How does logistic regression work?
- How do you train a linear regression model?
- What are some loss functions that you are familiar with?
- Why does Cross Entropy loss make sense?
- What are residual networks?
</code></pre>
<p>These are usually follow up questions where the interviewer will try to dig deeper into these concepts, often picking on some portion of the initial answer.</p>
<p>I did a lot of reading, and then some writing with a pen and paper for this part of the interview. If I am already somewhat/fairly familiar with a topic, like say, object detection, then my process was:</p>
<ol>
<li><strong>Write</strong> from memory a summary of what I remember about the topic</li>
<li>Note down <strong>questions</strong> for the parts that I am not clear about</li>
<li><strong>Read</strong> about the topic, and fill in whatever I missed on first go.</li>
</ol>
<p>If I don't remember much about a topic at all, like say, multi-armed bandits, then I would do step (3) first, and then do steps (1) and (2) a few days later, and eventually repeating step (3) as needed.</p>
<p>It helps to start with a list of topics that you want do this for. This list will grow as you remember more topics or expand the list of companies you are interviewing at. For reference, the list of topics I looked at is <a href="https://bharathpbhat.github.io/assets/files/index_card.pdf">here</a>, and a sample of the handwritten notes I made is here, for <a href="https://bharathpbhat.github.io/assets/files/rec_sys.pdf">recommendation systems</a>.</p>
<h4 id="ml-system-design">ML System Design</h4>
<p>This is my favorite interview, and corresponds neatly to skills used day to day as a ML practitioner. These are typically open ended interviews where the candidate is expected to design a product with some ML at its core. For example, things like:</p>
<pre><code>- Let's build a model that ranks photos in your photo library based on quality.
- How would you build a model that identifies pedestrians from drone imagery?
- Let's build a model that can does face detection for a user's photo library.
- How do you build a model that automatically picks out …</code></pre></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bharathpbhat.github.io/2020/09/19/laid-off-now-what.html">https://bharathpbhat.github.io/2020/09/19/laid-off-now-what.html</a></em></p>]]>
            </description>
            <link>https://bharathpbhat.github.io/2020/09/19/laid-off-now-what.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24534685</guid>
            <pubDate>Sun, 20 Sep 2020 15:54:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why is unauthenticated encryption insecure?]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 36 (<a href="https://news.ycombinator.com/item?id=24534619">thread link</a>) | @todsacerdoti
<br/>
September 20, 2020 | https://cybergibbons.com/reverse-engineering-2/why-is-unauthenticated-encryption-insecure/ | <a href="https://web.archive.org/web/*/https://cybergibbons.com/reverse-engineering-2/why-is-unauthenticated-encryption-insecure/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Cryptography is a complex subject. There are many subtle issues that can be introduced if you don’t know what you are doing.</p>



<p>There is a common mantra: “don’t roll your own crypto”. This is because both inexperienced and experienced developers frequently build cryptographic systems that are insecure.</p>



<p>However, there has to be a line – when does it start becoming “rolling your own”? Particularly in embedded systems, there are times when custom protocols need to be used, and developers stray into the dangerous area of cryptography.</p>



<p>One of the most common mistakes we have seen is the use of unauthenticated encryption.</p>



<h3>What is encryption?</h3>



<p>Encryption is encoding a plaintext into a ciphertext using a key, with the goal of keeping the plaintext confidential.</p>



<p>Only someone with the correct key should be able to decrypt the ciphertext and turn it back into plaintext.</p>



<p>Encryption provides confidentiality. It stops someone working out what the message is.</p>



<h3>So what’s the issue?</h3>



<p>An attacker can modify the ciphertext and cause the plaintext to change. There is no inherent means in encryption to detect this change.</p>



<p>Encryption does not provide authenticity. You cannot check that the message is genuine and has not been tampered with.</p>



<h3>What can an attacker do with this?</h3>



<p>I’m going to describe one attack against unauthenticated encryption.</p>



<p>Many encryption algorithms only operate on fixed-size blocks of data – they are called <a href="https://en.wikipedia.org/wiki/Block_cipher">block ciphers</a>. To encrypt longer lengths of data, a <a href="https://en.wikipedia.org/wiki/Block_cipher_mode_of_operation">mode of operation</a> is used to apply the block cipher repeatedly.</p>



<p>One mode of operation is called <a href="https://en.wikipedia.org/wiki/Block_cipher_mode_of_operation#Cipher_block_chaining_(CBC)">CBC</a> (Cipher Block Chaining). When encrypting the data, the previous ciphertext block is mixed into the current plaintext block using an operation called “<a href="https://en.wikipedia.org/wiki/Exclusive_or">exclusive OR</a>“. This is denoted with the + in a circle in diagrams.</p>



<figure><img src="https://upload.wikimedia.org/wikipedia/commons/8/80/CBC_encryption.svg" alt=""></figure>



<p>There is also an input called the initialisation vector, or IV. This is a random input to the algorithm, and is intended to ensure that the ciphertext is different, even if the same plaintext is encrypted. This prevents leaking information about the content.</p>



<p>The initialisation vector is transmitted alongside the ciphertext.</p>



<p>Decryption is similar. The previous ciphertext block is exclusive ORed with the output of the block cipher to obtain the plaintext.</p>



<figure><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/2/2a/CBC_decryption.svg/1200px-CBC_decryption.svg.png" alt=""></figure>



<p>Exclusive OR is a deterministic operation. If we look at a single bit, then it operates as follows:</p>



<figure><table><tbody><tr><td>A</td><td>B</td><td>Output</td></tr><tr><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>1</td><td>1</td></tr><tr><td>1</td><td>0</td><td>1</td></tr><tr><td>1</td><td>1</td><td>0</td></tr></tbody></table></figure>



<p>I always think of this as “if one input is high, invert the other input, otherwise leave it alone”.</p>



<p>The operation is carried out for each bit in a byte.</p>



<pre><code>A: 0 1 0 1 1 0 0 1 (0x59)
B: 1 1 1 1 0 0 0 0 (0xF0)
O: 1 0 1 0 1 0 0 1 (0xA9)</code></pre>



<p>What this means is that modifying one of the inputs to exclusive OR results in a predictable change to the output. And the operation can be easily reversed.</p>



<pre><code>A: 0123456789ABCDEF
B: FFFF00FFF00F0FF0
O: FEDC459879A4C21F</code></pre>



<p>If we now exclusive OR the output with one of the inputs:</p>



<pre><code>A: FEDC459879A4C21F
B: FFFF00FFF00F0FF0
O: 0123456789ABCDEF</code></pre>



<p>Hopefully that explains exclusive OR.</p>



<p>Let’s look back to how CBC uses this in decryption. In the first block, the IV is exclusive ORed with the output of the block cipher. The IV is transmitted alongside the ciphertext and an attacker can modify both at at will.</p>



<figure><img loading="lazy" width="922" height="786" src="https://cybergibbons.com/wp-content/uploads/2020/09/Screenshot-2020-09-20-at-14.55.37.png" alt="" srcset="https://cybergibbons.com/wp-content/uploads/2020/09/Screenshot-2020-09-20-at-14.55.37.png 922w, https://cybergibbons.com/wp-content/uploads/2020/09/Screenshot-2020-09-20-at-14.55.37-300x256.png 300w, https://cybergibbons.com/wp-content/uploads/2020/09/Screenshot-2020-09-20-at-14.55.37-768x655.png 768w" sizes="(max-width: 922px) 100vw, 922px"></figure>



<p>We can encrypt the string “A dog’s breakfast” using a key and the initialisation vector of all 0x00 (<a href="https://gchq.github.io/CyberChef/#recipe=AES_Encrypt(%7B'option':'Hex','string':'0123456789ABCDEF0123456789ABCDEF'%7D,%7B'option':'Hex','string':'0000000000000000000000000000000'%7D,'CBC','Raw','Hex')&amp;input=QSBkb2cncyBicmVha2Zhc3Q">here</a> on CyberChef).</p>



<pre><code>Key: 0123456789ABCDEF0123456789ABCDEF
IV:  0000000000000000000000000000000
Plaintext: A dog's breakfast
Ciphertext: c7b1d96f0f520f33faaccfdc107f718aafe8892c3a29c76b0732a760a0f54f50</code></pre>



<p>Of course, this can be decrypted (<a href="https://gchq.github.io/CyberChef/#recipe=AES_Decrypt(%7B'option':'Hex','string':'0123456789ABCDEF0123456789ABCDEF'%7D,%7B'option':'Hex','string':'0000000000000000000000000000000'%7D,'CBC','Hex','Raw',%7B'option':'Hex','string':''%7D)&amp;input=YzdiMWQ5NmYwZjUyMGYzM2ZhYWNjZmRjMTA3ZjcxOGFhZmU4ODkyYzNhMjljNzZiMDczMmE3NjBhMGY1NGY1MA">here</a> on CyberChef).</p>



<p>If I change just one byte in the ciphertext, the entire message is corrupted (<a href="https://gchq.github.io/CyberChef/#recipe=AES_Decrypt(%7B'option':'Hex','string':'0123456789ABCDEF0123456789ABCDEF'%7D,%7B'option':'Hex','string':'0000000000000000000000000000000'%7D,'CBC','Hex','Raw',%7B'option':'Hex','string':''%7D)&amp;input=YzdiMmQ5NmYwZjUyMGYzM2ZhYWNjZmRjMTA3ZjcxOGFhZmU4ODkyYzNhMjljNzZiMDczMmE3NjBhMGY1NGY1MA">here</a> on Cyberchef). There’s no way for me to predictably modify this plaintext by changing the ciphertext.</p>



<pre><code>Key: 0123456789ABCDEF0123456789ABCDEF
IV:  0000000000000000000000000000000
Ciphertext: c7b2d96f0f520f33faaccfdc107f718aafe8892c3a29c76b0732a760a0f54f50
Plaintext: .L...Q½êU...ì7Ò.t</code></pre>



<p>But the attacker also has control over the IV. Let’s set the first byte of the IV to 0xFF (<a href="https://gchq.github.io/CyberChef/#recipe=AES_Decrypt(%7B'option':'Hex','string':'0123456789ABCDEF0123456789ABCDEF'%7D,%7B'option':'Hex','string':'FF00000000000000000000000000000'%7D,'CBC','Hex','Raw',%7B'option':'Hex','string':''%7D)&amp;input=YzdiMWQ5NmYwZjUyMGYzM2ZhYWNjZmRjMTA3ZjcxOGFhZmU4ODkyYzNhMjljNzZiMDczMmE3NjBhMGY1NGY1MA">here</a> on CyberChef). Only the first byte of the plaintext has changed!</p>



<pre><code>Key: 0123456789ABCDEF0123456789ABCDEF
IV:  FF00000000000000000000000000000
Ciphertext: c7b1d96f0f520f33faaccfdc107f718aafe8892c3a29c76b0732a760a0f54f50
Plaintext: ¾ dog's breakfast</code></pre>



<p>And it has changed predictably. The capital A (ASCII 0x41) has been exclusive ORed with 0xFF to become 0xBE (which decodes as ¾ although it’s above the normal ASCII range).</p>



<pre><code>A: 0 1 0 0 0 0 0 1 (0x41)
B: 1 1 1 1 1 1 1 1 (0xFF)
O: 1 0 1 1 1 1 1 0 (0xBE)</code></pre>



<p>This is a very high level of control! The attacker can now modify the plaintext without detection. Let’s try and significantly change the meaning of it.</p>



<p>The original message contained “A dog’s breakfast”. Can we change this canine feast into a feline one?</p>



<p>We exclusive OR the original plaintext with the desired one (<a href="https://gchq.github.io/CyberChef/#recipe=XOR(%7B'option':'UTF8','string':'The%20cat%5C's%20breakfast'%7D,'Standard',false)To_Hex('Space',0)&amp;input=VGhlIGRvZydzIGJyZWFrZmFzdA">here</a> on CyberChef). Notice how the output only has value for the characters we have changed.</p>



<pre><code>Original: A. .d.o.g.'.s. .b.r.e.a.k.f.a.s.t.
Original: 4120646f67277320627265616b66617374
Desired:  A. .c.a.t.'.s. .b.r.e.a.k.f.a.s.t.
Desired:  4120636174277320627265616b66617374
Output:   0000070e13000000000000000000000000</code></pre>



<p>Pop that output in as the IV to the decryption, and we’ve successfully changed the message (here on <a href="https://gchq.github.io/CyberChef/#recipe=AES_Decrypt(%7B'option':'Hex','string':'0123456789ABCDEF0123456789ABCDEF'%7D,%7B'option':'Hex','string':'0000070e13000000000000000000000000'%7D,'CBC','Hex','Raw',%7B'option':'Hex','string':''%7D)&amp;input=YzdiMWQ5NmYwZjUyMGYzM2ZhYWNjZmRjMTA3ZjcxOGFhZmU4ODkyYzNhMjljNzZiMDczMmE3NjBhMGY1NGY1MA">CyberChef</a>). All of this without even knowing the key.</p>



<pre><code>Key: 0123456789ABCDEF0123456789ABCDEF
IV:  0000070e130000000000000000000000
Ciphertext: c7b1d96f0f520f33faaccfdc107f718aafe8892c3a29c76b0732a760a0f54f50
Plaintext: A cat's breakfast</code></pre>



<p>Of course, the attacker needs to have knowledge of the plaintext to make use of this attack. However, it’s extremely common for some or all of the message to be known. For example, when we visit most websites, the first part of the response will be “HTTP/1.1 200 OK”. If this was only protected by CBC encryption, we could change that to “HTTP/1.1 404 No”, changing the behaviour of the browser (here on <a href="https://gchq.github.io/CyberChef/#recipe=AES_Decrypt(%7B'option':'Hex','string':'0123456789ABCDEF0123456789ABCDEF'%7D,%7B'option':'Hex','string':'00000000000000000006000000012400'%7D,'CBC','Hex','Raw',%7B'option':'Hex','string':''%7D)&amp;input=ZGJkY2FkYWZjYjQ5NTJiNDE0OTBhODM4NDFhYzgxZGE">CyberChef</a>).</p>



<p>This doesn’t just impact the first block of data either. After the first block, instead of the IV, the previous ciphertext block is used in the exclusive OR operation. The attacker can modify the ciphertext and end up controlling the plaintext.</p>



<figure><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/2/2a/CBC_decryption.svg/2880px-CBC_decryption.svg.png" alt=""></figure>



<p>This comes at a cost though – the previous plaintext block will be totally corrupted as a result.</p>



<p>To illustrate this, we can encrypt a longer block of text (<a href="https://gchq.github.io/CyberChef/#recipe=AES_Encrypt(%7B'option':'Hex','string':'0123456789ABCDEF0123456789ABCDEF'%7D,%7B'option':'Hex','string':'0000000000000000000000000000000'%7D,'CBC','Raw','Hex')&amp;input=VGhpcyBpcyBvdXIgd29ybGQgbm93Li4uIHRoZSB3b3JsZCBvZiB0aGUgZWxlY3Ryb24gYW5kIHRoZSBzd2l0Y2gsIHRoZQpiZWF1dHkgb2YgdGhlIGJhdWQuICBXZSBtYWtlIHVzZSBvZiBhIHNlcnZpY2UgYWxyZWFkeSBleGlzdGluZyB3aXRob3V0IHBheWluZwpmb3Igd2hhdCBjb3VsZCBiZSBkaXJ0LWNoZWFwIGlmIGl0IHdhc24ndCBydW4gYnkgcHJvZml0ZWVyaW5nIGdsdXR0b25zLCBhbmQKeW91IGNhbGwgdXMgY3JpbWluYWxzLiAgV2UgZXhwbG9yZS4uLiBhbmQgeW91IGNhbGwgdXMgY3JpbWluYWxzLiAgV2Ugc2VlawphZnRlciBrbm93bGVkZ2UuLi4gYW5kIHlvdSBjYWxsIHVzIGNyaW1pbmFscy4gIFdlIGV4aXN0IHdpdGhvdXQgc2tpbiBjb2xvciwKd2l0aG91dCBuYXRpb25hbGl0eSwgd2l0aG91dCByZWxpZ2lvdXMgYmlhcy4uLiBhbmQgeW91IGNhbGwgdXMgY3JpbWluYWxzLgpZb3UgYnVpbGQgYXRvbWljIGJvbWJzLCB5b3Ugd2FnZSB3YXJzLCB5b3UgbXVyZGVyLCBjaGVhdCwgYW5kIGxpZSB0byB1cwphbmQgdHJ5IHRvIG1ha2UgdXMgYmVsaWV2ZSBpdCdzIGZvciBvdXIgb3duIGdvb2QsIHlldCB3ZSdyZSB0aGUgY3JpbWluYWxzLg">here</a> on CyberChef).</p>



<p>Let’s change “baud” to “cats”. We need to locate the correct place in the ciphertext. AES (the encryption algorithm we are using) works in 16 byte blocks. The word “baud” is 85 characters in, so in the 6th block. We therefore want to modify the 5th block of ciphertext.</p>



<p>The exclusive OR is a bit more complex than last time – we now need to exclusive OR the ciphertext, the original text, and the desired text (<a href="https://gchq.github.io/CyberChef/#recipe=AES_Decrypt(%7B'option':'Hex','string':'0123456789ABCDEF0123456789ABCDEF'%7D,%7B'option':'Hex','string':'0000000000000000000000000000000'%7D,'CBC','Hex','Raw',%7B'option':'Hex','string':''%7D)&amp;input=MTkxNWRkOGU4ODBhN2JlZjgzN2Y1NDRlMzBlZGI5YmQxMjA3ZjMwMmRjM2NlZGQwY2I2NGJkY2JiOTk3YjVkYmM4M2RhNjU3MmZkNmMyMDVmOGQ4ZDI2NjQ5MmQyMDY3M2U0NGZhNzUwNGU2YzY0ZTI4M2E2NzI2MmIyYzMwNjM4OGI4ZjQyZTBmYjMxNzdmNmFmMTNlMWE0OGUxNDBmYTFhNDhmMThmZGYyNTc3MzgwMTUwYzM5ZDIwZTYyY2QzMzQ1ZDVmNTFiYzU4NDU2NGUwMzc5MTFkYTM1MTc3YjVkY2ZmOTkxZTRmYzg3NDFlYmJjMmRmM2I2YTc3OGViOTU3MTI1MmQxYTY0Yjk5NmRhOWFkMzFmNGE5MTI3NjM0M2FhMmU1ODQ1NjEyOTM1MDg0Zjc3Y2FhMmRiNDRiYTM5OTA5NzFkOTcwZWVlMjFlZDc3MjRiOWU3MDMwODEyZWI4N2U1ZDVmYmI3Y2M1MGE1NzYxNDBiN2I0NzhiYmZiNzU1MGU1MWU3ZmM0ZTg5ODExY2Y4MTg1OTJjNGY4ZWU3NGIyNTQ0Y2VhMGE4ZDdkZjM0OTE2YjIzYmMwOWIxYWJhN2IwN2ZlNDM0YWRjNjY5MzhhNzczMDU4MjNhYzdkMWJjZmEwOGNlOTRhYzc0MjUzNjdiODQwMGE5NGFlMDc0ZTFhY2NmZDkwYThjNDllYmYzNDNkMmU4YWQ5MmI2NDZlZDM0OTM4Yzg3NTI2MDUyYjA4ZjQ1MzgxMWQ4YTYyZjE2MzczMzkxZmE4YTBlZGIwZDJlZDBhYWQyNDViY2RlZmI1YTk0ZmRmZTBkNzA4YTMwYTVjZDVlZmI5ZjExNTk3MDU2NWFiMjg1ZGUyY2FlYWNkMTI3YzBhNzhkZDRjNmE4Y2U2NjRjYTFiOWI0YjI1ODk0MTYxMmUzMjgwOWEwNGRhYzIxODlkNGVkN2Q2ZDU4ZDcwMGNlODM5NTIzYzlmNTZiOGU2YWY1NGIzYjMxYjAxM2E4ODM4MjljM2Y0YTJhZmI3Mzc3OTFjNjBiN2E1N2I4NGNhOTgxYjFiM2E3N2M2YmI5ZWNiMzIwNzk3YmVhNzAyMDk5NGUwNzRmYmQ1NzM0MWQwMmVjYTY3ZWM1NWU5YzA1MmFkODA3NjUzMmUxZTI4MDJjMzc2YmRhMzg1NWIxYzYzY2FhNzRhZmI0YTRjNTFkMDNlNGZiMjEzY2ZiMTM4YjcxMTc1NzFhNTIzOTQzZGU1MWJiNzZiYTgwMzY2MDNkNDI2NmFmMzI3MGMyYjBhOTNjZDdlYzkyZmVjMjA0MTAyYjJkYWZlNDliMzUwZDFhNDk2NjVhYjE0MTFiMjhkZWQ1MmE5ZWE5NTA3ZWU5ZDljM2M0NzI4ZDBlNTk0YjEzM2VkMmRiOGUwYWQxZjBjZWM0NWRhYjJlN2Y1ODE5YTQyNWQ4NTY2ZWQ5MGQwYzI4MTMzZjlkZTM4ODQ4OTE3NjJhYTcxMzc2MjZmNmM2MTEzMDY4M2NkNWEzYmFjN2EzNTFkZDY0MjZjYzI2NzdjOGRjYWI0ZDMwZjg0OGNiZjYwOTBmMjM4MDM2ZTFlMzczMGZmODc4MTk2YWYyMjg4YWY5MTU5ZThkZA">here</a> on CyberChef). But change those 4 bytes, and we change the word “baud” to “cats”.</p>



<figure><img loading="lazy" width="1024" height="272" src="https://cybergibbons.com/wp-content/uploads/2020/09/Screenshot-2020-09-20-at-16.03.54-1024x272.png" alt="" srcset="https://cybergibbons.com/wp-content/uploads/2020/09/Screenshot-2020-09-20-at-16.03.54-1024x272.png 1024w, https://cybergibbons.com/wp-content/uploads/2020/09/Screenshot-2020-09-20-at-16.03.54-300x80.png 300w, https://cybergibbons.com/wp-content/uploads/2020/09/Screenshot-2020-09-20-at-16.03.54-768x204.png 768w, https://cybergibbons.com/wp-content/uploads/2020/09/Screenshot-2020-09-20-at-16.03.54-1536x407.png 1536w, https://cybergibbons.com/wp-content/uploads/2020/09/Screenshot-2020-09-20-at-16.03.54.png 1682w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>The only issue is, as expected, the previous block has been entirely corrupted. Whilst in this case, it’s made part of the message nonsensical, it frequently has no impact when carrying out attacks.</p>



<h3>But there are worse problems?</h3>



<p>The above issue allows an attacker to modify the plaintext without detection. This would be an issue in certain situations, such as lock/unlock messages to a door.</p>



<p>But not authenticating your encryption can lead to worse issues. A type of attack called <a href="https://en.wikipedia.org/wiki/Padding_oracle_attack">padding oracle attacks</a> can let an attacker obtain the plaintext by sending a large number of specially crafted packets.</p>



<p>Block ciphers only operated on fixed blocks. If the data is shorter than a block, it must be padded. There are a number of ways of doing this, such as appending the number of padding bytes (e.g. 0x02 0x02 or 0x05 0x05 0x05 0x05 0x05). The process of decryption may check this padding is correct or not, and respond differently in each case. </p>



<p>An attacker can exploit these differential responses to leak the plaintext. This can break the confidentiality of messages.</p>



<h3>What’s the solution to this?</h3>



<p>Encryption should always be authenticated. There are two common solutions to this:</p>



<ul><li>Add a <a href="https://en.wikipedia.org/wiki/Message_authentication_code">Message Authentication Code</a> (MAC). This is a keyed cryptographic checksum that provides authenticity and integrity.</li><li>Use an authenticated mode of operation such as <a href="https://en.wikipedia.org/wiki/Block_cipher_mode_of_operation#Galois/Counter_(GCM)">GCM</a>.  </li></ul>



<p>Even with this advice, there are many pitfalls. Applying the authentication and encryption in the wrong order can lead to weaknesses; this is so common that it has been deemed the <a href="https://moxie.org/2011/12/13/the-cryptographic-doom-principle.html">Cryptographic Doom Principle</a>.</p>



<p>Generally, developers shouldn’t be working with cryptography at this level unless they are suitably skilled. That’s easy to say, harder to put into action. There is a big movement to make use of secure-by-default cryptographic libraries and APIs that provide developers with useful functions without giving them so much rope they can hang themselves.</p>



<p>There are scant few reasons for not authenticating encryption.</p>
			</div></div>]]>
            </description>
            <link>https://cybergibbons.com/reverse-engineering-2/why-is-unauthenticated-encryption-insecure/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24534619</guid>
            <pubDate>Sun, 20 Sep 2020 15:42:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apache Arrow and MinIO]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 45 (<a href="https://news.ycombinator.com/item?id=24534274">thread link</a>) | @jtsymonds
<br/>
September 20, 2020 | https://blog.min.io/turbocharging-minio-datalakes-with-arrowrdd/ | <a href="https://web.archive.org/web/*/https://blog.min.io/turbocharging-minio-datalakes-with-arrowrdd/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                    <p>More and more enterprises have begun or have already implemented a data lake strategy based on some of the work we did a couple of years ago. If you want to take a moment to review - you can find those posts below <a href="https://blog.min.io/modern-data-lake-with-minio-part-1/">here</a> and <a href="https://blog.min.io/modern-data-lake-with-minio-part-2/">here</a>. </p><h2 id="objective">Objective</h2><p>In this article, I am going to explain a mechanism to turbocharge the use of MinIO. Nothing changes as far as MinIO is concerned, the optimization will be on the underlying storage of our data. We are going to choose one of the latest formats to improve agility manifoldly. We are going to show the ways by which your data lake data can travel across systems without experiencing any "conversion" time. </p><h2 id="apache-arrow">Apache Arrow</h2><p>I believe understanding this article needs some basic concepts of<a href="https://arrow.apache.org/"> </a>how applications like Spark works. Let me explain it in simple terms.</p><p>Imagine you got a nice job at a location different from where you live currently and you want to relocate, as the new company demands it and pays for it. You have got the most modern televisions, refrigerators, super soft leather sofas, bed and so on. You engage a moving company, who comes, disassembles everything, packs it conveniently. They also make sure to pack as much possible in containers to fill the truck such that they can do it in a single trip. Once they reach the destination, they unpack, assembles and restore everything as it was.</p><p>The same applies to data. When I store some data in MinIO , and I need to feed it to, say, another application, say Spark, the consuming application needs to disassemble the data from MinIO data lake, pack it and transport it through the wire (or wireless), receive, unpack and re-assemble. </p><p>Let's use more technical terms for this disassembly and assembly - serialization and de-serialization of data. The unfortunate part is, both these processes are complex and time consuming. Here is a brief diagram illustrating what happens in Apache Spark when it reads data</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-1.54.30-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-1.54.30-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-1.54.30-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-1.54.30-AM.png 1600w, https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-1.54.30-AM.png 1944w" sizes="(min-width: 720px) 720px"><figcaption>Experimental setup. Courtesy: <a href="https://databricks.com/session/running-apache-spark-on-a-high-performance-cluster-using-rdma-and-nvme-flash">Spark Summit</a></figcaption></figure><p>You may not have noticed this problem before. Assume that MinIO is on a machine(s) on the network. We write a Spark Map-Reduce application. Eventhough the network limit is 100 GbE, we are almost getting less that 10 GbE speed. What's the use of this high speed network then? What is the potential problem which is not allowing us to utilize the full potential of the network, or at least 70-80% of it?</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-2.00.34-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-2.00.34-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-2.00.34-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-2.00.34-AM.png 1600w, https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-2.00.34-AM.png 1948w" sizes="(min-width: 720px) 720px"><figcaption>Additional layers, buffers and serializers</figcaption></figure><p>The issues are with the way in which Spark is retrieving the data. Look at the number of layers the data has to pass though. This creates a limit on the throughput that we can achieve. There are projects like <a href="https://crail.apache.org/">Apache Crail,</a> which are designed to address these issues.</p><h2 id="optimization-columnar-data-format">Optimization : Columnar Data Format </h2><div><p>If we think about the relocation example mentioned above, we see that the logistic company will never take the sofa as it is, they will break it down to make it easy to transport. Note that this is for transportation purposes only - if that objective is different, then disassembling the sofa might not be the right approach. </p><p>Given that the objective for a data lake is analytics - rather than transactional needs we must take that under consideration. For transactions, we often use OLTP systems like Oracle or PostGres - given that they are particularly well suited for the job. A quick review of OLAP's analytics requirements is probably in order. </p></div><figure><img src="https://blog.min.io/content/images/2020/09/Picture1.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Picture1.png 600w, https://blog.min.io/content/images/2020/09/Picture1.png 966w" sizes="(min-width: 720px) 720px"><figcaption>Introducing columnar format</figcaption></figure><p>Let's start with one of the most famous RDMBS table - the "emp" table of Oracle. The top part shows how the data is stored in RDBMS as a "relation" or "tuple". We call it a table. I am providing you two queries</p><!--kg-card-begin: markdown--><ol>
<li>select ename from emp where job = 'CLERK'</li>
<li>select sum(sal) from emp</li>
</ol>
<!--kg-card-end: markdown--><p>The first is a transactional query. It has to scan every row on the table and find out the name of the employee wherever the job is clerk. The second is an analytical query - rather than an atomic result, the goal is a general result. Unfortunately, the first and second query has to scan through all the rows, if we use RDBMS way of representation of data. If the size of data is 20 GB, all the 20 GB more or less will be scanned. This is the top part of above figure.</p><p>Let's make some changes - taking all of our columns and make them into rows. Like a transpose of a matrix - and see the bottom part of above figure, how your data will look like. Following this transposition, an entire block is just representing one column. How many blocks need to be scanned for the second analytical query? Just one block, probably around 2 GB of size. </p><p>The difference is significant? Columnar representation is what is being used in ORC (Optimized Row Columnar) and Parquet files - with the goal of making the analytics faster.</p><p>Columnar formats are easier to read, however, they pose another problem - they are usually stored in compressed format. As a result, the consuming application will need to uncompress it while reading and compress it back while writing. </p><p>Note this, as we will revisit the point later.</p><h2 id="the-science-of-reading-writing-data">The Science of Reading/Writing Data</h2><p>Let me explain briefly how reading/writing happens in a software system and what role is played by the hardware.</p><p>Microprocessors normally use two methods to connect external devices: <strong>memory mapped</strong> or <strong>port mapped</strong> I/O. </p><p>Memory mapped I/O is mapped into the same address space as program memory and/or user memory, and is accessed in the same way.</p><p>Port mapped I/O uses a separate, dedicated address space and is accessed via a dedicated set of microprocessor instructions.</p><p>In memory mapped approach, I/O devices are mapped into the system memory map along with RAM and ROM. To access a hardware device, simply read or write to those 'special' addresses using the normal memory access instructions.The advantage to this method is that every instruction which can access memory can be used to manipulate an I/O device.</p><p>Usually applications use Port mapped I/O. If we are using memory mapped I/O for a particular format, it will be faster, especially for analytical needs. When combined with our columnar data format, then it becomes even more advantageous.</p><p>Welcome to <a href="https://arrow.apache.org/">Apache Arrow</a>. </p><p>Arrow uses memory mapped I/O and avoids serialization/deserialization overheads when you convert between most of the formats while leveraging the columnar data format. </p><p>Thanks to <a href="https://wesmckinney.com/">Wes McKinney</a> for this brilliant innovation, its not a surprise that such an idea came from him and team, as he is well known as the creator of Pandas in Python. He calls Arrow as the future of data transfer.</p><h2 id="store-data-in-minio-in-arrow-format">Store Data in MinIO in Arrow Format</h2><p>This is how we are going to make MinIO even more powerful. </p><p>We are going to store that data in Arrow and then let the consuming applications read it - resulting in dramatically increased speeds. Step one has us putting the data into MinIO in Arrow format. I was using my own approach until I saw a much better implementation from <a href="https://github.com/BryanCutler">Bryan Cutler</a>, whose contributions include integrating Arrow formats to Spark as well.</p><p>We will start with a a .csv file, in this case movie ratings downloaded from the <a href="https://movielens.org/">movielens</a> site. For illustration purposes, I took about 100K rows. First, let's write a Spark program to read this CSV file and write it into Arrow format using Arrow RDD. You can get the full code from the link given towards the bottom of this article.</p><p>Step 1: build.sbt , please note the arrow dependencies</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-4.38.17-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-4.38.17-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-4.38.17-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-4.38.17-AM.png 1600w, https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-4.38.17-AM.png 1990w" sizes="(min-width: 720px) 720px"><figcaption>See lines 18 and 19, we have Arrow related dependencies with Spark</figcaption></figure><p>We will use Spark 3.0, with Apache Arrow 0.17.1</p><p>The ArrowRDD class has an iterator and RDD itself. For creating a custom RDD, essentially you must override mapPartitions method. You can browse the code for details. </p><p>Next, start MinIO and create a bucket named "arrowbucket". </p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-4.26.37-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-4.26.37-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-4.26.37-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-4.26.37-AM.png 1600w, https://blog.min.io/content/images/size/w2400/2020/09/Screen-Shot-2020-09-06-at-4.26.37-AM.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Create a bucket named "arrowbucket" in MinIO</figcaption></figure><p>Let's use ArrowRDD and create an ArrowFile in local. Here is the code:</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-4.48.45-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-4.48.45-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-4.48.45-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-4.48.45-AM.png 1600w, https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-4.48.45-AM.png 2372w" sizes="(min-width: 720px) 720px"><figcaption>Writing Arrow file with ArrowRDD</figcaption></figure><p>Lines 22 to 34 do the main part. Compile and execute the code:</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-4.50.42-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-4.50.42-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-4.50.42-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-4.50.42-AM.png 1600w, https://blog.min.io/content/images/size/w2400/2020/09/Screen-Shot-2020-09-06-at-4.50.42-AM.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Execute the code</figcaption></figure><p>As you see from code, the Arrow format file is is generated in data directory. Let's copy it to the MinIO bucket we created earlier (bucket name is arrowbucket)</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-5.04.23-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-5.04.23-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-5.04.23-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-5.04.23-AM.png 1600w, https://blog.min.io/content/images/size/w2400/2020/09/Screen-Shot-2020-09-06-at-5.04.23-AM.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Copy the arrow file we generated to MinIO bucket</figcaption></figure><p>Let's have some fun now. </p><p>Use your favorite Python editor, and write some code. First, let us start with Spark reading the file and converting it to a dataframe, with and without Arrow enabled options.</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-11.52.01-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-11.52.01-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-11.52.01-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-11.52.01-AM.png 1600w, https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-11.52.01-AM.png 1698w" sizes="(min-width: 720px) 720px"><figcaption>Initializing Spark context and connection parameters to Minio</figcaption></figure><p>Start your Spark cluster. Complete the code with all settings and check whether we created the Spark context successfully. To ensure that our app (named Minio-Arrow-Spark at line 8) is connected, just check the Spark UI. You should see something like this:</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-11.46.01-AM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-11.46.01-AM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-11.46.01-AM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-11.46.01-AM.png 1600w, https://blog.min.io/content/images/size/w2400/2020/09/Screen-Shot-2020-09-06-at-11.46.01-AM.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Spark UI (default localhost:8080) is showing our app is connected</figcaption></figure><p>Run the below code now:</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-11.09.47-PM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-11.09.47-PM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-11.09.47-PM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-11.09.47-PM.png 1600w, https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-11.09.47-PM.png 1708w" sizes="(min-width: 720px) 720px"><figcaption>Reading from MinIO with Arrow format "not enabled" (top) and "enabled"(bottom)</figcaption></figure><p>The output which displays the time, shows the power of this approach. The performance boost is tremendous, almost 50%.</p><p>Recall that we created an ArrowRDD earlier and used it to write to MinIO. Let us test the memory consumption in reading it. We will use different methods.</p><figure><img src="https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-11.17.22-PM.png" alt="" srcset="https://blog.min.io/content/images/size/w600/2020/09/Screen-Shot-2020-09-06-at-11.17.22-PM.png 600w, https://blog.min.io/content/images/size/w1000/2020/09/Screen-Shot-2020-09-06-at-11.17.22-PM.png 1000w, https://blog.min.io/content/images/size/w1600/2020/09/Screen-Shot-2020-09-06-at-11.17.22-PM.png 1600w, https://blog.min.io/content/images/2020/09/Screen-Shot-2020-09-06-at-11.17.22-PM.png 1882w" sizes="(min-width: 720px) 720px"><figcaption>See the results - Arrow is zero copy memory format</figcaption></figure><p>We are reading different file formats and seeing the memory consumption for each. As it is evident, Arrow format based files are zero copy - almost no memory consumed at all.</p><p>By combining MinIO with the Arrow Format, you can enhance your analytics ecosystem and virtually eliminating the friction associated with converting between different formats. This is primarily due to the reduction of serialization overhead.</p><h2 id="code">Code </h2><p>You can see the<a href="https://github.com/passionbytes/ArrowRDD"> Jupyter notebook and ArrowRDD code here</a>.</p><p>Ravishankar Nair is a technology evangelist, a consultant and an inspiring speaker. He is the CTO of PassionBytes, based in Florida. With his vast expertise in data engineering, Ravi provides consultancy in machine learning, modern data lakes and distributed computing technology. You can refer to his other articles related to MinIO here:</p><p>1) <a href="https://blog.min.io/modern-data-lake-with-minio-part-1/">Modern Data Lakes with Minio - Part 1</a></p><p>2) <a href="https://blog.min.io/modern-data-lake-with-minio-part-2/">Modern Data Lakes with MinIO - Part 2</a></p><p>3) <a href="https://blog.min.io/building-an-on-premise-ml-ecosystem-with-minio-powered-by-presto-r-and-s3select-feature/">Building an …</a></p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.min.io/turbocharging-minio-datalakes-with-arrowrdd/">https://blog.min.io/turbocharging-minio-datalakes-with-arrowrdd/</a></em></p>]]>
            </description>
            <link>https://blog.min.io/turbocharging-minio-datalakes-with-arrowrdd/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24534274</guid>
            <pubDate>Sun, 20 Sep 2020 14:32:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Yelp: Local Economic Impact Report]]>
            </title>
            <description>
<![CDATA[
Score 141 | Comments 172 (<a href="https://news.ycombinator.com/item?id=24534186">thread link</a>) | @bookofjoe
<br/>
September 20, 2020 | https://www.yelpeconomicaverage.com/business-closures-update-sep-2020.html | <a href="https://web.archive.org/web/*/https://www.yelpeconomicaverage.com/business-closures-update-sep-2020.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
      
    
    <section>
      <!--<p class='prose flag'><i>If you'd like additional detail on how the economy is shifting, please contact us at <a href='mailto:press@yelp.com'>press@yelp.com</a> or <a class=underline href=http://eepurl.com/cMFvGL target=_blank>join our mailing list</a> to receive an email when new reports are released.</i></p>-->
    
      
        <p>Since the first fears of the pandemic emerged in the U.S. in early March, businesses across the nation have endured six months of uncertainty. Yet, businesses are adapting and proving their resilience through lockdowns, reopenings, a <a href="https://www.nytimes.com/interactive/2020/us/coronavirus-us-cases.html?name=styln-coronavirus-markets&amp;region=TOP_BANNER&amp;variant=1_Show&amp;block=storyline_menu_recirc&amp;action=click&amp;pgtype=Article&amp;impression_id=76e345d2-e946-11ea-8ee3-5b12c6c78bc9" target="_blank">summer surge in virus cases</a>, new ways of doing business such as <a href="https://www.nytimes.com/2020/08/23/nyregion/outdoor-dining-new-york.html" target="_blank">outdoor dining</a>, new mask wearing rules and backlash from <a href="https://www.washingtonpost.com/nation/2020/07/18/covid-pandemic-store-clerk-north-carolina/?arc404=true" target="_blank">anti-mask patrons</a>, as well as milestones such as the <a href="https://www.yelpeconomicaverage.com/back-to-school-2020.html" target="_blank">return to school</a>. Even in the wake of increased closures we’re seeing businesses effectively transition to new operating models while keeping their employees and consumers safe.</p>
        <p>Yelp closure data shows that businesses providing home, local and professional services have been able to withstand the effects of the pandemic particularly well. But despite bright spots in some sectors, restaurants and retail continue to struggle and total closures nationwide have started to increase.</p>
        <p>The <a href="https://www.yelpeconomicaverage.com/yea-q2-2020.html" target="_blank">last Yelp Economic Average</a> showed a decreasing number of overall closures, 132,580 in total. As of August 31, 163,735 total U.S. businesses on Yelp have closed since the beginning of the pandemic (observed as March 1), a 23% increase since July 10. In the wake of COVID-19 cases increasing and local restrictions continuing to change in many states we’re seeing both permanent and temporary closures rise across the nation, with 60% of those closed businesses not reopening (97,966 permanently closed).</p>
    </section>
    
    <section>
      <h3>Business Closures Continue to Increase Nationally</h3>
      <h4>Number of businesses marked closed on Yelp that were open March 1</h4>
      <p><i></i>Hover over a circle to see closures</p>
    	
    </section>
    
    <!--
    <section class='report-wrapper'>
    	<h3 class='centered-title'>Business Closures Continue to Increase Nationally</h3>
      <h4 class='centered-title'>Number of businesses marked closed on Yelp that were open March 1</h4>
    
    	<div class='static-image-container'>
    		<img class='static-image-desktop' src='./assets/img/closures092020/Closures_Rate_Desktop-2a05305cb0.png'/>
    		<img class='static-image-tablet' src='./assets/img/closures092020/Closures_Rate_Desktop-2a05305cb0.png'/>
    		<img class='static-image-mobile' src='./assets/img/closures092020/Closures_Rate_Mobile-f0f8a42c99.png'/>
    	</div>
    </section>
    -->    <section>
    	<h2>Resilient Businesses Operating in an Unpredictable Economy</h2>
        <p>Some business sectors have been able to weather the COVID-19 storm particularly well. In general, professional services and solo proprietors as a whole have been able to maintain a relatively low fraction of closures since March 1. This group includes lawyers, real estate agents, architects, and accountants – all with only two to three out of every thousand businesses closed, as of August 31. Health related businesses in particular have been able to maintain a low rate of closures – orthopedists, internal medicine, hospitals, physicians, family doctors and OB/GYNs all have less than three closures out of every thousand businesses.</p>
        <p>Yelp’s closure data also shows that demand for <a href="https://blog.yelp.com/2020/08/yelp-reinvents-the-hiring-experience-for-home-and-local-services" target="_blank">home, local</a> and automotive services has remained robust with a far lower rate of closures compared to restaurants and retail. Towing companies, plumbers and contractors in particular have maintained a low rate of closures, with only six to seven out of every thousand businesses closed. In fact, the share of consumer interest in home and local services is up 24% between March 1 and August 31, relative to all categories on Yelp, compared to the same time last year.</p>
    </section>
    
    <section>
    	<h3>Home, Local, Professional, and Auto Services Prove Their Strength Amid the Pandemic</h3>
    
    	<p><img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Sector_Desktop-b84f739960.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Sector_Desktop-b84f739960.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Sector_Mobile-069e01b319.png">
    	</p>
    </section>    <section>
      <h2>Restaurants Remain Hardest Hit, Permanent and Temporary Closures Increase</h2>
        <p>The restaurant industry continues to be among the most impacted with an increasing number of closures – totalling 32,109 closures as of August 31, with 19,590 of these business closures indicated to be permanent (61%). Breakfast and brunch restaurants, burger joints, sandwich shops, dessert places and Mexican restaurants are among the types of restaurants with the highest rate of business closures. Foods that work well for delivery and takeout have been able to keep their closure rates lower than others, including pizza places, delis, food trucks, bakeries and coffee shops.</p>
        <p>Meanwhile, bars and nightlife, an industry 6X smaller than restaurants, has endured an especially high closure rate, with an increasing percentage of closures being permanent. As of the end of August there were 6,451 total business closures, of which 3,499 were permanently closed (54%). The share of permanent closures within bars and nightlife have increased by 10% since our <a href="https://www.yelpeconomicaverage.com/yea-q2-2020.html" target="_blank">Economic Average Report</a> in July.</p>
        <p>Retail and shopping follows closely behind restaurants with 30,374 total business closures, 17,503 of which are permanent (58%). Similar to bars and nightlife, the share of permanent closures increased by 10% since July. Both men and women’s clothing, as well as home decor, have the highest rate of business closures.</p>
        <p>The beauty industry has seen a 22% increase in closures since July, totalling 16,585 closures. Of all closed businesses in the beauty industry 7,002 won’t reopen (42%), a significant 43% increase since July when we reported that 4,897 of all closures in the beauty industry were permanent. Similarly the fitness industry has endured a 23% increase in closures since July, with 6,024 total closures, 2,616 of which are permanently closed.</p>
    </section>
    
    <section>
    	<h3>Restaurants and Retail Continue to Struggle</h3>
      <h4>Number of businesses marked closed on Yelp that were open March 1</h4>
    
    	<p><img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Category_Desktop-91d671567c.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Category_Desktop-91d671567c.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Category_Mobile-529b856e87.png">
    	</p>
    </section>    <section>
      <h2>Larger States and Metros See a Greater COVID-19 Impact on Local Businesses</h2>
        <p>Even as the pandemic spreads nationally, geographically Yelp data shows business closure rates vary across the country. Bigger states and metros with higher rents and more stringent local operations for small businesses throughout the last six months have felt a greater toll. So have businesses more closely linked to physical locations that require crowds of consumers to attain profitability. Meanwhile, smaller cities and solo operations that can do their work one-on-one or virtually have proven better positioned to stay in business.</p>
        <p>For the states with widespread business closures, the economic struggle appears to be closely coupled with unemployment rates. Hawaii, California, and Nevada have the highest rate of total closures and permanent closures – they’re also the three states with the <a href="https://finance.yahoo.com/news/these-states-are-suffering-from-the-worst-unemployment-rates-144451899.html?guccounter=1&amp;guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&amp;guce_referrer_sig=AQAAABND8yZDak2Xg6GnNC9LukDHqDayj3GYnFbfZn_9NctEnowVC1JMpg9oZFKixnWrRLGLPortUEEaymyEAYmZ0jMN8vOuriLR1N7S0Roqv9OT99H-WdN5XH_sd_I_r0-EgEJSDExY9yTtI7Xduv3Q-Agxb55dUepi3-k8T1fGZ153" target="_blank">highest unemployment rates</a>, and among the <a href="https://www.worldatlas.com/articles/the-most-visited-states-in-the-us.html" target="_blank">biggest states for tourism</a>. Meanwhile, West Virginia and the Dakotas have the lowest closure rates.</p>
        <p>The states with the most closures are home to the hardest-hit metros: Las Vegas in Nevada, Honolulu in Hawaii, and several of the largest California urban areas all are among the metro areas with the highest total closure and permanent closure rates (San Diego, San Francisco, San Jose, Los Angeles and others), with roughly 20 businesses per thousand temporarily or permanently closing their doors since March 1. Larger metros with far fewer closures tend to be in the East, including Pittsburgh, Philadelphia, and Baltimore, all with closure rates below 10 per thousand.</p>
    </section>
    
    <section>
    	<h3>Where are the Most Businesses Closed?</h3>
      <h4>Geographic areas with the largest number of business closures since March 1</h4>
    	<div>
    		<p>Total Closures</p>
    		<p>Closures per 1,000</p>
    	</div>
    
    	<p><img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Geography_Total_Desktop-dce0442da9.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Geography_Total_Desktop-dce0442da9.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Geography_Total_Mobile-98f53c8115.png">
    	</p>
    
    	<p><img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Geography_Capita_Desktop-846de29ad1.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Geography_Capita_Desktop-846de29ad1.png">
    		<img src="https://www.yelpeconomicaverage.com/assets/img/closures092020/Closures_Geography_Capita_Mobile-1878bbd645.png">
    	</p>
    </section>
    <section>
        <p>Keep an eye out for our next update in our Q3 <a href="https://www.yelpeconomicaverage.com/index.html" target="_blank">Yelp Economic Average</a>.</p>
        <p>—Carl Bialik and Daniel Gole contributed to this report</p>
    </section>
    
    <section>
        <p><em>If you'd like additional detail on how the economy is shifting, please contact us at <a href="https://www.yelpeconomicaverage.com/cdn-cgi/l/email-protection#e19193849292a198848d91cf828e8c"><span data-cfemail="a6d6d4c3d5d5e6dfc3cad688c5c9cb">[email&nbsp;protected]</span></a> or <a href="http://eepurl.com/cMFvGL" target="_blank">join our mailing list</a> to receive an email when new reports are released.</em></p>
        <p><em>Interested in learning how Yelp data can assist you in developing market insights for your business? Yelp Knowledge can help, learn more <a href="https://www.yelp.com/knowledge" target="_blank">here</a>.</em></p>
    </section>
    
    
    <!--
    <section class='report-wrapper'>
    </section>
    -->
    
    <section>
    	
    	<h2>Methodology</h2>
    
    		<p><em>Business Closures</em></p>
    		<p>On each date, starting with March 1, we count U.S. businesses that were open on March 1 and were closed on that day. Closure can be permanent or temporary, and is signaled by a business owner marking the business as closed, including by changing its hours or through a COVID-19 banner on its Yelp page. Closure counts are likely an estimate of the businesses most impacted, with many others not counted because they remain open with curtailed hours and staffing, or because they have not yet updated their Yelp business pages to reflect closures. Additionally, we only count closures that have been vetted by our User Ops team or have been updated directly by a business owner. Closures are counted by state, metro area, and category; some businesses are in more than one category. Businesses can also set automatic reopening dates on Yelp, which are counted as reopenings unless the business updates their information.</p>
    		<p><em>Downloadable static graphics can be found <a href="https://drive.google.com/drive/folders/1kSIOmVz_06NEP37NRfkODkzrpE0lAl3X?usp=sharing" target="_blank">here</a>.</em></p>
    		<p><em>See Yelp's previous Local Economic Impact Reports at our Data Science Medium, <a href="https://medium.com/tag/yelp-coronavirus-report/archive" target="_blank">Locally Optimal</a>.</em></p>
    </section>
    <section>
      <!-- <p class='prose'><strong>Interested in the numbers behind YEA? Check out the <a class='underline' href='./methodology.html'>methodology</a>.</strong></p> -->
      
    </section>    
  </div></div>]]>
            </description>
            <link>https://www.yelpeconomicaverage.com/business-closures-update-sep-2020.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24534186</guid>
            <pubDate>Sun, 20 Sep 2020 14:17:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Revisiting Apple Notes (6): The Protobuf]]>
            </title>
            <description>
<![CDATA[
Score 124 | Comments 47 (<a href="https://news.ycombinator.com/item?id=24533249">thread link</a>) | @LaSombra
<br/>
September 20, 2020 | https://ciofecaforensics.com/2020/09/18/apple-notes-revisited-protobuf/ | <a href="https://web.archive.org/web/*/https://ciofecaforensics.com/2020/09/18/apple-notes-revisited-protobuf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemprop="articleBody"> <p><strong>TL;DR</strong>: This post explains portions of two protobufs used by Apple, one for the Note format itself and another for embedded objects. More importantly, it explains how you can figure out the structure of protobufs.</p> <!--more--> <h2 id="background">Background</h2> <p>Previous entries in this series covered how to deal with <a href="https://ciofecaforensics.com/2020/01/10/apple-notes-revisited/">Apple Notes</a> and the <a href="https://ciofecaforensics.com/2020/01/13/apple-notes-revisited-easy-embedded-objects/">embedded objects</a> in them, including <a href="https://ciofecaforensics.com/2020/01/14/apple-notes-revisited-embedded-tables/">embedded tables</a> and <a href="https://ciofecaforensics.com/2020/01/20/apple-notes-revisited-galleries/">galleries</a>. Throughout these posts, I have referred to the fact that Apple uses protocol buffers (protobufs) to store the information for both notes and the embedded objects within them. What I have not yet done is actually provide the .proto file that was used to generate the Ruby output, or explained how you can develop the same on your app of interest. If you only care about the first part of that, you can view the <a href="https://github.com/threeplanetssoftware/apple_cloud_notes_parser/blob/master/proto/notestore.proto">.proto file</a> or the <a href="https://github.com/threeplanetssoftware/apple_cloud_notes_parser/blob/master/proto/protobuf_config.py">config</a> I use for <a href="https://github.com/jmendeth/protobuf-inspector">protobuf-inspector</a>. Both of these files are just a start to pull out the important parts for processing and can certainly be improved.</p> <p>As with previous entries, I want to make sure I give credit where it is due. After pulling apart the Note protobuf and while I was trying to figure out the table protobuf, I came across <a href="https://github.com/dunhamsteve">dunhamsteve’s</a> work. As a result, I went back and modified some of my naming to better align to what he had <a href="https://github.com/dunhamsteve/notesutils/blob/master/notes.md">published</a> and added in some fields like version which I did not have the data to discover.</p> <h2 id="what-is-a-protocol-buffer">What is a Protocol Buffer?</h2> <p>To quote directly from <a href="https://developers.google.com/protocol-buffers">the source</a>,</p> <blockquote> <p>Protocol buffers are Google’s language-neutral, platform-neutral, extensible mechanism for serializing structured data – think XML, but smaller, faster, and simpler. You define how you want your data to be structured once, then you can use special generated source code to easily write and read your structured data to and from a variety of data streams and using a variety of languages.</p> </blockquote> <p>What does that mean? It means a protocol buffer is a way you can write a specification for your data and use it in many projects and languages with one command. The end result is source code for whatever language you are writing in. For example, <a href="https://github.com/sballin/alfred-search-notes-app/blob/master/search/proto/notestore.pb.go">Sean Ballinger’s Alfred Search Notes App</a> used my <code>notestore.proto</code> file to compile to Go instead of Ruby to interact with Notes on MacOS. When you use it in your program, the data which you save will be a raw data stream which won’t look like much, but will be intelligable to any code with that protobuf definition.</p> <p>The definition is generally a <code>.proto</code> file which would look something like:</p> <figure><pre><code data-lang="protobuf"><span>syntax</span> <span>=</span> <span>"proto2"</span><span>;</span>

<span>// Represents an attachment (embedded object)</span>
<span>message</span> <span>AttachmentInfo</span> <span>{</span>
   <span>optional</span> <span>string</span> <span>attachment_identifier</span> <span>=</span> <span>1</span><span>;</span>
   <span>optional</span> <span>string</span> <span>type_uti</span> <span>=</span> <span>2</span><span>;</span>
<span>}</span></code></pre></figure> <p>This definition would have just one message type (AttachmentInfo), with two fields (attachment_identifier and type_uti), both optional. This is using the <code>proto2</code> syntax.</p> <h2 id="why-care-about-protobufs">Why Care About Protobufs</h2> <p>Protobufs are everywhere, especially if you happen to be working with or looking at Google-based systems, such as Android. Apple also uses a lot of them in iOS, and for people that have to support both operating systems, using a protobuf makes the pain of maintaining two different code bases slightly less annoying because you can compile the same definition to different languages. If you are in forensics, you may come across something that looks like it isn’t plaintext and discover that you’re actually looking at a protobuf. When it comes specifically to Apple Notes, protobufs are used both for the Note itself and the attachments.</p> <h2 id="how-to-use-a-proto-file">How to Use a .proto file</h2> <p>Assuming you have a <code>.proto</code> file, either from building one yourself or from finding one from your favorite application, you can compile it to your target language using <a href="https://github.com/protocolbuffers/protobuf/releases">protoc</a>. The resulting file can then be included in your project using whatever that language’s include statement is to create the necessary classes for the data. For example, when writing Apple Cloud Notes Parser in Ruby, I used <code>protoc --ruby_out=. ./proto/notestore.proto</code> to compile it and then <code>require_relative 'notestore_pb.rb'</code> in my code to include it.</p> <p>If I wanted instead to add in support for python, I would only have to make this change: <code>protoc --ruby_out=. --python_out=. ./proto/notestore.proto</code></p> <h2 id="how-can-you-find-a-protobuf-definition-file">How Can You Find a Protobuf Definition File?</h2> <p>If you come up against a protobuf in an application you are looking at, you might be able to find the <code>.proto</code> protobuf definition file in the application itself or somewhere on the forensic image. I ended up going through an iOS 13 forensic image earlier this year and found that Apple still had some of theirs on disk:</p> <figure><pre><code data-lang="shell"><span>[</span>notta@cuppa iOS13_logical]<span>$ </span>find | <span>grep</span> <span>'\.proto$'</span>
./System/Library/Frameworks/MultipeerConnectivity.framework/MultipeerConnectivity.proto
./System/Library/PrivateFrameworks/ActivityAchievements.framework/ActivityAchievementsBackCompat.proto
./System/Library/PrivateFrameworks/ActivityAchievements.framework/ActivityAchievements.proto
./System/Library/PrivateFrameworks/CoreLocationProtobuf.framework/Support/Harvest/CLPCollectionRequest.proto
./System/Library/PrivateFrameworks/ActivitySharing.framework/ActivitySharingDatabaseCodables.proto
./System/Library/PrivateFrameworks/ActivitySharing.framework/ActivitySharingDomainCodables.proto
./System/Library/PrivateFrameworks/ActivitySharing.framework/ActivitySharingInvitationCodables.proto
./System/Library/PrivateFrameworks/ActivitySharing.framework/ActivitySharingCloudKitCodables.proto
./System/Library/PrivateFrameworks/CloudKitCode.framework/RecordTransport.proto
./System/Library/PrivateFrameworks/RemoteMediaServices.framework/RemoteMediaServices.proto
./System/Library/PrivateFrameworks/CoreDuet.framework/knowledge.proto
./System/Library/PrivateFrameworks/HealthDaemon.framework/Statistics.proto
./System/Library/PrivateFrameworks/AVConference.framework/VCCallInfoBlob.proto
./System/Library/PrivateFrameworks/AVConference.framework/captions.proto</code></pre></figure> <p>Some of these are <em>really</em> interesting when you look at them, particularly if you care about their location data and pairing. You don’t even have to have an iOS forensic image sitting around as all of the same files are included in your copy of MacOS 10.15.6, as well, if you run <code>sudo find /System/ -iname "*.proto"</code>. I am not including any interesting snippets of those because they are copyrighted by Apple and I would explicitly note that none are related to Apple Notes or the contents of this post.</p> <p>In general, you should not expect to find these definitions sitting around since the definition file isn’t needed once the code is generated. For more open source applications, you might be interested in some <a href="https://www.google.com/search?q=ext%3Aproto++AND+inurl%3Aproto+AND+message+AND+proto2">Google Dorks</a>, especially when looking at Android artifacts, as you might still find them.</p> <h2 id="how-can-you-rebuild-the-protobuf">How Can You Rebuild The Protobuf?</h2> <p>But what if you can’t find the definition file, how can you rebuild it yourself? This was the most interesting part of rewriting Apple Cloud Notes Parser as I had no knowledge of how Apple typically represents data, nor protobufs, so it was a fun learning adventure.</p> <p>If you have nothing else, the <code>protoc --decode-raw</code> command can give you an intial look at what is in the data, however this amounts to not much more than pretty printing a JSON object, it doesn’t do a great job of telling you you what might be in there. I made heavy use of mildsunrise’s <a href="https://github.com/mildsunrise/protobuf-inspector">protobuf-inspector</a> which at least makes an attempt to tell you what you might be looking at. Another benefit to using this is that it lets you incrementally build up your own definition by editing a file named <code>protobuf_config.py</code> in the protobuf-insepctor folder.</p> <p>For example, below is the output from protobuf-inspector when I ran it on the Gunzipped contents of one of the first notes in my test database.</p> <figure><pre><code data-lang="python"><span>[</span><span>notta</span><span>@</span><span>cuppa</span> <span>protobuf</span><span>-</span><span>inspector</span><span>]</span><span>$</span> <span>python3</span> <span>main</span><span>.</span><span>py</span> <span>&lt;</span> <span>~/</span><span>note_18</span><span>.</span><span>blob</span> 
<span>root</span><span>:</span>
    <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
    <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
        <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
        <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
        <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
            <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>"Pure blob title"</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>5</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>5</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>2</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span><span>)</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>8</span><span>)</span>
                <span>4</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span>
                <span>5</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>3</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>10</span><span>)</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>4</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>4</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span>
                <span>5</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>4</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>14</span><span>)</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>10</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>5</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                    <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
                    <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>4294967295</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                    <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
                    <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>4294967295</span>
            <span>4</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                    <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>bytes</span> <span>(</span><span>16</span><span>)</span>
                        <span>0000</span>   <span>EE</span> <span>FE</span> <span>10</span> <span>DA</span> <span>5</span><span>A</span> <span>79</span> <span>43</span> <span>25</span> <span>88</span> <span>BA</span> <span>6</span><span>D</span> <span>CA</span> <span>E2</span> <span>E9</span> <span>B7</span> <span>EC</span>                          <span>....</span><span>ZyC</span><span>%</span><span>..</span><span>m</span><span>.....</span>
                    <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>24</span><span>)</span>
                    <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>9</span><span>)</span>
            <span>5</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span>
                <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>,</span> <span>3</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>)</span>
            <span>5</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span>
                <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>,</span> <span>3</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>)</span>
            <span>5</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
          …</code></pre></figure></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ciofecaforensics.com/2020/09/18/apple-notes-revisited-protobuf/">https://ciofecaforensics.com/2020/09/18/apple-notes-revisited-protobuf/</a></em></p>]]>
            </description>
            <link>https://ciofecaforensics.com/2020/09/18/apple-notes-revisited-protobuf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24533249</guid>
            <pubDate>Sun, 20 Sep 2020 11:02:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Generative Bad Handwriting]]>
            </title>
            <description>
<![CDATA[
Score 190 | Comments 17 (<a href="https://news.ycombinator.com/item?id=24532352">thread link</a>) | @atulvi
<br/>
September 19, 2020 | https://avinayak.github.io/programming/art/2020/09/18/p5-strokes.html | <a href="https://web.archive.org/web/*/https://avinayak.github.io/programming/art/2020/09/18/p5-strokes.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>So.. I made a popular tweet last week in the <a href="https://twitter.com/hashtag/%E3%81%A4%E3%81%B6%E3%82%84%E3%81%8DProcessing?src=hashtag_click">#つぶやきProcessing</a> circles.</p>

<blockquote><p lang="cy" dir="ltr">j=24,m=0,draw=(a=&gt;{for(v=(i=&gt;w/3*(n=noise)(i)-k),createCanvas(w=1e3,w),noFill(),background('<a href="https://twitter.com/hashtag/fd7?src=hash&amp;ref_src=twsrc%5Etfw">#fd7</a>'),translate(0,m--),i=0,y=0;y&lt;w-m;y+=j)for(x=k=90;x&lt;w-k;x+=9)if(y+k&gt;-m?curve(v(i++)+x,v(i++)+y,x,j+y,x+9,j+y,v(i++)+x,v(i++)+y):i+=4,x+=v(i++)%9,n(x*y)&lt;.13)y+=j});//<a href="https://twitter.com/hashtag/%E3%81%A4%E3%81%B6%E3%82%84%E3%81%8DProcessing?src=hash&amp;ref_src=twsrc%5Etfw">#つぶやきProcessing</a> <a href="https://t.co/WNIwAAAXjQ">pic.twitter.com/WNIwAAAXjQ</a></p>— atulvinayak (@atulvinayak) <a href="https://twitter.com/atulvinayak/status/1305116417419653120?ref_src=twsrc%5Etfw">September 13, 2020</a></blockquote>


<p>I’ll try to explain how this script worked and how I was able to fit the whole thing into 280 characters. If you’re new to p5.js, just try pasting the tweet text to <a href="https://editor.p5js.org/" title="https://editor.p5js.org/">https://editor.p5js.org/</a> to get a similar output.</p>



<p>All of this started when last week when I was experimenting with the p5js <code>curve()</code> function. Internally this is an implementation of the <a href="https://en.wikipedia.org/wiki/Centripetal_Catmull%E2%80%93Rom_spline" title="Centripetal Catmull–Rom spline">Centripetal Catmull–Rom spline</a>. I tried generating a bunch of 8 legged water spiders for fun :)</p>

<video controls="" muted="" src="https://video.twimg.com/ext_tw_video/1303620577589039104/pu/vid/720x720/8iYWjReFxe-9kWVl.mp4?tag=10">
</video>

<p>I admit this looks pretty stupid. The aim was to generate an animation a whole bunch of water spiders with the camera panning around. But then, for me to understand how exactly the Catmull-Rom spline worked, I decided to randomly plot a bunch of curves on a 2D canvas and it somehow resembled handwriting from my native language (<a href="https://en.wikipedia.org/wiki/Malayalam">Malayalam</a>).</p>

<p><img src="https://avinayak.github.io/uploads/download-12.png" alt=""></p>

<p>Actual Malayalam handwriting sample.<br>
<img src="https://avinayak.github.io/uploads/4f31bc2ce9a02537444fc6eeea276dc5.jpg" alt=""></p>

<p>Reducing character spacing.. Do you see the similarity now?<br>
<img src="https://avinayak.github.io/uploads/download-10.png" alt=""></p>

<p>Also, at this time I was playing the PC remaster of <a href="https://en.wikipedia.org/wiki/Journey_(2012_video_game)">Journey (2012)</a>. Journey has a very beautiful blocky scriptures all over the temples in the game.</p>

<p><img src="https://avinayak.github.io/uploads/eayhyxhueaagmqu.jpg" alt=""></p>

<p>I guessed this is pretty easy generate. I made a few attempts to reproduce the approximate style using p5.js</p>

<p><img src="https://avinayak.github.io/uploads/download-8.png" alt=""></p>

<p>and even an infinite scrolling version</p>

<video controls="" muted="" src="https://video.twimg.com/ext_tw_video/1304311867284664323/pu/vid/720x720/zNWZ-LQrIl0KrnCU.mp4?tag=10">
</video>

<p>This script had some serious performance issues(you can see it slowing down towards the end). Later I learned that this style of meaningless writing is a thing in the art community known as Generative <a href="https://en.wikipedia.org/wiki/Asemic_writing">Asemic Writing</a>. According to Wikipedia:</p>

<blockquote>
  <p><strong>Asemic writing</strong> is a wordless open semantic form of writing. The word asemic means “having no specific semantic content”. With the nonspecificity of asemic writing there comes a vacuum of meaning which is left for the reader to fill in and interpret.</p>
</blockquote>

<p>I decided to combine the two and make an infinite generator of malayalam-esque asemic writing. I’ve seen curve generated asemic <a href="https://www.reddit.com/r/asemic/comments/dw5ze3/generative_script/?ref=share&amp;ref_source=link">before</a>. So, What I did is not something new.. however, maybe the way I made it infinite scrolling was something new(?). I’ll try to explain how the code works.</p>



<p>I lost the original script in the minifying process, but I managed to unminify the tweet somehow.</p>

<div><div><pre><code>var yOffset = 24;
var scrollPosition = 0;
var canvasWidth = 800;
var margin = 90

function setup() {
    createCanvas(canvasWidth, canvasWidth)
    noFill();
}

function deterministicRandom(index) {
  return 1000 / 3 * noise(index) - 90
}

function draw() {
    background('#fd7');
    translate(0, scrollPosition--);

    for (i = 0, y = 0; y &lt; canvasWidth - scrollPosition; y += yOffset)
        for (x = 90; x &lt; canvasWidth - margin;) {
            if (y + margin &gt; -scrollPosition) {
                curve(
                  deterministicRandom(i++) + x, 
                  deterministicRandom(i++) + y, 
                  x, 
                  y + yOffset, 
                  x + 9, 
                  y + yOffset, 
                  deterministicRandom(i++) + x, 
                  deterministicRandom(i++) + y
                )
            } else {
                i += 4
            }
            x += (9 + deterministicRandom(i++) % 9)
            if (noise(x * y) &lt; .13)
            {
              y += 2*yOffset
              x = margin
            }
        }

}
</code></pre></div></div>

<p>The most important part of the code is the function <code>deterministicRandom()</code> which is used a lot of times in the sketch. It’s basically <code>noise()</code> but mapped to range <code>[243, -90]</code>. p5 js <code>curve()</code> takes in 2 control point and 2 physical point coordinate to determine the location and shape of the curve. Each character is is thus a set of 4 deterministically random numbers for control points + 4 constants for physical points. All of these points are offset by a base <code>&lt;x,y&gt;</code> coordinate to place the curve in a line. <em>Because it’s deterministically random, the shapes and location of the curves are preserved in every frame</em>.. making the infinite scroll effect work.</p>

<p>The 2 loops iterate over x and y, at a constant rate. x by 9 pixels and y by 24 pixels. But, inside the loop, based on deterministic random, x is randomly incremented by up to 9 pixels to simulate the randomness in spaces between characters. Also, if for a random condition with somewhat low probability (<code>noise(x * y) &lt; .13</code>), a line-break is added. Which means, y is incremented thrice in that loop and x is reset to a margin value (90).</p>





<p>The infinite scroll effect is basically done using <code>translate(0, scrollPosition--)</code>. The loop termination clause is adjusted such that only lines within the frame are rendered (between <code>y = scrollPosition to scrollPosition+canvasHeight</code>). The condition <code>y + margin &gt; -scrollPosition</code> directly inside the loop checks for this. This also offsets the random number index to the one needed by the lines being rendered in the else case. Here’s a version of the script that shows lines being rendered as the script runs:</p>



<p>And that’s basically it. The initial version I designed rendered every line from the first scroll position to the last in every frame, even if those lines were not visible. This is terrible for performance and the if condition inside the loop fixed this.</p>



<p>Step one of minifying was converting all the functions to <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Functions/Arrow_functions">arrow functions</a>. This took up way less space. Then I moved all the <code>setup()</code> stuff to <code>draw()</code>. p5 does not re-execute <code>createCanvas</code> even if you place it in <code>draw()</code>. Then I had to cut down number of variables as much as I can. 2 of them were reused: <code>canvasWidth(w)</code> and <code>margin(k)</code> were also used as a coefficient in <code>deterministicRandom()</code>. Finally spaces were removed and long names were truncated to single characters.</p>



<p>This script was written in about 2-3 hours. Looking back, I can see a lot of places where I’d try to reduce repeated code and make it smoother. I never thought this would go so popular, so I never really cared to optimize so much. But there you go.. a simple way to generate bad handwriting :)</p>

</div></div>]]>
            </description>
            <link>https://avinayak.github.io/programming/art/2020/09/18/p5-strokes.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24532352</guid>
            <pubDate>Sun, 20 Sep 2020 06:53:39 GMT</pubDate>
        </item>
    </channel>
</rss>
