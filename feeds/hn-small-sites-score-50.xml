<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Fri, 09 Oct 2020 20:27:28 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Fri, 09 Oct 2020 20:27:28 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[New York City thinks up to half of restaurants will close permanently [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 120 (<a href="https://news.ycombinator.com/item?id=24715150">thread link</a>) | @bookofjoe
<br/>
October 7, 2020 | https://www.osc.state.ny.us/files/reports/osdc/pdf/nyc-restaurant-industry-final.pdf | <a href="https://web.archive.org/web/*/https://www.osc.state.ny.us/files/reports/osdc/pdf/nyc-restaurant-industry-final.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.osc.state.ny.us/files/reports/osdc/pdf/nyc-restaurant-industry-final.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24715150</guid>
            <pubDate>Thu, 08 Oct 2020 02:47:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I built an app to fix my depression]]>
            </title>
            <description>
<![CDATA[
Score 64 | Comments 39 (<a href="https://news.ycombinator.com/item?id=24715148">thread link</a>) | @zoozla
<br/>
October 7, 2020 | https://blog.elifiner.com/i-built-an-app-to-fix-my-depression/ | <a href="https://web.archive.org/web/*/https://blog.elifiner.com/i-built-an-app-to-fix-my-depression/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://blog.elifiner.com/i-built-an-app-to-fix-my-depression/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24715148</guid>
            <pubDate>Thu, 08 Oct 2020 02:47:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Recycling was a lie to sell more plastic, recycling industry veteran says]]>
            </title>
            <description>
<![CDATA[
Score 691 | Comments 308 (<a href="https://news.ycombinator.com/item?id=24714880">thread link</a>) | @vivekd
<br/>
October 7, 2020 | https://www.cbc.ca/documentaries/the-passionate-eye/recycling-was-a-lie-a-big-lie-to-sell-more-plastic-industry-experts-say-1.5735618 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/documentaries/the-passionate-eye/recycling-was-a-lie-a-big-lie-to-sell-more-plastic-industry-experts-say-1.5735618">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Less than 10 per cent of the plastics we’ve used have been recycled. A new documentary reveals why</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5755241.1602170985!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/157672506.jpg"></p></div><figcaption>trash on the beach<!-- --> <!-- -->(Getty Images)</figcaption></figure><p><span><p>Although our landfills and oceans are full of it, we are as dependent as ever on plastic. And since COVID-19, it's gotten worse.&nbsp;</p>  <p>Last year, Canada announced it was working on a ban of single-use plastics, which was initally&nbsp;<a href="https://www.cbc.ca/news/canada/toronto/single-use-plastics-covid-1.5683617">sidelined by the pandemic</a>. Recently, the government announced that <a href="https://www.cbc.ca/news/politics/single-use-plastics-1.5753327">many single-use plastics will be banned</a> by the end of 2021. At the same time, <a href="https://www.cbc.ca/news/canada/toronto/single-use-plastics-covid-1.5683617">CBC News reports</a> our single-use plastic use increased by 250 to 300 per cent as people tossed their personal protective equipment and stopped using reusable bags and containers over fears they would spread the virus.</p>  <p>What makes our lives convenient is also burying us. <a href="https://www.cbc.ca/passionateeye/episodes/plastic-wars"><strong><em>Plastic Wars</em></strong></a>, presented by <em>The Passionate Eye</em>, looks at the mounting crisis and how the industry has spent millions promoting recycling — just to sell more plastic.</p>  <h2>Less than 10% of the plastics we've used have been recycled</h2>  <p>Although activists sounded the alarm about plastic waste in the 1970s, the documentary claims from 1990 to 2010, plastic production more than doubled. We've been sorting our trash for decades, believing it would be recycled. But the truth is the vast majority of the plastic we use won't be. Over the last seven decades, <a href="https://www.oecd.org/environment/waste/policy-highlights-improving-plastics-management.pdf">less than 10 per cent of plastic waste has been recycled</a>.&nbsp;</p>  <p>That's because, says David Allaway, from the Oregon Department of Environmental Quality, the conversation has been almost exclusively about recycling and not reducing and reusing.</p>  <p><span><span><div><div role="button" tabindex="0" title="Plastic Wars: Recycling"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/1002/935/PlasticWars_Recycling_2500kbps_620x350_1755680835594.jpg" alt=""></p></div></div></div><span>Even as the plastic crisis worsens, the demand for plastic grows and plastic production is rapidly expanding. One issue? Only focusing on recycling, and not reducing the amount of plastic that we use.<!-- --> <!-- -->1:06</span></span></span></p>  <h2>Recycling logo was used as a green marketing tool, says industry expert</h2>  <p>In the '80s, the industry was at the centre of an environmental backlash. Fearing an outright ban on plastics, manufacturers looked for ways to get ahead of the problem. They looked at recycling as a way to improve the image of their product and started labeling plastics with the now ubiquitous chasing-arrows symbol with a number inside.&nbsp;</p>  <p>According to Ronald Liesemer, an industry veteran who was tasked with overseeing the new initiative, "Making recycling work was a way to keep their products in the marketplace."&nbsp;</p>  <p>Most consumers might have assumed the symbol meant the product was recyclable. But according to experts in the film, there was no economically viable way to recycle most plastics, and they have ultimately ended up in a landfill. This included plastic films, bags and the wrapping around packaged goods, as well as containers like margarine tubs.<br> "Our own customers … they would flat out say, 'It says it's recyclable right on it,'" says Coy Smith, former board member of the National Recycling Coalition. "And I'd be like, 'I can tell you, I can't give this away. There's no one that would even take it if I paid them to take it.'" He believes manufacturers used the symbol as a green marketing tool.</p>  <p>"If the public thinks that recycling is working, then they're not going to be as concerned about the environment," says Larry Thomas, another top industry official interviewed in <a href="https://www.cbc.ca/passionateeye/episodes/plastic-wars"><em><strong>Plastic Wars</strong></em></a>.</p>  <p>According to Lewis Freeman, a former vice-president with the Society of the Plastics Industry, many in the industry had doubts about recycling from the start. "There was never an enthusiastic belief that recycling was ultimately going to work in a significant way," he says.</p>  <p>Yet the plastic industry spent millions on ads selling plastics and recycling to consumers.</p>  <h2>Lots of our plastic was shipped to China, then Southeast Asia, for 'recycling'</h2>  <p>To solve the plastic waste problem, many recyclers started selling their product to China in the 1990s. According to recycling broker Sunil Bagaria, China took waste that North American recyclers couldn't use. "As long as it remotely resembled plastic, they wanted it," he says.</p>  <p>But they used the good stuff and disposed of the rest. And because of a growing plastic waste problem in that country, China finally stopped taking most imported plastic waste in 2018.</p>  <p>"We never asked the question, 'Are they doing it the right way? Are we damaging the environment more in the name of recycling?'" says Bagaria.</p>  <p>Now, Southeast Asian countries like Indonesia have picked up the plastic waste market. And although some North American plastics recyclers are following up to ensure their products are in fact being recycled, plastic waste is now a growing problem there, too.&nbsp;</p>  <p>In <a href="https://www.cbc.ca/passionateeye/episodes/plastic-wars"><em><strong>Plastic Wars</strong></em></a>, local activist Yuyan Ismawati visits a rural community where locals scour through a huge field of plastic waste for items of value and burn the rest. This creates health problems for the residents in addition to destroying the surrounding environment. "We are struggling to clean up the modern debris and modern litter in Indonesia, the additional burden of waste from overseas — I don't know how we are going to handle it," says Ismawati. "Americans need to know that your waste ended up here."</p>  <h2>Production of plastics expected to triple by 2050</h2>  <p>In 2020, roughly 60 years after concerns about plastic waste were first raised, the focus is still on the consumer to recycle, says Allaway, and not on the environmental impact of the product and overproduction by the industry.</p>  <p><span><span><div><div role="button" tabindex="0" title="Plastic Wars: Full Impact"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/1004/887/PlasticWars_FullImpact_2500kbps_620x350_1755684419745.jpg" alt=""></p></div></div></div><span>Consumers are constantly told that they should do their part to reduce plastic waste, but in reality, consumers have the lowest amount of leverage in reducing waste - it's plastic producers that should be reporting their full environmental impacts.<!-- --> <!-- -->1:56</span></span></span></p>  <p>According to <a href="https://www.cbc.ca/passionateeye/episodes/plastic-wars"><em><strong>Plastic Wars</strong></em></a> the problem is only going to get worse. By 2050, it's estimated the global production of plastic will triple. As the oil and gas industry — which provides the source materials for plastics — &nbsp;faces a future of declining demand for fuel, it has turned to other markets.&nbsp;</p>  <p>The stakes are high, says Annie Leonard, executive director of Greenpeace USA. "This is their lifeline," she says. "They are going to double down on single-use plastic like we have never seen. So we're heading towards a real battle.... This is the big war."&nbsp;</p>  <p>Watch <a href="https://www.cbc.ca/passionateeye/episodes/plastic-wars"><em><strong>Plastic Wars</strong></em></a> on <em>The Passionate Eye</em>.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/documentaries/the-passionate-eye/recycling-was-a-lie-a-big-lie-to-sell-more-plastic-industry-experts-say-1.5735618</link>
            <guid isPermaLink="false">hacker-news-small-sites-24714880</guid>
            <pubDate>Thu, 08 Oct 2020 02:01:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lisp and Haskell (2015)]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 56 (<a href="https://news.ycombinator.com/item?id=24712207">thread link</a>) | @dunefox
<br/>
October 7, 2020 | https://markkarpov.com/post/lisp-and-haskell.html | <a href="https://web.archive.org/web/*/https://markkarpov.com/post/lisp-and-haskell.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>
          

<p><a href="https://markkarpov.com/tag/haskell.html">haskell</a></p><p>
  <em>
    Published on October 23, 2015, last updated November 23, 2019
  </em>
</p>

  <p>Lisp and Haskell are arguably some of the more peculiar languages out there.
It is always interesting to compare languages, so let me entertain you with
a story how I finally decided which of them is better.</p>
<p>When I first found out about Common Lisp it took my breath away. Seriously,
Lisp has consistent syntax, good design, and unique metaprogramming
capabilities. After Common Lisp, I learned a few other languages, some of
them out of necessity, others because of curiosity: Python, JavaScript,
Prolog, Clojure, and Haskell. I also was doing C and C++ in the past, but I
don’t touch them now. Until recently I considered Common Lisp the best
language I know, and probably the most powerful language in existence.</p>
<p>The fact is, I know what Common Lisp is and what it can do, but the days
when I actually hacked Lisp (more or less) regularly are long gone, and I’m
mainly doing Haskell these days.</p>
<h2 id="goodbye-lisp">Goodbye, Lisp</h2>
<p>Today I actually have had a chance to compare my productivity with Common
Lisp and Haskell. I decided to spend a few hours on my open source projects.
First, I refactored <a href="https://github.com/mrkkrp/megaparsec">Megaparsec</a>, and that was nice and easy,
but I didn’t notice this because I’m already used to the level of efficiency
Haskell gives me.</p>
<p>Next, a user of one of my Common Lisp libraries opened an issue asking to
improve one thing a bit. I estimated the required work in 15 minutes of time
and started Common Lisp hacking for the first time in a couple of months.</p>
<p>It took about 1 hour to write about 20 lines of trivial code. Of course one
might say that I just forgot the details. Yet, from my point of view the
real reasons are:</p>
<ul>
<li>
<p>Common Lisp is dynamically typed and the compiler cannot help you when you
write your code. (Well, it can help you a bit, making sure that your code
is syntactically correct and all your declared variables are used for
something.)</p>
</li>
<li>
<p>Common Lisp mixes functional code with code that has side effects. To
write idiomatic Common Lisp, you usually have to mix functional code with
not-so-functional approaches. See how this works below.</p>
</li>
<li>
<p>Common Lisp’s standard library (the functions that are available to you as
part of the ANSI Common Lisp standard) is quite poor by modern standards.
A lot of useful functions are missing. There are libraries, but I’ll get
to them.</p>
</li>
</ul>
<p>It’s essential for that library I was working on to have minimal
dependencies, so I came up with this function in bare Common Lisp to add
padding to every line of text except for the first line:</p>
<div><pre><code><span>(</span><span>defun</span><span> add-text-padding </span><span>(str &amp;key padding newline)</span>
<span>  </span><span>"Add padding to text STR. Every line except for the first one, will be</span>
<span>prefixed with PADDING spaces. If NEWLINE is non-NIL, newline character will</span>
<span>be prepended to the text making it start on the next line with padding</span>
<span>applied to every single line."</span>
<span>  (</span><span>let</span><span> ((str (</span><span>if</span><span> newline</span>
<span>                 (</span><span>concatenate</span><span> 'string (</span><span>string</span><span> </span><span>#\N</span><span>ewline) str)</span>
<span>                 str)))</span>
<span>    (</span><span>with-output-to-string</span><span> (s)</span>
<span>      (</span><span>map</span><span> 'string</span>
<span>           (</span><span>lambda</span><span> (x)</span>
<span>             (</span><span>princ</span><span> x s)</span>
<span>             (</span><span>when</span><span> (</span><span>char=</span><span> x </span><span>#\N</span><span>ewline)</span>
<span>               (</span><span>dotimes</span><span> (i padding)</span>
<span>                 (</span><span>princ</span><span> </span><span>#\S</span><span>pace s))))</span>
<span>           str))))</span>
</code></pre></div>
<p>In case you don’t speak Common Lisp, let me highlight some parts of the
code:</p>
<ul>
<li>
<p><code>concatenate</code> needs to know the type of its output, so we pass it a symbol
specifying type of desired result as the first argument.</p>
</li>
<li>
<p><code>(string #\Newline)</code> constructs a line containing a single newline
character. There is no syntax in Common Lisp to write something like
<code>"\n"</code>. The alternative approach would be <code>(format nil "~%")</code>. There is no
syntax for all other special characters if you want to put them into
string. To be fair, you have multi-line string literals without funny
escaping instead, which is vital for doc-strings and the like.</p>
</li>
<li>
<p><code>(map 'string …)</code> is used to loop through characters in a string. Note
that here we use <code>map</code> function as a helper for a rather imperative
procedure—printing results to new string using a temporarily created
stream <code>s</code> (with the help of <code>with-output-to-string</code>). But that’s
idiomatic in Common Lisp.</p>
</li>
</ul>
<p>When I ran this in the REPL, I got the following:</p>
<div><pre><code><span>; SLIME 2015-10-18</span>
<span>CL-USER&gt; (asdf:load-system :unix-opts)</span>
<span>T</span>
<span>CL-USER&gt; (</span><span>in-package</span><span> :unix-opts)</span>
<span>#&lt;PACKAGE </span><span>"UNIX-OPTS"</span><span>&gt;</span>
<span>OPTS&gt; (</span><span>defvar</span><span> *foo* </span><span>(</span><span>format</span><span> </span><span>nil</span><span> </span><span>"first line~%second line~%third line"</span><span>))</span>
<span>*FOO*</span>
<span>OPTS&gt; *foo*</span>
<span>"first line</span>
<span>second line</span>
<span>third line"</span>
<span>; compiling (DEFUN ADD-TEXT-PADDING ...)</span>
<span>OPTS&gt; (add-text-padding *foo* :padding </span><span>10</span><span>)</span>
<span>; Evaluation aborted on #&lt;TYPE-ERROR expected-type: CHARACTER datum: NIL&gt;.</span>
</code></pre></div>
<p>The debugger popped up and told me in plain English:</p>
<blockquote>
<p>The value NIL is not of type CHARACTER.</p>
</blockquote>
<p>It is difficult to argue with, <code>nil</code> is definitely not a character. But why
the heck do I get this? Can you tell? Please try as hard as you can! <em>(The
answer is at the end of the blog post.)</em></p>
<p>I decided that I won’t hack Common Lisp anymore. That’s great and expressive
language, but I want to write in something I’m efficient with.</p>
<h2 id="productivity-of-haskell-programmer">Productivity of Haskell programmer</h2>
<p>I use <a href="https://gnu.org/software/emacs/">Emacs</a> for almost everything that is
related to text. One package I love in particular is
<a href="http://www.flycheck.org/">Flycheck</a>. When I edit Haskell source code,
Flycheck is running GHC with <code>-Wall</code> flag and
<a href="https://github.com/ndmitchell/hlint">HLint</a> in the background and displays
warnings and errors interactively underlining my source code. This is a
convenient feature for any language, but only Haskell with its type system
takes this sort of tool to its limits.</p>
<p>In fact, this non-stop interactive conversation with compiler is the most
efficient programming workflow I’ve ever used. Combined with the fact that
<em>if your code compiles, it probably works</em>, Haskell must be the most
efficient (with respect to human resources) programming language in
existence just because of the static type system that works as a powerful
ally for the programmer. Of course, bugs can live in Haskell code too, but
I’m not saying we should abandon writing tests.</p>
<h2 id="problems-of-common-lisp">Problems of Common Lisp</h2>
<p>Speaking of tests, recently I discovered that Zach Beane AKA Xach, an
über-level Common Lisp hacker <a href="http://xach.livejournal.com/278047.html?thread=674335#t674335">doesn’t usually write tests</a>.
FYI, he is the author of <a href="https://www.quicklisp.org/beta/">Quicklisp</a>, that is something like (but
not quite) Cabal or Stack. Quicklisp is de-facto the only widely used
library manager in Common Lisp world, and so it’s written in Common Lisp and
<a href="https://github.com/quicklisp/quicklisp-client">doesn’t have any tests</a>. It is a wonder for me how it
works. Usually when a project is big enough I start to have doubts whether
all parts of it still work after some changes, so I cannot imagine you can
do a thing like Quicklisp without tests and be confident about the result.</p>
<p>But you know what, Lisp, and its most advanced dialect (IMO), Common Lisp is
really cool. If you don’t believe me, you can read <a href="http://www.paulgraham.com/avg.html">Paul Graham</a> at any
time. The author can tell you what a great language Common Lisp is on
many-many pages. I don’t remember where I read this, but he has something
like “There is the problem of lacking libraries, but on a big enough project
benefits of the language itself outweigh the lack of libraries.”</p>
<p><em>Well, take any high-level language like Python, which have all the nice
libraries, and for project of any size it will be better than Common Lisp.
Macros are missing, but you can live without macros after all.</em></p>
<p>Common Lisp doesn’t have enough high-quality, actively maintained libraries.
The fact is, there are some pearls like <a href="https://github.com/fukamachi/caveman">caveman</a> or
<a href="https://github.com/stumpwm/stumpwm">stumpwm</a>, but most libraries don’t look good enough. Sometimes you
start thinking that if you want to end up with a great project you’ll need
to write your own libraries (which you’ll probably do, like many people
before you, not that it has improved the situation though).</p>
<p>Another problem is that some widely-used Common Lisp libraries have no
documentation at all. If you’re to understand how to use them, <em>read the
source code</em>. I can name a couple of them, but I don’t want to do so,
because I don’t think it’s polite. I’ve opened an issue on GitHub of one
quite popular library, asking the maintainer to write documentation. After 6
months it’s still not written (strange, right?). In my opinion, this is not
a serious approach to maintaining your code.</p>
<p>When I was interested in Common Lisp, I had an idea of a pet project to help
me remember all sorts of French words and verbs in particular. Of course I
wanted to do the whole thing decently, even though it’s console app, it
should have decent interface and work smoothly in general. I succeeded, but
I had to do a lot more than I would need to do if I wrote it in, say Python.
This is how (in retrospect I understand) less powerful Python would be
better fit for this (or almost any) project.</p>
<h2 id="the-curse-of-dynamic-languages">The curse of dynamic languages</h2>
<p>There is a blog post called <a href="https://existentialtype.wordpress.com/2011/03/19/dynamic-languages-are-static-languages/"><em>Dynamic Languages are Static
Languages</em></a>. In short, the author makes the point that
dynamic langauges are static languages but with one huge type including all
possible values. Here is a paragraph I find important:</p>
<blockquote>
<p>And this is precisely what is wrong with dynamically typed languages:
rather than affording the <em>freedom</em> to ignore types, they instead impose
the <em>bondage</em> of restricting attention to a <em>single</em> type! Every single
value has to be a value of that type, you have no choice! Even if in a
particular situation we are absolutely certain that a particular value is,
say, an integer, we have no choice but to regard it as a value of the “one
true type” that is <em>classified</em>, not typed, as an integer. Conceptually,
this is just rubbish, but it has serious, tangible penalties. For one, you
are depriving yourself of the ability to state and enforce the <em>invariant</em>
that the value at a particular program point must be an integer. For
another, you are imposing a serious bit of run-time overhead to represent
the class itself (a tag of some sort) and to check and remove and apply
the class tag on the value each time it is used.</p>
</blockquote>
<p>The lack of the power to express meaning of your program on type level is
another downside of Lisp. (You can add types in Common Lisp too, but that’s
used solely for optimization. Common Lisp can be almost as fast …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://markkarpov.com/post/lisp-and-haskell.html">https://markkarpov.com/post/lisp-and-haskell.html</a></em></p>]]>
            </description>
            <link>https://markkarpov.com/post/lisp-and-haskell.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24712207</guid>
            <pubDate>Wed, 07 Oct 2020 20:13:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Designing a New Rust Class at Stanford: Safety in Systems Programming]]>
            </title>
            <description>
<![CDATA[
Score 199 | Comments 46 (<a href="https://news.ycombinator.com/item?id=24711314">thread link</a>) | @ksml
<br/>
October 7, 2020 | https://reberhardt.com/blog/2020/10/05/designing-a-new-class-at-stanford-safety-in-systems-programming.html | <a href="https://web.archive.org/web/*/https://reberhardt.com/blog/2020/10/05/designing-a-new-class-at-stanford-safety-in-systems-programming.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
                <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Writing quality software is hard. Sometimes, software breaks in entertaining
ways. However, when software runs everything from personal assistants like
Alexa and Google Home to banking to elections, some bugs can be much more
severe.</p>

<p>This past quarter, Armin Namavari and I tried teaching a class about how to
write software that sucks just a <em>little</em> less. We focused on common problems
in computer systems caused by certain kinds of silly (but very serious)
mistakes, such as issues of memory safety and thread safety. The core theme of
the class was, <em>What are common problems with systems programming right now?
How are people responding to those issues? How do those measures fall short?</em>
We wanted students to be aware of problems that have plagued the industry for
decades, and we wanted to teach students how to use tools and mental models
that people have developed to combat those issues. However, these tools are
imperfect, and we also wanted students to experience and understand the
limitations of such tools to be better aware of what to watch out for when
building systems.</p>

<!--more-->

<p>In particular, we focused on teaching the Rust programming language as a way to
build better habits and combat mistakes endemic to C- and C++-based software.
In many ways, Rust <em>requires</em> good practices, and it has an educational
compiler with helpful error messages that help students learn. Additionally, we
looked at how lessons from Rust can be applied to write better code in C++, and
we taught students about tools that can be used to detect common mistakes
before they become a problem.</p>

<p>In contrast with a typical security class, we aimed to build a robust software
engineering aspect into the course, giving code-heavy assignments and trying to
improve students’ processes rather than merely giving awareness about common
problems. Our goal with this class was to train students to be better software
developers, regardless of what programming language they end up using.</p>

<p>I think the class went quite well, and student evaluations were extremely
positive. Even before the quarter ended, students told us that the class was
extremely helpful for implementing and debugging assignments in other classes.
We hope to teach the class again this coming fall, and are looking for input on
how it might be improved.</p>

<p>This blog post aims to be a summary of what we did, why we did it, and what we
are thinking about changing for the future. It’s long, but written so you can
skip around to whatever is interesting to you. Here’s an outline:</p>

<!--* [What is systems programming?](#what-is-systems-programming)-->
<ul>
  <li><a href="#what-is-safety-and-why-should-we-care">What is safety, and why should we care?</a></li>
  <li><a href="#imagining-safety-education">Imagining safety education</a>
    <ul>
      <li><a href="#should-there-be-a-safety-class">Should there be a “safety class”?</a></li>
      <li><a href="#how-would-this-be-different-from-a-security-class">How would this be different from a security class?</a></li>
      <li><a href="#how-does-one-teach-safe-programming">How does one teach safe programming?</a></li>
    </ul>
  </li>
  <li><a href="#summary-of-the-class">Summary of the class</a>
    <ul>
      <li><a href="#lectures">Lectures</a></li>
      <li><a href="#assignments">Assignments</a></li>
    </ul>
  </li>
  <li><a href="#survey-results">Survey results</a></li>
  <li><a href="#takeaways">Takeaways</a>
    <ul>
      <li><a href="#is-there-a-place-for-a-safety-class-in-a-cs-curriculum">Is there a place for a safety class in a CS curriculum?</a></li>
      <li><a href="#whats-it-like-for-students-to-learn-rust-in-a-short-time-frame">What’s it like for students to learn Rust in a short time frame?</a></li>
      <li><a href="#should-we-try-to-incorporate-rust-into-the-stanford-core-curriculum">Should we try to incorporate Rust into the Stanford core curriculum?</a></li>
      <li><a href="#should-this-be-a-standalone-class-or-should-it-remain-an-addon-to-cs-110">Should this be a standalone class, or should it remain an addon class to CS 110?</a></li>
    </ul>
  </li>
  <li><a href="#general-teaching-lessons-learned">General teaching lessons learned</a></li>
</ul>

<p>Major thanks go to Armin Namavari for being a wonderful co-instructor, Sergio
Benitez for giving an excellent guest lecture, Will Crichton for providing
feedback and guidance in designing the class, Jerry Cain for giving us the
opportunity to teach and giving encouragement throughout, and Rakesh Chatrath,
Jeff Tucker, Vinesh Kannan, John Deng, and Shiranka Miskin for reviewing drafts
of this post.</p>

<!--
## What is systems programming?

In this class, we wanted to focus on safety in systems programming &mdash; but what
*is* systems programming, anyways?

"Systems programming" is a frequently-used term that I have never heard a clear
definition for, despite specializing in this track in undergrad. While it is
used in many different ways, I think about it like this: **Systems programming
is when you spend more time thinking about hardware than humans.** An
application programmer must think, *what does a user of my software need, and
how can I implement that in code?* An application programmer might work with
different programming languages and libraries, but rarely needs to think about
exactly what the hardware is doing under the hood. By contrast, a systems
programmer must think, *how can I teach this hardware new tricks in order to do
the things we need to do?* A systems programmer spends much more time thinking
about when memory is allocated, when a processor might switch contexts, when
data might be passed over a network, etc.
-->

<!-- TODO: picture of restaurant -->

<!--
As an application developer, you spend more time implementing business logic using whatever programming languages and tools you've decided to use. You're trying to design something that fits within the physical constraints of whatever you're running on. As a systems programmer, you spend much more time thinking about when memory gets allocated, when a processor switches contexts, when data gets passed over a network, etc.

Humans are still important (I'll admit I deemphasized humans partially for the alliteration), but the focus is less on end users and more on supporting the application developers and the application software that builds on top

Diagram: trying to show humans walking on top, hardware on bottom, and application developers standing on top of the systems developers
Diagram: floor is programming languages, libraries, and abstractions
Have some plumbers, carpenters, etc under the floor, and application devs servicing customers on top

If a computer were a restaurant, systems programmers would be the plumbers etc, and application programmers would be the chefs, waiters, etc

Examples of systems software: the code generating directions for Google Maps, Google Chrome, the infrastructure that does transcription for Siri (not the AI algorithms, but everything in between your phone and the algorithms), banking infrastructure, car firmware, etc.
-->

<h2 id="what-is-safety-and-why-should-we-care">What is safety, and why should we care?</h2>

<p>Safety is an unfortunately vague term lacking a great definition, but for our
purposes, we’ll say <strong>safety is about avoiding harmful mistakes.</strong> I view
safety as being concerned with the subset of potentially serious bugs: if a
button on a website renders as purple instead of blue, that’s a bug we might
not care much about, but if bank account software allows users to withdraw the
same $1000 multiple times, or if autonomous vehicle software can fail under
certain circumstances, that’s a more concerning problem.</p>

<p>Safety is particularly relevant in systems programming because systems
programming is <em>hard</em>. Systems programming often involves pushing the limits of
what hardware can do, and often involves reasoning about the state of multiple
threads sometimes even distributed across thousands of machines. Additionally,
for performance and historical reasons, the majority of systems software is
written in C or C++, which are <em>notoriously</em> difficult to use correctly.
Reasoning about pointers and memory is hard, and C and C++ do little to help.
C/C++’s weak type systems and poorly defined
specifications mean they will happily accept <a href="https://www.radford.edu/ibarland/Manifestoes/whyC++isBad.shtml">clearly broken code with no
sensible
interpretation</a>.
Even worse, there are countless minefields where the languages’ poor designs
are just begging for mistakes to happen. Simple functions like <code>strcpy</code>, which
copies a string from one place in memory to another, are extremely easy to
misuse and have been the cause of countless <a href="https://pointerless.wordpress.com/2012/02/26/strcpy-security-exploit-how-to-easily-buffer-overflow/">security
vulnerabilities</a>.
The <code>strncpy</code> function was introduced to address the weaknesses of <code>strcpy</code>,
yet <a href="https://devblogs.microsoft.com/oldnewthing/20050107-00/?p=36773"><code>strncpy</code> turns out to be almost just as
bad</a>. Even
<a href="https://stackoverflow.com/questions/7459630/how-can-a-format-string-vulnerability-be-exploited"><code>printf</code> can lead to security
vulnerabilities</a>
when called the wrong way.</p>

<figure>
    <a href="https://reberhardt.com/blog/images/designing-cs-110l/strcpy.png">
        <img src="https://reberhardt.com/blog/images/designing-cs-110l/strcpy.png" alt="">
    </a>
    
</figure>

<p>Also, as systems software provides the foundation on which other software runs,
it’s particularly important to get right. Many real-world examples demonstrate
the severe impact of the aforementioned issues.  One of my favorite examples is
presented in <a href="http://www.autosec.org/pubs/cars-usenixsec2011.pdf">Comprehensive Experimental Analyses of Automotive Attack
Surfaces</a>.  It’s a great
read, but as a summary, the authors bought a popular car and attempted to find
as many ways as possible to remotely hijack the car without having physical
access. They examined vectors such as wireless key fobs, Bluetooth, and even
the tire pressure monitoring system (which uses wireless signals to transmit
information from sensors in the tires). Every vector was found to be
exploitable, many of them trivially so. For example, the Bluetooth software had
“over 20 calls to <code>strcpy</code>, none of which were clearly safe.” The authors only
looked at the first instance of <code>strcpy</code>, and found that it copies data to the
stack when handling a Bluetooth configuration command without checking the
length of the string. This results in a trivially exploitable buffer overflow
that allows a paired device to execute arbitrary code in the media system.
Since the subsystems in most cars lack isolation, compromising one subsystem
(such as the media player) can result in the compromise of the entire car. In
2015, researchers demonstrated this, <a href="https://www.wired.com/2015/07/hackers-remotely-kill-jeep-highway/">remotely killing a Jeep that was driving
on the
highway</a>.</p>

<p>This isn’t just a problem with the automotive industry. <a href="https://blog.zimperium.com/whatsapp-buffer-overflow-vulnerability-under-the-scope/">Professional</a>
<a href="https://www.theregister.com/2019/08/06/qualcomm_android_security_patches/">programmers</a>
<a href="https://www.biometricupdate.com/202006/acronis-reports-critical-flaws-in-geovision-biometric-devices-man-in-the-middle-attack-risks">across</a>
<a href="https://www.zdnet.com/article/critical-security-flaw-schneider-industrial-software-power-plants-vulnerabilty/">many</a>
<a href="https://blog.zecops.com/vulnerabilities/youve-got-0-click-mail/">industries</a>
<a href="https://www.theverge.com/2017/5/12/15630354/nhs-hospitals-ransomware-hack-wannacry-bitcoin">regularly</a>
<a href="https://tools.cisco.com/security/center/content/CiscoSecurityAdvisory/cisco-sa-sdwanbo-QKcABnS2">make</a>
<a href="https://threatpost.com/netgear-zero-day-takeover-routers/156744/">simple</a>
<a href="https://gadgets.ndtv.com/mobiles/news/samsung-critical-bug-fix-skia-sve-2020-16747-zero-click-vulnerability-2224867">but</a>
<a href="https://redmondmag.com/articles/2020/07/16/cisa-windows-server-dns-vulnerability.aspx">serious</a>
<a href="https://threatpost.com/google-squashes-high-severity-flaws-in-chrome-browser/154424/">mistakes</a>.</p>

<p>This seems like something we should be talking about. Would you hand a
chemistry student a bunch of volatile chemicals that regularly explode in
professional labs without a robust discussion of safety?  Probably not. Yet
that’s effectively what our curriculums are doing. We’re handing students a
series of tools that professionals routinely shoot themselves in the foot with,
and we aren’t having a substantial discussion of precautions we can take to
avoid potentially life-threatening mistakes.</p>

<figure>
    <a href="https://reberhardt.com/blog/images/designing-cs-110l/chem-lab.png">
        <img src="https://reberhardt.com/blog/images/designing-cs-110l/chem-lab.png" alt="In many ways, our CS curriculums are like inviting students into a chem lab without any discussion of safety.">
    </a>
    
    <figcaption>In many ways, our CS curriculums are like inviting students into a chem lab without any discussion of safety.</figcaption>
    
</figure>

<p>One might argue that the perils of strcpy are nothing like the dangers of a
fully-stocked chemistry lab; there’s no danger of students dying in front of
the computer here. (Well, we hope.) However, I argue that we deal with dangers
on a much larger scale.  One line of code can easily affect millions (or
billions) of people, and the impacts of our code can be much greater than we
realize, even when we aren’t working on software for cars (which <a href="https://www.safetyresearch.net/blog/articles/toyota-unintended-acceleration-and-big-bowl-%E2%80%9Cspaghetti%E2%80%9D-code">we’ve killed
people
with</a>)
or medical devices (which <a href="https://hackaday.com/2015/10/26/killed-by-a-machine-the-therac-25/">we’ve also killed people
with</a>). It
may seem that the worst-case bugs in a file sharing server would simply prevent
users from sharing files, but one such bug led to the <a href="https://www.telegraph.co.uk/technology/2018/10/11/wannacry-cyber-attack-cost-nhs-92m-19000-appointments-cancelled/">significant disruption
of the National Health Service in the
UK</a>.
Non-critical emergencies had to be refused. It may seem that the worst-case
bugs in a web application library would simply take down some websites, but one
such bug led to the <a href="https://www.csoonline.com/article/3444488/equifax-data-breach-faq-what-happened-who-was-affected-what-was-the-impact.html">exfiltration of extremely sensitive data on nearly every
American adult with a credit
history</a>.</p>

<!--We've spent a lot of effort over the last three decades finding ways to improve
the safety of code. We have linters, which can detect unsafe patterns in code
(e.g. calls to `strcpy`, or use of uninitialized memory). We have fuzzers and
sanitizers, which can stress test our code and identify memory errors and data
races. Most promising (in my opinion), we have new progamming languages such as
Rust and Swift which are safer, competitive on performance, and showing
potential for replacing C and C++ in the settings that those languages have
typically dominated. These languages can prevent entire classes of mistakes
that keep recurring in C and C++ codebases even with the use of other safety
tools. Linters, sanitizers, fuzzers, and static analyzers all help to catch
mistakes, but they don't *prevent* them, and they can't catch everything. While
these new languages are not a panacea and have their own problems, they make
massive strides towards squashing issues we haven't been able to address via
other means. Despite having some of the best security and development practices
in the world, Google Chrome (written in C++) is still plagued with memory
errors that would have been entirely prevented with Rust. Recently, they found
that [70% of security vulnerabilities were caused by memory
errors](https://www.chromium.org/Home/chromium-security/memory-safety).-->

<p>Precautions and safety measures <em>do</em> exist, but people aren’t using them. Part
of this may be because the tooling isn’t good enough or easy enough to use.
Part of this may be because there hasn’t been enough time to see mass adoption.
But I think part of this may also be because of a lack of education and
awareness surrounding these issues. We can teach C and C++ and hope that
students will learn good habits and learn how to use static analyzers,
sanitizers, fuzzers, and safer languages on the job, but then have we not
failed them as educators? Seeing that software engineers keep making pretty
basic mistakes with critical impact, it seems that something is wrong and we
should be trying to do more.</p>

<h2 id="imagining-safety-education">Imagining safety education</h2>

<p>So, we should talk more about safety. But how should we go about it?</p>

<h3 id="should-there-be-a-safety-class">Should there be a “safety class”?</h3>

<p>In planning this class, we couldn’t find any other programming safety class out
there. Is that because no one has thought to do it yet, or is it because it is
better to teach safety in context alongside more central material?</p>

<p>Particularly because “safety” is so broad, it does seem helpful
to cover best practices and helpful tricks/tools while introducing new
material. However, there were two reasons we felt it might make sense to teach
a class entirely focused on safety.</p>

<p>First, teaching a separate safety class gives us room to experiment with
teaching new material that would be difficult to integrate into existing</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://reberhardt.com/blog/2020/10/05/designing-a-new-class-at-stanford-safety-in-systems-programming.html">https://reberhardt.com/blog/2020/10/05/designing-a-new-class-at-stanford-safety-in-systems-programming.html</a></em></p>]]>
            </description>
            <link>https://reberhardt.com/blog/2020/10/05/designing-a-new-class-at-stanford-safety-in-systems-programming.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24711314</guid>
            <pubDate>Wed, 07 Oct 2020 18:47:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google Interview Questions Deconstructed: The Knight’s Dialer]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 100 (<a href="https://news.ycombinator.com/item?id=24711094">thread link</a>) | @thanato0s
<br/>
October 7, 2020 | https://alexgolec.dev/google-interview-questions-deconstructed-the-knights-dialer/ | <a href="https://web.archive.org/web/*/https://alexgolec.dev/google-interview-questions-deconstructed-the-knights-dialer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p>This is the second in a series of posts in which I share my advice for candidates interviewing for tech companies, drawing on my experience as an engineer and interviewer at Google. If you haven’t already, take a look at the <a href="https://alexgolec.dev/introducing-google-interview-questions-deconstructed/">introduction</a> to this series.</p><p><em>Before I start, a disclaimer: while interviewing candidates is one of my professional responsibilities, this blog represents my personal observations, my personal anecdotes, and my personal opinions. Please don’t mistake this for any sort of official statement by or about Google, Alphabet, or any other person or organization.</em></p><p>This was the first problem I used during my interviewing career, and it was also the first to leak and get banned. I like it because it hits number of sweet spots:</p><ul><li>It’s easy to state and understand.</li><li>It has a number of solutions, each requiring varying degrees of algorithms and data structures knowledge. Also, a little bit of insight goes a long way.</li><li>Each solution can be implemented in relatively few lines, making it perfect for a time-constrained environment.</li></ul><p>If you’re a student or otherwise applying to tech jobs, my hope is that you’ll come away from reading this with a better understanding of what to expect from interview problems. If you’re an interviewer, I’d like to share my thought process and stylistic approach to interviewing, the better to inform others and solicit comments.</p><p>Note I’ll be writing code in Python. I like Python because it’s easy to learn, compact, and has an absolutely massive standard library. Candidates like it, too: even though we impose no language constraints, 90% of people I interview use Python. Also I use Python 3 because c’mon, it’s 2018.</p><p><em>Join <a href="https://discord.gg/cKFppJ">our Discord</a> to discuss this problem with the author and the community! </em></p><p>Imagine you place a knight chess piece on a phone dial pad. This chess piece moves in an uppercase “L” shape: two steps horizontally followed by one vertically, or one step horizontally then two vertically:</p><figure><img src="https://alexgolec.dev/content/images/2020/08/1-pE4b3hqGDv7pKivQTQZyPw.png" alt="Image for post"><figcaption>Pay no attention to the poorly-redacted star and pound keys</figcaption></figure><p>Suppose you dial keys on the keypad using only hops a knight can make. Every time the knight lands on a key, we dial that key and make another hop. The starting position counts as being dialed.</p><p>How many distinct numbers can you dial in N hops from a particular starting position?</p><p>Every interview I conduct basically breaks down into two parts: first we find an algorithmic solution and then the candidate implements it in code. I say “we” find a solution because I’m not a mute spectator: 45 minutes is not a lot of time to design and implement anything under the best circumstances, never mind under pressure. I let candidates take the lead in the discussion, generating ideas, solving instances of the problem, etc., but I’m more than happy to give a nudge in the right direction. The better the candidate, the fewer hints I tend to have to give, but I have yet to see a candidate who required no input from me at all.</p><p>I should underscore this, because it’s important: as an interviewer, I’m not in the business of sitting back and watching people fail. I want to write as much positive feedback as I can, and I try to give you opportunities to allow me to write good things about you. Hints are my way of saying “okay, I’m gonna give this bit to you, but only so you can move on and show me what you’ve got on the other parts of the question.”</p><p>With that being said, your first action after hearing the question should be stepping up to the whiteboard and solving small instances of the problem by hand. <em>Never dive right into code!</em> Solving small instances lets you spot patterns, observed and edge cases, and also helps crystallize a solution in your head. As an example, suppose you start on 6 and have two hops to make. Your sequences will be…</p><ul><li>6–1–8</li><li>6–1–6</li><li>6–7–2</li><li>6–7–6</li><li>6–0–4</li><li>6–0–6</li></ul><p>…for a total of six sequences. If you’re following along, try taking a pencil and paper and deriving these. This doesn’t translate well into a blog post, but trust me when I say there’s something magical about working out a problem by hand that leads to many more insights than just staring at it and thinking quietly.</p><p>With all that said, you may have a solution forming in your head. But before we get there…</p><p>One of the surprises I had when I started using this problem is how often candidates get stuck on computing the keys to which we can hop from a given position, also known as the neighbors. My advice is: when in doubt, write an empty placeholder and ask the interviewer if you can implement it later. This problem’s complexity does not lie in the neighbor computation; I’m paying attention to how well you count full numbers. Any time spent on neighbor computation is effectively wasted.</p><p>I would accept “let’s assume there’s a function that gives me the neighbors” along with the following stub. Of course, I’ll probably ask you to double back and implement this later, but only if we have time. You can simply write a stub like this and move on:</p><pre><code>def neighbors(position):
	...</code></pre><p>Also, you don’t really lose much by asking to use a stub: if the question’s complexity is elsewhere I’ll allow it. If not, I’ll ask you to actually implement it. I don’t mind when candidates don’t realize where the complexity of a question lies, especially in the early stages when they might not have fully explored the problem.</p><p>As for the neighbors function here, given that it never changes you can simply create a map and return the appropriate value:</p><pre><code>NEIGHBORS_MAP = {
    1: (6, 8),
    2: (7, 9),
    3: (4, 8),
    4: (3, 9, 0),
    5: tuple(),  # 5 has no neighbors
    6: (1, 7, 0),
    7: (2, 6),
    8: (1, 3),
    9: (2, 4),
    0: (4, 6),
}
def neighbors(position):
    return NEIGHBORS_MAP[position]</code></pre><p>Anyway, on to the solution. Perhaps you’ve already noticed this problem can be solved by enumerating all possible numbers and counting them. You can use recursion to generate these values:</p><pre><code>def yield_sequences(starting_position, num_hops, sequence=None):
    if sequence is None:
        sequence = [starting_position]
    
    if num_hops == 0:
        yield sequence
        return

    for neighbor in neighbors(starting_position):
        yield from yield_sequences(
            neighbor, num_hops - 1, sequence + [neighbor])

def count_sequences(starting_position, num_hops):
    num_sequences = 0
    for sequence in yield_sequences(starting_position, num_hops):
        num_sequences += 1
    return num_sequences</code></pre><p>This works, and it’s a common starting point I saw in interviews. Notice, however, that we generate the numbers and never actually use them. This problem asks for the <em>count</em> of numbers, not the numbers themselves. Once we count a number we never revisit it. As a general rule of thumb, I recommend paying attention to when your solution computes something it doesn’t use. Often you can cut it out and get a better solution. Let’s do that now.</p><p>How can we count phone numbers without generating them? It can be done, but not without an additional insight. Notice how the count of numbers that can be generated from a given starting position in N hops is equal to the sum of the counts of hops that can be generated starting from each of its neighbors in N-1 hops. Stated mathematically as a recurrence relation, it looks like this:</p><figure><img src="https://alexgolec.dev/content/images/2020/08/1-mcwSdrDe69X5FDegPmfgHg.png" alt="Image for post"></figure><p>This is intuitively obvious when you consider what happens with one hop: 6 has 3 neighbors (1, 7, and 0) and in zero hops you can reach one number for each, so you can only dial three numbers.</p><p>How does one arrive at this insight, you might ask? If you’ve studied recursion, this should become evident after some exploration on the whiteboard. Many candidates who’ve practiced recursion immediately notice this problem breaks down into smaller subproblems, which is a dead giveaway. If you’re in an interview with me and you can’t seem to arrive at this insight, I will usually give hints to help get you there, up to and including outright giving it away if prodding fails.</p><p>Once you have this insight in hand, you can already move forward and solve this problem again. There are a number of implementations that use this fact, but let’s start with the one I see most often in interviews: the naive recursive approach:</p><pre><code>from neighbors import neighbors                                 
                                                                
def count_sequences(start_position, num_hops):                  
    if num_hops == 0:                                           
        return 1                                                
                                                                
    num_sequences = 0                                           
    for position in neighbors(start_position):                  
        num_sequences += count_sequences(position, num_hops - 1)
    return num_sequences                                        
                                                                
if __name__ == '__main__':                                      
    print(count_sequences(6, 2))                                </code></pre><p>That’s it! Combine this with a function to compute the neighbors and you’ve produced a working solution! At this point, you should pat yourself on the back. If you scroll down you’ll notice we’ve still got a lot of ground to cover, but this point is a milestone. Producing any working solution already sets you apart from a surprising number of candidates.</p><p>This next question is one you’re going to be hearing a lot from me: what is the Big-O complexity of this solution? For those who don’t know, Big-O complexity is (informally) a sort of shorthand for the rate at which the amount of computation required by a solution grows as a function of the size of the input. For this problem, the size of the input is the number of hops. If you’re interested in the proper mathematical definition, you can read more <a href="https://en.wikipedia.org/wiki/Big_O_notation" rel="noopener nofollow">here</a>.</p><p>For this implementation, every call to <code>count_sequences()</code> recursively calls <code>count_sequences()</code> at least twice, because each key has at least two neighbors. Since we recurse a number of times equal to the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://alexgolec.dev/google-interview-questions-deconstructed-the-knights-dialer/">https://alexgolec.dev/google-interview-questions-deconstructed-the-knights-dialer/</a></em></p>]]>
            </description>
            <link>https://alexgolec.dev/google-interview-questions-deconstructed-the-knights-dialer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24711094</guid>
            <pubDate>Wed, 07 Oct 2020 18:22:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WSL2 – Installation Tutorial for Graphical Windows Subsystem on Linux]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 85 (<a href="https://news.ycombinator.com/item?id=24711054">thread link</a>) | @todsacerdoti
<br/>
October 7, 2020 | https://l-o-o-s-e-d.net/wsl2 | <a href="https://web.archive.org/web/*/https://l-o-o-s-e-d.net/wsl2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
          <div>
            <p><h2>WSL2</h2></p>

            

            <div>
              <p>06:00pm | 10/05/2020<br>Daniel Tompkins</p>
              


 
            </div>

            <p>
              <h3>Microsoft 💔 Linux</h3>
            </p>

            <div>
              <p>In 2001, Microsoft's former CEO— Steve Ballmer— was <a target="_blank" href="https://www.theregister.com/2001/06/02/ballmer_linux_is_a_cancer/">quoted</a> by the online tech news publication, <em>The Register</em>, saying:</p>
              <p>Linux is a cancer that attaches itself in an intellectual property sense to everything it touches</p>
              <p>Fast-forward 15 years into the future— at Microsoft's developer conference, <em>Build 2016</em>— and Gates' tech behemoth reveals a sudden volte-face. The current CEO, Satya Nadella, announces Windows Subsystem for Linux. With WSL, Microsoft is taking some of the most popular Linux distributions and making them available within Windows through the Microsoft Store.</p>
              <p>According to a <a target="_blank" href="https://w3techs.com/technologies/overview/operating_system">W<sup>3</sup>Techs survey</a>, Unix operating systems (the under-pinning OS of Linux, as well as MacOS) make up 71% of the Web, the remaining 29% being Windows. Additionally, every Android phone, tablet and smart TV runs on a modified version of the Linux kernel. So, I guess if you can't beat 'em, join 'em?</p>
            </div>

            <a target="_blank" href="https://l-o-o-s-e-d.net/assets/img/wsl2/w3techs_webservers.jpg">
              <p><img alt="W3Techs Survey on Web OS's, Unix: 71%, Windows: 29%" data-src="assets/img/wsl2/w3techs_webservers.jpg" src="https://l-o-o-s-e-d.net/assets/img/wsl2/w3techs_webservers.jpg">
              </p>
            </a>

            <p>Whether or not its because of Microsoft's good graces or some ulterior motive, I know having an easily accessible Unix-type environment available on Windows has been a godsend for me and for so many other developers.</p>

            <p>
              <h3>What's so great about WSL?</h3>
            </p>

            <div>
              <p>Before WSL, developers running Windows had two options: 1) a virtual machine (VM), or 2) dual-booting. Running a virtual machine uses up more resources than WSL. It can also be difficult to integrate hardware and files between the host machine and the VM. Dual-booting allows for a full-fledged install on a separate disk partition; but it requires a restart any time you want to switch between OS's.</p>
              <p>Windows Subsystem on Linux doesn't integrate with the host's hardware perfectly— for example, NVIDIA is still working on <a target="_blank" href="https://developer.nvidia.com/cuda/wsl">CUDA drivers</a> that will take advantage of GPU resources from within WSL. However, for Linux developers who are frequently running CAD software or Adobe Suite (which are <a target="_blank" href="https://appdb.winehq.org/objectManager.php?iId=17&amp;sClass=application">difficult-to-impossible</a> to install on Linux), WSL can be a fantastic partner.</p>
            </div>

            <p>
              <h3>WSL1 vs WSL2</h3>
            </p>

            <div>
              <p>More recently, Microsoft announced WSL2— an update that allows for a more complete Linux kernel to run on a Windows machine. This made it much easier to install a variety of software that had been difficult to run on the previous, WSL1. WSL2 is very similar to running a virtual machine (in fact it uses Microsoft's hyperV virtual machines).</p>
              <p>However, using WSL2 (as opposed to installing a Linux distro through VirtualBox, or another VM manager) provides some minor performance benefits since Microsoft has optimized it to integrate with Windows' services. If you want, I recommend reading Microsoft's own WSL1-vs-WSL2 <a target="_blank" href="https://docs.microsoft.com/en-us/windows/wsl/compare-versions">feature comparison</a> docs.</p>
            </div>

            <p>
              <h3>Alright, so how do I install WSL2?</h3>
            </p>

            <div>
              <p>Microsoft has clean, straight-forward <a target="_blank" href="https://docs.microsoft.com/en-us/windows/wsl/install-win10">installation documentation</a> for WSL and WSL2. You can refer to that tutorial if you get stuck, or just follow the steps outlined below. Before starting, make sure you update your Windows 10 installation with the most recent build.</p>
              <p>I'll also be going one-step further, and showing you how to run a Linux GUI using WSL2 and VcXsrv (display forwarding). If you're more of a visual-learner, I've also included an installation speedrun <a target="_blank" href="https://www.youtube.com/embed/gtXIzVM5wZE">video</a> that follows the same steps outlined below (<em>edit: I forgot step 11 in the video, and it's a critical one! Make sure you do that!</em>).</p>
            </div>

            <div>
              <p><b>1. Enable WSL Feature</b></p>
              <p>First you need to enable the Windows Subsystem on Linux feature by right-clicking on Powershell from the start menu and clicking "Run as Administrator".</p>
              <p>Then, paste the following command and hit "Enter"— don't close the Powershell!</p>
              <pre><code>dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart</code></pre>
            </div>

            <div>
              <p><b>2. Enable WSL2 Virtual Machine Feature</b></p>
              <p>After the last command is finished, paste the following command in the same Administrator-level shell, and hit "Enter" to enable the WSL2 VM. Again, keep this shell open.</p>
              <pre><code>dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart</code></pre>
            </div>

            <div>
              <p><b>3. Download and Install the WSL2 Linux Kernel Update</b></p>
              <p>Click <a target="_blank" href="https://wslstorestorage.blob.core.windows.net/wslblob/wsl_update_x64.msi">here</a> to download the Microsoft executable for installing the WSL2 Linux Kernel update. Once it's finished downloading, double-click the executable and follow the installation steps. This part's pretty straightforward</p>
            </div>

            <div>
              <p><b>4. Set WSL2 as Default Version</b></p>
              <p>Copy and paste the following command in Powershell to set WSL2 to be the default version:</p>
              <pre><code>wsl --set-default-version 2</code></pre>
            </div>

            <div>
              <p><b>5. Install Ubuntu 20.04 from the Microsoft Store</b></p>
              <p>Click the start menu and open the Microsoft Store. Search for "Ubuntu 20.04" and install this Linux distro. If you want to use another distro, that's fine; but Ubuntu 20.04 is compatible with the Regolith Linux desktop GUI we'll be installing in just a bit.</p>
            </div>

            <div>
              <p><b>6. Ubuntu 20.04 Initial Setup</b></p>
              <p>Once Ubuntu is done installing, click "Launch" to initiate first-time installation setup. You'll be prompted to put in a username and password.</p>
            </div>

            <div>
              <p><b>7. Make sure You're Using WSL2</b></p>
              <p>At this point, it might be a good idea to double-check that WSL is using version 2 by default. Open a command prompt (or use Powershell if it's still open) to paste in the following command:</p>
              <pre><code>wsl --list --verbose</code></pre>
            </div>

            <div>
              <p><b>8. Download and Install VcXsrv</b></p>
              <p>VcXsrv is an X Server that we'll use to view the GUI from WSL2.</p>
              <p>There are a few other display-forwarding servers available (like <a target="_blank" href="https://sourceforge.net/projects/xming/">Xming</a>), but I've found VcXsrv works the best. Download the executable <a target="_blank" href="https://sourceforge.net/projects/vcxsrv/">here</a> and click through the installation steps.</p>
            </div>

            <div>
              <p><b>9. Install Regolith Desktop</b></p>
              <p>I have <a target="_blank" href="https://l-o-o-s-e-d.net/regolith">Regolith Desktop</a> installed on one of my PCs, and it's fantastic. It's preconfigured to use the i3 window manager which I find incredibly efficient for its tiling and hotkey features.</p>
              <p>A <em>loosed</em> reader, Rodrigo, asked me use Regolith for the tutorial; but if you want to install a different GUI you can! To install Regolith Desktop, open your fresh Ubuntu install, and paste in the following lines:</p>
              <pre><code>sudo add-apt-repository ppa:regolith-linux/release</code></pre>
              <pre><code>sudo apt install regolith-desktop i3xrocks-net-traffic i3xrocks-cpu-usage i3xrocks-time</code></pre>
              <p>It's a lot of packages, so it'll take some time.</p>
            </div>

            <div>
              <p><b>10. Change the "Mod" Key</b></p>
              <p>Regolith, or rather i3-wm, uses the Super (Windows) key as the hotkey prefix by default. Since you're running this GUI within Windows, you'll run into a lot of overlap between Windows' and i3-wm's preconfigured shortcuts.</p>
              <p>For this reason, I recommend swapping the Super key for the Alt key. To  change the Mod key mapping use the Vim or Nano text editors to open the configuration file located at:</p>
              <pre><code>vim /etc/regolith/i3/config</code></pre>
              <p>On line 42 and 43, you'll find the Mod key assignment. Switch "Mod1" and "Mod4" and you'll be good to go! Your edited lines should look like this:</p>
              <pre><code>set_from_resource $mod i3-wm.mod Mod1</code></pre>
              <pre><code>set_from_resource $alt i3-wm.alt Mod4</code></pre>
              <p>If you're using Vim, hit "Escape" and type ":wq", then hit "Enter" to write and quit the file. You can check out the <a target="_blank" href="https://regolith-linux.org/regolith-site-r13/docs/howto/super-to-alt/">official Regolith tutorial</a> on making these changes if you get stuck.</p>
            </div>

            <div>
              <p><b>11. Export DISPLAY parameter</b></p>
              <p>Another critical edit (that I forgot to put in the video— oops 🙃) is to export the DISPLAY variable. Since WSL2 is a VM, it has it's own IP address (which can change at each startup). As a result, you'll need to add a couple lines to your bash profile for VcXsrv to connect to WSL2.</p>
              <p>To open your ".bashrc" with Vim:</p>
            </div>
            <div>
              <pre><code>vim ~/.bashrc</code></pre>
              <p>Press and hold Shift then press "G" to jump to the bottom of the file. On two new lines, paste in the following code:</p> 
              <pre><code>export DISPLAY=$(awk '/nameserver / {print $2; exit}' /etc/resolv.conf 2&gt;/dev/null):0<br>export LIBGL_ALWAYS_INDIRECT=1</code></pre>
            </div>

            <div>
              <p><b>12. Open and Configure VcXsrv</b></p>
              <p>Click the start menu and type in "Xlaunch" then hit "Enter" to run VcXsrv. Click the "One window without titlebar" option (you can explore the others later, if you want) and click next. Leave it on "Start no client" and click next. Then, in the "Additional parameters" input, add "-ac" and click next. I recommend clicking "Save configuration" for ease of use.</p>
              <p>At this point, you should have a black screen waiting to accept a display input.</p>
            </div>

            <p><b>13. Run Regolith Desktop</b></p>
            <p>The last thing to do is run the magic line:</p>
            <div>
              <pre><code>i3-gnome-flashback-session</code></pre>
              <p>You should then see a graphical Regolith Desktop appear in the VcXsrv window! Huzzah! Feel free to play around with your new graphical WSL2 setup. To see an overview of the available shortcuts, use "Alt+Shift+?" to bring up the help menu. You can find more help in Regolith's official <a target="_blank" href="https://regolith-linux.org/docs/">documentation</a>.</p>
            </div>

            <a target="_blank" href="https://l-o-o-s-e-d.net/assets/img/wsl2/regolith_screenshot.jpg">
              <p><img alt="Regolith Desktop with Windows 10 Taskbar and i3 tiling running on WSL2" data-src="assets/img/wsl2/regolith_screenshot.jpg" src="https://l-o-o-s-e-d.net/assets/img/wsl2/regolith_screenshot.jpg">
              </p>
            </a>

            <p>
              </p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://l-o-o-s-e-d.net/wsl2">https://l-o-o-s-e-d.net/wsl2</a></em></p>]]>
            </description>
            <link>https://l-o-o-s-e-d.net/wsl2</link>
            <guid isPermaLink="false">hacker-news-small-sites-24711054</guid>
            <pubDate>Wed, 07 Oct 2020 18:18:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Translation Units Considered Harmful?]]>
            </title>
            <description>
<![CDATA[
Score 102 | Comments 51 (<a href="https://news.ycombinator.com/item?id=24710612">thread link</a>) | @ingve
<br/>
October 7, 2020 | https://cor3ntin.github.io/posts/translation_units/ | <a href="https://web.archive.org/web/*/https://cor3ntin.github.io/posts/translation_units/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>Let say you have some struct <code>square</code> you want to compute the area of.</p>
<p><code>struct square { int width; }</code></p>
<p>You could of course do that:</p>
<p><code>int area(square s) { return s.width * s.width; }</code></p>
<p>But, your friend Tony told you to use more functions, so instead you do that</p>
<div><pre><code data-lang="cpp"><span>int</span> <span>area</span>(square s) { <span>return</span> width(s) * width(s); }
<span>int</span> <span>width</span>(square s) { <span>return</span> s.width; }
</code></pre></div><p><code>area</code> being the function you really care about it is defined first - after all, code reads from top to bottom.</p>
<p>As you may have guessed from the lack of <code>;</code> after the struct’s closing bracket, the above code is written in D.
I figure my readership isn’t really into D, so maybe you would prefer some <strong>Rust</strong>?</p>
<div><pre><code data-lang="rs"><span>pub</span><span> </span><span>fn</span> <span>area</span>(square: <span>Square</span>)<span> </span>-&gt; <span>i32</span> {<span> </span><span>return</span><span> </span>width(s)<span> </span>*<span> </span>width(s)<span> </span>}<span>
</span><span></span><span>pub</span><span> </span><span>fn</span> <span>width</span>(square: <span>Square</span>)<span> </span>-&gt; <span>i32</span> {<span> </span><span>return</span><span> </span>s.width<span> </span>}<span>
</span><span></span><span>pub</span><span> </span><span>struct</span> <span>Square</span><span> </span>{<span> </span>width: <span>i32</span> }<span>
</span></code></pre></div><p>You can even compute the area of you square <strong><em>at scale</em></strong> with go</p>
<div><pre><code data-lang="go"><span>func</span> <span>Area</span>(s square) <span>int</span> { <span>return</span> <span>width</span>(s) * <span>width</span>(s); }
<span>func</span> <span>width</span>(s square) <span>int</span> { <span>return</span> s.width }
<span>type</span> square <span>struct</span> { width  <span>int</span> }
</code></pre></div><p>Or even <strong>Swift</strong>ly.</p>
<div><pre><code data-lang="swift"><span>func</span> <span>area</span>(s: Square) -&gt; <span>Int</span> { <span>return</span> width(s:s) * width(s:s); }
<span>func</span> <span>width</span>(s: Square) -&gt; <span>Int</span> { <span>return</span> s.width }
<span>struct</span> <span>Square</span> { <span>var</span> <span>width</span>:<span>Int</span> = <span>0</span>; }
</code></pre></div><p>But of course, <em>you</em> will worry about the overhead and will want the language the most performant (that’s not a word).
Eager to please and impress, let me copy the D code and add that oh-so-important semi-colon.</p>
<div><pre><code data-lang="cpp"><span>struct</span> <span>square</span> { <span>int</span> width; };
<span>int</span> <span>area</span>(square s)  { <span>return</span> width(s) * width(s); }
<span>int</span> <span>width</span>(square s) { <span>return</span> s.width; }
</code></pre></div><p>That’s nice, isn’t it?  Interesting how most languages look alike.
Hum, wait, that doesn’t work???!!!</p>
<p><code>error: 'width' was not declared in this scope</code></p>
<p>But, you stupid thing, it’s <em>RIGHT THERE</em>.
I declared everything in the global scope like a maniac, can’t you see?</p>
<p>Alas, the standard makes the compiler blind.</p>
<blockquote>
<p>In the definition of a function that is a member of namespace N, a name used after the function’s declarator-id23 shall be declared before its use in the block in which it is used or in one of its enclosing blocks ([stmt.block]) or shall be declared before its use in namespace N or, if N is a nested namespace, shall be declared before its use in one of N’s enclosing namespaces.</p>
</blockquote>
<p>Of course, this makes no sense, a compiler can really easily parse the declaration independently of the definition, as
proven by other languages. Or you know, C++ classes. (imagine replacing a big namespace with a class full of static methods and nested types)
Unless of course, it’s a performance thing.
But, you are a very great engineer, so you wouldn’t let a source file grow above a few hundred lines of code, would you?
I bet your code is beautiful, like this small self-contained super useful program</p>
<div><pre><code data-lang="cpp"><span>#include</span> <span>&lt;iostream&gt;</span><span>
</span><span></span><span>int</span> <span>main</span> () {
    std::cout &lt;&lt; <span>"Hello world</span><span>\n</span><span>"</span>;
}
</code></pre></div><p>Which on my system expands to about <em>33000</em> lines of code. The freaking thing. But more on that later.</p>
<p>Let’s go back to square one.
C++, in its infinite wisdom, lets us forward-declare functions, so we can write this:</p>
<div><pre><code data-lang="cpp"><span>struct</span> <span>square</span> { <span>int</span> width; };
<span>int</span> <span>width</span>(<span>const</span> square&amp; s);
<span>int</span> <span>area</span>(<span>const</span> square&amp; s)  { <span>return</span> width(s) * width(s); }
<span>int</span> <span>width</span>(<span>const</span> square&amp; s) { <span>return</span> s.width; }
</code></pre></div><p>Which is nice and dandy, if you squint.</p>
<p>Besides requiring you to get the exact declaration of functions perfectly right - which is hard to maintain, lots of entities are not forward-declarable,
notably type alias, templated types, etc.
Which is an odd limitation given that where forward declaring a function require you
to know the precise signature, for types you are merely trying to introduce a name.</p>
<h2 id="noexcept">noexcept</h2>
<p>You will notice that <code>area</code> never throws.
That is, there is no subexpression of <code>area</code> that can throw, ever.</p>
<p>You can check that it does not.</p>
<p><code>static_assert(noexcept(area(square{})));</code></p>
<p>Inevitably,  that fails.
<code>error: static assertion failed</code>.
We indeed forgot to tell the compiler that our function could not throw.</p>
<div><pre><code data-lang="cpp"><span>int</span> <span>width</span>(<span>const</span> square&amp; s) <span>noexcept</span>;
<span>int</span> <span>area</span>(<span>const</span> square&amp; s) <span>noexcept</span> { <span>return</span> width(s) * width(s); }
<span>int</span> <span>width</span>(<span>const</span> square&amp; s) <span>noexcept</span> { <span>return</span> s.width; }
</code></pre></div><p>Notice that we need to add <code>noexcept</code> on all declarations, including the forward declarations.
And, you can lie to the compiler pretty easily.</p>
<div><pre><code data-lang="cpp"><span>int</span> <span>area</span>(<span>const</span> square&amp; s) <span>noexcept</span> {
    <span>return</span> width(s) * width(s);
}

<span>int</span> <span>width</span>(<span>const</span> square&amp; s) {
    <span>throw</span> <span>42</span>;
}
</code></pre></div><p>The above code will <code>std::terminate()</code>, you know that the compiler knows that, everybody knows that.</p>
<p>So…what functions should be marked <code>noexcept</code>?
It’s pretty simple actually. All the functions that can not throw.
That is the functions that:</p>
<ul>
<li>Don’t contain a <code>throw</code> exception</li>
<li>Don’t call non-noexcept functions</li>
</ul>
<p>Notice the double (triple?) negative.</p>
<p>So you, as a developer striving to mark all function that can be <code>noexcept</code> as such,
have to walk the call tree recursively until you can ascertain that the call chain will never throw
or actually might (because one callee does throw, or is at a C interface boundary, etc).
One argument against exceptions is that it makes reasoning about control flow harder:
Exceptions more or less force you to reason about the control flow of the whole program at every time.
<code>noexcept</code> is supposed to solve that, but, to put that <code>noexcept</code> keyword confidently, you still need
to do that analyze. The chances you get it wrong are high.
If you write generic code, you will have to tell the compiler that a symbol is noexcept
if all of it’s subexpression is noexcept manually.</p>
<p>And the compiler can not trust you that the function will indeed not throw, so implementers will inject calls to <code>std::terminate</code>
here and there, negating somewhat the performance benefits of marking the function <code>noexcept</code> in the first place.</p>
<p>Let’s rewrite our code using lambda instead</p>
<div><pre><code data-lang="cpp"><span>auto</span> width = [](<span>const</span> square&amp; s) -&gt; <span>int</span> {
    <span>return</span> s.width;
};
<span>auto</span> area = [](<span>const</span> square&amp; s) -&gt; <span>int</span> {
    <span>return</span> <span>width</span>(s) * width(s);
};
</code></pre></div><p>Of course, lambdas cannot be forward declared.
So I had to reorganize the code.</p>
<p>And now, despite the lack of <code>noexcept</code> keyword,
<code>static_assert(noexcept(area(square{})));</code> passes.</p>
<p><strong>What is happening?</strong></p>
<p>It turns out that the compiler is pretty good at knowing which functions are <code>noexcept</code>.
In the case of lambdas, the definition will always be visible to the compiler before any invocation,
so it can implicitly mark it no except and do the work for us. This allowed as part of C++20.</p>
<h3 id="what-does-noexcept-even-mean">What does noexcept even mean?</h3>
<p>I’m not saying that <code>noexcept</code> would not be necessary in an ideal world, because it has more than one meaning
and people use it differently. Notably, <code>noexcept</code> might mean:</p>
<ul>
<li>Do not generate exception handling code for this function</li>
<li>This function does not throw</li>
<li>This function will <em>never</em> throw</li>
</ul>
<p>The first statement is a request for the compiler, the second is an assertion for both the compiler and human readers,
while the last one is exclusively for people.</p>
<p>So <code>noexcept</code> would remain interesting at API boundary as a contract between people even if the compiler could decide
for itself whether the function was actually non-throwing.</p>
<h2 id="transaction_safe">transaction_safe</h2>
<p>The Transactional Memory TS defines the notion of <em>transaction safe expression</em> as follow:</p>
<blockquote>
<p>An expression is transaction-unsafe if it contains any of the following as a potentially-evaluated subexpression (3.2[basic.def.odr]):</p>
</blockquote>
<blockquote>
<ul>
<li>an lvalue-to-rvalue conversion (4.1 [conv.lval]) applied to a volatile glvalue</li>
<li>an expression that modifies an object through a volatile glvalue</li>
<li>the creation of a temporary object of volatile-qualified type or with a subobject of volatile-qualified type</li>
<li>a function call (5.2.2 expr.call) whose postfix-expression is an id-expression that names a non-virtual
function that is not transaction-safe</li>
<li>an implicit call of a non-virtual function that is not transaction-safe</li>
<li>any other <strong>call of a function, where the function type is not “transaction_safe function”</strong></li>
</ul>
</blockquote>
<p>(Emphasis mine)</p>
<p>The details are not important, but, basically, a <code>transaction_safe</code> safe expression is one that doesn’t touch volatile objects.
And only call functions with the same properties.
That’s probably upward of 99% of functions - I suspect the very terrible default exists for compatibility reasons.
The important part is that you have to tag all your functions or hope that the property holds true recursively.
(Like <code>noexcept</code>, you can lie, by marking a function <code>transaction_safe</code> even if a callee is not itself <code>transaction_safe</code>, opening the door to UB).
An issue that seems to hold this TS back.</p>
<h2 id="constexpr">constexpr</h2>
<p><code>constexpr</code> functions are a bit different. The compiler knows what functions are candidate <code>constexpr</code>.
Most of the time it will constant evaluate them regardless of whether they are actually marked as such.
The keyword is required to ensure that the compiler will actually do the constant evaluation when it can and, most importantly,
because removing the constexpr-ness of a function may be a source breaking change - (if that function is called during the evaluation of a <code>constexpr</code> variable).
By its very nature, <code>constexpr</code> implies that <code>constexpr</code> functions are defined somewhere is the TU. And everything not defined in the TU cannot be constant-evaluated.
<a href="https://wg21.link/p1235">A proposal for C++20 proposes to make it implicit in some cases</a></p>
<p>For now, we are left with the following code, and it is on you to use the appropriate qualifiers.</p>
<div><pre><code data-lang="cpp"><span>constexpr</span> <span>int</span> <span>width</span>(square s) <span>noexcept</span> transaction_safe;
<span>constexpr</span> <span>int</span> <span>area</span>(square s) <span>noexcept</span> transaction_safe  { <span>return</span> width(s) * width(s); }
<span>constexpr</span> <span>int</span> <span>width</span>(square s) <span>noexcept</span> transaction_safe { <span>return</span> s.width; }
</code></pre></div><p>As of C++20, <code>constexpr</code> functions can throw. The committee is also considering making <code>new</code> expressions
<code>noexcept</code> by 23 or 26 so we are slowly getting to a place where 95%+ of functions will be both <code>constexpr</code> and <code>noexcept</code>
eligible and will have to be marked manually.</p>
<p><strong>Is there a better way ?</strong></p>

<p>A source file and its included headers form a translation unit.
Multiple translations units form a program.</p>
<p>Sounds simple enough right?
It’s actually <em>simpler</em> than right.</p>
<p>Headers and sources files are a bit of a lie we tell ourselves.
As far as I can tell, the term “header” only appear in the standard as to name the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cor3ntin.github.io/posts/translation_units/">https://cor3ntin.github.io/posts/translation_units/</a></em></p>]]>
            </description>
            <link>https://cor3ntin.github.io/posts/translation_units/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24710612</guid>
            <pubDate>Wed, 07 Oct 2020 17:34:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Generalizing 'jq' and Traversal Systems using optics and standard monads]]>
            </title>
            <description>
<![CDATA[
Score 142 | Comments 78 (<a href="https://news.ycombinator.com/item?id=24710565">thread link</a>) | @todsacerdoti
<br/>
October 7, 2020 | https://chrispenner.ca/posts/traversal-systems | <a href="https://web.archive.org/web/*/https://chrispenner.ca/posts/traversal-systems">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p>Hi folks! Today I'll be chatting about <strong>Traversal Systems</strong> like <strong>jq</strong> and <strong>XPath</strong>; we're going to discover which properties make them useful, then see how we can replicate their most useful behaviours in Haskell using (almost entirely) pre-ols!existing standard Haskell tools! Let's go!</p>
<h2 id="whats-a-traversal-system">What's a Traversal System?</h2>
<p>First off I'll admit that "Traversal System" is a name I just came up with, you probably won't find anything if you search for it (unless this post really catches on 😉).</p>
<p>A <strong>Traversal System</strong> allows you dive deeply into a piece of data and may allow you to fetch, query, and edit the structure as you go while maintaining references to other pieces of the structure to influence your work. The goal of most Traversal Systems is to make this as painless and concise as possible. It turns out that this sort of thing is <strong>incredibly useful</strong> for manipulating JSON, querying HTML and CSS, working with CSVs, or even just handling standard Haskell Records and data-types.</p>
<p>Some good examples of existing <strong>Traversal Systems</strong> which you may have heard of include the brilliant <a href="https://stedolan.github.io/jq/">jq</a> utility for manipulating and querying JSON, the <strong>XPath</strong> language for querying XML, and the <a href="https://github.com/noprompt/meander">meander</a> data manipulation system in Clojure. Although each of these systems may appear drastically different at a glance, they both <em>accomplish many of the same goals</em> of manipulating and querying data in a concise way.</p>
<p>The similarities between these systems intrigued me! They seem so similar, but yet still seem to share very little in the way of structure, syntax, and prior art. They re-invent the wheel for each new data type! Ideally we could recognize the useful behaviours in each system and build a generalized system which works for any data type.</p>
<p>This post is an attempt to do exactly that; we'll take a look at a few things that these systems do well, then we'll re-build them in Haskell using standard tooling, all the while abstracting over the type of data!</p>
<h2 id="optics-as-a-basis-for-a-traversal-system">Optics as a basis for a traversal system</h2>
<p>For any of those who know me it should be no surprise that my first thought was to look at optics (i.e. Lenses and Traversals). In general I find that optics solve a lot of my problems, but in this case they are particularly appropriate! Optics inherently deal with the idea of diving deep into data and querying or updating data in a structured and compositional fashion.</p>
<p>In addition, optics also allow abstracting over the data type they work on. There are pre-existing libraries of optics for working with JSON via <a href="https://hackage.haskell.org/package/lens-aeson"><code>lens-aeson</code></a> and for html via <a href="https://hackage.haskell.org/package/taggy-lens"><code>taggy-lens</code></a>. I've written optics libraries for working with <a href="https://hackage.haskell.org/package/lens-csv">CSVs</a> and even <a href="https://hackage.haskell.org/package/lens-regex-pcre">Regular Expressions</a>, so I can say confidently that they're a brilliantly adaptable tool for data manipulation.</p>
<p>It also happens that optics are well-principled and mathematically sound, so they're a good tool for studying the properties that a system like this may have.</p>
<p>However, optics themselves don't provide everything we need! Optics are rather obtuse, in fact I wrote <a href="https://leanpub.com/optics-by-example">a whole book</a> to help teach them, and they lack clarity and easy of use when it comes to building larger expressions. It's also pretty tough to work on one part of a data structure while referencing data in another part of the same structure. My hope is to address some of these short comings in this post.</p>
<p>In this particular post I'm mostly interested in explaining a framework for traversal systems in Haskell, we'll be using many standard <a href="https://hackage.haskell.org/package/mtl"><strong>mtl</strong></a> Monad Transformers alongside a lot of combinators from the <a href="https://hackage.haskell.org/package/lens"><strong>lens</strong></a> library. You won't need to understand any of these intimately to get the <em>gist</em> of what's going on, but I won't be explaining them in depth here, so you may need to look elsewhere if you're lacking a bit of context.</p>
<h2 id="establishing-the-problem">Establishing the Problem</h2>
<p>I'll be demoing a few examples as we go along so let's set up some data. I'll be working in both <strong>jq</strong> and <strong>Haskell</strong> to make comparisons between them, so we'll set up the same data in both <strong>JSON</strong> and Haskell.</p>
<p>Here's a funny lil' company as a JSON object:</p>
<div id="cb1"><pre><code><span id="cb1-1"><a href="#cb1-1"></a><span>{</span></span>
<span id="cb1-2"><a href="#cb1-2"></a>    <span>"staff"</span><span>:</span></span>
<span id="cb1-3"><a href="#cb1-3"></a>      <span>[</span></span>
<span id="cb1-4"><a href="#cb1-4"></a>        <span>{</span> <span>"id"</span><span>:</span> <span>"1"</span></span>
<span id="cb1-5"><a href="#cb1-5"></a>        <span>,</span> <span>"name"</span><span>:</span> <span>"bob"</span></span>
<span id="cb1-6"><a href="#cb1-6"></a>        <span>,</span> <span>"pets"</span><span>:</span> <span>[</span></span>
<span id="cb1-7"><a href="#cb1-7"></a>              <span>{</span> <span>"name"</span><span>:</span> <span>"Rocky"</span></span>
<span id="cb1-8"><a href="#cb1-8"></a>              <span>,</span> <span>"type"</span><span>:</span> <span>"cat"</span></span>
<span id="cb1-9"><a href="#cb1-9"></a>              <span>}</span><span>,</span></span>
<span id="cb1-10"><a href="#cb1-10"></a>              <span>{</span> <span>"name"</span><span>:</span> <span>"Bullwinkle"</span></span>
<span id="cb1-11"><a href="#cb1-11"></a>              <span>,</span> <span>"type"</span><span>:</span> <span>"dog"</span></span>
<span id="cb1-12"><a href="#cb1-12"></a>              <span>}</span></span>
<span id="cb1-13"><a href="#cb1-13"></a>            <span>]</span></span>
<span id="cb1-14"><a href="#cb1-14"></a>        <span>}</span><span>,</span></span>
<span id="cb1-15"><a href="#cb1-15"></a>        <span>{</span> <span>"id"</span><span>:</span> <span>"2"</span></span>
<span id="cb1-16"><a href="#cb1-16"></a>        <span>,</span> <span>"name"</span><span>:</span> <span>"sally"</span></span>
<span id="cb1-17"><a href="#cb1-17"></a>        <span>,</span> <span>"pets"</span><span>:</span> <span>[</span></span>
<span id="cb1-18"><a href="#cb1-18"></a>              <span>{</span> <span>"name"</span><span>:</span> <span>"Inigo"</span></span>
<span id="cb1-19"><a href="#cb1-19"></a>              <span>,</span> <span>"type"</span><span>:</span> <span>"cat"</span></span>
<span id="cb1-20"><a href="#cb1-20"></a>              <span>}</span></span>
<span id="cb1-21"><a href="#cb1-21"></a>            <span>]</span></span>
<span id="cb1-22"><a href="#cb1-22"></a>        <span>}</span></span>
<span id="cb1-23"><a href="#cb1-23"></a>      <span>]</span><span>,</span></span>
<span id="cb1-24"><a href="#cb1-24"></a>    <span>"salaries"</span><span>:</span> <span>{</span></span>
<span id="cb1-25"><a href="#cb1-25"></a>        <span>"1"</span><span>:</span> <span>12</span><span>,</span></span>
<span id="cb1-26"><a href="#cb1-26"></a>        <span>"2"</span><span>:</span> <span>15</span></span>
<span id="cb1-27"><a href="#cb1-27"></a>    <span>}</span></span>
<span id="cb1-28"><a href="#cb1-28"></a><span>}</span></span></code></pre></div>
<p>And here's the same data in its Haskell representation, complete with generated optics for each record field.</p>
<div id="cb2"><pre><code><span id="cb2-1"><a href="#cb2-1"></a><span>data</span> <span>Company</span> <span>=</span> <span>Company</span> {<span> _staff ::</span> [<span>Employee</span>]</span>
<span id="cb2-2"><a href="#cb2-2"></a>                       ,<span> _salaries ::</span> <span>M.Map</span> <span>Int</span> <span>Int</span></span>
<span id="cb2-3"><a href="#cb2-3"></a>                       } <span>deriving</span> <span>Show</span></span>
<span id="cb2-4"><a href="#cb2-4"></a><span>data</span> <span>Pet</span> <span>=</span> <span>Pet</span> {<span> _petName ::</span> <span>String</span></span>
<span id="cb2-5"><a href="#cb2-5"></a>               ,<span> _petType ::</span> <span>String</span></span>
<span id="cb2-6"><a href="#cb2-6"></a>               } <span>deriving</span> <span>Show</span></span>
<span id="cb2-7"><a href="#cb2-7"></a><span>data</span> <span>Employee</span> <span>=</span> <span>Employee</span> {<span> _employeeId ::</span> <span>Int</span></span>
<span id="cb2-8"><a href="#cb2-8"></a>                         ,<span> _employeeName ::</span> <span>String</span></span>
<span id="cb2-9"><a href="#cb2-9"></a>                         ,<span> _employeePets ::</span> [<span>Pet</span>]</span>
<span id="cb2-10"><a href="#cb2-10"></a>                         } <span>deriving</span> <span>Show</span></span>
<span id="cb2-11"><a href="#cb2-11"></a></span>
<span id="cb2-12"><a href="#cb2-12"></a>makeLenses '<span>'Company</span></span>
<span id="cb2-13"><a href="#cb2-13"></a>makeLenses '<span>'Pet</span></span>
<span id="cb2-14"><a href="#cb2-14"></a>makeLenses '<span>'Employee</span></span>
<span id="cb2-15"><a href="#cb2-15"></a></span>
<span id="cb2-16"><a href="#cb2-16"></a><span>company ::</span> <span>Company</span></span>
<span id="cb2-17"><a href="#cb2-17"></a>company <span>=</span> <span>Company</span> [ <span>Employee</span> <span>1</span> <span>"bob"</span> [<span>Pet</span> <span>"Rocky"</span> <span>"cat"</span>, <span>Pet</span> <span>"Bullwinkle"</span> <span>"dog"</span>] </span>
<span id="cb2-18"><a href="#cb2-18"></a>                  , <span>Employee</span> <span>2</span> <span>"sally"</span> [<span>Pet</span> <span>"Inigo"</span> <span>"cat"</span>]</span>
<span id="cb2-19"><a href="#cb2-19"></a>                  ] (M.fromList [ (<span>1</span>, <span>12</span>)</span>
<span id="cb2-20"><a href="#cb2-20"></a>                                , (<span>2</span>, <span>15</span>)</span>
<span id="cb2-21"><a href="#cb2-21"></a>                                ])</span></code></pre></div>
<h2 id="querying">Querying</h2>
<p>Let's dive into a few example queries to test the waters! First an easy one, let's write a query to find all the pets owned by any of our employees.</p>
<p>Here's how it looks in <strong>jq</strong>:</p>
<pre><code>$ cat company.json | jq '.staff[].pets[] | select(.type == "cat")'
{
  "name": "Rocky",
  "type": "cat"
}
{
  "name": "Inigo",
  "type": "cat"
}</code></pre>
<p>We look in the <code>staff</code> key, then <em>enumerate</em> that list, then for each staff member we enumerate their cats! Lastly we filter out anything that's not a cat.</p>
<p>We can recognize a few hallmarks of a <strong>Traversal System</strong> here. <strong>jq</strong> allows us to "dive" down deeper into our structure by providing a path to where we want to be. It also allows us to <strong>enumerate</strong> many possibilities using the <code>[]</code> operator, which will forward <strong>each</strong> value to the rest of the pipeline one after the other. Lastly it allows us to <strong>filter</strong> our results using <code>select</code>.</p>
<p>And in Haskell using optics it looks like this:</p>
<div id="cb4"><pre><code><span id="cb4-1"><a href="#cb4-1"></a><span>&gt;&gt;&gt;</span> toListOf (staff <span>.</span> folded <span>.</span> employeePets <span>.</span> folded <span>.</span> filteredBy (petType <span>.</span> only <span>"cat"</span>)) company</span>
<span id="cb4-2"><a href="#cb4-2"></a>[ <span>Pet</span> {_petName <span>=</span> <span>"Rocky"</span>, _petType <span>=</span> <span>"cat"</span>}</span>
<span id="cb4-3"><a href="#cb4-3"></a>, <span>Pet</span> {_petName <span>=</span> <span>"Inigo"</span>, _petType <span>=</span> <span>"cat"</span>}</span>
<span id="cb4-4"><a href="#cb4-4"></a>]</span></code></pre></div>
<p>Here we use "toListOf" along with an optic which "folds" over each staff member, then folds over each of their pets, again filtering for "only" cats.</p>
<p>At a glance the two are extremely similar!</p>
<p>They each allow the <em>enumeration</em> of multiple values, in <strong>jq</strong> using <code>[]</code> and in optics using <code>folded</code>.</p>
<p>Both implement some form of <strong>filtering</strong>, <strong>jq</strong> using <code>select</code> and our optics with <code>filteredBy</code>.</p>
<p>Great! So far we've had no trouble keeping up! We're already starting to see a lot of similarities between the two, and our solutions using optics are easily generalizable to any data type.</p>
<p>Let's move on to a more complex example.</p>
<h2 id="keeping-references">Keeping references</h2>
<p>This time we're going to print out each pet and their owner!</p>
<p>First, here's the <strong>jq</strong>:</p>
<div id="cb5"><pre><code><span id="cb5-1"><a href="#cb5-1"></a>$ <span>cat</span> join.json <span>|</span> <span>jq</span> <span>'</span></span>
<span id="cb5-2"><a href="#cb5-2"></a><span>    .staff[] </span></span>
<span id="cb5-3"><a href="#cb5-3"></a><span>  | .name as $personName </span></span>
<span id="cb5-4"><a href="#cb5-4"></a><span>  | .pets[] </span></span>
<span id="cb5-5"><a href="#cb5-5"></a><span>  | "\(.name) belongs to \($personName)"</span></span>
<span id="cb5-6"><a href="#cb5-6"></a><span>'</span></span>
<span id="cb5-7"><a href="#cb5-7"></a><span>"Rocky belongs to bob"</span></span>
<span id="cb5-8"><a href="#cb5-8"></a><span>"Bullwinkle belongs to bob"</span></span>
<span id="cb5-9"><a href="#cb5-9"></a><span>"Inigo belongs to sally"</span></span></code></pre></div>
<p>Here we see a new feature in <strong>jq</strong> which is the ability to maintain <strong>references</strong> to a part of the structure for later while we continue to dig deeper into the structure. We're grabbing the name of each employee as we enumerate them and saving it into <code>$personName</code> so we can refer to this later on. Then we enumerate each of the pets and use string interpolation to describe who owns each pet.</p>
<p>If we try to stick with optics on their own, well, it's possible, but unfortunately this is where it all starts to break down, look at this absolute mess:</p>
<div id="cb6"><pre><code><span id="cb6-1"><a href="#cb6-1"></a><span>owners ::</span> [<span>String</span>]</span>
<span id="cb6-2"><a href="#cb6-2"></a>owners <span>=</span> </span>
<span id="cb6-3"><a href="#cb6-3"></a>  company <span>^..</span> </span>
<span id="cb6-4"><a href="#cb6-4"></a>    (staff <span>.</span> folded <span>.</span> reindexed _employeeName selfIndex <span>&lt;.</span> employeePets <span>.</span> folded <span>.</span> petName) </span>
<span id="cb6-5"><a href="#cb6-5"></a>    <span>.</span> withIndex </span>
<span id="cb6-6"><a href="#cb6-6"></a>    <span>.</span> to (\(eName, pName) <span>-&gt;</span> pName <span>&lt;&gt;</span> <span>" belongs to "</span> <span>&lt;&gt;</span> eName)</span>
<span id="cb6-7"><a href="#cb6-7"></a></span>
<span id="cb6-8"><a href="#cb6-8"></a><span>&gt;&gt;&gt;</span> owners</span>
<span id="cb6-9"><a href="#cb6-9"></a>[ <span>"Rocky belongs to bob"</span></span>
<span id="cb6-10"><a href="#cb6-10"></a>, <span>"Bullwinkle belongs to bob"</span></span>
<span id="cb6-11"><a href="#cb6-11"></a>, <span>"Inigo belongs to sally"</span></span>
<span id="cb6-12"><a href="#cb6-12"></a>]</span></code></pre></div>
<p>You can bet that nobody is calling that "easy to read". Heck, I wrote a book on optics and it still took me a few tries to figure out where the brackets needed to go!</p>
<p>Optics are great for handling a <em>single</em> stream of values, but they're much worse at more complex expressions, especially those which require a reference to values that occur <em>earlier</em> in the chain. Let's see how we can address those shortcomings as we build our <strong>Traversal System</strong> in Haskell.</p>
<p>Just for the <strong>jq</strong> aficionados in the audience I'll show off this alternate version which uses a little bit of <em>magic</em> that <strong>jq</strong> does for you.</p>
<div id="cb7"><pre><code><span id="cb7-1"><a href="#cb7-1"></a> $ <span>cat</span> company.json <span>|</span> <span>jq</span> <span>'.staff[] | "\(.pets[].name) belongs to \(.name)"'</span></span>
<span id="cb7-2"><a href="#cb7-2"></a><span>"Rocky belongs to bob"</span></span>
<span id="cb7-3"><a href="#cb7-3"></a><span>"Bullwinkle belongs to bob"</span></span>
<span id="cb7-4"><a href="#cb7-4"></a><span>"Inigo belongs to sally"</span></span></code></pre></div>
<p>Depending on your experience may be less <strong>magical</strong> and more <strong>confusing</strong> 😬. Since the final expression contains an <strong>enumeration</strong> (i.e. <code>\(.pets[].name)</code>) <strong>jq</strong> will expand the final term once for each value in the enumeration. This is really cool, but unfortunately a bit "less principled" and tough to understand in my opinion.</p>
<p>Regardless, the behaviour is the same, and we haven't replicated it in Haskell satisfactorily yet, let's see what we can do about that!</p>
<h2 id="monads-to-the-rescue-again">Monads to the rescue (again...)</h2>
<p>In Haskell we love our <strong>embedded DSLs</strong>; if you give a Haskeller a problem to solve, you can bet that 9 times out of 10 they'll solve it with a custom monad and an DSL 😂. Well, I'm sorry to tell you that I'm no different!</p>
<p>We'll be using a monad to address the readability problem of the last optics solution, but the question is... <em>which</em> monad?</p>
<p>Since all we're doing at the moment is <strong>querying</strong> data, we can make use of the esteemed <strong>Reader Monad</strong> to provide a context for our query.</p>
<p>Here's what that last query looks like when we use the <a href="https://hackage.haskell.org/package/mtl-2.2.2/docs/Control-Monad-Reader.html"><code>Reader</code></a> monad with the relatively …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://chrispenner.ca/posts/traversal-systems">https://chrispenner.ca/posts/traversal-systems</a></em></p>]]>
            </description>
            <link>https://chrispenner.ca/posts/traversal-systems</link>
            <guid isPermaLink="false">hacker-news-small-sites-24710565</guid>
            <pubDate>Wed, 07 Oct 2020 17:29:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Competition and Quarter-Life Crises]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 84 (<a href="https://news.ycombinator.com/item?id=24710496">thread link</a>) | @arvarik
<br/>
October 7, 2020 | https://www.arvarik.com/competition-quarter-life-crisis | <a href="https://web.archive.org/web/*/https://www.arvarik.com/competition-quarter-life-crisis">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Growing up in an Indian household and in one of the most
<a href="https://en.wikipedia.org/wiki/New_Jersey#Demographics">diverse states/towns</a> in the US, it’s not easy to avoid
the competitive stress that derives from first generation families.</p><p>From test scores, which classes I take, SAT scores, college admissions, sports performance, internships received etc.,
the first 22 years of my life have been filled with constant competition with others. As a result I’ve turned out to
be a pretty competitive person - if there was anything that I liked, I not only wanted to be good at it, but I also wanted
to be better at it than others.</p><p>Something happened right around when I graduated college and joined the workforce. My Saturdays were totally free and
weren’t consumed by an all-day track meet where I would compete in the 800m and gruel over two laps trying to edge out
other people over the finish line. After work, my weekday nights consisted of me making dinner instead of living in the
library and taking caffeine pills to study for a test that I’ve been procrastinating to study for. </p><p>For the first time in my life there was no clear next step in what I had to do, and there was no clear competition that
I could engage in with peers. It was a dramatic change and something that I refer to as my quarter life crisis. It’s not
well documented in many places, but it’s a concept that I think is
<a href="https://en.wikipedia.org/wiki/Quarter-life_crisis">picking up steam</a> in recent years.</p><h3>What does a Quarter-Life Crisis look like?</h3><p>I think there’s one song that really encapsulates this feeling, The Beatles’
<a href="https://www.youtube.com/watch?v=8scSwaKbE64">Nowhere Man</a>. The opening lines go:</p><blockquote><p>He's a real nowhere man.
Sitting in his nowhere land.
Making all his nowhere plans for nobody</p></blockquote><p>In fact, the song is what inspired me to name my blog post <strong>Nowhere Plans</strong>. John Lennon was 25 when he wrote this,
and I think he really captures the general feeling of this time in one’s life.</p><p>Back when I was in college and high school I was really competitive with other people, whether in academics or sports,
and I felt I had a strong purpose - anything that I did was to get further in these pursuits. It was a nice and easy
framework to live life by. Decision making was incredibly easy.</p><p>Fast forward to work-life ~&gt; I felt that I couldn’t really relate much to my work peers, and all my college and high
school friends were vibing and doing their own thing in their respective companies. I spent my nights binge watching
shows, my weekends binge watching movies, and my free time working or hanging with peers talking about the binge
watched shows/movies. </p><p>The <a href="https://en.wikipedia.org/wiki/Seattle_Freeze">isolating</a> and incredibly gray city of Seattle didn’t help not
feeling like a nowhere man in nowhere land.</p><p>Maybe I’ll get a cat? Will that help find some purpose to be doing something? I’ll download some dating apps and try to
get a girlfriend, hopefully that should bring me closer to my next stage in life of marriage right? Should I go to grad
school? I have to, no, I need to do these things now! 😬</p><p>I was truly lost in what my next steps in life were going to be, and felt that I was just aimlessly swimming around in a sea of uncertainty.</p><h3>Swimming Out</h3><p>When 2019 had come, I knew I wanted to do something different. I made a list of things that were important to me and that I
wanted to achieve. Visiting friends more, learning to play the piano, getting back into running races, fixing my posture, volunteering etc. </p><p>But the biggest shift in my thinking during this time was to try to bring back competition in my life. No, not competition
with others like I had previously experienced all my life, but instead with something much easier to think about. Myself. </p><p>There’s a saying that you should “Compare yourself to who you were yesterday, not to who someone else is today”. People always
say that you’ll never find happiness comparing yourself to others, and that competitive stress is really bad for you. While that
is true, I also don’t think many people advocate for competition against yourself. It’s possibly because of the stress and
anxiety induced from competition, but if you’re anything like me, it’s necessary to find some purpose and bring back a fire
in you to go about and live life.</p><p>In 2019, I had worked on things I had never done in my life in order to be a better person than who I was in years past.
I’ll probably never be as fit as I was in college on the varsity XC/T&amp;F teams, but hey, in 2019 I
set <a href="https://www.strava.com/athletes/19875553">personal records</a> in
the 10 mile and marathon (granted it was my only time running them but that’s besides the point). </p><p>I also had an entirely different view in perceiving others. Anyone who has spent 5 min on LinkedIn can describe this
feeling - seeing other people who are really successful and do the things that you’ve always want to do is disheartening to
say the least. You feel like somewhere along your life path you made a wrong turn which didn’t lead you to where that other
person is. But, at the end of the day, that’s just life - there’s always going to be someone better than you at everything
you do, you just have to find solace in that you’re better than who you used to be.</p><h3>Where are you now?</h3><p>This past year has been wild. It felt like a decade fit into 9 months so far, but with all the major events and uncertainty
happening, I’ve never felt more certain about myself than I have now.</p><p>I try to focus on things that I really enjoy, and try to be better than my former self. I stopped going to my piano teacher
because of COVID, but still try to play the pieces that I remember learning every now and then while also trying to learn
some more music theory. Writing and deep diving on topics that I find interesting have always been a favorite past-time of
mine, why not start a blog and have others critique me to become better? And finally, if I’m going to make a career out of
my current profession, why not be the best that I can be in more ways than programming. I’ve engaged in more leadership
opportunities to mentor younger engineers and also participate in the daunting interviewing process but this time as an interviewer.</p><p>Through this process I’ve grown to know that I really enjoy helping and teaching others - it’s something that has helped me
envision what I want to be doing as I grow.</p><p>I don’t advise many people to live life with this much analysis on your past self, but if this story resonated with you I
encourage to try it out! It’s helped me get out of a quarter life crisis and will hopefully keep me going until my
inevitable mid-life crisis. Stay tuned for that post.</p></section></div>]]>
            </description>
            <link>https://www.arvarik.com/competition-quarter-life-crisis</link>
            <guid isPermaLink="false">hacker-news-small-sites-24710496</guid>
            <pubDate>Wed, 07 Oct 2020 17:22:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust and Raspberry Pi Tide Clock]]>
            </title>
            <description>
<![CDATA[
Score 94 | Comments 13 (<a href="https://news.ycombinator.com/item?id=24708345">thread link</a>) | @zdw
<br/>
October 7, 2020 | https://thefuntastic.com/blog/rust-tide-clock | <a href="https://web.archive.org/web/*/https://thefuntastic.com/blog/rust-tide-clock">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-10b1bd0a="" data-v-6f4ff34b=""><p><em>In this part 1 of 2 posts, I share the process of a heartwarming maker project built on top of Raspberry Pi and Rust. It's more a story than a how-to guide, but provides an interesting chronology of problems encountered. In part 2 I'll be getting technical and discussing Rust in-depth. Source code for this project can be found on <a href="https://github.com/thefuntastic/rust-tide-clock" target="_blank" rel="nofollow noopener noreferrer">Github</a></em></p>
<p>I had the good fortune to spend my summer with Alice's family who had recently moved to a seaside town. Tim, the patriarch of the family, was distraught to learn that, out of his impressive array of nautical implements, his tide clock readings were never accurate. This is the story of how we built him a surprise 60th birthday present he'd never forget: </p>
<p><img src="https://thefuntastic.com/blog/2020-09-25-Tide-Clock-12.jpg" title="Picture completed Tide-Clock"></p>
<h2 id="the-problem-with-tides">The Problem with Tides</h2>
<p>Most people understand the moons gravitational pull causes a regular ebb and flow in water levels. Those concerned with the sea will likely recite 6 hours and 10-ish minutes as the duration between low and high tide. Consider a wristwatch or wall clock, most mechanical timepieces already track a daily period of 12 hours. With a small adjustment to gearing ratios, it would be easy enough to build a clock that reports instead the tidal cycle of 12 hours and 25 minutes. Indeed this is how most ornamental tide clocks work. </p>
<p><img src="https://thefuntastic.com/blog/2020-09-Wikipedia-Tide-clock.jpg" title="Picture of tide clock - Wikipedia"></p>
<p>I was surprised, however, to learn <a href="http://www.coastalwiki.org/wiki/Tidal_asymmetry_and_tidal_basin_morphodynamics" target="_blank" rel="nofollow noopener noreferrer">tides can be asymmetric</a>! Instead of six hours, it might take the tide seven hours to come in and five hours to go out again. Local environmental factors like the shallowness of an estuary basin can have a pronounced effect on tidal regularity. In extreme places, like the Gulf of Mexico, this can be enough to reduce the regular cycle from four tides a day to just two. </p>
<p><img src="https://thefuntastic.com/blog/2020-09-25-Tide-Graph.png" title="WorldTides.info graph of tide station in the Gulf of Mexico showing asymmetry changing to produce single daily tide"></p>
<p>A disaster for the clockmaker! This asymmetry also changes with the lunar cycle, so it's not even possible for a mechanical clock to be consistently wrong. It makes intuitive sense if you think about it. Water is "stuff". When the tide changes that stuff has to go somewhere. If something makes it hard for stuff to move about, like say sandbars in a shallow basin, it's going to make the stuff pile up. The bigger the change in stuff, like say near spring tide, the more piling up is going to happen. If that stuff is still hanging about when the tide changes, the net effect is going to be an asymmetric tide.</p>
<h2 id="making-with-embedded-devices">Making with Embedded Devices</h2>
<p>To my mind, this was the perfect application for an internet-of-things powered device. By outsourcing the problem and fetching data from an API it meant the source of truth would always be accurate. Furthermore, a digital display could accurately visualise the asymmetric ebbs and floods.</p>
<h3 id="on-choosing-raspberry-pi">On choosing Raspberry Pi</h3>
<p>Initially, I considered using an Arduino, as I already had one knocking about my toolbox, together with a compatible LED screen. Ultimately I chose the path of least resistance because the Raspberry Pi comes with an integrated WiFi chip. Unlike the Arduino, the Pi is a mini-computer running an entire operating system. This is the sledgehammer approach, but has advantages considering the project would eventually live in the hands of someone unfamiliar with embedded tech. If the WiFi connection were to drop or need changing, logging onto a desktop would be a much friendlier experience. </p>
<p><img src="https://thefuntastic.com/blog/2020-09-Tide-Clock-21.jpg" title="Raspbian Desktop Interface running on Raspberry Pi"></p>
<p>Having settled on a Raspberry Pi build, the next job was to find a suitable display. Considering tides change relatively slowly, it was tempting to use an e-ink display for crazy power efficiency. That might be necessary if the clock was battery-powered, however, the need to keep the Pi running meant we were already committed to a plug-in power supply. In the end, I choose the 128x32 pixel <a href="https://thepihut.com/collections/waveshare/products/128x32-2-23inch-oled-display-hat-for-raspberry-pi" target="_blank" rel="nofollow noopener noreferrer">Waveshare 1305</a>. Its convenient "hat" form factor meant no soldering. Also, OLED looks crazy good compared to the standard LED screen I already had. </p>
<p><img src="https://thefuntastic.com/blog/2020-09-Tide-Clock-3.jpg" title="Waveshare OLED screen shown attached to Raspberry Pi"></p>
<h3 id="on-choosing-rust">On Choosing Rust</h3>
<p>At this point, I was still unsure of which programming language to use. Whilst the Raspberry Pi can run anything that compiles to Linux, communication to the screen happens through the Pi's <code>GPIO</code> pins (<a href="https://en.wikipedia.org/wiki/General-purpose_input/output" target="_blank" rel="nofollow noopener noreferrer">General Purpose Input/Output</a>). All information is transmitted by setting pins high and low and feels reminiscent of working on Arduino and other embedded platforms. Even though the screen is just 128x32 (aka 4096) pixels, that's far more destinations than the Pi's 40 <code>GPIO</code> pins can individually address. Fortunately protocols, in this case <code>SPI</code>, exist to pack data into compressed blocks which can be sent over the limited bandwidth of the IO pins. </p>
<p><img src="https://thefuntastic.com/blog/2020-09-Tide-Clock-31.jpg" title="Raspberry Pi 3 GPIO Pins"></p>
<p>The screen manufacturer-provided <a href="https://www.waveshare.com/wiki/2.23inch_OLED_HAT#Demo_codes" target="_blank" rel="nofollow noopener noreferrer">3 code samples</a>: 1 written in python and 2 written in C. Python was my immediate choice, given the online nature of the project, however, I simply couldn't get it to work. The two C samples were curious. One was built on top of a bring-your-own driver for the embedded Broadcom chip that controls <code>GPIO</code> pins. The other was written on top of <a href="https://github.com/WiringPi/WiringPi" target="_blank" rel="nofollow noopener noreferrer"><code>wiringPi</code></a>, which ships with Raspbian (aka the Pi flavoured Linux OS) and seems to be the blessed path for doing IO. However, I was saddened to learn this open source project was largely the efforts of a single person who has since <a href="http://wiringpi.com/wiringpi-deprecated/" target="_blank" rel="nofollow noopener noreferrer">stepped down as a maintainer</a> due to open source burnout. It's a worrying trend I'm seeing a lot lately. </p>
<p><img src="https://thefuntastic.com/blog/2020-09-Tide-Clock-4.jpg" title="Waveshare OLED screen showing Hello World"></p>
<p>Despite the above, the current <code>wiringPi</code> sample still works well. In theory I'm sure it would have been absolutely possible to complete the rest of the project in C. As a language though, C tends to come batteries-not-included. The prospect of stumbling my way through image processing, data parsing, fetching URLs and date-time munging did not fill me with joy, especially given my rudimentary C experience. I'd much rather be building sand-castles in a play pit that didn't require me to build my shovel first.  </p>
<p>I've been "Rust-curious" for a long time, and it's done a great job of establishing itself as <strong>an alternative for workloads where C was historically the only viable candidate </strong>(high performance or memory-constrained). That it does so without forsaking a first-class developer experience is one of the many reasons it's become such <a href="https://insights.stackoverflow.com/survey/2020#technology-most-loved-dreaded-and-wanted-languages" target="_blank" rel="nofollow noopener noreferrer">a beloved language</a>. Through the package manager, <code>cargo</code>, I'd have a thriving ecosystem of 3rd party libraries (aka crates) within arms reach. Indeed, I quickly found <code>rppal</code> (<a href="https://github.com/golemparts/rppal" target="_blank" rel="nofollow noopener noreferrer">Raspberry Pi Peripheral Access Layer</a>), a Rust crate to manage <code>GPIO</code>.</p>
<pre>

<span>[</span><span>dependencies</span><span>]</span>
<span>image</span> <span>=</span> <span>"0.23.8"</span>
<span>chrono</span> <span>=</span> <span>"0.4"</span>
<span>serde</span> <span>=</span> <span>{</span> <span>version</span> <span>=</span> <span>"1.0"</span><span>,</span> <span>features</span> <span>=</span> <span>[</span><span>"derive"</span><span>]</span> <span>}</span>
<span>serde_json</span> <span>=</span> <span>"1.0"</span>
<span>toml</span> <span>=</span> <span>"0.5"</span>
<span>ordered-float</span> <span>=</span> <span>"2.0"</span>
<span>reqwest</span> <span>=</span> <span>{</span> <span>version</span> <span>=</span> <span>"0.10"</span><span>,</span> <span>features</span> <span>=</span> <span>[</span><span>"json"</span><span>]</span> <span>}</span>
<span>tokio</span> <span>=</span> <span>{</span> <span>version</span> <span>=</span> <span>"0.2"</span><span>,</span> <span>features</span> <span>=</span> <span>[</span><span>"full"</span><span>]</span> <span>}</span>
<span>simple-error</span> <span>=</span> <span>"0.1.9"</span>

<span>[</span><span>target.'cfg(target_arch="arm")'.dependencies</span><span>]</span>
<span>rppal</span> <span>=</span> <span>"0.9.0"</span></pre>
<p>There were also plenty of reasons <strong>not</strong> to choose Rust. Scant few weeks remained until the birthday party; if we were going to pull off the surprise it meant sticking to a very aggressive timeline. <code>rppal</code> is not a port of <code>wiringPi</code>, the <code>SPI</code> protocol implementation details might differ in subtle but fundamental ways, enough to bork the entire endeavour. Rust's borrow checker is infamously unforgiving to the uninitiated (it's a bit of an arsehole really). If I was being a responsible lead I'd probably command the troops to trudge on with C. But hack projects really should be about personal edification. So sod it, how hard could it be? </p>
<h2 id="programming-the-app">Programming the App</h2>
<p>Lets just say I got a beating, the likes of which demand a doughnut-shaped cushion afterwards. Rust's learning curve is notoriously steep, and hoping to grok it on such a tight schedule was perhaps optimistic. To Rust's credit, there are plenty of escape hatches to get yourself out of (or into) trouble. This is useful when writing your own code, but by consuming 3rd party libraries you're expected to be more fluent with "idiomatic Rust". </p>
<p><em>(Stay tuned for part 2 where I'll discuss my technical first impressions of Rust)</em>.</p>
<p>Idiomatic understanding is difficult to rush, as it requires a breadth of exposure. I'd fare better now, but as my first-touch point I simply couldn't figure out how I was meant to consume the <code>rppal</code> library. Combing the changelog revealed a big refactor towards a <strong>more</strong> idiomatic and Rust-like API. By reverting to an earlier <strong>less</strong> idiomatic version I'd found a cheeky get out of jail card. Breakthrough, at last, a single pixel signalled business time. </p>
<p><img src="https://thefuntastic.com/blog/2020-09-Tide-Clock-5.jpg" alt="The happiest pixel" title="Displaying single pixel"></p>
<h3 id="interface-and-ui">Interface and UI</h3>
<p>Now that drawing was possible, the next question was a matter of <em>what</em> to draw? In answer, I cracked open a pixel editor and performed a design sprint in miniature. Several iterations later I had a single image that served as my "design document". </p>
<p><img src="https://thefuntastic.com/blog/2020-09-Tide-Clock-6.jpg" title="Designing in the pixel editor"></p>
<p>That's a great example of why this project was so much fun. The problem space left room to flex muscles in every layer of abstraction, whilst being constrained enough to avoid becoming an onerous chore. Font rendering is another example. By using the old school technique of copying slices from a sprite sheet I didn't have to bother myself with font files or font rendering libraries.   </p>
<p><img src="https://thefuntastic.com/blog/2020-09-Tide-Clock-7.jpg" title="Designing the font. First on paper, then on screen"></p>
<p>To help me copy slices I relied on the <code>image</code> crate. Again there was a high degree of fumbling to get my head around the API, but once I did I was very impressed by the quality of the library. Even if the ecosystem is still technically maturing, the quality already on display announces Rust's arrival as a serious contender. </p>
<pre>

 
<span>pub</span> <span>fn</span> <span>new</span><span>(</span><span>)</span> <span>-&gt;</span> <span>Font5</span> <span>{</span>
    <span>let</span> p <span>=</span> <span>Path</span><span>::</span><span>new</span><span>(</span><span>"resources/Font-5px.png"</span><span>)</span><span>;</span>

    <span>let</span> img <span>=</span> <span>image<span>::</span></span><span>open</span><span>(</span>p<span>)</span><span>.</span><span>unwrap</span><span>(</span><span>)</span><span>.</span><span>to_rgb</span><span>(</span><span>)</span><span>;</span>

    <span>let</span> <span>mut</span> faces <span>=</span> <span>HashMap</span><span>::</span><span>new</span><span>(</span><span>)</span><span>;</span>

    faces<span>.</span><span>insert</span><span>(</span><span>'1'</span><span>,</span> img<span>.</span><span>view</span><span>(</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>1</span><span>,</span> <span>5</span><span>)</span><span>.</span><span>to_image</span><span>(</span><span>)</span><span>)</span><span>;</span>
    faces<span>.</span><span>insert</span><span>(</span><span>'2'</span><span>,</span> img<span>.</span><span>view</span><span>(</span><span>2</span><span>,</span> <span>0</span><span>,</span> <span>3</span><span>,</span> <span>5</span><span>)</span><span>.</span><span>to_image</span><span>(</span><span>)</span><span>)</span><span>;</span>
    faces<span>.</span><span>insert</span><span>(</span><span>'3'</span><span>,</span> img<span>.</span><span>view</span><span>(</span><span>6</span><span>,</span> <span>0</span><span>,</span> <span>3</span><span>,</span> <span>5</span><span>)</span><span>.</span><span>to_image</span><span>(</span><span>)</span><span>)</span><span>;</span>
    <span>...</span>
    faces<span>.</span><span>insert</span><span>(</span><span>'X'</span><span>,</span> img<span>.</span><span>view</span><span>(</span><span>95</span><span>,</span> <span>6</span><span>,</span> <span>3</span><span>,</span> <span>5</span><span>)</span><span>.</span><span>to_image</span><span>(</span><span>)</span><span>)</span><span>;</span>
    faces<span>.</span><span>insert</span><span>(</span><span>'Y'</span><span>,</span> img<span>.</span><span>view</span><span>(</span><span>99</span><span>,</span> <span>6</span><span>,</span> <span>3</span><span>,</span> <span>5</span><span>)</span><span>.</span><span>to_image</span><span>(</span><span>)</span><span>)</span><span>;</span>
    faces<span>.</span><span>insert</span><span>(</span><span>'Z'</span><span>,</span> img<span>.</span><span>view</span><span>(</span><span>103</span><span>,</span> <span>6</span><span>,</span> <span>3</span><span>,</span> <span>5</span><span>)</span><span>.</span><span>to_image</span><span>(</span><span>)</span><span>)</span><span>;</span>

    <span>Font5</span> <span>{</span> faces <span>}</span>
<span>}</span></pre>
<p>Up till now, I had been doing all the development directly on a Raspberry Pi 3. It worked well enough, but I was sorely missing the quality of life features I could enjoy in a full developer environment. The <code>image</code> crate was convenient enough that I started using it for other …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thefuntastic.com/blog/rust-tide-clock">https://thefuntastic.com/blog/rust-tide-clock</a></em></p>]]>
            </description>
            <link>https://thefuntastic.com/blog/rust-tide-clock</link>
            <guid isPermaLink="false">hacker-news-small-sites-24708345</guid>
            <pubDate>Wed, 07 Oct 2020 14:06:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Complete AWS Lambda Handbook for Beginners]]>
            </title>
            <description>
<![CDATA[
Score 127 | Comments 34 (<a href="https://news.ycombinator.com/item?id=24708237">thread link</a>) | @maridashbird
<br/>
October 7, 2020 | https://dashbird.io/blog/complete-aws-lambda-handbook-beginners-part-1/ | <a href="https://web.archive.org/web/*/https://dashbird.io/blog/complete-aws-lambda-handbook-beginners-part-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div><p>Welcome to the Serverless world. One of the first things you’ll hear about is AWS Lambda - and you’ll continue to keep hearing about it! While architecture can be serverless without Lambdas involved, it’s very often the key component within a serverless application. In the first post of this 3-part AWS Lambda Handbook series, we run through what is AWS Lambda, dialling back to basics with the various terminology, how to create a Lambda function and how to run it.&nbsp;</p>
<blockquote>
<p>Read <a href="https://dashbird.io/blog/complete-aws-lambda-handbook-beginners-part-2/">Part 2</a> and <a href="https://dashbird.io/blog/complete-aws-lambda-handbook-beginners-part-3/">Part 3</a></p>
</blockquote>
<h2 id="what-is-aws-lambda-and-what-does-it-do">What is AWS Lambda, and what does it do?</h2>
<p>AWS Lambda is an event-driven serverless compute platform, spinning up the service in response to an event - find out more about Lambda triggers in <a href="https://dashbird.io/blog/complete-guide-lambda-triggers-design-patterns-part-1/">part 1</a> and <a href="https://dashbird.io/blog/complete-guide-lambda-triggers-design-patterns-part-2/">part 2</a> of our Complete Guide to Lambda Triggers series. Your code simply sits there as a file while AWS keeps a lookout for the trigger event you’ve set. When that event occurs, your code is executed and the required operations are carried out. It’s deemed ‘serverless’ because the server doesn’t exist until the user goes out to look for it - this is the epitome of <a href="https://dashbird.io/blog/what-is-faas-function-as-a-service/">Function-as-a-Service (FaaS)</a>.</p>
<p>Another bonus to Lambda is it’s auto-scalability managed by AWS, meaning you don’t need to think about infrastructure. The service will automatically accommodate growing needs and likewise, will scale down to conserve resources. All of this makes AWS Lambda a great solution to reduce waste of resources and budget.&nbsp;</p>
<h2 id="aws-lambda-definitions-explained">AWS Lambda Definitions Explained</h2>
<p>Before getting into how to set up and configure Lambda, below are definitions and terminology commonly used and spoken about.</p>
<p>Lambda Function: a group of related statements that perform a specific task in your application. It consists of code and any dependencies that are associated with it. Each Lambda function has its associated configuration information (name, description, entry point, and resource requirements).</p>
<p>The function itself has the following important aspects associated with it:</p>
<ol>
<li>
<p>Trigger: A set of activities which invokes the function (runs the code you provide). The activity could be anything like a new object coming to your S3 bucket, a website or a service going down, an API call, etc.</p>
</li>
<li>
<p>The actual function: This is the run-time code that constitutes the function. AWS supports Python, Node.js, C#, Go and Java8 as runtime environments.&nbsp;</p>
</li>
<li>
<p>Resources: Each function can be assigned certain Roles, which grants the function certain privileges such as reading S3 bucket contents, writing results to a database and so on.</p>
</li>
</ol>
<p><img src="https://dashbird.io/images/blog/2020-05-vacation-buffer/1aws-lambda-api-gateway-trigger.png" alt="AWS Lambda anatomy" title="AWS Lambda anatomy"></p>
<p>The triggers are shown to the left, and in this case an API gateway trigger is active. The resources are shown on the right, which in this case, are CloudWatch Logs and DynamoDB.</p>
<p>Event Sources: an entity that publishes events. An event source can be an AWS service or developer-created application that produces events that trigger a function to run.</p>
<p>Invocation: an invocation is called up to execute a specific Lambda function. These are triggers for the code of the function to start running. Invocations can be either <a href="https://docs.aws.amazon.com/lambda/latest/dg/invocation-options.html">synchronous or asynchronous</a>.</p>
<p>Event Source Mapping: a configuration of AWS services in which an event source is tied to a specific Lambda function. It enables automatic invocation of a Lambda function when specific events occur.</p>
<p>Lambda Execution Model: When you create a Lambda function, you can specify configuration information, such as the amount of memory and maximum execution time that you allow for your function. When that function is invoked, AWS Lambda launches an <a href="https://docs.aws.amazon.com/lambda/latest/dg/running-lambda-code.html">Execution Context</a> based on the configuration settings you have provided.</p>
<p>Cold Starts: A cold start happens when a Lambda function is invoked after not being used for an extended period of time, which results in increased invocation latency (more on this later).</p>
<h2 id="aws-lambda-configuration-elements">AWS Lambda Configuration Elements</h2>
<p>A Lambda function consists of the code and associated dependencies, and it also has configuration information within it. An API is also provided so you can update some of the configuration data. Lambda function configuration information comes with these critical elements:</p>
<ul>
<li>
<p>Calculating the required resources: specifying the amount of memory that you wish to allocate for your Lambda function. AWS Lambda allocates CPU power in proportion to the memory by the same ratio as a general-purpose AWS EC2 instance type, like an M3 type.&nbsp;</p>
</li>
<li>
<p>Maximum execution time (timeout): specified to prevent the Lambda function from running non-stop. Since you’re paying for the AWS resources that are used to run your Lambda function, this is particularly important. Upon reaching the timeout, AWS Lambda is terminating the execution of your Lambda function. The recommended setting is valued upon the expected execution time.</p>
</li>
<li>
<p>IAM role (execution role): the role that AWS Lambda performs on your behalf when executing a Lambda function.</p>
</li>
<li>
<p>Handler name: the method of entry point that runs your code with any event source dependencies included as a part of your Lambda function. You will be able to discover more details, and the quality features of monitoring and debugging AWS Lambda using this.&nbsp;</p>
</li>
</ul>
<h2 id="creating-a-simple-aws-lambda-function">Creating a Simple AWS Lambda Function</h2>
<p>Let’s create a simple Lambda function that is invoked by an API call, i.e. we generate a URL, which when entered in the browser would invoke the function. Our input would be passed into the function via this URL and the output would be returned and shown in the browser.</p>
<p>Step 1: Creating the function</p>
<p>In the Lambda console panel, click on create function. Give your function a name, in our case, it is DemoFunction. Also select the runtime as Python3, as we will be using that particular language for this example. Lastly, give your function’s role a name and, from Policy Templates, select Simple Microservice permissions.</p>
<p><img src="https://dashbird.io/images/blog/2020-05-vacation-buffer/2creating-new-aws-serverless-function.png" alt="AWS Lambda Author From Scratch" title="AWS Lambda Author From Scratch"></p>
<p>Click on Create Function and you will be taken to the next screen where you can provide the actual code. We are authoring this API from scratch, but there are tons of templates from Amazon repository that you can explore.</p>
<p>The next page will have an inline text editor with a simple python function in there. Replace that with the following content:</p>
<pre><code>import json

print('Loading function')

def lambda_handler(event, context):

&nbsp;&nbsp;&nbsp;&nbsp;firstName = event['first']

&nbsp;&nbsp;&nbsp;&nbsp;lastName = event['last']

&nbsp;&nbsp;&nbsp;&nbsp;return 'Greetings, ' + firstName + ' ' + lastName +'!' 
</code></pre><p>The first line is for parsing the JSON using the JSON library in Python. The lambda_handler function gets the event as one of its parameters; this event brings along a set of data. The first and second line inside the function extracts whatever data is labeled first and second, and stores them into the respective variables.</p>
<p>The last line returns a message back and that’s what we will see in our browser.</p>
<p><img src="https://dashbird.io/images/blog/2020-05-vacation-buffer/3creating-new-aws-serverless-function.png" alt="Creating AWS Lambda function" title="Creating AWS Lambda function"></p>
<p>We can add an API Gateway trigger right here, but for the sake of clarity, let’s do it separately. For now, we can click Save and move into the testing phase.</p>
<p>Step 2: Testing your function</p>
<p>To test your function, just click on the top right corner where it says ‘TestEvent’, then click on Configure Test Event.</p>
<p><img src="https://dashbird.io/images/blog/2020-05-vacation-buffer/4creating-new-aws-serverless-function.png" alt="Testing AWS Lambda function" title="Testing AWS Lambda function"></p>
<p>Here we will have our first encounter with a JSON payload. In the template TestEvent.</p>
<p><img src="https://dashbird.io/images/blog/2020-05-vacation-buffer/5test-new-aws-serverless-function.png" alt="Testing AWS Lambda JSON function" title="Testing AWS Lambda JSON function"></p>
<p>Replace the file’s content with the following lines:</p>
<pre><code>{

&nbsp;&nbsp;"first": "Jane",

&nbsp;&nbsp;"last": "Doe"

}
</code></pre><p>Now that we have saved the test event. Click on Test in the previous menu. Upon successful execution you should see:</p>
<p><img src="https://dashbird.io/images/blog/2020-05-vacation-buffer/6creating-new-aws-serverless-function.png" alt="AWS Lambda function output" title="AWS Lambda function output"></p>
<p>Step 3: Setting up a Trigger</p>
<p>As mentioned before, our user would <a href="https://dashbird.io/blog/what-are-aws-lambda-triggers/">invoke the function</a> by accessing a certain URL. To enable that go to the API Gateway Console under your AWS Services and click on Get Started or New API option.</p>
<p>Let’s create one from scratch:</p>
<p><img src="https://dashbird.io/images/blog/2020-05-vacation-buffer/7creating-new-aws-serverless-function.png" alt="AWS Lambda API creation" title="AWS Lambda API creation"></p>
<p>Our API is named dashbird-api. After clicking on Create API. You will get the resources that the API has access to (listed in the next menu):</p>
<p><img src="https://dashbird.io/images/blog/2020-05-vacation-buffer/8creating-new-aws-serverless-function.png" alt="AWS Lambda API resources" title="AWS Lambda API resources"></p>
<p>Since there are no resources, we just get a forward-slash. But you can create a new resource by using the Actions drop-down and picking Create Resource.</p>
<p><img src="https://dashbird.io/images/blog/2020-05-vacation-buffer/9creating-new-aws-serverless-function.png" alt="AWS Lambda child resources" title="AWS Lambda child resources">
In the resource list, you can select this new resource (named greetings), click on actions and select Create Method. Our HTTP request method is going to be a GET request since our aim is to get an appropriate response from invoking the function.</p>
<p><img src="https://dashbird.io/images/blog/2020-05-vacation-buffer/91creating-new-aws-serverless-function.png" alt="AWS Lambda GET request" title="AWS Lambda GET request"></p>
<p>The method will have a Lambda integration option, select that and then enter the function name chosen by you earlier Step 2. Also, from Step 2’s screenshot, make note of the function’s <a href="https://dashbird.io/knowledge-base/aws-cloud/arn-amazon-resource-names/">ARN</a> (top-right corner), it has the string eu-central-1 indicating the region it is in. Make sure that the same region is selected for the Lambda region also, as shown above. It would then ask permission for invoking the function; grant that and now we are ready for the final modification.</p>
<p>The GET method execution is explained in this diagram:</p>
<p><img src="https://dashbird.io/images/blog/2020-05-vacation-buffer/92-GET-method-execution-aws-serverless.png" alt="AWS Lambda modify method" title="AWS Lambda modify method">
We still need to make sure that the input parameters are passed on correctly. For that we need to modify the Integration Request stage from above. You can click on it to make modifications:</p>
<p><img src="https://dashbird.io/images/blog/2020-05-vacation-buffer/93-GET-method-execution-aws-serverless.png" alt="AWS Lambda body mapping" title="AWS Lambda body mapping"></p>
<p>Leave everything as it is, except at the very bottom of the menu where you will find the Body Mapping Template here we get to describe our input template.The template is going to be of type application/json :</p>
<pre><code data-lang="{">
&nbsp;&nbsp;&nbsp;&nbsp;"first": "$input.params('first')",

&nbsp;&nbsp;&nbsp;&nbsp;"last": "$input.params('last')"

}
</code></pre><p>The dollar sign and the input.params() part act as a placeholder and helps us define the structure of a proper request. Now we can save our changes, and click on Actions and select Deploy API option. It will ask for a stage name; give it a suitable name (in our case it is called prod). All is set! We can now run this function in real-time.</p>
<h2 id="running-the-function">Running the Function&nbsp;</h2>
<p>The function can be invoked using a unique URL associated with it. In the API console, where we first selected Resources, select Stage submenu instead. Then drop down to greetings and then to the GET option.</p>
<p><img src="https://dashbird.io/images/blog/2020-05-vacation-buffer/94-GET-method-execution-aws-serverless.png" alt="AWS Lambda invoke URL" title="AWS Lambda invoke URL"></p>
<p>It will give you an invoke URL, which you can click on for the function to run. However, on the first try you might get an error message if you didn’t give any input. You can rectify this by modifying the URL like this:</p>
<p><a href="https://.........amazonaws.com/prod/greetings?first=John&amp;last=Doe">https://.........amazonaws.com/prod/greetings?first=John&amp;last=Doe</a></p>
<p>Adding …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dashbird.io/blog/complete-aws-lambda-handbook-beginners-part-1/">https://dashbird.io/blog/complete-aws-lambda-handbook-beginners-part-1/</a></em></p>]]>
            </description>
            <link>https://dashbird.io/blog/complete-aws-lambda-handbook-beginners-part-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24708237</guid>
            <pubDate>Wed, 07 Oct 2020 13:57:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lessons learned from onboarding emails with no HTML styling]]>
            </title>
            <description>
<![CDATA[
Score 165 | Comments 166 (<a href="https://news.ycombinator.com/item?id=24707994">thread link</a>) | @pau_alcala
<br/>
October 7, 2020 | https://blog.palabra.io/great-onboarding-plain-text | <a href="https://web.archive.org/web/*/https://blog.palabra.io/great-onboarding-plain-text">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><em>By <a href="https://www.linkedin.com/in/naara-abril-taker/">Abril Taker</a> - Content Creator at <a href="https://www.palabra.io/?utm_medium=best-onboarding&amp;utm_source=blog">Palabra</a></em></p><p>Great onboarding emails don't need to have impressive design. They should provide a clear path for new users to follow to get as much value from your product and as quickly as possible. While creating <a href="https://www.palabra.io/?utm_medium=best-onboarding&amp;utm_source=blog">Palabra's</a> onboarding, we went through our favorite plain text emails. Here's what we learned.</p><h2>Plain text is the way to go 🚀</h2><p>Writing HTML emails takes a lot of time, even with image based builders. As an early stage company, we simply didn't have enough time to design and mark our emails.</p><p>We also have <a href="https://blog.palabra.io/plain-text-engagement">a lot of reasons to go with plain text</a> instead of image-based. It helps deliverability, accesibility and looks much more real and important than ad-looking emails.</p><p>That's why we decided to go with plain text emails all the way. We explored different email sequences that used plain text (or simple styling) to understand what they did best. And where better to start than our very own inbox?</p><p>We noticed a few of the onboarding email sequences we got were really helpful for us as users. They kept simple a simple design and used mostly text to share their best features. </p><p>And we found some awesome examples of onboarding sequences that use little to no HTML styling:</p><ul><li>Notion's awesome and personal onboarding (simple styling).</li><li>Superhuman's daily bits of information on its greatest features (only text and images).</li><li><a href="http://zest.is/">Zest.is</a> drips using only plain text and images or gifs (our personal favorite).</li></ul><p>Here's what we discovered.</p><h2>Welcome emails are more than a confirmation</h2><p>Every SaaS company must start their onboarding sequences with a welcome message that is sent when a user joins the platform. This is a must by now, since everyone who signs up will expect some sort of confirmation of their transaction.</p><p>I mean, it is essentially a welcome message, but it can be so much more.</p><p><span>
      <span></span>
  <img alt="Image" title="Image" src="https://blog.palabra.io/static/7cbe707b1b06d73390376c23df182939/f0157/01.png" srcset="https://blog.palabra.io/static/7cbe707b1b06d73390376c23df182939/5243c/01.png 240w,https://blog.palabra.io/static/7cbe707b1b06d73390376c23df182939/ab158/01.png 480w,https://blog.palabra.io/static/7cbe707b1b06d73390376c23df182939/f0157/01.png 809w" sizes="(max-width: 809px) 100vw, 809px" loading="lazy">
    </span></p><p>For example, SuperHuman sends you a warm welcome message that immediately teaches you how to use their Command.</p><p>Another excellent example of welcome email is from Zest:</p><p><span>
      <span></span>
  <img alt="Image" title="Image" src="https://blog.palabra.io/static/484d998ef2ecfebe45feeffb359a512e/7d769/02.png" srcset="https://blog.palabra.io/static/484d998ef2ecfebe45feeffb359a512e/5243c/02.png 240w,https://blog.palabra.io/static/484d998ef2ecfebe45feeffb359a512e/ab158/02.png 480w,https://blog.palabra.io/static/484d998ef2ecfebe45feeffb359a512e/7d769/02.png 960w,https://blog.palabra.io/static/484d998ef2ecfebe45feeffb359a512e/b1884/02.png 994w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
    </span></p><p>We love these simple but catchy lines. They nail the exact effect that plain text should achieve: make you feel among friends.</p><p>Both Superhuman and Zest suggest a next step you should follow after receiving that first email. This gives a clear path for people to follow if they want to get value from their products. And that's the best thing you can do with a welcome message.</p><h2>A name and a face</h2><p>This is a great tip to increase engagement. I always feel awkward when I don’t know who is writing on the other side. Is it the CEO? Someone from Sales? Is it a super intelligent baby? Who knows.</p><p><span>
      <span></span>
  <img alt="Image" title="Image" src="https://blog.palabra.io/static/e6bb721d1b9ff6f37091aedd39fcc4d5/0248a/03.png" srcset="https://blog.palabra.io/static/e6bb721d1b9ff6f37091aedd39fcc4d5/5243c/03.png 240w,https://blog.palabra.io/static/e6bb721d1b9ff6f37091aedd39fcc4d5/ab158/03.png 480w,https://blog.palabra.io/static/e6bb721d1b9ff6f37091aedd39fcc4d5/0248a/03.png 658w" sizes="(max-width: 658px) 100vw, 658px" loading="lazy">
    </span></p><p>We can see this information clearly in Notion’s emails. Ivan is not only a name, he is Notion’s Co-founder. It’s flattering to receive a direct message from a co-founder, it also gives the impression of commitment from the very roots of the company. </p><p>At <a href="https://www.palabra.io/?utm_medium=best-onboarding&amp;utm_source=blog">Palabra</a> we do the very same thing. Our emails are sent by Paula or Karen, who are the founders (and the heart) of this project. </p><p>A photo is not a requirement in itself, yet, the clearer the image we have of the person who sends and receives the emails, the more engagement we can generate.</p><p>Even if you have hundreds of people working in your business, you can create an identity to address your users.</p><h2>Emojis in the subject (use with caution)</h2><p>This point is more to talk about email subjects, a very important topic that sometimes is forgotten.</p><p>If every email is a gift to your users, the subject is the wrapping paper. You want it to be shining, flashy, stunning so the reader has no other option than to open the email.</p><p>Definitely, most of the plain text onboarding sequences than we observed have emojis (at some stage) in their subjects. </p><p>Remember: emojis are important, but they have to reinforce the idea of the text in the subject. Otherwise you’re gonna look cu-cu or, even worse, desperate.</p><p>Zest win the contest of better subjects seding thing like: </p><ul><li>you here -&gt; 💗</li><li>make yourself at home 🍋</li></ul><p>You can also include them in the body of the email to generate a greater visual impact and a neatear appearance.</p><h2>Email 'til you make it</h2><p>Yes, we received tons of emails per week. In fact, Superhuman mentioned it in their onboarding email sequence.</p><p><span>
      <span></span>
  <img alt="Image" title="Image" src="https://blog.palabra.io/static/21d1789e9a7a13f7b48e1446974657ed/a9fc9/04.png" srcset="https://blog.palabra.io/static/21d1789e9a7a13f7b48e1446974657ed/5243c/04.png 240w,https://blog.palabra.io/static/21d1789e9a7a13f7b48e1446974657ed/ab158/04.png 480w,https://blog.palabra.io/static/21d1789e9a7a13f7b48e1446974657ed/a9fc9/04.png 701w" sizes="(max-width: 701px) 100vw, 701px" loading="lazy">
    </span></p><p><em>(this is simply genius)</em></p><p>But preciscely for that reason you have to be present. The first days are critical to impress your users.</p><p>Zest has the strategy of sending an email the first day a user joins. And then three more during the second day, another 4 days after and another one 10 days after.</p><p>Imagine someone you’re dating sends you 4 emails in 10 days (well, in that case, you’re probably Meg Ryan, so maybe it’s not so bad).</p><p>This could sound excessive, but it can take a while until people understand your value. Just make sure the value you're providing is clear, and that each email you send has a reason to be in people's inbox.</p><h2>Thank yous matter</h2><p>Far from recommending you stalk your users, we want to encourage you to use emails as a tool for a meaningful exchange of information. You can learn one thing or two about your own service or product.</p><p>The Superhuman sequence puts feedback as a priority, using sentences like:</p><p>“<strong>We love hearing your feedback: please reply to this email and say hello :)”</strong></p><p><strong>“We love hearing from you! Please reply and let us know what you think 😃”</strong></p><p>In the email sequence that we mentioned from Zest, at the 10 day after the user joins, they ask for the thoughts and feelings about the platform and for the likes and dislikes.</p><p>A “thank you” at the end of every email leaves a good impression. Of course. It’s also a good idea to make a special thanking email. When a business is growing, every user is something to thank, so let them know that in your own words (or emojis!).</p><p>If you read this far, ping us at <a href="https://twitter.com/palabraio">Twitter</a> and tell us who sent you your favorite onboarding emails.</p><hr><p>Hope you enjoyed this post! If you are curious about what you can do with Palabra or would just like to try it go ahead and <a href="https://www.palabra.io/?utm_medium=best-onboarding&amp;utm_source=blog">create an account here</a>.</p></section></div>]]>
            </description>
            <link>https://blog.palabra.io/great-onboarding-plain-text</link>
            <guid isPermaLink="false">hacker-news-small-sites-24707994</guid>
            <pubDate>Wed, 07 Oct 2020 13:35:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making the Monty Hall problem weirder but obvious]]>
            </title>
            <description>
<![CDATA[
Score 160 | Comments 208 (<a href="https://news.ycombinator.com/item?id=24707305">thread link</a>) | @dyno-might
<br/>
October 7, 2020 | https://dyno-might.github.io/2020/09/17/making-the-monty-hall-problem-weirder-but-obvious/ | <a href="https://web.archive.org/web/*/https://dyno-might.github.io/2020/09/17/making-the-monty-hall-problem-weirder-but-obvious/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <div>
        







<div>
    <div>
        <div>
            
            <p><strong>Sep 17, 2020</strong></p>
            
            



<p>The <a href="https://en.wikipedia.org/wiki/Monty_Hall_problem">Monty Hall problem</a> is famously unintuitive. This post starts with an extreme version where the solution is blindingly obvious. We then go through a series of small changes. It will be clear that these don’t affect the solution. At the end, we arrive at the classic Monty Hall problem.</p>

<p>For reference, the <a href="https://en.wikipedia.org/wiki/Monty_Hall_problem">classic formulation</a> goes:</p>

<blockquote>
  <p>Suppose you’re on a game show, and you’re given the choice of three doors: Behind one door is a car; behind the others, goats. You pick a door, say No. 1, and the host, who knows what’s behind the doors, opens another door, say No. 3, which has a goat. He then says to you, “Do you want to pick door No. 2?” Is it to your advantage to switch your choice?</p>
</blockquote>

<p>Intuitively, many people guess it doesn’t matter if you switch. But it does. You get the car 2/3 of the time if you switch, and 1/3 of the time if you don’t. Why?</p>



<p>Here’s our first game.</p>

<ol>
  <li>There are 10 doors. A car is randomly placed behind one, and goats behind the other 9.</li>
  <li>You pick one door.</li>
  <li>You get two options:
    <ul>
      <li>Option A: You get whatever is behind the door you picked.</li>
      <li>Option B: You get whatever is behind all of the other 9 doors.</li>
    </ul>
  </li>
</ol>

<p><img src="https://dyno-might.github.io/img/monty-hall/game1.png">
</p>

<p>There’s nothing mysterious here. You should choose option B. There’s only a 10% chance you picked the right door, so there’s a 90% chance the car is behind one of the others.</p>



<p>Now, we slightly update the game (new part in bold).</p>

<ol>
  <li>There are 10 doors. A car is randomly placed behind one, and goats behind the other 9.</li>
  <li>You pick one door.</li>
  <li><strong>Monty says “Hey! I promise you that there is a goat behind at least 8 of the other 9 doors!”</strong></li>
  <li>You get two options:
    <ul>
      <li>Option A: You get whatever is behind the door you picked.</li>
      <li>Option B: You get whatever is behind all of the other 9 doors.</li>
    </ul>
  </li>
</ol>

<p><img src="https://dyno-might.github.io/img/monty-hall/game2.png">
</p>

<p>Monty’s statement changes nothing. You don’t need to rely on his <a href="https://en.wikipedia.org/wiki/Monty_Hall#/media/File:Monty_hall_abc_tv.JPG">trustworthy looks</a>. You already <em>knew</em> there were at least 8 goats! Option B still gets you the car 90% of the time.</p>



<p>Let’s update the game again (new part in bold).</p>

<ol>
  <li>There are 10 doors. A car is randomly placed behind one, and goats behind the other 9.</li>
  <li>You pick one door.</li>
  <li><strong>Monty looks behind the other 9 doors. He chooses 8 with goats behind them, and opens them.</strong></li>
  <li>You get two options:
    <ul>
      <li>Option A: You get whatever is behind the door you picked.</li>
      <li>Option B: You get whatever is behind all of the other 9 doors.</li>
    </ul>
  </li>
</ol>

<p><img src="https://dyno-might.github.io/img/monty-hall/game3.png">
</p>

<p>The key insight is this: When Monty shows you that 8 of the 9 other doors contain goats, you haven’t learned anything relevant to your decision. You <em>already knew there were at least 8 goats behind the other doors</em>! So this is just like game 2. Option B still gets you the car 90% of the time.</p>

<p>Want more intuition? Suppose you picked door 3. Imagne Monty walking past the doors, opening doors 1, 2, 4, 5, 6, <strong>skipping 7</strong>, then opening 8, 9, and 10. Doesn’t door 7 seem special?</p>



<p>Let’s make another change. Finally, we arrive at a game very similar to Monty Hall.</p>

<ol>
  <li>There are 10 doors. A car is randomly placed behind one, and goats behind the other 9.</li>
  <li>You pick one door.</li>
  <li>Monty looks behind the other 9 doors. He chooses 8 of them with goats behind them, and opens them.</li>
  <li>You get two options:
    <ul>
      <li>Option A: You get whatever is behind the door you picked.</li>
      <li>Option B: You get whatever is behind <strong>the other closed door</strong>.</li>
    </ul>
  </li>
</ol>

<p><img src="https://dyno-might.github.io/img/monty-hall/game4.png">
</p>

<p>The only difference with Game 3 is that option B doesn’t get you the 8 visible goats. Since you don’t care about goats, this makes no difference. This is still just like the game 3. You get the car 90% of the time by switching.</p>



<p>Here is the last game. We just change the number of doors from 10 to 3.</p>

<ol>
  <li>There are <strong>3</strong> doors. A car is randomly placed behind one, and goats behind the other <strong>2</strong>.</li>
  <li>You pick one door.</li>
  <li>Monty looks behind the other <strong>2</strong> doors. He chooses one <strong>1</strong> of them with a goat behind it, and opens it.</li>
  <li>You get two options:
    <ul>
      <li>Option A: You get whatever is behind the door you picked.</li>
      <li>Option B: You get whatever is behind the other closed door.</li>
    </ul>
  </li>
</ol>

<p><img src="https://dyno-might.github.io/img/monty-hall/game5.png">
</p>

<p>Of course, you still want to choose option B. The chance of success is now 2/3 instead of 9/10. This game is exactly Monty Hall, so we’re done.</p>



<ul>
  <li>
    <p>It’s important that Monty looked behind the doors before choosing which to open. This is where people’s intuition usually fails. If he had chosen a door at random — <em>in a way that he risked possibly exposing a car</em>, then the situation would be different. (In that case, there’s no advantage or harm in switching.) But he doesn’t choose the door at random. He deliberately chooses to show you goats. Since this is always possible, it tells you nothing. I think this is the crux of what makes this problem unintuitive. Many people intuitively think it doen’t matter if you switch. And that <em>would be correct</em> if the door had been opened at random!</p>
  </li>
  <li>
    <p>It might be helpful to draw a diagram of the relationship of the different games, starting with classic Monty Hall and ending with the extreme version.</p>
  </li>
</ul>

<blockquote>
  <p>Game 5 (Classic Monty Hall)<br>
 ↓<br>
 ↓ (Use 10 doors instead of 3)<br>
 ↓ <br>
Game 4<br>
 ↓<br>
 ↓ (If you switch, get the contents of <em>all</em> other doors, not just the other closed door.)<br>
 ↓<br>
Game 3<br>
 ↓<br>
 ↓ (Monty promises 8 goats behind the other doors instead of showing you.)<br>
 ↓<br>
Game 2<br>
 ↓<br>
 ↓ (Monty doesn’t bother promsising.)<br>
 ↓<br>
Game 1 (Dyno Might© Monty Hall)</p>
</blockquote>

<ul>
  <li>
    <p>There are <a href="https://marginalrevolution.com/marginalrevolution/2019/09/the-intuitive-monty-hall-problem.html">some</a> <a href="https://twitter.com/jben0/status/1174180200072011776">other</a> <a href="https://statmodeling.stat.columbia.edu/2019/09/19/alternative-more-intuitive-formulation-of-monte-hall-problem/">attempts</a> at <a href="https://math.stackexchange.com/questions/96826/the-monty-hall-problem/3360686#3360686">variants</a> of the Monty Hall problem, also intended to be more intuitive. These involve switching the doors for “boxers”.</p>
  </li>
  <li>
    <p>Monty Hall was actually named “Monte” at birth! Given that <a href="https://en.wikipedia.org/wiki/Monte_Carlo_method">Monte Carlo simulations</a> are often used for exploring the Monty Hall problem, that’s either a tragedy for puns or a miracle for confused students.</p>
  </li>
</ul>

        </div>

        

        
        
    </div>
</div>


    </div>
</section></div>]]>
            </description>
            <link>https://dyno-might.github.io/2020/09/17/making-the-monty-hall-problem-weirder-but-obvious/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24707305</guid>
            <pubDate>Wed, 07 Oct 2020 11:57:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Design an Algorithm (2018)]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24706841">thread link</a>) | @rohithkp
<br/>
October 7, 2020 | https://www.adamconrad.dev/blog/how-to-design-an-algorithm/ | <a href="https://web.archive.org/web/*/https://www.adamconrad.dev/blog/how-to-design-an-algorithm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">

    <article>

        

        <section>

            <p>If you missed my <a href="https://www.adamconrad.dev/blog/why-hiring-is-broken-and-how-im-dealing-with-it">previous article</a>, I’m going to spend a series of articles providing notes as I audit <a href="http://www3.cs.stonybrook.edu/~skiena/373/">Steven Skiena’s CSE 373 Analysis of Algorithms class</a>.</p>

<p>In the first lecture, Skiena mentions you should take a data structures course and a linear algebra course before studying this material.</p>

<p>For professional (read: practical) purposes, we’re obviously not starting from scratch, but peaking at the syllabus I do believe we can incorporate data structures by implementing them in JavaScript (this is, after all, a front-end blog) along the way.</p>

<p>And as much as foundational linear algebra will help, there simply won’t be anything in a technical interview that would warrant deep study anyway, so we can safely skip this prerequisite.</p>

<h2 id="what-is-an-algorithm">What is an algorithm?</h2>

<p>An algorithm is <strong>an instruction set.</strong> Kind of like a recipe for a food dish. And just like that recipe for cauliflower rice you found on some random blog, you can translate that recipe into any language you want.</p>

<p>Algorithms are the same way: they are language-agnostic and can be expressed in a human-readable form or machine-readable. The simpler the idea, the easier it’s going to be to express in English. The more complex or nuanced the algorithm is, the more likely you’ll want to lean on a machine language like Python or JavaScript.</p>

<p>For practical purposes, think of the high-level overview of your algorithm as something you’ll explain to an interviewer in English before you dive into the code, but understand that in order to prove your chops as a programmer the code will have to be the primary source for explaining and validating the algorithms you design.</p>

<p>The two defining characteristics of an algorithm that separate an algorithm from other instructions are:</p>

<ol>
  <li><strong>It’s correct.</strong> Has anyone ever received credit for implementing an algorithm in a tech interview that didn’t produce the correct result every single time?</li>
  <li><strong>It’s efficient.</strong> We’d like our algorithms to run sometime before we get old.</li>
</ol>

<p>Now, <em>technically</em>, programs don’t have to run correctly to be acceptable. Programs that run instructions that are <em>mostly</em> correct are known as <em>heuristics</em>. These will become important when studying approximation algorithms later, but for now, assume that correctness is a requirement.</p>

<h3 id="how-do-you-prove-an-algorithm-is-correct">How do you prove an algorithm is correct?</h3>

<p>Proofs were not my strong suit in high school or college. For some reason, it never really clicked for me because the steps in a proof never seemed to line up with the logic my brain used to jump from one step to the next.</p>

<p>Luckily, the easiest way to prove correctness is to prove something <strong>isn’t correct.</strong></p>

<p>Wait, what? How does proving the opposite help us here?</p>

<p>Well, when we’re trying to figure out a correct and efficient algorithm to solve a problem, we can narrow the scope of possible choices by eliminating the ones that are demonstratively incorrect. Proving by counterexample can be far easier than other methods.</p>

<p>As a trivial example, suppose we have a total <em>T = 6</em> we want to strive for by adding up numbers in a valid set like <em>S = [1,2,3]</em>. It might seem like a very simple algorithm that will solve this problem is to pick numbers from left to right until we reach the total <em>T</em>. Even if you add in a big number at the beginning like <em>S = [5,1,2,3]</em> this works since we can just scrap the last two numbers.</p>

<p>What’s a counterexample that wouldn’t work?</p>

<p>How about <em>S = [5,2,4]</em>.</p>

<p>First, we pick 5, which is less than 6. There are no other numbers in our set that could add up to equal 6 after already picking 5, but there <em>is</em> a valid configuration that would still satisfy <em>T</em> (2 and 4). That’s proof by counterexample that our algorithm was not correct. It’s also a pretty simple counterexample. <strong>Counter-examples can be useful in the real-world to quickly help you assess if the path you’re going down is a good one or not.</strong></p>

<p>If you can come up with a relatively simple counterexample (simple meaning it should only require a handful of variables or items) you know that your algorithm is dead on arrival and you’ll need to try something else. If you can’t, you’re probably on the right track, but that doesn’t mean your algorithm is definitively correct.</p>

<h3 id="what-techniques-are-used-to-prove-correctness">What techniques are used to prove correctness?</h3>

<p>One way to prove correctness is induction. <strong>Proof by induction indicates that if we can solve for a base case <em>and</em> the general case for <code>n+1</code>, we know we’ve provided a correct answer for all possible inputs.</strong></p>

<p>There are two important connections to make here about induction which are useful in a professional setting:</p>

<ol>
  <li><strong>Proof by induction is a mathematical form of recursion.</strong> Recursion is a fundamental concept in programming which allows a function to call itself. It allows us to split up large problems into smaller ones.</li>
</ol>

<p>The classic example here is the Fibonacci sequence (a sequence of integers where the current number is the sum of the previous two numbers). To calculate Fibonacci for a value <em>n</em> in the sequence, you <em>could</em> count up all of the previous numbers manually for each input of <em>n</em>, but that would not only be slow and laborious, it would also be difficult to express as a program.</p>

<p>Another way would be to count a few base cases (n = 0 and n = 1) to get the counting started, and then continuously call a <code>Fibonacci</code> function with the summed values from the previous step. Recursion is what allows us to accomplish this in code. It is the programming strategy for tackling induction, which is the mathematical strategy for proving statements for algorithms which operate on our sets of data.</p>

<ol>
  <li><strong>Proof by induction is useful for summation.</strong> If you’re adding up a lot of inputs together, and you need to prove it will work for all cases, even ones larger than the set you have defined, it can be proven with induction.</li>
</ol>

<p>But are you ever going to need to formally prove something at work or in an interview? Absolutely not. <strong>But you will need to test your code, and tests are a form of proof.</strong></p>

<p>So while a formal mathematical proof of induction is likely way more rigorous than you will ever need to showcase in a professional setting, it does set the tone that you can’t simply write code and have people assume what you wrote is correct. It needs to be tested somehow, so if you have the mindset that your algorithm needs to be proven correct in some form, you’re on the right track to writing quality code.</p>

<h3 id="and-how-do-you-prove-something-is-efficient">And how do you prove something is efficient?</h3>

<p>If we’ll primarily be using code to express our algorithms, and tests to prove their correctness, Big O notation will be used to prove our algorithms are efficient.</p>

<p>We’ll cover Big O in a later post in this series, but the important thing to remember now is that in general, you’re going to want to strive for things that take a reasonable amount of time on large data.</p>

<p>For example, if something you design takes an <code>n!</code> factorial amount of time, anything over a measly 30 items and you’re dealing with numbers larger than the number of stars in the known universe. You <em>probably</em> want something that runs a bit faster than that.</p>

<h3 id="the-big-picture-on-the-properties-of-algorithms">The big picture on the properties of algorithms</h3>

<p>Most CS courses (and most schools) only ever care about these two things. If your teachers and TAs can successfully run your program within a reasonable amount of time, you get an A. Real life doesn’t give you an A for these two things because <em>you don’t work in a vacuum</em> as you do on a problem set or exam. So what things are missing from the real world picture?</p>

<ul>
  <li><strong>Orthogonality:</strong> Is your code dependent on other stuff? Are you writing stateful or functional code? Since most coding whiteboard problems are isolated and self-contained, you usually can’t test for this, so make sure you present a portfolio of real-world projects and open source code to demonstrate this</li>
  <li><strong>Readability:</strong> You can write the hackiest crap to get an algorithm to work, but in the real world other people can’t read or use that code, and that’s a fail. Make sure if you have time and your code is correct and efficient, to <em>refactor</em> to demonstrate you can write readable, reusable code that is DRY (don’t repeat yourself) and orthogonal (or at least that it can be written as part of an orthogonal system)</li>
</ul>

<h3 id="the-first-step-in-designing-an-algorithm">The first step in designing an algorithm</h3>

<p>So now that we know what defines an algorithm and what is required to prove it’s worth using to solve our problems, the next step is to decide how we will design our algorithms. Modeling a problem means knowing the objects you’re dealing with, and there are two classes of objects we will cover:</p>

<h4 id="combinatorial-objects">Combinatorial objects</h4>

<p>A <em>combinatorial object</em> is just a fancy way of saying “what kinds of things can I use to count with?” Since machines are just big 0 and 1 factories, combinatorial objects are the way for us to collect and organize all of the 0 and 1 math our machines are performing thousands upon millions of instructions per second. What kinds of things are we talking about?</p>

<ul>
  <li><strong>Permutations:</strong> reorderings of a set. Colloquial terms for this include words like <em>arrangement</em>, <em>tour</em>, <em>ordering</em>, and/or <em>sequence</em>.</li>
  <li><strong>String:</strong> sequence of characters or patterns. Think of strings like permutations but with letters instead of numbers. Words like <em>text</em>, <em>character</em>, <em>pattern</em>, <em>label</em>, <em>sentence</em> are key insights that you’re dealing with string data.</li>
  <li><strong>Subsets:</strong> portions of a set. If you see words like <em>cluster</em>, <em>collection</em>, <em>committee</em>, <em>group</em>, <em>packaging</em>, or <em>selection</em>, you’ve probably got a subset.</li>
  <li><strong>Points:</strong> locations in space. Words like <em>node</em>, <em>site</em>, <em>position</em>, <em>record</em>, or <em>location</em> are all references to <em>points</em>.</li>
  <li><strong>Graphs:</strong> nodes with vertices to connect them and give them direction. We mentioned this much earlier in this article. Words like <em>network</em>, <em>circuit</em>, <em>web</em>, and <em>relationship</em> all describe graphs.</li>
  <li><strong>Trees:</strong> graphs that flow in one direction and don’t end up where they started (acyclic). When they’re perfectly balanced, they literally look like a Christmas tree. Words like <em>hierarchy</em>, <em>dominance relationship</em>, <em>ancestor/descendent relationship</em>, <em>taxonomy</em> are all indicators you’re dealing with trees in your problem.</li>
  <li><strong>Polygon:</strong> …</li></ul></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.adamconrad.dev/blog/how-to-design-an-algorithm/">https://www.adamconrad.dev/blog/how-to-design-an-algorithm/</a></em></p>]]>
            </description>
            <link>https://www.adamconrad.dev/blog/how-to-design-an-algorithm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24706841</guid>
            <pubDate>Wed, 07 Oct 2020 10:23:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Crouching T2, Hidden Danger]]>
            </title>
            <description>
<![CDATA[
Score 217 | Comments 109 (<a href="https://news.ycombinator.com/item?id=24705645">thread link</a>) | @xrayarx
<br/>
October 6, 2020 | https://ironpeak.be/blog/crouching-t2-hidden-danger/ | <a href="https://web.archive.org/web/*/https://ironpeak.be/blog/crouching-t2-hidden-danger/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="info"><div><p><h4><br><span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512" width="25" height="20"><path fill="currentcolor" d="M448 0H64C28.7.0.0 28.7.0 64v288c0 35.3 28.7 64 64 64h96v84c0 7.1 5.8 12 12 12 2.4.0 4.9-.7 7.1-2.4L304 416h144c35.3.0 64-28.7 64-64V64c0-35.3-28.7-64-64-64zm16 352c0 8.8-7.2 16-16 16H288l-12.8 9.6L208 428v-60H64c-8.8.0-16-7.2-16-16V64c0-8.8 7.2-16 16-16h384c8.8.0 16 7.2 16 16v288z"></path></svg></span>Crouching T2, Hidden Danger
<span>Mon Oct 5, 2020</span></h4></p></div></div><div id="features"><div><p><h4>Crouching T2, Hidden Danger
<span>Mon Oct 5, 2020</span></h4><hr><br></p><p><strong>Let’s talk about that thing nobody’s talking about.
Let’s talk about a vulnerability that’s exposing 2018-2020 Macs while most are declining to act nor report about the matter.
Oh, and did I mention it’s unpatchable?</strong></p><p><strong>Buckle up buckaroo, we’re in for a wild ride.</strong></p><p>Skip to <a href="#security-issues">#security-issues</a> for the technical mumbo-jumbo.</p><h2 id="preface">Preface</h2><h3 id="attribution">Attribution</h3><p>The following post is an industry analysis of the code and research performed by <a href="https://twitter.com/axi0mx/">twitter.com/axi0mx</a>, <a href="https://twitter.com/h0m3us3r/">twitter.com/h0m3us3r</a>, <a href="https://twitter.com/aunali1/">twitter.com/aunali1</a>, <a href="https://twitter.com/mcmrarm/">twitter.com/mcmrarm</a> and <a href="https://twitter.com/su_rickmark/">twitter.com/su_rickmark</a> who poured endless hours of work into this, allowing companies and users to understand their risks concerning this issue.</p><h3 id="intel-vs-silicon">Intel vs Silicon</h3><p>This blog post only applies to macOS systems with an Intel processor and the embedded T2 security chip.
Apple silicon systems will run completely on a set of Apple-designed ARM processors and mighth have a different topology, e.g. based on the A12.
Since the A12 chip seems to have fixed this issue (to be confirmed), it’s highly likely the new Apple Silicon machines will not be vulnerable.
And while the new upcoming Intel Macs at the end of year will probably receive a new hardware revision of the T2 chip (e.g. based on the A12), we are still stuck with this vulnerability on Macs between 2018 and 2020.</p><h3 id="so-about-this-t2-thing">So about this T2 thing</h3><p>In case you are using a recent macOS device, you are probably using <a href="https://support.apple.com/en-us/HT208862">the embedded T2 security chip</a> which runs <em>bridgeOS</em> and is actually based on watchOS. This is a custom ARM processor designed by Apple based on the A10 CPU found in the iPhone 7.
The T2 chip contains a <em>Secure Enclave Processor</em> (SEP), much like the A-series processor in your iPhone will contain a SEP.</p><p>While newer Macs and/or Apple Silicon (including the dev kit) will use a more recent A-series processor such as the one found in the recent iPhone (A12), current Macs still use the A10.</p><p>It performs a predefined set of tasks for macOS such as audio processing, handling I/O, functioning as a <a href="https://en.wikipedia.org/wiki/Hardware_security_module">Hardware Security Module</a> for e.g. Apple KeyChain or 2FA, hardware accelerating media playback, whitelisting kernel extensions, cryptographic operations and <strong>ensuring the operating system you are booting is not tampered with</strong>.
The T2 chip runs its own firmware called <em>bridgeOS</em>, which can be updated when you install a new macOS version. (ever notice the screen flickering? that’s the display driver being interrupted and possibly updated.)</p><p><em>Edit</em>: I first mentioned the iPad Pro to be impacted by the T2 vulnerability, but while it could suffer from the same vulnerability, it does not contain a T2 chip.</p><h3 id="the-macos-boot-sequence">The macOS boot sequence</h3><p>So let’s focus on the boot image verification on macOS. What exactly happens when you press that power button?
<a href="https://eclecticlightdotcom.files.wordpress.com/2018/08/bootprocess.png">There’s also a visual representation for any <em>conaisseurs</em></a>.
For the enthusiasts, I personally find <a href="https://michaellynn.github.io/2018/07/27/booting-secure/">Booting Secure by mikeymikey</a> a more in-depth description.</p><ol><li><p>The T2 chip is fully booted and stays on, even if your Mac device is shutdown.</p></li><li><p>The press of the power button or the opening of the lid triggers the System Management Controller (SMC) to boot.</p></li><li><p>The SMC performs a Power-On-Self-Test (POST) to detect any EFI or hardware issues such as bad RAM and possibly redirect to Recovery.</p></li><li><p>After those basic sanity checks, the T2 chip is triggered and I/O connectors are setup. (USB, NVMe, PCIe, …) It will use NVMe and PCIe to talk to NAND storage.</p></li><li><p>The applicable boot disk is selected and a disk encryption password is asked if enabled to mount <a href="https://en.wikipedia.org/wiki/Apple_File_System">APFS</a> volumes possibly via FileVault2 disk encryption.</p></li><li><p><code>/System/Library/CoreServices/boot.efi</code> is located on your System APFS volume and <a href="https://support.apple.com/en-us/HT208330">depending on your secure boot settings</a> is validated.</p></li><li><p><em>boot.efi</em> is ran which loads the Darwin kernel <em>(throwback to BSD)</em> (or Boot Camp if booting Microsoft Windows) &amp; IODevice drivers. If a kernel cache is found in <code>/System/Library/PrelinkedKernels/prelinkedkernel</code>, it will use that.</p></li><li><p>Any User Approved Kernel Extensions are initialized &amp; added to the kernel space -if- they are approved by the T2 chip.
<em>This will go away with System Extensions</em>.</p></li></ol><h3 id="macos-security-features">macOS security features</h3><p>So Apple has a couple of tricks up its sleeve to limit the attack surface of any potential security vulnerabilities. A small summary of related measures since macOS Big Sur on Intel processors:</p><ul><li><p><em>System Integrity Protection</em> (SIP): a read-only <code>/System</code> partition so the base install of macOS (including the kernel) cannot be tampered with.</p></li><li><p><em>System Extensions</em>: a move to away from Kernel Extensions, getting external code out of the Kernel framework-wise.</p></li><li><p><em>Secure Boot</em>: verifies the signature validity of the operating system on disk.</p></li><li><p><em>Filesystem seals</em>: every byte of data is compared to a hash in the filesystem metadata tree, recursively verifying integrity.</p></li></ul><h3 id="apple-marketing">Apple marketing</h3><p>As you probably all already know, Apple pushes forward privacy &amp; security as important weapons in todays world of technology.
They tout their devices as highly secure and vouch to handle your personal data using a privacy-centric approach.
While there have been mistakes made in the past (who can blame them?), Apple has been generally quick to fix any security issues that were disclosed to <a href="https://support.apple.com/en-gb/HT201220">their responsible disclosure program</a> or in public.</p><h2 id="security-issues">Security issues</h2><h3 id="jailbreaking">Jailbreaking</h3><h3 id="the-core-problem">The core problem</h3><p>The mini operating system on the T2 (<em>SepOS</em>) suffers from a security vulnerable also found in the iPhone 7 since it contains a processor based on the iOS A10. Exploitation of this type of processor for the sake of installing homebrew software is very actively discussed in the <a href="https://reddit.com/r/jailbreak/">/r/jailbreak</a> subreddit.</p><p>So using the <a href="https://checkm8.info/">checkm8 exploit</a> originally made for iPhones, the checkra1n exploit was developed to build a semi-tethered exploit for the T2 security chip, exploiting a flaw. This could be used to e.g. circumvent activation lock, allowing stolen iPhones or macOS devices to be reset and sold on the black market.</p><p>Normally the T2 chip will exit with a fatal error if it is in DFU mode and it detects a decryption call, but thanks to the <a href="https://github.com/windknown/presentations/blob/master/Attack_Secure_Boot_of_SEP.pdf">blackbird vulnerability</a> by team Pangu, we can completely circumvent that check in the SEP and do whatever we please.</p><p>Since sepOS/BootROM is <em>Read-Only Memory</em> for security reasons, interestingly, Apple cannot patch this core vulnerability without a new hardware revision.
This thankfully also means that this is not a persistent vulnerability, so it will require a hardware insert or other attached component such as a malicious USB-C cable.</p><h3 id="debugging">Debugging</h3><p>Every Apple iDevice (which includes the T2 and the Watch, via a port under the band) ships with a firmware recovery USB interface called Device Firmware Update (DFU), which is triggered when the device is not be able to boot or by pressing a particular set of buttons when turned on. It is always available because it is code run from SecureROM. This is the mode in which checkm8 runs.</p><p>Apple also leaves the ability to access various debug functionality which is disabled on production devices unless a special boot payload is used which runs in DFU. Since Apple is the only one who can sign code for DFU, they can demote any device they like, including the most recent A14 processors.
But since the checkm8 vulnerability runs so early in the boot process, we too can demote the T2 into DFU mode.
Without checkm8, we would not be able to run unsigned code in DFU and thus not be able enable debug interfaces. Once the debug interface is enabled Apple uses specialized cables with simian names (see Chimp, Kanzi, Gorilla).</p><h3 id="impact">Impact</h3><p>Once you have access on the T2, you have full <code>root</code> access and kernel execution privileges since the kernel is rewritten before execution.
Good news is that if you are using FileVault2 as disk encryption, they do not have access to your data on disk <em>immediately</em>.
They can however inject a keylogger in the T2 firmware since it manages keyboard access, storing your password for retrieval or transmitting it in the case of a malicious hardware attachment.</p><p>The functionality of locking an Apple device remotely (e.g. via MDM or FindMy) can be bypassed (<em>Activation Lock</em>).</p><p>A firmware password does not mitigate this issue since it requires keyboard access, and thus needs the T2 chip to run first.</p><p>Any kernel extension could be whitelisted since the T2 chip decides which one to load during boot.</p><p>If the attack is able to alter your hardware (or sneak in a malicious USB-C cable), it would be possible to achieve a semi-tethered exploit.</p><p>While this may not sound as frightening, be aware that this is a perfectly possible attack scenario for state actors.
I have sources that say more news is on the way in the upcoming weeks. I quote: <em>be afraid, be very afraid</em>.</p><h2 id="exploitation">Exploitation</h2><pre><code># install devtools
$ xcode-select --install

# check the script &amp; install homebrew
$ /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)"

# install packages
$ brew install libplist automake autoconf pkg-config openssl libtool llvm libusb

# git clone, autogen.sh, make &amp; make install
# https://github.com/sbingner/ldid
# https://github.com/libimobiledevice/libusbmuxd
# https://github.com/libimobiledevice/libimobiledevice
# https://github.com/libimobiledevice/usbmuxd

# Run checkra1n and wait for T2 boot. It will stall when complete.
# TODO describe the checkra1n exploitation 

# Unplug and replug the usb connection. Checkra1n should now send the overlay.
# TODO describe the usb debug mode &amp; overlay

# Bring up a proxy to dropbear
$ iproxy 2222 44 &amp;

# Connect to T2 &amp; enjoy
$ ssh -p 2222 root@127.0.0.1
</code></pre><h2 id="responsible-disclosure">Responsible Disclosure</h2><p>I’ve reached out to Apple concerning this issue on numerous occasions, even doing the dreaded cc <em>tcook@apple.com</em> to get some exposure.
Since I did not receive a response for weeks, I did the same to numerous news websites that cover Apple, but no response there as well.
In hope of raising more awareness (and an official response from Apple), I am hereby disclosing almost all of the details.
You could argue I’m not following responsible disclosure, but since this issue has been known since 2019, I think …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ironpeak.be/blog/crouching-t2-hidden-danger/">https://ironpeak.be/blog/crouching-t2-hidden-danger/</a></em></p>]]>
            </description>
            <link>https://ironpeak.be/blog/crouching-t2-hidden-danger/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24705645</guid>
            <pubDate>Wed, 07 Oct 2020 05:52:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[VSCode on Google Colab]]>
            </title>
            <description>
<![CDATA[
Score 193 | Comments 49 (<a href="https://news.ycombinator.com/item?id=24705599">thread link</a>) | @amitness
<br/>
October 6, 2020 | https://amitness.com/vscode-on-colab/ | <a href="https://web.archive.org/web/*/https://amitness.com/vscode-on-colab/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<header>

<p>
<span>

2 minute read
</span>
</p>
</header>
<section itemprop="text">
<p>I recently discovered a way to set up VSCode on Google Colab and use it as an editor to write code and run experiments on the Colab VM.</p>
<p>With this setup, you can still prototype in the Colab Notebook while also using VSCode for all the advantages of a full-fledged code editor. Here is how you can replicate my setup.</p>
<h2 id="approach-1-python-package">Approach 1: Python Package</h2>
<p>In this setup, we use the <a href="https://github.com/abhishekkrthakur/colabcode">colab-code</a> package that automates all the manual setup steps previously described in the <strong>Approach 2</strong> section of this blog post. You can make a copy of this <a href="https://colab.research.google.com/github/abhishekkrthakur/colabcode/blob/master/colab_starter.ipynb">notebook</a> directly to get started.</p>
<ol>
<li>
<p>First, install the <code>colab-code</code> package using the following command:</p>

</li>
<li>
<p>Now, import <code>ColabCode</code> class from the package and specify the port and password.</p>
<div><div><pre><code> <span>from</span> <span>colabcode</span> <span>import</span> <span>ColabCode</span>
 <span>ColabCode</span><span>(</span><span>port</span><span>=</span><span>10000</span><span>,</span> <span>password</span><span>=</span><span>"password123"</span><span>)</span>
</code></pre></div> </div>
<p>You can also use it directly with the default port and without any password as shown below.</p>
<div><div><pre><code> <span>from</span> <span>colabcode</span> <span>import</span> <span>ColabCode</span>
 <span>ColabCode</span><span>()</span>
</code></pre></div> </div>
</li>
<li>
<p>You will get the ngrok URL in the output. Click the link and a login page will open in a new tab.</p>
<p><img src="https://amitness.com/images/colab-code-step-1.png" alt="Generated NGROK URL"></p>
</li>
<li>
<p>Type the password you had set in step 2 and click submit. If the page gets stuck for more than 4-5 seconds, refresh the page and you should be redirected to the editor.</p>
<p><img src="https://amitness.com/images/colab-code-step-2.png" alt="Authenticating with password in VSCode"></p>
</li>
<li>
<p>Now you will get access to the editor interface and can use it to work on python files.</p>
<p><img src="https://amitness.com/images/colab-code-step-3.png" alt="VSCode Interface"></p>
</li>
</ol>
<h2 id="approach-2-manual-setup">Approach 2: Manual Setup</h2>
<p>I have described the setup steps in detail below. After going through all the steps, please use this <a href="https://colab.research.google.com/drive/1yvUy5Gn9lPjmCQH6RjD_LvUO2NE0Z7RM?usp=sharing">colab notebook</a> to try it out directly.</p>
<ol>
<li>
<p>First, we will install the <a href="https://github.com/cdr/code-server">code-server</a> package to run VSCode editor as a web app. Copy and run the following command on colab to install <code>code-server</code>.</p>
<div><div><pre><code> !curl -fsSL https://code-server.dev/install.sh | sh
</code></pre></div> </div>
</li>
<li>
<p>After the installation is complete, we will expose a random port <code>9000</code> to an external URL we can access using the <code>pyngrok</code> package. To install <code>pyngrok</code>, run</p>
<div><div><pre><code> <span>!</span>pip <span>install</span> <span>-qqq</span> pyngrok
</code></pre></div> </div>
</li>
<li>
<p>Then, run the following command to get a public ngrok URL. This will be the URL we will use to access VSCode.</p>
<div><div><pre><code> <span>from</span> <span>pyngrok</span> <span>import</span> <span>ngrok</span>
 <span>url</span> <span>=</span> <span>ngrok</span><span>.</span><span>connect</span><span>(</span><span>port</span><span>=</span><span>9000</span><span>)</span>
 <span>print</span><span>(</span><span>url</span><span>)</span>
</code></pre></div> </div>
</li>
<li>
<p>Now, we will start the VSCode server in the background at port 9000 without any authentication using the following command.</p>
<div><div><pre><code> !nohup code-server --port 9000 --auth none &amp;
</code></pre></div> </div>
</li>
<li>
<p>Now, you can access the VSCode interface at the URL you got from step 3. The interface and functionality are the same as the desktop version of VSCode.</p>
</li>
</ol>
<p><img src="https://amitness.com/images/colab-vscode.png" alt="Example of a running instance of VSCode server"></p>
<h2 id="usage-tips">Usage Tips</h2>
<ol>
<li>
<p>You can switch to the dark theme by going to the bottom-left corner of the editor, clicking the <strong>settings icon</strong>, and then clicking ‘<strong>Color Theme</strong>’.</p>
<p><img src="https://amitness.com/images/colab-dark-theme-step-1.png" alt="Switching to dark theme on VSCode"></p>
<p>A popup will open. Select <strong>Dark (Visual Studio)</strong> in the options and the editor will switch to a dark theme.
<img src="https://amitness.com/images/colab-dark-theme-step-2.png" alt="Theme selection interface on VSCode"></p>
</li>
<li>
<p>All the keyword shortcuts of regular VSCode works with this. For example, you can use <code>Ctrl + Shift + P</code> to open a popup for various actions.</p>
<p><img src="https://amitness.com/images/vscode-ctrl-shift-p.png" alt="Action popup in VSCode"></p>
</li>
<li>
<p>To open a terminal, you can use the shortcut <code>Ctrl + Shift + `</code>.</p>
<p><img src="https://amitness.com/images/vscode-terminal.png" alt="Opening integrated terminal in VSCode"></p>
</li>
<li>
<p>To get python code completions, you can install the Python(<code>ms-python</code>) extension from the extensions page on the left sidebar.</p>
<p><img src="https://amitness.com/images/vscode-code-completions.png" alt="Installing extensions in VSCode"></p>
</li>
<li>
<p>The Colab interface is still usable as a notebook and regular functions to upload and download files and mount with Google Drive. Thus, you get the benefits of both a notebook and a code editor.</p>
</li>
</ol>
<h2 id="references">References</h2>
<ul>
<li><a href="https://github.com/cdr/code-server/blob/v3.5.0/doc/FAQ.md">Code-Server FAQs</a></li>
<li><a href="https://pyngrok.readthedocs.io/en/latest/">pyngrok - a Python wrapper for ngrok</a></li>
</ul>
</section>



</div></div>]]>
            </description>
            <link>https://amitness.com/vscode-on-colab/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24705599</guid>
            <pubDate>Wed, 07 Oct 2020 05:38:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[USB3: Why it's a bit harder than USB2]]>
            </title>
            <description>
<![CDATA[
Score 231 | Comments 145 (<a href="https://news.ycombinator.com/item?id=24704298">thread link</a>) | @panic
<br/>
October 6, 2020 | https://lab.ktemkin.com/post/why-is-usb3-harder/ | <a href="https://web.archive.org/web/*/https://lab.ktemkin.com/post/why-is-usb3-harder/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    

    <p>A few people on twitter have asked me to explain why the USB3 winds up being much harder to implement than USB2.
The answer is more than will fit in a single tweet, so I thought I'd put a quick-but-rough answer, here. This is
by no means comprehensive; consider it <del>a longer tweet</del> what a tweet would be given I had more than 240 characters and a proclivity to babble. (I do.)</p>
<p>A lot of the challenges come from the way we work around <em>physical-layer</em> limitations. Put poetically, physics gives
us lots of little obstacles we have to work around in order to talk at 5 billion transfers per second (5GT/s).</p>
<h5 id="its-hard-to-establish-common-dc-operating-conditions-on-both-sides-of-a-link">It's hard to establish common “DC operating conditions” on both sides of a link.</h5>
<p>It's not trivial to get the same bias voltages – and common grounds – across a long motherboard or down a cable – and when you're operating at really high frequencies, you're a lot more sensitive to changes in your operating environment. In USB3, we work around this by <em>capacitively isolating</em> both sides of the link from each other – in short, we use capacitors to ensure only signal <em>changes</em> are carried across the link, which means that both sides can establish their own local operating conditions.</p>
<figure>
    <img src="https://lab.ktemkin.com/post-media/why-is-usb3-harder/circuit.png" alt="diagram showing the transmitter is connected to the receiver through a pair of AC coupling capacitors"> <figcaption>
            <h4>From the USB3.2 specification: diagram showing how signals are isolated</h4>
        </figcaption>
</figure>

<p>This puts some requirements on the digital protocols used to exchange data. Because data currents are exchanged as the relevant capacitors charge and discharge, <em>capacitive coupling</em> only works when those capacitors have room to charge and discharge. <strong>This means our data must be DC-balanced; we have to spend as much time charging those capacitors as we do discharging them</strong>. In digital terms, this means we have to encode the data in a way that sends the same amount of <code>1</code>s and <code>0</code>s.</p>
<h5 id="its-hard-to-establish-a-common-clock-across-both-sides-of-a-link">It's hard to establish a “common clock” across both sides of a link.</h5>
<p>When sending serial data, you typically have two challenges: you need to make sure both sides are sampling the data <em>at the same rate</em>, and that both sample clocks are <em>synchronized enough</em> that you're sampling at the right point. Many high-speed protocols deal with this using a technique called <em>clock recovery</em>, which essentially means that each receiver looks at the data it receives and tries to figure out what the clock that produced it looks like.</p>
<p>If both sides have agreed on a clock rate, this can be simple, in theory: if the receiver sees a change in its
received data, it can infer that that changed happened <em>on an active edge of the transmitter's clock</em>, and so it can start to figure out how to align its internal clock with the transmitter's.</p>
<p>This introduces another protocol requirement: <strong>for <em>clock recovery</em> to work, the data has to change frequently enough that the two sides can keep synchronized</strong>. At 5GT/s and high data throughputs, there's not much time for clocks to become synchronized when a packet is received; accordingly, it's important that data is encoded with lots of transitions, even when the line is idle.</p>
<p><strong>To ensure both <em>DC-Balance</em> and <em>sufficient transition density</em>, USB3 uses a method of encoding called 8b10b encoding.</strong>
In this encoding scheme, every single byte of data is transmitted as ten bits, with encodings chosen so that:</p>
<ul>
<li>A typical data byte can be transmitted <em>either</em> as a code with <em>one more one than zero</em>, or <em>one more zero than one</em>.
This allows the transmitter to choose between the two encodings, in order to keep the data stream at 50% ones.</li>
<li>Every valid encoding has sufficient <em>transition density</em> to ensure that it's useful for clock recovery.</li>
</ul>
<p>I won't go into more 8b10b background here, but you can read about the typical IBM implementation <a href="https://en.wikipedia.org/wiki/8b/10b_encoding">on wikipedia</a>.</p>
<h5 id="its-hard-to-run-both-sides-of-the-link-at-the-same--clock-rate-">It's hard to run both sides of the link at the same <em>clock rate</em>.</h5>
<p>Even with successful <em>clock recovery</em>, it's difficult to have both sides of the link produce and consume data at
the same rate. Each side's internal logic is running off of its own <em>clock source</em>; and every clock has a bit of deviation from its nominal frequency. For the protocol to function despite these differences, the USB3 specification allows each clock to deviate from its nominal value by up to a certain <em>tolerance</em>; and specifies a method for compensating for this tolerance. This technique is appropriately named <em>clock tolerance compensation</em>, or CTC.</p>
<p><strong>To compensate for mismatches in sender/receiver clock rates, USB3 requires senders to periodically insert filler data into their transmitted data-stream</strong>. Receivers can then discard this data; allowing a brief pause in which the slower
side of the link can “catch up”. For this to be useful, the filler data (called ‘skip sets’) must be sent regularly;
which means additional logic on the transmitter side for insertion, and additional logic on the receiver side for
removal.</p>
<h5 id="its-hard-to-deal-with-varying-electrical-properties-of-different-transmitters-receivers-and-cables">It's hard to deal with varying electrical properties of different transmitters, receivers, and cables.</h5>
<p>When operating at very high frequencies, all of the little non-idealities along your transmission path really add up. At slower data rates, there's plenty of time for digital signals to “settle” after a change; making the non-ideal properties of your transmission lines less important. The faster your data gets, the more important it is for your data
to reach a “readable” value quickly.</p>
<p>To help with this, most high-speed receivers employ a technique called <em>receiver equalization</em>, which uses analog hardware
to help reshape signal transitions, so they can be more reliably sampled. Equalization helps to “cancel out” some of the ways the non-ideal transmission path adversely affects the signal.</p>
<figure>
    <img src="https://lab.ktemkin.com/post-media/why-is-usb3-harder/eye.png" alt="diagram showing a variety of slow rises and falls; illustrating that the physical link slows transitions"> <figcaption>
            <h4>From the USB3.2 specification: an 'eye diagram', which shows an overlay of many rising and falling transitions, illustrating how non-ideal properties affect the link.</h4>
        </figcaption>
</figure>

<p>Since every transmission path is different – due to different transmitter, receiver, and cable properties – it's impossible to create a single “one size fits all” equalizer. Instead, each USB3 equalizer needs to be tuned to its transmission path via a process called <em>link training</em>.</p>
<p><strong>At the start of each USB3 communication, link partners repeatedly exchange collections of known data called <em>training sets</em>, which give the opportunity for each side to tune their equalizer.</strong> Training sets include both sets of data chosen to have high transition density and sets designed to include a wide range of “normally-distributed” data.</p>
<p>During a few milliseconds of data exchange – an eternity in fast-protocol terms – both sides of the link gradually
tweak their equalizer settings until they're clearly seeing the expected values from the other side.</p>
<h5 id="its-hard-not-to-generate-harmful-interference">It's hard not to generate harmful interference.</h5>
<p>USB3 has a very high transition rate – it easily qualifies as high radio-frequency signaling – and its link
often tends to exchange repeating data. This has a nasty side effect: even a well-functioning link can act as an
antenna; unintentionally emitting RF that can interfere with nearby systems. The more repeating elements this signaling
has, the more troublesome the interference tends to be.</p>
<p><strong>To reduce the amount of harmful interference generated, USB3 links use a technique called <em>scrambling</em>, in which data is XOR'd with a fixed pattern before transmission.</strong> The receiver is then capable of applying the same transform to <em>descramble</em> the data stream, recovering the relevant data.</p>
<p>You can think of scrambling as being very similar to encryption – except everyone knows the key. Once data is scrambled, it looks a lot more like “random numbers” than the pre-scrambling data – and accordingly, it's a lot less likely to
generate troublesome interference. Once the scrambled data travels the link, it can be <em>descrambled</em> by the receiving end – a process similar to decryption – restoring the original data stream.</p>
<h5 id="in-summary">In summary…</h5>
<p>In summary, before you can even exchange meaningful data, the digital side of your device needs:</p>
<ul>
<li><strong>8b10b encoding and decoding hardware</strong>, so the data exchanged is <em>DC-balanced</em> and contains sufficient transitions as to allow <em>clock recovery</em>;</li>
<li><strong>Clock Tolerance Compensation hardware</strong>, which allows the two sides to communicate even with slightly-varying clock frequencies;</li>
<li>Hardware to orchestrate <strong>link training</strong> and <strong>receiver equalization</strong>, which helps to deal with non-ideal transmission properties;</li>
<li><strong>Scrambling</strong> and <strong>descrambling</strong> hardware, which help to reduce harmful interference.</li>
</ul>
<p>This omits a few minor things, such as USB3's <em>Low Frequency Periodic Signaling</em>; but these are the major components.</p>
<h5 id="oh-and-one-more-thing-its-hard-to-get-good-resources">Oh, and one more thing: it's hard to get good resources.</h5>
<p>Finally, ignoring all the physical layer challenges associated with bringing a link up, there's one more major obstacle: it's hard to get good resources for working with USB3:</p>
<ul>
<li>Most hardware enabling custom USB designs is expensive; and <a href="https://lab.ktemkin.com/post/ab07-usb3fmc-wtf/">still rife with issues</a>.</li>
<li>Most USB3 tooling is <a href="https://www.totalphase.com/products/beagle-usb5000-v2-ultimate/">very expensive</a>, and still rife with issues.</li>
<li>There's very little documentation in support of the specification; and what documentation exists still hasn't been
used enough to <a href="https://lab.ktemkin.com/post/mindshare-usb3/">identify all of its errors</a>.</li>
</ul>
<p>Hopefully, at some point, I'll have built enough tooling to change this.</p>


  </article></div>]]>
            </description>
            <link>https://lab.ktemkin.com/post/why-is-usb3-harder/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24704298</guid>
            <pubDate>Wed, 07 Oct 2020 01:11:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DOMPurify bypass: XSS via HTML namespace confusion]]>
            </title>
            <description>
<![CDATA[
Score 159 | Comments 80 (<a href="https://news.ycombinator.com/item?id=24703230">thread link</a>) | @fanf2
<br/>
October 6, 2020 | https://research.securitum.com/mutation-xss-via-mathml-mutation-dompurify-2-0-17-bypass/ | <a href="https://web.archive.org/web/*/https://research.securitum.com/mutation-xss-via-mathml-mutation-dompurify-2-0-17-bypass/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1639">
	<!-- .entry-header -->

	
	<div>
		
<p>In this blogpost I’ll explain my recent bypass in <a href="https://github.com/cure53/DOMPurify/">DOMPurify</a> – the popular HTML sanitizer library. In a nutshell, DOMPurify’s job is to take an untrusted HTML snippet, supposedly coming from an end-user, and remove all elements and attributes that can lead to Cross-Site Scripting (XSS).</p>



<p>This is the bypass:</p>



<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-5f80c7ddc0fd2531893482" data-settings=" minimize scroll-mouseover">
		
			
			
			
			<div>
				<table>
					<tbody><tr>
				<td data-settings="show">
					
				</td>
						<td><div><p><span>&lt;</span><span>form</span><span>&gt;</span></p><p><span>&lt;</span><span>math</span><span>&gt;</span><span>&lt;</span><span>mtext</span><span>&gt;</span></p><p><span>&lt;</span><span>/</span><span>form</span><span>&gt;</span><span>&lt;</span><span>form</span><span>&gt;</span></p><p><span>&lt;</span><span>mglyph</span><span>&gt;</span></p><p><span>&lt;</span><span>style</span><span>&gt;</span><span>&lt;</span><span>/</span><span>math</span><span>&gt;</span><span>&lt;</span><span>img </span><span>src </span><span>onerror</span><span>=</span><span>alert</span><span>(</span><span>1</span><span>)</span><span>&gt;</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
		</div>
<!-- [Format Time: 0.0004 seconds] -->




<p>Believe me that there’s not a single element in this snippet that is superfluous 🙂 </p>



<p>To understand why this particular code worked, I need to give you a ride through some interesting features of HTML specification that I used to make the bypass work.</p>



<h2>Usage of DOMPurify</h2>



<p>Let’s begin with the basics, and explain how DOMPurify is usually used. Assuming that we have an untrusted HTML in <code>htmlMarkup</code> and we want to assign it to a certain <code>div</code>, we use the following code to sanitize it using DOMPurify and assign to the <code>div</code>:</p>



<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-5f80c7ddc0fd9589762198" data-settings=" minimize scroll-mouseover">
		
			
			
			
			<div>
				<table>
					<tbody><tr>
				<td data-settings="show">
					
				</td>
						<td><div><p><span>div</span><span>.</span><span>innerHTML</span><span> </span><span>=</span><span> </span><span>DOMPurify</span><span>.</span><span>sanitize</span><span>(</span><span>htmlMarkup</span><span>)</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
		</div>
<!-- [Format Time: 0.0001 seconds] -->




<p>In terms of parsing and serializing HTML as well as operations on the DOM tree, the following operations happen in the short snippet above:</p>



<ol><li><code>htmlMarkup</code> is parsed into the DOM Tree.</li><li>DOMPurify sanitizes the DOM Tree (in a nutshell, the process is about walking through all elements and attributes in the DOM tree, and deleting all nodes that are not in the allow-list).</li><li>The DOM tree is serialized back into the HTML markup.</li><li>After assignment to <code>innerHTML</code>, the browser parses the HTML markup again.</li><li>The parsed DOM tree is appended into the DOM tree of the document.</li></ol>



<p>Let’s see that on a simple example. Assume that our initial markup is <code>A&lt;img src=1 onerror=alert(1)&gt;B</code>. In the first step it is parsed into the following tree:</p>



<figure><img src="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-1-1024x104.png" alt="" srcset="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-1-1024x104.png 1024w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-1-300x30.png 300w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-1-768x78.png 768w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-1-1536x155.png 1536w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-1-1320x134.png 1320w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-1.png 1956w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Then, DOMPurify sanitizes it, leaving the following DOM tree:</p>



<figure><img src="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-2-1024x107.png" alt="" srcset="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-2-1024x107.png 1024w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-2-300x31.png 300w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-2-768x80.png 768w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-2-1536x161.png 1536w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-2-1320x138.png 1320w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-2.png 1952w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Then it is serialized to:</p>



<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		
<!-- [Format Time: 0.0001 seconds] -->




<p>And this is what <code>DOMPurify.sanitize</code> returns. Then the markup is parsed again by the browser on assignment to innerHTML:</p>



<figure><img src="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-3-1024x107.png" alt="" srcset="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-3-1024x107.png 1024w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-3-300x31.png 300w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-3-768x80.png 768w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-3-1536x161.png 1536w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-3-1320x138.png 1320w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-3.png 1952w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>The DOM tree is identical to the one that DOMPurify worked on, and it is then appended to the document.</p>



<p>So to put it shortly, we have the following order of operations: <strong>parsing ➡️ serialization ➡️ parsing</strong>. The intuition may be that serializing a DOM tree and parsing it again should always return the initial DOM tree. But this is not true at all. There’s even <a href="https://html.spec.whatwg.org/multipage/parsing.html#serialising-html-fragments:escapingString-3:~:text=It%20is%20possible%20that%20the%20output,not%20return%20the%20original%20tree%20structure">a warning in the HTML spec</a> in a section about serializing HTML fragments:</p>



<blockquote><p>It is possible that the output of this algorithm [serializing HTML], if parsed with an HTML parser, will not return the original tree structure. <strong>Tree structures that do not roundtrip a serialize and reparse step can also be produced by the HTML parser itself</strong>, although such cases are typically non-conforming.</p></blockquote>



<p>The important take-away is that serialize-parse roundtrip is not guaranteed to return the original DOM tree (this is also a root cause of a type of XSS known as <strong>mutation XSS</strong>). While usually these situations are a result of some kind of parser/serializer error, there are at least two cases of spec-compliant mutations.</p>



<h2>Nesting FORM element</h2>



<p>One of these cases is related to the FORM element. It is quite special element in the HTML because it cannot be nested in itself. The specification is explicit that<a href="https://html.spec.whatwg.org/#the-form-element"> it cannot have any descendant that is also a FORM</a>:</p>



<figure><img src="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-4-1024x279.png" alt="" srcset="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-4-1024x279.png 1024w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-4-300x82.png 300w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-4-768x209.png 768w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-4-1536x419.png 1536w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-4-1320x360.png 1320w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-4.png 1936w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>This can be confirmed in any browser, with the following markup:</p>



<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-5f80c7ddc0fde730047119" data-settings=" minimize scroll-mouseover">
		
			
			
			
			<div>
				<table>
					<tbody><tr>
				<td data-settings="show">
					
				</td>
						<td><div><p><span>&lt;</span><span>form </span><span>id</span><span>=</span><span>form1</span><span>&gt;</span></p><p><span>INSIDE_FORM1</span></p><p><span>&lt;</span><span>form </span><span>id</span><span>=</span><span>form2</span><span>&gt;</span></p><p><span>INSIDE_FORM2</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
		</div>
<!-- [Format Time: 0.0001 seconds] -->




<p>Which would yield the following DOM tree:</p>



<figure><img src="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-5-1024x80.png" alt="" srcset="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-5-1024x80.png 1024w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-5-300x24.png 300w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-5-768x60.png 768w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-5-1536x121.png 1536w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-5-1320x104.png 1320w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-5.png 1960w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>The second <code>form</code> is completely omitted in the DOM tree just as it wasn’t ever there.</p>



<p>Now comes the interesting part. If we keep reading the HTML specification, it actually gives <a href="https://html.spec.whatwg.org/multipage/parsing.html#serialising-html-fragments:the-script-element-4:~:text=DOM.-,For%20example%2C%20consider%20the%20following%20markup%3A,%3Cform">an example</a> that with a slightly broken markup with mis-nested tags, it is possible to create nested forms. Here it comes (taken directly from the spec):</p>



<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-5f80c7ddc0fe2033786425" data-settings=" minimize scroll-mouseover">
		
			
			
			
			<div>
				<table>
					<tbody><tr>
				<td data-settings="show">
					
				</td>
						<td><div><p><span>&lt;</span><span>form </span><span>id</span><span>=</span><span>"outer"</span><span>&gt;</span><span>&lt;</span><span>div</span><span>&gt;</span><span>&lt;</span><span>/</span><span>form</span><span>&gt;</span><span>&lt;</span><span>form </span><span>id</span><span>=</span><span>"inner"</span><span>&gt;</span><span>&lt;</span><span>input</span><span>&gt;</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
		</div>
<!-- [Format Time: 0.0002 seconds] -->




<p>It yields the following DOM tree, which contains a nested form element:</p>



<figure><img src="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-6-1024x141.png" alt="" srcset="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-6-1024x141.png 1024w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-6-300x41.png 300w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-6-768x106.png 768w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-6-1536x211.png 1536w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-6-1320x182.png 1320w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-6.png 1948w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>This is not a bug in any particular browser; it results directly from the HTML spec, and is described in the algorithm of parsing HTML. Here’s the general idea:</p>



<ul><li>When you open a <code>&lt;form&gt;</code> tag, the parser needs to keep record of the fact that it was opened with a <strong>form element pointer</strong> (that’s how it’s called in the spec). If the pointer is not <code>null</code>, then <code>form</code> element cannot be created.</li><li>When you end a <code>&lt;form&gt;</code> tag, the form element pointer is always set to <code>null</code>. </li></ul>



<p>Thus, going back to the snippet:</p>



<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-5f80c7ddc0fe3446990181" data-settings=" minimize scroll-mouseover">
		
			
			
			
			<div>
				<table>
					<tbody><tr>
				<td data-settings="show">
					
				</td>
						<td><div><p><span>&lt;</span><span>form </span><span>id</span><span>=</span><span>"outer"</span><span>&gt;</span><span>&lt;</span><span>div</span><span>&gt;</span><span>&lt;</span><span>/</span><span>form</span><span>&gt;</span><span>&lt;</span><span>form </span><span>id</span><span>=</span><span>"inner"</span><span>&gt;</span><span>&lt;</span><span>input</span><span>&gt;</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
		</div>
<!-- [Format Time: 0.0002 seconds] -->




<p>In the beginning, the form element pointer is set to the one with <code>id="outer"</code>. Then, a <code>div</code> is being started, and the <code>&lt;/form&gt;</code> end tag set the form element pointer to <code>null</code>. Because it’s <code>null</code>, the next form with <code>id="inner"</code> can be created; and because we’re currently within <code>div</code>, we effectively have a <code>form</code> nested in <code>form</code>.</p>



<p>Now, if we try to serialize the resulting DOM tree, we’ll get the following markup:</p>



<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-5f80c7ddc0fe5853704634" data-settings=" minimize scroll-mouseover">
		
			
			
			
			<div>
				<table>
					<tbody><tr>
				<td data-settings="show">
					
				</td>
						<td><div><p><span>&lt;</span><span>form </span><span>id</span><span>=</span><span>"outer"</span><span>&gt;</span><span>&lt;</span><span>div</span><span>&gt;</span><span>&lt;</span><span>form </span><span>id</span><span>=</span><span>"inner"</span><span>&gt;</span><span>&lt;</span><span>input</span><span>&gt;</span><span>&lt;</span><span>/</span><span>form</span><span>&gt;</span><span>&lt;</span><span>/</span><span>div</span><span>&gt;</span><span>&lt;</span><span>/</span><span>form</span><span>&gt;</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
		</div>
<!-- [Format Time: 0.0002 seconds] -->




<p>Note that this markup no longer has any mis-nested tags. And when the markup is parsed again, the following DOM tree is created:</p>



<figure><img src="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-7-1024x101.png" alt="" srcset="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-7-1024x101.png 1024w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-7-300x30.png 300w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-7-768x76.png 768w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-7-1536x151.png 1536w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-7-2048x202.png 2048w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-7-1320x130.png 1320w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>So this is a proof that serialize-reparse roundtrip is not guaranteed to return the original DOM tree. And even more interestingly, this is basically <strong>a spec-compliant mutation</strong>.</p>



<p>Since the very moment I was made aware of this quirk, I’ve been pretty sure that it must be possible to somehow abuse it to bypass HTML sanitizers. And after a long time of not getting any ideas of how to make use of it, I finally stumbled upon another quirk in HTML specification. But before going into the specific quirk itself, let’s talk about my favorite Pandora’s box of the HTML specification: foreign content.</p>



<h2>Foreign content</h2>



<p>Foreign content is a like a Swiss Army knife for breaking parsers and sanitizers. I used it in my <a href="https://research.securitum.com/dompurify-bypass-using-mxss/">previous DOMPurify bypass</a> as well as in <a href="https://research.securitum.com/html-sanitization-bypass-in-ruby-sanitize-5-2-1/">bypass of Ruby sanitize library</a>.</p>



<p>The HTML parser can create a DOM tree with elements of three namespaces:</p>



<ul><li>HTML namespace (<code>http://www.w3.org/1999/xhtml</code>)</li><li>SVG namespace (<code>http://www.w3.org/2000/svg</code>)</li><li>MathML namespace (<code>http://www.w3.org/1998/Math/MathML</code>)</li></ul>



<p>By default, all elements are in HTML namespace; however if the parser encounters <code>&lt;svg&gt;</code> or <code>&lt;math&gt;</code> element, then it “switches” to SVG and MathML namespace respectively. And both these namespaces make foreign content.</p>



<p>In foreign content markup is parsed differently than in ordinary HTML. This can be most clearly shown on parsing of <code>&lt;style&gt;</code> element. In HTML namespace, <code>&lt;style&gt;</code> can only contain text; no descendants, and HTML entities are not decoded. The same is not true in foreign content: foreign content’s <code>&lt;style&gt;</code> can have child elements, and entities are decoded.</p>



<p>Consider the following markup:</p>



<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-5f80c7ddc0fe7468827382" data-settings=" minimize scroll-mouseover">
		
			
			
			
			<div>
				<table>
					<tbody><tr>
				<td data-settings="show">
					
				</td>
						<td><div><p><span>&lt;style&gt;</span><span>&lt;a&gt;</span><span>ABC&lt;/style&gt;</span><span>&lt;</span><span>svg</span><span>&gt;</span><span>&lt;</span><span>style</span><span>&gt;</span><span>&lt;</span><span>a</span><span>&gt;</span><span>ABC</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
		</div>
<!-- [Format Time: 0.0005 seconds] -->




<p>It is parsed into the following DOM tree</p>



<figure><img src="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-8-1024x206.png" alt="" srcset="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-8-1024x206.png 1024w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-8-300x60.png 300w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-8-768x154.png 768w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-8-1536x308.png 1536w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-8-1320x265.png 1320w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-8.png 1962w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p><strong>Note:</strong> from now on, all elements in the DOM tree in this blogpost will contain a namespace. So <code>html style</code> means that it is a <code>&lt;style&gt;</code> element in HTML namespace, while <code>svg style</code> means that it is a <code>&lt;style&gt;</code> element in SVG namespace.</p>



<p>The resulting DOM tree proves my point: <code>html style</code> has only text content, while <code>svg style</code> is parsed just like an ordinary element.</p>



<p>Moving on, it may be tempting to make a certain observation. That is: if we are inside <code>&lt;svg&gt;</code> or <code>&lt;math&gt;</code> then all elements are also in non-HTML namespace. But this is not true. There are certain elements in HTML specification called <strong>MathML text integration points</strong> and <strong>HTML integration point</strong>. And the children of these elements have HTML namespace (with certain exceptions I’m listing below).</p>



<p>Consider the following example:</p>



<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-5f80c7ddc0fe9859207437" data-settings=" minimize scroll-mouseover">
		
			
			
			
			<div>
				<table>
					<tbody><tr>
				<td data-settings="show">
					
				</td>
						<td><div><p><span>&lt;</span><span>math</span><span>&gt;</span></p><p><span>&lt;style&gt;</span><span>&lt;/style&gt;</span></p><p><span>&lt;</span><span>mtext</span><span>&gt;</span><span>&lt;style&gt;</span><span>&lt;/style&gt;</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
		</div>
<!-- [Format Time: 0.0001 seconds] -->




<p>It is parsed into the following DOM tree:</p>



<figure><img src="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-9-1024x138.png" alt="" srcset="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-9-1024x138.png 1024w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-9-300x40.png 300w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-9-768x104.png 768w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-9-1536x207.png 1536w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-9-1320x178.png 1320w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-9.png 1956w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Note how the <code>style</code> element that is a direct child of <code>math</code> is in MathML namespace, while the <code>style</code> element in <code>mtext</code> is in HTML namespace. And this is because <code>mtext</code> is <strong>MathML text integration points</strong> and makes the parser switch namespaces. </p>



<p>MathML text integration points are:</p>



<ul><li><code>math mi</code></li><li><code>math mo</code></li><li><code>math mn</code></li><li><code>math ms</code></li></ul>



<p>HTML integration points are:</p>



<ul><li><code>math annotation-xml</code> if it has an attribute called <code>encoding</code> whose value is equal to either <code>text/html</code> or <code>application/xhtml+xml</code></li><li><code>svg foreignObject</code></li><li><code>svg desc</code></li><li><code>svg title</code></li></ul>



<p>I always assumed that all children of MathML text integration points or HTML integration points have HTML namespace by default. How wrong was I! The HTML specification says that children of MathML text integration points are by default in HTML namespace with two exceptions: <code>mglyph</code> and <code>malignmark</code>. And this only happens if they are a direct child of MathML text integration points.</p>



<p>Let’s check that with the following markup:</p>



<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-5f80c7ddc0feb289280684" data-settings=" minimize scroll-mouseover">
		
			
			
			
			<div>
				<table>
					<tbody><tr>
				<td data-settings="show">
					
				</td>
						<td><div><p><span>&lt;</span><span>math</span><span>&gt;</span></p><p><span>&lt;</span><span>mtext</span><span>&gt;</span></p><p><span>&lt;</span><span>mglyph</span><span>&gt;</span><span>&lt;</span><span>/</span><span>mglyph</span><span>&gt;</span></p><p><span>&lt;</span><span>a</span><span>&gt;</span><span>&lt;</span><span>mglyph</span><span>&gt;</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
		</div>
<!-- [Format Time: 0.0001 seconds] -->




<figure><img src="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-10-1024x168.png" alt="" srcset="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-10-1024x168.png 1024w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-10-300x49.png 300w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-10-768x126.png 768w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-10-1536x252.png 1536w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-10-1320x217.png 1320w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-10.png 1974w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Notice that <code>mglyph</code> that is a direct child of <code>mtext</code> is in MathML namespace, while the one that is a child of <code>html a</code> element is in HTML namespace.</p>



<p>Assume that we have a “current element”, and we’d like determine its namespace. I’ve compiled some rules of thumb:</p>



<ul><li>Current element is in the namespace of its parent unless conditions from the points below are met.</li><li>If current element is <code>&lt;svg&gt;</code> or <code>&lt;math&gt;</code> and parent is in HTML namespace, then current element is in SVG or MathML namespace respectively.</li><li>If parent of current element is an HTML integration point, then current element is in HTML namespace unless it’s <code>&lt;svg&gt;</code> or <code>&lt;math&gt;</code>.</li><li>If parent of current element is an MathML integration point, then current element is in HTML namespace unless it’s <code>&lt;svg&gt;</code>, <code>&lt;math&gt;</code>, <code>&lt;mglyph&gt;</code> or <code>&lt;malignmark&gt;</code>.</li><li>If current element is one of <code>&lt;b&gt;, &lt;big&gt;, &lt;blockquote&gt;, &lt;body&gt;, &lt;br&gt;, &lt;center&gt;, &lt;code…</code></li></ul></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://research.securitum.com/mutation-xss-via-mathml-mutation-dompurify-2-0-17-bypass/">https://research.securitum.com/mutation-xss-via-mathml-mutation-dompurify-2-0-17-bypass/</a></em></p>]]>
            </description>
            <link>https://research.securitum.com/mutation-xss-via-mathml-mutation-dompurify-2-0-17-bypass/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24703230</guid>
            <pubDate>Tue, 06 Oct 2020 22:43:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quest for the Whistler Button]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 20 (<a href="https://news.ycombinator.com/item?id=24702444">thread link</a>) | @josecastillo
<br/>
October 6, 2020 | https://newscrewdriver.com/2020/10/06/quest-for-the-whistler-button/ | <a href="https://web.archive.org/web/*/https://newscrewdriver.com/2020/10/06/quest-for-the-whistler-button/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>I’m a fan of physical, tactile buttons that provide visual feedback. I realize the current trend favors capacitive touch, but I love individual buttons I can find by feel. And one of the best looking buttons I’ve seen was from the 1992 movie <em><a rel="noreferrer noopener" href="https://www.imdb.com/title/tt0105435/" target="_blank">Sneakers</a></em>. When the blind character Whistler used a Braille-labeled device to add a sound effect representing the “thump” sound of a car going over seams of a concrete bridge.</p>



<p>They were only on screen for a few seconds, but I was enamored with the black buttons, each with a corresponding red LED. The aesthetics reminded me of <em>2001</em>, like the eye of HAL in a mini monolith. Or maybe Darth Vader, if the Sith lord were a button. When I first watched the movie many years ago, I thought they were neat and left it at that. But in recent years I’ve started building electronics projects. So when I rewatched the movie recently and saw them again, I decided to research these buttons.</p>



<p>The first step is to determine if they were even a thing. All we saw was the front control panel of an unknown device. It was possible the buttons and LEDs were unrelated components sitting adjacent to each other on the circuit board, and only visually tied together by pieces of plastic custom-made for the device. So the first step was to find that device. There was a label at the bottom of the panel below Whistler’s hand, but due to the shallow depth of field I could only make out the end as “… 2002 digital sampler”. Time to hit the internet and see if anyone recognized the machine.</p>



<p>The first step is <a href="https://www.imdb.com/title/tt0105435/trivia" target="_blank" rel="noreferrer noopener">the Trivia section</a> of the movie’s page on Internet Movie Database where people contribute random and minute pieces of information. Firearms enthusiasts can usually be counted on to name specific guns used in a film, and automotive enthusiasts frequently contribute make and model of cars as well.</p>



<p>Sadly, the electronics audio enthusiasts have not felt fit to contribute to this page, so I went elsewhere on the internet trying various keyword combinations of “Sneakers”, “Whistler”, “sampler”, etc. The answer was found in <a rel="noreferrer noopener" href="https://hackaday.com/2017/09/15/sneakers-a-love-fest/#comment-4015147" target="_blank">a comment to a Hackaday post about the movie</a>. I’ve complained a lot about the general quality of internet comments, but this time one person’s nitpicking correction is my rare nugget of gold.</p>



<p>Whistler’s device is a <a rel="noreferrer noopener" href="https://encyclotronic.com/synthesizers/sequential-circuits/prophet-2002-r469/" target="_blank">Sequential Circuits Prophet 2002 Digital Sampler rack</a>. As befitting the movie character, the sampler’s control panel had Braille labels covering the default text. But otherwise it appears relatively unmodified for the movie. I wish the pictures were higher resolution, but their arrangement strongly implies the button and LED are part of a single subcomponent. The strongest evidence came from the presence of four vertical axis buttons, rotated 90 degrees from the rest.</p>



<blockquote><p><em>Aside: On the far right of the control panel, we can see a sign of the era, a 3.5″ floppy drive for data storage.</em></p></blockquote>



<p>Encouraged by this find, I started searching for Prophet 2002 buttons. I quickly found an eBay community offering replacement parts for Sequential Circuits products <a rel="noreferrer noopener" href="https://www.ebay.com/itm/Sequential-Circuits-Prophet-VS-Prophet-2002-Black-Switch-with-led/224163004481" target="_blank">including these buttons</a>. What’s intriguing to me is that these are sold in “New” condition, not surplus or salvaged from old units. I’m optimistically interpreting this as a hint these buttons might still be in production, decades after the Prophet 2002 was released in 1985.</p>



<p>Thanks to those eBay listings, I have seen a picture of the component by itself and it is exactly what I hoped it would be: the button’s exterior surface, the electric switch itself, and the LED are integrated into a single through-hole component. Given the tantalizing possibility it is still in active production and something I can buy for my own projects, I went next to electronics supplier Digi-Key.</p>



<p>Digi-Key carries 305,212 components under its “<a rel="noreferrer noopener" href="https://www.digikey.com/en/products/category/switches/15" target="_blank">Switches</a>” section, not practical for individual manual review. Fortunately there are subsections and I first tried “<a href="https://www.digikey.com/en/products/filter/tactile-switches/197">Tactile Switches</a>” (5721 items) because those buttons look like they’d give a good tactile response. In the movie we also heard a satisfying click when the button was pressed, but I don’t know if that was added later by the film’s sound mixer.</p>



<p>Within the “Tactile Switches” section, I aggressively filtered by the most optimistic wish they are active and in stock:</p>



<ul><li>Part Status: Active</li><li>Stocking Options: In Stock</li><li>Illumination: Illuminated</li><li>Illuminator: LED, Red</li></ul>



<p>That dropped it to 76 candidates. Almost all of them carried their illumination under the button instead of adjacent to it. The closest candidate is a JF Series switch by NKK Switches, the <a rel="noreferrer noopener" href="https://www.digikey.com/en/products/detail/nkk-switches/JF15RP3HC/2104244" target="_blank">JF15RP3HC which has a Digi-Key part number 360-3284-ND</a>.</p>



<figure><img data-attachment-id="23048" data-permalink="https://newscrewdriver.com/nkk-jf15rp3hc-illuminated-switch/" data-orig-file="https://newscrewdriver.files.wordpress.com/2020/10/nkk-jf15rp3hc-illuminated-switch.jpg" data-orig-size="948,643" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="nkk-jf15rp3hc-illuminated-switch" data-image-description="" data-medium-file="https://newscrewdriver.files.wordpress.com/2020/10/nkk-jf15rp3hc-illuminated-switch.jpg?w=300" data-large-file="https://newscrewdriver.files.wordpress.com/2020/10/nkk-jf15rp3hc-illuminated-switch.jpg?w=700" src="https://newscrewdriver.files.wordpress.com/2020/10/nkk-jf15rp3hc-illuminated-switch.jpg?w=948" alt="" srcset="https://newscrewdriver.files.wordpress.com/2020/10/nkk-jf15rp3hc-illuminated-switch.jpg 948w, https://newscrewdriver.files.wordpress.com/2020/10/nkk-jf15rp3hc-illuminated-switch.jpg?w=150 150w, https://newscrewdriver.files.wordpress.com/2020/10/nkk-jf15rp3hc-illuminated-switch.jpg?w=300 300w, https://newscrewdriver.files.wordpress.com/2020/10/nkk-jf15rp3hc-illuminated-switch.jpg?w=768 768w" sizes="(max-width: 948px) 100vw, 948px"></figure>



<p>It is a more modern and refined variant of the same concept. The button is sculpted, and the illuminated portion sits flush with the surroundings. This would be a great choice if I was updating the design, but I am chasing a specific aesthetic and this switch does not look like a monolith or Vader.</p>



<p>So that wasn’t too bad, but I’m not ready to stop. Peer to “Tactile Switches” are several other subsections worth investigating. I next went to “<a rel="noreferrer noopener" href="https://www.digikey.com/en/products/filter/pushbutton-switches/199" target="_blank">Pushbutton Switches</a>” (175,722 items) and applied the following filters. Again starting with the optimistic wish they are active and in stock:</p>



<ul><li>Part Status: Active</li><li>Stocking Options: In Stock</li><li>Type: Keyswitch, Illuminated</li><li>Illumination Type, Color: LED, Red</li></ul>



<p>That filter cut the number of possibilities from 175,722 down to 21 which felt like an overly aggressive shot in the dark, and I expected I would have to adjust the search. But it wouldn’t hurt to take a quick look over those 21 and my eyes widened when I saw that list. Most of the 21 results had a very similar aesthetic and would make an acceptable substitute, but that would not be necessary because I saw the Omron B3J-2100.</p>



<figure><img data-attachment-id="23053" data-permalink="https://newscrewdriver.com/pushbutton-switches-illuminated-led-red/" data-orig-file="https://newscrewdriver.files.wordpress.com/2020/10/pushbutton-switches-illuminated-led-red.jpg" data-orig-size="1639,925" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="pushbutton-switches-illuminated-led-red" data-image-description="" data-medium-file="https://newscrewdriver.files.wordpress.com/2020/10/pushbutton-switches-illuminated-led-red.jpg?w=300" data-large-file="https://newscrewdriver.files.wordpress.com/2020/10/pushbutton-switches-illuminated-led-red.jpg?w=700" src="https://newscrewdriver.files.wordpress.com/2020/10/pushbutton-switches-illuminated-led-red.jpg?w=1024" alt="" srcset="https://newscrewdriver.files.wordpress.com/2020/10/pushbutton-switches-illuminated-led-red.jpg?w=1024 1024w, https://newscrewdriver.files.wordpress.com/2020/10/pushbutton-switches-illuminated-led-red.jpg?w=150 150w, https://newscrewdriver.files.wordpress.com/2020/10/pushbutton-switches-illuminated-led-red.jpg?w=300 300w, https://newscrewdriver.files.wordpress.com/2020/10/pushbutton-switches-illuminated-led-red.jpg?w=768 768w, https://newscrewdriver.files.wordpress.com/2020/10/pushbutton-switches-illuminated-led-red.jpg 1639w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Yes, I’ve hit the jackpot! Even if that isn’t precisely the correct replacement for a Prophet 2002 sampler, it has the right aesthetics: a dark angular block with the round LED poking out. But now that I’ve found the component, I can perform web searches with its name to confirm that others have also decided <a rel="noreferrer noopener" href="https://www.gearslutz.com/board/electronic-music-instruments-and-electronic-music-production/871589-few-words-refurbishing-sequential-digital-gear.html" target="_blank">Omron B3J is the correct replacement</a>.</p>



<figure><img data-attachment-id="23056" data-permalink="https://newscrewdriver.com/omron-b3j-list-of-models/" data-orig-file="https://newscrewdriver.files.wordpress.com/2020/10/omron-b3j-list-of-models.jpg" data-orig-size="1482,906" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="omron-b3j-list-of-models" data-image-description="" data-medium-file="https://newscrewdriver.files.wordpress.com/2020/10/omron-b3j-list-of-models.jpg?w=300" data-large-file="https://newscrewdriver.files.wordpress.com/2020/10/omron-b3j-list-of-models.jpg?w=700" src="https://newscrewdriver.files.wordpress.com/2020/10/omron-b3j-list-of-models.jpg?w=1024" alt="" srcset="https://newscrewdriver.files.wordpress.com/2020/10/omron-b3j-list-of-models.jpg?w=1024 1024w, https://newscrewdriver.files.wordpress.com/2020/10/omron-b3j-list-of-models.jpg?w=150 150w, https://newscrewdriver.files.wordpress.com/2020/10/omron-b3j-list-of-models.jpg?w=300 300w, https://newscrewdriver.files.wordpress.com/2020/10/omron-b3j-list-of-models.jpg?w=768 768w, https://newscrewdriver.files.wordpress.com/2020/10/omron-b3j-list-of-models.jpg 1482w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p><a rel="noreferrer noopener" href="https://omronfs.omron.com/en_US/ecb/products/pdf/en-b3j.pdf" target="_blank">Omron’s B3J datasheet</a> showed a list of models, where we can see variations on this design. The button is available in multiple colors, including this black unit and the blue also used by the Prophet 2002. The number and color of LEDs add to the possible combinations, from no LEDs (a few blue examples on a Prophet 2002 have no lights) to two lights in combinations of red, green, or yellow.</p>



<p>Sure, these switches are more expensive than the lowest bidder options on Amazon. But the price premium is a small price to pay when I’m specifically seeking this specific aesthetic. When I want the look that started me on this little research project, only the <a href="https://www.digikey.com/en/products/detail/omron-electronics-inc-emc-div/B3J-2100/700006" target="_blank" rel="noreferrer noopener">Omron B3J-2100</a> will do. And yeah, I’m going to call them “Whistler buttons”.</p>



<figure><img data-attachment-id="23051" data-permalink="https://newscrewdriver.com/omron-b3j-2100/" data-orig-file="https://newscrewdriver.files.wordpress.com/2020/10/omron-b3j-2100.jpg" data-orig-size="954,955" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="omron-b3j-2100" data-image-description="" data-medium-file="https://newscrewdriver.files.wordpress.com/2020/10/omron-b3j-2100.jpg?w=300" data-large-file="https://newscrewdriver.files.wordpress.com/2020/10/omron-b3j-2100.jpg?w=700" src="https://newscrewdriver.files.wordpress.com/2020/10/omron-b3j-2100.jpg?w=954" alt="" srcset="https://newscrewdriver.files.wordpress.com/2020/10/omron-b3j-2100.jpg 954w, https://newscrewdriver.files.wordpress.com/2020/10/omron-b3j-2100.jpg?w=150 150w, https://newscrewdriver.files.wordpress.com/2020/10/omron-b3j-2100.jpg?w=300 300w, https://newscrewdriver.files.wordpress.com/2020/10/omron-b3j-2100.jpg?w=768 768w" sizes="(max-width: 954px) 100vw, 954px"></figure>



<p>[Follow-up: This post became more popular than I had expected, and I’m glad I <a href="https://newscrewdriver.com/2020/10/07/a-delight-for-the-button-connoisseur/">made a lot of fellow button enthusiasts happy</a>.]</p>
			</div></div>]]>
            </description>
            <link>https://newscrewdriver.com/2020/10/06/quest-for-the-whistler-button/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24702444</guid>
            <pubDate>Tue, 06 Oct 2020 21:20:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hootsuite employee fired after speaking out about company's ICE deal]]>
            </title>
            <description>
<![CDATA[
Score 64 | Comments 22 (<a href="https://news.ycombinator.com/item?id=24702114">thread link</a>) | @foofoo55
<br/>
October 6, 2020 | https://bc.ctvnews.ca/hootsuite-employee-fired-after-speaking-out-about-company-s-ice-deal-1.5135073 | <a href="https://web.archive.org/web/*/https://bc.ctvnews.ca/hootsuite-employee-fired-after-speaking-out-about-company-s-ice-deal-1.5135073">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>VANCOUVER -- 
	A Hootsuite employee who publicly criticized the company's decision to work with U.S. Immigration and Customs Enforcement has lost her job.</p>
<p>
	Sam Anderson said she was let go on Monday, less than two weeks after she spoke out about Hootsuite's three-year contract with ICE, which has since been called off.</p>
<p>
	"I'm not sure what I can and can't say about my departure, but I assume it's fair to say (and also probably obvious) that it was not my decision to leave," Anderson wrote on Twitter.</p>
<p>
	Anderson said she wouldn't be commenting further on her firing because "this has been an exhausting week and a half and I need to focus my energy on finding a new job."</p>
<p>
	Before going public with her concerns, Anderson was a senior training specialist with Hootsuite, according to her LinkedIn profile.</p>
<p>
	Anderson slammed the ICE deal in a series of tweets on Sept. 23, alleging that more than 100 Hootsuite employees had raised similar concerns about working with the government agency.</p>
<div data-attribute="embed_code">
<!--startPolopolyEmbed-->	<blockquote>
		<p dir="ltr" lang="en">
			As of yesterday morning I am no longer employed by Hootsuite. I’m not sure what I can and can’t say about my departure, but I assume it’s fair to say (and also probably obvious) that it was not my decision to leave.</p>
		— Sam | abolish the police (@samelaanderson) <a href="https://twitter.com/samelaanderson/status/1313515970195984384?ref_src=twsrc%5Etfw">October 6, 2020</a></blockquote>
<!--endPolopolyEmbed--></div>
<p>
	"That we are eagerly accepting money from an organization that is allegedly subjecting its female detainees to forced hysterectomies, that has a documented history of locking children in cages, that tears families apart and destroys lives is devastating and disgusting," she wrote at the time.</p>
<p>
	Hootsuite issued a statement the next day announcing that it was backing out of the ICE contract.</p>
<p>
	Asked about Anderson's departure on Tuesday, the company said it doesn't discuss employee status for privacy reasons, but "supports differences of thoughts and opinions within the company and firmly believes in engaging dialogue."</p>
<p>
	"We deeply value the trust of our employees, partners and customers. To that end we must be unequivocal in upholding our confidentiality obligations," Hootsuite said in an email statement.</p>
<p>
	Last month, CEO Tom Keiser shed some light on the company's original response to employee concerns about the ICE contract, which Anderson said they first learned about in June.</p>
<p>
	In a written statement, Keiser said the internal strife initially led Hootsuite to form a committee to "consider all points of view" on the deal, but that management decided to press forward with the contract anyway.</p>
<p>
	That changed in September following a "broad emotional and passionate reaction from our people," the CEO added.</p>
<p>
	"I – and the rest of the management team – share the concerns our people have expressed. As a result, we have decided to not proceed with the deal with ICE," Keiser said.</p>
<p>
	Immigration and Customs Enforcement prompted widespread outrage last year after it was revealed that six migrant children had died in federal custody over a period of months.</p>
<p>
	There has been more anger in recent weeks after several women alleged they were given hysterectomies without their consent while detained by ICE.</p>
                                              </div></div>]]>
            </description>
            <link>https://bc.ctvnews.ca/hootsuite-employee-fired-after-speaking-out-about-company-s-ice-deal-1.5135073</link>
            <guid isPermaLink="false">hacker-news-small-sites-24702114</guid>
            <pubDate>Tue, 06 Oct 2020 20:40:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Clarifying exceptions and visualizing tensor operations in deep learning code]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24701739">thread link</a>) | @parrt
<br/>
October 6, 2020 | https://explained.ai/tensor-sensor/index.html | <a href="https://web.archive.org/web/*/https://explained.ai/tensor-sensor/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">






<p><a href="http://parrt.cs.usfca.edu/">Terence Parr</a></p>

<p>(Terence teaches in <a href="https://www.usfca.edu/arts-sciences/graduate-programs/data-science">University of San Francisco's MS in Data Science program</a>. You might know Terence as the creator of the ANTLR parser generator.)</p>






<p>	Most people solve deep learning problems using high-level libraries such as <a href="https://keras.io/">Keras</a> or <a href="https://www.fast.ai/">fastai</a>,  which makes sense. These libraries hide a lot of implementation details that we either don't care about or can learn later.  To truly understand deep learning, however, I think it's important at some point to implement your own network layers and training loops. For example, see my recent article called <a href="https://explained.ai/rnn/index.html">Explaining RNNs without neural networks</a>. If you're comfortable building deep learning models while leaving some of the details a bit fuzzy, then this article is not for you.  In my quirky case, I care more about learning something deeply than actually applying it to something useful, so I go straight for the details. (I guess that's why I work at a university, not in industry ðŸ˜€.)  This article is in response to a pain point I experienced during an obsessive coding and learning burn through the fundamentals of deep learning in the isolation of Covid summer 2020.</p>

<center>
<a href="https://explained.ai/tensor-sensor/images/teaser.png">
<img src="https://explained.ai/tensor-sensor/images/teaser.png" width="40%" url="images/teaser.png">
</a>
</center>
One of the biggest challenges when writing code to implement deep learning networks, particularly for us newbies, is getting all of the tensor (matrix and vector) dimensions to line up properly. It's really easy to lose track of tensor dimensionality in complicated expressions involving multiple tensors and tensor operations.  Even when just feeding data into predefined <a href="https://www.tensorflow.org/">Tensorflow</a> network layers, we still need to get the dimensions right. When you ask for improper computations, you're going to run into some less than helpful exception messages.  To help myself and other programmers debug tensor code, I built a new library called <a href="https://github.com/parrt/tensor-sensor">TensorSensor</a> (<span>pip install tensor-sensor</span>).  TensorSensor clarifies exceptions by augmenting messages and visualizing Python code to indicate the shape of tensor variables (see figure to the right for a teaser). It works with <a href="https://www.tensorflow.org/">Tensorflow</a>, <a href="https://pytorch.org/">PyTorch</a>, and <a href="https://numpy.org/">Numpy</a>, as well as higher-level libraries like <a href="https://keras.io/">Keras</a> and <a href="https://www.fast.ai/">fastai</a>.

<p><i>TensorSensor is currently at 0.1b1 so I'm happy to receive issues created at the</i> <a href="https://github.com/parrt/tensor-sensor">repo</a> <i>or direct email</i>.</p>



<h2 id="sec:1.1">Isolating issues in tensor code is maddening!</h2>


<p>Even for experts, it can be hard to quickly identify the cause of an exception in a line of Python code performing tensor operations.  The debugging process usually involves adding a print statement in front of the offending line to emit the shape of each tensor operand.  That requires editing the code to create the debugging statement and rerunning the training process. Or, we can manually click or type commands to request all operand shapes using an interactive debugger. (This can be less practical in an IDE like PyCharm where executing code in debug mode seems to be much slower.)  The following subsections illustrate the anemic default exception messages and my proposed TensorSensor approach, rather than a debugger or print statements.</p>



<h3 id="sec:1.1.1">Debugging a simple linear layer</h3>


<p>Let's look at a simple tensor computation to illustrate the less-than-optimal information provided by the default exception message. Consider the following simple NumPy implementation for a hardcoded single (linear) network layer that contains a tensor dimension error.</p>


<p>import numpy as np

n = 200                          # number of instances
d = 764                          # number of instance features
n_neurons = 100                  # how many neurons in this layer?

W = np.random.rand(d,n_neurons)  # Ooops! Should be (n_neurons,d) &lt;=======
b = np.random.rand(n_neurons,1)
X = np.random.rand(n,d)          # fake input matrix with n rows of d-dimensions

Y = W @ X.T + b                  # pass all X instances through layer</p>


<p>Executing that code triggers an exception whose important elements are:</p>

<p>...
---&gt; 10 Y = W @ X.T + b
	
ValueError: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)-&gt;(n?,m?) (size 764 is different from 100)</p>


<p>The exception identifies the offending line and which operation (<span>matmul</span>: matrix multiply) but would be more useful if it gave the complete tensor dimensions. Also, the exception would be unable to distinguish between multiple matrix multiplications occurring in one line of Python.</p>

<p>Next, let's see how TensorSensor makes debugging that statement much easier. If we wrap the statement using a Python <span>with</span> statement and <span>tsensor</span>'s <span>clarify()</span>, we get a visualization and an augmented error message. </p>


<p>import tsensor
with tsensor.clarify():
    Y = W @ X.T + b</p>


<p>
<a href="https://explained.ai/tensor-sensor/images/numpy-mm-py.svg">
<img nocenter="true" src="https://explained.ai/tensor-sensor/images/numpy-mm-py.svg" url="images/numpy-mm-py.svg">
</a>
</p>

<p>...
ValueError: matmul: Input operand ...
Cause: @ on tensor operand W w/shape (764, 100) and operand X.T w/shape (764, 200)</p>


<p>It's clear from the visualization that <span>W</span>'s dimensions should be flipped to be <span>n_neurons x d</span>; the columns of <span>W</span> must match the rows of <span>X.T</span>. You can also checkout a <a href="https://explained.ai/tensor-sensor/images/numpy-mm.png">complete side-by-side image</a> with and without <span>clarify()</span> to see what it looks like in a notebook.</p>

<p>The <span>clarify()</span> functionality incurs no overhead on the executing program until an exception occurs. Upon exception, <span>clarify()</span>:</p>
<ol>
<li> Augments the exception object's message created by the underlying tensor library.</li>
<li> Gives a visual representation of the tensor sizes involved in the offending operation; only the operands and operator involved in the exception are highlighted, while the other Python elements are de-highlighted.</li>
</ol>
<p>TensorSensor also clarifies tensor-related exceptions raised by PyTorch and TensorFlow. Here are the equivalent code snippets and resulting augmented exception error messages (<span>Cause: @ on tensor ...</span>) and visualization from TensorSensor:</p>
<center>
<table>
<thead>
<tr>
<th>PyTorch</th><th>TensorFlow</th>
</tr>
</thead>
<tbody>
<tr>
<td>

<p>import torch
W = torch.rand(d,n_neurons)
b = torch.rand(n_neurons,1)
X = torch.rand(n,d)
with tsensor.clarify():
    Y = W @ X.T + b</p>

</td><td>

<p>import tensorflow as tf
W = tf.random.uniform((d,n_neurons))
b = tf.random.uniform((n_neurons,1))
X = tf.random.uniform((n,d))
with tsensor.clarify():
    Y = W @ tf.transpose(X) + b</p>

</td>
</tr>
<tr>
<td>

<a href="https://explained.ai/tensor-sensor/images/mm.svg">
<img nocenter="true" src="https://explained.ai/tensor-sensor/images/mm.svg" url="images/mm.svg">
</a>



<p>RuntimeError: size mismatch, m1: [764 x 100], m2: [764 x 200] at /tmp/pip-req-build-as628lz5/aten/src/TH/generic/THTensorMath.cpp:41
Cause: @ on tensor operand W w/shape [764, 100] and operand X.T w/shape [764, 200]</p>

</td><td>
<img src="https://explained.ai/tensor-sensor/images/tf-mm.svg" nocenter="true">

<p>InvalidArgumentError: Matrix size-incompatible: In[0]: [764,100], In[1]: [764,200] [Op:MatMul]
Cause: @ on tensor operand W w/shape (764, 100) and operand tf.transpose(X) w/shape (764, 200)</p>
</td>
</tr>
</tbody>
</table>
</center>
<p>The PyTorch message does not identify which operation triggered the exception, but TensorFlow's message does indicate matrix multiplication. Both show the operand dimensions. These default exception messages are probably good enough for this simple tensor expression for a linear layer. Still, it's easier to see the problem with the TensorSensor visualization.</p>

<p>You might be wondering, though, why tensor libraries don't generate a more helpful exception message that identified the names of the Python variables involved in the offending subexpression.  It's not that the library authors couldn't be bothered. The fundamental issue is that Python tensor libraries are wrappers around extremely efficient cores written in C or C++. Python passes, say, the data for two tensors to a C++ function, but not the associated tensor variable names in Python space. An exception caught deep in C++ has no access to the local and global variable spaces in Python, so it just throws a generic exception back over the fence.  Because Python traps exceptions at the statement level, it also cannot isolate the subexpression within the statement.  (To learn how TensorSensor manages to generate such specific messages, check out <b>Section</b> <i>Key TensorSensor implementation Kung Fu</i> below.)</p>



<h3 id="sec:1.1.2">Debugging a complex tensor expression</h3>


<p>That lack of specificity in default messages makes it hard to identify bad subexpressions within more complicated statements that contain lots of operators. For example, here's a statement pulled from the guts of a Gated Recurrent Unit (GRU) implementation:</p>


<p>h_ = torch.tanh(Whh_ @ (r*h) + Uxh_ @ X.T + bh_)</p>


<p>It doesn't matter what it's computing or what the variables represent, just that they are tensor variables. There are two matrix multiplications, two vector additions, and even a vector element-wise modification (<span>r*h</span>).  Without augmented error messages or visualizations we wouldn't know which operator and operands caused an exception. To demonstrate how TensorSensor clarifies exceptions in this case, we need to give some fake definitions for the variables used in the statement (the assignment to <span>h_</span>) to get executable code:</p>


<p>nhidden = 256
Whh_ = torch.eye(nhidden, nhidden)  # Identity matrix
Uxh_ = torch.randn(d, nhidden)
bh_  = torch.zeros(nhidden, 1)
h = torch.randn(nhidden, 1)         # fake previous hidden state h
r = torch.randn(nhidden, 1)         # fake this computation
X = torch.rand(n,d)                 # fake input

with tsensor.clarify():
    h_ = torch.tanh(Whh_ @ (r*h) + Uxh_ @ X.T + bh_)</p>


<p>Again, you can ignore the actual computation performed by the code to focus on the shape of the tensor variables.  </p>

<p>For most of us, it's impossible to identify the problem just by looking at the tensor dimensions and the tensor code.  The default exception message is helpful of course, but most of us will still struggle to identify the problem.  Here are the key bits of the default exception message (note the less-than-helpful reference to the C++ code):</p>

<p>---&gt; 10     h_ = torch.tanh(Whh_ @ (r*h) + Uxh_ @ X.T + bh_)
RuntimeError: size mismatch, m1: [764 x 256], m2: [764 x 200] at /tmp/pip-req-build-as628lz5/aten/src/TH/generic/THTensorMath.cpp:41
</p>


<p>What we need to know is which operator and operands failed, then we can look at the dimensions to identify the problem.  Here is TensorSensor's visualization and augmented exception message:</p>

<p>
<a href="https://explained.ai/tensor-sensor/images/torch-gru.svg">
<img nocenter="true" src="https://explained.ai/tensor-sensor/images/torch-gru.svg" url="images/torch-gru.svg">
</a>

</p><p>---&gt; 10 h_ = torch.tanh(Whh_ @ (r*h) + Uxh_ @ X.T + bh_)
RuntimeError: size mismatch, m1: [764 x 256], m2: [764 x 200] at …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://explained.ai/tensor-sensor/index.html">https://explained.ai/tensor-sensor/index.html</a></em></p>]]>
            </description>
            <link>https://explained.ai/tensor-sensor/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24701739</guid>
            <pubDate>Tue, 06 Oct 2020 20:01:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Simulating Machines in Clojure]]>
            </title>
            <description>
<![CDATA[
Score 159 | Comments 17 (<a href="https://news.ycombinator.com/item?id=24701737">thread link</a>) | @stopachka
<br/>
October 6, 2020 | https://stopa.io/post/255 | <a href="https://web.archive.org/web/*/https://stopa.io/post/255">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span><p><a href="https://twitter.com/stopachka/status/1295411936625074178" target="_blank">My cofounder Joe and I recently finished SICP.</a> It was a mind-bending experience: you start from just 3 concepts, and you recursively build up algebraic equation solvers, circuit simulators, 4 interpreters, and a compiler. </p><p>At some point you experience a visceral feeling: If you were dropped in a forest…you could create your own computer. The project that contributed most significantly to this feeling was creating a machine simulator.</p><p>We diverged from the book by writing the simulator in Clojure rather than Scheme. Immutable data structures and higher-level concepts available to us in Clojure compressed the solution, to the point where I think you can build your own in a few days worth of hacking.</p><p>This essay will guide you through doing just that: let’s build a machine simulator, over a good few days worth of hacking! I hope this inspires you to play with Clojure and to take a deeper look at SICP. </p><p>Before we simulate general machines, let’s think about a concrete machine. <strong>How could we create a machine that could figure out factorials?</strong> </p><p>If we were writing code, factorial could look something like this:</p><pre><code><span>(</span><span>defn</span><span> factorial [n]</span>
<span>  (</span><span>loop</span><span> [res </span><span>1</span>
<span>         counter </span><span>1</span><span>]</span>
<span>    (</span><span>if</span><span> (</span><span>&gt;</span><span> counter n)</span>
<span>      res</span>
<span>      (</span><span>recur</span>
<span>        (</span><span>*</span><span> counter res)</span>
<span>        (</span><span>inc</span><span> counter)))))</span></code></pre><p>Let’s see if we could build factorials using <em>physical</em> devices.</p><p>Well, we need a way to keep track of <code value="counter">counter</code>, <code value="res">res</code>, and <code value="n">n</code>. To do that, we’ll need a device that stores information. </p><h2>Bulbs</h2><p>Imagine a device that has some light bulbs inside of it. </p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1MjUwNDUyLTFlNzkzODgwLTA3ZTgtMTFlYi04MjI4LWQwYzE4ZTcwNTZhYS5wbmc" alt="image"></span></p><p>We can say that if a light bulb is <em>on,</em> that represents the number 1, and if a light bulb is <em>off</em> that represents the number 0. </p><p>If we had a bunch of light bulbs in the device, we could interpret the state of these bulbs as larger and larger binary numbers. The light bulbs in the device I just showed you for example, would represent “10101”, which is binary for “21”.</p><h2>Incoming Current</h2><p>Now, imagine that at all times there are a bunch of other wires connected to this device. These wires carry “new” charges for the light bulbs, but with a twist: the incoming charges <em>do not</em> affect the light bulbs inside just yet.</p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1MjUwNjIxLTVhMTQwMjgwLTA3ZTgtMTFlYi05ZjM2LTU2MDFkZTIyOWUwOS5wbmc" alt="image"></span></p><p>Notice how the <em>incoming charge</em> for the “a” light bulb is “off”, but the bulb inside is still on. Conversely, the incoming charge "b" is "on", but the bulb is off. If our device can do this, it means that whatever the charges for the light bulbs are inside is a <em>stored value</em>. Very cool! </p><h2>Save</h2><p>Now, we need these incoming wires to do something at some point. What if this device had a “save” button. </p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1MjUwNjQ1LTYzMDRkNDAwLTA3ZTgtMTFlYi04NjVjLWE3YTg3OTE5Njg3ZC5wbmc" alt="image"></span></p><p>Once we pressed “save”, the incoming current would transfer inside the box:  </p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1MjUwNjU0LTY3Yzk4ODAwLTA3ZTgtMTFlYi04MjU1LTExNmEzMGUxNTcwMy5wbmc" alt="image"></span></p><p>Here, light bulb “a” changes from “on” to “off”, and the light bulb "b" changed from "on" to "off".</p><p>Great, now we have a way to “save” new numbers inside! </p><h2>Outgoing current</h2><p>We also need a way to share the state of what’s inside to other devices.  All we’d need to do to make that work, is to have a bunch of wires that leave our device, which carry the sames charges as the light bulbs: </p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1MjUxNzQ2LWY5ODVjNTAwLTA3ZTktMTFlYi05YzczLTY4ZWYwNzc3OGJlMi5wbmc" alt="image"></span></p><p>Now, if we hooked those outgoing charges to some other device, that device would receive the “number” that was stored in this one. </p><h2>Registers</h2><p>What we just described is analogous to a computer’s <em>register</em> (1). Registers let us store and share information. </p><p>Now, we could use three of registers to store the value of <code value="res">res</code> <code value="counter">counter</code> and <code value="n">n</code>.</p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1MjUwODUxLWIxYjI2ZTAwLTA3ZTgtMTFlYi04NzRjLTQxODgyODAxNTQ2OC5wbmc" alt="image"></span></p><p>Next up, we’ll need a device that that can “add” two registers. Imagine a device that had two register’s worth of incoming wires, and one register’s worth of outgoing wires: </p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1MjUwODY5LWI4ZDk3YzAwLTA3ZTgtMTFlYi05ZDM0LTQwMDE0YmQ5NDAyOC5wbmc" alt="image"></span></p><h2>Adder</h2><p>If the device could connect those incoming wires in such a way, that the outgoing wires represented the “addition” of those registers, we’d have an “adder” device! </p><p>In the example above, the left register represents “10101” (21), and the right represents “00001” (1). The output wires are charged as “10110”…which represent 22!</p><p>Similarly, we could have a device that has two register’s worth input wires, and one register’s worth of output wires: </p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1MjUwODkyLWMxMzFiNzAwLTA3ZTgtMTFlYi05OTQ1LTI4ZDljNmU4N2IzNy5wbmc" alt="image"></span></p><h2>Multiplier</h2><p>If we could connect the incoming wires in such a way, that the outgoing wires represent the result of a multiplication, boom we would have a multiplying device! </p><p>The left register above represents “00101” (5), the right register represents “00010” (2), and the charge of the outgoing wire is “01010” (10). Nice! That gives us a multiplier machine. </p><h2>Comparator</h2><p>We need one more device. Imagine a device that takes two register’s worth of input wires, and only has <em>one</em> output wire: </p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1MjUwOTE1LWNhMjI4ODgwLTA3ZTgtMTFlYi05Y2RiLWM2ZDEwZTYxNzc1Yi5wbmc" alt="image"></span></p><p>If we could combine the input wires in such a way, that the output wire was “on” when the left register was bigger, and off otherwise, we could use this as a comparator machine! </p><p>If we had all these machines, we can wire them in such a way, that lets us compute factorials: </p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1MjUwOTg1LWRlZmYxYzAwLTA3ZTgtMTFlYi05MDRjLTE2NmUzNTIyMjJkOS5wbmc" alt="image"></span></p><p>Here, we wired the output wires of <code value="res">res</code> and <code value="counter">counter</code> to the <code value="*">*</code> machine. We wired the output wires of the <code value="*">*</code> machine, to <em>be</em> the input wires of <code value="res">res</code>. </p><p>This way, if we press “A”, we would “store” the result of multiplying <code value="counter">counter</code> with <code value="res">res</code>! </p><p>Similarly, we wired up the output wires of <code value="counter">counter</code> and a register that keeps the value <code value="1">1</code>, to the <code value="+">+</code> machine. We wired the output wires of the <code value="+">+</code> machine, to <em>be</em> the input wires of <code value="counter">counter</code>. </p><p>Now, If we pressed “B”, <code value="counter">counter</code> would be stored with the result of adding <code value="1">1</code>! </p><p>Next up, we also wired up <code value="counter">counter</code> and <code value="n">n</code> with the <code value=">">&gt;</code> machine. If we hooked up a light bulb to the output wire of the <code value=">">&gt;</code> machine for example, then whenever it was on, we would know that <code value="counter">counter</code> was larger than <code value="n">n</code>. </p><p>We’ve just drawn out the “data path” of our machine. </p><h2>Manual Recipe</h2><p>Let’s remember our code for factorial: </p><pre><code><span>  (</span><span>loop</span><span> [res </span><span>1</span>
<span>         counter </span><span>1</span><span>]</span>
<span>    (</span><span>if</span><span> (</span><span>&gt;</span><span> counter n)</span>
<span>      res</span>
<span>      (</span><span>recur</span>
<span>        (</span><span>*</span><span> counter res)</span>
<span>        (</span><span>inc</span><span> counter))))</span></code></pre><p>imagine if we had our “data path” machine. What would happen if we followed the following recipe:</p><ol><li>Take a look at the output of the <code value=">">&gt;</code> machine. </li><li>If the light bulb connected to the <code value=">">&gt;</code>  machine is on, <strong>stop</strong></li></ol><p><em>Otherwise…</em></p><ol><li>"Press A". This will update <code value="res">res</code>  with the result of the <code value="*">*</code>  machine on <code value="res">res</code> and <code value="counter">counter</code> </li><li>“Press B“. This will update <code value="counter">counter</code> with the result of the <code value="+">+</code>  machine on <code value="1">1</code> and <code value="counter">counter</code></li><li>Go back up to the start of the recipe</li></ol><p><strong>If we did this over and over again, once the light bulb connected to the output of the</strong>  <strong><code value=">">&gt;</code></strong> <strong>machine turns on,</strong> <strong><code value="res">res</code></strong> <strong>would contain the result of factorial!</strong> </p><h2>Automation</h2><p>Pretty cool, but this kind of manual work would be annoying. If you look at these instructions though, there’s a pretty significant insight: <em>all of those instructions are simple: "look at charge of light bulb", "press button..."</em></p><p>In fact, they’re so simple that we could wire up a machine that goes through that recipe! Imagine if we created a machine that could “press” buttons for us, depending on whether the output wire of the <code value=">">&gt;</code> machine is on:</p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1MjUxMDIwLWU5MjExYTgwLTA3ZTgtMTFlYi04MDJlLTI4YzIyNjZiNzQwOC5wbmc" alt="image"></span></p><p>We would be able to automate computing factorials 🙂</p><h2>Balls and Hills</h2><p>Now, at this stage, you may be wondering: exactly <em>how</em> would <code value="*">*</code> produce output wires that represent the multiplication? How would <code value="+">+</code> work, and how would the <code value="controller">controller</code> move along? </p><p>If you think about it, these can all be reduced to very simple machines. They don’t even necessarily have to be electronic: </p><p>Imagine you had a ball rolling down some hill. You could construct something like the <code value=">">&gt;</code> machine, by putting <code value="res">res</code> and <code value="counter">counter</code> on a scale: based on what’s bigger, the ball would take a different path</p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1MjUxMDQ4LWY4MDdjZDAwLTA3ZTgtMTFlYi04NTg3LWRiYjE2ZDU3NGZkMy5wbmc" alt="image"></span></p><p>With sufficient energy, space, time, and ingenuity you really could build all of this with a ball on a hill. Now, you wouldn’t necessarily do that (2), but you can imagine how the electronic parts that make up our machines are similarly simple, logical machines: <em>turn on if off, turn off if on, etc</em>. These logical machines are called “logic gates”. You can look them up, but hopefully I’ll have an essay for you about these machines soon 🙂. </p><p>Now, we drew out our machine and saw how we could build them with simple devices. How could we simulate these machines? </p><p>To simulate these machines, we need to transform our <em>picture descriptions</em> into something that computers can manipulate. Computers can manipulate text much better: let’s create a <em>language</em> for describing these machines. </p><p>If we remember the pictures again:</p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1MjUxMTg3LTJmNzY3OTgwLTA3ZTktMTFlYi05ZTNlLTg3Zjg0NDkxZjQxYS5wbmc" alt="image"></span></p><p>we could transform them into a language that looks like this:</p><pre><code><span>(</span><span>def</span><span> factorial-instructions</span>
<span>  '(</span>
<span>     start</span>
<!-- -->
<span>     (</span><span>test</span><span> (</span><span>op</span><span> &gt;) (</span><span>reg</span><span> counter) (</span><span>reg</span><span> n))</span>
<span>     (</span><span>branch</span><span> (</span><span>label</span><span> done))</span>
<!-- -->
<span>     (</span><span>assign</span><span> res (</span><span>op</span><span> *) (</span><span>reg</span><span> counter) (</span><span>reg</span><span> res))</span>
<span>     (</span><span>assign</span><span> counter (</span><span>op</span><span> +) (</span><span>reg</span><span> counter) (</span><span>const</span><span> </span><span>1</span><span>))</span>
<span>     (</span><span>goto</span><span> (</span><span>label</span><span> start))</span>
<!-- -->
<span>     done))</span></code></pre><p>When the <code value="test">test</code> instruction runs, we run the <code value=">">&gt;</code> machine with <code value="counter">counter</code> and <code value="n">n</code>.</p><p>Our <code value="branch">branch</code> instruction checks if the <code value="test">test</code> instruction said <code value="yes">yes</code>. If it did, it moves to <code value="done">done</code>. Otherwise it no-ops and the machine moves forward by one.</p><p>After that, our <code value="(assign res">(assign res</code> expression is analogous to “press A”. <code value="(assign counter">(assign counter</code> is analogous to “press B”, and <code value="(goto (label start)">(goto (label start)</code> is analogous to the arrow bringing us back to the start.</p><p>With this textual representation, we can build an interpreter and simulate our machine. Let’s do this! </p><p>What does the state of our machine look like in Clojure? Well, how do we represent most things in Clojure? With maps!  Let’s represent the state of our machine as a map:</p><pre><code><span>(</span><span>def</span><span> ex-machine-state-v0</span>
<span>  {</span><span>:registry-map</span><span> {'n </span><span>10</span><span> 'res </span><span>1</span><span> 'counter </span><span>1</span><span>}</span>
<span>   </span><span>:label-&gt;idx</span><span> {'start </span><span>0</span><span> 'done </span><span>5</span><span>}})</span></code></pre><p><code value="registry-map">registry-map</code> could keep a mapping of registers to values. 
<code value="label→idx">label→idx</code> could keep a mapping of labels to their <code value="idx">idx</code> in the instruction list</p><p>With this, we can get the most foundational part of our language to work: We use <code value="(const…">(const…</code>  <code value="(reg...">(reg...</code> and <code value="(label…">(label…</code> all over the place.</p><ol><li>If our machine sees <code value="(const 1)">(const 1)</code>, it should return the actual value <code value="1">1</code></li><li>If our machine sees <code value="(reg foo)">(reg foo)</code>, it should look up whatever is in the <code value="foo">foo</code> register, and return that </li><li>If our machine sees <code value="(label foo)">(label foo)</code>, it should return the correct index in our instruction list.</li></ol><p>Let’s write this out in Clojure:</p><pre><code><span>(</span><span>def</span><span> tag first) </span><span>; (tag '(const 1)) =&gt; const</span>
<span>(</span><span>defn</span><span> tag-of? [sym s] (</span><span>=</span><span> sym (</span><span>tag</span><span> s))) </span><span>; (tag-of? 'const '(const 1)) =&gt; true</span>
<!-- -->
<span>(</span><span>defn</span><span> parse-primitive [{</span><span>:keys</span><span> [registry-map label-&gt;idx] </span><span>:as</span><span> machine-state}</span>
<span>                       prim-exp]</span>
<span>  (</span><span>condp</span><span> tag-of? prim-exp</span>
<span>    'const</span>
<span>    (</span><span>second</span><span> prim-exp)</span>
<span>    'reg</span>
<span>    (</span><span>g…</span></code></pre></span></p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://stopa.io/post/255">https://stopa.io/post/255</a></em></p>]]>
            </description>
            <link>https://stopa.io/post/255</link>
            <guid isPermaLink="false">hacker-news-small-sites-24701737</guid>
            <pubDate>Tue, 06 Oct 2020 20:01:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I remember what I learn]]>
            </title>
            <description>
<![CDATA[
Score 517 | Comments 121 (<a href="https://news.ycombinator.com/item?id=24700647">thread link</a>) | @flreln
<br/>
October 6, 2020 | https://vasilishynkarenka.com/learning/ | <a href="https://web.archive.org/web/*/https://vasilishynkarenka.com/learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://vasilishynkarenka.com/content/images/size/w300/2020/09/IMG_1517.jpg 300w,
                            https://vasilishynkarenka.com/content/images/size/w600/2020/09/IMG_1517.jpg 600w,
                            https://vasilishynkarenka.com/content/images/size/w1000/2020/09/IMG_1517.jpg 1000w,
                            https://vasilishynkarenka.com/content/images/size/w2000/2020/09/IMG_1517.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://vasilishynkarenka.com/content/images/size/w2000/2020/09/IMG_1517.jpg" alt="How to remember what you learn">
            </figure>

            <section>
                <div>
                    <p><em>“I don’t remember a damn thing.”</em></p><p>The book I held my hands was full of highlights. It seemed like I’ve got all colors of the rainbow on a page. Apparently, this didn’t help. When I tried recalling ideas from the book, I didn’t hear a thing. Just. Silence.</p><p>Terrified, I started questioning how much I <em>really</em> know. If I forget everything I read, I can’t apply my knowledge to the problem at hand. I can’t transfer it. And without transfer, knowledge is very much like music for deaf ears.</p><p>I quickly did the math. I was planning to invest in learning a few hours a day for the next ~75 years of my life. Staring at the number of potentially wasted hours, I knew exactly what I had to do.</p><hr><p>In the past six months, I’ve devoured dozens of books, research papers, and studies on how people learn. As a result, I’ve designed a learning process that works for me. It’s not perfect, but an order of magnitude better than what I had before. </p><p>In this work, I outline my workflow so that you can try it out. It applies to any subject or discipline, from programming to economics. If you stumble upon something where it doesn’t work, let me know.</p><blockquote><em>Make it time-based, take regular breaks, and learn what you’re curious about.</em></blockquote><p>The most important thing is that my learning is time-based, not goal-based. Setting learning goals such as “read X pages today” is a way to fail because you set up the wrong incentives. When you plan to read X pages by lunch, you can’t help but begin optimizing for the goal, which leads to focusing on speed instead of understanding. And when you don’t have those “aha” moments, it is hard to remember what you learn.</p><p>It’s also important to not overload yourself and take breaks. I do 3h learning sessions every day split into 30 min intervals with 5 min breaks. Breaks help to fall back into the diffuse mode of thinking and get access to a broader set of neural networks in my head. They also warm up my body, and I feel better after moving around for a few minutes.</p><p>As for material, I learn what I’m interested in. First, because life is <a href="http://www.paulgraham.com/vb.html">too short</a> to do things that you don’t love. Second, I’ve found that studying stuff I genuinely like awakens my curiosity. And curiosity is essential to develop mastery because mastery is about depth and breadth of knowledge. </p><p>For example, if you’re learning JavaScript and you’re curious about it, you’ll go and figure out how JS runtime environment works in Chrome even though the tutorial doesn’t cover it. Just because you’re interested. But if you’re not curious, then you’ll just memorize the tutorial, and your knowledge will be shallow.</p><h2 id="how-my-learning-session-works">How my learning session works</h2><blockquote>Clean up working memory, apply metacognition, and "siege" the thing with questions to improve understanding.</blockquote><p>When I learn, I always have two devices on my desk. I have my laptop with the study material (ie, a book, a video, an article) on the right, and I have my iPad with a text editor open on the left.</p><p>This is how my current setup looks like:</p><figure><img src="https://vasilishynkarenka.com/content/images/2020/09/IMG_2658.jpg" alt="" srcset="https://vasilishynkarenka.com/content/images/size/w600/2020/09/IMG_2658.jpg 600w, https://vasilishynkarenka.com/content/images/size/w1000/2020/09/IMG_2658.jpg 1000w, https://vasilishynkarenka.com/content/images/size/w1600/2020/09/IMG_2658.jpg 1600w, https://vasilishynkarenka.com/content/images/size/w2400/2020/09/IMG_2658.jpg 2400w" sizes="(min-width: 720px) 720px"><figcaption>Morning learning session.</figcaption></figure><p>When I begin learning, I set a timer for 30 minutes and create three files in Drafts:</p><ol><li>A file with a timestamp where my random thoughts go.</li><li>A file with a timestamp where I think about the subject.</li><li>A file with questions.</li></ol><p><strong>The first file is a mind dump.</strong> When I start learning, I immediately begin thinking about things. It’s almost as if my brain wakes up and starts throwing ideas, tasks, and memories at me. I suspect this comes from the associative memory because I present myself with many triggers when I’m learning; words and sentences that bear special meaning to me and invoke these ideas.</p><p>But here’s the problem. If I don’t write thoughts down, I can’t focus. My working memory is overloaded with todos, ideas, and emotions. You’ve probably experienced this for yourself – your mind is running too fast, and you can’t really concentrate on what you’re learning. Having this “dump” file is immensely useful to a) free up my working memory to focus on my learning instead of thinking about these things, and b) store these thoughts somewhere safe to go back to them later and take action.</p><p><strong>The second file is where I write about what I’m learning.</strong> Folks in the kitchen call it metacognition, which means thinking about thinking. Metacognition is the single best trick I’ve found to improve understanding, and I will write more about it in the future. Whenever I don’t understand something or see that my understanding is shallow, I begin writing in the first person. It looks like this: “So Peter explains that there are four characteristics of a monopoly, but I don’t really understand why branding is one of them; why so?”</p><p>It’s also important to note that I don’t write in a usual sentence-paragraph manner. Instead, I write every thought on a new line. I don’t even put dots at the end of the sentences. This helps me to focus on understanding instead of nitty-gritty styling and typos. The “enter” key on a keyboard serves as the “end of thought” symbol and helps formulate ideas more clearly.</p><p>Another important idea is that my editor is plain text. I’ve found it incredibly liberating to operate in a plain text environment where you don’t have incentives to color, underline, bold, italicize, or do some other weird things with the text you’re writing. Instead of choosing the right font for my heading, I can focus on meaning instead. Also, my plain text app is way faster than all feature-rich text editors, and I’ve found it essential for a thought input environment to be fast. Otherwise, I can't think.</p><p>Here’s a fragment from my learning of React yesterday:</p><figure><img src="https://vasilishynkarenka.com/content/images/2020/09/IMG_D7F6BD12F133-1.jpeg" alt="" srcset="https://vasilishynkarenka.com/content/images/size/w600/2020/09/IMG_D7F6BD12F133-1.jpeg 600w, https://vasilishynkarenka.com/content/images/size/w1000/2020/09/IMG_D7F6BD12F133-1.jpeg 1000w, https://vasilishynkarenka.com/content/images/size/w1600/2020/09/IMG_D7F6BD12F133-1.jpeg 1600w, https://vasilishynkarenka.com/content/images/size/w2400/2020/09/IMG_D7F6BD12F133-1.jpeg 2400w" sizes="(min-width: 720px) 720px"><figcaption>Metacognition notes from studying React.js.</figcaption></figure><p>You’re probably thinking that it’s quite a bit of writing. It is. For an hour-long learning session, I usually do about 500-1000 words in this file. But it’s worth every character, and here’s why:</p><ul><li>When I apply metacognition, I understand things <em>way</em> better than when I don’t. I’ve tested many different learning modes and found metacognition to perform at least 2x better based on my later ability to recall and transfer knowledge. Also, there’s <a href="https://academicpublishingplatforms.com/downloads/pdfs/ati/volume18/201607070302_09_ATI_Vol11_Issue2_2015_Todorova_and_Karamanska_Study_motivation_satisfaction_students_e-learning_pp.82-89.pdf">some</a> <a href="http://www.csun.edu/science/ref/reasoning/how-students-learn/1.html">research</a> on metacognition as well.</li><li>Having a file with my thinking about the subject keeps my working memory clean. I don’t feel overloaded as I usually feel after reading many articles at one go. You’ve probably experienced this yourself; your brain is almost melting after an hour of scrolling through the web. That’s because you present yourself with too much information without really making sense of it. After a few months of applying metacognitive practices, I realized that I can’t go back. It just feels so strange to experience that cognitive load again.</li><li>Metacognition improves remembering through elaboration and interleaving. When I’m writing my thoughts in the file, I can’t help but begin connecting them with other ideas on that topic because of associative memory. And interleaving leads to mastery.</li><li>(Speculation) Training metacognition improves my ability to transform vague notions and thoughts that I have during the day into specific words that I can write down for later analysis. This one is particularly interesting to me, but there’s no evidence besides my own experiments. And I might be biased because I’ve come up with this method.</li></ul><p>Moreover, I type 2-3x faster than most people because I use <a href="https://barehands.substack.com/p/how-to-type-3x-faster">shortcuts</a>. So it’s not that bad.</p><p><strong>The third file is questions. </strong>Whenever I stumble upon something that I don’t understand, I try to break it down into a set of simple questions. Each question in the group takes on a small part of the problem. If the concept is particularly challenging, I try to “siege” it with questions from many many different angles and break it down even further.</p><p>When I’m beginning a new session, I always start from the previous one’s questions file. I only look at questions and answer them before I’m beginning new learning. This doesn’t sound like very much fun, but it’s actually pretty interesting to explain stuff to yourself if you do it out loud. Answering questions improves my understanding and helps to connect ideas together. And yes, answering questions counts as learning – probably the most efficient learning you could be doing.</p><p><em>I'm not going into much detail on questions because Michael Nielsen has done a phenomenal job describing it <a href="http://augmentingcognition.com/ltm.html">here</a>.</em></p><h2 id="what-happens-after-the-session">What happens after the session</h2><blockquote>Write a dense summary, provoke elaboration, interleaving, and transfer, and choose what to never forget.</blockquote><p>After the session is done, and my three files are full of information, I begin the recap process.</p><p><strong>First, I write a three to five sentence-long summary of what I’ve just studied.</strong> Here I try to distill the material’s core idea and compress the whole thing into a maximally dense chunk. When I’m summarizing, my laptop is closed. Not looking at the text helps to “compress” the idea to its core and make a small “hook” to my memory to later see what the whole book was about.</p><p>Here’s how my summary note looks like: </p><figure><img src="https://vasilishynkarenka.com/content/images/2020/09/IMG_9771D059CFD1-1.jpeg" alt="Recap of studying React.js." srcset="https://vasilishynkarenka.com/content/images/size/w600/2020/09/IMG_9771D059CFD1-1.jpeg 600w, https://vasilishynkarenka.com/content/images/size/w1000/2020/09/IMG_9771D059CFD1-1.jpeg 1000w, https://vasilishynkarenka.com/content/images/size/w1600/2020/09/IMG_9771D059CFD1-1.jpeg 1600w, https://vasilishynkarenka.com/content/images/size/w2400/2020/09/IMG_9771D059CFD1-1.jpeg 2400w" sizes="(min-width: 720px) 720px"><figcaption>Recap of studying React.js.</figcaption></figure><p>Very often, what I’m writing in the summary section is not what the text was about, but what it means to me. In other words, if both of us read this text and wrote a summary of it, mine would be very different than yours.</p><p>After I’m done with the summary, I write down the answers to three questions:</p><ol><li>What are the key ideas? </li><li>How can I apply this knowledge that I learned? </li><li>How do these ideas relate to what I already know?</li></ol><p><strong>The first question speaks for itself.</strong> I try to remember what I just read and write down as many ideas as I can bring back. When I began applying the metacognition trick that I mentioned earlier, I noticed a 3x increase in the number of concepts I could recall. And as I speculate that long-term memory recall is influenced by initial interleaving and recall, this might actually help to improve your long-term memory.</p><p><strong>The second question is about transfer.</strong> The sole purpose of learning is to apply the knowledge that we learn. Without application, …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vasilishynkarenka.com/learning/">https://vasilishynkarenka.com/learning/</a></em></p>]]>
            </description>
            <link>https://vasilishynkarenka.com/learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24700647</guid>
            <pubDate>Tue, 06 Oct 2020 18:06:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Q3 Linux touchpad update: Multitouch gesture test packages now ready]]>
            </title>
            <description>
<![CDATA[
Score 413 | Comments 133 (<a href="https://news.ycombinator.com/item?id=24700537">thread link</a>) | @wbharding
<br/>
October 6, 2020 | https://bill.harding.blog/2020/10/06/q3-linux-touchpad-like-macbook-update-multitouch-gesture-test-packages-are-ready/ | <a href="https://web.archive.org/web/*/https://bill.harding.blog/2020/10/06/q3-linux-touchpad-like-macbook-update-multitouch-gesture-test-packages-are-ready/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="comments">

		<div id="respond">
		<h3 id="reply-title">Leave a Reply <small></small></h3><form action="https://bill.harding.blog/wp-comments-post.php" method="post" id="commentform" novalidate=""><p><span id="email-notes">Your email address will not be published.</span> Required fields are marked <span>*</span></p><p><label for="comment">Comment</label> </p><p><label for="author">Name <span>*</span></label> </p>
<p><label for="email">Email <span>*</span></label> </p>
<p><label for="url">Website</label> </p>
<p> <label for="wp-comment-cookies-consent">Save my name, email, and website in this browser for the next time I comment.</label></p>
<!-- Anti-spam plugin wordpress.org/plugins/anti-spam/ --><div><p><label>Current ye@r <span>*</span></label>
					
					
				  </p>

</div><!--\End Anti-spam plugin --></form>	</div><!-- #respond -->
	
</div></div>]]>
            </description>
            <link>https://bill.harding.blog/2020/10/06/q3-linux-touchpad-like-macbook-update-multitouch-gesture-test-packages-are-ready/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24700537</guid>
            <pubDate>Tue, 06 Oct 2020 17:54:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A quick introduction to data parallelism in Julia]]>
            </title>
            <description>
<![CDATA[
Score 155 | Comments 15 (<a href="https://news.ycombinator.com/item?id=24700436">thread link</a>) | @amkkma
<br/>
October 6, 2020 | https://juliafolds.github.io/data-parallelism/tutorials/quick-introduction/ | <a href="https://web.archive.org/web/*/https://juliafolds.github.io/data-parallelism/tutorials/quick-introduction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p>If you have a large collection of data and have to do similar computations on each element, <a href="https://en.wikipedia.org/wiki/Data_parallelism">data parallelism</a> is an easy way to speedup computation using multiple CPUs and machines as well as GPU(s). While this is not the only kind of parallelism, it covers a vast class of compute-intensive programs. A major hurdle for using data parallelism is that you need to unlearn some habits useful in sequential computation (i.e., patterns result in mutations of data structure). In particular, it is important to use libraries that help you describe <em>what</em> to compute rather than <em>how</em> to compute. Practically, it means to use generalized form of map and reduce operations and learn how to express your computation in terms of them. Luckily, if you already know how to write <a href="https://docs.julialang.org/en/v1/manual/arrays/#Generator-Expressions">iterator comprehensions</a>, there is not much more to learn for accessing a large class of data parallel computations.</p>  <p>This introduction primary focuses on the Julia packages that I (Takafumi Arakaki <strong><code>@tkf</code></strong>) have developed. As a result, it currently focuses on thread-based parallelism. There is simple distributed computing support. GPU support is a frequently requested feature but <a href="https://github.com/JuliaFolds/Transducers.jl/issues/236">it hasn't been implemented yet</a>. See also <a href="https://juliafolds.github.io/data-parallelism/explanation/libraries/">other parallel-computation libraries in Julia</a>.</p> <p>Also note that this introduction does not discuss how to use threading primitives such as <a href="https://docs.julialang.org/en/v1/base/multi-threading/"><code>Threads.@spawn</code></a> since it is too low-level and error-prone. For data parallelism, a higher-level description is much more appropriate. It also helps you write more reusable code; e.g., using the same code for single-threaded, multi-threaded, and distributed computing.</p>   <h2 id="getting_julia_and_libraries"><a href="#getting_julia_and_libraries">Getting <code>julia</code> and libraries</a></h2> <p>Most of the examples here may work in all Julia 1.x releases. However, for the best result, it is highly recommended to get the latest released version (1.5.2 as of writing). You can download it at <a href="https://julialang.org/">https://julialang.org/</a>.</p> <p>Once you get <code>julia</code>, you can get the dependencies required for this tutorial by running <code>using Pkg; Pkg.add(["Transducers", "ThreadsX", "OnlineStats", "FLoops", "MicroCollections", "BangBang", "Plots", "BenchmarkTools"])</code> in Julia REPL.</p> <p>If you prefer using exactly the same environment used for testing this tutorial, run the following commands</p> <pre><code>git <span>clone</span> https://github.com/JuliaFolds/data-parallelism
<span>cd</span> data-parallelism
julia --project</code></pre> <p>and then in the Julia REPL:</p> <pre><code><span>julia&gt;</span><span> <span>using</span> Pkg
</span>
<span>julia&gt;</span><span> Pkg.instantiate()</span></code></pre> <h2 id="starting_julia"><a href="#starting_julia">Starting <code>julia</code></a></h2> <p>To use multi-threading in Julia, you need to start it with multiple execution threads. If you have Julia 1.5 or higher, you can start it with the <code>-t auto</code> (or, equivalently, <code>--threads auto</code>) option:</p> <pre><code>$ julia -t auto
               _
   _       _ _(_)_     |  Documentation: https://docs.julialang.org
  (_)     | (_) (_)    |
   _ _   _| |_  __ _   |  Type "?" for help, "]?" for Pkg help.
  | | | | | | |/ _` |  |
  | | |_| | | | (_| |  |  Version 1.5.2 (2020-09-23)
 _/ |\__'_|_|_|\__'_|  |  Official https://julialang.org/ release
|__/                   |

julia&gt; Threads.nthreads()  # number of core you have
8</code></pre> <p>The command line option <code>-t</code>/<code>--threads</code> can also take the number of threads to be used. In older Julia releases, use the <code>JULIA_NUM_THREADS</code> environment variable. For example, on Linux and macOS, <code>JULIA_NUM_THREADS=4 julia</code> starts <code>juila</code> with 4 execution threads.</p> <p>For more information, see <a href="https://docs.julialang.org/en/v1/manual/multi-threading/#Starting-Julia-with-multiple-threads">Starting Julia with multiple threads</a> in the Julia manual.</p> <h3 id="starting_julia_with_multiple_worker_processes"><a href="#starting_julia_with_multiple_worker_processes">Starting <code>julia</code> with multiple worker processes</a></h3> <p>A few examples below mention <a href="https://docs.julialang.org/en/v1/stdlib/Distributed/">Distributed.jl</a>-based parallelism. Like how multi-threading is setup, you need to setup multiple worker processes to get speedup. You can start <code>julia</code> with <code>-p auto</code> (or, equivalently, <code>--procs auto</code>). Distributed.jl also lets you add worker processes after starting Julia with <a href="https://docs.julialang.org/en/v1/stdlib/Distributed/#Distributed.addprocs"><code>addprocs</code></a>:</p> <pre><code><span>using</span> Distributed
addprocs(<span>8</span>)</code></pre> <p>For more information, see <a href="https://docs.julialang.org/en/v1/manual/distributed-computing/#Starting-and-managing-worker-processes">Starting and managing worker processes</a> section in the Julia manual.</p> <h2 id="mapping"><a href="#mapping">Mapping</a></h2> <p>Mapping is probably the most frequently used function in data parallelism. Recall how Julia's sequential <code>map</code> works:</p> <pre><code>a1 = map(string, <span>1</span>:<span>9</span>, <span>'a'</span>:<span>'i'</span>)</code></pre>
<pre><code>9-element Array{String,1}:
 "1a"
 "2b"
 "3c"
 "4d"
 "5e"
 "6f"
 "7g"
 "8h"
 "9i"</code></pre>
<p>We can simply replace it with <a href="https://github.com/tkf/ThreadsX.jl"><code>ThreadsX.map</code></a> for thread-based parallelism (see also <a href="https://juliafolds.github.io/data-parallelism/explanation/libraries/">other libraries</a>):</p>
<pre><code><span>using</span> ThreadsX
a2 = ThreadsX.map(string, <span>1</span>:<span>9</span>, <span>'a'</span>:<span>'i'</span>)
<span>@assert</span> a1 == a2</code></pre>

<p>Julia's standard library Distributed.jl contains <a href="https://docs.julialang.org/en/v1/stdlib/Distributed/#Distributed.pmap"><code>pmap</code></a> as a distributed version of <code>map</code>:</p>
<pre><code><span>using</span> Distributed
a3 = pmap(string, <span>1</span>:<span>9</span>, <span>'a'</span>:<span>'i'</span>)
<span>@assert</span> a1 == a3</code></pre>

<div><div><p>🔬 Test Code</p>
<pre><code><span>using</span> Test
    <span>@testset</span> <span>begin</span>
        <span>@test</span> a1 == a2
        <span>@test</span> a1 == a3
    <span>end</span></code></pre></div> <div><p>☑ Pass</p>
<pre><code>Test Summary: | Pass  Total
test set      |    2      2
</code></pre></div></div>
<h3 id="practical_example_stopping_time_of_collatz_function"><a href="#practical_example_stopping_time_of_collatz_function">Practical example: Stopping time of Collatz function</a></h3>
<p>As a slightly more "practical" example, let's play with the <a href="https://en.wikipedia.org/wiki/Collatz_conjecture">Collatz conjecture</a> which states that recursive application the <em>Collatz function</em> defined as</p>
<pre><code>collatz(x) =
    <span>if</span> iseven(x)
        x ÷ <span>2</span>
    <span>else</span>
        <span>3</span>x + <span>1</span>
    <span>end</span></code></pre>

<p>reaches the number 1 for all positive integers.</p>
<p>I'll skip the mathematical background of it (as I don't know much about it) but let me mention that there are plenty of fun-to-watch explanations in YouTube :)</p>
<p>If the conjecture is correct, the number of iteration required for the initial value is finite.  In Julia, we can calculate it with</p>
<pre><code><span>function</span> collatz_stopping_time(x)
    n = <span>0</span>
    <span>while</span> <span>true</span>
        x == <span>1</span> &amp;&amp; <span>return</span> n
        n += <span>1</span>
        x = collatz(x)
    <span>end</span>
<span>end</span></code></pre>

<p>Just for fun, let's plot the stopping time of the initial values from 1 to 10,000:</p>
<pre><code><span>using</span> Plots
plt = scatter(
    map(collatz_stopping_time, <span>1</span>:<span>10_000</span>),
    xlabel = <span>"Initial value"</span>,
    ylabel = <span>"Stopping time"</span>,
    label = <span>""</span>,
    markercolor = <span>1</span>,
    markerstrokecolor = <span>1</span>,
    markersize = <span>3</span>,
    size = (<span>450</span>, <span>300</span>),
)</code></pre>
<p><img src="https://juliafolds.github.io/data-parallelism/assets/tutorials/quick-introduction/code/output/collatz_stopping_time_scatter.png" alt=""></p><p>We can easily parallelize <code>map(collatz_stopping_time, 1:10_000)</code> and get a good speedup:</p>
<pre><code><span>julia&gt;</span><span> Threads.nthreads()  
</span>4

<span>julia&gt;</span><span> <span>using</span> BenchmarkTools
</span>
<span>julia&gt;</span><span> <span>@btime</span> map(collatz_stopping_time, <span>1</span>:<span>100_000</span>);
</span>  18.116 ms (2 allocations: 781.33 KiB)

<span>julia&gt;</span><span> <span>@btime</span> ThreadsX.map(collatz_stopping_time, <span>1</span>:<span>100_000</span>);
</span>  5.391 ms (1665 allocations: 7.09 MiB)</code></pre>
<h2 id="iterator_comprehensions"><a href="#iterator_comprehensions">Iterator comprehensions</a></h2>
<p>Julia's <a href="https://docs.julialang.org/en/v1/manual/arrays/#Generator-Expressions">iterator comprehension syntax</a> is a powerful tool for composing mapping, filtering, and flattening. Recall that mapping can be written as an array or iterator comprehension:</p>
<pre><code>b1 = map(x -&gt; x + <span>1</span>, <span>1</span>:<span>3</span>)
b2 = [x + <span>1</span> <span>for</span> x <span>in</span> <span>1</span>:<span>3</span>]         
b3 = collect(x + <span>1</span> <span>for</span> x <span>in</span> <span>1</span>:<span>3</span>)  
<span>@assert</span> b1 == b2 == b3
b1</code></pre>
<pre><code>3-element Array{Int64,1}:
 2
 3
 4</code></pre>
<p>The iterator comprehension can be executed with threads by using <a href="https://github.com/tkf/ThreadsX.jl"><code>ThreadsX.collect</code></a>:</p>
<pre><code>b4 = ThreadsX.collect(x + <span>1</span> <span>for</span> x <span>in</span> <span>1</span>:<span>3</span>)
<span>@assert</span> b1 == b4</code></pre>

<div><div><p>🔬 Test Code</p>
<pre><code><span>using</span> Test
    <span>@testset</span> <span>begin</span>
        <span>@test</span> b1 == b2 == b3
    <span>end</span></code></pre></div> <div><p>☑ Pass</p>
<pre><code>Test Summary: | Pass  Total
test set      |    1      1
</code></pre></div></div>
<p>Note that more complex composition of mapping, filtering, and flattening can also be executed in parallel:</p>
<pre><code>c1 = ThreadsX.collect(y <span>for</span> x <span>in</span> <span>1</span>:<span>3</span> <span>if</span> isodd(x) <span>for</span> y <span>in</span> <span>1</span>:x)</code></pre>
<pre><code>4-element Array{Int64,1}:
 1
 1
 2
 3</code></pre>
<p><a href="https://juliafolds.github.io/Transducers.jl/dev/reference/manual/#Transducers.dcollect"><code>Transducers.dcollect</code></a> is for using iterator comprehensions with a distributed backend:</p>
<pre><code><span>using</span> Transducers
c2 = dcollect(y <span>for</span> x <span>in</span> <span>1</span>:<span>3</span> <span>if</span> isodd(x) <span>for</span> y <span>in</span> <span>1</span>:x)
<span>@assert</span> c1 == c2</code></pre>

<div><div><p>🔬 Test Code</p>
<pre><code><span>@test</span> c1 == c2 == [<span>1</span>, <span>1</span>, <span>2</span>, <span>3</span>]</code></pre></div> </div>
<h2 id="pre-defined_reductions"><a href="#pre-defined_reductions">Pre-defined reductions</a></h2>
<p>Functions such as <code>sum</code>, <code>prod</code>, <code>maximum</code>, and <code>all</code> are the examples of <em>reduction</em> (aka <a href="https://en.wikipedia.org/wiki/Fold_(higher-order_function)"><em>fold</em></a>) that can be parallelized.  They are very powerful tools when combined with iterator comprehensions.  Using ThreadsX.jl, a sum of an iterator created by the comprehension syntax</p>
<pre><code>d1 = sum(x + <span>1</span> <span>for</span> x <span>in</span> <span>1</span>:<span>3</span>)</code></pre>
<pre><code>9</code></pre>
<p>can easily be parallelized by</p>
<pre><code>d2 = ThreadsX.sum(x + <span>1</span> <span>for</span> x <span>in</span> <span>1</span>:<span>3</span>)</code></pre>
<pre><code>9</code></pre>
<div><div><p>🔬 Test Code</p>
<pre><code><span>@test</span> d1 == d2</code></pre></div> </div>
<p>For the full list of pre-defined reductions and other parallelized functions, type <code>ThreadsX.</code> and press <kbd>TAB</kbd> in the REPL.</p>
<h3 id="practical_example_maximum_stopping_time_of_collatz_function"><a href="#practical_example_maximum_stopping_time_of_collatz_function">Practical example: Maximum stopping time of Collatz function</a></h3>
<p>We can use <code>maximum</code> to compute the maximum stopping time of Collatz function on a given the range of initial values</p>
<pre><code>max_time = ThreadsX.maximum(collatz_stopping_time, <span>1</span>:<span>100_000</span>)</code></pre>
<pre><code>350</code></pre>
<div><div><p>🔬 Test Code</p>
<pre><code><span>@test</span> max_time == <span>350</span></code></pre></div> </div>
<p>We get a speedup similar to the <code>map</code> example above:</p>
<pre><code><span>julia&gt;</span><span> <span>@btime</span> maximum(collatz_stopping_time, <span>1</span>:<span>100_000</span>)
</span>  17.625 ms (0 allocations: 0 bytes)
350

<span>julia&gt;</span><span> <span>@btime</span> ThreadsX.maximum(collatz_stopping_time, <span>1</span>:<span>100_000</span>)
</span>  5.024 ms (1214 allocations: 69.17 KiB)
350</code></pre>
<h3 id="onlinestatsjl"><a href="#onlinestatsjl">OnlineStats.jl</a></h3>
<p><a href="https://github.com/joshday/OnlineStats.jl">OnlineStats.jl</a> provides a <a href="https://joshday.github.io/OnlineStats.jl/latest/stats_and_models/">very rich</a> and <a href="https://joshday.github.io/OnlineStats.jl/latest/collections/">composable</a> set of reductions.  You can pass it as the first argument to <a href="https://github.com/tkf/ThreadsX.jl#onlinestatsjl"><code>ThreadsX.reduce</code></a>:</p>
<pre><code><span>using</span> OnlineStats: Mean
e1 = ThreadsX.reduce(Mean(), <span>1</span>:<span>10</span>)</code></pre>
<pre><code>Mean: n=10 | value=5.5</code></pre>
<div><div><p>🔬 Test Code</p>
<pre><code><span>using</span> OnlineStats; <span>@test</span> e1 == fit!(Mean(), <span>1</span>:<span>10</span>)</code></pre></div> </div>
<div><p>💡 Note</p>
<p>While OnlineStats.jl often does not provide the fastest way to compute the given statistics when all the intermediate data can fit in memory, in many cases you don't really need the absolute best performance. However, it may be worth considering other ways to compute statistics if ThreadsX.jl + OnlineStats.jl becomes the bottleneck.</p></div>
<h2 id="manual_reductions"><a href="#manual_reductions">Manual reductions</a></h2>
<p>For non-trivial parallel computations, you need to write a custom reduction.  <a href="https://github.com/JuliaFolds/FLoops.jl">FLoops.jl</a> provides a concise set of syntax for writing custom reductions.  For example, this is how to compute sums of two quantities in one sweep:</p>
<pre><code><span>using</span> FLoops

<span>@floop</span> <span>for</span> (x, y) <span>in</span> zip(<span>1</span>:<span>3</span>, <span>1</span>:<span>2</span>:<span>6</span>)
    a = x + y
    b = x - y
    <span>@reduce</span>(s += a, t += b)
<span>end</span>
(s, t)</code></pre>
<pre><code>(15, -3)</code></pre> <div><div><p>🔬 Test Code</p>
<pre><code><span>@test</span> (s, t) == (<span>15</span>, -<span>3</span>)</code></pre></div> </div>
<p>In this example, we do not initialize <code>s</code> and <code>t</code>; but it is not a typo.  In parallel sum, the only reasonable value of the initial state of the accumulators like <code>s</code> and <code>t</code> is zero.  So, <code>@reduce(s += a, t
+= b)</code> works as if <code>s</code> and <code>t</code> are initialized to appropriate type of zero.  However, since there are many zeros in Julia (<code>0::Int</code>, <code>0.0::Float64</code>, <code>(0x00 + 0x00im)::Complex{UInt8}</code>, ...), <code>s</code> and <code>t</code> are undefined if the input collection (i.e., the value of <code>xs</code> in <code>for
x in xs</code>) is empty.</p>
<p>To control the type of the accumulators and also to avoid <code>UndefVarError</code> in the empty case, you can set the initial value with <code>accumulator = initial_value op input</code> syntax</p>
<pre><code><span>@floop</span> <span>for</span> (x, y) <span>in</span> zip(<span>1</span>:<span>3</span>, <span>1</span>:<span>2</span>:<span>6</span>)
    a = x + y
    b = x - y
    <span>@reduce</span>(s2 = <span>0.0</span> + a, t2 = <span>0</span><span>im</span> + b)
<span>end</span>
(s2, t2)</code></pre>
<pre><code>(15.0, -3 + 0im)</code></pre> <div><div><p>🔬 Test Code</p>
<pre><code><span>@test</span> (s2, t2) === (<span>15.0</span>, -<span>3</span> + <span>0</span><span>im</span>)</code></pre></div> </div>
<p>To understand the computation of <code>@floop</code>…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://juliafolds.github.io/data-parallelism/tutorials/quick-introduction/">https://juliafolds.github.io/data-parallelism/tutorials/quick-introduction/</a></em></p>]]>
            </description>
            <link>https://juliafolds.github.io/data-parallelism/tutorials/quick-introduction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24700436</guid>
            <pubDate>Tue, 06 Oct 2020 17:44:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gradient Boosted Decision Trees]]>
            </title>
            <description>
<![CDATA[
Score 141 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24700250">thread link</a>) | @simonwardjones
<br/>
October 6, 2020 | https://www.simonwardjones.co.uk/posts/gradient_boosted_decision_trees/ | <a href="https://web.archive.org/web/*/https://www.simonwardjones.co.uk/posts/gradient_boosted_decision_trees/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

<article>
  <div>
    <div>
      
      
      
      <p>What is a <code>gradient boosted decision tree</code>? 🤷‍♂️</p>
<p>This article is the fifth in a series covering fundamental machine learning algorithms. Each post will be split into two parts</p>
<ol>
<li><a href="#the-idea-and-key-concepts"><strong>The idea and key concepts</strong></a>
- Most people should be able to follow this section and learn how the algorithm works</li>
<li><a href="#the-maths"><strong>The maths</strong></a>
- This is for the interested reader and will include detailed mathematical derivations followed by an implementation in Python</li>
</ol>
<p>Click</p>
<ul>
<li><a href="https://www.simonwardjones.co.uk/posts/linear_regression/">here</a> if you missed <code>From zero to Linear Regression</code></li>
<li><a href="https://www.simonwardjones.co.uk/posts/logistic_regression/">here</a> if you missed <code>From zero to Logistic Regression</code></li>
<li><a href="https://www.simonwardjones.co.uk/posts/decision_trees/">here</a> if you missed <code>From zero to Decision Tree</code></li>
<li><a href="https://www.simonwardjones.co.uk/posts/random_forests/">here</a> if you missed <code>From zero to Random Forest</code></li>
</ul>
<p>Great if you have already read these!</p>
<hr>
<h2 id="the-idea-and-key-concepts">The idea and key concepts</h2>
<p>In the last post we talked about <code>underfitting</code>, <code>overfitting</code>, <code>bias</code> and <code>variance</code>. We explained how a <code>random forest</code> uses the average output of multiple trees to reduce the chance of overfitting without introducing bias by oversimplifying (such as using only one tree but restricting the depth).</p>
<p><code>Gradient boosting</code> is a machine learning technique for regression and classification where multiple models are trained <code>sequentially</code> with each model trying to learn the mistakes from the previous models. The individual models are known as <code>weak learners</code> and in the case of <code>gradient boosted decision trees</code> the individual models are decision trees.</p>
<p>In order to give intuition it is easiest to consider first the case of regression. Imagine we are again trying to predict house prices in a desirable area of north London. With training data that looks like the following</p>





<table <thead="">
<tbody><tr>
<th></th>
<th>House size 🏠</th>
<th>Garden size 🌳</th>
<th>Garage? 🚙</th>
<th>True House Price 💰</th>
</tr>

</tbody><tbody>
<tr>
<td>1</td>
<td>1000</td>
<td>700</td>
<td>Garage</td>
<td>£1m</td>
</tr>
<tr>
<td>2</td>
<td>770</td>
<td>580</td>
<td>No Garage</td>
<td>£0.75m</td>
</tr>
<tr>
<td>3</td>
<td>660</td>
<td>200</td>
<td>Garage</td>
<td>£0.72m</td>
</tr>
</tbody>
</table>

<p><strong>Initial prediction $f_0$</strong></p>
<p>We can make an initial prediction for each of the house prices based on an initial model, let’s call this initial model $f_0$. Often this model is very simple - just using the mean of the target variable in the training data. The following table shows the initial predictions as well as the <code>errors</code> $e_1$ (also known as the <code>residuals</code>) defined for each sample as $e_1 = y - f_0$ where $y$ is the true value and $f_0$ is our initial prediction</p>





<table <thead="">
<tbody><tr>
<th></th>
<th>True House Price 💰</th>
<th>Initial Prediction $f_0$</th>
<th>Error $e_1$</th>
</tr>

</tbody><tbody>
<tr>
<td>1</td>
<td>£1m</td>
<td>£0.82m</td>
<td>£(1m - 0.82) = £0.18m</td>
</tr>
<tr>
<td>2</td>
<td>£0.75m</td>
<td>£0.82m</td>
<td>£(0.75m - 0.82m) = -£0.07m</td>
</tr>
<tr>
<td>3</td>
<td>£0.72m</td>
<td>£0.82m</td>
<td>£(0.72m - 0.82m) = -£0.1m</td>
</tr>
</tbody>
</table>

<p><strong>Predicting the error</strong></p>
<p>Our initial prediction isn’t very accurate as it is just the mean house price of the training data! In order to improve this we introduce another model $f_1$ trying to predict the error $e_1$ from the sample feature values. In gradient boosted decision trees this model is itself a decision tree. So now we can predict what the error $e_1$ will be for each sample using $f_1$</p>





<table <thead="">
<tbody><tr>
<th></th>
<th>True House Price 💰</th>
<th>Initial Prediction $f_0$</th>
<th>Error $e_1$</th>
<th>Predicted Error $f_1$</th>
</tr>

</tbody><tbody>
<tr>
<td>1</td>
<td>£1m</td>
<td>£0.82m</td>
<td>£(1m - 0.82) = £0.18m</td>
<td>£0.17m</td>
</tr>
<tr>
<td>2</td>
<td>£0.75m</td>
<td>£0.82m</td>
<td>£(0.75m - 0.82m) = -£0.07m</td>
<td>£-0.09m</td>
</tr>
<tr>
<td>3</td>
<td>£0.72m</td>
<td>£0.82m</td>
<td>£(0.72m - 0.82m) = -£0.1m</td>
<td>£-0.1m</td>
</tr>
</tbody>
</table>

<p><strong>Updating our prediction using the error prediction</strong></p>
<p>For the first house our initial prediction $f_0$ was £0.82m (using the mean) and as we actually know the true value we can see this gave an error $e_1$ of 0.18m. We then trained $f_1$ - a decision tree - to predict the error $e_1$ for each sample. In practise this is only a prediction of the error so it wont be exactly equal, in this toy example our $f_1$ model predicted an error of £0.17m. We could now combine the two models into a new second prediction called $F_1$ by adding the predicted error $f_1$ to the initial prediction $f_0$ as in the table below</p>





<table <thead="">
<tbody><tr>
<th></th>
<th>True House Price 💰</th>
<th>Initial Prediction $f_0$</th>
<th>Predicted Error $f_1$</th>
<th>Prediction $F_1 =f_0 + f_1$</th>
</tr>

</tbody><tbody>
<tr>
<td>1</td>
<td>£1m</td>
<td>£0.82m</td>
<td>£0.17m</td>
<td>£0.99m</td>
</tr>
<tr>
<td>2</td>
<td>£0.75m</td>
<td>£0.82m</td>
<td>-£0.09m</td>
<td>£0.73m</td>
</tr>
<tr>
<td>3</td>
<td>£0.72m</td>
<td>£0.82m</td>
<td>-£0.1m</td>
<td>£0.71m</td>
</tr>
</tbody>
</table>

<p><strong>Additive model</strong></p>
<p>Now we have a second prediction $F_1$ we can continue in a sequential manner, again calculating the error of our second prediction $e_2$ and training a tree $f_2$ to predict this second error. Then once again we add this second predicted error to the second prediction to get a third prediction $F_2 = F_1 + f_2$ and so on. As the models are summed together this approach is known as an <code>aditive model</code>. In general we have
$$F_m =  F_{m-1} + f_m$$
Where the next prediction $F_m$ is made up of the current prediction $F_{m-1}$ and the prediction of the error $f_m \sim e_m =y - F_{m-1}$ at this stage. In general the number of <code>weak learners</code> is a <code>hyper parameter</code> you have to choose.</p>
<p><strong>learning rate</strong></p>
<p>We can think of each individual <code>weak learner</code> $f_m$ as stepping our predictions closer to the true target values $y$. To reduce the variance and overfitting rather than stepping the whole predicted error we can instead add only a fraction of the step controlled by the learning rate. So rather than
$$F_m =  F_{m-1} + f_m$$
In gradient boosting we use
$$F_m =  F_{m-1} + (\text{learning rate}*f_m)$$
This process requires more steps but reduces the variance and overfitting overall.</p>
<p><strong>Summary of the algorithm</strong></p>
<ol>
<li>Make initial model $f_0$ (often the mean of y)</li>
<li>Train decision tree model $f_1$ on the error $e_1 = y - f_0$ where y is the true value</li>
<li>Calculate new prediction $F_1 = f_0 + \eta * f_1$ where $\eta$ is the learning rate</li>
<li>Repeat 2, 3 as many times as chosen where in general
<ol>
<li>Train model $f_m$ on the error $e_m = y - F_{m-1}$</li>
<li>Calculate new prediction as $F_{m-1} + \eta * f_m$</li>
</ol>
</li>
</ol>
<p>In short gradient boosting uses an initial prediction and then sequentially updates this prediction by fitting a model to the error at that stage.</p>
<p>In the following section we explore the mathematical details and extend the algorithm to the classification setting. We also cover the intuition behind gradient boosting as gradient descent.</p>
<hr>
<h2 id="the-maths">The maths</h2>
<p><strong>Why is it called gradient boosting?</strong></p>
<p>In general in <code>supervised learning</code> we aim to find a model $F$ to fit the data such that the predicted value $\hat{y}_i$ for the $j$th training example $\mathbf{x}_i$ is approximately equal to the $j$th target value $y_i$ or equivalently</p>
<p>
    $$
\hat{y}_i=F(\mathbf{x}_i)\sim y_i \quad\forall j \in {1,\dots,n} 
$$
</p><p>
Where n is the number of training samples.</p>
<p>Equivalently we aim to minimise a loss function $\mathcal{L(y, \hat{y})}$ which tells us how badly the model $\hat{y}$ currently fits the data $y$.</p>
<p>In a <code>parametric</code> setting (e.g. logistic regression) the model can be written as

</p><p>
    $$
\hat{y}_i=F_{\mathbf{\theta}}(\mathbf{x}_i)
$$
</p>
<p>Where the subscript $\mathbf{\theta}$ indicates the models dependence on the parameters. We can also write the loss in terms of $\mathbf{\theta}$ as $\mathcal{L(y, \hat{y}(\mathbf{\theta})})$. In this setting we update the model parameters using gradient descent. That is we iteratively update the model parameters by stepping the parameters in the direction of the negative gradient of the loss function with respect to the parameters (where $\eta$ is the learning rate).</p>

<p>
    $$
\mathbf{\theta}^{m+1} = \mathbf{\theta}^{m} - \eta* \frac{\partial\mathcal{L}}{\partial{\mathbf{\theta}^m}}
$$
</p>
<p>Instead of differentiating the loss with respect to $\mathbf{\theta}$ we can differentiate with respect to the prediction $\hat{y}$ directly. If we think about gradient descent ideally we would update $\hat{y}$ as follows to reduce the cost function</p>

<p>
    $$
\hat{y}_i \to \hat{y}_i - \eta\frac{\partial\mathcal{L}}{\partial{\hat{y}_i}}
$$
</p>
<p>Equivalently we update $F_{m-1}$ by adding another “delta model” $f_{m+1}$</p>

<p>
    $$
\hat{y}_i = F_m(\mathbf{x}_i) + f_{m+1}(\mathbf{x}_i) \quad\forall j \in {1,\dots,n} 
$$
</p>
<p>Where $\eta$ is the learning rate and

</p><p>
    $$
f_{m+1}(\mathbf{x}_i)= -\eta\frac{\partial\mathcal{L}}{\partial{\hat{y}_i}}
$$
</p>
<p>In practise we cannot set this delta model exactly so we train a model on the data to fit

</p><p>
    $$
 - \eta\frac{\partial\mathcal{L}}{\partial{\hat{y}_i}}$$
</p><p>
In general this gradient can be fitted with any model but gradient boosted decision trees use a decision tree - hence the name! Note each tree will have it’s own Loss $\mathcal{L}^{f_{m+1}}$ separate to the global loss $\mathcal{L}$.</p>
<p><strong>Key Point</strong></p>
<p>The gradient boosted decision tree is not trained on the residuals at each step. Rather it is trained on the negative gradient of the loss function evaluated using the prediction of the current step - which happens to be the residual for some common cost functions.</p>
<h3 id="regression">Regression</h3>
<p>In the case of regression we define the loss function as the mean square error</p>
<p>$$
\mathcal{L}(\hat{y}) = \frac{1}{2n}\sum_{i=1}^{n}(y_i-\hat{y}_i)^2
$$
hence
$$
-\eta\frac{\partial\mathcal{L}}{\partial{\hat{y}_i}} = \frac{\eta}{n}(y_i-\hat{y}_i)
$$</p>
<p>How the process looks:</p>
<p>We fit $f_0(x)\sim y$ then $F_0(x) = f_0(x)$<br>
We fit $f_1(x)\sim (y-F_0(x))$ then $F_1(x) = F_0(x) + \eta f_1(x)$<br>
We fit $f_2(x)\sim (y-F_1(x))$ then $F_2(x) = F_1(x) + \eta f_2(x)$<br>
We fit $f_3(x)\sim (y-F_2(x))$ then $F_3(x) = F_2(x) + \eta f_3(x)$<br>
…<br>
We fit $f_m(x)\sim (y-F_{m-1}(x))$ then $F_m(x) = F_{m-1}(x) + \eta f_m(x)$</p>
<p>Then predictions $\hat{y} = F_m(x)$</p>
<h4 id="binomial-classification">Binomial Classification</h4>
<p>Suppose our iterative model was $\hat{y}_i = F_m(x_i)$ where the $\hat{y}_i$ directly represented the probability $x_i$ is in class 1. i.e. $P(x_i \in C_1)$ where $C_1$ represents class 1.</p>
<p>In this case the delta model doesn’t make sense as we would be directly adding to a probability value. As in logistic regression it is often the case to fit the model to a transformation of probability.</p>
<p>We define a model
$$
\hat{y}\sim F(x)
$$
where
$$
\hat{p} = \frac{1}{1+e^{-\hat{y}}}
$$
so
$$
\hat{y} = \log\left(\frac{\hat{p}}{1-\hat{p}}\right)
$$</p>
<p>where $\hat{p}$ represents the probability of being in class 1, $\hat{y}$ is sometimes known as the logit.</p>
<p>Note $\hat{p}\in[0,1],\quad \hat{y}\in(-\infty,\infty),\quad y\in{0,1}$</p>
<p>Hence in the classification setting the gradient boosted decision tree predicts $\hat{y}$ as a sum of multiple delta models. The probability values are then calculated by transforming $\hat{y}$ using the sigmoid function (a.k.a the expit function).</p>
<p>We will use the following fact later on</p>

<p>
    $$
\begin{align}
\hat{p} &amp;= \frac{1}{1+e^{-\hat{y}}} \quad so \\
\hat{p} &amp;= …</p></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.simonwardjones.co.uk/posts/gradient_boosted_decision_trees/">https://www.simonwardjones.co.uk/posts/gradient_boosted_decision_trees/</a></em></p>]]>
            </description>
            <link>https://www.simonwardjones.co.uk/posts/gradient_boosted_decision_trees/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24700250</guid>
            <pubDate>Tue, 06 Oct 2020 17:26:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Eliminating Task Processing Outages by Replacing RabbitMQ with Apache Kafka]]>
            </title>
            <description>
<![CDATA[
Score 93 | Comments 61 (<a href="https://news.ycombinator.com/item?id=24699534">thread link</a>) | @sciurus
<br/>
October 6, 2020 | https://doordash.engineering/2020/09/03/eliminating-task-processing-outages-with-kafka/ | <a href="https://web.archive.org/web/*/https://doordash.engineering/2020/09/03/eliminating-task-processing-outages-with-kafka/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<p><span>Scaling backend infrastructure to handle hyper-growth is one of the many exciting challenges of working at DoorDash. In mid 2019, we faced significant scaling challenges and frequent outages involving </span><a href="https://en.wikipedia.org/wiki/Celery_(software)"><span>Celery</span></a><span> and </span><a href="https://www.rabbitmq.com/"><span>RabbitMQ</span></a><span>, two technologies powering the system that handles the asynchronous work enabling critical functionalities of our platform, including order checkout and Dasher assignments.&nbsp;</span></p>
<p><span>We quickly solved this problem with a simple, </span><a href="https://kafka.apache.org/"><span>Apache Kafka</span></a><span>-based asynchronous task processing system that stopped our outages while we continued to iterate on a robust solution. Our initial version implemented the smallest set of features needed to accommodate a large portion of existing Celery tasks. Once in production, we continued to add support for more Celery features while addressing novel problems that arose when using Kafka. </span></p>
<h2><span>The problems we faced using Celery and RabbitMQ</span></h2>
<p><span>RabbitMQ and Celery were mission critical pieces of our infrastructure that powered over 900 different asynchronous tasks at DoorDash, including order checkout, merchant order transmission, and Dasher location processing. The problem DoorDash faced was that RabbitMQ was frequently going down due to excessive load. If task processing went down, DoorDash effectively went down and orders could not be completed, resulting in revenue loss for our merchants and Dashers, and a poor experience for our consumers. We faced issues on the following fronts:</span></p>
<ul>
<li><b>Availability:</b><span> Outages caused by demand reduced availability.&nbsp;</span></li>
<li><b>Scalability:</b><span> RabbitMQ could not scale with the growth of our business.&nbsp;</span></li>
<li><b>Observability:</b><span> RabbitMQ offered limited metrics and Celery workers were opaque.&nbsp;</span></li>
<li><b>Operational efficiency:</b><span> Restarting these components was a time-consuming, manual process.&nbsp;</span></li>
</ul>
<h3><span>Why our asynchronous task processing system wasn’t highly available</span></h3>
<p><span>This biggest problem we faced were outages, and they often came when demand was at its peak. RabbitMQ would go down due to load, </span><a href="https://www.rabbitmq.com/connections.html#high-connection-churn"><span>excessive connection churn</span></a><span>, and other reasons. Orders would be halted, and we’d have to restart our system or sometimes even bring up an entirely new broker and manually </span><a href="https://en.wikipedia.org/wiki/Failover"><span>failover</span></a><span> in order to recover from the outage.</span></p>
<p><span>On diving deeper into the availability issues, we found the following sub-issues:</span></p>
<ul>
<li><span>Celery allows users to schedule tasks in the future with a countdown or ETA. Our heavy use of&nbsp; these countdowns resulted in noticeable load increases on the broker. Some of our outages were directly related to an increase in tasks with countdowns. We ultimately decided to restrict the use of countdowns in favor of another system we had in place for scheduling work in the future.</span></li>
<li><span>Sudden bursts of traffic would leave RabbitMQ in a degraded state where task consumption was significantly lower than expected. In our experience, this could only be resolved with a RabbitMQ bounce. RabbitMQ has a concept of Flow Control where it will reduce the speed of connections which are publishing too quickly so that queues can keep up. Flow Control was often, but not always, involved in these availability degradations. When Flow Control kicks in, the publishers effectively see it as network latency. Network latency reduces our response times; if latency increases during peak traffic, significant slowdowns can result that cascade as requests pile up upstream.</span></li>
<li><span>Our python </span><a href="https://uwsgi-docs.readthedocs.io/en/latest/"><span>uWSGI</span></a><span> web workers had a feature called harakiri that was enabled to kill any processes that exceeded a timeout. During outages or slowdowns, harakiri resulted in a connection churn to the RabbitMQ brokers as processes were repeatedly killed and restarted. With thousands of web workers running at any given time, any slowness that triggered harakiri would in turn contribute even more to slowness by adding extra load to RabbitMQ.</span></li>
<li><span>In production we experienced several cases where task processing in the Celery consumers&nbsp; stopped, even in the absence of significant load. Our investigation efforts did not yield evidence of any resource constraints that would’ve halted processing, and the workers resumed processing once they were bounced. This problem was never root caused, though we suspect an issue in the Celery workers themselves and not RabbitMQ.</span></li>
</ul>
<p><span>Overall, all of these availability issues were unacceptable for us as high reliability is one of our highest priorities. Since these outages were costing us a lot in terms of missed orders and credibility we needed a solution that would address these problems as soon as possible.</span></p>
<h3><span>Why our legacy solution did not scale&nbsp;</span></h3>
<p><span>The next biggest problem was scale. DoorDash is growing fast and we were quickly reaching the limits of our existing solution. We needed to find something that would keep up with our continued growth since our legacy solution had the following problems:&nbsp;</span></p>
<p><strong>Hitting the vertical scaling limit</strong></p>
<p><span>We were using the largest available single-node RabbitMQ solution that was available to us. There was no path to scale vertically any further and we were already starting to push that node to its limits.</span></p>
<p><strong>The High Availability mode limited our capacity&nbsp;</strong></p>
<p><span>Due to replication, the primary-secondary High Availability (HA) mode reduced throughput compared to the single node option, leaving us with even less headroom than just the single node solution. We could not afford to trade throughput for availability.</span></p>
<p><span>Secondly, the primary-secondary HA mode did not, in practice, reduce the severity of our outages. Failovers took more than 20&nbsp; minutes&nbsp; to complete and would often get stuck requiring manual intervention. Messages were often lost in the process as well.</span></p>
<p><span>We were quickly running out of headroom as DoorDash continued to grow and push our task processing to its limits. We needed a solution that could scale horizontally as our processing needs grew.</span></p>
<h3><span>How Celery and RabbitMQ offered limited observability</span></h3>
<p><span>Knowing what’s going on in any system is fundamental to ensuring its availability, scalability, and operational integrity.&nbsp;</span></p>
<p><span>As we navigated the issues outlined above, we noticed that :</span></p>
<ul>
<li><span>We were limited to a small set of RabbitMQ metrics available to us.</span></li>
<li><span>We had limited visibility into the Celery workers themselves.</span></li>
</ul>
<p><span>We needed to be able to see real-time metrics of every aspect of our system which meant the observability limitations needed to be addressed as well.&nbsp;</span></p>
<h3><span>The operational efficiency challenges</span></h3>
<p><span>We also faced several issues with operating RabbitMQ:</span></p>
<ul>
<li><span>We often had to failover our RabbitMQ node to a new one to resolve the persistent degradation we observed. This operation was manual and time consuming for the engineers involved and often had to be done late at night, outside of peak times.</span></li>
<li><span>There were no in-house Celery or RabbitMQ experts at DoorDash who we could lean on to help devise a scaling strategy for this technology.</span></li>
</ul>
<p><span>Engineering time spent operating and maintaining RabbitMQ was not sustainable. We needed something that better met our current and future needs.</span></p>
<h2><span>Potential solutions to our problems with Celery and RabbitMQ&nbsp;</span></h2>
<p><span>With the problems outlined above, we considered the following solutions:</span></p>
<ul>
<li><b>Change the Celery broker from RabbitMQ to Redis or Kafka. </b>This would allow us to continue using Celery, with a different and potentially more reliable backing datastore.</li>
</ul>
<ul>
<li><b>Add multi-broker support to our </b><a href="https://www.djangoproject.com/"><b>Django</b></a><b> app so consumers could publish to N different brokers based on whatever logic we wanted. </b>Task processing will get sharded across multiple brokers, so each broker will experience a fraction of the initial load.</li>
</ul>
<ul>
<li><b>Upgrade to newer versions of Celery and RabbitMQ. </b>Newer versions of Celery and RabbitMQ were expected to fix reliability issues, buying us time as we were already extracting components from our Django monolith in parallel.</li>
</ul>
<ul>
<li><b>Migrate to a custom solution backed by Kafka. </b>This solution takes more effort than the other options we listed, but also has more potential to solve every problem we were having with the legacy solution.</li>
</ul>
<p><span>Each option has its pros and cons:</span></p>
<table>
<tbody>
<tr>
<td><b>Option</b></td>
<td><b>Pros</b></td>
<td><b>Cons</b></td>
</tr>
<tr>
<td><span>Redis as broker&nbsp;</span></td>
<td>
<ul>
<li><span>Improved availability with ElasticCache and multi-AZ support</span></li>
<li><span>Improved broker observability with ElasticCache as the broker</span></li>
<li><span>Improved operational efficiency</span></li>
<li><span>In-house operational experience and expertise with Redis</span></li>
<li><span>A broker swap is straight-foward as a supported option in Celery</span></li>
<li><span>Harakiri connection churn does not significantly degrade Redis performance</span></li>
</ul>
</td>
<td>
<ul>
<li><span>Incompatible with Redis clustered mode</span></li>
<li><span>Single node Redis does not scale horizontally</span></li>
<li><span>No Celery observability improvements</span></li>
<li><span>This solution does not address the observed issue where Celery workers stopped processing tasks</span></li>
</ul>
</td>
</tr>
<tr>
<td><span>Kafka as broker</span></td>
<td>
<ul>
<li><span>Kafka can be highly available</span></li>
<li><span>Kafka is horizontally scalable</span></li>
<li><span>Improved observability with Kafka as the broker</span></li>
<li><span>Improved operational efficiency</span></li>
<li><span>DoorDash had in-house Kafka expertise</span></li>
<li><span>A broker swap is straight-foward as a supported option in Celery</span></li>
<li><span>Harakiri connection churn does not significantly degrade Kafka performance</span></li>
</ul>
</td>
<td>
<ul>
<li><span>Kafka is not supported by Celery yet&nbsp;</span></li>
<li><span>Does not address the observed issue where Celery workers stop processing tasks</span></li>
<li><span>No celery observability improvements</span></li>
<li><span>Despite in-house experience, we had not operated Kafka at scale at DoorDash.</span></li>
</ul>
</td>
</tr>
<tr>
<td><span>Multiple brokers</span></td>
<td>
<ul>
<li><span>Improved availability&nbsp;</span></li>
<li><span>Horizontal scalability</span></li>
</ul>
</td>
<td>
<ul>
<li><span>No observability improvements</span></li>
<li><span>No operational efficiency improvements</span></li>
<li><span>Does not address the observed issue where Celery workers stop processing tasks</span></li>
<li><span>Does not address the issue with harakiri-induced connection churn</span></li>
</ul>
</td>
</tr>
<tr>
<td><span>Upgrade versions</span></td>
<td>
<ul>
<li><span>Might improve the issue where RabbitMQ becomes stuck in a degraded state</span></li>
<li><span>Might improve the issue where Celery workers get stuck</span></li>
<li><span>Might buy us headroom to implement a longer term strategy</span></li>
</ul>
</td>
<td>
<ul>
<li><span>Not guaranteed to fix our observed bugs</span></li>
<li><span>Will not immediately fix our issues with availability, scalability, observability, and operational efficiency</span></li>
<li><span>Newer versions of RabbitMQ and Celery required newer versions of Python.</span></li>
<li><span>Does not address the issue with harakiri-induced connection churn</span></li>
</ul>
</td>
</tr>
<tr>
<td><span>Custom Kafka solution</span></td>
<td>
<ul>
<li><span>Kafka can be highly available</span></li>
<li><span>Kafka is horizontally scalable</span></li>
<li><span>Improved observability with Kakfa as the broker</span></li>
<li><span>Improved operational efficiency</span></li>
<li><span>In-house Kafka expertise</span></li>
<li><span>A broker change is …</span></li></ul></td></tr></tbody></table></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://doordash.engineering/2020/09/03/eliminating-task-processing-outages-with-kafka/">https://doordash.engineering/2020/09/03/eliminating-task-processing-outages-with-kafka/</a></em></p>]]>
            </description>
            <link>https://doordash.engineering/2020/09/03/eliminating-task-processing-outages-with-kafka/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24699534</guid>
            <pubDate>Tue, 06 Oct 2020 16:26:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Teaching our five year old to code by cheating]]>
            </title>
            <description>
<![CDATA[
Score 119 | Comments 104 (<a href="https://news.ycombinator.com/item?id=24699448">thread link</a>) | @gregorymichael
<br/>
October 6, 2020 | https://baugues.com/cheat-code/ | <a href="https://web.archive.org/web/*/https://baugues.com/cheat-code/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>My wife and I became <a href="https://baugues.com/homeschool">reluctant homeschoolers</a> this year – choosing to teach our five year old daughter without the our school's remote learning. Rachel teaches Reading, Writing, Arts, and Science. My job is Math, Chess, and Technology. </p><p>I started programming on a <a href="https://baugues.com/trs-80">TRS-80</a> when I was six or seven. Back then, the computer booted into BASIC, the most approachable programming language of all time. Hello World in BASIC looks something like:</p><pre><code>10 print "hello world" 
20 goto 10
</code></pre><p>Programming in BASIC was the most instant gratification you could get on a TRS-80. There were few games and no Internet. Had I been introduced to a different programming language at a different age, I'm not sure I would have taken to it.</p><p>That's been a problem I've been wrestling with when introducing our daughter, Emma, to programming. Modern developer environments have a lot of friction and overhead. We've played with Swift Playgrounds, which is great for introducing programming concepts, but feels like you're writing instructions inside a video game as opposed to harnessing the the raw power of code to control the computer.</p><p>A colleague recently introduced me to <a href="https://repl.it/talk/announcements/Announcing-Basic-Language-With-Graphics-Beta/31741">pg-basic on repl.it</a>, which recaptures the simplicity of writing BASIC on a TRS-80.</p><p>Emma and I are working on addition. She likes video games and coding, so I figured we could create a game to practice math. The general idea is: pick two numbers at random, ask her to add them, give her points if she gets it right. We did it in Python, as the code was't that dissimilar to its Basic equivalent. </p><p>Go ahead, run it. (And edit, if you wish.) </p><!--kg-card-begin: html--><!--kg-card-end: html--><p>I composed the code with her sitting next to me, asking for her suggestions along the way.</p><ul><li>"What should we name this variable?"</li><li>"How many points should you get when you get one right?"</li><li>"How many points do you need to win?"</li><li>"What should it say when you win?" </li></ul><p>Then I made her a deal: if she won the game two times, she could cheat and change the code. She loves cheating.</p><p>She quickly figured out she could change the lines that generate numbers to:</p><pre><code>lulu = 0
boonie = random.randrange(11)
</code></pre><p>Math problems got easier. Then she changed it to: </p><pre><code>lulu = 0
boonie = 0
</code></pre><p>Problems got <em>a lot</em> easier.</p><p>She still had to answer a bunch of questions to win the game, and typing zero and enter repeatedly is hard work, so she changed the looping condition to:</p><pre><code>while points &lt; 1:
</code></pre><p>It may be the first time in her short educational career when she's had control over the quiz, instead of the quiz having control over her.</p><p>Thinking back to how I started writing code, it was copying a few dozen lines of BASIC out of the back of <em><a href="http://games.datagrind.com/index.php?pageid=10">3-2-1 Contact</a></em>, getting it to run, and then tweaking it. Today, when I learn a new language or service, it's "copy, paste, edit."</p><p>Composing along side Emma and letting her edit seems to be a winning strategy. Yesterday, after making a modification, she thought for a few seconds, turned to look at me, and said, "... I can use code to do <em>anything</em>."</p><p>She's starting to get it.</p>
			</section></div>]]>
            </description>
            <link>https://baugues.com/cheat-code/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24699448</guid>
            <pubDate>Tue, 06 Oct 2020 16:22:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Time for a WTF MySQL Moment]]>
            </title>
            <description>
<![CDATA[
Score 321 | Comments 113 (<a href="https://news.ycombinator.com/item?id=24698660">thread link</a>) | @gbl08ma
<br/>
October 6, 2020 | https://gbl08ma.com/time-for-a-wtf-mysql-moment/ | <a href="https://web.archive.org/web/*/https://gbl08ma.com/time-for-a-wtf-mysql-moment/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content-holder" role="main">
	<div>
		<article id="post-21465">			
			
	<p>
				October 4, 2020 / gbl08ma / 0 Comments	</p>
	<p>Many people have been experiencing strange time perception phenomenon throughout 2020, but certain database management systems have been into time shenanigans for way longer. This came to my attention when a friend received the following exception in one of his projects (his popular Discord bot, <a href="https://accord.abcric.net/">Accord</a>), coming from the MySQL connector being used with EF Core:</p>
<pre>MySqlException: Incorrect TIME value: '960:00:00.000000'</pre>
<p>Not being too experienced with MySQL, as I prefer PostgreSQL for reasons that will soon become self-evident, for a brief moment I assumed the incorrection in this value was the hundreds of hours, as one could reasonably assume that maybe TIME values were capped at 24 hours, or that a different syntax was needed for values spanning multiple days, and that one would need to use, say, “40:00:00:00” to represent 40 days. But reality turned out to be more complex and harder to explain.</p>
<p>With checking the documentation being the most natural next step, the MySQL documentation goes:</p>
<blockquote><p>MySQL retrieves and displays <code>TIME</code> values in <em><code>'hh:mm:ss'</code></em> format (or <em><code>'hhh:mm:ss'</code></em> format for large hours values).</p></blockquote>
<p>So far so good, our problematic TIME value respects this format, but the fact that <code>hh</code> and <code>hhh</code> are explicitly pointed out is already suspect (what about values with over 999 hours?). The next sentence in the documentation explains why, and left me with even more questions of the WTF kind:</p>
<blockquote><p><code>TIME</code> values may range from <code>'-838:59:59'</code> to <code>'838:59:59'</code>.</p></blockquote>
<p>Oooh Kaaay… that’s an oddly specific range, but I’m sure there has to be a technical reason for it. 839 hours is 34.958(3) days, and the whole range spans exactly 6040798 seconds. The documentation also mentions the following:</p>
<blockquote><p>MySQL recognizes <code>TIME</code> values in several formats, some of which can include a trailing fractional seconds part in up to microseconds (6 digits) precision.</p></blockquote>
<p>Therefore, it also makes sense to point out that the whole interval spans <span id="display">6 040 798 </span>000 000 microseconds, but again, these seem like oddly specific numbers. They are not near any power of two, the latter being between 2<sup>42</sup> and 2<sup>43</sup>, so MySQL must be using some awkward internal representation format. But before we dive into that, let me just point out how bad this type is. It is the closest MySQL has to a time interval type, and yet it can’t deal with intervals that are just a bit over a month long. How much is that “bit”? Not even a nice, rounded number of days, it seems.</p>
<p>To make matters worse, it appears that the most popular EF Core MySQL provider maps .NET’s <code>TimeSpan</code> to <code>TIME</code> by default, despite the fact that&nbsp;<code>TimeSpan</code> can contain intervals in the dozens of millennia (it uses a 64 bit integer and has 10<sup>-8</sup> s precision) compared to TIME’s measly “a bit over two months”. This is an <a href="https://github.com/PomeloFoundation/Pomelo.EntityFrameworkCore.MySql/issues/1046">issue other people have run into</a>, and the discussion in that issue includes a “This mimics the behavior of SQL Server” remark, which made me go check and, sure enough, SQL Server’s <code>time</code> is meant to encode a time of day and has a range of 00:00:00.0000000 through 23:59:59.9999999, something which overall makes more sense to me than MySQL’s odd TIME range.</p>
<p>So let’s go back to MySQL. What is the reasoning behind such an <em>interesting</em> range? The <a href="https://dev.mysql.com/doc/internals/en/date-and-time-data-type-representation.html">MySQL Internals Manual</a> says that the storage for the TIME type has changed with version 5.6.4, having gained support for fractional seconds in this version. It uses 3 bytes for the non-fractional type. Now, had they just used these 3 bytes to encode a number of seconds, they would have been able to support intervals spanning over 2330 hours, which would already be a considerable improvement over the current 838 hours maximum, even if still a bit useless when it comes to mapping a <code>TimeSpan</code> to it.</p>
<p>This means their encoding must be wasting bits, probably so it is easier to work with… not sure in what circumstances exactly, but maybe it makes more sense if your database management system (and/or your conception of what the users will do with it) just loves strings, and you really want to speed up the hh:mm:ss representation. So, behold:</p>
<blockquote>
<pre>1 bit sign (1= non-negative, 0= negative)
1 bit unused (reserved for future extensions)
10 bits hour (0-838)
6 bits minute (0-59) 
6 bits second (0-59) 
---------------------
24 bits = 3 bytes</pre>
</blockquote>
<p>This explains everything, right? Well, look closely. 10 bits for the hour… and a range of 0 to 838. I kindly remind you that 2<sup>10</sup> is 1024, not 838. The plot thickens. I’m not the first person to wonder about this, of course, <a href="https://stackoverflow.com/questions/39259910/why-is-mysqls-maximum-time-limit-8385959">this was asked on StackOverflow before</a>. The accepted answer in that question explains everything, but <em>it almost didn’t</em>, as it initially dismisses the odd choice of 838 as “backward compatibility with applications that were written a while ago”, and only later it is explained that this choice had to do with compatibility with MySQL version… 3, from the times when, you know, Windows 98 was a fresh operating system and Linux wasn’t 10 years old yet.</p>
<p>In MySQL 3, the TIME type used 3 bytes as well, but they were used differently. One of the bits was used for the sign as well, but the remaining 23 bits were an integer value produced like this: Hours × 10000 + Minutes × 100 + Seconds; in other words, the two least significant decimal digits of the number contained the seconds, the next two contained the minutes, and the remaining ones contained the hours. 2<sup>23</sup> is 83888608, i.e. 838:86:08, therefore, the maximum valid time in this format is 838:59:59. This format is even less wieldy than the current one, requiring multiplication and division to do basically anything with it, except string formatting and parsing – once again showing that MySQL places too much value on string IO and not so much on having types that are convenient for internal operations and non-string-based protocols.</p>
<p>MySQL developers had ample opportunities to fix this type, or at the very least introduce an alternative one that is free of this reduced range. They changed this type twice from MySQL 3 until now, but decided to retain the range every time, supposedly for compatibility reasons. I am struggling to imagine the circumstances where increasing the value range for a type can break compatibility with an application – do types in MySQL have defined overflow behaviors? Is any sane person writing applications where they are relying on a database type’s intrinsic limits for validation? If yes, who looked at this awkward 838 hours range and thought of it as an appropriate limitation to carry unchanged into their application’s data model? At this point, I don’t even want to know.</p>
<p>Despite having changed twice throughout MySQL’s lifetime, the TIME type is still quite an awkward and limited one. That unused, “reserved for future extensions” bit is, in my opinion, really the <em>pièce de résistance</em> here. Here’s hoping that one day it will be used to signify a “legacy” TIME value and that, by then, MySQL and/or MariaDB will have support for a proper type like <a href="https://www.postgresql.org/docs/current/datatype-datetime.html">PostgreSQL’s INTERVAL</a>, which has a range of +/- 178000000 years and a very reasonable microsecond precision.</p>
	</article>		
	</div>
	</div></div>]]>
            </description>
            <link>https://gbl08ma.com/time-for-a-wtf-mysql-moment/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24698660</guid>
            <pubDate>Tue, 06 Oct 2020 15:23:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hiring for tech jobs has increased more than 100% in these Midwestern cities]]>
            </title>
            <description>
<![CDATA[
Score 118 | Comments 288 (<a href="https://news.ycombinator.com/item?id=24698449">thread link</a>) | @KaiserSanchez
<br/>
October 6, 2020 | https://www.purpose.jobs/blog/hiring-tech-jobs-has-increased-in-midwestern-cities | <a href="https://web.archive.org/web/*/https://www.purpose.jobs/blog/hiring-tech-jobs-has-increased-in-midwestern-cities">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><img src="https://www.purpose.jobs/hubfs/social-suggested-images/www.michiganbusiness.org49d2d3globalassetsimagesnews1440-bannersdetroit-1440.jpg" alt="Hiring for Tech Jobs has Increased More than 100% in These Midwestern Cities">
</p></div><div>
<p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p>When people think tech jobs, they tend to think Silicon Valley or New York City.</p>
<!--more-->
<p>They don’t think about the Midwest, which is better known for rolling farmland and wide-open spaces than a booming tech scene where startups thrive.</p>
<p>But it’s time to think again about the Midwest.&nbsp;</p>
<p><a href="https://www.purpose.jobs/midwest-salary-report?utm_source=blog&amp;utm_medium=web&amp;utm_campaign=community" rel="noopener" target="_blank"><img src="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-1-midwest.jpg?width=600&amp;name=img-1-midwest.jpg" alt="img-1-midwest" width="600" srcset="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-1-midwest.jpg?width=300&amp;name=img-1-midwest.jpg 300w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-1-midwest.jpg?width=600&amp;name=img-1-midwest.jpg 600w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-1-midwest.jpg?width=900&amp;name=img-1-midwest.jpg 900w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-1-midwest.jpg?width=1200&amp;name=img-1-midwest.jpg 1200w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-1-midwest.jpg?width=1500&amp;name=img-1-midwest.jpg 1500w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-1-midwest.jpg?width=1800&amp;name=img-1-midwest.jpg 1800w" sizes="(max-width: 600px) 100vw, 600px"></a></p>
<p>This region comprises 19 percent of the <em>entire U.S. GDP</em>. Twenty-five percent of all computer science grads get their degrees in the Midwest. Forty-five percent of Fortune 500 countries are located here, as is 60 percent of all U.S. manufacturing.</p>
<p>And, as icing on the cake, seven of the top 10 <a href="https://www.purpose.jobs/midwest-salary-report?utm_source=blog&amp;utm_medium=web&amp;utm_campaign=community" rel="noopener" target="_blank">most affordable states</a> in the nation are in the Midwest.</p>
<p>What does that have to do with tech jobs? Well, increasingly, startup founders and investors are taking note of all those things the Midwest has to offer, as well as the excellent quality of life and affordable cost of living you can find in so many cities in the Heartland. They’re realizing you don’t have to be based in the Golden State or the Big Apple if you want your startup to succeed. You can be based in the Midwest and find just as much success.</p>
<div><p>So tech startups are booming in the Midwest. Don’t believe us? The proof is in the numbers.</p></div>
<h2><span>In 3 of the Midwest’s Top 10 Cities, Tech Hiring Is Up More than 100% In the Last 3 Years</span></h2>
<div><p>We’ll let the numbers tell the full story. These are the Midwest’s top 10 cities in terms of growth and offerings for tech workers.&nbsp;</p></div>
<h3><span>Chicago: 8th in the U.S. for Net Tech Employment</span><a href="https://www.purpose.jobs/midwest-salary-report?utm_source=blog&amp;utm_medium=web&amp;utm_campaign=community" rel="noopener" target="_blank"><img src="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-2-chicago.jpg?width=600&amp;name=img-2-chicago.jpg" alt="img-2-chicago" width="600" srcset="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-2-chicago.jpg?width=300&amp;name=img-2-chicago.jpg 300w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-2-chicago.jpg?width=600&amp;name=img-2-chicago.jpg 600w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-2-chicago.jpg?width=900&amp;name=img-2-chicago.jpg 900w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-2-chicago.jpg?width=1200&amp;name=img-2-chicago.jpg 1200w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-2-chicago.jpg?width=1500&amp;name=img-2-chicago.jpg 1500w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-2-chicago.jpg?width=1800&amp;name=img-2-chicago.jpg 1800w" sizes="(max-width: 600px) 100vw, 600px"></a></h3>
<div><p><a href="https://www.purpose.jobs/chicago" rel="noopener" target="_blank">Chicago</a> is the No. 1 city in the Midwest for growth in the tech sector, and it ranks eighth in the country for net tech employment. Currently, there are 344,146 people in Chicago working in tech jobs. The city saw nearly 18 percent growth in its net tech employment from 2010 to 2018, and from just 2017 to 2018, job posting in the tech sector increased by a whopping 73 percent.</p></div>
<h3><span>Detroit: 11th in the U.S. for Net Tech Employment</span><a href="https://www.purpose.jobs/midwest-salary-report?utm_source=blog&amp;utm_medium=web&amp;utm_campaign=community" rel="noopener" target="_blank"><img src="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-3-detroit.jpg?width=600&amp;name=img-3-detroit.jpg" alt="img-3-detroit" width="600" srcset="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-3-detroit.jpg?width=300&amp;name=img-3-detroit.jpg 300w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-3-detroit.jpg?width=600&amp;name=img-3-detroit.jpg 600w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-3-detroit.jpg?width=900&amp;name=img-3-detroit.jpg 900w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-3-detroit.jpg?width=1200&amp;name=img-3-detroit.jpg 1200w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-3-detroit.jpg?width=1500&amp;name=img-3-detroit.jpg 1500w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-3-detroit.jpg?width=1800&amp;name=img-3-detroit.jpg 1800w" sizes="(max-width: 600px) 100vw, 600px"></a></h3>
<p>Coming in just behind Chicago is <a href="https://www.purpose.jobs/detroit" rel="noopener" target="_blank">Detroit</a>, which ranks 11th in the U.S. for its net tech employment. 241,135 people work in the tech sector in Detroit, where net tech employment increased by 37.2 percent from 2010 to 2018. From 2017 to 2018, job postings in tech rose 41 percent, making Detroit a fantastic spot to look for a startup job.</p>
<p><em>Looking to get connected with top startups? Join the purpose.jobs talent community to start applying for Midwest startup jobs.</em> <!--HubSpot Call-to-Action Code --><span id="hs-cta-wrapper-6fe04a32-7b40-49d0-873c-8f8ae79aa1dd"><span id="hs-cta-6fe04a32-7b40-49d0-873c-8f8ae79aa1dd"><!--[if lte IE 8]><div id="hs-cta-ie-element"></div><![endif]--><a href="https://cta-redirect.hubspot.com/cta/redirect/2873777/6fe04a32-7b40-49d0-873c-8f8ae79aa1dd" target="_blank"><img id="hs-cta-img-6fe04a32-7b40-49d0-873c-8f8ae79aa1dd" src="https://no-cache.hubspot.com/cta/default/2873777/6fe04a32-7b40-49d0-873c-8f8ae79aa1dd.png" alt="Create a free profile."></a></span></span><!-- end HubSpot Call-to-Action Code --></p>

<h3><span>Minneapolis: Nearly 200,000 Tech Jobs and Growing</span><a href="https://www.purpose.jobs/midwest-salary-report?utm_source=blog&amp;utm_medium=web&amp;utm_campaign=community" rel="noopener" target="_blank"><img src="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-4-minn.jpg?width=600&amp;name=img-4-minn.jpg" alt="img-4-minn" width="600" srcset="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-4-minn.jpg?width=300&amp;name=img-4-minn.jpg 300w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-4-minn.jpg?width=600&amp;name=img-4-minn.jpg 600w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-4-minn.jpg?width=900&amp;name=img-4-minn.jpg 900w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-4-minn.jpg?width=1200&amp;name=img-4-minn.jpg 1200w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-4-minn.jpg?width=1500&amp;name=img-4-minn.jpg 1500w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-4-minn.jpg?width=1800&amp;name=img-4-minn.jpg 1800w" sizes="(max-width: 600px) 100vw, 600px"></a></h3>
<div><p>Third in the Midwest for growth is Minneapolis, a thriving city many overlook, despite its tech workforce of 196,151 and growing. Minneapolis is ranked 14th in the U.S. overall for net tech employment, which increased 17 percent in the city from 2010 to 2018. What’s even more impressive is that job postings in the tech sector increased 76 percent in Minneapolis from 2017 to 2018.</p></div>
<h3><span>Kansas City: Where New Tech Jobs Have Almost Doubled in Recent Years<br></span><a href="https://www.purpose.jobs/midwest-salary-report?utm_source=blog&amp;utm_medium=web&amp;utm_campaign=community" rel="noopener" target="_blank"><img src="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-5-kc.jpg?width=600&amp;name=img-5-kc.jpg" alt="img-5-kc" width="600" srcset="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-5-kc.jpg?width=300&amp;name=img-5-kc.jpg 300w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-5-kc.jpg?width=600&amp;name=img-5-kc.jpg 600w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-5-kc.jpg?width=900&amp;name=img-5-kc.jpg 900w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-5-kc.jpg?width=1200&amp;name=img-5-kc.jpg 1200w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-5-kc.jpg?width=1500&amp;name=img-5-kc.jpg 1500w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-5-kc.jpg?width=1800&amp;name=img-5-kc.jpg 1800w" sizes="(max-width: 600px) 100vw, 600px"></a></h3>
<div><p>Kansas City has more to boast about than its Super Bowl win. The city is home to 100,782 people who work in the tech sector, making it 24th in the U.S. for net tech employment. Kansas City also saw 17.3 percent growth in its net tech employment from 2010 to 2018, and 82 percent growth in its tech job posting just from 2017 to 2018, indicating that its rate of growth is ramping up even faster in recent years than over the last decade.</p></div>
<h3><span>Cincinnati: Nearly 100,000 Tech Workers and Steady Growth of New Jobs<br></span><a href="https://www.purpose.jobs/midwest-salary-report?utm_source=blog&amp;utm_medium=web&amp;utm_campaign=community" rel="noopener" target="_blank"><img src="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-6-cinci.jpg?width=600&amp;name=img-6-cinci.jpg" alt="img-6-cinci" width="600" srcset="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-6-cinci.jpg?width=300&amp;name=img-6-cinci.jpg 300w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-6-cinci.jpg?width=600&amp;name=img-6-cinci.jpg 600w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-6-cinci.jpg?width=900&amp;name=img-6-cinci.jpg 900w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-6-cinci.jpg?width=1200&amp;name=img-6-cinci.jpg 1200w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-6-cinci.jpg?width=1500&amp;name=img-6-cinci.jpg 1500w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-6-cinci.jpg?width=1800&amp;name=img-6-cinci.jpg 1800w" sizes="(max-width: 600px) 100vw, 600px"></a></h3>
<div><p>Fifth on the list of growing Midwest cities in <a href="https://www.purpose.jobs/cincinnati" rel="noopener" target="_blank">Cincinnati</a>, where 82,088 workers already have tech jobs. From 2010 to 2018, the city saw a 23.9 percent increase in its net tech employment, and job postings in the tech sector jumped up 41 percent just from 2017 to 2018. That lands Cincinnati 28th in the U.S. for net tech employment, and there’s plenty of opportunity here as the city continues to grow.</p></div>
<h3><span>Cleveland: Job Growth that Nearly Doubled in Just One Year</span><a href="https://www.purpose.jobs/midwest-salary-report?utm_source=blog&amp;utm_medium=web&amp;utm_campaign=community" rel="noopener" target="_blank"><img src="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-7-cleveland.jpg?width=600&amp;name=img-7-cleveland.jpg" alt="img-7-cleveland" width="600" srcset="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-7-cleveland.jpg?width=300&amp;name=img-7-cleveland.jpg 300w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-7-cleveland.jpg?width=600&amp;name=img-7-cleveland.jpg 600w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-7-cleveland.jpg?width=900&amp;name=img-7-cleveland.jpg 900w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-7-cleveland.jpg?width=1200&amp;name=img-7-cleveland.jpg 1200w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-7-cleveland.jpg?width=1500&amp;name=img-7-cleveland.jpg 1500w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-7-cleveland.jpg?width=1800&amp;name=img-7-cleveland.jpg 1800w" sizes="(max-width: 600px) 100vw, 600px"></a></h3>
<div><p>Sixth in the Midwest is <a href="https://www.purpose.jobs/cleveland" rel="noopener" target="_blank">Cleveland</a>, an oft-overlooked Ohio metropolis that has plenty to offer tech workers —&nbsp;just ask the 76,698 workers who have tech jobs there. Cleveland saw 16.3 percent growth in its net tech employment from 2010 to 2018, which led to its 93 percent increase in tech job postings from 2017 to 2018. Of all the cities in the U.S., Cleveland ranks 29th for net tech employment, making it a place well worth considering whether you’re looking for a tech job or hoping to found a startup in a new home.</p></div>
<h3><span>Indianapolis: More than 100 Percent Job Growth in One Year</span><a href="https://www.purpose.jobs/midwest-salary-report?utm_source=blog&amp;utm_medium=web&amp;utm_campaign=community" rel="noopener" target="_blank"><img src="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-8-indi.jpg?width=600&amp;name=img-8-indi.jpg" alt="img-8-indi" width="600" srcset="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-8-indi.jpg?width=300&amp;name=img-8-indi.jpg 300w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-8-indi.jpg?width=600&amp;name=img-8-indi.jpg 600w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-8-indi.jpg?width=900&amp;name=img-8-indi.jpg 900w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-8-indi.jpg?width=1200&amp;name=img-8-indi.jpg 1200w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-8-indi.jpg?width=1500&amp;name=img-8-indi.jpg 1500w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-8-indi.jpg?width=1800&amp;name=img-8-indi.jpg 1800w" sizes="(max-width: 600px) 100vw, 600px"></a></h3>
<div><p><a href="https://www.purpose.jobs/indianapolis" rel="noopener" target="_blank">Indianapolis</a> is the first of our three Midwestern cities that increased their startup job growth more than 100 percent —&nbsp;the city saw a 121 percent increase in new tech job postings from 2017 to 2018, after 24.2 percent growth in net tech employment from 2010 to 2018. As of now, there are 74,615 people employed in the tech sector in Indy, and that number is only going up.</p></div>
<h3><span>Milwaukee: Tied for Highest Increase in New Tech Jobs in the Midwest</span><a href="https://www.purpose.jobs/midwest-salary-report?utm_source=blog&amp;utm_medium=web&amp;utm_campaign=community" rel="noopener" target="_blank"><img src="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-9-milwak.jpg?width=600&amp;name=img-9-milwak.jpg" alt="img-9-milwak" width="600" srcset="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-9-milwak.jpg?width=300&amp;name=img-9-milwak.jpg 300w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-9-milwak.jpg?width=600&amp;name=img-9-milwak.jpg 600w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-9-milwak.jpg?width=900&amp;name=img-9-milwak.jpg 900w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-9-milwak.jpg?width=1200&amp;name=img-9-milwak.jpg 1200w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-9-milwak.jpg?width=1500&amp;name=img-9-milwak.jpg 1500w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-9-milwak.jpg?width=1800&amp;name=img-9-milwak.jpg 1800w" sizes="(max-width: 600px) 100vw, 600px"></a></h3>
<div><p>With an astonishing 137 percent increase in new tech job postings from 2017 to 2018, Milwaukee is one of the most promising spots in the Midwest for anyone looking for a tech position. The city currently boasts 71,755 tech workers after a 9.2 percent increase in net tech employment from 2010 to 2018. Sure, that’s slower growth over the course of the decade than some of the cities on our list, but the rate of new job postings in Milwaukee show this city is just getting started.</p></div>
<h3><span>Omaha: An Unlikely Hotspot for New Tech Job Postings</span><a href="https://www.purpose.jobs/midwest-salary-report?utm_source=blog&amp;utm_medium=web&amp;utm_campaign=community" rel="noopener" target="_blank"><img src="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-10-omaha.jpg?width=600&amp;name=img-10-omaha.jpg" alt="img-10-omaha" width="600" srcset="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-10-omaha.jpg?width=300&amp;name=img-10-omaha.jpg 300w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-10-omaha.jpg?width=600&amp;name=img-10-omaha.jpg 600w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-10-omaha.jpg?width=900&amp;name=img-10-omaha.jpg 900w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-10-omaha.jpg?width=1200&amp;name=img-10-omaha.jpg 1200w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-10-omaha.jpg?width=1500&amp;name=img-10-omaha.jpg 1500w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-10-omaha.jpg?width=1800&amp;name=img-10-omaha.jpg 1800w" sizes="(max-width: 600px) 100vw, 600px"></a></h3>
<div><p>Like Milwaukee, Omaha also had a stunning 137 percent increase in new tech job postings from 2017 to 2018. While growth in net tech jobs in the city was only 10.7 percent from 2010 to 2018, all that seems to indicate is that tech workers are <em>just</em> starting to realize what Omaha has to offer. 37,508 tech workers live in the city now, but with such a marked increase in new tech jobs, we can only see that number going up.</p></div>
<h3><span>Des Moines: Second-Highest 10-Year Growth in the Midwest</span><a href="https://www.purpose.jobs/midwest-salary-report?utm_source=blog&amp;utm_medium=web&amp;utm_campaign=community" rel="noopener" target="_blank"><img src="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-11-des-moines.jpg?width=600&amp;name=img-11-des-moines.jpg" alt="img-11-des-moines" width="600" srcset="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-11-des-moines.jpg?width=300&amp;name=img-11-des-moines.jpg 300w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-11-des-moines.jpg?width=600&amp;name=img-11-des-moines.jpg 600w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-11-des-moines.jpg?width=900&amp;name=img-11-des-moines.jpg 900w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-11-des-moines.jpg?width=1200&amp;name=img-11-des-moines.jpg 1200w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-11-des-moines.jpg?width=1500&amp;name=img-11-des-moines.jpg 1500w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-11-des-moines.jpg?width=1800&amp;name=img-11-des-moines.jpg 1800w" sizes="(max-width: 600px) 100vw, 600px"></a></h3>
<div><p>While Des Moines is 10th in the top 10 Midwestern cities, it’s had the second-highest rate of growth in net tech employment from 2010 to 2018: 26.9 percent, behind only Detroit. Des Moines is currently home to 28,693 tech workers, and from 2017 to 2018, saw a 47 percent increase in new tech job postings.&nbsp;</p></div>
<h2><span>Midwestern Companies Are Hiring Tens of Thousands of Tech Workers Right Now</span></h2>
<div><p>In Chicago, Detroit, and Indianapolis alone, there are nearly 31,000 open tech positions at any given time. The Midwest is next for tech workers. Find out more with a free download of the Midwest Salary and Cost of Living Handbook.</p></div>
<p><!--HubSpot Call-to-Action Code --><span id="hs-cta-wrapper-d825b188-3a7f-4d00-ac4a-1ef02e65ec84"><span id="hs-cta-d825b188-3a7f-4d00-ac4a-1ef02e65ec84"><!--[if lte IE 8]><div id="hs-cta-ie-element"></div><![endif]--><a href="https://cta-redirect.hubspot.com/cta/redirect/2873777/d825b188-3a7f-4d00-ac4a-1ef02e65ec84" target="_blank"><img id="hs-cta-img-d825b188-3a7f-4d00-ac4a-1ef02e65ec84" height="709" width="1600" src="https://no-cache.hubspot.com/cta/default/2873777/d825b188-3a7f-4d00-ac4a-1ef02e65ec84.png" alt="New call-to-action"></a></span></span><!-- end HubSpot Call-to-Action Code --></p>

<p><strong><br></strong><strong><img src="https://www.purpose.jobs/hs-fs/hubfs/Christina%20headshot.png?width=120&amp;name=Christina%20headshot.png" alt="Christina headshot" width="120" srcset="https://www.purpose.jobs/hs-fs/hubfs/Christina%20headshot.png?width=60&amp;name=Christina%20headshot.png 60w, https://www.purpose.jobs/hs-fs/hubfs/Christina%20headshot.png?width=120&amp;name=Christina%20headshot.png 120w, https://www.purpose.jobs/hs-fs/hubfs/Christina%20headshot.png?width=180&amp;name=Christina%20headshot.png 180w, https://www.purpose.jobs/hs-fs/hubfs/Christina%20headshot.png?width=240&amp;name=Christina%20headshot.png 240w, https://www.purpose.jobs/hs-fs/hubfs/Christina%20headshot.png?width=300&amp;name=Christina%20headshot.png 300w, https://www.purpose.jobs/hs-fs/hubfs/Christina%20headshot.png?width=360&amp;name=Christina%20headshot.png 360w" sizes="(max-width: 120px) 100vw, 120px"></strong><em><strong>Christina Marfice</strong> is a born and raised Midwesterner who traveled the globe and came right back. She has been a journalist and freelance writer for almost ten years. In addition to her other projects, she explores startup strategies, business operations, and eCommerce topics for&nbsp;<a target="_blank" data-stringify-link="https://www.yesoptimist.com/" delay="150" data-sk="tooltip_parent" href="https://www.yesoptimist.com/" rel="noopener">Optimist</a>. She currently resides in Chicago with her two cats, Dumpling and Doughnut.</em></p></span>
</p>

</div></div>]]>
            </description>
            <link>https://www.purpose.jobs/blog/hiring-tech-jobs-has-increased-in-midwestern-cities</link>
            <guid isPermaLink="false">hacker-news-small-sites-24698449</guid>
            <pubDate>Tue, 06 Oct 2020 15:09:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Deploy to K8s without YAML using ShuttleOps]]>
            </title>
            <description>
<![CDATA[
Score 61 | Comments 52 (<a href="https://news.ycombinator.com/item?id=24698326">thread link</a>) | @gscho
<br/>
October 6, 2020 | https://go.shuttleops.io/no-code-docker-kubernetes | <a href="https://web.archive.org/web/*/https://go.shuttleops.io/no-code-docker-kubernetes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<div data-widget-type="custom_widget" data-x="0" data-w="12">
<p><span id="hs_cos_wrapper_module_159802898093264_" data-hs-cos-general-type="widget" data-hs-cos-type="rich_text"><h2><span>See How No-Code </span><span id="5f0fb456-fdf5-4e5b-993a-ec7087c62a86" data-renderer-mark="true" data-mark-type="annotation" data-mark-annotation-type="inlineComment" data-id="5f0fb456-fdf5-4e5b-993a-ec7087c62a86">Continuous Delivery<br></span><span>&nbsp;Can Accelerate Your Business</span></h2>
<h5>The same powerful drag-and-drop interface, true multicloud integration and security and compliance you’ve come to expect from ShuttleOps, now with Docker and Kubernetes support. See how easy it is to onboard your application, your team, and scale your delivery. Get started today for free. No credit card required!&nbsp;</h5>

<p><span><!--HubSpot Call-to-Action Code --><span id="hs-cta-wrapper-fcb53eb1-7328-44f8-b128-f953ffc8bab9"><span id="hs-cta-fcb53eb1-7328-44f8-b128-f953ffc8bab9"><!--[if lte IE 8]><div id="hs-cta-ie-element"></div><![endif]--><a href="https://cta-redirect.hubspot.com/cta/redirect/5669359/fcb53eb1-7328-44f8-b128-f953ffc8bab9"><img id="hs-cta-img-fcb53eb1-7328-44f8-b128-f953ffc8bab9" src="https://no-cache.hubspot.com/cta/default/5669359/fcb53eb1-7328-44f8-b128-f953ffc8bab9.png" alt="Get Started"></a></span></span><!-- end HubSpot Call-to-Action Code --></span></p></span></p>

</div><!--end widget-span -->
</div><!--end row-->
</div></div>]]>
            </description>
            <link>https://go.shuttleops.io/no-code-docker-kubernetes</link>
            <guid isPermaLink="false">hacker-news-small-sites-24698326</guid>
            <pubDate>Tue, 06 Oct 2020 14:58:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[4x4 Macro Pad Kit]]>
            </title>
            <description>
<![CDATA[
Score 77 | Comments 39 (<a href="https://news.ycombinator.com/item?id=24697624">thread link</a>) | @0xC45
<br/>
October 6, 2020 | https://0xc45.com/blog/4x4-macro-pad/ | <a href="https://web.archive.org/web/*/https://0xc45.com/blog/4x4-macro-pad/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <header>
        
    </header>
    <p>10/6/2020</p>
    <h2>Contents</h2>
    <ul>
        
        <li>
            <a href="https://0xc45.com/blog/4x4-macro-pad/#overview">Overview</a>
            
        </li>
        
        <li>
            <a href="https://0xc45.com/blog/4x4-macro-pad/#build-process">Build Process</a>
            
        </li>
        
        <li>
            <a href="https://0xc45.com/blog/4x4-macro-pad/#flash-firmware">Flash Firmware</a>
            
        </li>
        
        <li>
            <a href="https://0xc45.com/blog/4x4-macro-pad/#design-keycaps">Design Keycaps</a>
            
        </li>
        
        <li>
            <a href="https://0xc45.com/blog/4x4-macro-pad/#conclusion">Conclusion</a>
            
        </li>
        
        <li>
            <a href="https://0xc45.com/blog/4x4-macro-pad/#links">Links</a>
            
        </li>
        
    </ul>
    <section>
<h2 id="overview">Overview</h2>
<p>Last weekend, I built a 4x4 keyboard kit. By this point, many people are familiar with the growing (and outspoken) mechanical keyboard hobbyist community. However, this kit is a bit unique. It's not a full keyboard. Instead, it's a 4x4 "macro pad" intended for sending keyboard shortcut sequences such as muting my microphone, muting my audio, volume up, volume down, etc. Additionally, with some extra software such as AutoHotKey, vastly complex programs could be triggered with the press of a button.</p>
<h2 id="build-process">Build Process</h2>
<p>Overall, building the macro pad was a simple and straightforward process. The <a href="https://www.1upkeyboards.com/instructions-downloads/sweet-16-instructions/">kit's build guide</a> provides a nice set of instructions with pictures to explain things. However, unlike many (some?) keyboard kits, the Sweet 16 kit requires soldering a few smaller components, such as the diodes and microcontroller headers. Additionally, the kit requires soldering one "surface-mount" component, the reset switch.</p>
<p>The parts:
<img src="https://0xc45.com/blog/4x4-macro-pad/sweet16-parts.jpg" alt="Sweet16 Parts"></p>
<p>Completed build:
<img src="https://0xc45.com/blog/4x4-macro-pad/sweet16-solder-joints.jpg" alt="Sweet16 Solder Joints"></p>
<h2 id="flash-firmware">Flash Firmware</h2>
<p>To program my custom keymap (including multiple keypress macros), I used <a href="https://qmk.fm/">QMK firmware</a>, the most popular keyboard firmware project.</p>
<p>Using QMK, it's possible to create custom keycodes that, when pressed, trigger a sequence of inputs. So, by pressing one button on the macro pad (or keyboard), the firmware will submit an entire sequence of keycode presses.</p>
<p>To do this, I defined my custom keycodes in an enum:</p>
<pre><code><span>enum </span><span>macro_keycodes {
  MICMUTE = SAFE_RANGE,
  MACRO1,
  MACRO2,
  MACRO3,
  MACRO4,
  MACRO5,
  MACRO6,
  MACRO7,
  MACRO8
};
</span></code></pre>
<p>Next, I defined a "keymap" array. Each position in the array corresponds to a single button on the 4x4 macro pad:</p>
<pre><code><span>const </span><span>uint16_t PROGMEM keymaps[][MATRIX_ROWS][MATRIX_COLS] = {
  [</span><span>0</span><span>] = </span><span>LAYOUT_ortho_4x4</span><span>( </span><span>/* Base */</span><span>
    MICMUTE, KC_MUTE, KC_VOLD, KC_VOLU,
    XXXXXXX, XXXXXXX, XXXXXXX, XXXXXXX,
    MACRO1,  MACRO2,  MACRO3,  MACRO4,
    MACRO5,  MACRO6,  MACRO7,  MACRO8
  ),
};
</span></code></pre>
<p>Lastly, I implemented the <code>process_record_user</code> function to define what should happen when each custom keycode is pressed:</p>
<pre><code><span>bool </span><span>process_record_user</span><span>(uint16_t </span><span>keycode</span><span>, keyrecord_t *</span><span>record</span><span>) {
  </span><span>switch </span><span>(keycode) {
  </span><span>case</span><span> MICMUTE:
    </span><span>if </span><span>(record-&gt;event.</span><span>pressed</span><span>) {
      </span><span>SEND_STRING</span><span>(</span><span>SS_LCTL</span><span>(</span><span>SS_LALT</span><span>(</span><span>SS_LSFT</span><span>(</span><span>SS_TAP</span><span>(X_F10)))));
    }
    </span><span>break</span><span>;
  </span><span>case</span><span> MACRO1:
    </span><span>if </span><span>(record-&gt;event.</span><span>pressed</span><span>) {
      </span><span>SEND_STRING</span><span>(</span><span>SS_LCTL</span><span>(</span><span>SS_LALT</span><span>(</span><span>SS_LSFT</span><span>(</span><span>SS_TAP</span><span>(X_F1)))));
    }
    </span><span>break</span><span>;
  </span><span>/*
   * ... etc
   */
  </span><span>}
  </span><span>return </span><span>true
</span><span>}
</span></code></pre>
<p>As you can see, I have configured the <code>MICMUTE</code> button to send the entire sequence <code>CTRL+ALT+SHIFT+F10</code>. However, in practice, any arbitrary sequence could be sent for any button. And, that's only beginning to scratch the surface of the capabilities of the QMK firmware.</p>
<h2 id="design-keycaps">Design Keycaps</h2>
<p>For this "DIY" kit, it felt important to design my own icons. I'm no graphic designer, but it was kinda fun. To do this, I used "re-legendable" keycaps that snap together with a clear top. Then, I printed the icons on plain white paper, cut them out, and sandwiched each icon in the keycaps. Here's a photo of my efforts:</p>
<p><img src="https://0xc45.com/blog/4x4-macro-pad/sweet16-completed.jpg" alt="Sweet16 Completed"></p>
<h2 id="conclusion">Conclusion</h2>
<p>This was a pretty quick project, but I felt like it deserved a writeup nevertheless. As a relative beginner at soldering, this kit was a fantastic way to increase my skills and ability beyond the "absolute beginner" level required for most keyboard kits. Furthermore, the final product is quite useful and extensible. Beyond the specific purpose as a simple macro pad keyboard, this hardware is essentially a microcontroller connected to a set of buttons. There are numerous possible applications. It's ripe for hacking. This device could become a MIDI controller, home automation remote, or anything else my imagination might dream up. Until next time.</p>
<h2 id="links">Links</h2>
<ol>
<li>Sweeet 16 Macro Pad Kit: <a href="https://www.1upkeyboards.com/shop/keyboard-kits/macro-pads/sweet-16-macro-pad-black/">https://www.1upkeyboards.com/shop/keyboard-kits/macro-pads/sweet-16-macro-pad-black/</a></li>
<li>QMK Firmware: <a href="https://qmk.fm/">https://qmk.fm/</a></li>
<li>My Sweet 16 Keymap: <a href="https://github.com/0xC45/qmk-firmware/blob/master/keyboards/1upkeyboards/sweet16/keymaps/0xC45/keymap.c">https://github.com/0xC45/qmk-firmware/blob/master/keyboards/1upkeyboards/sweet16/keymaps/0xC45/keymap.c</a></li>
</ol>

    </section>
</article></div>]]>
            </description>
            <link>https://0xc45.com/blog/4x4-macro-pad/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24697624</guid>
            <pubDate>Tue, 06 Oct 2020 13:49:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cyclone Scheme]]>
            </title>
            <description>
<![CDATA[
Score 89 | Comments 29 (<a href="https://news.ycombinator.com/item?id=24696939">thread link</a>) | @andrenth
<br/>
October 6, 2020 | https://justinethier.github.io/cyclone/ | <a href="https://web.archive.org/web/*/https://justinethier.github.io/cyclone/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main_content_wrap">
      <section id="main_content">
      <p>Cyclone Scheme is a brand-new compiler that allows real-world application development using the R<sup>7</sup>RS Scheme Language standard. We provide modern features and a stable system capable of generating fast native binaries.</p>

<p><a href="https://github.com/justinethier/cyclone/raw/master/docs/research-papers/CheneyMTA.pdf">Cheney on the MTA</a> is used by Cyclone’s runtime to implement full tail recursion, continuations, and generational garbage collection. In addition, the Cheney on the MTA concept has been extended to allow execution of multiple native threads. An on-the-fly garbage collector is used to manage the second-generation heap and perform major collections without “stopping the world”.</p>



<ul>
  <li>Support for the majority of the Scheme language as specified by the latest <a href="https://justinethier.github.io/cyclone/docs/Scheme-Language-Compliance.html">R<sup>7</sup>RS standard</a>.</li>
  <li>New features from R<sup>7</sup>RS including libraries, exceptions, and record types.</li>
  <li>Built-in support for Unicode strings and characters.</li>
  <li>Hygienic macros based on <code>syntax-rules</code></li>
  <li>Low-level explicit renaming macros</li>
  <li>Guaranteed tail call optimizations</li>
  <li>Native multithreading support</li>
  <li>A foreign function interface that allows easy integration with C</li>
  <li>A concurrent, generational garbage collector based on Cheney on the MTA</li>
  <li>Includes an optimizing Scheme-to-C compiler,</li>
  <li>… as well as an interpreter for debugging</li>
  <li>A <a href="https://github.com/cyclone-scheme/cyclone-winds">Package Manager</a> and a growing list of packages.</li>
  <li>Support for <a href="https://justinethier.github.io/cyclone/docs/API.html#srfi-libraries">many popular SRFI’s</a></li>
  <li>Online user manual and API documentation</li>
  <li>Support for Linux, Windows, FreeBSD, and Mac platforms.</li>
  <li>Known to run on x86-64, x86, and Arm (Raspberry Pi) architectures.</li>
</ul>



<p>There are several options available for installing Cyclone:</p>

<h2 id="docker">Docker</h2>
<p><img src="https://justinethier.github.io/cyclone/docs/images/docker-thumb.png" alt="Docker" title="Docker"></p>

<p>Cyclone can be run from a <a href="https://hub.docker.com/r/cyclonescm/cyclone">Docker Image</a>:</p>

<div><div><pre><code>docker run -it cyclonescm/cyclone bash
</code></pre></div></div>

<h2 id="homebrew">Homebrew</h2>
<p><img src="https://justinethier.github.io/cyclone/docs/images/homebrew-thumb.png" alt="Homebrew" title="Homebrew"></p>

<p>Mac (and Linux!) users wanting to use Homebrew can do the following.</p>

<p>Note if Homebrew is not already installed: follow the instructions at <a href="https://brew.sh/">https://brew.sh/</a> to install the homebrew package manager.</p>

<div><div><pre><code>brew tap cyclone-scheme/cyclone
brew install cyclone-scheme/cyclone/cyclone-bootstrap
</code></pre></div></div>

<h2 id="arch-linux">Arch Linux</h2>
<p><img src="https://justinethier.github.io/cyclone/docs/images/arch-linux-thumb.png" alt="Arch Linux" title="Arch Linux"></p>

<p>Arch Linux users can install using the <a href="https://aur.archlinux.org/packages/cyclone-scheme/">AUR</a>:</p>

<div><div><pre><code>git clone https://aur.archlinux.org/cyclone-scheme.git
cd cyclone-scheme
makepkg -si
</code></pre></div></div>

<h2 id="build-from-source">Build from Source</h2>
<p><img src="https://justinethier.github.io/cyclone/docs/images/build-thumb.png" alt="Build from Source" title="Build from Source"></p>

<p>To install Cyclone on your machine for the first time on Linux, Windows, FreeBSD, and for Mac users wanting to install without using Homebrew, use <a href="https://github.com/justinethier/cyclone-bootstrap"><strong>cyclone-bootstrap</strong></a> to build a set of binaries. Instructions are provided for Linux, Mac, Windows (via MSYS), and FreeBSD 12.</p>



<p>After installing you can run the <code>cyclone</code> command to compile a single Scheme file:</p>

<div><div><pre><code>$ cyclone examples/fac.scm
$ examples/fac
3628800
</code></pre></div></div>

<p>And the <code>icyc</code> command to start an interactive interpreter. Note you can use <a href="http://linux.die.net/man/1/rlwrap"><code>rlwrap</code></a> to make the interpreter more friendly, EG: <code>rlwrap icyc</code>:</p>

<div><div><pre><code>$ icyc

              :@
            @@@
          @@@@:
        `@@@@@+
       .@@@+@@@      
       @@     @@     Cyclone Scheme-&gt;C compiler
      ,@             http://justinethier.github.io/cyclone/
      '@
      .@
       @@     #@     (c) 2014-2019 Justin Ethier
       `@@@#@@@.     Version 0.11
        #@@@@@
        +@@@+
        @@#
      `@.
   
cyclone&gt; (write 'hello-world)
hello-world
</code></pre></div></div>

<p>Read the documentation below for more information on how to use Cyclone.</p>



<p><img src="https://justinethier.github.io/cyclone/docs/images/cyclone-winds-small.png" alt="Cyclone Winds" title="Cyclone Winds"></p>

<p>The <code>cyclone-winds</code> package manager provides the ability to install packaged libraries and programs for Cyclone. See the <a href="https://github.com/cyclone-scheme/cyclone-winds#cyclone-winds">cyclone-winds</a> site for more information.</p>



<ul>
  <li>
    <p>The <a href="https://justinethier.github.io/cyclone/docs/User-Manual">User Manual</a> covers in detail how to use Cyclone and provides information on the Scheme language features implemented by Cyclone.</p>
  </li>
  <li>
    <p>An <a href="https://justinethier.github.io/cyclone/docs/API">API Reference</a> is available for all libraries provided by Cyclone, including a complete alphabetical listing.</p>
  </li>
  <li>
    <p>If you need a resource to start learning the Scheme language you may want to try a classic textbook such as <a href="https://mitpress.mit.edu/sicp/full-text/book/book.html">Structure and Interpretation of Computer Programs</a>.</p>
  </li>
  <li>
    <p>Finally, this <a href="http://ecraven.github.io/r7rs-benchmarks/benchmark.html">benchmarks</a> page by <a href="https://github.com/ecraven">ecraven</a> compares the performance of Cyclone with other Schemes.</p>
  </li>
</ul>



<p>Cyclone provides several example programs, including:</p>

<ul>
  <li>
    <p><a href="https://github.com/justinethier/cyclone/blob/master/examples/tail-call-optimization.scm">Tail Call Optimization</a> - A simple example of Scheme tail call optimization; this program runs forever, calling into two mutually recursive functions.</p>
  </li>
  <li>
    <p><a href="https://github.com/justinethier/cyclone/blob/master/examples/threading">Threading</a> - Various examples of multi-threaded programs.</p>
  </li>
  <li>
    <p><a href="https://github.com/justinethier/cyclone/blob/master/examples/game-of-life">Game of Life</a> - The <a href="https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life">Conway’s game of life</a> example program and libraries from R<sup>7</sup>RS.</p>
  </li>
  <li>
    <p><a href="https://github.com/justinethier/cyclone/blob/master/examples/game-of-life-png">Game of Life PNG Image Generator</a> - A modified version of game of life that uses libpng to create an image of each iteration instead of writing it to console. This example also demonstrates basic usage of the C Foreign Function Interface (FFI).</p>
  </li>
  <li>
    <p>Finally, the largest program is the compiler itself. Most of the code is contained in a series of libraries which are used by <a href="https://github.com/justinethier/cyclone/blob/master/cyclone.scm"><code>cyclone.scm</code></a> and <a href="https://github.com/justinethier/cyclone/blob/master/icyc.scm"><code>icyc.scm</code></a> to create executables for Cyclone’s compiler and interpreter.</p>
  </li>
</ul>



<ul>
  <li>
    <p><a href="https://justinethier.github.io/cyclone/docs/Writing-the-Cyclone-Scheme-Compiler-Revised-2017">Writing the Cyclone Scheme Compiler</a> provides high-level details on how the compiler was written and how it works.</p>
  </li>
  <li>
    <p>There is a <a href="https://justinethier.github.io/cyclone/docs/Development">Development Guide</a> with instructions for common tasks when hacking on the compiler itself.</p>
  </li>
  <li>
    <p>Cyclone’s <a href="https://justinethier.github.io/cyclone/docs/Garbage-Collector">Garbage Collector</a> is documented at a high-level. This document includes details on extending Cheney on the MTA to support multiple stacks and fusing that approach with a tri-color marking collector.</p>
  </li>
  <li>
    <p>The garbage collector was subsequently enhanced to support <a href="https://justinethier.github.io/cyclone/docs/Garbage-Collection-Using-Lazy-Sweeping">Lazy Sweeping</a> which improves performance for a wide range of applications.</p>
  </li>
</ul>



<p>Copyright (C) 2014 <a href="http://github.com/justinethier">Justin Ethier</a>.</p>

<p>Cyclone is available under the <a href="http://www.opensource.org/licenses/mit-license.php">MIT license</a>.</p>

            <h2>Recent News</h2>
      
        <h4>
          <a href="https://justinethier.github.io/cyclone//2020/09/17/Released-Cyclone-Scheme-0.21.html">Released Cyclone Scheme 0.21</a>
        </h4>
        <span>September 17, 2020</span>
        <br>
        Various bug fixes and continuous integration support for FreeBSD.
      
        <h4>
          <a href="https://justinethier.github.io/cyclone//2020/08/14/Released-Cyclone-Scheme-0.20.html">Released Cyclone Scheme 0.20</a>
        </h4>
        <span>August 14, 2020</span>
        <br>
        We now have official support for calling Scheme from C.
      
        <h4>
          <a href="https://justinethier.github.io/cyclone//2020/08/03/Released-Cyclone-Scheme-0.19.html">Released Cyclone Scheme 0.19</a>
        </h4>
        <span>August  3, 2020</span>
        <br>
        This release improves error reporting and includes many bug fixes.
      


      </section>
    </div></div>]]>
            </description>
            <link>https://justinethier.github.io/cyclone/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24696939</guid>
            <pubDate>Tue, 06 Oct 2020 12:23:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I am building permapeople.org]]>
            </title>
            <description>
<![CDATA[
Score 137 | Comments 141 (<a href="https://news.ycombinator.com/item?id=24696688">thread link</a>) | @roboben
<br/>
October 6, 2020 | https://permapeople.org/blog/2020/10/05/why-i-am-building-permapeople-org.html | <a href="https://web.archive.org/web/*/https://permapeople.org/blog/2020/10/05/why-i-am-building-permapeople-org.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><img src="https://permapeople.org/blog/assets/why-permapeople.jpg" alt="Two potatoes in an Ikea bag"></p>

<p>Four years ago my grandfather gave me two potatoes. I had no idea what to do, so I put them in bought soil in a big blue Ikea bag on the balcony and with a bit watering, they turned out great and I got hooked on growing food for my family and me. It is really magical if you think of how much you spare our planet with growing your own food: You need to get a job to make money so that you can spend that money on buying food which was produced and delivered close to you by large, complex and very inefficient industries. This system spends incredible amounts of resources (time, energy, labor) which you can save by simply growing your own food. And it doesn’t stop with food only: People grow plants for medicinal uses, to help the nature and wildlife around them, or just for their own pleasure.</p>

<h2 id="the-problem">The Problem</h2>

<p>This season I really tried to scale up and created raised beds all over our small urban plot in Berlin, Germany. I wanted to do it sustainable and close to nature, so I read Toby Hemenway’s Gaia’s Garden, which is probably the most widely read book on permaculture. While it is a good base to start and there are a lot of resources around online, it is actually pretty hard to make all that info useful for my own garden. Most of the time I found myself random googling just to answer simple questions like</p>

<ul>
  <li>What plants in the herb layer are available in my zone?</li>
  <li>What are the best companion plants for Tomatoes?</li>
  <li>What is the best time to sow peas in the garden in my zone?</li>
</ul>

<p>I fell back to having a spreadsheet, a collection of browser bookmarks, and a few books to look up what plants I can grow and how they could fit together in my garden. This took me a lot of time, I’d rather spend in the garden.
After the garden was planned, the next challenge was where to find seeds, seedlings and plants to start the garden. Mostly I googled the plant name I wanted to buy and ordered in whatever shop came up but it would be so much easier to buy it directly from other fellow gardeners.
The season started and another thing I did was writing a diary of all my garden activities. The idea was to learn from past mistakes to grow better next year. It worked well for me but true learning comes from sharing experiences with others, which was not possible with that.
While this worked for this year, I wanted to have something better next year so I started building a platform around all these topics.</p>

<h2 id="a-platform-for-everyone">A Platform for Everyone</h2>

<p>Most of the resources about growing plants you find online are either anecdotal or very scientific. There is no place where a gardening enthusiast can share their experiences, see what other enthusiasts learned already, and collaborate on everything related to growing plants. I think to achieve that, we need:</p>

<p>A <strong>permaculture plant database</strong> which everyone can search easily by common permaculture plant attributes like Layer, preferred light and soil conditions, times when to plant and harvest and benefits for animals, human and the environment. In addition everyone can look up advanced topics like companion planting and guild design. To make this info useful, it needs to be verified by others through ratings, comments and linked sources. If someone could see that most people were successful with growing that specific variety of a plant in your area or that a certain guild really works for a lot of others, that would be a huge help for everyone.</p>

<p>A <strong>permaculture marketplace</strong> where people can share/trade/buy/sell seeds, plants and everything else they might need like equipment, books, courses. Others can use it to sell products from their permaculture gardens to make an income for themselves. Everything happens directly between fellow gardeners.</p>

<p>A <strong>permaculture garden log and planner</strong> where everyone can log their past garden activities, learn from each other and plan their next season or project. If this info is combined with all other gardeners, then it becomes citizen science and we can improve everyone’s gardening results. Imagine you could be notified when all the more advanced gardeners start their tomato seedlings in your area, so you could do that too.</p>

<h2 id="make-the-planet-a-better-place-for-real">Make the planet a better place (for real)</h2>

<p>There are many people who want to grow plants for many reasons but don’t know how. There are also many people already growing a few plants in their garden and learned it the hard way. I believe we need a platform where they can come together and share their experiences and learn from one another to help improve the life of eveveryone. If we would all start growing a bit of our own food, we could help the planet and ourselves in so many impactful ways.</p>

<p>There is a lot to write about the implications of having such a platform, which I will do in future posts.</p>

<p>In the meantime, you can check out the plant database <a href="https://permapeople.org/database">here</a> and if you are interested, either <a href="https://permapeople.org/users/sign_up">sign up</a>, write me an email to hello at permapeople org or sign up for the newsletter where I am posting regular updates.</p>

<p>Thanks for reading 🌱✌️,</p>

<p>ben</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://permapeople.org/blog/2020/10/05/why-i-am-building-permapeople-org.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24696688</guid>
            <pubDate>Tue, 06 Oct 2020 11:42:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Chat bot powered by GPT-3]]>
            </title>
            <description>
<![CDATA[
Score 70 | Comments 79 (<a href="https://news.ycombinator.com/item?id=24695710">thread link</a>) | @piotrgrudzien
<br/>
October 6, 2020 | https://blog.quickchat.ai/post/knowledge-base-chat-bot/ | <a href="https://web.archive.org/web/*/https://blog.quickchat.ai/post/knowledge-base-chat-bot/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><figure><img src="https://blog.quickchat.ai/images/blog-post-1-bg.png" alt="Knowledge-base chat bot for SaaS product sales"></figure><section><div><p><em>Brief summary of our GPT-3 chat bot for SaaS product sales.</em></p><p>The most natural way for us to communicate is, well, <em>natural language</em>. Chat bots are nothing new but unless they meet a high-enough quality bar, they tend to be a step backwards rather than forward. We believe huge language models such as <a href="https://openai.com/blog/openai-api/">OpenAI’s GPT-3</a> will form a foundation for a truly conversational human-computer interface. It is, however, a foundation rather than a solution in and of itself.</p><p>In this new paradigm, the big challenge becomes to ensure the chat bot strictly sticks to the topic it was designed for and provides accurate information - without depriving it of its creativity.</p><p>I will discuss this briefly in the context of what we refer to as <strong>knowledge-base chat bots</strong>. They are built to answer general questions and hold a conversation about a product, service or a topic delineated by a predetermined unstructured knowledge base.</p><p><img src="https://blog.quickchat.ai/images/zeroth_faster.gif" alt="Start a conversation - image" title="Start a conversation"></p><p>Our chat bot implementation approved by the OpenAI team (try it out live at <a href="https://itemsy.com/">itemsy.com</a>) is an expert on Itemsy - a software product for managing the content you read online. It relies on GPT-3 for its conversational capabilities.</p><p>Thanks to our <a href="https://quickchat.ai/">Quickchat</a> engine (on top of GPT-3), it makes full and accurate use of the Itemsy knowledge base it was provided with, focuses on the topic at hand and cannot be maneuvered away from it:</p><p><img src="https://blog.quickchat.ai/images/first_faster.gif" alt="Avoid off-topic conversations - image" title="Avoid off-topic conversations"></p><p>Ultimately, it’s all about <em>conversation</em>. It requires context, needs to be unscripted, adaptive and creative. You’re still talking to a machine but this time language feels more like natural language. 🙃</p><p><img src="https://blog.quickchat.ai/images/second_faster.gif" alt="Creative conversation guided by the user - image" title="Creative conversation guided by the user"></p><p>We’re ready to work with you and launch conversational chat bots for a wide range of use cases. Reach out to us at <a href="https://quickchat.ai/">quickchat.ai</a>!</p><blockquote>— Dominik Posmyk (@dominikposmyk) <a href="https://twitter.com/dominikposmyk/status/1309497928810213376?ref_src=twsrc%5Etfw">September 25, 2020</a></blockquote></div></section></article><div><h2>Follow the Quickchat blog for product updates, user stories and technical posts about artificial intelligence.</h2><p>
<span>Please correct your email address</span></p></div></div>]]>
            </description>
            <link>https://blog.quickchat.ai/post/knowledge-base-chat-bot/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24695710</guid>
            <pubDate>Tue, 06 Oct 2020 08:22:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fooling Around with Foveated Rendering]]>
            </title>
            <description>
<![CDATA[
Score 172 | Comments 85 (<a href="https://news.ycombinator.com/item?id=24695275">thread link</a>) | @underanalyzer
<br/>
October 5, 2020 | https://www.peterstefek.me/focused-render.html | <a href="https://web.archive.org/web/*/https://www.peterstefek.me/focused-render.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
 <div>
  
  <p><label>Posted on <strong>28 September 2020</strong></label></p>
<p>Shadertoy is a wonderful tool which lets users create and share a type of program called a fragment shader online. The true magic of shadertoy is its community of very talented graphics programmers who build incredible works of art despite having access to only a sliver of the traditional graphics pipeline.  </p>
<p>Some of these shaders are very computationally intensive and even in a small window, they crawl along well below their intended 60 frames per second on my old laptop. Inspired by a technique in the VR community called Foveated Rendering, I decided to try to optimize these shaders by only rendering a fully detailed image within a small focal region. As you move away from the focal point the image quality decreases.   </p>
<p>This rendering scheme is motivated by biology. It turns out your eye notices more detail in the center of your vision than in the periphery. Some VR graphics programmers realized they could take advantage of this phenomenon to increase the effective resolution of images by increasing image quality towards the center of your vision. An in depth discussion of foveated rendering can be found in the “previous work section” of this <a href="https://ai.facebook.com/blog/deepfovea-using-deep-learning-for-foveated-reconstruction-in-ar-vr">paper</a>.  </p>
<p>I did not have the time, equipment or the background necessary to implement a full foveated rendering system but it was fun to fool around with the concept.  </p>
<p>Before diving into the technical details let’s look at a simple shadertoy fragment shader.   </p>
<p><code>
void mainImage(out vec4 fragColor, in vec2 fragCoord)<br>
{
</code></p><p><code>
    // Normalized pixel coordinates (from 0 to 1)<br>
    vec2 uv = fragCoord/iResolution.xy;
<div><pre><span></span><span>//</span> <span>Output</span> <span>the</span> <span>pixel</span> <span>coordinates</span> <span>as</span> <span>a</span> <span>color</span> <span>to</span> <span>screen</span>
<span>//</span> <span>fragColor</span> <span>is</span> <span>a</span> <span>4</span> <span>vector</span> <span>of</span> <span>the</span> <span>form</span>
<span>//</span> <span>(</span><span>red</span><span>,</span> <span>green</span><span>,</span> <span>blue</span><span>,</span> <span>transparency</span><span>)</span>
<span>fragColor</span> <span>=</span> <span>vec4</span><span>(</span><span>uv</span><span>,</span> <span>0</span><span>.</span><span>0</span><span>,</span> <span>1</span><span>.</span><span>0</span><span>);</span>
</pre></div>


</code></p><p><code>
}<br>
</code></p>
<p>This program runs once for each pixel on the screen. Each time it runs, we receive the input variable <code>fragCoord</code>. <code>fragCoord</code> is a 2d vector which contains the x and y coordinates of the pixel being drawn. We normalize those coordinates by dividing by <code>iResolution</code>, another 2d vector, which contains the width and height of the image. Finally we output a color to the screen, whose red and green channels are proportional to the x and y position of the pixel being drawn. The output of this shader looks like this:<br>
</p><p>
  <img src="https://www.peterstefek.me/images/focused-render/simple-shader-out.png" width="50%"> 
</p>
<p>Side note, why do these shader programs require their own language? Shaders are special because they run on the graphics card instead of the cpu. They are highly parallel. A helpful mental model might be imagining that each pixel is colored simultaneously. Therefore a lot of things that we take for granted in normal program languages such as liberally accessing memory and branching become much more difficult.  </p>
<p>In shadertoy shaders the bottleneck is always in the pixel rendering step. So to speed them up we want to only render a subset of the all the pixels on the screen. It seems like selectively rendering pixels should be as simple as adding a branch to the per pixel shader code that looks like:  </p>
<p><code>
void mainImage(out vec4 fragColor, in vec2 fragCoord) <br>
{<br>
</code></p><p><code>
    if (fragCoord is in the subset of pixels to render) {
      <p>
      ... do computationally intensive work 
      </p> 
    } else {
      <p>
      // return a black pixel<br>
      return vec4(0, 0, 0, 1); 
      </p> 
    } 
</code></p><p><code> 
}
</code></p>
<p>Unfortunately we cannot just use an if statement inside of the shader to save us from rendering all the pixels. Unlike normal programming languages, fragment shaders always execute both parts of each branch due to gpu limitations. So while our above code will still have to spend the sample amount of time evaluating compuationally intensive work.  </p>
<p>Luckily, it turns out that graphics drivers can selectively mark which pixels not to shade by writing their location to a special buffer called the stencil buffer. We can use this stencil buffer to only shade the subset of pixels we are interested in.</p>
<p>Once I could efficiently render a subset of the pixels, I needed to come up with a pre-generated sampling pattern. Most foveated rendering techniques seem to use a grid, but I decided to try a non uniform approach. Searching for some kind of optimal sampling pattern seemed like an interesting problem and if I was going to devote more time to this I'd explore options like <a href="https://blog.demofox.org/2018/01/30/what-the-heck-is-blue-noise/">blue noise</a>. However in the interest of time, I just decided fill in a small circle in the center and then use samples drawn from one low variance and one high variance gaussians centered at the middle of the screen to place the rest of the pixels. The final sampling pattern ended up looking like this:
</p><p>
  <img src="https://www.peterstefek.me/images/focused-render/final-sample-pattern.png" width="50%"> 
</p>
<p>Next, I needed a way to fill in all the missing pixels in the final image. The approach I took was pretty simple. I started by mapping each pixel in the final screen to its nearest neighbor. Since my sampling pattern was predetermined, I could create this map beforehand and pass it into the shader as a texture. Here's what this mapping looks like:<br>
</p><p>
  <img src="https://www.peterstefek.me/images/focused-render/nearest-mapping.png" width="50%"> 
</p>
<p>And here’s a gif of the mapping applied to a <a href="https://www.shadertoy.com/view/3lsSzf">shadertoy</a> created by the extremely talented <a href="https://www.iquilezles.org/">Inigo Quilez</a>:<br>
</p><p>
  <img src="https://www.peterstefek.me/images/focused-render/1-neighbor.gif"> 
</p>
<p>The above screen is 420x236 pixels and only 1/10th of those pixels are actually rendered. The focal point is directly in the center of the screen. Here's what the full resolution version looks like:</p>
<p>
  <img src="https://www.peterstefek.me/images/focused-render/original.gif"> 
</p>

<p>And here's what it looks like with only our sampling pixels:
</p><p>
  <img src="https://www.peterstefek.me/images/focused-render/sample-pixels.gif"> 
</p>
<p>One little improvement I tried was to make 4 different maps. The kth map mapped each pixel in the final image to its kth nearest sampled neighbor. I weighted each of neighbors by the inverse of their distance to the pixel in question. I actually even tried using some gradient descent based optimization to fine tune the weights but ended up seeing little improvement. It also seemed that increasing the number of maps beyond 4 did not improve things much either. Here's what the example from above looks like with weighted interpolation between the four closest neighbors of each pixel (we are still rendering only 1/10th of the total pixels):
</p><p>
  <img src="https://www.peterstefek.me/images/focused-render/4-neighbors.gif"> 
</p>
<p>Finally, here's the shader with 1/5th of the total pixels rendered (as opposed to 1/10th shown above):
</p><p>
  <img src="https://www.peterstefek.me/images/focused-render/1of5pixels.gif"> 
</p>
<p>Okay that's all cool but does this technique actually increase performance? I did not do a rigerous benchmark, but <a href="https://www.shadertoy.com/view/3l23Rh">this shader</a> goes from around 20-25 fps on my plugged in laptop to 60 fps when reduced to 1/5th of the total pixels. <a href="https://www.shadertoy.com/view/Ms2SD1">Another shader</a> went from around 15 fps to 60 fps.  </p>
<p>One last side note is that this method can be used with any 3d scene and is not exclusive to shader toys. I just chose to use them because they are always bottlenecked by the pixel rendering step and they are really pretty!</p>
<p>Further questions:</p>
<ul>
<li>How do we achive better temporal stability? (the <a href="https://ai.facebook.com/blog/deepfovea-using-deep-learning-for-foveated-reconstruction-in-ar-vr">paper</a> I mentioned earlier talks about this)</li>
<li>Can we dynamically change the sampling pattern to give us better results? For example what if we sampled along edges or areas where large amounts of motion is occuring? Of course to do this we would need to compute our nearest neighbor mappings on the fly (there are actually <a href="https://www.shadertoy.com/view/XtlGDS">some</a> <a href="https://www.shadertoy.com/view/ldl3W8">shadertoys</a> which already demonstrate capability).</li>
<li>How could this scheme improve if we had access to the internals of the 3d scene? For example, could we adjust our sampling pattern based on depth information?  </li>
<li>How does this actually look in VR?  </li>
</ul>
<p>Have questions / comments / corrections?<br>
Get in touch: <a href="mailto:pstefek.dev@gmail.com">pstefek.dev@gmail.com</a>   </p>
<p>Discussion on <a href="https://news.ycombinator.com/item?id=24695275">Hacker News</a></p>
 </div>
</div></div>]]>
            </description>
            <link>https://www.peterstefek.me/focused-render.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24695275</guid>
            <pubDate>Tue, 06 Oct 2020 06:44:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Oswald Spengler – an intellectual life]]>
            </title>
            <description>
<![CDATA[
Score 51 | Comments 41 (<a href="https://news.ycombinator.com/item?id=24693655">thread link</a>) | @objections
<br/>
October 5, 2020 | https://engelsbergideas.com/portraits/oswald-spengler-an-intellectual-life/ | <a href="https://web.archive.org/web/*/https://engelsbergideas.com/portraits/oswald-spengler-an-intellectual-life/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://engelsbergideas.com/portraits/oswald-spengler-an-intellectual-life/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24693655</guid>
            <pubDate>Tue, 06 Oct 2020 00:30:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Probability and Statistics with Applications to Computing [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 70 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24693589">thread link</a>) | @ArtWomb
<br/>
October 5, 2020 | https://www.alextsun.com/files/Prob_Stat_for_CS_Book.pdf | <a href="https://web.archive.org/web/*/https://www.alextsun.com/files/Prob_Stat_for_CS_Book.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><i d]g(*hª®jcš»•ßÕ]¿¿}[xï^îr)Šf3@="ïJ§“ccc–/_^RRbs—¬mÈ" ;ÄçÏeáÚ?§‹€Ñ="" p8]x±<Å<­}ßô‡Ù…‹!kim2Š‹‹m1cÆ¡–›Ï·yyyb¡'��aÀ‡kd¡8ûû£‡="" öØ½+êæ�dôfÔà:qàeuÊju;~×¨)?l7¥="" Â="" Ö®[bc£vciqòÊ!á2ÜÑÃrø="" Ì|ñÝê`‰-»�8&7ž¢Ãý="" ý­¼„_öÇŒ)ŠÇ3™.d¢çl¥&nœxûöí'ož˜o)­Ê�“?yÉŠvw-jþb7r�Å»s="" †�çh<b¦iì²Ó„a-åpËmÉ¬y-g="" "æ³gÏ6nÜh¡�\]°xÎýúz�]gó•†="" mÊ`4Ýî‡qp;iì1™ìôŸÿ|åääÑ«w¯#f,y²äâÅ‹.mqÕ´ˆ�£`‹ýÃŽð¢ß7aïËÙ)ÑsÔŒhŽ,ÚxÕÖò(j®a¬jËk²yœuëÖÙbÎ¡c-7Ÿoóóó÷ìÙ3yòä&mšøøx“Éd"Ñ�nw‹qéŒáÃ¼²–nÛ~ð@ÌÙÓÊ‹çÕ¹Õ9Ô'�+öîŽ=""><b n¸1 ±Ü®3Ô%Õe!�j¡«ŒÁ±�Æcv‰ynglbpa�k¯„«cò,´å�£(ŠÜÊ"Í^¯iî2¢^?å‘×ue‰�m„ÉÝ^ÏsÏ?¿}Çvø–.˜_`6zÞÑ#Ð¶Áo°îŽ;îp©d^¯ô«eÅ\Ë¶ãÛÍŸ|ý±uñ&×™Ëb9%…n)Øäzµ(¶¼'§ oýÚâíw¬žk="" üau¸‰;ïpv”“�@&ë.‘t‰º="" …°ñÁï¬x±â\å¤eíŒ="" nü�?þxe’Ý%buÔ¥Ž°j+r…¤b_›ÀÜuØ.wê‰ˆsæÐimzua@jÑÈœ¡Žê.c!˜Ü�ÛÛ‡ƒú=""><s ‘hª÷*^íÕªjži[j¯Ÿ!±¼šgyä1<`ÀÕ="" Ü8(²gp!z$_õôŒûkÁ”uq�àât‡Ñh6:p<‰ã×îŒ�ÀÞ$bxÀ%µ¨˜‘}h="" !="" l‘"„‡b!qÂhˆ@b"�p¼ze‚‘Œ…ic"�(µ="™41" ¡¤!½ŠlÀÈÌ«fip7ñ¼êþ¿ûÉ‡½sìžž� káu�¤Ñ¼j9Ô3î‰–ïüÿ¥="" wü¤ðú+nŸfíÕcÎ.÷œ÷áÒ•–s‚hh¯r‚Îui’x5–4©¼Ê«�&{¯="" bÚØ™eö«�–®ò®6<uºqµýv="" ï‰oÈcoœuoí·ès="" ‰çu&û�o�ôê˜wš]tc4g˜wii´’gz•'ñê±�mï="" ‹Ÿ:fbªð*="" ;k¯ò¬½Êˆ?Þ@š¾vçùó*d^sŽi‘fêàu¸™Î«êÔÕ«ƒsxv®x5�<òÈc¸ÈÒ"Ï‹üÈ”ª\áåpý0æy0ãe~¤|&®]ƒœ.ªÓû¤�è›a%†hð‰="" šd!¨_<”fƒû™="" Áe™a`l%¤:iÂqæh’Æh\rñ‰Œb¬Ž&„Ç“ÆhhliÁ«Î™3âkû¾5<½j}º©ë�»äknù}qåûi="" ¯ÎµžuÏ|ß·_á="" iƒ©¡¼'��^å="" æu†q¤©Þ«bÝgï›Ö8ñÅdkägÎê€�^½urå%�'[-8t8!="" f€,¯¾ÿiåq�Çoí²i¯ªüéhräÕp¯*œdzuÍc%÷tú�ßõk^­"�h0jêubš*«à¾kŸ¬°ôî�Å”„ÄóªŠ$s¯’„h7dé¿�’x^{dîu±ºaj^="" ½Šo2É#�<òÁ8ƒÉÛ_pj="" n="" ‹¥,jªå ="Cëå" Å="" ‰¨×dq#ò¹z‡p="Õ«¼D‚ú3#¡Êk!’HWa²çÒÐ„&nbsp;Œú{6!" ¬yÌ.mˆ2¦éa�?ªñ*«ñ¼j}¶¥íwºgÙ­¿ºp¾¬€ò*=""><i ‹b#ÅÄ(cŒ##eƒ*mü“rŠ‰‹txƒƒà@1¸Ü•béîÉåÓàúà¸‹i§rŒ¤àpmÆ]Š™Úx="" ‡î-&�©="" b„19[khy”3ƒ§Ç\‹6„"'?Œ“tà´1%•–üejq9›k�r¬ƒ#="" Åx="" Ž¯´98×*="" ¥x="×Âfb&quot;#Eß¥" ój¸ßÂ@€Ý20gÌ5ŠÀÂ‹‰´Çk&†[¶â§9p="" m8le="v]Ð­€$=ˆö+¤" =""><i Ên<y¾"+xÒo%bw�o v!æÇ="" <aëÂÓj‡�´…' `xz(hž,="" bÔa{ñ¬g‡¡‰£:="" ov‰Ìcoº´×of‡!(›Ýxz€µµÏjkkýýý±.ìg£iÓff£áçŸop¨Úpz¸p¡Éh"Ÿ�`ÃÁÑ± °àþƒû¯x�²á="" ®Ïc�jkŸ<~¼lî¤Ô0u=""><i ¼,<-;l]?h�="xÙ‰'¥`Ý�¦ý›úƒvÓ7±Tž?;ºMb7wE62" g”Ôj<b—.kwgº+Úú©ÜcxÚxçø0eç="" c@1ê˜4•éoÊð3vòÕ·ñsÅ´”÷‘="" rd&ˆzh�pf9�eÀ5Ê“š&ì)¢€k@yp[qh¤="" Ü…‹ìÍÇf4°ikahh#&¶*Ä_À$cpå!Õ®hØÂ}ˆÖ="" z¾Üsï spd;¨Âl=""><i Â'@Èâ°jið$*ˆ_³zápýÛa‚ïÀ“j0]Á“ ="" cuwa„¢ ²="" år4ujß§ªÄsj÷mð¤(Øu<5j€½Áô4À�eüýfò$="¬-ñ÷7" žÏ®ÍÜájõ»•.Æ2ÜÌxãuì|y£¦ê¹öãxzó<û¡Û4È;5Ê÷žfwÊ€gjÀ,câd#‡5<‡e\·þ&.Öü™¦z3="" y3e¯ñ§É&&lájojÛ;±mý¹Ã†hƒà|²=""><i âïa5Á“¢="" ÏÙÙû¡i:aaa¹¹¹ÿf<uŒ¢Ü`ºˆ§”fya•xj¦="" ‚Ð(xwwwéÒ¥åË—c3»ûûøá#­‚]À“¨`×ñdÈxr%âšÅil0åo—ð”Òáiu�p…$<¿eü2x=""><s k™-sòšæs\ÿh%=""><i ƒƒ…="" ¨="" ˆfÄƒëšáÿnë1š$•á,—ÁÝŒ‡À'ŸntÜËà="" Ã´3<âùˆ²×��¶Âˆº×#€e0’’�cp0•ñ="" ˜¬»Í`="Æ`+ŒÀv3F�«Á0E|÷2¸Í`ÌðîÔùHQò98€…~Øv`¦íÂÀn³­ìÛ¼k4Uük¤wá³Œ…�·Àð®¹"><i><s Œ¦Ü7ËÈs�\ –xŠµ(`="" Þ�ÿèzðú~ìÿtz~tÙËc�¢ ºœj%�ù¾Å…Œ‹*�Èrò”@ˆ|)pùÀÜÍÖ4íÈ‘#.œ<y2¿ÌÈÈ0="" Ãw¿Ïý­a¢="" Ø="" ª="" 0="" [�o@vr‘ÕjÁ£�–«’Ûüž´ñ³="" Ç�(¸�="" cÆåe{µÀdfbÿr="" sˆ¥áÅ="" ‚="" —="" .0ÄrŠ°}²;–¬¶…a$`Ø°j="" ÜÑy{™ª[z·="" -yqÓpˆ×Ë†rcl*ovŽ£´;v®hb¨r¹ÍÏÉÉy»víÔ©sgÍšµcÇÓ4ub Ê÷Âb]2‰j`¢¡ro,xpå•w~öÙg¹¹¹g•÷ò§:dü#Ú¦m›¶mÛnÚ´é<{ûÕ<Øóøÿyyyü÷ª=""><b><b �bÉöv�j§ÅºdÀ�8ÇgÅ.k\†¨‡Œ="" =""><i ¬ŽqÔ¥w´é:‡õ�ƒóò_fç:§uÒ¶šª7½¾âfrø¹×eøŠ«è5ñ!_¢‘q<dñáeÅ=""><s „û·tb!aÈçù*`lze;‹×5Ñrƒð¬ºÐÌzÒà¸gxl¼Àdiyû-y­;o="" Î†iÂ+j–¶âo\^åÊuÂ“o*1`hžsÛ€="" –©eÊvie;¿¤÷”á£©Öh™c|ÉÙ¨b£p…ed�-í¨r9¹Ü=""><i ’îãqšƒì}="" ¯5À7-}£ðgzfèõ4n¼¦kx˜™~œcri³¯È�g@Å´)î1‰þ_¼alsb÷ˆk=""><b ­Êë%jt�="" Õç¬,p1Áï¾ûn]l="" hj‚‚‚ ÛyÛ¶m _®ì½ñÂ¸="" ="" ¯�öwh�Æë œà÷gÂnj2}²?á§](„pÆa`†cªòð›ñþ@Žd="" t–ø,utyÊ="" Èúìizzj)ð“’§iy™yb–Øluy–Š="" Ÿ=""><b><i o*d´,wÎg·®À+œ¶*‚‹f\y„="" «'yèÏÿ¥¨¿©œÿ›´Îÿroë›®·5¾wëeqÏýy”#Ì—ùÂ‹nçÅ¦pöãyú�Û,ÒÜ­Ýün³yÖÞ²ŽÜ="" 7Îsä="" £íbî&2x«Î‰zqöÚ¢qŒ+¡:ì…]„!Ô“Ü{ÈŽ8^Ç=""><s><b Á7˜ó¸ãÑÇÆa$211y¼hqbb†épØ1*œˆ“g0^3gÎ:tÄ¾ýû¢¢¢Ê�^�³©i“¦äêccggg˜Ýù’üÄÄ„·xq="" „Å‰*)’š·}ûŽvß?zÔè;w$’|x–hpÐk(ÿ="" 9ù0Œ×ömÛë7h�y="" Ï#À"r©”ãâz·jmhˆ="" ÆhÙ²å¹sç�¥¬âÍ|¦ò‡Ì,y�ìŽ‡g³æÍ!u•ªu—ýµìÝ»w"4éø@À-û[-ÿ÷?rim¿þýðÁ="" ºtÐ1bƒ_§ÆüéuÀ"—”•“~Û?jÍå€Á›Üú®Ã×ßŽûÛóˆkðëèô\‰¬@®¬°ývÀÜÔcxÏ`j="" »Â@´5f¨b€ža="Õ€þ&nbsp;¾" §h3˜ç›€Š½lhÓ="" Ào`â€s!½cqó˜xÍ`Û˜="ï�²ÌP'ˆ" ¡Õngìkvp±Ÿ‘÷Ÿ_Ôò‹Ï Ì²ÅÖ3Ž=""><s><u><i sÝs[Ž="" ´‚="" mpn¬i©ø8¦¸_ªs÷w4´:®ƒvaæ="" Ò.v›bó:!®†?jƒzØÅyrìÄáè§ãkãžuËõfË¸ yzïânË="" «="" néìÊÁ�¢‹¿¿Ù="" q="" gwhÚì£åz•à‹„²“¹­Ýã^yˆ="" t­Ž»xhu="" Š5¦c·›=""><u><i hæèÙß&Šê="" ¦m¤’)’�#cm›5k˜ìÑkldº°)u+¡bt•�="" ~yt¨Ö="Ð‰zUiè%�´ºT‰‚ž…" ƒnôht„)w«ÌhÅÐ»wc·Ñ%Äå�À="" Õ@="" èÞbèþÝÛjèüq4tx‰�ˆï:%.¨¬{Ëb)Ælyj‘ã wÑ:¥]uº{i9#nèÝ«bÏ.è’Íiwa'êu¥¡—4Òèr¥Þœx vï$†^onü»·‹6'g®€õdjrwdŽl€$ˆ°cÄhË¤µá*üŒ§d‘j“c¶jÈx¥�ðÒ“|€”1‚$Ì*f4="" |xá'ô#rbŽ¶p#å¡‹deÝ+†_="" tp”…nÅ%Œhµ*kkˆ2w½Øˆ:ˆÐÐåç"#­„n`­äuqs–âu@÷2â„^Îˆzžöty§ø=""><a ä‹Ÿ­9�1ï.“}(—x’dŽ|wÎ-ŒÊÃ“4ÿd¦¼[b="" †©ùo0…œly®h§.ã.Ïú‹�!Ö©€w\ÀïÝvòzvÕc¸‡,jçþ»?Üô%]£uØÞò'v~tØµ˜m¬úÍf¼Å="" Ú¡¨y8jŽ§¸.=""><u ý…�îØ¿?v9å$;bii"iÚßß�ìd¹Âe$&&Š¤*¡×(•j;;;ìbÊèÑlÚ´i$iy?t×®]ØyòÆÙÙÙÑÑq$u="" ý¥­­md¦ad$v="" åmxx8$ÞÜÜ,†ªñññðæ'nœÀÎ’7ÑÑÑl6ºªúknn.Œ#gŽ`—pÞ°©Ü"u� }èää„�"ìqu�ˆ1øøø˜™™uuua—pÞtvvšššŠÑujiia_�êû|�]þ—¶²²¢®1šžž¨!!!œ‹"ØzjjŠ··÷Úµk¿úê+øaß¾}ü·eóóóƒôÁp„u•­¥\wwÇ9="" ï‹="" ¾x×]w-[¶ŒÿÕcccÅë�úë;pÞÑ#!!á™gž¹kðkpž‘äää@úvu="" Än|w¬y³†iŠâ3lfåþýû…u•Ð_ Óe¢££ƒ[!t*•cyôÑg_ýõ×^{í§?ý©æ—<×£`÷ÀáŠj:44„Øi:{öìªu«4b¢ø="" �="" À- ª„þ2<<Ì6âvüà›nîÜ¹pþ|ðÁÑ‹hÁw0„Á^‚�="Ê-$¶•H!”ªÐûcS5¹¥&nbsp;!**jÁ‚£›ˆX">ÈO’ÑrÚ(�ÌüIYæætòÆtÚ²:»·�0È�þêÃ-•£|Ò+e©›¼9V9-‚Îsm5—'«ï­SïoV¿?Ç8×^6ÐíÛ+56é/Óï¬06‡™ç•õhkÆ’‚u¾³æÆRÕÝµÊçˆ«ƒ”¤TÂã‚ª1&gt;ô Us‰êfÂ\gþÆTòÅñ¤¹®4
ßQƒ^æH©9brvg]âL‡ÿL‡Ï¨Ä‡[žÔXœ„‚jm~,=;–UÞÕ`­âXv7˜Ó²}ËƒññÈýa¬¯6©
ïC\^š¯�3kœM}L½OŸ
&gt;1rb&amp;øÄlà‰Ù`#¥¨õ·`ÕW»&nbsp;¬ªëºµ¼B�Qc¥]¬
4YÏª»k€!«jÐ¼ê½»w^Ò¯ÚÞÕ!æ˜¶Ý¯úE’é'‰&amp;ýá¿Ìª0vŠö.À¼ÀªÚ¼*5CÏÆ0bkršÊ±½ÍQ#’hvQF+1½¹4«¿%uY“ry.mu8Kýº‹vÕ”.U&nbsp;yÕks´9%eœOÑšuŸkßÎ¨®©!¨p/
6ƒˆèoŸŽþï¯¡ÚßžN|ÿÁøÿþrþ~^ý¿[ùéã™G3òGsò‡³²{ÓÐíÖ¨ðÆ¨àƒUùŸÁ{þg�:ž^•~rSòùÉg„�¯4_‡ŽLüê�ÑjpðlA«¥11AU_Ö×ýº»˜…àÀŠÉ…Û¬:3¥Œ•Òpì’Ô&amp;pZK «æÆCVÁ¼*`UrZ(!)Œ€ƒ¬ºí×ã“…\õ#©U´k5°ªïóQÈÁ.f€U¯DÃ‘7boDÞŽ2˜/Oz³yU"²~±øõkõu€µ±“î=¿žUõëßcí©þrW^õöíÛ333ûö«ba¿êS¤_õÃD^�‰–Uu£ì_h¸x�UƒVEòª„UÓâ¹Po9	¼Ê¸!Ads,§$�_‘ÞR–¥¦\zïšó¿_|_cdU˜W¥]š¬†¬*&nbsp;"¥¿ŒE­Þö4hõöò`ó½…¶?ûÏo¦ÿþ×¹¿&gt;ÿþñøß¿Yzûß?,ÿhüÑìŽÞ"&amp;7G7Ç]jÿáÓ�o&gt;ìùâAû“ËâOo½v_ðp“»®fM	h3âjð¯?¼ô–¼6V¡á•÷6”õ6à»YEpœ£@L*ÜfÕQ”U“Ù%)Me‰¨ÞÒsâ«‹]4«’R�Þ†¢z‹Þá½Í‰òÒÞ
&amp;¿p7õ6ÜÍ&lt;ÐÙ,ßÃä¢·×co½�4˜¨.|³¬º_Ã…®ãú«.tõV×q]·ÞeU+++ÀªgÎœÑ³ª~ýAÖ/²ê¥ýYu¼,y=äÔ…ðS«á°Ar&gt;ôT´½��:Gì9®‚xøyC\&nbsp;SJ°Kn´sY’Sv„gv„oI¼g
ÎÏ’1Ìkò&lt;Ë“"H©a¤Ô¨¢G‹=³ ¦&amp;/ŽU×PŒm(Nj&amp;$öó‚ç{üz4Â()5CLÎi£æòÒÎ«cWG±çÕI=õ¨VÃ)CM„¡&amp;â0�¸Ð�_Ÿ(i¦N&nbsp;h_Ô®/•Ü8�ßœ ž•B€�Õ®“oœ/¿¹RöþùòõÒ¶å�Œ&gt;#¦ÏÉ©—¦K®/å_š)Xì.m¡Œ¶’Fx•šf¢š‡Žõ7.“dŸWÇ-k¢g:ãäÕ…rZøÙ$”,!)KP™ÞQ3©ð—¹õr½ê‹pu…ÐC&nbsp;6–÷P3ÁÓQ2-�ñßf”,||Pq\À&nbsp;ªÓ—�‚êód�«y˜³i�“‰�½1ËëÔDàñ©Àãã`û4TŠ[eo˜U÷×¸×­å‚üR· ÈèpUWWWÛØØèYu7«&gt;ûòÙ£‡ˆ·dÕ™ÙÙ{wî,-.¾”UÛw|€¡&gt;ÀXãž£YÕúåyÕhmMZ@YR`c©çìWuèá@V¥VÍÇÔÀØ)vH:*�h£'u5&amp;¶×%k„¸óC¸ÍiAeL´å*i«Ö–žë+»µZñp«êêYÊYeÕûž{°Tk»©¼�=ÐšßkýæÃþ&gt;SÿôlôéZÇ£ùWwÿã›ÉŸžMüøùøÇºLA´ûSm0vÝ<ziûöi×³gÊ ÉŸ="lûâ¾øãÛü‡[ÜKõó2ÆŒ„">ÑJ»¨¦Ü]¯º·AÜœ$Œ‹Ë{«²µ¬š/©*kKEúU£&amp;ä	ÇÆ§5•¡¬ÏÈM�×ø#ýª²7Èª¸ç¬úBYÊªÁÎ/eÕgÓ�¨3¨PÎ«gfJÁ	•½QVÝ5X
­ØÛ¬º·yjï¤¿ýKiÏ©öžßÎÎNÏªúõ»^»YõË/&gt;GûUûúÀÙ\X\¼}óæÙ³g_ZÜßÌü4š½ý$ÁäAœQs€ñî¼ª®Þ†¹iõV›W-Çò*ÝÕ­°_UÉ¬
¨-†UM&lt;ÄÕ1ÃâPµ JÆHêlHê¨OãVGq›3)F24‚üœMâŸUuù½uâÃKU[“”iiˆ|Ð6UTo«¢z»}78Ð|gNôíÓþ&gt;×üôÕØ£%ù‹Šïk~þjòçg“ýpôérçƒ©6ÄpÑÛQáÍ1á‡›òo&gt;|®·Ÿß}|‹½i]SÂ§i}ZR½1
'¡ÅÓhù6«6îÌòc@½�éÀ­¨c/G!cw’9øTÎ6«ÆÓs»½4"'µÐAPå	Y÷"«b^dUDo÷²j®»ÉfÔ™›Ñ—¢Î\‰<s-üÌ(µpþ°ê?[o¶·yõõf¨é:Ð[”umll�«‚ëyu¿þë_fu¹¬m¤4y9èär(Üká§§‚odØžö´>ãog&nbsp;‹«Úô
Ð�‡¤@'B²·Ü23Â5-Ä»0ÎMŠ°ªˆjAÉô(‰‡þ·É"ª�‚iS�S�…aäÆ€À˜™ßP¯¨
žVºO·{‹ýEUÉ­ÄAeV;+eº#ri0t±?²—�ÙýRŠºY°øPU_6À)�VäœÈèk ©!]V.õlNglÍd®Ž¡#Ãø”™6âÆDîÖlÖ¥³YGògdÄ1u\˜”2!"^ÉÜ˜J¾0’:-/`W6•îgÃKBð¯íí¨)éçfÎtD.öM)Cd´LQUŽñfç•gð‰¸öºàQ)P]')Í§6/©6^–¢Þìä´HzN&nbsp;œaÚUoÖYgFÎð.Šó/ÀøæÇxï€êvF§Ó¦ºSUh@5ÄÉ±g7bxœö?:âlÈï¨Æç¨Æß@ñæXU÷òp¯{ÀÞq�{àW»µh›UuYÍ×œ<yrÏª;yÕgh^uzxx,v½{çÎâkyµ£«cÄ¿“dÿ�™÷÷0Þè^œqg°‘—Ã¶·ÚtÞÙasy€#x¯g½>Ð¦rtrQ\`ib`ÞsúÛu³�¨™ðTÖäa9ñrô„&lt;`E°:¼&gt;¶1¹&gt;sa{q,im<eº=«�qÔ n?×�ÿ\éÝ5ÂåÙÊ³jò(�2-�ýs="" ªy€–j¬ó;Íªë½œ�¾¦«#Í_Üw|ýaÇ×�;ïÍiÞ|¸®øöcÕw÷~÷tõé•ö›ÃÂ›ˆûÙ�1Ú¸zwiðÅcég÷do®ð="" �²7Ôõûë–”µg%Œ³r:ÕÆ[«—h·v="" ·="" –®oàÇdeªºr;uïÌa–tŒiq‹1ç‡"f%1b2’w-ÝÉ«æ$È¾="" €tìÛ®äÔ]v-|}vu1]�8u1@[‹8½vjŸðÛ±ê~±“–uuÍº_Ý<¥kô±—uaì¤guýú½¯—äu!«^îc¼•o½”u‘ùªý\æ“h£ûqfwâŒ="">@æ«rüŒ|_nâ‘üât°Ø¯ÚBtäA`E­)5°*b�›ÐÆˆ˜ézxa4d}"Ñ[Ì…Ñøµñ¤‹c)£’œŽš¢.VIO=~©ûBé½õŠÍÉÊ))y¼è-4@õµTÒÕÛ3ü/(¾ù°óëÇ]·&amp;Dï?¹ÚþíS¨·ß&lt;îùhSqC#„ÀˆÞ^Ó´^æ?\½ýôŽèÑ&amp;oc°qS]¡—µ ßÖ[&nbsp;íSbê
4œ¼}a¯æ•ƒxÍ«vÀ–U¨·Óí	ç£—‡Âù±­•ÉœX¼�WÍNè¬÷TC`»V’Ç/³êN^5öEVÍq7¾ˆèíÅÈÓëá§7BO
S~#VÕ�¶·Yuo½™nËKõV·ÞLÏªúõ‡]û°ê‚B"þEVU—àæý�ÏŸ{9ìÔhÀñPëî–§|lN\
´7v4Þ5#ÎÇëëXŽ³å-3Ãý½
c�etKÛ¢…hMHö(Ä@!¸*c˜ñˆ6¤Ô¨ª´Èê,€rÑôœØÚü8&gt;)dDì8,vÒˆÜ„äØæ²”æ²t!9¥¿9b®Ç÷l�ÿPkŒ”š'«ÎSÒó@ð©dÀj“1qòÙÎø®Bo}©ª¾|F™¾2Œ]ÁÎu¥
pƒMC\ Ðùðù„ÕQì²:qZž&gt;3Ä-ëk$ª›Kûâ—5Q‹}˜Qf7³Žv…u,E�µ°tº'U*k2†Z#f:=ÇeÞò,��Å«Hm!$³KÒxDLg½ûP«�ŠcßXFÏŽ§eƒ€<w¥‡sÂ©ÙŠšmv%¥yäÇÀ�ªº½o {�”þ†" „Ž½¶1 ºï÷92ès´×ûhŸç‘="">ßÓ
ÑfÕ—ŽkÜÏ=à5`­ £¬ªÕd=«ÂõK¬zg_VíVŠøï'ØÝŠ6¸›ÊoÆ*
Ñ
à—g»JßÛ:ÞñëFZ¨P{%Ô¯„O…±þø„€ºb÷þfë�ÛÎz{Ô„Oôœ81-|Tê£òC5âðIÔXf¾³¢‰½8?Û•ÚQ“pµ�^2)+¼:Wps¥hkºtFQ¡á’'„U;£`×ê¼¼v”#	ÖÕîÆ�AöG7xŸÞ|zWxs†·Õ×|sšÿÑ5Ñ�$ŸÝz[‚¥+C¼+C-—‡Z¶ú›7¸ïÏr?ºÅ}zƒsï4@[�1çeµsmHà$¥MŠ©c&lt;Ê|gÅµ¥’÷Ï\Í–t³J{ê·“ª
zž„œ7*‰Ÿï‹XìV"ùDÀªˆY7ìŸŠÇVJ÷àÙðl¤ÕÎ¤Ô¤_AÖíWÝÝ?¥Û¯êjìYu1ô$ˆš€l.‡ž\
99VòæYu¿©ô¿¾YU;¡¬ª[“¦gUýú½¯�U«ª¸Ì{7c&nbsp;ÞÞ‹5¼mÐàkèã`¢ÛËÌ½M~É|&nbsp;·¥‰þ\‚ÐÛþf[Ã¥2%––ÅÈÅÐs°È�·¯Z4Ø:,Ž‘D�µÅ.
`V†ã.Ž%Œ·eÀhÞÕÏ*nœz[¼1Q:!!·�'…U:¦ëÛz{I°½½2Æùè&amp;ÿ³ûPo¯�¶lö6ß™oýø¦ø‹‡PoŸ^]QC±Eõvèí ÷öÐÛ¦'×Ù·ÏÕÏK˜²ÚyY
Ð[hå!­žR'Z«–T„+ÅïŸË_Õä5ã»ëð¨·™ä4¨·SJÌBøb_poSLÑÛ’m½¥eÇ·×¹
òíZlø•î•)!H¿ªvèüs+`8¹fGoµ7ùH¿ªy�³Y¶»ñRÔÛó;z«¦¼yV}Eo”nðë4«î½Ã×:ooo¯gUýú£­�Uå«'Mû›&lt;6pülð‰A¿£AÇ�ÍOxZžô±&gt;åg{&amp;À­Þž‚
B5  1ž¶øÑ"%È&gt;ÌÙ»$ÁZYk¡b›³Šì
0ž¹Q@‚üË’ü;ë,ùÎ¥	aÉ¡ä´°ªôJF5Ã*Œèm²îo�)žVrxCqRc1ŽƒÇ‰¨˜‰ë¸Üu\æ!¥%·óE¤<iužˆ\¤`d�hbg$‘2*^É(pÐj†…‰s=!ó½!ãmñ�µ¥Ð´è'aÍo?Û±Ø²Ð:¥ˆë©(zÐsw4¥,0ÕÒ×”‚|Ÿ<ÙÊh¹mÈdfiu–˜”%$e*j1€£‡eŽ] ìâ¬Æ’´†âva*ŸÜÝhÕÃ¶�tÛu¥Çk)•”jlÅ'„s�žw×›uÕ™•&zdfødflŠî2sÒõ="" u6a^úÛøÚœv³:er="">Öíu¤ÇëH‡çáN÷CÝÞ§eÂVEG'€•
…J¥ú•¬ºŸ{Êª¿8êMª¾ÔéN+È(«M1°6_sâÄ‰ææf=«îfU¡pæìÙ»wï¾‚U/am¯Fž¹Œ4•_‰2�øŸñ°…³éuÂ§=ck®Fx&nbsp;Kù¿b¬³ÐUÅ¶èm²T0mI©‘”ŒHdlMt[M`_³§ÛXœÄ-Ã5RZÊÒ†ø±½‘+šèÙ®„Îºì6j¡‚V¤æå¯Od^YÈÞ˜Ì›VàØÄ^%œG�z&nbsp;‰ªçd´•^ÚrcA�»W{X7Y�¯×?¾Úpy´qµ«q½Ÿ}k�ýá�Æ'×?|¿ñú4{­‡³¦b¯õ6^èn\í®¿4Îzt…ñðíæyÚ¢¢v[¯÷EÔ	!e¬•¬i&amp;MJ[Ó9—ç2V‡3†5%];&amp;À²ê1)wDs¶;h¶Ë¿·)&lt;#v15VbæÇÒ²°bªWo“Mo“•˜âX™\šRš&nbsp;[¬[®ÿ¢/%;¹˜;™F9›Ì†œQÓ&lt;ØÁ'OÅ¿YV}�i5{›UÑ£úR³î—–ÒžSmì¤gUýú½¯_`Õ¥¥[·níÃª�=MÌ÷ÃÎ&nbsp;z{#Æp+òÓÛÀËÎX'
BõVgô|èöØ&nbsp;·ù&nbsp;·þøx_N™S/ÇBÅ±’T;Uàb¨™Poó¢»ý:ëƒ8øxös½M“Æ,öG®GOÈ“:˜92*´¢aP9&nbsp;·kãùcâ²!ÔÛ±çzK›SÐ/ÐÎu"e-Jæúëá%Do¯4l²�Þ‚�wWØ@iŸ\oüàJãÕ	ö…NÎZ/{MÄ¶qµ§þÚóÑeúýMhApV@Rê´¸Õ[&nbsp;íÃ-•3Š²+Y—Î¦¯¨3¸ &nbsp;*Ñš®·Q¡ÞN*"æº¡ádG}tS)¼�Àaˆ�Guf¼¢Ö¥�kÝË±l©p%&amp;±
Fõ¶p§=jÛX{™ïg¯�‘À«
ô6ÐÉ4ÓÍh.äÄJèIðÕÛrþdÕ7Ò¬ºkZÍKëÍ´¬jiiill|úôi=«ê×dýë¬ÚÖÖ[”4êuTãwTã«Ê÷ˆ¿ÙGã£nfÇ&lt;,NxY�Ô&amp;Xƒ�U¶Št³ˆpµ*ÂZ‰©¦åÉfo§F¼iÇRQcFHvLõÌŒðÊŽò"§;wÕ[P3�
cññÁåIAÉ!Ä”0bJ$=;PQcÞÁ2ïn´h­tcæG×æ%°
€¾Ié~ÃB[�Ð^ÅqS1¼Š4&gt;1­�×ßì?!wëkÅä&lt;)5«¿%|\æ5!÷R·†’m£ÈªóeÕÊš� lRá
ö˜Ô_ÅÆJ)%’ª’vfÊ°È\æ&gt;,öênˆWA�B8ÍT¦·Óø0šÂ-Kk!$(j¼yÖà]¦µÒ‹U¢±Ký¤4ÛîsE�Mm¾_e
†”
žK(\–TTŒ
 g¸Ëè¦LÓv¦)1Õ&gt;#Ü-9Ø=%ØeÇž(ðÎm!â&amp;
@#ÄÙ¼°€RmÏøXŸò°&lt;éd~¢ÜñˆÂã�Òã�Ìý�Âí&nbsp;Üë¤BÔªììzƒ¬úÏŽk|�X·YÕËËKÏª/¬_bÕ{û³j»˜¿k³~z=òô¥È3‘§…¾§ÝmŒ¶�ä&gt;¸š³«nY‘n¹Q¹Q&gt; 0¨Éw¿ÀàÐIi–Éä´pRj#/LVãÕQï~É™ù	õE‰l|RCaZg}ÌtGÈÒ@ÈLgTwcŠ˜W^'+÷Ü n}wq<ur–ß[_>È)Ws+4-0ˆi©š‘‘.j*Î÷’§„tó,(i·–+ï®“î^$_¨YT²–”¬µ¡ÚÛ«Ôû›”û”÷«¡õ™’u®�¹¨»æâõöÂ­Õ²Ë³å³R2M
)ã­U ji�ÝåƒlÂ·lE“º6‘p^�¨nÍVÒ‹Ðé	mÕÙbr¶�”9,�éðú&nbsp;d†#–n	¨ÂŠ}JFœ€ìÞÕ
Ð$û
2_5~gÞßÎÀští¼¿M€³nÓ@'“H'ã‰&nbsp;ã jš;èøŒÿñ¡B„UÛß«¾~³ªîQÕ­ÐmVÕ��tÍºuc'”UAì¤gUýú½¯W±ªLXõÎ­[³/eÕöÎ.órÈé�ˆÓk‘§¯D�¹qšáyÆÓè­ñNd0
ÅÕû�)«®@o³¡ÞzæFùÇù°ñŽ@d@ÔJ²/Kˆ¦d„‘R£™…!�
îRz Ð[ó@½ÅÕ¤÷5GÎvŸ™�c:ëÒ$d˜²ìiÈ¹0š—ÆRGEE½
åƒMåêfToI#ÍUg••ëc„…Ê´ˆ&gt;+¡/«ªo­@½½s±j¹»ê­¢nk¬æÎ¨·w×¨×ÎV/ÊëàÀ¾væ‚œ¹¨¬Ù©º}¡üærÙÖ$a²•&gt;%F¯«FÁ÷o©Ts‰ƒÂp+~m·6n0±¯)OI/TÒQÃÉlÔÛŒ	YÐÛ1©—”ÝP„C3ªT�ÞV¥ÇIiŽÝ�–]
æMå.è„^ì¦Óe�&amp;UÑª³G“4WÃÉm½=ôvÖïxéÍ³êë4«êöFý³Ã´ƒüô¬ª_ÀõkXµ»0qÀóH¿Ï‘&gt;ß#ÃþG;&lt;{²58äl|ØÕô¨»ù1O‹ÞV§|Qbu@K‚MBœÍ±½l‹žF+Õ€j_“-×2-Ô1)Ð5=Ì¥"Å©“e3ØbÙÓ`Ë%Ø–&amp;Â*Äl@yR«Ð½“e×Û¾ÖB¿ƒ5�èÉÈ
§eÇ2rbY…QbªKo“å×º‡ãØUïÒÝèÒÇuäÙõ7;Ji!œâ<iux×k-pÒˆì‡Á‚¿õè®h%fh­ÄÜv¨zà<"†–§j�[g]€²&x�ï®8 ³¹íyn€…åt@¦Ü2\sŽsšÄf:,ê‹axþ)©¶ëio4Ö="" †½œîØÁ²íi°�Ñ­ëŠÝ="" ¸p™s‘kyÀs£f¹i¨¶Ýõ¶}l‹^Že“ew�u[µ="" !Þ»být»s‘«bwsð2‚3ÐÞÐÏöŒ¯õið"ƒ—ÚÕì˜½É±b»cb·ƒr·ƒb×bçb÷="" ±ð�°ê«y·yõõ§Õì="" €qvš¬��õ¬ú‹¬zÿyu19Æz5ìÔrØöÔÝïs®vv†¯ÂuÄ�še‹opÎŠðÊ�ö¦ç:u7˜�˜�o²(m'¦„’¢jd5n’j="" jf|m="">õ@cå'KhÑ#bÿ¹nß)e�ŠË'äJ)Y’ªÜ)%ö¼:fe8vB–Ö]WÜS‡ïkÄ÷³Ë´4'$¥Ëƒs¥ÃÍU à™–�/Ÿ-¼¾Tpm¡h±‹&lt;#¡M‹és
êú(áÆrÑõÅ’ëKÅK]U3:òWÕÓbêRáêBÎ•¹ìµÑÜ±VÒpØDu3q¨‰°Ý]^�ïf•Îv&amp;žŠZì�ä%ˆF
ÐDä~E–€ŒøMÈ]Á‘QÃ˜ù8œJä%†–ENÃð*\:Xàh›ñ+íK“‹âÀöÝU�Wƒ*x©CœLüŒÃŒ†ŽM86êlÜçXV®øMXõ�&gt;^Ý¬ú
£4vÒ³ª~ý›­W³êâ+Yµ»‰¹tÕÛõˆÓçÂNQÝO»[À–¨íû(wÝìê®†ºÔäÛÄºf†{çc¼Jì�Þ©i*·-Ž‹"¥—'F7”ø(YŽ<r@ul;Ö!zËÌo‘×fŒËüæz|ÇeÁ�õ ‚Š)%»­:g®³¬‰yŽ…�k»õ¶rj†_Õäo·fz ÞÎ)‰wæ¶õvnk…Ã.vr¶&ËÞ?õöê|É¼‚:#†õ½s¢ê="" ue ="" èíå³Ù«êm="" °êmÅ¶Þ6–ªêñ½�Å½qËêÈ…¾'è­Õ[r&¿"sx•4*õš�»ô·¸ó*£™ùiˆÞbè9°cŠ”Šqì:ë`c»Ì„leq@o÷Ž›‡zëo¿k:ª·~Æ)Î#ˆÞŽîè­Š”‡ô¿1vÕ-�Ömv}�†‹½ÍªhÃÅ®fu4.¬="" 4vÏªúõg[Ïyõoûéë¯ÿ)ví(hìv;Ôå}¸Ëëð€ï™Ç!÷3ïyžzÏÎà £á!'ã#.�x�#Äú<Ç`oœhr_d,­6•Ðldsr†yj�="" ÖÇ="">ÁÏäXgÇ)3ç”Y´TXÖæ[`Üs£¼óc|Šâ¼©YÎüJ«–
ë–
›¢M+É¦®È­*=%"EÂŒÜ0N™§˜j'¯±TÖš+j,Ûhö²'·&lt;FÑ©-AmtWÃEÆp•3Ü5®ŠZW)Õ›ƒOå–&amp;qði<blÝ|rqþÖmlñvùËk\dt—6ØÎm4')Í©•ä]w˜twˆeb™È5 ´šÉ�¡ç`hÙÐÔ—[Ôff7—3Ì%Õ–ÍzŽwyr`i|pi¼1Ö¯0†¸9q="">€ÍÙxn¹%øØXb6§Ô‚]bVg…õ±Åxm·¦î¢T[Xô^XOËàEv5=êh|ØÆðp¾õ¾ó{­ÎZœßã9¾Çs=®Þ,«êvdèvÀíç°wZ
¿T�Qc¥]1°žU_ÂªÓÍ/³ªˆ¿iµÇÁ©»‹¡'9ž'œ,NûÚœ	°G=Ð`1pÄŽŠ«	þŽINÍ‹Ê4»ôP÷¬Z®CrÏßˆ·*ŠƒMš¥ñuEžš5—àIJÅÒ‘Ž*@¬5¹‰Í„è^®Ï¤Üm¬ÍSÕÊ-ÍT¦ñÊsúšãf»BB&amp;d±ÝõY
@ÜÅ,‚£µe~þ\WÚ„4¿¯ÐeÅ0¿üâXÚÆTÊúdÚ´¬æxd@&nbsp;gÛñ›Óië“é[³©‹ªü1AåŸ4Ì«{FQ¸6‘¸6žpn y°	À)Ø¥}HÈ„6˜w2åÕ%êÖøÙîà³=þ-1
4g�`iDSI¦ˆ5ÀsÙwÔ»sÊ"9	5y1´ìh´hŸ˜ÕLpjgš!¬jW
0Þ/	œà-ÓîŒj(ÒWîkgbgÐïwtÄïèØ&gt;GÕ^GTùqo–U_g°Ô«c§×,µ÷žßÖÖVÏªúõ»^û°ê…á¾Þ_`UðFË©=ïb1êíJØ©¹�“$×“.–§}aK”ÀU¤Øl×õ Ð[€«Òj³’‡´Ïœ(÷úbxÝ­dZ0í
bÂ	¸&lt;6ŠSî"¥Y7”ø“Óâè9Q5ˆÞ2r“x•C­ž“
7À}u‘ÍebzkEö� f^ôvDßÉÌUÒ�„z[S&gt;"Ì[P¥Ž´÷7›*&amp;$øµñT¨·iãÂŠ½­\ì.z»1•&gt;ÎwŽðªFù•Ã-¤&gt;q®+èíÅÑÄUZ_}%&nbsp;` ¶Z·IÄ@©HÉ(cæT�g»ýTl¬¸*S@Ê„o„4niš¤:\#tz+¯õl(‰aäÄƒ 
5œ¬J�¨HŽ’m:X«–:�¨©ã—=v'wgTa°´m8é²m8écg˜äxzÐïè¨ÿÑTo=�tU¾IVÕ-~�á{§ƒéÖ›¡z«Ûp±k�`U###=«ê×gíÏªÐxeUµZ—Uå;¬ªÈKPºTx”{êö&gt;,r;è|òmÓco[�|Çæ4 Ö�X»˜&nbsp;UÁÇaU°õ)›3�†oÃ”ãŒÓ”SŒ§y¤Pèçc›`—f›nŸeŸé�êš}Ý=€:åÇ¸—$¸•$¸—&amp;z”%y’ýù–%–%pAÄä�ŠäðÊÔÐêlÿš|_f¡³À¯&amp;/ˆ–Q�‰¡eÅÒsQF1ÂXá¬‚ˆºB¸ë‹Âë‹"™ù°ò„Yx6®¾(ª¡8|²¾&lt; šUSWÉ*G¾0ŒYZ›Ž`)b�®FiEûO‘ÚÈpbrDej05Ó‡–ãIËñ¨Êð,Çù@÷Ìswßß$÷Ì—œ(ðL3ÃíÁOµM
±I
±Š÷…¯I$RÊ‚
/tJ=ƒP*Ì¥º›”êlrÄÑè��ÁAËS²-Þmr|—ëô.Ûá]¶ý;§cò7Çª»`T�u`ÝªÂW�kÜoZ�–UÑX›¯Ñ³êV]ŸÖ¨_Íª2„UgÂ-f�O��ÓLÐ‰:÷ãf°Dßw´X»8oGÑ‚”fƒpMqcäÙªØæ�u”,û¼hhÃXÚPâ*¤XÕä{’b(aà Ð²Áç(FQëK„N=N	Ž[šÒ„OS†E�3�ÞòÀN¼˜œßFÍ“ÓòŒ|ßßœ6)�Uó3:kÊ`
€]¼Ô�YÖDŸÂhZúQö$¨y%‹½‰0_&nbsp;‰YìÃjøEàóàoA˜4*Ê:7~n |¶3¦»®¤‹	M“:kÛá¤ch�$§çŠÉJ&amp;nDâB»þ	%�[šÕ\žÒTš\_�ÞF÷ék¶ëãZÈÞ�R³bµ­å•©a¥‰MåŽ(«ò*l‘»&amp;ßÜ´ç=ªhàä³c€†Vì;ƒóëogèms&amp;Èæt·74@SyQyîõ8Ü™'«½Ãàÿñ×°ê~ÍS¿X«ÿÒæ©W×êï½ç×³ª~ýÞ×¾¬ÚûË¬ÚÉ©�÷9&gt;t|*èÄBÈÉÉ&nbsp;çãŽæ'½�³X`fìdö\oaØëcïë(§›—ÄÛ&amp;ø¹gE¸4âm€ÞÊè–¤t§Ü¨`|¼_alxK…C+Éš–íW�‹¦d„#zMËÆ²
£»ÝÔB¨·í¬@&gt;è-·4]JÇŽË|gº¼ÇÚ‚:ëpâª&lt;&nbsp;·
¨·m”R57­Äô7åvÕ–v×á‡Zò—¶õv�[É�F„‹ýñPoÕ˜…ÞøÁ¦R&nbsp;·½
@Šñm©@oû#¦Øv¡‹Y„èm�Voe´\IU^G]Â¸Üè­Š$$á¸eÜò&gt;¥±8YQë&gt;À³éåZ·TÀ±Y˜ê,J‘ÓÂ*SÂð	‘­$Èª]uf
%ŽèÝ&gt;4¯Ó5þ}aÖüvé¯ŽÞxÙœ‰·?Õƒèmª·î‡;ˆ¹r…R®ìPüjVÝo8ª·ºŽëû
GØ«·ºŽëºz«:�²ê©S§Àãõ¬ª_„¥Ëª?¾Èªýýý[[[—/]Ò¼˜W•Éd
„U¥¹ñ§b·ƒ`+&lt;µ¸°?ög£Ão™û³Åñ¿Xž|ÇúÔ{vg8t2:xÊÕô˜»ùqË“§ÝÍÏxXz[ûØ˜Ú›‚P9ÜÕIîXF{XG¹ÛE{8`¼â|Q{Òä`g M©Án)Ážé¡^aÞYá¾Ù‘¾¹Ñ¾ùßÂXß¢8¿¬?&gt;&gt;é ƒnE¥‰áå‰á„¤`ÃHiÐ£‰”IJ�&amp;¥Æ�ÒbÈ`§cªÒ1”XpDl&nbsp;ÿ”LxÇVeÄR2à_�]…&lt;ŒŒ~IZ4ò"IKC+SB‰)¡É!\p9.¨,	øÀ'cƒ
0Aù1�yÑ¹Qþ9Q~9QÞ9Q ¬EmB¡iR°3â\ç„õqŠõvŒñtŒö°‹t³�pµ	u¶s�N,Û‰TÄ=ÉÏæ4€}@€Rþ»˜u2&gt;ì`tÈÞà&nbsp;íé÷¬N½kzì�T³·ëìßi°‡i÷Ëæm–ÃQ¹èÍ°ê®øu:à^=®q?AF^kc`”U�?Îårõ¬úÏ²ªBÄµ÷?6pl):­q=jkO¢—å	ðëä«ã�¶ã¶d�¼éÛµTXP2-üœÒBaê¿�cÑF·(À¸fGú€sW€ñç”:µ’l+Ó¼K°áÄ”`pÊÈéáätGÅ´’<zØv}ÍÖ] Î�%Ñ¬‚äÆâdœ(™aj¡ëx›àd15©•˜#"e‹È9jö="" btÔÓˆk£Éiùíµ¹ÓíÁg»f»‚z›2ÚkŠ;k‹;jkºxešÖÄyuÀÙ®à9u š‡cfõ•vÔ="" 4'ÏvúÎtúŽjcäô|¤="" }ÇýŒ’%&gŠhb¿"£«!`hàØßâ(¥�Ÿª¾(¹®0©¡£dÚ©Ø2†m]q="" ¢="" °3·2ð²Ä�¢¸pv©ƒ²ÆnÍ5¥‡yi)uÇ�Ívk€{¦�ÀiÇ�íŒ§Õ)«“="" ÏÃ="ž‡ÛÁö8ÔávH™�º;Þ«ê�ë}ì7éoo°®ÑÇÞæ)ÔX÷ž°*ˆ�lllô¬ª_¿ëõkXµƒS;åul<�êíTÐñá€cxÇ£v&amp;ÇÝ-NxézN:‡ê¸-Åx¹°“1ÌËq–±^®¹Ñö¼JØåÔJ²Ê�qËŽðÍCôV@¶k*·¯HöÃÇ”!¥†Áëñt¢HiÎ*Ô[E­Ð±ºB¢·)]�¾Ãb—1©K'DDIÑê­”’=," ‘u°ÒeÔb9­ »!cº#ÕÛ®úÜ ·Ì¢Žz|w}þ¨8ÕÛyuà�7­£¶èmgm¡šôvºÝo#Œ�t•È«ó ÞrwÜ&µzkÌp5y”îã:‰ªÂŠ“ëà|ùdnidw½•Šc!­¶­É£d@�g(5´õ¶0.”_iÓÁ„z[wlŸå¥«·¸@§ú,t="" 'µ!“�ÍiËs±¶'€Òª<+½ít="¤¬€¬ªhïPÈå¿žUu×_s²ê.Çõ×iVEM×QV577×³ª~ý¡Ö.Výa‡UAÔÛ××·¹µuåòe”UÛÚÚtYˆ³(Ë·�ïòÏå€Äí" Ûé="»£oú“Éá?™yËôèŸÍ�ýÅòøÛÖ'ß$ef;ÍêŒ¤Y=-Ž{[¡Ò}ÚßîÌÎ}#ê?`én†ÌÛ5vêdììq�)!Ž)!Né¡ÎéaÎáp¾�ÀœHÏÜ(¯¼hï|8hÃ»0Ö»(Î§8Î·ë[ïà±ìÄÀ²D8¼" lÝaÉ`wÀœ,ºÁŸƒ‰Ègd#Àà†_rž;gËp&ÅÇû#5½°ß¿(p³o="">b¥žã•
~*�ì÷¬p·Ìp×ô0èè‹Æ´IH• â
•6ÎÛ
qH¶Œò0Ï=ÂÕ4ÌÙ$Ä^Øø#M©^V§Ðr_H©&amp;G ¥²;sÀæÔ{V'ßµ&lt;ñ¶Ù±¿þs¢ñŸé6o×Ø¾M³y›fýºÝa™HÐÞÙ¥üu¬ºŸ[Ë?¿Z�µÆJÚÍ×MÖ³ê¿ÈªB¾:Ø\ãËM‡ýáÇjç#VG^¨v°9ígk&nbsp;ã�ájælÝB4o®0Á'YU¦[+jÌT�–õÅ‰þžð²Å«çÚJ¶VÙP2ÜÀÀÇ�Ã…G£fó*œÓuÖ™·3­›	ž´ìxX'Ÿ›ÄÆG)™ƒ&lt;Ûž}Wƒ‡�ÓZ™(¢`»üG%.C9#NP‘+¡¤¶³âF$cmncR;FÁHm£fK)yRj®²6
|r¼ÍcBæ®øw°’¤Ô9#­·)lTê:"qjõPÔb¥”aeF+–¶ÝÏšË“¹eI�Åé¼ŠÈvìmogÙò*½ë
£ë‹ÂD›Î:‹–»Ô£*=Œ˜Ûr¡Z`1xvI¾•i^&lt;¢M;x^,3Ù²"Å1'Ú59ÈDM¨ÖgWœP4?h€vÄ«®æ'¼-Ž‹Ý*Ýµ�ív°Íå€,£PÈ•]¿«¾¢=ªºµúºÓjtkõuÒ´±“žUõëßoýVmg×ŽxUûB¥¸:àw´Ðîˆ�!Ô[xQo¡SÐ²ãà�è-�ky�9»Ô¤ Î†žgÙÁ2BDÏµÂxfF@½%¦:·Ñ¬Z*ìHi%ðN&gt;zN½M	£e‰ÈvH½‡¹œaË)ó£ç`kóãjrqœ²ˆ®—A¾í@‹};ËGPôVB�Uq|ÆeN<o)' æh«sº¢µzÛÕ€•ÓÓ!u"zÛyŸ8Öæ1.ó˜�»="" µ*kr¥”emrs0ÐÛa‰ë�Ï§�Ž“t¥=""  Þ¦½åíèms f Àa]="" Ðf¾Æ¾™àô–�’t[w7€§iywèmjbnl)ÇƒÈª$="">°çKJ÷UY‚çô–[nU–ä”‰êívø›¤�têóº_c]ÃIOË“.æ'¢¬ŽIÜJ•º’½u&gt; ¯È2«|£¬úŠi5¯Ùp¡ÕÛ½ÀzVÕ¯?øz«ööõmll\¾|yxxx/«ÊÛÚÙXŽí;§wÁæ»`9¾kwl›U·÷¡?™~Ëì(’f=ñŽõ©w!´„Ðjtˆ–µ9„[·}ƒC ·š‚`„ÍQîÈÝ#:ëX¬¯í6ºú;€ä”‚f]C]ÓÂÜÒaÁ0ÀC÷lÄ&gt;'Ê372,œ¾A²l•ÛÙØí�…ƒ9�í_„…ì‰ü~}@aœ_áÎW�ï¾øn“¢½Ð’.;Ò#+Â…</o)'></zøv}íö]></blý|rqþömlñvùëk\dt—6øîm4')í©•ä]w˜twˆeb™è5></r@ul;ö!zëìo‘×fœëüæz|çeá�õ></iux×k-pòˆì‡á‚¿õè®h%fh­äüv¨zà<"†–§j�[g]€²&x�ï®8></ur–ß[_></iužˆ\¤`d�hbg$‘2*^é(pðj†…‰s=!ó½!ãmñ�µ¥ð´è'aío?û±ø²ð:¥ˆë©(zðsw4¥,0õò×”‚|ÿ<ùêh¹mèdfiu–˜”%$e*j1€£‡ež]></w¥‡sâ©ùššmv%¥yäçà�ªº½o></eº=«�qô></yrïª;yõgh^uzxx,v½{çîâkyµ£«cä¿“dÿ�™÷÷0þè^œqg°‘—ã¶·útþùasy€#x¯g½></s-üì(µpþ°ê?[o¶·yõõf¨é:ð[”umll�«‚ëyu¿þë_fu¹¬m¤4y9èär(üká§§‚odøžö´></ziûöi×³gê></u></a></i></u></i></u></s></b></s></i></b></b></i></s></i></b></b></s></i></i></s></i></i></i></i></i></s></b></i></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.alextsun.com/files/Prob_Stat_for_CS_Book.pdf">https://www.alextsun.com/files/Prob_Stat_for_CS_Book.pdf</a></em></p>]]>
            </description>
            <link>https://www.alextsun.com/files/Prob_Stat_for_CS_Book.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24693589</guid>
            <pubDate>Tue, 06 Oct 2020 00:17:45 GMT</pubDate>
        </item>
    </channel>
</rss>
