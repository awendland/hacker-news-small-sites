<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Wed, 02 Dec 2020 16:50:09 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Wed, 02 Dec 2020 16:50:09 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Busybox-based Linux distro from scratch]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25263398">thread link</a>) | @pfrog
<br/>
December 1, 2020 | https://re-ws.pl/2020/11/busybox-based-linux-distro-from-scratch/ | <a href="https://web.archive.org/web/*/https://re-ws.pl/2020/11/busybox-based-linux-distro-from-scratch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1624">
	<!-- .entry-header -->

	<div>
		<p><img width="257" height="303" src="https://re-ws.pl/wp-content/uploads/2020/11/logo.gif" alt="linux logo" loading="lazy"></p><figure id="attachment_1648" aria-describedby="caption-attachment-1648"><a href="https://re-ws.pl/wp-content/uploads/2020/11/mmc16mib.jpg"><img loading="lazy" src="https://re-ws.pl/wp-content/uploads/2020/11/mmc16mib-263x300.jpg" alt="Canon SD MMC card 16 MiB" width="263" height="300" srcset="https://re-ws.pl/wp-content/uploads/2020/11/mmc16mib-263x300.jpg 263w, https://re-ws.pl/wp-content/uploads/2020/11/mmc16mib-899x1024.jpg 899w, https://re-ws.pl/wp-content/uploads/2020/11/mmc16mib-768x875.jpg 768w, https://re-ws.pl/wp-content/uploads/2020/11/mmc16mib-1348x1536.jpg 1348w, https://re-ws.pl/wp-content/uploads/2020/11/mmc16mib.jpg 1443w" sizes="(max-width: 263px) 100vw, 263px"></a><figcaption id="caption-attachment-1648">16 MiB SD/MMC card. Made in Japan in 2005</figcaption></figure>
<p>Today, I would like to show something different, than usual reverse-engineering, that appears on my blog usually. I needed to prepare a Linux distro for myself to be able to run it on my PC. But not the ordinary operating system that we download from webpage, then use fancy graphical installer to select, what we want and where. My goals were very specific. First was to have it custom-compiled. With that in mind there arenâ€™t many choices left (maybe Gentoo?). Second was to not cross 16 MiB boundary. Why exactly that? Thatâ€™s simple. I have old (15 years old to be precise) SD/MMC card made for Canon of exactly that size. Quick check showed me that this is possible. I tried buildroot and it failed to fulfill second requirement and I decided not to continue, despite the obvious optimizations on kernel modules, I could do. Itâ€™s simply too complex for such a simple task. If not buildroot, then letâ€™s go and see how to do such thing from scratch!</p>

<p>Basically the plan is to have custom Linux distro compiled from scratch. It may sound like something incredibly complex and hard to do. But itâ€™s not. There are just few problems one must learn on how to overcome. The most problematic constraint in my case is, obviously, 16 MiB limit. To not exceed it, I have to use busybox as my userspace. This by the way simplifies distro development significantly. Busybox works the way, that, if linked statically, requires only one, single binary to be able to work correctly. So, to sum up, on software side, we need Linux and busybox. You may wonder, how do I want to boot that system, then? Well. I said I need Linux ðŸ™‚ Maybe some people know, some does not, that Linux is itself a boot loader of some kind. At least, when using UEFI and this is what I want to use, it can be loaded directly by UEFI firmware. But thatâ€™s another thing to note â€“ I will describe a way to prepare a distro for UEFI â€“ it wonâ€™t be as simple as that, for legacy BIOS.</p>
<p>The whole plan will look as follows:</p>
<ol>
<li>Get compiler</li>
<li>Compile Linux kernel</li>
<li>Compile busybox (statically and stripped!)</li>
<li>Prepare initramfs with whole userspace</li>
<li>Format drive as EFI System Partition</li>
<li>Combine kernel and initramfs into single binary</li>
<li>Optionally sign the binary, in case we want Secure Boot to be enabled</li>
<li>Add entry to embedded UEFI boot manager</li>
</ol>
<p>In the meantime, I am going to show few ways to debug the system, in case of any problems.<span id="more-1624"></span></p>

<p>This is maybe not so obvious, but you need new compiler. Most likely, you could use the one that your distro provides, aliased as simply gcc. But this way, you will by the way use glibc as your standard library. For a lightweight system, glibc does not fit well, as this is most heavyweight libc, we have available. Therefore, I will use uClibc. And for that, we need a compiler. Or, to be precise, a toolchain. A toolchain, consisting of kernel headers, uClibc and gcc. Here, I could show, how to build such thing from scratch. But itâ€™s not a tutorial about building a toolchain. This requires knowledge that can fill another tutorial. Instead, I will use the toolchain prepared by my latest project â€“ <a href="https://github.com/v3l0c1r4pt0r/cc-factory" target="_blank" rel="noopener noreferrer">cc-factory</a>. For those, who did not read <a href="https://re-ws.pl/2020/10/meet-cc-factory-a-factory-for-cross-compilers/">my previous post</a>, it is toolchain factory running in Docker container, that provides a recipe for a toolchain that just works. If you tried compiling a toolchain from scratch in the past, then you know that this can fail, even if you use crosstool-ng. With cc-factory, it works as long as Docker can start a service and has Docker Hub working. But enough of that. In cc-factory, I am experimenting with releasing binary distributions of my toolchain. And <a href="https://github.com/v3l0c1r4pt0r/cc-factory/releases/tag/x86_64-gcc10.2.0-linux5.9.13-uclibc1.0.36-1">newest one</a> is special-made for this job. You can simply download it to you disk with:</p>
<pre>wget <span>'</span><span>https://github.com/v3l0c1r4pt0r/cc-factory/releases/download/x86_64-gcc10.2.0-linux5.9.13-uclibc1.0.36-1/x86_64-gcc10.2.0-linux5.9.13-uclibc1.0.36-1.tar.gz</span><span>'</span>
</pre>
<p>After that, you have to install it to your <code>/opt</code> directory with:</p>
<pre>tar <span>-xvf</span> x86_64-gcc10.<span>2</span>.0-linux5.<span>9</span>.13-uclibc1.<span>0</span>.36-1.tar.gz <span>-C</span> /
</pre>
<p>If you prefer another installation path, then head onto cc-factory project to see, how to build one from source. Then, you can choose whatever path, you like for this SDK.</p>
<p>Next step is to export SDKâ€™s bin directory to you PATH for convenience:</p>
<pre><span>export</span> <span>PATH</span>=<span>"</span><span>$PATH</span><span>:/opt/x86_64-linux-uclibc/bin</span><span>"</span>
</pre>
<p>Now, itâ€™s nice to check, if toolchain works. Letâ€™s write one-liner C hello world program to your temp directory, compile and run:</p>
<pre><span>echo</span><span> -e </span><span>'</span><span>#include &lt;stdio.h&gt;\nint main() {printf("Hello, World!\\n");}</span><span>'</span> <span>&gt;</span>/tmp/main.c
x86_64-linux-uclibc-gcc <span>-static</span> <span>-o</span> /tmp/main /tmp/main.c
/tmp/main
</pre>
<p>And you should see the familiar text on your screen. You are ready to go!</p>

<p>That is, in my opinion, the easiest part. First, we have to download kernel image, that we want to use. For that purpose, we need to go to <a href="https://www.kernel.org/" target="_blank" rel="noopener noreferrer">Kernel Archives</a> and download latest stable tarball. Optionally, we can download PGP signature and verify its correctness. But this is outside the scope of this tutorial. Another option to get kernel is to clone its stable repo with:</p>
<pre>git clone git://git.kernel.org/pub/scm/linux/kernel/git/stable/linux.git
</pre>
<p>This is the path, I chose, because I donâ€™t like leaving multiple copies of kernel sources on my hard drive, so I prefer to have one, central clone of repo and use for any project, I need it to.</p>
<p>In case of tarball, it now has to be unpacked with usual:</p>
<pre>tar <span>-xvf</span> linux-*.tar.gz
</pre>
<p>Then, in case of tarball, you got directory with name dependent on you kernel version, in case of git repo, it is simply linux. So we can cd into it, in any of the above cases:</p>
<pre><span>cd</span> linux*
</pre>
<p>In theory at this point, we could set the compiler, we prepared to be run by kernel buildsystem. But this is optional, as we target <code>x86_64</code> platform, that we run our host on, so default compiler should be as good as uClibc variant. I case, you want to use custom one, you have to export the following:</p>
<pre><span>export</span> <span>CROSS_COMPILE</span>=x86_64-linux-uclibc-
</pre>
<p>Now, we have to configure our kernel.</p>
<p>First step is to choose defconfig. Possible values can be listed in case of x86 with:</p>
<pre><span>ls</span> arch/x86/configs/
</pre>
<p>At the time of writing this returned the following options:</p>
<pre>i386_defconfig tiny.config x86_64_defconfig xen.config
</pre>
<p>As you can see, there are only a few. So, we do:</p>
<pre>make x86_64_defconfig
</pre>
<p>At this point, we are ready to compile. In case, you want to do some modifications, you could do:</p>
<pre>make menuconfig
</pre>
<p>And select (or deselect) some options there. If you think, you are ready, you can type:</p>
<pre>make <span>-j</span>
</pre>
<p>And wait couple of minutes (up to half an hour), depending on speed of your PC. Afterwards, you should see that <code>bzImage</code> has been made and is available at <code>arch/x86/boot/bzImage</code>. We can copy it somewhere in order to not accidentally start its recompilation:</p>
<pre>cp arch/x86/boot/bzImage ../
</pre>
<h2>Testing on hardware</h2>
<p>At this point, it is possible to run the kernel on our system. If you donâ€™t have Secure Boot enabled, then you can try to copy the kernel to you EFI System Partition (wherever it is, I will call this path <code>ESP</code> from now on). But first create new directory for your distro:</p>
<pre><span>mkdir</span> <span>-p</span> ESP/EFI/linux
cp arch/x86/boot/bzImage ESP/EFI/linux/linuxx64.efi
</pre>
<p>I am changing the name in the meantime, as I heard that some systems does not like binaries without <code>.efi</code> extension. Now, we can try to boot.There is more than one way to do it. The one that works always is to utilize EFI firmware directly. But this one differs significantly between manufacturers, so if you prefer that one, please refer to his support pages. The other is to use one of existing tools. For sure KeyTool, that manages Secure Boot keys, is able to start any executable from ESP by browsing the filesystem. But the way I would like to show is, by using so called EFI shell. Why? Because EFI shell allows us to experiment with kernel parameters, by simply typing them, as we would start new user program. And, in fact, from EFI perspective, we simply start a new program.</p>
<p>There are many shells in the wild. I tried EDK2, that is available on Arch as <code>edk2-shell</code> package. It is then available at <code>/usr/share/edk2-shell/x64/Shell.efi</code> You can simply copy it to <code>ESP</code>, just like with kernel, then you have to add it to your EFI boot manager, or use boot manager that is able to autodetect it. You can find a bunch of resources on how to do it, even from inside Linux. But, please do not add the kernel, you copied in such way, to boot manager, as we will play with it a bit, later. Now, in EFI shell, you will be presented with a list of partitions, that the shell has detected. This might be not so obvious at first, but, somehow, you have to identify the one, that is you EFI partition. You should see a similar numbering to the one you see in Linux console, when you list with e.g. <code>lsblk</code>. You can try guessing it by typing its name, in similar way as in Windows, e.g.:</p>
<pre>FS0:
</pre>
<p>to switch to <code>FS0</code> partition. Then you can simply type ls to list its content. Once, you found the right one, itâ€™s worth to remember it, as you might need it couple of times. How many, depends on how many problems, you would have.</p>
<p>Then go to the directory, where you copied your kernel:</p>
<pre><span>cd</span> EFI\linux
</pre>
<p>And ls to make sure, it is there. Now, we are ready to call it:</p>
<pre>linuxx64.efi
</pre>
<p>Yes. Itâ€™s as simple as that. But this will fail. We did not provide any root filesystem for our kernel, so it will gonna panic. But donâ€™t worry, as long as reason of the panic is like that:</p>
<pre>not syncing: VFS: Unable to mount root fs on unknown-block(0,0)
</pre>
<p>then it was expected. In case of any other error, act accordingly, as this may be hardware dependent. So, probably, something has to be reconfigured in menuconfig.</p>
<h2>Testing in qemu</h2>
<p>Itâ€™s quite a nice option to be able to test your work on real hardware. However, in my opinion, it is much easier to do it in virtualized environment, that you can quickly reset at any time and where you would have latest binaries for testing, all the time, without wasting time for flashing them somewhere. Therefore I recommend to prepare qemu as such environment.</p>
<p>For that, you will need â€¦</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://re-ws.pl/2020/11/busybox-based-linux-distro-from-scratch/">https://re-ws.pl/2020/11/busybox-based-linux-distro-from-scratch/</a></em></p>]]>
            </description>
            <link>https://re-ws.pl/2020/11/busybox-based-linux-distro-from-scratch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25263398</guid>
            <pubDate>Tue, 01 Dec 2020 08:10:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[QEMU Advent Calendar 2020]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25262608">thread link</a>) | @todsacerdoti
<br/>
November 30, 2020 | https://www.qemu-advent-calendar.org/2020/ | <a href="https://web.archive.org/web/*/https://www.qemu-advent-calendar.org/2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    


    <div id="myCarousel">
      <div>
        <div>
          <div>
            <div>
              <p><img src="https://www.qemu-advent-calendar.org/2020/images/qemu-winter.png" alt="QEMU"></p>
              <h2>Brightening your days in the winter holiday season.</h2>
              <p>
               This advent calendar is brought to you by the
               <a href="https://www.qemu.org/">QEMU community</a>.
              </p>
            </div>
          </div>
        </div>
      </div>
    </div><!-- /.carousel -->

    <div id="day-1">
     <p>
	<img id="img-day01" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 1" onclick="opendoor('day01', 'Day 1 - Tweetable bootsector game');">
     </p>
     <h2 id="title-day01">Day 1</h2>
     <div id="desc-day01">
      <p>
        This bootloader game can be generated from text that fits in a tweet.
      </p>
      <p>
       Size of download is 893 bytes.
      </p>
      
     </div>
     <p>
       <a href="https://www.qemu-advent-calendar.org/2020/download/day01.tar.gz" role="button">Download</a>
     </p>
    </div>

    <div id="day-2">
     <p>
       <img id="img-day02" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 2" onclick="opendoor('day02', 'Day 2 - QEMU 5.2.0-rc4');">
     </p>
     <h2 id="title-day02">Day 2</h2>
     <div id="desc-day02">
      <p>
       No disk image today, but a new release candidate for QEMU: Version 5.2.0-rc4 has just been published yesterday â€“ please download the package and give it a try! 
      </p>
      <p>
       Size of download is 102 MB
      </p>
      
     </div>
     <p>
       <a href="https://download.qemu.org/qemu-5.2.0-rc4.tar.xz" role="button">Download</a>
     </p>
    </div>

    <div id="day-3">
     <p>
       <img id="img-day03" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 3" onclick="zonk('day03');">
     </p>
     <h2 id="title-day03">Day 3</h2>
     <p>
       Image will be available on December 3rd.
      </p>
     
    </div>

    <div id="day-4">
     <p>
       <img id="img-day04" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 4" onclick="zonk('day04');">
     </p>
     <h2 id="title-day04">Day 4</h2>
     <p>
       Image will be available on December 4th.
      </p>
     
    </div>

    <div id="day-5">
     <p>
       <img id="img-day05" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 5" onclick="zonk('day05');">
     </p>
     <h2 id="title-day05">Day 5</h2>
     <p>
       Image will be available on December 5th.
      </p>
     
    </div>

    <div id="day-6">
     <p>
       <img id="img-day06" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 6" onclick="zonk('day06');">
     </p>
     <h2 id="title-day06">Day 6</h2>
     <p>
       Image will be available on December 6th.
      </p>
     
    </div>

    <div id="day-7">
     <p>
       <img id="img-day07" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 7" onclick="zonk('day07');">
     </p>
     <h2 id="title-day07">Day 7</h2>
     <p>
       Image will be available on December 7th.
      </p>
     
    </div>

    <div id="day-8">
     <p>
       <img id="img-day08" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 8" onclick="zonk('day08');">
     </p>
     <h2 id="title-day08">Day 8</h2>
     <p>
       Image will be available on December 8th.
      </p>
     
    </div>

    <div id="day-9">
     <p>
       <img id="img-day09" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 9" onclick="zonk('day09');">
     </p>
     <h2 id="title-day09">Day 9</h2>
     <p>
       Image will be available on December 9th.
      </p>
     
    </div>


    <div id="day-10">
     <p>
       <img id="img-day10" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 10" onclick="zonk('day10');">
     </p>
     <h2 id="title-day10">Day 10</h2>
     <p>
       Image will be available on December 10th.
      </p>
     
    </div>

    <div id="day-11">
     <p>
       <img id="img-day11" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 11" onclick="zonk('day11');">
     </p>
     <h2 id="title-day11">Day 11</h2>
     <p>
       Image will be available on December 11th.
      </p>
     
    </div>

    <div id="day-12">
     <p>
       <img id="img-day12" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 12" onclick="zonk('day12');">
     </p>
     <h2 id="title-day12">Day 12</h2>
     <p>
       Image will be available on December 12th.
      </p>
     
    </div>

    <div id="day-13">
     <p>
       <img id="img-day13" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 13" onclick="zonk('day13');">
     </p>
     <h2 id="title-day13">Day 13</h2>
     <p>
       Image will be available on December 13th.
      </p>
     
    </div>

    <div id="day-14">
     <p>
       <img id="img-day14" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 14" onclick="zonk('day14');">
     </p>
     <h2 id="title-day14">Day 14</h2>
     <p>
       Image will be available on December 14th.
      </p>
     
    </div>

    <div id="day-15">
     <p>
       <img id="img-day15" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 15" onclick="zonk('day15');">
     </p>
     <h2 id="title-day15">Day 15</h2>
     <p>
       Image will be available on December 15th.
      </p>
     
    </div>

    <div id="day-16">
     <p>
       <img id="img-day16" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 16" onclick="zonk('day16');">
     </p>
     <h2 id="title-day16">Day 16</h2>
     <p>
       Image will be available on December 16th.
      </p>
     
    </div>

    <div id="day-17">
     <p>
       <img id="img-day17" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 17" onclick="zonk('day17');">
     </p>
     <h2 id="title-day17">Day 17</h2>
     <p>
       Image will be available on December 17th.
      </p>
     
    </div>

    <div id="day-18">
     <p>
       <img id="img-day18" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 18" onclick="zonk('day18');">
     </p>
     <h2 id="title-day18">Day 18</h2>
     <p>
       Image will be available on December 18th.
      </p>
     
    </div>

    <div id="day-19">
     <p>
       <img id="img-day19" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 19" onclick="zonk('day19');">
     </p>
     <h2 id="title-day19">Day 19</h2>
     <p>
       Image will be available on December 19th.
      </p>
     
    </div>

    <div id="day-20">
     <p>
       <img id="img-day20" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 20" onclick="zonk('day20');">
     </p>
     <h2 id="title-day20">Day 20</h2>
     <p>
       Image will be available on December 20th.
      </p>
     
    </div>

    <div id="day-21">
     <p>
       <img id="img-day21" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 21" onclick="zonk('day21');">
     </p>
     <h2 id="title-day21">Day 21</h2>
     <p>
       Image will be available on December 21th.
      </p>
     
    </div>

    <div id="day-22">
     <p>
       <img id="img-day22" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 22" onclick="zonk('day22');">
     </p>
     <h2 id="title-day22">Day 22</h2>
     <p>
       Image will be available on December 22th.
      </p>
     
    </div>

    <div id="day-23">
     <p>
       <img id="img-day23" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 23" onclick="zonk('day23');">
     </p>
     <h2 id="title-day23">Day 23</h2>
     <p>
       Image will be available on December 23th.
      </p>
     
    </div>

    <div id="day-24">
     <p>
       <img id="img-day24" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 24" onclick="zonk('day24');">
     </p>
     <h2 id="title-day24">Day 24</h2>
     <p>
       Image will be available on December 24th.
      </p>
     
    </div>

    <hr>

    <div>

      <div id="about">
        <h2>About</h2>
        <p>
          The QEMU Advent Calendar 2020 features a QEMU disk image each day of
          December until the 24th. Each day a new package becomes available
          for download.
        </p>
        <p>
          Every download contains a little 'run' shell script that starts the
          QEMU emulator with the recommended parameters for the disk image.
          Disk images are either contained directly in the download or are
          downloaded by the 'run' script (you need to have installed 'curl' or
          'wget' in that case).
        </p>
        <p>
          The disk images contain interesting operating systems and software
          that run under the QEMU emulator. Some of them are well-known or
          not-so-well-known operating systems, old and new, others are custom
          demos and neat algorithms.
        </p>
        <p>
          The 'run' scripts (and disk images if included in the download)
          were created by volunteers from the QEMU community to showcase cool
          software that QEMU can run.
        </p>
      </div>

      

      <hr>

      

    </div><!-- /.container -->


    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    
    
  

</div>]]>
            </description>
            <link>https://www.qemu-advent-calendar.org/2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25262608</guid>
            <pubDate>Tue, 01 Dec 2020 05:23:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why do I care the open web is dying?]]>
            </title>
            <description>
<![CDATA[
Score 239 | Comments 167 (<a href="https://news.ycombinator.com/item?id=25261132">thread link</a>) | @archajain
<br/>
November 30, 2020 | https://insightbrowser.com/blog/open-web-dying-why-care | <a href="https://web.archive.org/web/*/https://insightbrowser.com/blog/open-web-dying-why-care">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><div><div><p><em>Part 1: How your user experience changes for the worse as the open web gives way to walled gardens</em></p><p>I hang out in two circles. Open web enthusiasts that are lamenting its demise, and regular users who are happy with their fast snappy apps and couldn't care less. </p><p>These groups have a hard time talking because the "open web" too often comes across as an idealistic abstract notion and most end users just don't tangibly feel the bad consequences. In fact, they're often happier with the snappy, vertically integrated experience of closed app ecosystems. </p><p>My goal here is to make it more palpable how everyday apps, searches and tools get worse when we let big centralized companies take over the web, and explore some paths for reversing it.</p><h2>What is the open web?</h2><p>Most definitions of the "open web" I've seen are either too technical to be accessible or too abstract to be usable and getting gridlocked in this debate often means watching from the sidelines while actual user welfare slowly diminishes.</p><p>Three characteristics that proponents of the open web will agree to in roughly descending order are:</p><ul><li><strong>Ease of publishing</strong>: anyone can publish to it freely or at least very cheaply, and is on the same footing with a globally accessible URL</li><li><strong>Ease of consuming</strong>: Net neutrality â€” ISP's dont cut deals with corporations to make some websites load faster or cheaper than others.</li><li><strong>Ease of remixing</strong>. You can see the source code. Content licenses and tools are permissive for derived works.</li></ul><h2>Detour: A framework to break down how people use the web</h2><p>I want to focus on the user experience point of view. To do this, I'm going to introduce a framework that divides up all our internet usage into two categories.</p><p><img src="https://landen.imgix.net/blog_uSsTzKptQlxlvUvQ/assets/xscGdbWOOPkGjdER.png" alt="Frame 1.png"></p><h3><strong>Unfamiliar problems</strong></h3><p>You have an unfamiliar problem and to solve it you either need to learn something new, or purchase goods or services to solve it</p><ul><li>e.g. taking out a mortgage, a health problem in the family, where to go to college, what skill to acquire next.</li><li>Unfamiliar problems are solved in large part with acquiring new knowledge, not just products or services.</li><li>These user journeys start with search engines â€” Google predominantly and **a lot of the time solving them is spent on web pages**.</li><li>When people are looking to solve unfamiliar problems, **revenue is typically higher-margin**, because users can't price the products and services as well.</li><li>These ultimately transition to being familiar problems.</li></ul><h3><strong>Familiar problems</strong></h3><ul><li>e.g. being entertained, keeping the dog food in stock,</li><li>These are best solved with apps like Email, Netflix, Twitter, DTC subscription boxes, etc.</li><li>Solving these needs has a very well defined user interaction journey. You open the app you're familiar with and follow its standard flow.</li><li>Revenue from people solving familiar problems is typically lower-margin and there's more competing products.
</li></ul><h3>How we're spending our time on familiar vs. unfamiliar problems</h3><p>Using time spent in apps vs mobile web on mobile is a way to proxy how we divide up our time.<strong> We spend most of our time on familiar problems but have a constant trickle of unfamiliar problems</strong>.</p><p><img src="https://landen.imgix.net/blog_uSsTzKptQlxlvUvQ/assets/cPuXkKFELALeIAkI.png" alt="Untitled (1).png"></p><h2>Unfamiliar problems are better solved with the open web</h2><p>Think about the last time you did some research, e.g. choosing a phone plan. You asked your friends, compared on forums, looked at the official sites, scribbled some notes and made a decision. Even if this journey was quick, you likely traversed a dozen services and products to do this.</p><p>Unfamiliar problems have less constraints, require creativity to solve, and thus are better suited to open solutions. Some other things that work for the open web here</p><ul><li>comparing alternatives is easier.</li><li>changing modalities (e.g. from reading to video) is easier.</li></ul><h2>Familiar problems stand to benefit more from tight vertical integration</h2><p>Take Spotify for example. It solves the very familiar problem of listening to music. Spotify just works better as an app because</p><ul><li>Controlling the user experience end to end makes for smoother flows.</li><li>Having all the user data kept with Spotify allows for better recommendation algorithms.</li><li>Spotify can easily hand off between devices.</li><li>It can run in the background</li></ul><p>Sure, the web can do a bunch of these things, but they're simply not first-class considerations in the open-read-close workflow that the browser was designed for.</p><h2>But the open web can be better for familiar problems too, especially for breaking monopolies</h2><p>Let's look at Amazon. Initially you start buying there because of their "always low prices" and the convenience of 2 day shipping. Over the years you keep shopping there, until you've forgotten that </p><ol><li>free 2 day shipping is now near universal</li><li>amazon isn't often the cheapest place</li></ol><p>On the Amazon app, you see the story around the product that best serves Amazon, not the buyer. Meanwhile, over on Insight you can use the web version and do all these things the app can't.</p><p><img src="https://landen.imgix.net/blog_uSsTzKptQlxlvUvQ/assets/ZEblynrLvBsutnlQ.png" alt="Screen Shot 2020-11-17 at 5.42.21 PM.png"></p><p>... and not just that

</p><p><img src="https://landen.imgix.net/blog_uSsTzKptQlxlvUvQ/assets/JVZoTRazmYPZXBQQ.png" alt="Screen Shot 2020-11-17 at 5.59.22 PM.png"></p><h2><strong>How solving unfamiliar problems gets harder too</strong></h2><p>Unfamiliar problems are solved in large part with acquiring new knowledge, not just products or services. The incentives to freely create knowledge that solves unfamiliar problems is lost as the web closes down.</p><ul><li>Google increasingly takes a larger percent of ad revenue as they <a href="https://sparktoro.com/blog/less-than-half-of-google-searches-now-result-in-a-click/">start extracting answers from pages and showing them on their search result pages.</a><a href="https://sparktoro.com/blog/less-than-half-of-google-searches-now-result-in-a-click/"></a></li><li><a href="https://sparktoro.com/blog/less-than-half-of-google-searches-now-result-in-a-click/"></a>Publishers have to either a) paywall their content (e.g. NYTimes) or b) subtly sell products (everyone standing a Wirecutter alternative), or c) ask for donations in order to survive.</li><li>Only a few big name publishers survive. Google and Facebook start sending them more of the traffic that's left, and since domain rank plays a big part in Google's ranking, those that survived assimilate more power and rank better.</li><li>and search engines seem more littered with SEO junk and less actually useful information year over year.</li></ul><h2>In conclusion, and where we fit in.</h2><p>And that's how your user experience slowly degrades, and that's why we stand to suffer as users if we give up the ability to remix software that the web brought us and closed apps are now taking away. </p><p>Our goal with Insight is to give the web (in particular on mobile) a fighting chance by exhibiting how it can be more powerful than a closed ecosystem and give more control to the end-user. We do this by showcasing the web's infinite extensibility and customizability for common use cases like <a href="http://insightbrowser.com/collections/search">search</a>, <a href="https://insightbrowser.com/collections/shopping">shopping</a>, <a href="https://insightbrowser.com/collections/reading">reading</a> and <a href="https://insightbrowser.com/collections/cooking">cooking</a>.</p><p>Insight's advanced features will soon only be available to Pro subscription users but for a limited time we're opening up <strong>lifetime free beta access if you download it via TestFlight below.</strong></p><h3>Coming up in part 2</h3><ul><li>What parts of the open web probably should die off?</li><li>A pragmatic path for what's left of the open web to thrive again.</li></ul><p>We'd love to hear from you, feel free to tweet at or DM us at @<a href="https://twitter.com/insightbrowser">insightbrowser</a>, and my personal Twitter is <a href="https://twitter.com/abhinavsharma">@abhinavsharma</a>.</p></div></div></div></div>]]>
            </description>
            <link>https://insightbrowser.com/blog/open-web-dying-why-care</link>
            <guid isPermaLink="false">hacker-news-small-sites-25261132</guid>
            <pubDate>Tue, 01 Dec 2020 01:16:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[H. G. Wells reviews "Metropolis" (1927)]]>
            </title>
            <description>
<![CDATA[
Score 98 | Comments 50 (<a href="https://news.ycombinator.com/item?id=25258616">thread link</a>) | @pmoriarty
<br/>
November 30, 2020 | https://erkelzaar.tsudao.com/reviews/H.G.Wells_on_Metropolis%201927.htm | <a href="https://web.archive.org/web/*/https://erkelzaar.tsudao.com/reviews/H.G.Wells_on_Metropolis%201927.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <blockquote>
    <blockquote>
      <blockquote>
              <p><i><span color="#00CCFF"> <img src="https://erkelzaar.tsudao.com/reviews/metro200.jpg" width="286" height="208">H.G. 
                Wells wrote a review of the German film "Metropolis" 
                for the </span></i><span color="#00CCFF">New York Times</span><i><span color="#00CCFF"> 
                which was published on April 17, 1927. <p>
                
                Most people find the film (even in its surviving truncated versions) 
                rather brilliant, but Wells didn't like it much, perhaps because 
                he believes it was 'plagiarized' from his "When The Sleeper 
                Wakes."</p></span></i></p>
<p>I have recently seen the silliest film.  </p>
<p>I do not believe it
would be possible to make one sillier.  </p>
<p>And as this film sets out to display the
way the world is going,  </p>
<p>I think [my book] The Way the World is Going may very
well concern itself with this film.  </p>
<p>It is called Metropolis, it comes from the
great Ufa studios in Germany, and the public is given to understand that it has
been produced at enormous cost.  </p>
<p>It gives in one eddying concentration almost
every possible foolishness, clichÃ©, platitude, and muddlement about mechanical
progress and progress in general served up with a sauce of sentimentality that
is all its own.</p>
<p><img src="https://erkelzaar.tsudao.com/reviews/metro163.jpg" width="485" height="745"></p>
<p>It is a
German film and there have been some amazingly good German films, before they
began to cultivate bad work under cover of a protective quota. And this film has
been adapted to the Anglo-Saxon taste, and quite possibly it has suffered in the
process, but even when every allowance has been made for that, there remains
enough to convince the intelligent observer that most of its silliness must be
fundamental.  </p>
<p>Possibly I dislike this soupy whirlpool none the less because I
find decaying fragments of my own juvenile work of thirty years ago, The Sleeper
Awakes, floating about in it. </p>
<p>Capek's Robots have been lifted without apology,
and that soulless mechanical monster of Mary Shelley's, who has fathered so many
German inventions, breeds once more in this confusion.  </p>
<p>Originality there is
none. Independent thought, none.  </p>
<p>Where nobody has imagined for them the authors
have simply fallen back on contemporary things.  </p>
<p>The aeroplanes that wander about above the great city show no 
advance on contemporary types, though all that stuff could have been livened up 
immensely with a few helicopters and vertical or unexpected movements. </p>
<p>The motor cars are 1926 models or earlier. I do not think there 
is a single new idea, a single instance of artistic creation or even intelligent 
anticipation, from first to last in the whole pretentious stew; I may have 
missed some point of novelty, but I doubt it; and this, though it must bore the 
intelligent man in the audience, makes the film all the more convenient as a 
gauge of the circle of ideas, the mentality, from which it has proceeded.</p>
<p>The word Metropolis, says the advertisement in English, 'is
in itself symbolic of greatness'- which only shows us how wise it is to consult
a dictionary before making assertions about the meaning of words.  </p>
<p>Probably it
was the adapter who made that shot. The German 'Neubabelsburg' was better, and
could have been rendered 'New Babel'. It is a city, we are told, of 'about one
hundred years hence.' It is represented as being enormously high; and all the
air and happiness are above and the workers live, as the servile toilers in the
blue uniform in The Sleeper Awakes lived, down, down, down below.</p>
<p>Now far away in the dear old 1897 it may have been excusable
to symbolize social relations in this way, but that was thirty years ago, and a
lot of thinking and some experience intervene.  </p>
<p>That vertical city of the future
we know now is, to put it mildly, highly improbable. Even in New York and
Chicago, where the pressure on the central sites is exceptionally great, it is
only the central office and entertainment region that soars and excavates. And
the same centripetal pressure that leads to the utmost exploitation of site
values at the centre leads also to the driving out of industrialism and labour
from the population center to cheaper areas, and of residential life to more
open and airy surroundings. That was all discussed and written about before
1900. Somewhere about 1930 the geniuses of Ufa studios will come up to a book of
Anticipations which was written more than a quarter of a century ago. The
British census returns of 1901 proved clearly that city populations were
becoming centrifugal, and that every increase in horizontal traffic facilities
produced a further distribution. This vertical social stratification is stale
old stuff. So far from being 'a hundred years hence,' Metropolis, in its forms
and shapes, is already, as a possibility, a third of a century out of date.</p>
<p>But its form is the least part of its staleness. This great
city is supposed to be evoked by a single dominating personality. The English
version calls him John Masterman, so that there may be no mistake about his
quality. Very unwisely he has called his son Eric, instead of sticking to good
hard John, and so relaxed the strain. He works with an inventor, one Rotwang,
and they make machines. There are a certain number of other people, and the
'sons of the rich' are seen disporting themselves, with underclad ladies in a
sort of joy conservatory, rather like the 'winter garden' of an enterprising
1890 hotel during an orgy. The rest of the population is in a state of abject
slavery, working in 'shifts' of ten hours in some mysteriously divided
twenty-four hours, and with no money to spend or property or freedom. The
machines make wealth. How, is not stated. We are shown rows of motor cars all
exactly alike; but the workers cannot own these, and no 'sons of the rich'
would. Even the middle classes nowadays want a car with personality. Probably
Masterman makes these cars in endless series to amuse himself.</p>
              <p><span face="Times New Roman"><img src="https://erkelzaar.tsudao.com/reviews/metro50.jpg" width="254" height="430"></span>One 
                is asked to believe that these machines are engaged quite furiously 
                in the mass production of nothing that is ever used, and that 
                Masterman grows richer and richer in the process. This is the 
                essential nonsense of it all. Unless the mass of the population 
                has the spending power there is no possibility of wealth in a 
                mechanical civilization. A vast, penniless slave population may 
                be necessary for wealth where there are no mass production machines, 
                but it is preposterous with mass production machines. You find 
                such a real proletariat in China still; it existed in the great 
                cities of the ancient world; but you do not find it in America, 
                which has gone furtherest in the direction of mechanical industry, 
                and there is no grain of reason in supposing it will exist in 
                the future. Masterman's watchword is 'Efficiency,' and you are 
                given to understand it is a very dreadful word, and the contrivers 
                of this idiotic spectacle are so hopelessly ignorant of all the 
                work that has been done upon industrial efficiency that they represent 
                him as working his machine-minders to the point of exhaustion, 
                so that they faint and machines explode and people are scalded 
                to death. You get machine-minders in torment turning levers in 
                response to signals - work that could be done far more effectively 
                by automata. Much stress is laid on the fact that the workers 
                are spiritless, hopeless drudges, working reluctantly and mechanically. 
                But a mechanical civilization has no use for mere drudges; the 
                more efficient its machinery the less need there is for the quasi-mechanical 
                minder. It is the inefficient factory that needs slaves; the ill-organized 
                mine that kills men. The hopeless drudge stage of human labour 
                lies behind us. With a sort of malignant stupidity this film contradicts 
                these facts.</p>
<p>The current tendency of economic life is to oust the mere
drudge altogether, to replace much highly skilled manual work by exquisite
machinery in skilled hands, and to increase the relative proportion of
semi-skilled, moderately versatile and fairly comfortable workers. It may indeed
create temporary masses of unemployed, and in The Sleeper Awakes there was a
mass of unemployed people under the hatches. That was written in 1897, when the
possibility of restraining the growth of large masses of population had scarcely
dawned on the world. It was reasonable then to anticipate an embarrassing
underworld of under-productive people. We did not know what to do with the
abyss. But there is no excuse for that today. And what this film anticipates is
not unemployment, but drudge employment, which is precisely what is passing
away. Its fabricators have not even realized that the machine ousts the drudge.</p>
<p>'Efficiency' means large-scale productions, machinery as
fully developed as possible, and <i>high</i> <i>wages</i>. The British
Government delegation sent to study success in America has reported unanimously
to that effect. The increasingly efficient industrialism of America has so
little need of drudges that it has set up the severest barriers against the
flooding of the United States by drudge immigration. 'Ufa' knows nothing of such
facts.</p>
<p>A young woman appears from nowhere in particular to 'help'
these drudges; she impinges upon Masterman's son Eric, and they go to the
'Catacombs,' which, in spite of the gas mains, steam mains, cables, and
drainage, have somehow contrived to get over from Rome, skeletons and all, and
burrow under this city of Metropolis. She conducts a sort of Christian worship
in these unaccountable caverns, and the drudges love and trust her. With a nice
sense of fitness she lights herself about the Catacombs with a torch instead of
the electric lamps that are now so common.</p>
<p>That reversion to torches is quite typical â€¦</p></blockquote></blockquote></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://erkelzaar.tsudao.com/reviews/H.G.Wells_on_Metropolis%201927.htm">https://erkelzaar.tsudao.com/reviews/H.G.Wells_on_Metropolis%201927.htm</a></em></p>]]>
            </description>
            <link>https://erkelzaar.tsudao.com/reviews/H.G.Wells_on_Metropolis%201927.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-25258616</guid>
            <pubDate>Mon, 30 Nov 2020 20:34:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Running a full desktop environment on a Kindle (2019)]]>
            </title>
            <description>
<![CDATA[
Score 173 | Comments 49 (<a href="https://news.ycombinator.com/item?id=25257772">thread link</a>) | @slondr
<br/>
November 30, 2020 | https://nns.ee/blog/2019/04/14/chroot-shenanigans-2.html | <a href="https://web.archive.org/web/*/https://nns.ee/blog/2019/04/14/chroot-shenanigans-2.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p><a href="https://nns.ee/blog/2019/03/21/chroot-shenanigans.html">In my previous post</a>, I described running Arch on an OpenWRT router. Today, Iâ€™ll be taking it a step further and running Arch and a full LXDE installation natively on an Amazon Kindle, which can be interacted with directly using the touch screen. This is possible thanks to the Kindleâ€™s operating system being Linux!
<!--description--></p>

<p>You can see the end result in action <a href="https://youtu.be/Bx386xpDqCY">here</a>. Apologies for the shaky video - it was shot using my phone and no tripod.</p>

<p>If youâ€™re wanting to follow along, make sure youâ€™ve <a href="https://wiki.mobileread.com/wiki/5_x_Jailbreak">rooted your Kindle</a> beforehand. This is essential â€“ without it, itâ€™s impossible to run custom scripts or binaries.</p>

<p>Iâ€™m testing this on an 8th generation Kindle (KT3) â€“ it should, however, work for all recent Kindles given youâ€™ve enough storage and are rooted. You also need to set up <a href="https://www.mobileread.com/forums/showthread.php?t=225030">USBnetwork</a> for SSH access and optionally <a href="https://www.mobileread.com/forums/showthread.php?t=203326">KUAL</a> if you want a simple way of launching the chroot.</p>

<p>First things first: We need to set up a filesystem and extract an Arch installation into it, which we can later chroot into. The filesystem will be a file which will be mounted as a loop device. The reason why weâ€™re not extracting the Arch installation directly into a directory on the Kindle is because the Kindleâ€™s storage filesystem is FAT32. FAT32 doesnâ€™t support required features such as symbolic links, which would break the Arch installation. Please note that this also means that your chroot filesystem can be 4 gigabytes large, at maximum. This can be worked around by mounting the real root inside the chroot filesystem, which itâ€™s still a hacky way to go about it. But I digress.</p>

<p>First, figure out how large your filesystem actually can be. SSH into your Kindle and see how much free space you have:</p>
<div><div><pre><code><span>$</span><span> </span>ssh root@192.168.15.244
<span>
</span><span>kindle#</span><span> </span><span>df</span> <span>-k</span> /mnt/base-us
<span>Filesystem   1K-blocks  Used    Available  Use%  Mounted on
/dev/loop/0  3188640    361856  2826784    11%   /mnt/base-us
</span></code></pre></div></div>

<p>Seems like we have around 2800000K (around 2.8G) of space available. Letâ€™s make our filesystem 2.6G â€“ itâ€™s enough to host our root filesystem and some extra applications, such as LXDE. Note that Iâ€™ll be running the following commands on my PC and transferring the filesystem over later. You can also do all of this on the Kindle, but itâ€™s simply easier and faster this way.</p>

<p>Letâ€™s create a blank file of the wanted size. Iâ€™m using <code>dd</code>, but you can also use <code>fallocate</code> for this:</p>
<div><div><pre><code><span>$</span><span> </span><span>dd </span><span>if</span><span>=</span>/dev/zero <span>of</span><span>=</span>arch.img <span>bs</span><span>=</span>1024 <span>count</span><span>=</span>2600000
<span>2600000+0 records in
2600000+0 records out
2662400000 bytes (2.7 GB, 2.5 GiB) copied, 6.92058 s, 385 MB/s
</span></code></pre></div></div>

<p>Letâ€™s create our filesystem on it. Since weâ€™re doing this on the PC, we need make it 32bit and disable the <code>metadata_csum</code> and <code>huge_file</code> options on the filesystem, as the Kindleâ€™s ext4 kernel doesnâ€™t support them.</p>
<div><div><pre><code><span>$</span><span> </span>mkfs.ext4 <span>-O</span> ^64bit,^metadata_csum,^huge_file arch.img
<span>mke2fs 1.45.0 (6-Mar-2019)
Discarding device blocks: done                            
Creating filesystem with 650000 4k blocks and 162560 inodes
Filesystem UUID: a4e72620-368a-44b4-81bb-9e66b2903523
Superblock backups stored on blocks: 
	32768, 98304, 163840, 229376, 294912

Allocating group tables: done                            
Writing inode tables: done                            
Creating journal (16384 blocks): done
Writing superblocks and filesystem accounting information: done 
</span></code></pre></div></div>

<p>This is optional, but Iâ€™ll also disable periodic filesystem checks on it:</p>
<div><div><pre><code><span>$</span><span> </span>tune2fs <span>-c</span> 0 <span>-i</span> 0 arch.img                               
<span>tune2fs 1.45.0 (6-Mar-2019)         
Setting maximal mount count to -1
Setting interval between checks to 0 seconds
</span></code></pre></div></div>

<p>Next itâ€™s time to mount the filesystem:</p>
<div><div><pre><code><span>$</span><span> </span><span>mkdir </span>rootfs
<span>$</span><span> </span><span>sudo </span>mount <span>-o</span> loop arch.img rootfs/
</code></pre></div></div>

<p>The Kindle Iâ€™m using has a Cortex-A9-based processor, so letâ€™s download the ARMv7 version of Arch Linux ARM from <a href="http://os.archlinuxarm.org/os/ArchLinuxARM-armv7-latest.tar.gz">here</a>. You can download it and extract then, or simply download and extract at the same time:</p>
<div><div><pre><code><span>$</span><span> </span>curl <span>-L</span> http://os.archlinuxarm.org/os/ArchLinuxARM-armv7-latest.tar.gz | <span>sudo tar </span>xz <span>-C</span> rootfs/
</code></pre></div></div>

<p><code>sudo</code> is required to extract as it sets up a lot of files with root permissions. You can ignore the errors about <code>SCHILY.fflags</code>. Verify that the files extracted successfully with <code>ls -l rootfs/</code>.</p>

<p>Letâ€™s prepare our Kindle for the filesystem. I opted for hosting the filesystem in <code>extensions/karch</code> as I want to use KUAL for easy launching:</p>
<div><div><pre><code><span>$</span><span> </span>ssh root@192.168.15.244
<span>
</span><span>kindle#</span><span> </span><span>mkdir</span> <span>-p</span> /mnt/base-us/extensions/karch
</code></pre></div></div>

<p>While weâ€™re here, itâ€™s also a good idea to stop the power daemon to prevent the Kindle from going into sleep mode while transferring the filesystem and interrupting our transfer:</p>
<div><div><pre><code><span>kindle#</span><span> </span>stop powerd
<span>powerd stop/waiting
</span></code></pre></div></div>

<p>Letâ€™s transfer our filesystem:</p>
<div><div><pre><code><span>kindle#</span><span> </span><span>exit</span>
<span>Connection to 192.168.15.244 closed.

</span><span>$</span><span> </span>scp arch.img root@192.168.15.244:/mnt/base-us/extensions/karch/
</code></pre></div></div>

<p>This might take quite a bit of time, depending on your connection.</p>

<p>Once itâ€™s done, letâ€™s SSH in once again and set up our mountpoint:</p>
<div><div><pre><code><span>$</span><span> </span>ssh root@192.168.15.244
<span>
</span><span>kindle#</span><span> </span><span>cd</span> /mnt/base-us/extensions/karch/
<span>kindle#</span><span> </span><span>mkdir </span>system
</code></pre></div></div>

<p>I decided to set up my own loop device, so I can have it named, but you can ignore this and opt to use <code>/dev/loop/12</code> or similar instead. Just make sure itâ€™s already not in use with <code>mount</code>.</p>

<p>Setting up a loop point and mounting the filesystem:</p>
<div><div><pre><code><span>kindle#</span><span> </span><span>mknod</span> <span>-m0660</span> /dev/loop/karch b 7 250
<span>kindle#</span><span> </span>mount <span>-o</span> <span>loop</span><span>=</span>/dev/loop/karch <span>-t</span> ext4 arch.img system/
</code></pre></div></div>

<p>We should also mount some system directories into it:</p>
<div><div><pre><code><span>kindle#</span><span> </span>mount <span>-o</span> <span>bind</span> /dev system/dev
<span>kindle#</span><span> </span>mount <span>-o</span> <span>bind</span> /dev/pts system/dev/pts
<span>kindle#</span><span> </span>mount <span>-o</span> <span>bind</span> /proc system/proc
<span>kindle#</span><span> </span>mount <span>-o</span> <span>bind</span> /sys system/sys
<span>kindle#</span><span> </span>mount <span>-o</span> <span>bind</span> /tmp system/tmp
<span>kindle#</span><span> </span><span>cp</span> /etc/hosts system/etc/
</code></pre></div></div>

<p>Itâ€™s time to chroot into our new system and set it up for LXDE. You can also use this opportunity to set up whatever applications you need, such as an onscreen keyboard:</p>
<div><div><pre><code><span>kindle#</span><span> </span><span>chroot </span>system/ /bin/bash
<span>chroot#</span><span> </span><span>echo</span> <span>'en_US.UTF-8 UTF-8'</span> <span>&gt;</span> /etc/locale.gen 
<span>chroot#</span><span> </span>locale-gen
<span>chroot#</span><span> </span><span>rm</span> /etc/resolv.conf 
<span>chroot#</span><span> </span><span>echo</span> <span>'nameserver 8.8.8.8'</span> <span>&gt;</span> /etc/resolv.conf
<span>chroot#</span><span> </span>pacman-key <span>--init</span> <span># this will take a while</span>
<span>chroot#</span><span> </span>pacman-key <span>--populate</span>
<span>chroot#</span><span> </span>pacman <span>-Syu</span> <span>--noconfirm</span>
<span>chroot#</span><span> </span>pacman <span>-S</span> lxde xorg-server-xephyr <span>--noconfirm</span>
</code></pre></div></div>

<p>We use Xephyr because itâ€™s the easiest way to get our LXDE session up and running. Since the Kindle uses X11 natively, we can try using that. Itâ€™s possible to stop the native window manager using <code>stop lab126_gui</code> outside the chroot, but then the Kindle will stop updating the screen with new data, leaving it blank â€“ forcing you to use something like <code>eips</code> to refresh the screen. The X server still works, however, and you can confirm this by using something like <code>x11vnc</code> after running your own WM in it. Xephyr spawns a new X server inside the preexisting X server, which is not as efficient but a lot easier.</p>

<p>We can however stop everything else related to the native GUI, as we need the extra memory and we canâ€™t use it while LXDE is running anyways:</p>
<div><div><pre><code><span>chroot#</span><span> </span><span>exit</span>
<span>kindle#</span><span> </span><span>SERVICES</span><span>=</span><span>"framework pillow webreader kb contentpackd"</span>
<span>kindle#</span><span> </span><span>for </span>service <span>in</span> <span>${</span><span>SERVICES</span><span>}</span><span>;</span> <span>do </span>stop <span>${</span><span>service</span><span>}</span><span>;</span> <span>done</span>
</code></pre></div></div>

<p>While weâ€™re here, we need to get the screen size for later:</p>
<div><div><pre><code><span>kindle#</span><span> </span>eips <span>-i</span> | <span>grep</span> <span>'xres:'</span> | <span>awk</span> <span>'{print $2"x"$4}'</span>
<span>600x800
</span></code></pre></div></div>

<p>Letâ€™s chroot back into the system and see if we can get LXDE to run. Be sure to replace the screen size parameter if needed:</p>
<div><div><pre><code><span>kindle#</span><span> </span><span>chroot </span>system/ /bin/bash
<span>chroot#</span><span> </span><span>export </span><span>DISPLAY</span><span>=</span>:0
<span>chroot#</span><span> </span>Xephyr :1 <span>-title</span> <span>"L:A_N:application_ID:xephyr"</span> <span>-screen</span> 600x800 <span>-cc</span> 4 <span>-nocursor</span> &amp;
<span>chroot#</span><span> </span><span>export </span><span>DISPLAY</span><span>=</span>:1
<span>chroot#</span><span> </span>lxsession &amp;
<span>chroot#</span><span> </span>xrandr <span>-o</span> right
</code></pre></div></div>

<p>If everything goes well, you should have LXDE visible on your Kindleâ€™s screen. Ta-da! Feel free to play around with it. Iâ€™ve found that the touch screen is suprisingly accurate, even though it is using an IR LED system to detect touches instead of a normal digitizer.</p>

<p>Once done in the chroot, Ctrl-C + Ctrl-D can be issued to exit the chroot. We can then restore the Kindle UI by doing:</p>
<div><div><pre><code><span>kindle#</span><span> </span><span>for </span>service <span>in</span> <span>${</span><span>SERVICES</span><span>}</span><span>;</span> <span>do </span>start <span>${</span><span>service</span><span>}</span><span>;</span> <span>done</span>
</code></pre></div></div>

<p>It might take a while for anything to display again.</p>

<p>Iâ€™ve mentioned setting up a KUAL extension to automate the entering and exiting of the chroot. You can find that <a href="https://github.com/neonsea/karch">here</a>. If youâ€™re interested in using this, make sure youâ€™ve set up your filesystem first and copied it over to the same directory as the extension, and that itâ€™s named <code>arch.img</code>. Everything else is not mandatory - the extension will do it for you.</p>

  </div></div>]]>
            </description>
            <link>https://nns.ee/blog/2019/04/14/chroot-shenanigans-2.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25257772</guid>
            <pubDate>Mon, 30 Nov 2020 19:25:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[M1 Mac mini overtakes entire Japanese desktop market in less than 2 weeks]]>
            </title>
            <description>
<![CDATA[
Score 86 | Comments 63 (<a href="https://news.ycombinator.com/item?id=25257488">thread link</a>) | @gumby
<br/>
November 30, 2020 | https://appleterm.com/2020/11/30/m1-mac-mini-desktop-market-share-japan/ | <a href="https://web.archive.org/web/*/https://appleterm.com/2020/11/30/m1-mac-mini-desktop-market-share-japan/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" itemscope="itemscope" itemtype="https://schema.org/CreativeWork">
<div data-sidebar="right" data-v-spacing="top:bottom" data-structure="default:boxed">
<section>
<article id="post-20363">
<section data-type="type-1">

</section>
<div> <figure><img onload="Wpfcll.r(this,true);" src="https://appleterm.com/wp-content/plugins/wp-fastest-cache-premium/pro/images/blank.gif" loading="lazy" width="1024" height="576" data-wpfc-original-src="https://appleterm.com/wp-content/uploads/2020/11/m1-mac-mini-market-in-japan-overtake-rect-1-1024x576.jpg" alt="m1 mac mini market in japan overtake rect 1" data-wpfc-original-srcset="https://appleterm.com/wp-content/uploads/2020/11/m1-mac-mini-market-in-japan-overtake-rect-1-1024x576.jpg 1024w, https://appleterm.com/wp-content/uploads/2020/11/m1-mac-mini-market-in-japan-overtake-rect-1-300x169.jpg 300w, https://appleterm.com/wp-content/uploads/2020/11/m1-mac-mini-market-in-japan-overtake-rect-1-768x432.jpg 768w, https://appleterm.com/wp-content/uploads/2020/11/m1-mac-mini-market-in-japan-overtake-rect-1.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px" title="M1 Mac mini overtakes entire Japanese desktop market in less than 2 weeks 1"></figure> <p>In just under 2 weeks since launch, the <a href="https://appleterm.com/2020/11/10/apple-announces-refreshed-mac-mini-at-one-more-thing-event/">M1 powered Mac mini</a> has catapulted <a href="https://apple.com/" target="_blank" rel="noopener">Apple</a> to the top rank in the desktop market in Japan by a whopping 14.4%, according to market data by <em><a href="https://www.bcnretail.com/research/detail/20201129_201698.html" target="_blank" rel="noopener">BCN Retail</a>.</em></p> <p><a href="https://www.bcnretail.com/research/detail/20201129_201698.html" target="_blank" rel="noopener">Data</a> between August and November 3rd, a little more than a week prior to the launch of the <a href="https://www.bcnretail.com/research/detail/20201129_201698.html" target="_blank" rel="noopener">M1 Mac mini</a> shows <a href="https://apple.com/" target="_blank" rel="noopener">Apple</a> at around 15% share in the desktop market, behind Lenovo Japan. However, following the launch of the new <a href="https://appleterm.com/2020/11/10/apple-announces-refreshed-mac-mini-at-one-more-thing-event/">Mac mini on November 17th</a>, Apple charged forward to a whopping 27.1% market share, a 14.4% increase from just the start of the month.</p> <p>The <a href="https://appleterm.com/2020/11/10/apple-announces-refreshed-mac-mini-at-one-more-thing-event/">new Mac mini</a> is the first desktop computer from Apple with the new <a href="https://apple.com/mac/m1" target="_blank" rel="noopener">Apple Silicon</a>. The new chip has gotten <a href="https://appleterm.com/2020/11/17/apple-silicon-mac-reviews-exceeds-almost-every-expectation/">nothing but praise</a> for its <a href="https://appleterm.com/2020/11/28/m1-intel-tiger-lake/">incredible performance</a> and outstanding battery life on the <a href="https://appleterm.com/2020/11/10/apple-reveals-silicon-based-macbook-air/">MacBook Air</a> and <a href="https://appleterm.com/2020/11/10/apple-announces-new-macbook-pros-at-one-more-thing-event/">MacBook Pro</a>. The <a href="https://appleterm.com/2020/11/10/apple-announces-refreshed-mac-mini-at-one-more-thing-event/">Mac mini</a> is the smallest-form factor desktop that <a href="https://apple.com/" target="_blank" rel="noopener">Apple</a> offers alongside the iMac, iMac Pro, and Mac Pro.</p> <p>Apple will have fully moved its entire lineup to Apple Silicon away from Intel in 2 years <a href="https://appleterm.com/2020/06/22/live-feed-wwdc2020/">according to CEO Tim Cook</a>. That transition is already underway and more devices are expected to join the Apple Silicon family early next year, including a <a href="https://appleterm.com/2020/11/25/kuo-5g-ipad-macbook-apple-watch-redesign/">redesigned 16-inch MacBook Pro</a> and <a href="https://appleterm.com/2020/10/27/arm-based-imac-a14t-chip-in-q1-of-2021/">iMac</a>.</p></div><nav>
<a href="https://appleterm.com/2020/11/30/digitimes-periscope-lens/">
<figure><img onload="Wpfcll.r(this,true);" src="https://appleterm.com/wp-content/plugins/wp-fastest-cache-premium/pro/images/blank.gif" width="300" height="300" data-wpfc-original-src="https://appleterm.com/wp-content/uploads/2020/11/persicope-lens-for-future-iphone-digitimes-squ-300x300.jpg" alt="blank" loading="lazy" data-wpfc-original-srcset="https://appleterm.com/wp-content/uploads/2020/11/persicope-lens-for-future-iphone-digitimes-squ-300x300.jpg 300w, https://appleterm.com/wp-content/uploads/2020/11/persicope-lens-for-future-iphone-digitimes-squ-1024x1024.jpg 1024w, https://appleterm.com/wp-content/uploads/2020/11/persicope-lens-for-future-iphone-digitimes-squ-150x150.jpg 150w, https://appleterm.com/wp-content/uploads/2020/11/persicope-lens-for-future-iphone-digitimes-squ-768x768.jpg 768w, https://appleterm.com/wp-content/uploads/2020/11/persicope-lens-for-future-iphone-digitimes-squ.jpg 1080w" sizes="(max-width: 300px) 100vw, 300px" data-object-fit="~" itemprop="image"><svg width="20px" height="15px" viewBox="0 0 20 15"><polygon points="0,7.5 5.5,13 6.4,12.1 2.4,8.1 20,8.1 20,6.9 2.4,6.9 6.4,2.9 5.5,2 "></polygon></svg><span></span></figure>
<p><span> Previous <span>Post</span> </span> <span> DigiTimes: Apple looking to use periscope lens for future iPhone model </span></p></a>
<a href="https://appleterm.com/2020/11/30/apple-ditches-initiative-in-france-set-to-ensure-big-tech-companies-pay-fair-taxes/">
<p><span> Next <span>Post</span> </span> <span> Apple ditches initiative in France set to ensure big-tech companies pay fair taxes </span></p><figure><img onload="Wpfcll.r(this,true);" src="https://appleterm.com/wp-content/plugins/wp-fastest-cache-premium/pro/images/blank.gif" width="300" height="300" data-wpfc-original-src="https://appleterm.com/wp-content/uploads/2020/11/apple-program-in-france-ditch-squ-300x300.jpg" alt="blank" loading="lazy" data-wpfc-original-srcset="https://appleterm.com/wp-content/uploads/2020/11/apple-program-in-france-ditch-squ-300x300.jpg 300w, https://appleterm.com/wp-content/uploads/2020/11/apple-program-in-france-ditch-squ-1024x1024.jpg 1024w, https://appleterm.com/wp-content/uploads/2020/11/apple-program-in-france-ditch-squ-150x150.jpg 150w, https://appleterm.com/wp-content/uploads/2020/11/apple-program-in-france-ditch-squ-768x768.jpg 768w, https://appleterm.com/wp-content/uploads/2020/11/apple-program-in-france-ditch-squ.jpg 1080w" sizes="(max-width: 300px) 100vw, 300px" data-object-fit="~" itemprop="image"><svg width="20px" height="15px" viewBox="0 0 20 15"><polygon points="14.5,2 13.6,2.9 17.6,6.9 0,6.9 0,8.1 17.6,8.1 13.6,12.1 14.5,13 20,7.5 "></polygon></svg><span></span></figure> </a>
</nav>
</article>
</section>
</div></div></div>]]>
            </description>
            <link>https://appleterm.com/2020/11/30/m1-mac-mini-desktop-market-share-japan/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25257488</guid>
            <pubDate>Mon, 30 Nov 2020 19:01:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How many registers does an x86-64 CPU have?]]>
            </title>
            <description>
<![CDATA[
Score 112 | Comments 108 (<a href="https://news.ycombinator.com/item?id=25253797">thread link</a>) | @woodruffw
<br/>
November 30, 2020 | https://blog.yossarian.net/2020/11/30/How-many-registers-does-an-x86-64-cpu-have | <a href="https://web.archive.org/web/*/https://blog.yossarian.net/2020/11/30/How-many-registers-does-an-x86-64-cpu-have">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<h2><em>Programming, philosophy, pedaling.</em></h2>

<ul>
    <li><a href="https://blog.yossarian.net/">Home</a></li>
    <li><a href="https://blog.yossarian.net/tags">Tags</a></li>
    <li><a href="https://blog.yossarian.net/favorites">Favorites</a></li>
    <li><a href="https://blog.yossarian.net/archive">Archive</a></li>
    
      <li><a href="https://yossarian.net/">Main Site</a></li>
    
</ul>

<hr>



<h2>
  <em>Nov 30, 2020</em>
</h2>

  <p>Tags:
  
    
    <a href="https://blog.yossarian.net/tags#programming">programming</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#x86">x86</a>
    
  
  </p>


<p>x86 is back in the general programmer discourse, in part thanks to Appleâ€™s M1 and
<a href="https://developer.apple.com/documentation/apple_silicon/about_the_rosetta_translation_environment">Rosetta 2</a>.
As such, I figured Iâ€™d do <em>yet another</em> x86-64 post.</p>

<p>Just like <a href="https://blog.yossarian.net/2020/06/13/How-x86_64-addresses-memory">the last one</a>,
Iâ€™m going to cover a facet of the x86-64 ISA that sets it apart
as unusually complex among modern ISAs: the number and diversity of registers available.</p>

<p><a href="https://stefanheule.com/blog/how-many-x86-64-instructions-are-there-anyway/">Like instruction counting</a>,
register counting on x86-64 is subject to debates over methodology. In particular, for this blog
post, Iâ€™m going to lay the following ground rules:</p>

<ul>
  <li>
    <p>I <strong>will</strong> count sub-registers (e.g., <code>EAX</code> for <code>RAX</code>) as distinct registers. My justification:
they have different instruction encodings, and both Intel and AMD optimize/pessimize
particular sub-register use patterns in their microcode.</p>
  </li>
  <li>
    <p>I <strong>will</strong> count registers that are present on x86-64 CPUs, but that canâ€™t be used in long mode.</p>
  </li>
  <li>
    <p>I <strong>wonâ€™t</strong> count registers that are <em>only</em> present on older x86 CPUs, like the 80386 and
80486 <a href="https://en.wikipedia.org/wiki/Test_register">test registers</a>.</p>
  </li>
  <li>
    <p>I <strong>wonâ€™t</strong> count microarchitectural implementation details, like shadow registers.</p>
  </li>
  <li>
    <p>I <strong>will</strong> count registers that arenâ€™t directly addressable, like MSRs that can only be accessed
through <code>RDMSR</code>. However, I <strong>wonâ€™t</strong> (or will try not to) double-count registers that
have multiple access mechanisms (like <code>RDMSR</code> and <code>RDTSC</code>).</p>
  </li>
  <li>
    <p>I <strong>wonâ€™t</strong> count model-specific registers that fall into these categories:</p>
    <ul>
      <li>MSRs that are only present on niche x86 vendors (Cyrix, Via)</li>
      <li>MSRs that arenâ€™t widely available on recent-ish x86-64 CPUs
        <ul>
          <li><strong>Errata</strong>: I accidentally included AVX-512 in some of the original counts below,
  not realizing that it hadnâ€™t been released on any AMD CPUs. The post has been updated.</li>
        </ul>
      </li>
      <li>MSRs that are <em>completely</em> undocumented (both officially and unofficially)</li>
    </ul>
  </li>
</ul>

<p>In addition to the rules above, Iâ€™m going to use the following considerations and methodology
for grouping registers together:</p>

<ul>
  <li>
    <p>Many sources, both official and unofficial, use â€œmodel-specific registerâ€ as an umbrella term
for any non-core or non-feature-set register supplied by an x86-64 CPU. Whenever possible, Iâ€™ll
try to avoid this in favor of more specific categories.</p>
  </li>
  <li>
    <p>Both Intel and AMD provide synonyms for registers (e.g. <code>CR8</code> as the â€œtask priority register,â€ or
<code>TPR</code>). Whenever possible, Iâ€™ll try to use the more generic/category conforming name (like <code>CR8</code>
in the case above).</p>
  </li>
  <li>
    <p>In general, the individual cores of a multicore processor have independent register states.
Whenever this <strong>isnâ€™t</strong> the case, Iâ€™ll make an effort to document it.</p>
  </li>
</ul>

<hr>

<h2 id="general-purpose-registers">General-purpose registers</h2>

<p>The general-purpose registers (or GPRs) are <strong>the</strong> primary registers in the x86-64 register model.
As their name implies, they are the <strong>only</strong> registers that are <em>general purpose</em>: each has a set
of conventional uses<sup id="fnref:conventional" role="doc-noteref"><a href="#fn:conventional">1</a></sup>, but programmers are generally free to ignore those conventions and use
them as they please<sup id="fnref:ignore" role="doc-noteref"><a href="#fn:ignore">2</a></sup>.</p>

<p>Because x86-64 evolved from a 32-bit ISA which in turn evolved from a 16-bit ISA, each
GPR has a set of <em>subregisters</em> that hold the lower 8, 16 and 32 bits of the full 64-bit
register.</p>

<p>As a table:</p>

<table>
  <tbody><tr>
    
    <th>64-bit</th>
    
    <th>32-bit</th>
    
    <th>16-bit</th>
    
    <th>8-bit (low)</th>
    
  </tr>
  
  <tr>
    
    <td>RAX</td>
    
    <td>EAX</td>
    
    <td>AX</td>
    
    <td>AL</td>
    
  </tr>
  
  <tr>
    
    <td>RBX</td>
    
    <td>EBX</td>
    
    <td>BX</td>
    
    <td>BL</td>
    
  </tr>
  
  <tr>
    
    <td>RCX</td>
    
    <td>ECX</td>
    
    <td>CX</td>
    
    <td>CL</td>
    
  </tr>
  
  <tr>
    
    <td>RDX</td>
    
    <td>EDX</td>
    
    <td>DX</td>
    
    <td>DL</td>
    
  </tr>
  
  <tr>
    
    <td>RSI</td>
    
    <td>ESI</td>
    
    <td>SI</td>
    
    <td>SIL</td>
    
  </tr>
  
  <tr>
    
    <td>RDI</td>
    
    <td>EDI</td>
    
    <td>DI</td>
    
    <td>DIL</td>
    
  </tr>
  
  <tr>
    
    <td>RBP</td>
    
    <td>EBP</td>
    
    <td>BP</td>
    
    <td>BPL</td>
    
  </tr>
  
  <tr>
    
    <td>RSP</td>
    
    <td>ESP</td>
    
    <td>SP</td>
    
    <td>SPL</td>
    
  </tr>
  
  <tr>
    
    <td>R8</td>
    
    <td>R8D</td>
    
    <td>R8W</td>
    
    <td>R8B</td>
    
  </tr>
  
  <tr>
    
    <td>R9</td>
    
    <td>R9D</td>
    
    <td>R9W</td>
    
    <td>R9B</td>
    
  </tr>
  
  <tr>
    
    <td>R10</td>
    
    <td>R10D</td>
    
    <td>R10W</td>
    
    <td>R10B</td>
    
  </tr>
  
  <tr>
    
    <td>R11</td>
    
    <td>R11D</td>
    
    <td>R11W</td>
    
    <td>R11B</td>
    
  </tr>
  
  <tr>
    
    <td>R12</td>
    
    <td>R12D</td>
    
    <td>R12W</td>
    
    <td>R12B</td>
    
  </tr>
  
  <tr>
    
    <td>R13</td>
    
    <td>R13D</td>
    
    <td>R13W</td>
    
    <td>R13B</td>
    
  </tr>
  
  <tr>
    
    <td>R14</td>
    
    <td>R14D</td>
    
    <td>R14W</td>
    
    <td>R14B</td>
    
  </tr>
  
  <tr>
    
    <td>R15</td>
    
    <td>R15D</td>
    
    <td>R15W</td>
    
    <td>R15B</td>
    
  </tr>
  
</tbody></table>

<p>Some of the 16-bit subregisters are also special: the original 8086 allowed the <strong>high</strong> byte
of <code>AX</code>, <code>BX</code>, <code>CX</code>, and <code>DX</code> to be accessed indepenently, so x86-64 preserves this for some
encodings:</p>

<table>
  <tbody><tr>
    
    <th>16-bit</th>
    
    <th>8-bit (high)</th>
    
  </tr>
  
  <tr>
    
    <td>AX</td>
    
    <td> AH</td>
    
  </tr>
  
  <tr>
    
    <td>BX</td>
    
    <td> BH</td>
    
  </tr>
  
  <tr>
    
    <td>CX</td>
    
    <td> CH</td>
    
  </tr>
  
  <tr>
    
    <td>DX</td>
    
    <td> DH</td>
    
  </tr>
  
</tbody></table>

<p>So thatâ€™s 16 full-width GPRs, fanning out to another 52 subregisters.</p>

<p><strong>Registers in this group: 68</strong>.</p>

<p><strong>Running total: 68</strong>.</p>

<h2 id="special-registers">Special registers</h2>

<p>This is sort of an artificial category: like every ISA, x86-64 has a few â€œspecialâ€ registers that
keep things moving along. In particular:</p>

<ul>
  <li>
    <p>The <em>instruction pointer</em>, or <code>RIP</code>.</p>

    <p>x86-64 has 32- and 16-bit variants of <code>RIP</code> (<code>EIP</code> and <code>IP</code>), but Iâ€™m <strong>not</strong> going to count
  them as separate registers: they have identical encodings and canâ€™t be used in the same
  CPU mode<sup id="fnref:ip" role="doc-noteref"><a href="#fn:ip">3</a></sup>.</p>
  </li>
  <li>
    <p>The <em>status register</em>, or <code>RFLAGS</code>.</p>

    <p>Just like <code>RIP</code>, <code>RFLAGS</code> has 32- and 16-bit counterparts (<code>EFLAGS</code> and <code>FLAGS</code>). Unlike
  <code>RIP</code>, these counterparts can be partially mixed: <code>PUSHF</code> and <code>PUSHFQ</code> are both valid in
  long mode, and <code>LAHF</code>/<code>SAHF</code> can operate on the bits of <code>FLAGS</code> on some x86-64 CPUs
  outside of compatiblility mode<sup id="fnref:cpuid-lahf-sahf" role="doc-noteref"><a href="#fn:cpuid-lahf-sahf">4</a></sup>. So Iâ€™m going to go ahead and count them.</p>
  </li>
</ul>

<p><strong>Registers in this group: 4</strong>.</p>

<p><strong>Running total: 72</strong>.</p>

<h2 id="segment-registers">Segment registers</h2>

<p>x86-64 has a total of 6 segment registers: <code>CS</code>, <code>SS</code>, <code>DS</code>, <code>ES</code>, <code>FS</code>, and <code>GS</code>. The operation
varies with the CPUâ€™s mode:</p>

<ul>
  <li>
    <p>In all modes except for long mode, each segment register holds a <em>selector</em>, which indexes into
either the <a href="https://en.wikipedia.org/wiki/Global_Descriptor_Table">GDT</a> or
<a href="https://en.wikipedia.org/wiki/Global_Descriptor_Table#Local_Descriptor_Table">LDT</a>. That yields
a segment <em>descriptor</em> which, among other things, supplies the base address and extent of the
segment.</p>
  </li>
  <li>
    <p>In long mode all but <code>FS</code> and <code>GS</code> are treated as having a base address of zero and a 64-bit
extent, effectively producing a flat address space. <code>FS</code> and <code>GS</code> are retained as special cases,
but no longer use the segment descriptor tables: instead, they access base addresses that
are stored in the <code>FSBASE</code> and <code>GSBASE</code> model-specific registers<sup id="fnref:kernelgsbase" role="doc-noteref"><a href="#fn:kernelgsbase">5</a></sup>.
More on those later.</p>
  </li>
</ul>

<p><strong>Registers in this group: 6</strong>.</p>

<p><strong>Running total: 78</strong>.</p>

<h2 id="simd-and-fp-registers">SIMD and FP registers</h2>

<p>The x86 family has gone through <em>several</em> generations of SIMD and floating-point instruction
groups, each of which has introduced, extended, or re-contextualized various registers:</p>

<ul>
  <li>x87</li>
  <li>MMX</li>
  <li>SSE (SSE2, SSE3, SSE4, SSE4, â€¦)</li>
  <li>AVX (AVX2, AVX512)</li>
</ul>

<p>Letâ€™s do them in rough order.</p>

<h3 id="x87">x87</h3>

<p>Originally a discrete coprocessor with its own instruction set and register file, the x87
instructions have been regularly baked into x86 cores themselves since the 80486.</p>

<p>Because of its coprocessor history, x87 defines both normal registers<sup id="fnref:normal-ish" role="doc-noteref"><a href="#fn:normal-ish">6</a></sup>
(akin to GPRs) and a variety of special registers needed to control the FPU state:</p>

<ul>
  <li><code>ST0</code> through <code>ST7</code>: 8 80-bit floating-point registers</li>
  <li><code>FPSW</code>, <code>FPCW</code>, <code>FPTW</code> <sup id="fnref:mynames" role="doc-noteref"><a href="#fn:mynames">7</a></sup>: Control, status, and tag-word registers</li>
  <li>â€œData operand pointerâ€: I donâ€™t know what this one does, but the Intel SDM specifies it<sup id="fnref:sdm" role="doc-noteref"><a href="#fn:sdm">8</a></sup></li>
  <li>Instruction pointer: the x87 state machine apparently holds its own copy of the current
x87 instruction</li>
  <li>Last instruction opcode: this is apparently distinct from the x87 opcode, and has its
own register</li>
</ul>

<p><strong>Registers in this group: 14</strong>.</p>

<p><strong>Running total: 92</strong>.</p>

<h3 id="mmx">MMX</h3>

<p>MMX was Intelâ€™s first attempt at consumer SIMD in their x86 chips, released back in 1997.</p>

<p>For design reasons that are a complete mystery to me, the MMX registers are actually sub-registers
of the x87 <code>STn</code> registers: each 64-bit <code>MMn</code> occupies the mantissa component of its corresponding
<code>STn</code>. Consequently, x86 (and x86-64) CPUs cannot execute MMX and x87 instructions at the same time.</p>

<p>In addition to <code>MM0</code> through <code>MM7</code>, MMX also defines a new status register (<code>MXCSR</code>) as well as
a load/store instruction pair for manipulating it (<code>LDMXCSR</code> and <code>STMXCSR</code>).</p>

<p><strong>Registers in this group: 9</strong>.</p>

<p><strong>Running total: 101</strong>.</p>

<h3 id="sse-and-avx">SSE and AVX</h3>

<p>For simplicityâ€™s sake, Iâ€™m going to wrap SSE and AVX into a single section: they use the same
sub-register pattern as the GPRs and x87/MMX do, so they fit well into a single table:</p>

<table>
  <tbody><tr>
    
    <th>AVX-512 (512-bit)</th>
    
    <th>AVX-2 (256-bit)</th>
    
    <th>SSE (128-bit)</th>
    
  </tr>
  
  <tr>
    
    <td>ZMM0</td>
    
    <td>YMM0</td>
    
    <td>XMM0</td>
    
  </tr>
  
  <tr>
    
    <td>ZMM1</td>
    
    <td>YMM1</td>
    
    <td>XMM1</td>
    
  </tr>
  
  <tr>
    
    <td>ZMM2</td>
    
    <td>YMM2</td>
    
    <td>XMM2</td>
    
  </tr>
  
  <tr>
    
    <td>ZMM3</td>
    
    <td>YMM3</td>
    
    <td>XMM3</td>
    
  </tr>
  
  <tr>
    
    <td>ZMM4</td>
    
    <td>YMM4</td>
    
    <td>XMM4</td>
    
  </tr>
  
  <tr>
    
    <td>ZMM5</td>
    
    <td>YMM5</td>
    
    <td>XMM5</td>
    
  </tr>
  
  <tr>
    
    <td>ZMM6</td>
    
    <td>YMM6</td>
    
    <td>XMM6</td>
    
  </tr>
  
  <tr>
    
    <td>ZMM7</td>
    
    <td>YMM7</td>
    
    <td>XMM7</td>
    
  </tr>
  
  <tr>
    
    <td>ZMM8</td>
    
    <td>YMM8</td>
    
    <td>XMM8</td>
    
  </tr>
  
  <tr>
    
    <td>ZMM9</td>
    
    <td>YMM9</td>
    
    <td>XMM9</td>
    
  </tr>
  
  <tr>
    
    <td>ZMM10</td>
    
    <td>YMM10</td>
    
    <td>XMM10</td>
    
  </tr>
  
  <tr>
    
    <td>ZMM11</td>
    
    <td>YMM11</td>
    
    <td>XMM11</td>
    
  </tr>
  
  <tr>
    
    <td>ZMM12</td>
    
    <td>YMM12</td>
    
    <td>XMM12</td>
    
  </tr>
  
  <tr>
    
    <td>ZMM13</td>
    
    <td>YMM13</td>
    
    <td>XMM13</td>
    
  </tr>
  
  <tr>
    
    <td>ZMM14</td>
    
    <td>YMM14</td>
    
    <td>XMM14</td>
    
  </tr>
  
  <tr>
    
    <td>ZMM15</td>
    
    <td>YMM15</td>
    
    <td>XMM15</td>
    
  </tr>
  
  <tr>
    
    <td>ZMM16</td>
    
    <td>YMM16</td>
    
    <td>XMM16</td>
    
  </tr>
  
  <tr>
    
    <td>ZMM17</td>
    
    <td>YMM17</td>
    
    <td>XMM17</td>
    
  </tr>
  
  <tr>
    
    <td>ZMM18</td>
    
    <td>YMM18</td>
    
    <td>XMM18</td>
    
  </tr>
  
  <tr>
    
    <td>ZMM19</td>
    
    <td>YMM19</td>
    
    <td>XMM19</td>
    
  </tr>
  
  <tr>
    
    <td>ZMM20</td>
    
    <td>YMM20</td>
    
    <td>XMM20</td>
    
  </tr>
  
  <tr>
    
    <td>ZMM21</td>
    
    <td>YMM21</td>
    
    <td>XMM21</td>
    
  </tr>
  
  <tr>
    
    <td>ZMM22</td>
    
    <td>YMM22</td>
    
    <td>XMM22</td>
    
  </tr>
  
  <tr>
    
    <td>ZMM23</td>
    
    <td>YMM23</td>
    
    <td>XMM23</td>
    
  </tr>
  
  <tr>
    
    <td>ZMM24</td>
    
    <td>YMM24</td>
    
    <td>XMM24</td>
    
  </tr>
  
  <tr>
    
    <td>ZMM25</td>
    
    <td>YMM25</td>
    
    <td>XMM25</td>
    
  </tr>
  
  <tr>
    
    <td>ZMM26</td>
    
    <td>YMM26</td>
    
    <td>XMM26</td>
    
  </tr>
  
  <tr>
    
    <td>ZMM27</td>
    
    <td>YMM27</td>
    
    <td>XMM27</td>
    
  </tr>
  
  <tr>
    
    <td>ZMM28</td>
    
    <td>YMM28</td>
    
    <td>XMM28</td>
    
  </tr>
  
  <tr>
    
    <td>ZMM29</td>
    
    <td>YMM29</td>
    
    <td>XMM29</td>
    
  </tr>
  
  <tr>
    
    <td>ZMM30</td>
    
    <td>YMM30</td>
    
    <td>XMM30</td>
    
  </tr>
  
  <tr>
    
    <td>ZMM31</td>
    
    <td>YMM31</td>
    
    <td>XMM31</td>
    
  </tr>
  
</tbody></table>

<p>In other words: the lower half of each <code>ZMMn</code> is <code>YMMn</code>, and the lower half of each <code>YMMn</code> is
<code>XMMn</code>. Thereâ€™s no direct way register access for just the upper half of <code>YMMn</code>, nor does
<code>ZMMn</code> have direct 256- or 128-bit access for the thunks of its upper half.</p>

<p>SSE also defines a new status register, <code>MXCSR</code>, that contains flags roughly parallel
to the arithmetic flags in <code>RFLAGS</code> (along with floating-point flags in the x87 status word).</p>

<p>AVX-512 <strong>also</strong> introduces eight <em>opmask</em> registers, <code>k0</code> through <code>k7</code>. <code>k0</code> is a special case
that behaves much like the â€œzeroâ€ register on some RISC ISAs: it canâ€™t be stored to, and
loads from it always produce a bitmask of all ones.</p>

<p><strong>Errata</strong>: The table above includes AVX-512, which isnâ€™t available on any AMD CPUs as of 2020.
Iâ€™ve updated the counts below to only include SSE and AVX2-introduced registers.</p>

<p><strong>Registers in this group: 33</strong>.</p>

<p><strong>Running total: 134</strong>.</p>

<h2 id="bounds-registers">Bounds registers</h2>

<p>Intel added these with <a href="https://en.wikipedia.org/wiki/Intel_MPX">MPX</a>, which was intended to
offer hardware-accelerated bounds checking. Nobody uses it, since
<a href="https://www.phoronix.com/scan.php?page=news_item&amp;px=Intel-MPX-Is-Dead">it doesnâ€™t work very well</a>.
But x86 is eternal and slow to fix mistakes, so weâ€™ll probably have these registers taking up space
for at least a while longer:</p>

<ul>
  <li><code>BND0</code> â€” <code>BND3</code>: Individual 128-bit registers, each containing a pair of addresses
for a bound.</li>
  <li><code>BNDCFG</code>: Bound configuration, kernel mode.</li>
  <li><code>BNDCFU</code>: Bound configuration, user mode.</li>
  <li><code>BNDSTATUS</code>: Bound status, after a <code>#BR</code> is raised.</li>
</ul>

<p><strong>Registers in this group: 7</strong>.</p>

<p><strong>Running total: 141</strong>.</p>

<h2 id="debug-registers">Debug registers</h2>

<p>These are what they sound like: registers that aid and accelerate software debuggers, like
<a href="https://www.gnu.org/software/gdb/">GDB</a>.</p>

<p>There are 6 debug registers of two types:</p>

<ul>
  <li>
    <p><code>DR0</code> through <code>DR3</code> contain linear addresses, each of which is associated with a breakpoint
condition.</p>
  </li>
  <li>
    <p><code>DR6</code> and <code>DR7</code> are the debug status and control registers. <code>DR6</code>â€™s lower bits indicate which
debug conditions were encountered (upon entering the debug exception handler), while <code>DR7</code> controls
which breakpoint addresses are enabled and their breakpoint conditions (e.g., when a particular
address is written to).</p>
  </li>
</ul>

<p>What about <code>DR4</code> and <code>DR5</code>? For reasons that are unclear to me, they donâ€™t (and have never)
existed<sup id="fnref:guess" role="doc-noteref"><a href="#fn:guess">9</a></sup>. They <em>do</em> have encodings but are treated as <code>DR6</code> and <code>DR7</code>, respective, or produce
an <code>#UD</code> exception when <code>CR4.DE[bit 3] = 1</code>.</p>

<p><strong>Registers in this group: 6.</strong></p>

<p><strong>Running â€¦</strong></p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.yossarian.net/2020/11/30/How-many-registers-does-an-x86-64-cpu-have">https://blog.yossarian.net/2020/11/30/How-many-registers-does-an-x86-64-cpu-have</a></em></p>]]>
            </description>
            <link>https://blog.yossarian.net/2020/11/30/How-many-registers-does-an-x86-64-cpu-have</link>
            <guid isPermaLink="false">hacker-news-small-sites-25253797</guid>
            <pubDate>Mon, 30 Nov 2020 14:07:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Feel Like I Have No Real Interests; My Only Interest Is Making Money]]>
            </title>
            <description>
<![CDATA[
Score 134 | Comments 185 (<a href="https://news.ycombinator.com/item?id=25253197">thread link</a>) | @_davebennett
<br/>
November 30, 2020 | https://www.bennettnotes.com/post/my-only-interest-is-making-money/ | <a href="https://web.archive.org/web/*/https://www.bennettnotes.com/post/my-only-interest-is-making-money/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<article>
<p>I have no real interests or hobbies. If I was shopping for myself Iâ€™d probably just buy another book on â€œgrowing your side hustleâ€ or one of the many â€œbuilding a startupâ€ books.</p>
<p>Revenue, monetization, and profit are always the primary driver for my activities. Whether or not I actually care about a particular topic is sorta irrelevant. And my frustration is that depending on who I talk to, I get entirely different perspectives on whether this going to facilitate my success in life or not. For example, people who are like my business/money focused family applaud my efforts. They donâ€™t understand how this is bad.</p>
<p>â€œDave, how is spending your free time trying to make more money a bad thing? You can use that money to pursue your hobbies or interests.â€</p>
<p>â€œYeah uncle, but I honestly donâ€™t know what my hobbies and interests are besides things that make more money.â€</p>
<p>â€œGreat Dave, so your passion is making money!â€</p>
<p>â€œBut I donâ€™t want that to be my passion!â€</p>
<p>But if I talk to my more passion focused friends, Iâ€™m sorta self-judging in my head.</p>
<p>â€œDave, Iâ€™m working on a youth charity. Itâ€™s soo many hours of long work and stressful, but really rewarding.â€</p>
<p>â€œOh ummâ€¦thatâ€™s great Pam. But thatâ€™s a lot of work, and no money? Likeâ€¦is it really worth it? Imagine if you turned it into some type of education business. Whatâ€™s the market like for that? You could charge at least $300 per student.â€</p>
<p>Ugh, this is what gives me migraines. My 25 year old anxiety is telling me that if I pick the wrong strategy then my future is forever doomed. I also have no idea where this obsession began. I didnâ€™t grow up poor, so I canâ€™t use that as an excuse for my obsession. I think it might have to do with imposter syndrome and feeling like I have to prove myself. Basically, if I have lots of money rolling in then I can say â€œfuck the systemâ€ and not be criticized. I falsely feel like people canâ€™t judge me if I have my own business thatâ€™s making Elon Musk level income.</p>
<p>Or maybe itâ€™s simply because I live in the United States, and thatâ€™s just our culture here. Plus with all the uncertainty, you never know when debt can hit you. Poverty, streets, homeless shelter, etc.</p>
<p>But this just all feels wrong to me. It feels like Iâ€™m digging myself into a bad hole. What if my time was used toward genuine activities and interests? I could also have a chance at financial success with those. I just donâ€™t know what those genuine interests are. All I know is that when I chase after these money quests, I always feel cheated in the end.</p>
<p>Letâ€™s walk inside my mind for a second.</p>
<p>So I work on coding side projects outside of work. Do I love coding and problem solving? Eh, Iâ€™m not really sure. But, I do love the idea of one day rolling in cash from some tool or app I built. Therefore, Iâ€™m going to spend my time trying to find a niche market that I can penetrate with some basic app/program that I can at least charge $100 a month for. Then I just need to spend a couple of hours everyday scouring through Google trends, Reddit, or Exploding Topics to find something people are currently into. Then maybe set up a landing page, and see if people enter in their credit card info. Or how about I search the Apple App Store and find some shitty app that people pay big bucks for and copy it? Oh wait, hold up, snack boxes are trending! Okay, so I can just set up a service for $20 a month to send people almonds, right?</p>
<p>Trust me, it gets worst.</p>
<p>I make videos on YouTube. I have a little over 200k subscribers currently. Do I like making videos? Ehâ€¦Iâ€™m not really sure. Truthfully, most days I would rather not engage in the activity. But influencer sponsorships pay a lot! Also, adsense is a really nice passive income source. So what I need to do is spend my time studying the YouTube algorithm so I can produce videos that get more views. More views equals more money!! Oh and remember when I made videos on Android? Yeah nobody cares about that niche anymore. So Iâ€™m going to use tools like TubeBuddy or VidIQ to see trending topics that people are watching. Okay people are all talking about <em>Among Us</em> right now. So if I make a video thatâ€™s at least 10 minutes long I can stick a mid-roll ad into it too! Donâ€™t forget all the long-tail keywords. Wait, my website hardly has any ads on it right now. Iâ€™m missing out on extra income! I need at least a sidebar ad and also a footer ad.</p>
<p>Guess what? After two days I lost motivation in the Snackbox idea. As for YouTube, I made videos on the â€œwell researched SEO friendly topicsâ€ and they performed horribly. It was like another slap in the face saying â€œDave, this is what happens when you chase money without regard for interests.â€ Butâ€¦.butâ€¦all the entrepreneurs say just having interest in building a business is enough!</p>
<p>Yeah, so I donâ€™t know what to say or how to end this. Iâ€™m just hoping that by sharing my obstacles and fears I get some helpful incite; or at least connect people who also share this struggle. I feel like itâ€™s one of the many problems thatâ€™s not addressed adequately and leaves us just desperate for answers.</p>

</article>

</div></div>]]>
            </description>
            <link>https://www.bennettnotes.com/post/my-only-interest-is-making-money/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25253197</guid>
            <pubDate>Mon, 30 Nov 2020 12:45:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I am an 80 column purist]]>
            </title>
            <description>
<![CDATA[
Score 71 | Comments 75 (<a href="https://news.ycombinator.com/item?id=25251494">thread link</a>) | @Spiritus
<br/>
November 29, 2020 | https://daniel.haxx.se/blog/2020/11/30/i-am-an-80-column-purist/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/11/30/i-am-an-80-column-purist/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>I write and prefer code that fits within 80 columns in <a href="https://curl.haxx.se/">curl</a> and other projects â€“ and there are reasons for it. Iâ€™m a little bored by the people who respond and say that they have 400 inch monitors already and they can use them.</p>



<p>I too have multiple large high resolution screens â€“ but writing wide code is still a bad idea! So I decided Iâ€™ll write down my reasoning once and for all!</p>



<h2>Narrower is easier to read</h2>



<p>Thereâ€™s a reason newspapers and magazines have used narrow texts for centuries and in fact even books <a href="https://en.wikipedia.org/wiki/Line_length">arenâ€™t using long lines</a>. For most humans, it is simply easier on the eyes and brain to read texts that arenâ€™t using really long lines. This has been known for a very long time.</p>



<p>Easy-to-read code is easier to follow and understand which leads to fewer bugs and faster debugging.</p>



<h2>Side-by-side works better</h2>



<p>I <em>never</em> run windows full sized on my screens for anything except watching movies. I frequently have two or more editor windows next to each other, sometimes also with one or two extra terminal/debugger windows next to those. To make this feasible and still have the code readable, it needs to fit â€œwraplessâ€ in those windows.</p>



<p>Sometimes reading a code diff is easier side-by-side and then too it is important that the two can fit next to each other nicely.</p>



<h2>Better diffs</h2>



<p>Having code grow vertically rather than horizontally is beneficial for diff, git and other tools that work on changes to files. It reduces the risk of merge conflicts and it makes the merge conflicts that still happen easier to deal with.</p>



<h2>It encourages shorter names</h2>



<p>A side effect by strictly not allowing anything beyond column 80 is that it becomes really hard to use those terribly annoying 30+ letters java-style names on functions and identifiers. A function name, and especially local ones, should be short. Having long names make them really hard to read and makes it really hard to spot the difference between the other functions with similarly long names where just a sub-word within is changed.</p>



<p>I know especially Java people object to this as theyâ€™re trained in a different culture and say that a method name should rather include a lot of details of the functionality â€œto help the userâ€, but to me thatâ€™s a weak argument as all non-trivial functions will have more functionality than what can be expressed in the name and thus the user needs to know how the function works <em>anyway.</em></p>



<p>I donâ€™t mean 2-letter names. I mean long enough to make sense but not be ridiculous lengths. Usually within 15 letters or so.</p>



<h2>Just a few spaces per indent level</h2>



<p>To make this work, and yet allow a few indent levels, the code basically have to have small indent-levels, so I prefer to have it set to two spaces per level.</p>



<h2>Many indent levels is wrong anyway</h2>



<p>If you do a lot of indent levels it gets really hard to write code that still fits within the 80 column limit. Thatâ€™s a subtle way to suggest that you should not write functions that needs or uses that many indent levels. It should then rather be split out into multiple smaller functions, where then each function wonâ€™t need that many levels!</p>



<h2>Why exactly 80?</h2>



<p>Once upon the time it was of course because terminals had that limit and these days the exact number 80 is not a must. I just happen to think that the limit has worked fine in the past and I havenâ€™t found any compelling reason to change it since.</p>



<p>It also has to be a hard and fixed limit as if we allow a few places to go beyond the limit we end up on a slippery slope and code slowly grow wider over time â€“ Iâ€™ve seen it happen in many projects with â€œsoft enforcementâ€ on code column limits.</p>



<h2>Enforced by a tool</h2>



<p>In <a href="https://curl.se/">curl</a>, we have â€˜checksrcâ€™ which will yell errors at any user trying to build code with a too long line present. This is good because then we donâ€™t have to â€œwasteâ€ human efforts to point this out to contributors who offer pull requests. The tool will point out such mistakes with ruthless accuracy.</p>



<h2>Credits</h2>



<p>Image by <a href="https://pixabay.com/users/piotrarssale-15944391/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=5016297">piotr kurpaska</a> from <a href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=5016297">Pixabay</a></p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/11/30/i-am-an-80-column-purist/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25251494</guid>
            <pubDate>Mon, 30 Nov 2020 07:31:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[And this worldâ€™s a fickle measure]]>
            </title>
            <description>
<![CDATA[
Score 70 | Comments 23 (<a href="https://news.ycombinator.com/item?id=25250968">thread link</a>) | @jseliger
<br/>
November 29, 2020 | https://quidplura.com/2020/11/29/and-this-worlds-a-fickle-measure/ | <a href="https://web.archive.org/web/*/https://quidplura.com/2020/11/29/and-this-worlds-a-fickle-measure/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-12060">
	<!-- .entry-header -->

	<div>
		
<p>They told me, â€œYou have to watch <a href="https://www.youtube.com/watch?v=rhThso-PE_o">this interview where Mike Tyson talks about medieval history</a>,â€ and so I did, and there he was at the New York Public Library in 2013 being interviewed by curator Paul HoldengrÃ¤ber, whose German accent strikes the American ear as both effortlessly intellectual and lightly amusing, and who would seem to have nothing in common with the face-tattooed boxer.</p>



<p><img data-attachment-id="12067" data-permalink="https://quidplura.com/2020/11/29/and-this-worlds-a-fickle-measure/screen-shot-2020-11-28-at-11-57-11-pm-copy/" data-orig-file="https://quidplurablog.files.wordpress.com/2020/11/screen-shot-2020-11-28-at-11.57.11-pm-copy.jpg" data-orig-size="1816,934" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Screen Shot 2020-11-28 at 11.57.11 PM copy" data-image-description="" data-medium-file="https://quidplurablog.files.wordpress.com/2020/11/screen-shot-2020-11-28-at-11.57.11-pm-copy.jpg?w=300" data-large-file="https://quidplurablog.files.wordpress.com/2020/11/screen-shot-2020-11-28-at-11.57.11-pm-copy.jpg?w=863" src="https://quidplurablog.files.wordpress.com/2020/11/screen-shot-2020-11-28-at-11.57.11-pm-copy.jpg" alt=""></p>



<p>The two men do, in fact, find much to talk about. Their discussion is mesmerizing, because to most of us Mike Tyson is nothing but a face and fists, not a man who reflects aloud and at length about his inner life. HoldengrÃ¤ber prompts a reticent Tyson to narrate clips of his greatest moments in the ring, and newcomers to boxing will easily see why Tyson was such a sensation, but Iron Mike grows more animated when other matters arise.</p>



<p>Half an hour into the interview, HoldengrÃ¤ber says that their mutual friend, eccentric German filmmaker Werner Herzog, urged him to ask Tyson why heâ€™s so fascinated by Clovis, the founder of the Merovingian Frankish dynasty, and Pepin the Short, the first Carolingian king of the Franks. Tysonâ€™s answer, however halting, makes him come alive: </p>



<blockquote><p>I donâ€™t knowâ€”it all comes from my insecurity from being poor, and not having enoughâ€”to be insecure, and beingâ€”yeah, thatâ€™s what it is: obscure. I never wanted to be obscure. I was born in obscurity and I never wanted to deal with that again, never wanted to be that. And they came from obscurity.</p></blockquote>



<p>Tyson then narrates a capsule history of the Frankish kings. He rambles, he doesnâ€™t get all the details right, and his mispronunciation of names marks him as an autodidact, but itâ€™s a shame to hear the audience laugh when HoldengrÃ¤ber asks, â€œMike, how do you know all this shit?â€ Whether Tyson is mapping his own experiences onto medieval history or hearing echoes of the Franks in his troubled life, the credentialed, status-conscious audience is uncomfortable with his sincere interest in a past they find trivial.</p>



<p>Yet Tyson is the real deal, a book lover not because his peer group yaks about whichever author the <em>New York Times</em> has dubbed fameâ€™s latest love child, but because heâ€™s hungry for ideas, for meaning, for connections across time. He speaks with undisguised emotion about Cus Dâ€™Amato, the trainer and manager who turned him into a lethal boxer. Obsessed with Nietzsche and Clausewitz, Dâ€™Amato taught Tyson to see boxing as war and war as the key to decoding the world. â€œThat is just what I do,â€ Tyson explains, an attentive pupil and dutiful son. â€œI love war. I love the act of war. I love the players in war, the philosophy of war.â€</p>



<p>Tyson is searching for more than war on the pages of the past. Having grown up amid crime and chaos and founded his life on violence, he now relies on books to make moral and ethical sense of the world:</p>



<blockquote><p>Yeahâ€”theyâ€™re our most priceless possessions, because if you think about it, you know, a room without a book is like a body without a soul. Itâ€™s the only way that we can connect the future with the past. Without that, thereâ€™s no way that we can know about the future, and know about particularly the past, or the present, you know, that when you think about history, the value of history is not necessarily scientific but moral. By liberating our minds and deepening our sympathies and fortifying our will, we can controlâ€”pretty much history allows us to control not society but ourselves, which is a much more important thing to do, you know what I mean? And it would allow us to pretty much meet the future more so than foretell it, and for that reason alone, in order to predict the future we always have to look through the past, because very rarely does time not repeat itself, and it always will repeat itself. </p><p>Iâ€™ve heard a quote before in a book that we would be fools to think historically that the past is us in funny clothes, but the past <em><span>is</span></em> us in funny clothes, and thatâ€™s truly what it is. Thatâ€™s from somebody who really said a really profound statement but he misquoted what he was saying, he must have been saying it backwards, because thatâ€™s really what the past was, itâ€™s just us in funny clothes, in different times, thatâ€™s really what it is.</p></blockquote>



<p>Of course, to hear Tyson cite <a href="http://thecampvs.com/2011/08/03/cicero-on-books-and-the-soul/">a quip inaccurately attributed to Cicero</a>, â€œa room without books is like a body without a soul,â€ is to wonder if heâ€™s putting us on. Late in the interview, he jokes that if you quote books, you fool people into thinking youâ€™re smartâ€”but Tyson, for all his malapropisms and mispronunciations and odd mannerisms, <em>is</em> intelligent. Heâ€™s going round after round with big questions that  many of the ostensibly educated attendees at his book-talk donâ€™t bother to ask.</p>



<p>When HoldengrÃ¤ber suggests that Tysonâ€™s knowledge of history didnâ€™t improve his behavior, Tyson calmly disagrees. He compares himself to the fictional Ben-Hur, a fellow athlete and celebrity who achieved glory but was doomed to be unfree until he set his priorities in order: â€œHe may not have been famous again,â€ Tyson points out, â€œbut he got his family, and that was his success.â€ </p>



<p>After listening to Mike Tysonâ€”childhood criminal, devastating fighter, struggling alcoholic and recovering drug addict, convicted rapist, pop-culture eidolonâ€”speak for an hour and a half, I still donâ€™t quite know who he is. He may be the closest thing 21st-century America has to <a href="https://quidplura.com/2011/11/03/but-the-answers-you-seek-will-never-be-found-at-home/">a Robert E. Howard character</a>, a born barbarian whoâ€™s ignorant of social niceties but possesses earned wisdom that the civilization around him disdains. I donâ€™t know whether heâ€™s all in on his bookish pursuits or one slight away from again gnawing off someoneâ€™s ear. Whether heâ€™s a good man or a bad man feels foolish to ask about a professional punch-thrower who reads Nietzsche, but Tyson looks like a <em>better</em> man, one who has perhaps searched harder for his humanity than the onlookers snickering from the safety of their library seats. What has their pride gained them? Tysonâ€™s, by contrast, has brought him perspective, and with it the humility to admit that his story is still being writtenâ€”and has been before.</p>




			</div><!-- .entry-content -->

	
	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://quidplura.com/2020/11/29/and-this-worlds-a-fickle-measure/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25250968</guid>
            <pubDate>Mon, 30 Nov 2020 05:24:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making Playstation 1 Modchips (2018)]]>
            </title>
            <description>
<![CDATA[
Score 106 | Comments 41 (<a href="https://news.ycombinator.com/item?id=25248660">thread link</a>) | @cwaffles
<br/>
November 29, 2020 | https://blog.kchung.co/making-playstation-modchips/ | <a href="https://web.archive.org/web/*/https://blog.kchung.co/making-playstation-modchips/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>

        

        <section>
            <p>When I was young I owned a PlayStation 1 (PS1). It was one of the first, if not the first, game consoles I owned and it had a profound effect on my future. </p>

<p>I can trace the history of how I got involved in computers back to playing and modding video games. While I wasn't smart enough to mod game consoles when I was young, my dad wasn't bad at it. He modded my PS1 to have a little switch in the back that would allow it to play burnt games. They say the apple doesn't fall far from the tree. </p>

<p>Fast-forward to today and I no longer have my original PS1. I remember some games wouldn't load anymore and I had gotten a PS2. So why keep an old console? Turns out the answer is nostalgia and memories. You miss what you don't have anymore.</p>

<p>Recently a friend gifted me a PS1. And so then the journey begins, how do I mod this thing? </p>

<blockquote>
  <p>If you are looking for them I am selling <a href="http://rover.ebay.com/rover/1/711-53200-19255-0/1?icep_ff3=2&amp;pub=5575378759&amp;campid=5338273189&amp;customid=&amp;icep_item=223024408143&amp;ipn=psmain&amp;icep_vectorid=229466&amp;kwid=902099&amp;mtid=824&amp;kw=lg&amp;toolid=11111">flashed, prewired modchips</a>. </p>
</blockquote>



<p>Very simply, the principles behind PS1 DRM work as follows:</p>

<ol>
<li>Sony baked (not the technical term) strings (i.e. <code>SCEA</code>, <code>SCEI</code>, <code>SCEE</code>, or in rare cases <code>SCEW</code>) into official PS1 games in locations which cannot be replicated by a regular reader. <a href="https://www.youtube.com/watch?v=XUwSOfQ1D3c">This video</a> and <a href="http://www.psxdev.net/forum/viewtopic.php?t=128">this post</a> discuss it reasonably well.  </li>
<li>The CD drive controller looks for those strings to identify a disc as official. Once the controller decides that the disc is/isn't official, the main CPU reads this decision and acts accordingly.  </li>
<li>If the string can't be found or is garbled, the PS1 knows the disc isn't an <strong>authentic</strong> PS1 game. However, because the PS1 needs to account for disc read errors, there's a good amount of leeway in what passes the authenticity check.  </li>
<li>Because region <small>(<strong>A</strong> for America, <strong>I</strong> for Japan, <strong>E</strong> for Europe, and <strong>W</strong> for <a href="https://en.wikipedia.org/wiki/Net_Yaroze">Net Yaroze</a>)</small> as well as authenticity are rolled into one string, Sony kills two birds with one stone here and achieves region locking as well as copy protection. </li>
</ol>

<blockquote>
  <p>If you want a real in-depth discussion you can read <a href="http://www.oldcrows.net/mcc2.html">the original posts by The Old Crow</a> or the <a href="https://problemkaputt.de/psx-spx.htm#cdromprotectionmodchips">No$PSX documentation page</a> or this <a href="http://psx-scene.com/forums/f10/psx-modchip-faq-64110/">Modchip FAQ</a></p>
</blockquote>

<p>PSX modchips work by electrically stifling the output originally generated by whatever CD is inside the drive and then injecting a new, faked signal into the CD microcontroller. This causes the PS1 to believe that whatever disc is inside is legitimate and proceed to boot up. </p>

<p>Later on Sony added more complicated checks like:</p>

<ul>
<li>Checking for the magic strings during the game instead of at boot </li>
<li>Changing the overall process to make it more difficult to bypass by simply emitting the correct strings.</li>
</ul>

<p>However, modern modchips already deal with this. Modchips that work under these updated circumstances are known as "stealth modchips" because the console shouldn't be able to detect them at all. </p>



<p>The first "open source" modchip was reverse engineered by a guy named "The Old Crow". Surprisingly, The Old Crow specializes in electronic music synthesizers, not hacking video game consoles. It's from his modchip that most other modchips are derived from in some sense. He originally reverse engineered a commercial PS1 modchip that was designed by a western engineer working for a Chinese company. </p>

<p>Today, there are three main modchips which are still used by the community today.</p>

<p>The modchips include:</p>

<ul>
<li><a href="https://quade.co/ps1-modchip-guide/mm3/">Multimode 3 (MM3)</a></li>
<li><a href="https://quade.co/ps1-modchip-guide/mayumi-v4/">Mayumi v4</a></li>
<li><a href="https://github.com/kalymos/PsNee">PSNee</a></li>
</ul>

<p>The three have their pros and cons but generally they can be summarized as follows:</p>

<ul>
<li><p>MM3 is the most common PS1 modchip seen/used today. Its only real downside is that it uses an internal oscillator which can become out of sync with the oscillator used by the CD drive. If this happens you simply need to reboot your console to try reading again.  </p></li>
<li><p>Mayumi v4 attempts to use the oscillator used by the CD drive. This reduces the chance of the oscillator sync issue from happening; however, Mayumi v4 is considered a bit difficult to install. </p></li>
<li><p><a href="https://github.com/kalymos/PsNee">PSNee</a> is an open source modchip originally written by <a href="https://assemblergames.com/threads/psnee-a-stealth-modchip-for-all-ps1-models.57907/">TheFrietMan</a>. Development on it was <a href="http://www.psxdev.net/forum/viewtopic.php?t=1262">later continued by others</a> and it appears to work rather well on all Playstation 1/PSOne models. Based on the code I believe it attempts to infer where the PS1 is in the boot process to begin injecting fake <code>SCEX</code> strings. Unfortunately PSNee is complicated to install. The provided diagrams are atrocious and nowhere near as simple as the available diagrams for MM3 and Mayumi. I worked out <a href="https://gist.github.com/ColdHeat/be633b7eb6e25758ec80ae0115c1887a">the pinout for the Attiny45</a> but I ended up going with MM3 and Mayumi because it's easier. </p></li>
</ul>



<blockquote>
  <p>If you want them I am selling <a href="http://rover.ebay.com/rover/1/711-53200-19255-0/1?icep_ff3=2&amp;pub=5575378759&amp;campid=5338273189&amp;customid=&amp;icep_item=223024408143&amp;ipn=psmain&amp;icep_vectorid=229466&amp;kwid=902099&amp;mtid=824&amp;kw=lg&amp;toolid=11111">flashed, prewired modchips</a>. </p>
</blockquote>

<p>It's generally pretty easy to make a PS1 modchip provided you have the right tools. In this tutorial we will focus on making MM3 or Mayumi v4 modchips.</p>

<blockquote>
  <p>While I do have an Arduino, I prefer to use the MM3 and Mayumi chips over PSNee. If you want to make a PSNee modchip, you can follow the <a href="http://www.instructables.com/id/Program-an-ATtiny-with-Arduino/">instructions here</a> to flash the <a href="https://github.com/kalymos/PsNee/blob/master/PsNee.ino">.ino file</a> to your Attiny. </p>
</blockquote>

<p>You will need:</p>

<ul>
<li><a href="https://www.ebay.com/sch/i.html?_nkw=PIC12F508+DIP">Microchip PIC12F508</a></li>
<li><a href="https://amzn.to/2tfdeP0">PICkit 3</a>
<ul><li>Also download and install <a href="http://www.microchip.com/mplab/mplab-x-ide">MPLAB IPE</a> from the MPLAB X IDE package. </li></ul></li>
<li>Some kind of <a href="https://amzn.to/2llKUG7">wiring &amp; breadboard</a> to connect the PIC to to the PICkit.</li>
<li>HEX codes for the modchip of your choice (provided below).</li>
</ul>

<blockquote>
  <p>Many tutorials call for the PIC12C508. This is an old model and continuing to use them is unnecessary unless you have them stockpiled. HEX codes that work for the 12C will work for the 12F. </p>
</blockquote>

<p>To begin you should first look your IC and determine which leg is which. The leg nearest the imprinted circle is Pin 1. The leg opposite it is Pin 8. </p>

<p><img src="https://blog.kchung.co/content/images/2018/06/pic12f508-2.JPG" alt="This is a DIP chip. I accidentally got SOIC-8 (i.e. surface mount) and had to solder my chip to a breadboard but generally you can avoid that"></p>

<p>You can plug this into a bread board and then wire it into the Pickit according to the following diagrams. You want to match the following (the rest are unused for now):</p>

<ul>
<li>PICKit 1 âŸ· IC 4 (V<sub>PP</sub>)</li>
<li>PICKit 2 âŸ· IC 1 (V<sub>DD</sub>)</li>
<li>PICKit 3 âŸ· IC 8 (V<sub>SS</sub>)</li>
<li>PICKit 4 âŸ· IC 7 (ICSPDAT)</li>
<li>PICKit 5 âŸ· IC 6 (ICSPCLK)</li>
</ul>

<p><img src="https://blog.kchung.co/content/images/2018/06/pickit-12f508-1.jpg" alt="PICKit 3 on the left, PIC12F508 on the right"></p>

<p>Once you've properly wired up the chip, connect the PICKit to your computer and start MPLAB IPE. Under <code>Device</code> select <code>PIC12F508</code>. </p>

<p>Go into <code>Settings &gt; Advanced Mode</code>. The default password for <code>Advanced Mode</code> is <code>microchip</code>. I don't recommend changing it, not sure why the option is even available. </p>

<p>Go into the <code>Power</code> tab on the left and enable <code>Power Target Circuit from Tool</code>.</p>

<p><img src="https://blog.kchung.co/content/images/2018/06/Screen-Shot-2018-06-20-at-8.39.15-PM.png" alt=""></p>

<p>Go back to the <code>Operate</code> tab and hit <code>Connect</code>.</p>

<p><img src="https://blog.kchung.co/content/images/2018/06/Screen-Shot-2018-06-20-at-8.40.54-PM.png" alt=""></p>

<p>From here download the appropriate HEX code for your chip and console. They are different per console region. </p>

<ul>
<li><a href="https://raw.githubusercontent.com/wiki/ColdHeat/PsNeePy/hexcodes/mm3/MM3USA.HEX">MM3 for American Consoles</a></li>
<li><a href="https://raw.githubusercontent.com/wiki/ColdHeat/PsNeePy/hexcodes/mm3/MM3EUR.HEX">MM3 for European Consoles</a></li>
<li><a href="https://raw.githubusercontent.com/wiki/ColdHeat/PsNeePy/hexcodes/mm3/MM3JAP.HEX">MM3 for Japanese Consoles</a></li>
</ul>

<p>You can also use Mayumi v4 on the PIC12F508 if you choose.</p>

<ul>
<li><a href="https://raw.githubusercontent.com/wiki/ColdHeat/PsNeePy/hexcodes/mayumiv4/mayumi-usa4.hex">MayumiV4 for American Consoles</a></li>
<li><a href="https://raw.githubusercontent.com/wiki/ColdHeat/PsNeePy/hexcodes/mayumiv4/mayumi-eu4.hex">MayumiV4 for European Consoles</a></li>
<li><a href="https://raw.githubusercontent.com/wiki/ColdHeat/PsNeePy/hexcodes/mayumiv4/mayumi-jap4.hex">MayumiV4 for Japanese Consoles</a></li>
</ul>

<p>In the <code>Source</code> file, select your hex code. </p>

<p>Hit the big <code>Program</code> button. </p>

<p>You should see something similar to the following text:</p>

<pre><code>2018-06-20 20:48:02 -0400 - Loading hex file. Please wait...  
Loading code from /Users/kchung/Repositories/PsNeePy.wiki/hexcodes/mm3/MM3USA.HEX...  
2018-06-20 20:48:03 -0400 - Hex file loaded successfully.

2018-06-20 20:48:20 -0400 - Programming...

Device Erased...

Programming...

The following memory area(s) will be programmed:  
program memory: start address = 0x0, end address = 0x1e7  
configuration memory  
Programming/Verify complete  
2018-06-20 20:48:25 -0400 - Programming complete  
</code></pre>

<p>If you'd like, you can hit the <code>Verify</code> button to make sure that your flash was correct. Your output should look something like the following:</p>

<pre><code>2018-06-20 20:50:10 -0400 - Verifying...

Verifying...

The following memory areas(s) will be verified:  
program memory: start address = 0x0, end address = 0x1ff  
configuration memory  
User Id Memory

Verification successful.  
2018-06-20 20:50:13 -0400 - Verify complete  
</code></pre>

<p>From here you can follow online diagrams for soldering your chip to the PSX that you own. I personally used <a href="https://quade.co/ps1-modchip-guide">William Quade's excellent diagrams</a> and think you should as well.   </p>



<p>While looking at all these modchips, I figured it would be nice to read and write Python code instead of Assembly and C code so I started working on porting PSNee to Python. </p>

<p>By using <a href="https://micropython.org/">MicroPython</a> and an <a href="https://amzn.to/2K4HdTq">ESP8266</a> we can actually create a modchip that we can remotely update and modify through the <a href="https://amzn.to/2K4HdTq">ESP8266</a>'s WiFi.  </p>

<p><img src="https://blog.kchung.co/content/images/2018/06/IMG_1084.jpg" alt="Effectively the very first WiFi enabled PS1!"></p>

<p>In the above photo (SCPH-7501), the ESP8266 is on the top left with the headers face up. The wires connect to the headers and route under the CD drive to a breadboard on the bottom right. </p>

<blockquote>
  <p>The breadboard has wires that are soldered to the correct MM3 points and then labeled with the corresponding pin number. By using this breadboard I can test modchips that I make much faster than soldering to the board over and over again. </p>
</blockquote>

<p>My modchip (named PsNeePy) is available on Github: <br>
<a href="https://github.com/ColdHeat/PsNeePy">https://github.com/ColdHeat/PsNeePy</a></p>

<p>While my test console is quite bad at reading discs and the console rarely boots into games, the modchip does work. </p>

<blockquote>
  <p>For the most part (ignoring stealth functionality), modchips are known to be working once you reach the black Playstation logo screen as this indicates that the CPU considers the game authentic. </p>
</blockquote>

<p>However, because the code is based off an older version of PSNee, stealth functionality does not seem to work on some newer PS1 revisions.</p>

<p>I mostly created this as a proof of concept and I'm unlikely to maintain it very much. While I don't recommend using my modchip, I hope that the community adopts it and helps improve it. Despite being a dead console, the PSX community is fairly active. </p>

<p>With <a href="https://github.com/ColdHeat/PsNeePy">PsNeePy</a>, you can remotely update the ESP8266 over WiFi, debug remotely, and also reset the chip easily. Having spent many hours working on the PS1 at this point, a more modern experience is quite refreshing. </p>

<p><img src="https://blog.kchung.co/content/images/2018/06/Screen-Shot-2018-06-21-at-2.47.33-AM.png" alt="Remotely controlling the modchip"></p>

<p>Thanks to an anonymous friend for my PS1, Sharan for fixing my PS1, <a href="https://quade.co/">William Quade</a> for the excellent diagrams, AssemblerGames for having good information despite not accepting me into the forum, and PSXDEV for answering some of my questions.</p>
        </section>

        

    </article>
</div></div>]]>
            </description>
            <link>https://blog.kchung.co/making-playstation-modchips/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25248660</guid>
            <pubDate>Sun, 29 Nov 2020 22:24:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Run a Ponzi Scheme for Tech People]]>
            </title>
            <description>
<![CDATA[
Score 437 | Comments 232 (<a href="https://news.ycombinator.com/item?id=25248563">thread link</a>) | @nish1500
<br/>
November 29, 2020 | https://callmenish.com/how-to-run-a-tech-ponzi-scheme/ | <a href="https://web.archive.org/web/*/https://callmenish.com/how-to-run-a-tech-ponzi-scheme/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article role="article" itemscope="" itemprop="blogPost" itemtype="http://schema.org/BlogPosting">
<center>
<header>


</header>
</center>
<p>More people are online than ever before. More people are desperate than ever before. Learn how to use that ðŸ‘‡</p>
<h2>Is this the right course for me?</h2>
<p>Good question. My courses are NOT for everyone. You need to be a good fit. This is the prefect course for you if you check any of the following boxes:</p>
<ol><li>You like having a business card that says <strong>Iâ€™m CEO bitch</strong></li><li>You dream of petting elephants in a Southeast asian monarchy with a questionable human rights record</li><li>doTerra didnâ€™t work out</li><li>You have $100 to spare</li></ol>
<h2>Basics first. What is a Ponzi scheme?</h2>
<p>Say I managed to save $500 from my day job. I find 5 people who begrudgingly agree to give me $100 because I told them I can turn it into $200 in a month. I give them $200 each at the end of the month.</p>
<p>Now, I am <strong>out of savings</strong> but I have 5 people who doubled their money in a month with no hard work at all.</p>
<p>I use their story as an example to show people that my idea works. Now itâ€™s easier to find people who pay me. I take $100 from 10 more people, wait for a month, and use the proceeds ($1,000) to give $200 each to 5 of those people.</p>
<p>Now I have a <strong>proven business model</strong>, and a good number of people who will vouch for my method. I use the proceeds from each successive group to pay the previous cohort of people.</p>
<h2>But this is a tech community. Not Wall Street.</h2>
<p>A Ponzi scheme can be used in any part of your life. Letâ€™s see how we can use this around us today:</p>
<h3>Example 1: Sell a Course</h3>
<p>Create a twitter account and manage to get 100 followers through a combination of spamming famous people, dad jokes, and paid followers. Write this blog post and share it:</p>
<blockquote><p>How I got 100 followers in my first week with no hard work at all.</p></blockquote>
<p>Over the next week 50 people will read your tweet / post and start following you. These people are curious, and it costs them nothing to follow you. 50 followers isnâ€™t much but you get to write another exciting post:</p>
<blockquote><p>How I increased my twitter following by 50% in less than 3 days.</p></blockquote>
<p>Now people are intrigued, and you have 500 more followers. Write another post.</p>
<blockquote><p>How I got 500 followers overnight</p></blockquote>
<p>Does it remind you of something â€“ like a <strong>for</strong> loop? When iteration = 5, <strong>sell a course</strong> on Gumroad.</p>
<h3>Example 2: Become a Digital Nomad</h3>
<p>Quit your job in Colorado and move to Thailand because a long-haired guy and his hot girlfriend shared a beach selfie telling you how they are living the digital nomad life, and how you can do it too. Best $100 you ever spent.</p>
<p>Except, it didnâ€™t work out (teaching English in Thailand only pays so much), and now youâ€™re stuck in Koh Samui running out of money and ideas. Go to the nearest beach, take a picture of your laptop with sunset in the background and write this blog post:</p>
<blockquote><p>How quitting my 9-5 job and moving to Thailand was the best thing I ever did.</p></blockquote>
<p>Congrats, now people are listening. Create a course, somehow manage to make $1,000. Now use that $1,000 to buy some food, rent a moped, and share more selfies about your perfect life. Itâ€™s a massive market â€“ these regular folks working boring jobs in rich white countries who believe in the good intentions of strangers on the internet. Exploit them.</p>
<h3>Example 3: No Code, Only Money</h3>
<p>Arenâ€™t you sick of all these Iâ€™m-so-smart programmers with their statically-typed-languages-are-fast on HackerNews? When you came across this priceless <strong>No Code</strong> directory of tools you realized it was the next big thing. You spend $100 on the site, and use the knowledge to create a form (using a form builder) and a Zapier hook that emails people on new responses. Genius idea. You try to sell it for $500. No buyers. Itâ€™s all your fault.</p>
<p>Time to pivot. You create a <strong>No Code</strong> website to teach people how to make money using No Code tools (like you did, haha) such as <strong>Airtable</strong> and <strong>Zapier</strong>.</p>
<p><em>Note: the lesson here is NOT that you can make money by creating a valuable tool like Airtable using code. No.</em></p>
<p>Between your <strong>No Code website</strong> and <strong>No Code podcast</strong> you manage to make $500. You take a screenshot of your Stripe dashboard and share it with the world. Now you are hot shit. Going from 0 to $500 was the hard bit; going from $500 to $5,000 is easier.</p>
<h2>FAQ</h2>
<h4>Are places like Indiehacker and Gumroad and just enablers of Ponzi schemes?</h4>
<p>Of course not. There are some amazing people there working on cool new ideas. They write comments here and there, and make a post once in a while, but mostly itâ€™s busy work building something. Most such communities are started by a group of well-intentioned people, who slowly become the minority.</p>
<p>Not all courses are scams. I bought one on Gumroad yesterday. Except it wasnâ€™t teaching me how to grow my twitter following; it was teaching me a cool programming language that Iâ€™ve been meaning to learn for a while.</p>
<h4>Will I be sharing fake milestones and fake Stripe dashboards?</h4>
<p>You didnâ€™t read anything, did you? No, you will actually get 500 new followers, and actually make $5,000. The ones who wonâ€™t are the suckers who buy your course.</p>
<h4>Wonâ€™t people call me out when they buy my course and fail to become rich?</h4>
<p>That is the best part â€“ they will blame <strong>themselves</strong>. You made money. The people who gave you Twitter testimonials apparently made money. If people fail they will think itâ€™s them. In fact, sell them your <strong>Advanced Course</strong>.</p>
<h4>How do I convince people I am legit?</h4>
<p>Tell people you are open to <strong>speaking engagements</strong>. Talk about the number of <strong>trees you planted</strong> this month. Tell them someone else forced you to post on IH or HN because of how great your content is. Talk about <strong>failure</strong> so you seem relatable. Act <strong>quirky</strong> on Twitter.</p>
<h4>Wait, are you writing this just to make me a part of your Ponzi scheme?</h4>
<p>Do you really think I am going to spend half a Sunday writing and formatting this long-ass post (instead of using my magic formula to make money for myself) for any reason other than the goodness of my heart?</p>
<p>Of course not. I swear. I just want to share my success with the world, help the little guy, Build in Publicâ„¢, like every other â€˜How I Made $5,000â€™ post. Pinky promise.</p>
<h4>I am sold. So, how DO I run a Ponzi scheme?</h4>
<p>You see, my goal in sharing my success here is to see <strong>YOU grow</strong>. Just like the guy who sold me into his Ponzi scheme â€“ I am only paying it forward ðŸ™ðŸ¼.</p>
<p>I do like to charge <strong>$100</strong> JUST to ensure that only serious people become a part of my Ponzi-family. We call it an investment.</p>
<p>Enough talk. Signup here:</p>
<p><a href="https://nish.formcrafts.com/ponzi-scheme" target="_blank" rel="noreferrer noopener">https://nish.formcrafts.com/ponzi-scheme</a></p>
<h4>How do I NOT run a Ponzi scheme?</h4>
<ol><li>Look around you for problems people would pay to resolve.</li><li>Create something of value.</li><li>Have fun while you do it.</li></ol>
<p>Discuss on <a rel="noreferrer noopener" href="https://news.ycombinator.com/item?id=25248563" target="_blank">HN</a>.</p>
<p><a href="https://twitter.com/nish_crafts" target="_blank" rel="noreferrer noopener">@nish_crafts</a></p>

</article></div>]]>
            </description>
            <link>https://callmenish.com/how-to-run-a-tech-ponzi-scheme/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25248563</guid>
            <pubDate>Sun, 29 Nov 2020 22:10:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vancouver's empty home tax is increasing to 3% next year]]>
            </title>
            <description>
<![CDATA[
Score 97 | Comments 38 (<a href="https://news.ycombinator.com/item?id=25247904">thread link</a>) | @synack
<br/>
November 29, 2020 | https://bc.ctvnews.ca/vancouver-s-empty-home-tax-is-increasing-to-3-next-year-1.5204533 | <a href="https://web.archive.org/web/*/https://bc.ctvnews.ca/vancouver-s-empty-home-tax-is-increasing-to-3-next-year-1.5204533">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>VANCOUVER -- 
	The empty homes tax in Vancouver will more than double next year, the city announced Wednesday.</p>
<p>
	Council voted in favour of increasing the tax from 1.25 per cent to three per cent for 2021. The current rate still applies for 2020 declarations, which are due by Feb. 2.&nbsp;</p>
<p>
	"I'm so glad that council backed my plan to stand up for renters and raise the empty homes tax to three per cent," said Mayor Kennedy Stewart in a news release.&nbsp;</p>
<p>
	"This groundbreaking tool has helped move thousands of homes back onto the rental market to help house our neighbours, but there are still too many homes that remain empty."</p>
<p>
	When the tax was first introduced in 2017, it started at one per cent. Then council voted to increase it for the first time in 2019, to 1.25 per cent.</p>
<p>
	"By tripling the tax from one to three per cent since the tax launched, we're sending an even stronger message that homes are for people, not speculation," Stewart said.</p>
<p>
	According to the city, $61.3 million in net revenues from the tax has been used to support affordable housing initiatives. Vacant property has decreased by 25 per cent since the tax was introduced in 2017, the city says.&nbsp;&nbsp;</p>
                                              </div></div>]]>
            </description>
            <link>https://bc.ctvnews.ca/vancouver-s-empty-home-tax-is-increasing-to-3-next-year-1.5204533</link>
            <guid isPermaLink="false">hacker-news-small-sites-25247904</guid>
            <pubDate>Sun, 29 Nov 2020 20:43:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Simple Password Management with GPG]]>
            </title>
            <description>
<![CDATA[
Score 93 | Comments 73 (<a href="https://news.ycombinator.com/item?id=25247211">thread link</a>) | @todsacerdoti
<br/>
November 29, 2020 | https://tylerlmz1.github.io/tools/2020/05/15/Password-management.html | <a href="https://web.archive.org/web/*/https://tylerlmz1.github.io/tools/2020/05/15/Password-management.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <!--**This is a post about a password management system where you GPG encrypt markdown files on Linux and Syncthing them to Android.**-->

<!--Want to use GPG encrypted files to manage your passwords?-->

<!-- use the word `markdown files` instead of `plain-text files` is because people who care enough to read on are tech savvy people that knows markdown anyway, but then ä¼šmake it too å¤æ‚å—, å†çœ‹å§, æ„Ÿè§‰ say plain-text might ä¹Ÿæ¯”è¾ƒå¥½çš„ -->

<!--I'm not too fond of using password management tools like `Dashlane` or `1Password`, I've never really tried them, because there's no guarantee that they will live forever, nor that their security perfect.-->

<!--Even though some of them are open-source, they are still at the mercy of their developers unless I'm willing to modify it myself,-->
<!--so it is harder to modify it to fit my needs better.-->

<!--I just want a password management system that is simple, extensible and will live forever, this is my setup:-->
<p>If you want a password management system that is plain-text based, let me introduce to you my setup which utilizes GPG encrypted files to do that.</p>

<p>It uses GPG to encrypt markdown files containing my login credentials, and Syncthing to synchronize them to my Android phone to realize cross-device availability.</p>


<!--To be more exact, I create markdown files and store my login credentials plain-text, then-->

<ul>
  <li>On my computer, I use
    <ul>
      <li><code>gpg</code> to encrypt the markdown files</li>
      <li><a href="https://vimawesome.com/plugin/gnupg-vim">jamessan/vim-gnupg</a> Vim plugin to easily decrypt and edit the files</li>
      <li><code>Git</code> to version control the folder so I have full history of my login credentials</li>
    </ul>
  </li>
  <li>To access them from my phone, I use
    <ul>
      <li><a href="https://syncthing.net/">Syncthing</a> to synchronize the folder to my phone</li>
      <li><a href="https://play.google.com/store/apps/details?id=org.sufficientlysecure.keychain&amp;hl=en">OpenKeychain</a> app to decrypt and read the encrypted files</li>
    </ul>
  </li>
</ul>

<p>I could just Syncthing the markdown files <em>without encryption</em> to my phone, but on the off chance that my phone is stolen / lost / hacked, I donâ€™t want my passwords to go down with it, so it is safer to have it gpg encrypted.</p>

<p><del>Iâ€™m aware of <a href="https://www.passwordstore.org/">pass</a> and tried it before I came to this setup, but I want to put more info than just a password string in my files, so thatâ€™s why <code>pass</code> doesnâ€™t fit my need.</del>
As many have pointed out in this <a href="https://news.ycombinator.com/item?id=25247211">HackerNews thread</a>, pass allows multi-line edit, so this paragraph is incorrect.</p>

<h3 id="how-to-replicate-this-setup">How to replicate this setup</h3>

<p><strong>1. Generate a PGP keypair with GPG</strong></p>

<p>you can skip this if you already have a keypair.</p>

<p>$ <code>gpg --full-gen-key</code></p>

<p><strong>2. Install the Vim plugin and put in corresponding config</strong></p>

<p>Assuming youâ€™re using VimPlug ( a vim plugin manager ),
put this into your ~/.vimrc and run <code>:PlugInstall</code> in Vim.</p>

<div><div><pre><code>Plug 'jamessan/vim-gnupg'
" Armor files
let g:GPGPreferArmor=1
" Set the default option
let g:GPGDefaultRecipients=["youremail@provider.com"]"
</code></pre></div></div>
<p>NOTE: remember to modify the <code>youremail@provider.com</code> to the email associated with your PGP key</p>

<!--This plugin will auto decrypt encrypted files when you open them with Vim, making the only difference with opening a normal unencrypted file a slight delay of opening the file due to the decryption process.-->
<!--æœ‰ç‚¹å•°å—¦ this ^ line, comment it out first-->

<p><strong>3. Create a markdown file</strong></p>

<p>$ <code>touch mygmail.md</code></p>

<p><strong>4. Encrypt the markdown file</strong></p>

<!--$ `gpg --recipient youremail@provider.com --armor --output %f.asc --encrypt %f`-->
<p>$ <code>gpg -e -r youremail@provider.com path/to/file</code></p>

<p>if you use <a href="https://github.com/ranger/ranger">Ranger</a>, you can put this mapping into your rc.conf to encrypt it easily by pressing <code>te</code> when the selection is hovering on the file:</p>

<div><div><pre><code>map te shell gpg --recipient youremail@provider.com --armor --output %f.asc --encrypt %f &amp;&amp; rm %f
</code></pre></div></div>

<p>Open the file with Vim to make sure it can auto decrypt and open up the file.</p>


<p><strong>5. Setup Syncthing</strong></p>

<p><a href="https://syncthing.net/downloads/">Install Syncthing</a> on Linux and Android, then set it up to sync your password folder to your phone.</p>

<p><strong>6. Setup OpenKeychain</strong></p>

<ol>
  <li>
    <p>Install <a href="https://play.google.com/store/apps/details?id=org.sufficientlysecure.keychain&amp;hl=en">OpenKeychain</a> Android app on your phone</p>
  </li>
  <li>export your PGP private key from Linux
    <div><div><pre><code>  $ gpg --export-secret-keys --armor youremail@provider.com &gt; privkey.asc
</code></pre></div>    </div>
  </li>
  <li>Transfer the file to your Android phone (for example through wire)</li>
  <li>Import the key file into <code>OpenKeychain</code> app</li>
</ol>

<p><strong>7. Try decrypting your files on Android</strong></p>

<p>To decrypt and view your password file:</p>

<ol>
  <li>Open the <code>OpenKeychain</code> app</li>
  <li>
    <p>Press the hamburger menu icon on the top left</p>
  </li>
  <li>Press <code>Encrypt/Decrypt</code></li>
</ol>

<p><img src="https://tylerlmz1.github.io/assets/decrypt.png" width="200px"></p>

<ol>
  <li>Press <code>Select input file</code> and browse to the encrypted password file</li>
  <li>Enter your PGP key passphrase</li>
</ol>

<p><strong>8. Done</strong></p>

<p><img src="https://tylerlmz1.github.io/assets/view_decrypted_pw_file.png" width="200px"></p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://tylerlmz1.github.io/tools/2020/05/15/Password-management.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25247211</guid>
            <pubDate>Sun, 29 Nov 2020 19:13:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Only distributed fact-checking can keep up with democratized distribution]]>
            </title>
            <description>
<![CDATA[
Score 129 | Comments 179 (<a href="https://news.ycombinator.com/item?id=25246733">thread link</a>) | @awinter-py
<br/>
November 29, 2020 | https://abe-winter.github.io/only/fans/2020/11/29/everything-in-moderation.html | <a href="https://web.archive.org/web/*/https://abe-winter.github.io/only/fans/2020/11/29/everything-in-moderation.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><img src="https://abe-winter.github.io/assets/swift-ftl.png" alt="tweet: the problem with being faster than light is that you always live in darkness"></p>

<p>Has social media democratized reporting as promised?
Weâ€™ve democratized <em>writing and publishing</em> but this year has made the point that thereâ€™s more to journalism than hitting send.
The rest of the stuff that happens in the newsroom has stayed in the newsroom:
cultivating sources, editing for quality, and most importantly, fact-checking.</p>

<p>Lacking checks, social media is amplifying or at least fertilizing false beliefs,
and then people cross state lines to shoot up pizza joints.
If the newsroomâ€™s adversarial functions canâ€™t make the jump to social media,
life will continue to be this weird.</p>

<p>Weâ€™re starting to address fact-checking, and will do more.
<a href="https://arstechnica.com/tech-policy/2019/11/why-cant-internet-companies-stop-awful-content/">Failing to curb antisocial behavior kills companies</a>, as well as communities.</p>

<p>Facebook has the technology to filter out the worst-quality content that their users think is â€˜P(bad for the world)â€™ â€“ <a href="https://twitter.com/kevinroose/status/1331257332538359810">but only at the cost of lower engagement</a>.
Given these incentives, nobody benefits if we leave this to platforms to solve.
Users should bring their own moderation to the web.</p>

<ul id="markdown-toc">
  <li><a href="#private-groups-will-decamp-if-they-dont-like-the-fact-bubbles" id="markdown-toc-private-groups-will-decamp-if-they-dont-like-the-fact-bubbles">Private groups will decamp if they donâ€™t like the fact bubbles</a></li>
  <li><a href="#conspiracies-are-topics-too" id="markdown-toc-conspiracies-are-topics-too">Conspiracies are topics too</a></li>
  <li><a href="#cranky-boomers-r-us" id="markdown-toc-cranky-boomers-r-us">Cranky boomers R us</a></li>
  <li><a href="#byo-vs-centralized-moderation" id="markdown-toc-byo-vs-centralized-moderation">BYO vs centralized moderation</a></li>
  <li><a href="#information-also-has-professional-customers" id="markdown-toc-information-also-has-professional-customers">Information also has professional customers</a></li>
  <li><a href="#conclusions" id="markdown-toc-conclusions">Conclusions</a></li>
</ul>

<h2 id="private-groups-will-decamp-if-they-dont-like-the-fact-bubbles">Private groups will decamp if they donâ€™t like the fact bubbles</h2>

<p>Filter bubbles donâ€™t have to put up with fact bubbles.
By filter bubbles, I mean clique groups that see mostly content that supports their priors.
By fact bubbles, I mean those blue exclamation marks that say â€˜official sources have called the election differentlyâ€™.</p>

<p>Private groups have the power to resist centralized moderation if they donâ€™t like it.
Private groups are sticky which is why facebook <a href="https://www.theverge.com/2019/4/30/18524188/facebook-f8-keynote-mark-zuckerberg-privacy-future-2019">bet their future on them</a>,
but this stickiness makes them hard to control.
Yes, their internal cohesion leads to engagement on FB, but it also allows them to move off the platform if theyâ€™re unhappy.
They own their slice of the network; their moat has a drawbridge.</p>

<p>A heavy hand will drive private groups to dark corners of the web â€“
not <em>un</em>-moderated exactly, because trust me, nobody wants that.
But â€˜differently moderatedâ€™.
Reality is a participation sport and groups which donâ€™t want to participate, wonâ€™t.</p>

<p>That said, deplatforming isnâ€™t zero-cost for groups:
they recruit in public spaces, and are helped by â€˜suggested groupsâ€™ features (which FB <a href="https://www.buzzfeednews.com/article/ryanmac/facebook-suspended-group-recommendations-election">partially disabled</a> for the election).
Standalone forums canâ€™t grow like that.
The fickle graces of <a href="https://www.theverge.com/2019/8/5/20754943/8chan-epik-offline-voxility-service-cutoff-hate-speech-ban">hosts</a> and <a href="https://www.theverge.com/2019/8/4/20754310/cloudflare-8chan-fredrick-brennan-ddos-attack">DDOS-protection companies</a> also make it hard to go solo.</p>

<p>But itâ€™s not like IRL networks will stop feeding online groups.
The counterargument to â€˜social media gives bad politicians a voiceâ€™ is that once someone has been elected, theyâ€™ll probably <a href="https://www.youtube.com/watch?v=f7131IkiSCg">have a voice anyway</a>.
FBâ€™s design gives eyeballs to demagogues but <a href="https://en.wikipedia.org/wiki/Triumph_des_Willens">so did Leni Riefenstahl</a>.</p>

<p>As I drafted this in early november, twitter was fact-bubbling multiple tweets in a row from the president,
the â€˜uncensoredâ€™ social media app parler <a href="https://twitter.com/yashar/status/1325229370126991363">trended to #1</a> in appleâ€™s store,
and local hero <a href="https://twitter.com/WilliamShatner/status/1326223481646665728">Bill Shatner took up the cause of moderation</a> to oppose them.
The â€˜moderation drives exodusâ€™ hypothesis is plausible.</p>

<p>But parler canâ€™t really want to be unmoderated.
Their debut came with a quick correction that despite the sales pitch, <a href="https://twitter.com/viaCristiano/status/1277941967402553345">your username canâ€™t be cumdumpster</a>.
(<a href="https://twitter.com/cumdumpster">Twitter has allowed this</a> since at least 2013).</p>

<p>My point: nobody wants to live in a trash can.
Every community has some kind of semi-official management.
I think even 8kun revoked someoneâ€™s access to the Q account after they had a falling out (admittedly, not over content I think, and also I donâ€™t really understand this world).
But the <em>forms</em> of moderation we invent have to be trusted or at least tolerated, or people will ditch.</p>

<p>Fact-checking, if itâ€™s trustworthy and useful, will be embraced IMO. But it canâ€™t be imposed.</p>

<h2 id="conspiracies-are-topics-too">Conspiracies are topics too</h2>

<p>A swedish friend, trying to explain why their <a href="https://en.wikipedia.org/wiki/Sweden_Democrats">far-right party</a> gained power in the Riksdag,
said something like â€˜Itâ€™s not that weâ€™re all nazis, but nobody else would even talk about immigration, and itâ€™s a real problemâ€™.</p>

<p>I like the â€˜marketplace of ideasâ€™ as a concept.<sup id="fnref:marketplace" role="doc-noteref"><a href="#fn:marketplace">1</a></sup>
Markets are an interesting model for public discourse.
Like goods on markets, there are a limited number of explanations or ideologies available (assuming most people canâ€™t coin our own â€“ for various reasons, I believe we canâ€™t).
Also, like a real market, itâ€™s two-sided, in that in addition to the ideas on offer, there are buyers:
people looking for an action, belief, or political party that suits them.</p>

<p>The marketplace model explains why political parties get to lie out loud, be revealed for hypocrisy, and admit their strategy is disingenuous.
Theyâ€™re <em>still</em> the only rallying point for â€˜critical idea Xâ€™ that their buyers need.
It may not matter to the fighting faithful if the center is hollow.
Theyâ€™re willing to ignore the cognitive dissonance.</p>

<p>I wonder if thereâ€™s a similar effect in the antivax movement â€“
autism seems to really be on the rise (0.7 to 1.5% in this century),
and if your family is affected by this, and thereâ€™s no other explanation, you â€˜buyâ€™ the idea that comes with a clear cause and a solution.</p>

<h2 id="cranky-boomers-r-us">Cranky boomers R us</h2>

<p>People are seeking answers that are plausible to them,
but may not be able or willing to dig deeply, and may not be ready to hear the truth if it means abandoning their hope, identity, or <a href="https://phys.org/news/2020-11-beliefs-world-filter.html">existing opinions</a>.
I suspect if someone is at the bottom of a rabbit hole and sees a fact bubble saying â€˜this is stupidâ€™, thatâ€™s the same as saying â€˜youâ€™re stupidâ€™, and they wonâ€™t listen.
The challenge here is matching them with a well-meaning authority whom theyâ€™ll trust and find useful.</p>

<p>There was a measles outbreak in Minnesota enabled by high vaccine refusal rate in a single immigrant community.
Parents noticed a lot of their kids in special autism education<sup id="fnref:stat-antivax" role="doc-noteref"><a href="#fn:stat-antivax">2</a></sup>, then fell prey to antivax lecturers or something.
But the parents had access to doctors.
And presumably they had access to other experts at the autism schools.
They ignored the fact bubble.
They chose who to trust.</p>

<p>On the flip side, community-owned moderation sometimes works rather well.
Iâ€™m thinking about subreddits, who tend to have very specific rules about what to post, and their users accept that these communities are actively moderated for the benefit of the community.
(Given that the community is a result of moderation, this is a little circular and feedback loop-y, but that may not be a bad thing).</p>

<p>I asked a friend who mods a small subbredit what itâ€™s like:
â€œIn six years, no one has ever said anything mean on my subreddit. Iâ€™ve never had to ban anyone and submitters and subscribers are respectful.â€</p>

<p>Cranky boomers got us into this mess by believing everything they read on facebook.
Maybe Cranky-Boomers-R-Usâ„¢ï¸ is the right branding for a community fact check to filter out some fast-spreading egregious claims.</p>

<p>We train people to consider the source, but mainstream mastheads like NYT feel ideologically hostile to readers who arenâ€™t centrists over 55.
Their news coverage can be accurate without being neutral â€“ factual claims in articles are fact-checked, but thatâ€™s mixed with interpretive conclusions.
The op-eds are <a href="https://www.cjr.org/the_media_today/james_bennet_tom_cotton_objectivity.php">far stranger</a>.</p>

<p>I donâ€™t blame people for switching to ideologically comfortable news.
I just wish they had a fact-check that was ideologically comfortable, but also competent and reputation-bound, to go along with it.</p>

<p>Repentant neocon Francis Fukuyama writes about social trust now and is <a href="https://www.project-syndicate.org/onpoint/the-emergence-of-a-post-fact-world-by-francis-fukuyama-2017-01">worried about post-fact world</a> where
â€œall authoritative information sources are challenged by contrary facts of dubious quality and provenanceâ€.
Readers have reasons for straying from reality.
Letâ€™s give people an ideologically comfortable way to come back.</p>

<p><a href="https://en.wikipedia.org/wiki/Harm_reduction">Gentler public health messaging</a> that accepts peopleâ€™s lifestyles can have higher efficacy;
I suspect the same is true of fact-checks.
Our goal isnâ€™t to change minds; itâ€™s to improve outcomes.</p>

<h2 id="byo-vs-centralized-moderation">BYO vs centralized moderation</h2>

<p>We need a market ecosystem of moderation vendors who provide different kinds of value to different kinds of users.
A moderation marketplace is good for platforms because they donâ€™t want to be the arbiter of truth, they just want users to have a good experience.
(Platforms will still have some policing to do on their own).</p>

<p>Itâ€™s good for users because theyâ€™re not forced into anything; they can pick which web they want to dwell on.
This may sound like a filter bubble, where â€˜everyone has their own truthâ€™,
but moderation vendors will still need to maintain their reputation for being right â€“
whatever their ideological alignment.
Moderation vendors, unlike cable news channels, donâ€™t produce content;
they just react to it and grade it.
BYO moderation isnâ€™t BYO newspaper, itâ€™s BYO snopes / politifact.</p>

<p>Centralized moderation has problems:</p>

<ul>
  <li>The costs are asymmetric, meaning itâ€™s too expensive to do widely, well, and fast (see lego point below). Jimmy Wales of wikipedia describes the economics here leading to a <a href="https://medium.com/conversations-with-tyler/jimmy-wales-tyler-cowen-wikipedia-610b6e931d20">sweatshop model</a>.</li>
  <li>Itâ€™s susceptible to abuse by platforms and institutions and therefore will be less trusted by users, especially the more conspiracy-minded ones whom we want to deradicalize. Note Iâ€™m not saying â€˜prone to abuseâ€™ or â€˜untrustworthyâ€™. Just less trust-<em>ed</em>, and less able to balance minority viewpoints in a way that feels authentic to minorities.</li>
  <li>Private groups will turn off mod systems if not effective / ergonomic / trustable, or else deplatform.</li>
  <li>For messy issues, cookie-cutter moderation can <a href="https://www.eff.org/wp/caught-net-impact-extremist-speech-regulations-human-rights-content">support violence by hiding its proof</a>. Or like <a href="https://twitter.com/KatMurti/status/1276183164109697028">whereâ€™s the parler for breastfeeding</a>?</li>
</ul>

<p>Every community needs moderation.
Some get away without it because they moderate membership rather than content â€“
small workplaces, for example, have relatively informal content moderation processes, but can fire you.</p>

<p>This isnâ€™t just a facebook / twitter issue anymore â€“ itâ€™s a problem for anyone with a supply of eyeballs and UGC or DM features, like <a href="https://www.washingtonpost.com/technology/2020/11/07/pinterest-linkedin-election-disinfo/">pinterest and linkedin</a>.
The older and funnier version of this is the <a href="https://www.managingcommunities.com/2015/06/04/lego-universes-penis-problem-and-why-moderation-efforts-arent-hopeless/">lego MMOâ€™s penis problem</a> â€“
they â€¦</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://abe-winter.github.io/only/fans/2020/11/29/everything-in-moderation.html">https://abe-winter.github.io/only/fans/2020/11/29/everything-in-moderation.html</a></em></p>]]>
            </description>
            <link>https://abe-winter.github.io/only/fans/2020/11/29/everything-in-moderation.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25246733</guid>
            <pubDate>Sun, 29 Nov 2020 18:01:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Study links mindfulness and meditation to narcissism and â€œspiritual superiorityâ€]]>
            </title>
            <description>
<![CDATA[
Score 58 | Comments 54 (<a href="https://news.ycombinator.com/item?id=25245512">thread link</a>) | @Bologo
<br/>
November 29, 2020 | https://www.psychnewsdaily.com/study-links-mindfulness-meditation-to-narcissism-and-spiritual-superiority/ | <a href="https://web.archive.org/web/*/https://www.psychnewsdaily.com/study-links-mindfulness-meditation-to-narcissism-and-spiritual-superiority/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-5234" role="main"><div><div><div><p><strong>A <a rel="noreferrer noopener" href="https://onlinelibrary.wiley.com/doi/abs/10.1002/ejsp.2721" target="_blank">new study</a> has found that some popular forms of spiritual training â€” such as energy healing, aura reading, and, to a lesser degree, mindfulness and meditation â€” correlate with both narcissism and â€œspiritual superiority.â€</strong></p><p>An implicit feature of spiritual training is that it allows its adherents to distance themselves from their egos, and thereby from things such as the need for social approval or success. By encouraging self-compassion and non-judgmental self-acceptance, spiritual training should presumably make people less concerned with such things.</p><p>But as a new paper explains, spiritual training may have the opposite effect. Namely, spiritual training might in fact enhance peopleâ€™s need to feel â€œmore successful, more respected or more loved,â€ as the authors Roos Vonk and Anouk Visser write.</p><h2>The first study to measure spiritual superiority</h2><p>No previous studies had specifically examined topic, which prompted Roos Vonk and Anouk Visser to investigate. Their <a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/ejsp.2721" target="_blank" rel="noreferrer noopener">new paper</a>, â€œAn Exploration of Spiritual Superiority: The Paradox of Selfâ€Enhancement,â€ appears in the <em><a href="https://onlinelibrary.wiley.com/journal/10990992" target="_blank" rel="noreferrer noopener">European Journal of Social Psychology</a></em>.</p><p>The authors developed a new measure they call â€œspiritual superiority.â€ It measures whether people feel superior to those â€œwho lack the spiritual wisdom they ascribe to themselves.â€<span data-ez-name="psychnewsdaily_com-medrectangle-4"></span></p><p>The measureâ€™s questionnaires ask people to respond on a scale of 1 to 7 to a series of statements. Example statements include â€œI am more in touch with my senses than most others,â€ â€œI am more aware of what is between heaven and earth than most people,â€ and â€œThe world would be a better place if others too had the insights that I have now.â€</p><h2>Spiritual guidance, supernatural overconfidence, and self-worth</h2><p>The authors also created three scales that they hypothesized would correlate with spiritual superiority.</p><p>The first scale, â€œspiritual guidance,â€ relates to how much people try to help others acquire the same wisdom they have acquired. It includes statements such as â€œI help others whenever possible on their path to greater wisdom and insight,â€ â€œI gladly help others to acquire my insights too,â€ and â€œI am patient with others, because I understand it takes time to gain the insights that I gained in my life and my education.â€</p><p>The second scale is â€œsupernatural overconfidence,â€ and it encompasses self-ascribed abilities in the paranormal domain. Example statements include â€œI can send positive energy to others from a distance,â€ â€œI can get in touch with people who are deceased,â€ and â€œI can influence the world around me with my thoughts.â€</p><p>The third scale, â€œspiritual contingency of self-worth,â€ measures how much a personâ€™s self-esteem is derived from their spirituality. Sample statements include â€œMy faith in myself increases when I acquire more spiritual wisdomâ€ and â€œWhen I gain new spiritual insights, this increases my self-worth.â€</p><p>In the three studies described below, the researchers found that their scale of spiritual superiority is a valid instrument. Moreover, it correlates significantly with the other three scales. It also correlates significantly with narcissism, selfâ€esteem, and other psychological variables. Finally, it also correlates, to varying degrees, with diverse forms of spiritual training.</p><h2><strong>Assessing spiritual superiority</strong></h2><p>For the first of the three studies included in the current paper, Vonk and Visser recruited 533 participants. They found them by contacting schools and spiritual centers that offer courses in subjects such as mindfulness and <a href="https://en.wikipedia.org/wiki/Energy_medicine" target="_blank" rel="noreferrer noopener">energetic training</a>.</p><p>The participants in this first study were about 75% female, with an average age of 51. They indicated that they were currently following some form of spiritual training. The types mentioned included <a href="https://www.psychnewsdaily.com/category/mental-health/mindfulness/" target="_blank" rel="noreferrer noopener">mindfulness</a>, meditation, energetic therapy, reading/healing aura, haptotherapy, reiki, and others.</p><p>The respondents filled in the questionnaires described above, and also answered questions about their age, sex, education, religion, and spiritual training.</p><p>The researchers found that â€œspiritual superiorityâ€ correlated significantly with self-esteem, mindfulness, supernatural overconfidence, and spiritual guidance.</p><p>As the authors predicted, these correlations were strongest for participants following forms of â€œenergeticâ€ training. These participants rated higher than the <a href="https://amzn.to/36jmlSH" target="_blank" rel="noreferrer noopener sponsored nofollow">mindfulness/meditation</a> students on all of the superiority-related scales, especially on the scale of supernatural overconfidence.</p><p>This makes sense, the authors write, as energetic training is meant to develop supernatural skills. This likely attracts students who already believe they have talents in this area.</p><p>Likewise, the training itself might further enhance their confidence. This is because no objective performance standards can conclusively demonstrate they are not in fact paranormally gifted.</p><h2><strong>What about people who donâ€™t follow spiritual training</strong>?</h2><p>The second study broadened the pool of respondents to include people who are not currently undergoing spiritual training. The goal was to compare their results on the spiritual superiority scale to those of the spiritual training students.</p><p>For this study, the researchers recruited 2,223 participants via a Dutch popular psychology magazine. Of these, 1960 were women. Their ages ranged from 15 to 82, with an average age of 41.</p><p>About a third had never followed any spiritual training; another third had followed mindfulness or meditation training. About 10% had followed some form of energetic training (including aura healing/reading). Another 10% had followed other kinds of spiritual training.</p><p>The result of this second study also showed that â€œspiritual superiorityâ€ significantly correlates with all the other measures. Furthermore, it also found the same pattern in Study 1. Namely there was a gradual increase in spiritual superiority as one moved from the â€œno spiritual trainingâ€ group to the â€œmindfulness trainingâ€ group to the â€œenergetic trainingâ€ group. And again, the results for the â€œenergeticâ€ group were much higher than for both the â€œmindfulnessâ€ and the â€œno-trainingâ€ groups.</p><h2>Correlations with <strong>narcissism</strong></h2><p>Study 3 tested the hypothesis that spiritual superiority is related to narcissism. As the researchers explain, past research has used the term â€œspiritual narcissism,â€ but none those studies empirically measured it.</p><p>For this study, the authors did not measure â€œagentic narcissismâ€ (for example, â€œI am more special than others and deserve special privilegesâ€), but rather â€œ<a href="https://www.psychologytoday.com/us/blog/tech-support/201605/the-communal-narcissist-another-wolf-wearing-sheep-outfit">communal narcissism</a>,â€ which describes people who think of themselves as more nurturing and empathic than others. Example statements that characterize this trait include â€œI have a very positive influence on othersâ€ and â€œI am generally the most understanding person.â€</p><p>This study recruited 965 participants via various channels. These included a Facebook page about psychology, spiritual schools, and participants who were not able to participate in the previous two studies due to a lack of space. The final sample included about 88% women, aged 19-79, with an average age of 46.</p><p>The participants answered the questionnaires for spiritual superiority and spiritual guidance, as well as several existing scales related to humility and overconfidence, a short 7-item version of the <a href="https://pubmed.ncbi.nlm.nih.gov/22889074/" target="_blank" rel="noreferrer noopener">Communal Narcissism scale</a>, and a three-item self-esteem scale.</p><p>The researchers found that the correlation between spiritual superiority and narcissism was 0.47. This is significantly stronger than the correlation with self-esteem. And once again, the same pattern emerged in terms of the type of spiritual training that the participants followed. The weakest correlations were among subjects with no spiritual training, and the highest for those who practiced energetic training. The mindfulness/meditation group was in between, though it was considerably closer to the â€œno-trainingâ€ group than to the â€œenergeticâ€ group.</p><h2><strong>Why t</strong>he link between <strong>spiritual superiority and narcissism</strong>?</h2><p>The authors argue that the lack of objectivity in the spiritual domain plays a role here. â€œLike religiosity, spirituality is a domain that seems like a safe and secure investment for self-worth,â€ they write. â€œOneâ€™s spiritual attainments allow lots of room for wishful thinking, thus easily lending themselves to the grip of the self-enhancement motive.â€</p><p>And because spiritual matters are generally â€œelusive to external objective standards,â€ that makes them a â€œsuitable domain for illusory beliefs about oneâ€™s superiority.â€</p><p>The results of these three studies do not imply any casual direction; the authors suggest the causal arrow may work in both directions. On one hand, people may use spirituality as a self-esteem booster: it allows them to see themselves as special, and they can achieve progress in the spiritual domain relatively easily, as there are no objectively measurable outcomes (in contrast to, for example, sports, academic success, or wealth accumulation).</p><p>On the other hand, spiritual training may attract people who already feel superior. And the â€œextensive exploration of oneâ€™s personal thoughts and feelingsâ€ that spiritual training encourages â€œmay be particularly appealingâ€ to <a href="https://amzn.to/3lhtAhZ" target="_blank" rel="noreferrer noopener sponsored nofollow">narcissists</a>, the authors write.</p><h2>Towards genuine spiritual growth</h2><p>The people who agreed to take part in this research might not represent spirituality students in general. â€œThe question is whether a truly enlightened person would even participate in our studies,â€ the authors write. â€œWould such a person be interested in or even capable of answering all these â€˜meâ€™ questions?â€</p><p>GIn any case, the researchers hope that future research can â€œreveal more insights into the effects of spiritual training, and possibly the conditions and personality characteristics that facilitate genuine spiritual growth.â€</p><hr><p><strong>Study:</strong> â€œ<a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/ejsp.2721">An Exploration of Spiritual Superiority: The Paradox of Selfâ€Enhancement</a>â€œ<br><strong>Authors: </strong>Roos Vonk and Anouk Visser<br><strong>Published in:</strong> <em><a href="https://onlinelibrary.wiley.com/journal/10990992" target="_blank" rel="noreferrer noopener">European Journal of Social Psychology</a></em><br><strong>Publication date:</strong> October 1, 2020<br><strong>DOI:</strong> <a href="https://doi.org/10.1002/ejsp.2721">https://doi.org/10.1002/ejsp.2721</a><br><strong>Photo: </strong>by <a href="https://pixabay.com/users/kalyanayahaluwo-1767926/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=5353620">Bhikku Amitha</a>&nbsp;via&nbsp;<a href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=5353620">Pixabay</a>&nbsp;</p><p>For a weekly summary of the latest psychology news, subscribe to our <a href="https://www.psychnewsdaily.com/the-psych-news-weekly-newsletter/" target="_blank" rel="noreferrer noopener">Psych News Weekly â€¦</a></p></div></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.psychnewsdaily.com/study-links-mindfulness-meditation-to-narcissism-and-spiritual-superiority/">https://www.psychnewsdaily.com/study-links-mindfulness-meditation-to-narcissism-and-spiritual-superiority/</a></em></p>]]>
            </description>
            <link>https://www.psychnewsdaily.com/study-links-mindfulness-meditation-to-narcissism-and-spiritual-superiority/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25245512</guid>
            <pubDate>Sun, 29 Nov 2020 15:09:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Little Things That Made Amiga Great]]>
            </title>
            <description>
<![CDATA[
Score 225 | Comments 189 (<a href="https://news.ycombinator.com/item?id=25245206">thread link</a>) | @eitland
<br/>
November 29, 2020 | https://datagubbe.se/ltmag/ | <a href="https://web.archive.org/web/*/https://datagubbe.se/ltmag/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>



<p><b>A deep dive into a selection of ingenious AmigaOS features.</b></p>

<p><i>Autumn 2020</i></p>

<h2 id="toc">Table of Contents</h2>

<ul>
  <li><a href="#intro">Introduction</a></li>
  <li><a href="#jargon">Jargon buster</a></li>
  <li>
    <a href="#littlethings">The Little Things</a>
    <ul>
      <li><a href="#ramdisk">The RAM Disk</a></li>
      <li><a href="#raddisk">The RAD Disk</a></li>
      <li><a href="#propscroll">Proportional scroll bars</a></li>
      <li><a href="#editors">The Text Editors</a></li>
      <li><a href="#arexx">ARexx</a></li>
      <li><a href="#nocd">No CD</a></li>
      <li><a href="#filesys">File Systems</a></li>
      <li><a href="#assigns">Assigns</a></li>
      <li><a href="#libs">Libraries</a></li>
      <li><a href="#asl">ASL</a></li>
      <li><a href="#datatypes">Datatypes</a></li>
      <li><a href="#readargs">ReadArgs</a></li>
      <li><a href="#guide">AmigaGuide</a></li>
      <li><a href="#installer">Installer</a></li>
      <li><a href="#filestruct">Standardized File Structure</a></li>
      <li><a href="#resident">Resident Programs</a></li>
      <li><a href="#reqchoice">RequestChoice</a></li>
      <li><a href="#infofiles">.info Files</a></li>
    </ul>
  </li>
  <li><a href="#closing">Closing words</a></li>
</ul>

<h3 id="intro">Introduction</h3>

<p>
To most people, the Amiga is probably synonymous with the Amiga 500 and that 
machine was, above all, a video game: something into which you plonked 
3.5" floppy disks that transported you to strange, wonderful worlds and 
hours of fun. To this group, the gamers, the operating system wasn't 
important. They probably booted Workbench 1.3 
only once, took a good look at the garish blue and orange interface,
and decided that enough was enough, before going back to blasting enemies 
in Silkworm.
</p>

<p>
And why not? The machine was great for games. There are tons of great 
texts about the groundbreaking audio and video capabilities of the 
Amiga.
</p>

<p>
This text is not one of those.
</p>

<p>
This text is about the later versions of AmigaOS produced by Commodore, 
from 2.0 to 3.1. While these newer versions (with majors released in 1990 
and 1992, respectively) certainly carried the Amiga heritage with pride 
and were - mostly - backwards compatible, the advent of AmigaOS 2.0 
marked a paradigm shift. The shift is best symbolized by the fact that 
AmigaBASIC - the ubiquitous and mandatory language of any 
self-respecting eighties home computer - was ditched and replaced by 
ARexx, a professional scripting language without any kind of graphics or 
sound features whatsoever.
</p>

<p>
This paradigm shift is also why so many of us who had the good fortune 
to come across those versions clung to the Amiga so desperately. A lot
of us stuck with it
well into the late nineties, years after Commodore's demise. And we were
fierce: if 
you think Apple fanboys are annoying today, be very happy you didn't meet an 
Amiga zealot in 1995. Things got personal quickly. It was downright ugly.
</p>

<p>
I still think there were some grounds for our fanaticism, though.
</p>

<p>
In a time when home PC:s were single tasking DOS boxes with 8 character 
file names and Ataris and Macs were single tasking GUI boxes, hampering
any hacker  with their glaring lack of a CLI, the Amiga was a champion of both 
worlds: It combined the CLI and GUI, leveraging both their strengths.
But there was more to it than that, something that's hard to convey
in so many words.
</p>

<p>
Many a time have I come across exasperated Amiga users who, on some 
online forum, tries to explain the greatness of the Amiga's operating 
system in a few short sentences. It often, quite understandably, boils 
down to something akin to "It's like UNIX", which I always think is 
unfair to both of the systems.
</p>

<p>
Sure, it was an early multitasking system with a capable command line. 
At the same time, it was also a mature and coherent desktop environment 
with levels of user friendliness much more like today's MacOS X than any 
traditional UNIX. But, contrary to today's MacOS, it never mollycoddled the
end user. It opened the machine up, rather than closing certain parts off.
</p>

<p>
Unlike UNIX, AmigaOS is a system designed for home computer use, lacking a 
lot of what makes UNIX so popular: memory protection, multi user 
support, source code portability and built in networking support.
</p>

<p>
They're very much alike in one aspect, though. Like UNIX, the Amiga's 
operating system is a collection of a lot of little strokes of genius 
that come together to make it bigger than the sum of its parts.
</p>

<p>
I invite you to explore this ingenuity with me. But first, let's get the 
terminology sorted.
</p>

<h3 id="jargon">Jargon buster</h3>

<p>
The Amiga's operating system has been called a lot of things by a lot of 
people, because it consists of many components that different types of 
users interacted more or less with. Let me try to clear things up a bit:
</p>


<dl>
<dt>AmigaOS</dt>

<dd>
This was never an official name during the Commodore days, but it's a 
handy way of describing all of the components below as a whole.
</dd>

<dt>Kickstart</dt>

<dd>
This is basically the firmware of the Amiga, residing in the ROM chip. 
On version 2.0 and up, the ROM chip was 512 kB large and contained not 
only code for self tests and bootstrapping but also quite sizable 
portions of the other parts of AmigaOS.
</dd>

<dt>AmigaDOS</dt>

<dd>
This is, roughly speaking, the command line interface, device drivers, 
file system management and so on. It was originally based on TRIPOS, a 
heritage that still shows to this day. (There are newer versions of AmigaOS
than 3.1, but this text will only cover the ones released by Commodore.)
</dd>

<dt>Intuition</dt>

<dd>
Best likened to a modern desktop compositor, Intuition handles screen 
updates and manages windows. The custom sound and video chips in the 
Amiga had mostly female names (Paula, Denise and later Alice), so I 
suppose Intuition is a fitting name for an abstraction layer that lets 
the OS interface with them.
</dd>

<dt>Workbench</dt>

<dd>
This is often used interchangeably with "AmigaOS" but it's really the 
name of just the desktop environment - which is a workbench, not a 
desktop: Programs are called tools, folders a called drawers and data 
files are called projects.
</dd>

</dl>

<h4>Other terminology</h4>

<dl>

<dt>Requesters</dt>

<dd>
Not really a major part of the OS per se, a requester is the Amiga's 
name for a dialog box. A "file requester" is a file selection dialog, 
for example. I still often use this term to describe any dialog on any 
platform, much to the confusion of friends and colleagues. Old habits 
die hard.
</dd>

<dt>Devices</dt>

<dd>
Devices, much like in UNIX, usually represent peripherals attached to the 
computer, such as storage media, printers, etc. The Amiga has a number 
of built-in devices that are automatically mounted,
for example the internal floppy drive, <code>DF0:</code>
and  the serial and parallel ports, <code>SER:</code> and <code>PAR:</code>
respectively. Other 
common devices are <code>DF1:</code>, the first external floppy drive,
<code>DH0:</code>, the 
common device name given to the bootable hard drive partition, and 
<code>CON:</code>, the text console.
There are also devices that can't
be mounted but only
be accessed using programming languages, such as <code>timer.device</code>
which is used to interface with hardware clocks.
</dd>

<dt>Volumes</dt>

<dd>
Mounted devices (such as <code>DF0</code>, <code>DF1</code>, <code>DH0</code>)
can contain a volume. In the 
case of <code>DH0:</code>, a bootable hard drive partition,
the volume is fixed and 
is represented by the name of the partition, such as <code>System:</code> or 
<code>Boot:</code>.
If you insert the Deluxe Paint program disk into the internal 
floppy drive, the current volume in device <code>DF0:</code>
will be <code>DPaint:</code>.
</dd>

</dl>


<h2 id="littlethings">The Little Things</h2>

<p>
<a href="https://datagubbe.se/ltmag/gfxs/cleanboot.png">
<img src="https://datagubbe.se/ltmag/gfxs/cleanboot.png" alt="The Amiga Workbench after a clean boot.">
</a>
</p>
<p>
<i>The Amiga Workbench after a clean boot. To the left are device icons,
for the RAM disk and hard drive partitions. The other icons represent various
applications, placed on the desktop for easy access.
Click the image for full resolution.</i>
</p>

<h3 id="ramdisk">The RAM Disk</h3>

<p>
The Amiga always has a RAM disk ready for use and the device name is 
always <code>RAM:</code>. No mounting, no third party software - it just sits 
there, waiting. That's clever in its own right, but the really ingenious 
part about it is that it's dynamically allocated. That means the size of the 
RAM disk corresponds to the amount of free memory currently available on 
the system, and that it never takes up more memory than is needed to
accommodate the files currently stored on it.
</p>

<p>
A RAM disk might sound esoteric today, but in the days of slow 
mechanical hard drives and floppy disks, it was a godsend for unpacking 
archives, running test compiles and storing temporary working documents.
</p>

<p>
The downside is that every time you reboot your computer, all the 
contents of the RAM disk are lost. Which brings us to...
</p>

<h3 id="raddisk">The RAD Disk</h3>

<p>
RAD, which (somehow) stands for Recoverable Ram Disk, is another 
testament to the flexibility and ingenuity of AmigaOS. The RAD disk is a 
fixed size RAM disk that can not only survive reboots but also itself
be booted from. It can be used as a small but extremely fast mini hard
drive, or  for extracting disk images to, for checking out their contents.
</p>

<h3 id="propscroll">Proportional scroll bars</h3>

<p>
A proportional scroll bar is a scroll bar that grows and shrinks to 
reflect the size of the scrollable content it represents:
</p>

<p>
<a href="https://datagubbe.se/ltmag/gfxs/propscroll.png">
<img src="https://datagubbe.se/ltmag/gfxs/propscroll.png" alt="Screenshot of proportional scroll bars">
</a>
</p>
<p>
<i>Click the image for full resolution.</i>
</p>

<p>
Highlighting a feature like this might 
seem like a silly point to make, because today all scroll bars are 
proportional. Not so in the bad old days: Microsoft 
didn't implement them until Windows 95 and Apple, as far as I know,
didn't make the move until MacOS 9 in 1999. In a time when computer mice 
had no scroll wheels, this was a nifty feature indeed.
</p>

<h3 id="editors">The Text Editors</h3>

<p>
<a href="https://datagubbe.se/ltmag/gfxs/ed.png">
<img src="https://datagubbe.se/ltmag/gfxs/ed.png" alt="Screenshot of Ed in full screen mode.">
</a>
</p>
<p>
<i>
Above, Ed is used to edit S:Shell-Startup, the equivalent of .bashrc for
AmigaShell. The editor is currently in command mode, getting ready to delete
a line of text.
Click the image for full resolution.</i>
</p>

<p>
AmigaOS shipped with three different text editors: Ed, Edit and MEmacs. 
The latter is a port of, you guessed it, Micro Emacs, and will of course 
appeal to Emacs fans. The other two are sort of curiously named: Edit is 
a line editor mostly resembling ed on UNIX. The Amiga's Ed, on the other 
hand, is a full screen editor with both mouse support and an 
extensive command language. Amiga Ed is probably best likened with vi.
</p>

<p>
All three of them are capable and powerful editors. Both MEmacs and Ed 
make use of the Amiga's drop down GUI menus and feature support for 
macros and extensive configuration.
</p>

<p>
Ed's command mode is, as mentioned earlier, somewhat reminiscent of vi. 
Consider the following examples:
</p>

<p>
Change the next three occurrences of "data" to "gubbe":<br>
<code>3 E/data/gubbe/</code>
</p>

<p>
Move to top of file, repeat (RP) replace of "data" with "gubbe" until 
end of file:<br>
<code>T; RP E/data/gubbe/</code>
</p>

<p>
Move to top of file, find all occurrences of "gubbe" and insert three 
blank lines after every occurrence, repeat until end of file:<br>
<code>T; RP (F /gubbe/; 3A//)</code>
</p>

<p>
Ed also has something called an ARexx port, which completely </p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://datagubbe.se/ltmag/">https://datagubbe.se/ltmag/</a></em></p>]]>
            </description>
            <link>https://datagubbe.se/ltmag/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25245206</guid>
            <pubDate>Sun, 29 Nov 2020 14:14:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pijul â€“ The Mathematically Sound Version Control System Written in Rust]]>
            </title>
            <description>
<![CDATA[
Score 89 | Comments 63 (<a href="https://news.ycombinator.com/item?id=25245129">thread link</a>) | @initialcommit
<br/>
November 29, 2020 | https://initialcommit.com/blog/pijul-version-control-system | <a href="https://web.archive.org/web/*/https://initialcommit.com/blog/pijul-version-control-system">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
			                <div>
			                    <p><img src="https://initialcommit.com/img/initialcommit/pijul-version-control-system.png" title="Pijul - The Mathematically Sound Version Control System Written in Rust" alt="Image of Pijul - The Mathematically Sound Version Control System Written in Rust">
			                    </p>
			                    
			                    
			                    	
			                    
			                    
			                    
			                    <h2>Introduction</h2>
<p>In our <a href="https://initialcommit.com/blog/Technical-Guide-VCS-Internals">Evolution of Version Control System Internals</a> post, we covered the inner workings of many version control systems, both historical and current. However, we haven't really covered <em>the possible future</em> of version control.  How will this field evolve going forward?</p>
<p>Although Git is dominant now and will certainly remain a strong player for years to come, will better tools be created? Pijul could be a strong contender.</p>
<p>In this article, we'll discuss Pijul - an alpha stage version control system that is gaining attention in the community.</p>
<h2>Background</h2>
<p><a href="https://pijul.org/">Pijul</a> is a VCS written by Pierre-Ãƒâ€°tienne Meunier and Florent Becker. After releasing a number of experimental prototypes between 2015 and 2020, the first alpha version was released in November 2020. By operating on diffs <em>and</em> on versions at the same time, Pijul combines aspects of third-generation VCS such as <a href="https://initialcommit.com/blog/Technical-Guide-VCS-Internals#git">Git</a> and <a href="https://initialcommit.com/blog/Evolution-of-VCS-Internals-2/#darcs">Darcs</a>.</p>
<p>Pijul is written in <a href="https://www.rust-lang.org/">Rust</a> and is currently in alpha stage development. The algorithms and formats underlying Pijul's design were recently overhauled for performance and robustness of the system, and the team is working on making it as stable as possible after these updates.</p>
<p>Pijul's architecture and design methodology was influenced by the <a href="http://darcs.net/">Darcs</a> project, which we <a href="https://initialcommit.com/blog/Evolution-of-VCS-Internals-2/#darcs">covered in detail here</a>.</p>
<p>One distinctive feature of Pijul (shared with Darcs) is <strong>change commutation</strong>, whereby changes that could be recorded independently can be applied in any order, without affecting the result.</p>
<p>However, unlike Darcs, which operates on changes only, Pijul applies changes to an abstract data structure representing generalized files, allowing it to maintain a notion of version as well as a notion of change between versions. This has a number of advantages, in particular in terms of performance and in terms of mathematical soundness.</p>
<p>The source code for Pijul can be found at <a href="https://nest.pijul.com/pijul/pijul">https://nest.pijul.com/pijul/pijul</a>. The <a href="https://nest.pijul.com/">Pijul Nest</a> is a remote hosting platform for Pijul repositories. Think of it as Pijul's version of GitHub or BitBucket.</p>
<h2>Purpose</h2>
<p>We already have <a href="https://git-scm.com/">Git</a>, the most popular and functional VCS on Earth. Git handles all of the features we could expect from a solid VCS (in fact it sets the benchmark for these features), including:</p>
<ul>
<li>Intuitive method and interface for version tracking</li>
<li>Easily sharing work and collaborating remotely</li>
<li>Lightweight branching and merging</li>
<li>Fast performance and security features</li>
<li>A long list of tools for conveniently managing repositories depending on desired workflow and personal style</li>
</ul>
<p>We also have Darcs, a patch-centric perspective on version control with the following advantages:</p>
<ul>
<li>In Darcs, a repository can be better thought of as a "set of patches" - applied as needed - as opposed to a linear history of dependent changesets.</li>
<li>The Darcs model preserves the <strong>identity</strong> of patches during operations like rebasing and cherry-picking, whereas Git sometimes needs to rewrite history due to chained identifiers that depend on the order of application. Preserving a change's ID can be considered a more natural approach.</li>
<li>Darcs has a very well designed interface and command set that provides verbose output to help speed up the learning curve for users and clarify what actions the users are taking.</li>
<li>Patch bundles can be easily transmitted via email to be applied by the remote repository owner.</li>
</ul>
<p>So since we have Git and Darcs, why do we need Pijul? Pijul was created to solve unrelated problems that exist in Git and Darcs.</p>
<p>Pijul uses a patch-centric model similar to Darcs, which doesn't require history to be re-written when reordering, cherry-picking, or otherwise reorganizing patches. All patches retain their identities permanently regardless of their context, order, operations performed, or team workflow. This is a very elegant solution and arguably a more natural way to create such a system. This is in contrast to Git in which certain operations such as rebases and cherry-picks can change commit ID's (and other identifiers), even if the content itself doesn't change.</p>
<p>Furthermore, subsequent cherry-picks from a remote branch in Git can lead to unnatural conflicts due to the rewriting of the initial cherry-picked commit's ID. Pijul avoids this problem completely as patches always retain their identity, regardless of their location in a branch.</p>
<p>So what about Darcs? In certain scenarios, Darcs runs into performance issues such as the <a href="http://darcs.net/FAQ/Performance#is-the-exponential-merge-problem-fixed-yet">exponential merge problem</a>. This issue causes certain merges to increase exponentially in difficulty, effectively preventing these merges from being performed. Pijul has solved this problem.</p>
<p>As is summed up nicely in <a href="https://pijul.org/posts/2020-11-07-towards-1.0#are-edge-labels-minimal">Pierre Meunier's recent post <strong>Toward's 1.0</strong></a>: "Our goals are to find the smallest possible system, both for reasons of mathematical aesthetics (why store useless stuff?) and the other one for performance."</p>
<p>Pijul's main purpose is to be an efficient VCS based on a sound mathematical theory, guaranteeing that basic properties of changes are always maintained. This consistency bolsters peace of mind in the software development process. With Pijul, developers can be 100% confident that the code they reviewed is the code that gets merged, which is not necessarily the case in Git and Mercurial. Even though file reshuffles do not seem to happen very often in these existing VCS, (and some of them are caught by tests), there are a few statistical studies highlighting their occurrence, and the security implications are huge.</p>
<p>One particular goal of Pijul is to model conflicts as normal states of collaboration, so that conflicts are resolved by normal changes, valid even for the same conflicts in any other context.</p>
<h2>Architecture</h2>
<p>A Pijul repository has a <code>pristine</code> directory, containing a number of <strong>channels</strong>. At any given time, a channel contains a set of unordered <strong>changes</strong>, which can also be seen as a version, since the order of independent changes does not matter in Pijul.</p>
<p>The "working copy" is simply the set of files directly editable by the user, and the correspondence between the working copy and the pristine is done by a <strong>file tracking tree</strong>, which is just a mapping between working copy files and files as stored in the pristine.</p>
<p>Moreover, changes <strong>can</strong> (but don't need to) depend on each other, and do so explicitly (see the section about the "sample change" below), in the sense that each change is uniquely identified by its cryptographic hash, and dependencies are explicit hashes of other changes. The <strong>minimal dependencies</strong> are enforced by Pijul to make sure that text edits make sense. For example, a change editing a file or a paragraph depends on the change that introduced that file or paragraph. This is because it doesn't make sense to change a piece of content that was never added in the first place, so the patch that added the content must be present for the patch that changed it to have meaning. Additionally, the user may specify extra, language-specific dependencies to model the edits more accurately, for example the dependency between introducing a function and using it in another file or another part of the same file. This is an extremely powerful feature.</p>
<p>If desired, this scheme of dependencies between changes allows Pijul to mimic the strict sequential ordering of commits used by Git and Mercurial, turning Pijul into a sort of "Git, but with mathematically sound merges". The downside of using Pijul like this is that changes relative to independent features of the project might need to be more carefully split between different channels, like Git branches. The "plain", or "standard" Pijul way is to try and record changes that are as independent as possible, and keep them on the same channel, since independent changes can always be split later on without changing their identity (i.e. their hash). Channels are useful for different "flavors" of the project, and one can push the same changes to multiple channels without modifying these changes.</p>
<h2>Q&amp;A with the Creator</h2>
<p>We wanted to get inside the head of Pierre-Ãƒâ€°tienne Meunier, the creator and lead developer of Pijul, so we <a href="https://initialcommit.com/blog/pijul-creator">asked him a series of questions related to his background and the creation of Pijul, and the direction of the version control field</a>. His answers were <strong>extremely</strong> interesting and worth a read (we split them into a separate post since they were fairly lengthy).</p>
<h2>Basic Commands</h2>
<p>One of Pijul's goals is to minimize the number of commands, so as to allow users to get a full understanding of the system as quickly as possible.</p>
<p>The commands are:</p>
<p><code>pijul init</code>: Creates a directory named <code>.pijul</code>, containing the following structure:</p>
<div>
    <pre><code>.pijul/
    changes
    config
    pristine
        db0
        db.lock</code></pre>
</div>
<p>Here, the meaningful things that get created are <code>db0</code>, which contains the pristine, in binary format, and a sample <code>config</code> file, editable in <a href="https://en.wikipedia.org/wiki/TOML">TOML format</a>.</p>
<p><code>pijul add &lt;filename.ext&gt;</code>: Adds a file to the repository's tracking list.<br>
<code>pijul remove &lt;filename.ext&gt;</code>:  Remove a file from the tracking list.<br>
<code>pijul mv &lt;filename1.ext&gt; &lt;filename2.ext&gt;</code>: Move and/or rename a file in the tracking list.<br>
<code>pijul ls</code>: Displays a list of currently tracked files.<br>
<code>pijul record</code> (or <code>pijul rec</code>): Creates a change and applies it to the pristine. Once we do that, the <code>.pijul/changes</code> gets populated with one change:</p>
<div>
    <pre><code>./
    file
    .pijul/
        changes
            ZN
                PGE4DJNVY4JAQABNSQYVF5LBFWNO6FRJI3LXX7E7EB4Y3NGGGQC.change
        config
        pristine
            db0
            db.lock</code></pre>
</div>
<p><code>pijul unrecord &lt;hash&gt;</code>: If no change depends on a change <code>hash</code>, we can also "undo" or "unapply" it using the <code>unrecord</code> command. For example, here our change's hash is <code>ZNPGE4DJNVY4JAQABNSQ...</code>, and we can use any unambiguous prefix of that hash, for example <code>pijul unrecord ZNPG</code>, or even <code>pijul unrecord Z</code> to undo it.<br>
<code>pijul reset</code>: Resets the repository to the state of a channel. Without any â€¦</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://initialcommit.com/blog/pijul-version-control-system">https://initialcommit.com/blog/pijul-version-control-system</a></em></p>]]>
            </description>
            <link>https://initialcommit.com/blog/pijul-version-control-system</link>
            <guid isPermaLink="false">hacker-news-small-sites-25245129</guid>
            <pubDate>Sun, 29 Nov 2020 14:01:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Made a Self-Quoting Tweet]]>
            </title>
            <description>
<![CDATA[
Score 476 | Comments 109 (<a href="https://news.ycombinator.com/item?id=25244872">thread link</a>) | @OisinMoran
<br/>
November 29, 2020 | https://oisinmoran.com/quinetweet | <a href="https://web.archive.org/web/*/https://oisinmoran.com/quinetweet">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<p><em>Or the real reason Twitter doesn't want you to have an edit button.</em></p>

<p>
I'll try to leave the pulp in here and keep this as chronological as I can. In that spirit, no tweets were harmed in the making of this post.
</p>

<p>
The original idea to make a tweet that quote tweets itself is from the 28<sup>th</sup> of May 2020â€”as recorded in Evernoteâ€”but I think had likely occurred to me earlier when considering what ramifications Twitter having an edit button would haveâ€”most notably being able to mislead, being able to vandalize someone's timeline post-retweet, and of course being able to edit your tweet to refer to itself.
</p>

<p>
Fundamentally the challenge is just correctly guessing what ID a given tweet is going to get, then appending that onto the URL for our profile and tweeting it.</p>

<p>
This initial note already had some background research done into determining how tweet IDs were generated, with a link to <a href="https://ws-dl.blogspot.com/2019/08/2019-08-03-tweetedat-finding-tweet.html">this article containing a useful breakdown of Twitter's Snowflake IDs</a>, so thanks to the author of that, Nauman Siddique.
</p>

<h3>Anatomy of a tweet ID</h3>
<p>
Twitter used to use sequential IDs but no longer do.
Public-facing sequential IDs have the drawback of making usage of your platform easy to estimate.
They are also hard to generate in a distributed fashion while preserving order.
</p>

<p>
From the link above we find that the new Twitter IDs (used for more than just tweetsâ€”for example, lists) are composed of three parts: a timestamp, a machine ID, and a sequence number, arranged like so:
</p>

<code><pre>TIMESTAMP MACHINE ID SEQUENCE NUM
41 BITS   10 BITS    12 BITS
000...000 0000000000 000000000000 
</pre></code>

<p>
These are then just stuck together and interpreted as a decimal number and look something like 1320553050730340354.
</p>

<p>
Brute-forcing the whole thing is not going to work here as there are so many possibilities, but thankfully the largest section is the timestamp, which should be easy enough to guess correctly.
This will likely just involve finding the delay between my program guessing an ID and Twitter assigning an ID to the generated tweet.
There will always be fluctuations here as we're dealing in milliseconds and both my computer and all of Twitter's system will be under varying loads.
However, it should be somewhat consistent, at least within a given timeframe.
Hopefully then we can just figure the other two out as they are much smallerâ€”having only 1024 and 4096 possibilities, compared to the timestamp's over 2 trillion (that's a lot of milliseconds).
</p>

<p>
I knew I'd likely have to do <em>some</em> spamming as I was not going to get it right on the first go, so I created a new account to spare my few but wonderful followers.
</p>

<h3>Why the name?</h3>
<p>
From Wikipedia:<br>
<em>
A quine is a computer program which takes no input and produces a copy of its own source code as its only output.
</em></p>
<p>
So it's only natural that a quinetweet would print its own URL, and thus hopefully quote tweet or retweet itself.
And naturally I set the profile photo to one of Quine himself, and the banner to a relevant Escher lithograph.
</p>


<h3>Tweeting with the API</h3>
<p>
I signed the new profile up for a <a href="https://developer.twitter.com/">developer account</a> to start tweeting programatically using Twitter's API. And began with their examples using <a href="https://github.com/twitter/twurl">twurl</a>.
</p>

<p>The first step is authorization with my shiny new API keys:</p>
<code><pre>twurl authorize --consumer-key CONSUMER_KEY \
                --consumer-secret CONSUMER_SECRET
</pre></code>

<p>And now we can get straight into tweeting:</p>
<code><pre>twurl -d 'status=Test tweet using the POST statuses/update endpoint' /1.1/statuses/update.json
</pre></code>
<p>Resulting in our beautiful first tweet:</p>
<blockquote><p lang="en" dir="ltr">Test tweet using the POST statuses/update endpoint</p>â€” quinetweet (@quinetweet) <a href="https://twitter.com/quinetweet/status/1308911113229209601?ref_src=twsrc%5Etfw">September 23, 2020</a></blockquote> 

<p>In the returned response there is quite a lot of information, but we only really care about the ID, in this case 1308911113229209601 which thankfully matches up with what shows up on Twitter's websiteâ€”they're not lying!</p>

<p>Okay, so now let's quote tweet the previous tweet:</p>

<code><pre>twurl -d 'status=https://twitter.com/quinetweet/status/1308911113229209601' /1.1/statuses/update.json
</pre></code>

<p>Beautiful! I can almost taste the recursion already.</p>
<blockquote><p lang="und" dir="ltr"><a href="https://t.co/FXps7y4yMw">https://t.co/FXps7y4yMw</a></p>â€” quinetweet (@quinetweet) <a href="https://twitter.com/quinetweet/status/1308912279853903872?ref_src=twsrc%5Etfw">September 23, 2020</a></blockquote> 

<p>Now to investigate the behaviour of the various components of the ID, let's do two tweets in quick succession, using a simple Bash loop:</p>

<code><pre>for i in {1..2}; do twurl -d 'status=Quick succession test' /1.1/statuses/update.json; done
</pre></code>

<p>
To which we're met with a warning from Twitter about the second attempt being a duplicateâ€”so apparently Twitter do have <em>some</em> protection against unoriginality.
</p>

<p>
No worries, simply adding a variable should fix this:
</p>

<code><pre>for i in {1..2}; do twurl -d 'status=Quick succession test <span>$i</span>' /1.1/statuses/update.json; done
</pre></code>

<p>
Oh no! This is also getting the same duplicate warning, what's going on?
Let's check Twitter:
</p>

<blockquote><p lang="en" dir="ltr">Quick succession test <a href="https://twitter.com/search?q=%24i&amp;src=ctag&amp;ref_src=twsrc%5Etfw">$i</a></p>â€” quinetweet (@quinetweet) <a href="https://twitter.com/quinetweet/status/1309237764035051520?ref_src=twsrc%5Etfw">September 24, 2020</a></blockquote> 

<p>
How embarrassingâ€”we've accidentally linked to <a href="https://en.wikipedia.org/wiki/Intelsat">Intelsat</a>'s stock ticker!
We should have used double quotes:
</p>

<code><pre>for i in {1..2}; do twurl -d <span>"</span>status=Quick succession test $i<span>"</span> /1.1/statuses/update.json; done
</pre></code>

<blockquote><p lang="en" dir="ltr">Quick succession test 1</p>â€” quinetweet (@quinetweet) <a href="https://twitter.com/quinetweet/status/1309237975868469248?ref_src=twsrc%5Etfw">September 24, 2020</a></blockquote> 
<blockquote><p lang="en" dir="ltr">Quick succession test 2</p>â€” quinetweet (@quinetweet) <a href="https://twitter.com/quinetweet/status/1309237977982345216?ref_src=twsrc%5Etfw">September 24, 2020</a></blockquote> 

<p>Finally! Now we can say we're programatically tweeting without completely lying.</p>

<p>
Okay now let's take a look at these last two IDs, splitting them into timestamp, machine ID, and sequence number:
</p>

<code><pre>1309237975868469248 -&gt; (312146657912, 375, 0)
1309237977982345216 -&gt; (312146658416, 362, 0)
</pre></code>

<p>
We see the second was posted 504&nbsp;ms after the first (from Twitter's point of view), the machine IDs differ by 13, and both the sequence numbers are 0. We might be able to get away with assuming the sequence number is most commonly 0. This is great news because it was the larger of the two non-timestamp components so greatly reduces the number of checks we'll have to make. The range for our brute forcing looks like it might be small enough after all!</p>

<p>While Bash was great to start off with, I'm more comfortable with Python, so...</p>

<h2>Let's start guessing some IDs</h2>
<p>I'm just going to post the final code here with a brief description of each function. I'm sure there are numerous ways the code could be improved (for one it should probably take the machine ID and other guesswork bits as arguments).</p>

<h3>tweet_id_from_timestamp</h3>
<p>This does roughly what it says on the tin, and was created by simply reversing the get_tweet_timestamp function that was helpfully shared in <a href="https://ws-dl.blogspot.com/2019/08/2019-08-03-tweetedat-finding-tweet.html">the article mentioned in the intro</a>, including Twitter's timestamp OFFSET that they had already worked out.</p>

<h3>tweet_id_to_parts</h3>
<p>This gets a tweet id and splits it up into the parts described above: the timestamp, machine ID, and sequence number.

</p><h3>compare_ids</h3>
<p>To see how badly off our guesses are, we'll need a function to compare the ID we guessed to the one Twitter actually assigned. While it might seem like a tweet ID is just one number and you might think you could just subtract the two to compare them, due to the nature of how they are created simply being off by one millisecond and getting everything else right would be lead your guess to be off by several million. For this reason it makes more sense to compare the individual parts so that is what we do here.</p>

<h3>guess_tweet_id</h3>
<p>Again, a simply named function that guesses a tweet ID based on the time it is called and another time offset and machine ID. Note here that we don't do anything about the sequence number as it was usually zero so there's not much point guessing anything else.</p>

<h3>guess</h3>
<p>This function actually does the posting of the tweets and will guess N different tweets in quick succession with the same time offset and machine ID. I kept N low enough so I could manually change the offsets and if they were very far off I wouldn't eat into the rate limit too much.</p>



<p>A non-gist version of the code is on Github <a href="https://github.com/OisinMoran/quinetweet/blob/main/quinetweet.py">here</a>.</p>

<h2>An idea that didn't work</h2>
<p>While manually adjustment of the offsets and machine ID was getting me kind of close, I thought it could be even better to do that automatically. If these values were time-sensitive, a program would be able to update them much faster than I could. I tried to do this by updating based on the mean error of the previous several responses, but this ended up not really working (maybe the median or mode would fare better here). It ended up being easier to just eyeball the differences and pick something reasonable, though I'm not entirely sure if I explicitly knowâ€”even nowâ€”what I was doing.</p>


<h2>Shit gets weird</h2>
<p>With that all done, I began the sport of just letting it run in short bursts until the rate limit (300 tweets per 3 hour window) forced me to go do something else. Who knew rate limits could be such an effective public health measure?</p>

<p>A strange and completely unexpected thing began to happen. In these quiet hours of the internet, some of the attempted self-quotes started linking to tweets from other accounts, mostly in South America and Japan! What was going on? All of the guessed URLs had the quinetweet account name hardcoded into them, so why and how were they linking to other tweets?</p>

<blockquote><p lang="und" dir="ltr"><a href="https://t.co/OOUKS9dwCp">https://t.co/OOUKS9dwCp</a></p>â€” quinetweet (@quinetweet) <a href="https://twitter.com/quinetweet/status/1309684115017527297?ref_src=twsrc%5Etfw">September 26, 2020</a></blockquote> 

<p>That is most certainly not my account. So what did we actually <em>try</em> to tweet here and what did it link to? Conveniently both of our accounts have ten character names so the URLs line up nicely in a monospaced font which makes visually comparing them even easier than normal.</p>

<code><pre>https://twitter.com/quinetweet/status/1309684114073808896
https://twitter.com/gzhdigital/status/1309684114073808896
</pre></code>

<p>Okay, wild! We guessed someone else's tweet ID! And as the IDs are time-dependent that means they were met with an instantaneous retweetâ€”creepy. Also, it seems like Twitter doesn't actually care about the username and just resolves URLs based on the tweet ID. I'm sure lots of people already knew that but it's new to me.</p>

<p>Let's try another, this time from the Pope: <a href="https://twitter.com/Pontifex/status/1107421599333007362">https://twitter.com/Pontifex/status/1107421599333007362</a></p>
<p>Okay this is pretty interesting, but back to the task at â€¦</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://oisinmoran.com/quinetweet">https://oisinmoran.com/quinetweet</a></em></p>]]>
            </description>
            <link>https://oisinmoran.com/quinetweet</link>
            <guid isPermaLink="false">hacker-news-small-sites-25244872</guid>
            <pubDate>Sun, 29 Nov 2020 12:53:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Raytracing in One Weekend (2016)]]>
            </title>
            <description>
<![CDATA[
Score 264 | Comments 68 (<a href="https://news.ycombinator.com/item?id=25244301">thread link</a>) | @fanf2
<br/>
November 29, 2020 | https://raytracing.github.io/books/RayTracingInOneWeekend.html | <a href="https://web.archive.org/web/*/https://raytracing.github.io/books/RayTracingInOneWeekend.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://raytracing.github.io/books/RayTracingInOneWeekend.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25244301</guid>
            <pubDate>Sun, 29 Nov 2020 10:43:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A better Kubernetes from the ground up]]>
            </title>
            <description>
<![CDATA[
Score 257 | Comments 149 (<a href="https://news.ycombinator.com/item?id=25243159">thread link</a>) | @mr-karan
<br/>
November 28, 2020 | https://blog.dave.tf/post/new-kubernetes/ | <a href="https://web.archive.org/web/*/https://blog.dave.tf/post/new-kubernetes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>
		<p><span>Written by</span>
        David Anderson
        <br>
        <span>on&nbsp;</span><time datetime="2020-11-28 00:00:00 +0000 UTC">November 28, 2020</time>
</p>
		


		

		<p>Recently I had a chat with the excellent <a href="https://timewitch.net/">Vallery Lancey</a>, about Kubernetes. Specifically, what we would do differently if we built something new, from the ground up, with no regard for compatibility with Kubernetes. I found that conversation so stimulating that I feel the need to write things down, so here we are.</p>

<p>Before we get started, I want to stress a few things.</p>

<ul>
<li>This is not a fully formed design. Some of these things may not work at all, or require significant redesign. Each section is one random piece of the entire puzzle.</li>
<li>These are not solely my ideas. Some I <em>think</em> are original, but like many things in the Kubernetes community itâ€™s the product of collective thinking. I know at least <a href="https://timewitch.net/">Vallery</a> and <a href="https://twitter.com/maisem_ali">Maisem Ali</a> have influenced my thinking at one time or another, and Iâ€™m forgetting many more. If you like an idea, it was a group effort. If you hate it, itâ€™s entirely mine.</li>
<li>Some of these things are polarizing. Iâ€™m designing something that makes <em>me</em> happy.</li>
</ul>

<h2 id="guiding-principles">Guiding principles</h2>

<p>My experience of Kubernetes comes from two very different places: authoring <a href="https://www.metallb.org/">MetalLB</a> for bare metal clusters, and operating a large fleet of clusters-as-a-service in <a href="https://cloud.google.com/kubernetes-engine">GKE SRE</a>. Both of these taught me that Kubernetes is extremely complex, and that most people who are trying to use it are not prepared for the sheer amount of work that lies between the marketing brochure and the system those brochures promise.</p>

<p>MetalLB taught me that itâ€™s not possible to build robust software that integrates with Kubernetes. I think MetalLB makes a damn good go of it, but Kubernetes still makes it far too easy to construct broken configurations, and far too hard to debug them. GKE SRE taught me that even the foremost Kubernetes experts cannot safely operate Kubernetes at scale. (Although GKE SRE does a spectacular job with the tools theyâ€™re given.)</p>

<p>Kubernetes is the C++ of orchestration software. Immensely powerful, includes all the features, looks deceptively simple, and <em>will</em> hurt you repeatedly until you join its priesthood and devote your life to its mysteries. And even then, the matrix of possible ways to configure and deploy it is so large that youâ€™re never on firm footing.</p>

<p>Continuing that analogy, my guide star is Go. If Kubernetes is C++, what would the Go of orchestration systems look like? Aggressively simple, opinionated, grown slowly and warily, and you can learn it in under a week and get on with what you were actually trying to accomplish.</p>

<p>With that, letâ€™s get going. Starting with Kubernetes, and with a license to completely and utterly break compatibility, what would I do?</p>

<h2 id="mutable-pods">Mutable pods</h2>

<p>In Kubernetes, pods are mostly (but not entirely) immutable after creation. If you want to change a pod, you donâ€™t. Make a new one and delete the old one. This is unlike most other things in Kubernetes, which are mostly mutable and gracefully reconcile towards the new spec.</p>

<p>So, Iâ€™m going to make pods be not special. Make them entirely read-write, and reconcile them like you would any other object.</p>

<p>The immediately useful thing I get from that is in-place restarts. If scheduling constraints and resource allocations havenâ€™t changed, guess what? SIGTERM runc, restart runc with different parameters, and youâ€™re done. Now pods look like regular old systemd services, that can move between machines <em>if necessary</em>.</p>

<p>Note that this doesnâ€™t require doing mutability at the runtime layer. If you change a pod definition, itâ€™s still mostly fine to terminate the container and restart it with a new configuration. The pod is still holding onto the resource reservation that got it scheduled onto this machine, so conceptually itâ€™s equivalent to <code>systemctl restart blah.service</code>. You could try to be fancy and make some operations actually update in place at the runtime level as well, but donâ€™t have to. The main benefit is decoupling scheduling, pod lifetime, and lifetime at the runtime layer.</p>

<h2 id="version-control-all-the-things">Version control all the things</h2>

<p>Sticking at the pod layer for a bit longer: now that theyâ€™re mutable, the next obvious thing I want is rollbacks. For that, letâ€™s keep old versions of pod definitions around, and make it trivial to â€œgo back to version Nâ€.</p>

<p>Now, a pod update looks like: write an updated definition of the pod, and it updates to match. Update broken? Write back version N-1, and youâ€™re done.</p>

<p>Bonus things you get from this: a diffable history of what happened to your cluster, without needing GitOps nonsense. By all means keep the GitOps nonsense if you want, it has benefits, but you can answer a basic â€œwhat changed?â€ question using only data in the cluster.</p>

<p>This needs a bit more design. In particular, I want to separate out external changes (human submits a new pod) from mechanical changes (some internals of k8s alter a pod definition). I havenâ€™t thought through how to encode both those histories and make both accessible to operators and automation. Maybe it could also be completely generic, wherein a â€œchangerâ€ identifies itself when submitting a new version, and you can then query for changes by or excluding particular changers (think similar to how label queries work at the minute). Again, more design needed there, I just know that I want versioned objects with an accessible history.</p>

<p>Weâ€™ll need garbage collection eventually. That said, changes to single pods should delta-compress really well, so my default would be to just keep everything until it becomes a truly dumb amount of data, and figure something out at that point. Keeping everything also acts as a useful mild pressure to avoid â€œdeath by a thousand changesâ€ in the rest of the system. Prefer to have fewer, more meaningful changes over a flurry of control loops each changing one field in pursuit of convergence.</p>

<p>Once we have this history, we can do some neat minor things too. For example, the node software could keep container images for the last N versions pinned to the machine, so that rollbacks are as fast as they can possibly be. With an accessible history, you can do this more precisely than â€œGC older than 30 days and hopeâ€. Generalizing, all the orchestration software can use older versions as GC roots for various resources, to make rollbacks faster. Rollbacks being the primary way of ending outages, this is a very valuable thing to have.</p>

<h2 id="replace-deployment-with-pinneddeployment">Replace Deployment with PinnedDeployment</h2>

<p>This is a short section to basically say that <a href="https://timewitch.net/">Vallery</a> knocked it out of the park with her <a href="https://timewitch.net/post/2019-12-30-pinneddeployments/">PinnedDeployment</a> resource, which lets operators explicitly control a rollout by tracking 2 versions of the deployment state. Itâ€™s a deployment object designed by an SRE, with a crisp understanding of what SREs want in a deployment. I love it.</p>

<p>This combines super well with the versioned, in-place pod updates above, and I really donâ€™t have anything to add. Itâ€™s clearly how multi-pod things should work. Thereâ€™s probably some tweaking required to adapt from the Kubernetes-constrained world to this new wonderful unconstrained universe, but the general design is perfect.</p>

<h2 id="explicit-orchestration-workflows">Explicit orchestration workflows</h2>

<p>The biggest issue I have with the â€œAPI machineryâ€ bits of Kubernetes is the idea of orchestration as a loose choreography of independent control loops. On the surface, this seems like a nice idea: you have dozens of little control loops, each focused on doing one small thing. When combined in a cluster, they indirectly cooperate with each other to push the state forward and converge on the desired end state. So, whatâ€™s the problem?</p>

<p>The problem is that itâ€™s entirely impossible to debug when it goes wrong. A typical failure mode in Kubernetes is that you submit a change to the cluster, then repeatedly refresh waiting for stuff to converge. When it doesnâ€™tâ€¦ Well, youâ€™re screwed. Kubernetes doesnâ€™t know the difference between â€œthe system has converged successfullyâ€ and â€œa control loop is wedged and is blocking everything else.â€ You can hope that the offending control loop posted some events to the object to help you, but by and large they donâ€™t.</p>

<p>At which point your only option is to cat the logs of every control loop that might be involved, looking for the one that was wedged. You can make this a bit faster if you have intimate knowledge of all the control loops and what each one does, because that lets you infer from the objectâ€™s current state which loop might be trying to run right now.</p>

<p>The key thing to notice here is that the complexity has been shifted from the designer of the control loop to the cluster operator. Itâ€™s easy (though not trivial) to make a control loop that does a dinky little thing in isolation. But to operate a cluster with dozens of these control loops requires the operator to assimilate the behavior of all of them, their interactions with each other, and try to reason about an extremely loosely coupled system. This is a problem because you have to write and test the control loop once, but work with it and its bugs many more times. And yet, the bias is to simplify the thing you only do once.</p>

<p>To fix this, I would look to systemd. It solves for a similar lifecycle problem: given a current state and a target, how do you get from A to B? The difference is that in systemd, the steps and their dependencies are made explicit. You <em>tell</em> systemd that your unit is a required part of <code>multi-user.target</code> (aka â€œnormally-booted happy systemâ€), that it must run after filesystems have been mounted, but before networking it brought up, and so forth. You can also depend on other concrete parts of the system, for example to say that your thing needs to run whenever sshd is running (sounds like a sidecar, right?).</p>

<p>The net result of this is that systemd can tell you precisely what piece of the system malfunctioned, or is still working on its thing, or failed a precondition. It can also print you a graph of the systemâ€™s boot process, and analyze it for things like â€œwhatâ€™s the long pole of bootup?â€</p>

<p>I want to steal all this wholesale, and plop it into my cluster orchestration â€¦</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.dave.tf/post/new-kubernetes/">https://blog.dave.tf/post/new-kubernetes/</a></em></p>]]>
            </description>
            <link>https://blog.dave.tf/post/new-kubernetes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25243159</guid>
            <pubDate>Sun, 29 Nov 2020 05:35:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Undeleting a file overwritten with mv]]>
            </title>
            <description>
<![CDATA[
Score 264 | Comments 81 (<a href="https://news.ycombinator.com/item?id=25242444">thread link</a>) | @todsacerdoti
<br/>
November 28, 2020 | https://behind.pretix.eu/2020/11/28/undelete-flv-file/ | <a href="https://web.archive.org/web/*/https://behind.pretix.eu/2020/11/28/undelete-flv-file/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">

    <article>

        

<!--         <header class="post-header">
            <a id="blog-logo" href="https://behind.pretix.eu">
                
                    <span class="blog-title">pretix â€“ behind the scenes</span>
                
            </a>
        </header> -->

        <!-- <span class="post-meta">
            <time datetime="2020-11-28">28 Nov 2020</time>
            
                on Technology, Forensics, and Linux
            
        </span> -->

        <!-- <h1 class="post-title">Undeleting a file overwritten with mv</h1> -->

        <section>
            <p>Itâ€™s been a while since we shared the story of an incident with you, and thatâ€™s probably a good thing â€“
most operational incidents we had in the past year were â€œboringâ€ enough in nature to fix them easily.
This time, weâ€™ve got a story of a data loss, caused by pure and simple human error â€“ and the story of
how we recovered the data.</p>

<p>Even though it is quite embarrassing how the data loss happened, we think itâ€™s worth sharing the story
of its recovery, as it might allow you to learn a few useful things in case you ever end up in a
similar situation.</p>

<p>As you might have seen, over the last 7 months weâ€™ve extended our offerings beyond ticketing to allow
our customers to transform their events into the digital space as long as the global pandemic makes
traditional event formats impossible. The result of our effort is a joint venture called 
<a href="https://venueless.org/">Venueless</a> that you should absolutely check out if you havenâ€™t yet.</p>

<p>One component of the virtual events we run on venueless is <strong>live video streaming</strong>. In this process,
our customers use a tool like <a href="https://obsproject.com/">OBS</a> or <a href="https://streamyard.com/">StreamYard</a>
to create a live video stream. The stream is then sent to an <strong>encoding server</strong> of ours via RTMP.
On the encoding server, we re-encode the stream into different quality levels and then distribute
it to our very own tiny streaming CDN.</p>

<p>Venueless currently does <strong>not yet</strong> include a video-on-demand component and usually, our customers record
their content at the source, e.g. with OBS or StreamYard, and process or publish them on their own.
However, just to be safe, we keep a recording of the incoming stream as well. This isnâ€™t currently
part of our promoted service offering, we rather see it as a free backup service to our clients in case they
lose their recording. Given that we already consider it to just be a backup, we currently donâ€™t make any
further backups of this data.</p>

<h4 id="data-loss">Data loss</h4>

<p>Usually, we delete these recordings after a while, but in some cases, our customers ask us to get them, e.g.
because their own recording failed, or because StreamYard only records the first 8 hours of every
stream. Since this doesnâ€™t happen a lot, itâ€™s not yet an automated process in our system. Whenever a customer
requests a recording we SSH into the respective encoding server and move the recording file to a
directory thatâ€™s accessible through HTTP, like this:</p>

<pre><code>/var/recordings $ mv recording-12345.flv public/
</code></pre>

<p>Thatâ€™s it, we share the link with the customer, and the process is done. One of the simplest steps possible
in all this. Yesterday, a customer asked us for the recordings of the two last streams of their event. Just
before finishing up for the week, I wanted to supply them with the required file, SSHâ€™d into the server,
looked for the correct files and typedâ€¦</p>

<pre><code>/var/recordings $ mv recording-16678.flv recording-16679.flv
</code></pre>

<p><strong>Oops.</strong> I hit return before typing out <code>public/</code>, and therefore replaced the last stream with the
second-last, losing one of the videos.</p>

<h4 id="damage-control">Damage control</h4>

<p>Having a very naive understanding of how file systems work, I knew that the <code>mv</code> command has only
changed the directory listing of the file system, but hasnâ€™t actually wiped the file from the disk,
so I knew there is likely still a chance to recover the file, if itâ€™s not overwritten by something
else in the meantime.</p>

<p>Since I didnâ€™t manage to re-mount the root partition as read-only to avoid further damage softly,
I used the <a href="https://www.kernel.org/doc/html/latest/admin-guide/sysrq.html">big hammer</a> to remount
everything read-only immediately:</p>

<pre><code># echo u &gt; /proc/sysrq-trigger
</code></pre>

<p>Uhm, okay, this worked, but how do I install any data recovery tools now? After some experiments,
I decided it would be easiest to reboot into the recovery system provided by our server provider
<a href="https://www.hetzner.com/">Hetzner</a>. So I configured the boot loader to boot their recovery system
from the network and forcefully rebooted the server.</p>

<p>To be able to perform disk dumps and have some operational flexibility without downloading a 2 TB
disk image to my local machine (which would take rougly a week), I also quickly purchased
a <a href="https://www.hetzner.com/storage/storage-box">Hetzner Storage Box</a> with 5 TB space.</p>

<h4 id="failed-attempts">Failed attempts</h4>

<p>Just before I executed my fatal <code>mv</code> command, I executed <code>ls -lisah</code> to get a directory listing
of the files:</p>

<pre><code>3146449 1.1G -rw-r--r-- 1 www-data www-data 1.1G Nov XX XX:XX recording-16678.flv
3146113 1.6G -rw-r--r-- 1 www-data www-data 1.6G Nov XX XX:XX recording-16679.flv
</code></pre>

<p>This meant I <strong>knew</strong> the inode number of the deleted file! As I mentioned before, my understanding
of file systems was (and is) rather naive, and I was pretty optimistic to be able to recover the
file using that information. Isnâ€™t that sort of what a journaling file system is for?</p>

<p>Recovering the file this way hover appeared to be impossible. <a href="http://ext4magic.sourceforge.net/howto_en.html">ext4magic</a>
and <a href="http://extundelete.sourceforge.net/">extundelete</a> are powerful tools that did find some 
deleted files on my disk â€“ but not the one I was looking for, even after trying different options
for over two hours.</p>

<p>I did not spend the time to really understand how ext4 works, but from what I gathered from various
blogs, I was pretty much out of luck since the inode did no longer contain the relevant information
and ext4magic also wasnâ€™t able to <a href="http://ext4magic.sourceforge.net/howto_en.html#Recovery_process_5">recover the neccessary information from the journal</a>
either.</p>

<pre><code>debugfs:  inode_dump &lt;3146113&gt;
0000  a081 0000 8503 0000 e83a c15f e83a c15f  .........:._.:._
0020  e83a c15f 0000 0000 7200 0100 0800 0000  .:._....r.......
0040  0000 0800 0100 0000 0af3 0100 0400 0000  ................
0060  0000 0000 0000 0000 0100 0000 e6eb c000  ................
0100  0000 0000 0000 0000 0000 0000 0000 0000  ................
*
0140  0000 0000 92d0 2cf5 0000 0000 0000 0000  ......,.........
0160  0000 0000 0000 0000 0000 0000 6fb2 0000  ............o...
0200  2000 e3fb 208a 515b 7c65 5d5a 7c65 5d5a   ... .Q[|e]Z|e]Z
0220  e83a c15f 7c65 5d5a 0000 0000 0000 0000  .:._|e]Z........
0240  0000 0000 0000 0000 0000 0000 0000 0000  ................
*
</code></pre>

<p>However, if youâ€™re in a similar situation â€“ the ext4magic how-tos are really helpful and worth a try.</p>

<h4 id="successful-recovery">Successful recovery</h4>

<p>There is this one other approach to file recovery that is often recommended on the internet, usually
for â€œsmall text filesâ€: Just <code>grep</code> your whole disk for known parts of its contents! So why wouldnâ€™t
this work on larger non-text files as well?</p>

<p>The first problem is obviously what to grep for. The only thing I know about the missing file, apart
from its rough size, is that itâ€™s a FLV video file. Luckily, <a href="https://en.wikipedia.org/wiki/Flash_Video#Flash_Video_Structure">all FLV files</a>
that contain video start with the byte sequence <code>FLV\x01\x05</code>. So letâ€™s search our 2 TB disk for
that byte sequence and print out the byte offset of all occurences!</p>

<pre><code>cat /dev/md2 \
	| pv -s 1888127576000 \
	| grep -P --byte-offset --text 'FLV\x01\x05' \
	| tee -a /mnt/storagebox/grep-log.txt
</code></pre>

<p>This took roughly 7 hours. The <code>pv</code> command with the (rough) total size of the disk is optional, but gives you
a nice progress bar. Overall, this took a little over 6 hours on our server.</p>

<p><code>grep</code> works line-based, which in a binary file menas â€œany byte sequence between two ASCII line breaksâ€. The
log file therefore contained lots of lines like this:</p>

<pre><code>184473878409:&lt;some binary data&gt;FLV&lt;some binary data&gt;
</code></pre>

<p>In total, the search found 126 FLV file headers on our disk. This was pretty reassuring, since we had 122 FLV files
still known to the file system â€“ so there are at least four FLV byte sequences without a filename!</p>

<pre><code># find /mnt/disk/var/recordings/ -name '*.flv' -not -empty -ls | wc -l
122
</code></pre>

<p>Now, I needed to find out which of the 126 byte sequences did not have a filename. Since I really didnâ€™t want
to spend all weekend with a deep-dive into the ext4 disk layout, I went for an easier solution: For every file
still known in the file system, I computed a hash of the first 500 kilobytes of the file:</p>

<figure><pre><code data-lang="python"><span>#!/usr/bin/python3
</span><span>import</span> <span>glob</span>
<span>import</span> <span>hashlib</span>
<span>import</span> <span>os</span>

<span>hashsize</span> <span>=</span> <span>500</span> <span>*</span> <span>1024</span>
<span>known_hashes</span> <span>=</span> <span>{}</span>
<span>not_deleted_files</span> <span>=</span> <span>sorted</span><span>(</span>
    <span>glob</span><span>.</span><span>glob</span><span>(</span><span>'/mnt/disk/var/recordings/*.flv'</span><span>)</span> <span>+</span> 
    <span>glob</span><span>.</span><span>glob</span><span>(</span><span>'/mnt/disk/var/recordings/public/*.flv'</span><span>)</span>
<span>)</span>
<span># Ignore files shorter than our hash size
</span><span>not_deleted_files</span> <span>=</span> <span>[</span>
    <span>f</span> <span>for</span> <span>f</span> <span>in</span> <span>not_deleted_files</span>
    <span>if</span> <span>os</span><span>.</span><span>stat</span><span>(</span><span>f</span><span>).</span><span>st_size</span> <span>&gt;</span> <span>hashsize</span>
<span>]</span>

<span>for</span> <span>fname</span> <span>in</span> <span>not_deleted_files</span><span>:</span>
    <span>with</span> <span>open</span><span>(</span><span>fname</span><span>,</span> <span>'rb'</span><span>)</span> <span>as</span> <span>f</span><span>:</span>
        <span>h</span> <span>=</span> <span>hashlib</span><span>.</span><span>md5</span><span>(</span><span>f</span><span>.</span><span>read</span><span>(</span><span>hashsize</span><span>)).</span><span>hexdigest</span><span>()</span>
        <span>if</span> <span>h</span> <span>in</span> <span>known_hashes</span><span>:</span>
            <span>print</span><span>(</span><span>"duplicate hash found:"</span><span>)</span>
        <span>known_hashes</span><span>[</span><span>h</span><span>]</span> <span>=</span> <span>fname</span>
        <span>print</span><span>(</span><span>h</span><span>,</span> <span>fname</span><span>)</span>

<span>print</span><span>(</span>
    <span>len</span><span>(</span><span>not_deleted_files</span><span>),</span> <span>"files with"</span><span>,</span>
    <span>len</span><span>(</span><span>known_hashes</span><span>),</span> <span>"hashes"</span>
<span>)</span></code></pre></figure>

<p>Interestingly, two files from the completely different customers shared the same hash of the first 500 kilobytes.
I havenâ€™t tested it yet, but my theory is that those were streams that just did not contain any audio or video
in their first minutes, but only empty frames. However, since I knew this isnâ€™t the case for my missing file,
I felt confident in proceeding with this approach.</p>

<p>Next, I computed the same hash for every byte offest found by grep and compared it to the hashes found in the
previous step:</p>

<figure><pre><code data-lang="python"><span>grep_log</span> <span>=</span> <span>'/mnt/storagebox/grep-log.txt'</span>
<span>disk</span> <span>=</span> <span>'/dev/md2'</span>

<span>print</span><span>(</span><span>"Parsing grep logâ€¦"</span><span>)</span>
<span>positions</span> <span>=</span> <span>[]</span>
<span>with</span> <span>open</span><span>(</span><span>grep_log</span><span>,</span> <span>'rb'</span><span>)</span> <span>as</span> <span>f</span><span>:</span>
    <span>for</span> <span>line</span> <span>in</span> <span>f</span><span>.</span><span>read</span><span>().</span><span>split</span><span>(</span><span>b'</span><span>\n</span><span>'</span><span>):</span>
        <span>if</span> <span>not</span> <span>line</span><span>:</span>  <span># ignore empty line e.g. at end of file
</span>            <span>continue</span>
        <span>pos</span><span>,</span> <span>data</span> <span>=</span> <span>line</span><span>.</span><span>split</span><span>(</span><span>b':'</span><span>,</span> <span>1</span><span>)</span>
        <span>pos</span> <span>=</span> <span>int</span><span>(</span><span>pos</span><span>.</span><span>decode</span><span>())</span>
        <span># add offset of FLV within line
</span>        <span>binoffset</span> <span>=</span> <span>data</span><span>.</span><span>index</span><span>(</span><span>b"FLV</span><span>\x01</span><span>"</span><span>)</span>
        <span>pos</span> <span>+=</span> <span>binoffset</span> 
        <span>positions</span><span>.</span><span>append</span><span>(</span><span>pos</span><span>)</span>

<span>print</span><span>(</span><span>"Computing hashes of files on diskâ€¦"</span><span>)</span>
<span>found_hashes</span> <span>=</span> <span>{}</span>
<span>with</span> <span>open</span><span>(</span><span>disk</span><span>,</span> <span>'rb'</span><span>)</span> <span>as</span> <span>f</span><span>:</span>
    <span>for</span> <span>p</span> <span>in</span> <span>positions</span><span>:</span>
        <span>f</span><span>.</span><span>seek</span><span>(</span><span>p</span><span>)</span>
        <span>d</span> <span>=</span> <span>f</span><span>.</span><span>read</span><span>(</span><span>hashsize</span><span>)</span>
        <span>h</span> <span>=</span> <span>hashlib</span><span>.</span><span>md5</span><span>(</span><span>d</span><span>).</span><span>hexdigest</span><span>()</span>
        <span>if</span> <span>h</span> <span>in</span> <span>known_hashes</span><span>:</span>
            <span>print</span><span>(</span><span>"At offset"</span><span>,</span> <span>p</span><span>,</span> <span>"found known hash"</span><span>,</span> <span>h</span><span>,</span>
                  <span>"corresponding to"</span><span>,</span> <span>known_hashes</span><span>[</span><span>h</span><span>])</span>
        <span>else</span><span>:</span>
            <span>print</span><span>(</span><span>"At offset"</span><span>,</span> <span>p</span><span>,</span> <span>"found unknown hash"</span><span>,</span> <span>h</span><span>)</span>
        <span>found_hashes</span><span>[</span><span>h</span><span>]</span> <span>=</span> <span>p</span>

<span>unknown_hashes</span> <span>=</span> <span>{</span>
    <span>h</span><span>:</span> <span>p</span> <span>for</span> <span>h</span><span>,</span> <span>p</span> <span>in</span> <span>found_hashes</span><span>.</span><span>items</span><span>()</span>
    <span>if</span> <span>h</span> <span>not</span> <span>in</span> <span>known_hashes</span>
<span>}</span>
<span>files_not_found</span> <span>=</span> <span>[</span>
    <span>fname</span> <span>for</span> <span>h</span><span>,</span> <span>fname</span> <span>in</span> <span>known_hashes</span><span>.</span><span>items</span><span>()</span>
   â€¦</code></pre></figure></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://behind.pretix.eu/2020/11/28/undelete-flv-file/">https://behind.pretix.eu/2020/11/28/undelete-flv-file/</a></em></p>]]>
            </description>
            <link>https://behind.pretix.eu/2020/11/28/undelete-flv-file/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25242444</guid>
            <pubDate>Sun, 29 Nov 2020 02:21:08 GMT</pubDate>
        </item>
    </channel>
</rss>
