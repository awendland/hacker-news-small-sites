<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Tue, 10 Nov 2020 08:20:15 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Tue, 10 Nov 2020 08:20:15 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Stack Videos Horizontally, Vertically, in a Grid With FFmpeg]]>
            </title>
            <description>
<![CDATA[
Score 107 | Comments 26 (<a href="https://news.ycombinator.com/item?id=25022665">thread link</a>) | @rrao84
<br/>
November 7, 2020 | https://ottverse.com/stack-videos-horizontally-vertically-grid-with-ffmpeg/ | <a href="https://web.archive.org/web/*/https://ottverse.com/stack-videos-horizontally-vertically-grid-with-ffmpeg/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<figure>
<img src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/11/stacking-videos.png?resize=678%2C381&amp;ssl=1" alt="stack videos using ffmpeg" title="stacking-videos" data-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/11/stacking-videos.png?resize=678%2C381&amp;ssl=1" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">
</figure>


<p>Often times, when you want to compare two videos side-by-side or you want to create an effect during post-processing, you might want to stack videos together. It can get expensive if you end up buying a tool to do this, but, guess what? </p>



<p><strong>FFmpeg offers a variety of tools to help stack videos together – horizontally, vertically, or in a grid fashion. In this tutorial, let’s learn about FFmpeg’s <code>hstack</code> and <code>vstack</code> filters for stacking videos. </strong></p>



<hr>




<h2><span id="How_to_Stack_Videos_Horizontally_using_FFmpeg"></span><strong>How to Stack Videos Horizontally using FFmpeg?</strong><span></span></h2>



<p>“Horizontally stacking videos” refers to placing videos side-by-side (one on the left and the other on the right). </p>



<p>Before you do this, there are a couple of points that you need to consider. </p>



<ol><li>The videos that you want to stack need to have the same height. </li><li> The videos need to have the same pixel format. </li></ol>



<p>The command line is shown below where we try and stack two <code>mp4</code> videos. </p>



<pre><code>ffmpeg -i input0.mp4 -i input1.mp4&nbsp;-filter_complex hstack=inputs=2 horizontal-stacked-output.mp4</code></pre>



<p>The <code>hstack</code> filter has a simple format. You need to specify the number of inputs and it parses that from the beginning portion of the commandline. The order of stacking follows the order of inputs. </p>



<p>Here is a screenshot of what it looks like. </p>



<figure><img src="https://lh6.googleusercontent.com/4FwbqByqDpDpOGTNvpSWSOh6RVE9yzesrQyAyGvaOF1ZjVsycKOlQUjrTmdJRFJWblHjC9gF6zMds0s5w2Yy2w6CVXXme-H-zF8nYoJ496khN0aHXHaWbnwEe41BYmu6c2mdoQb8" alt="stack videos using ffmpeg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>And, here is a video! </p>



<p><iframe frameborder="0" allow="autoplay; fullscreen" allowfullscreen="" data-src="https://player.vimeo.com/video/475731721" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></iframe></p>







<p>Here is another use case. Companies or teams working on video compression often like to compare videos side-by-side in the lab or showcase their work in conferences. FFmpeg’s horizontal stacking is an easy way to do this and achieve a very good result. </p>



<p>Below are two videos encoded at different video quality settings and stacked horizontally. Comparison made simple, right? <em>(note: Vimeo’s choise of bitrate might mess with the comparison, but, when done offline (downloaded), the <code>hstack</code> filter makes comparisons easy!)</em></p>



<p><iframe frameborder="0" allow="autoplay; fullscreen" allowfullscreen="" data-src="https://player.vimeo.com/video/476095363" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></iframe></p>



<hr>



<h2><span id="Stacking_Videos_Vertically_using_FFmpeg"></span><strong>Stacking Videos Vertically using FFmpeg</strong><span></span></h2>



<p>“Vertically stacked videos” results in placing videos one below the other. Unlike in horizontal stacking, inputs need to be having the same width. The command is as shown.&nbsp;</p>



<p>For vertical stacking, we need to use the <code>vstack</code> filter whose syntax is similar to the <code>hstack</code> filter we used in the previous horizontal stacking example.</p>



<pre><code>ffmpeg -i input0.mp4 -i input1.mp4&nbsp;-filter_complex vstack=inputs=2 vertical-stack-output.mp4</code></pre>



<figure><img src="https://lh5.googleusercontent.com/qtyxioWFR54pqwZhX7jgX6HkSG7gCw840GdK78HGHHP7X3sv3fr3Pou9hOMFu2O-e6O7nmCith3U6CM1SpDanhwmIFIBzZUQyaG4T0BJaF9QCdMIPrmMmH0qc9WTK5f-5Nf4-92y" alt="stack videos using ffmpeg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>Both functions pretty much use the same commands with a simple distinction, the <a href="https://ffmpeg.org/ffmpeg-filters.html#hstack" target="_blank" rel="noopener"><code>hstack</code></a> and the <a href="https://ffmpeg.org/ffmpeg-filters.html#vstack" target="_blank" rel="noopener"><code>vstack</code></a> under the <code>-filter_complex</code> argument.&nbsp;</p>



<p>Here’s a video of stacking two videos vertically using FFmpeg. </p>



<p><iframe frameborder="0" allow="autoplay; fullscreen" allowfullscreen="" data-src="https://player.vimeo.com/video/475731607" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></iframe></p>



<hr>



<h2><span id="Stacking_Videos_of_Different_Lengths"></span><strong>Stacking Videos of Different Lengths</strong><span></span></h2>



<p>Well, there’s a really nifty ability for both of these to prioritize the length of the shortest video. And as luck would have it the parameter is named <code>shortest</code>, and it’s applicable to both the horizontal and vertical stacking filters. Using <code>shortest=1</code> ensures the shortest length is used. </p>



<p>For example – </p>



<pre><code>ffmpeg -i input0.mp4 -i input1.mp4 -filter_complex hstack=inputs=2:shortest=1 shortest-output.mp4</code></pre>



<p>As a <b>side note</b>, if you run into an error that claims frames are being duplicated, the easiest workaround is to slip the <code>vsync 2</code> parameter into your command, and it worked like a charm.</p>



<h3><span id="Stacking_Videos_of_Different_Lengths_Without_the_shortest_parameter"></span>Stacking Videos of Different Lengths Without the <code>shortest</code> parameter<span></span></h3>



<p>To test what happens in this situation, let’s stack two videos vertically – a 10 second clip and an 18 second clip. You’ll see that the shorter clip just stops after it completes, but the output video continues till the longest of the input clips complete.  </p>



<p><iframe frameborder="0" allow="autoplay; fullscreen" allowfullscreen="" data-src="https://player.vimeo.com/video/475731684" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></iframe></p>











<p>If you want to truncate the clips to the length of the shortest clip, then you need to use the <code>shortest=1</code> parameter. Let’s look at that in the next section.</p>



<h3><span id="Stacking_Videos_of_Different_Lengths_With_the_shortest=1_parameter"></span>Stacking Videos of Different Lengths With the <code>shortest=1</code> parameter<span></span></h3>



<p>In this example, we use the <code>shortest=1</code> command-line parameter and as you can see, the length of the final video is truncated to the length of the shortest of the inputs. </p>



<p><iframe frameborder="0" allow="autoplay; fullscreen" allowfullscreen="" data-src="https://player.vimeo.com/video/475731643" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></iframe></p>



<hr>



<h2><span id="2%C3%972_Grid_of_Videos_using_FFmpeg"></span><strong><strong>2×2 Grid of Videos using FFmpeg</strong></strong><span></span></h2>



<p>We can achieve a 2×2 grid of videos using a combination of the <code>hstack</code> and <code>vstack</code> filters. Let’s start by looking at the command-line and then break it down. It’s actually pretty simple! </p>



<pre><code>ffmpeg \
-i input0.mp4 -i input1.mp4 -i input2.mp4 -i input3.mp4 \
-filter_complex \
"[0:v][1:v]hstack=inputs=2[top]; \
[2:v][3:v]hstack=inputs=2[bottom]; \
[top][bottom]vstack=inputs=2[v]" \
-map "[v]" \
finalOutput.mp4</code></pre>



<p>What’s happening here?</p>



<ul><li>firstly, you need to provide 4 input videos with the same height and width</li><li>next, you stack the first two videos horizontally and call it “top” i.e. <code>[0:v][1:v]hstack=inputs=2[top]</code></li><li>then, you you stack the next two videos horizontally and call it “bottom” i.e. <code>[2:v][3:v]hstack=inputs=2[bottom]</code></li><li>then, you stack <code>top</code> and <code>bottom</code> vertically to create a 2×2 grid. — <code>[top][bottom]vstack=inputs=2[v]</code></li><li>then using the <code>map</code> command, we can extract and push the video track to the output container. </li></ul>



<p>Here is what the video looks like. </p>



<p><iframe frameborder="0" allow="autoplay; fullscreen" allowfullscreen="" data-src="https://player.vimeo.com/video/475771172" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></iframe></p>



<hr>



<h2><span id="3%C3%972_Grid_of_Videos_using_FFmpeg"></span><strong>3×2 Grid of Videos using FFmpeg</strong><span></span></h2>



<p>Along the same lines, here is a 3×2 grid of videos using <code>hstack</code> and <code>vstack</code> filters. </p>



<pre><code>ffmpeg \
-i input0.mp4 -i input1.mp4 \
-i input2.mp4 -i input3.mp4 \
-i input4.mp4 -i input5.mp4 \
-filter_complex \
"[0:v][1:v][2:v]hstack=inputs=3[top];\
[3:v][4:v][5:v]hstack=inputs=3[bottom];\
[top][bottom]vstack=inputs=2[v]" \
-map "[v]" \
finalOutput.mp4</code></pre>



<p><iframe frameborder="0" allow="autoplay; fullscreen" allowfullscreen="" data-src="https://player.vimeo.com/video/475780643" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></iframe></p>



<hr>



<h2><span id="Conclusion"></span>Conclusion<span></span></h2>



<p>That’s it folks. Now you know how to stack videos together horizontally, vertically, and in a grid. This is very useful in comparing videos and also creating fun effects along the way! </p>



<p>If you enjoyed this post, do check out the rest of<a href="https://ottverse.com/category/ffmpeg/"> <strong>OTTVerse’s FFmpeg tutorials</strong></a> to learn more about this amazing media editing and compression software!  </p>

	</div></div>]]>
            </description>
            <link>https://ottverse.com/stack-videos-horizontally-vertically-grid-with-ffmpeg/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25022665</guid>
            <pubDate>Sun, 08 Nov 2020 03:36:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Going from $0 to $2M ARR in 2 years]]>
            </title>
            <description>
<![CDATA[
Score 130 | Comments 31 (<a href="https://news.ycombinator.com/item?id=25019737">thread link</a>) | @gatsby
<br/>
November 7, 2020 | https://laskie.co/playbooks/bootstrapping-b2b-sales | <a href="https://web.archive.org/web/*/https://laskie.co/playbooks/bootstrapping-b2b-sales">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Welcome! You're probably here because you read <a href="https://twitter.com/ChrisJBakke/status/1309197276061945857" target="_blank">this tweet</a> and then signed up to hear the longer-form version of how we ran founder-led sales to grow from $0 to $2m ARR in under 2 years.</p><p><strong>This guide is for founders who have a B2B company that is just starting out, where you're selling a product that is $250/mo or more.</strong></p><p>You might also find value in certain sections if you're running an agency, or a B2C company, or are selling a product &lt;$250/mo. You might find value if you're a B2B sales leader, or an account executive, or are just trying to learn more about sales.</p><p>Like many other things - sales, marketing, pricing, and onboarding are all really case-dependent. This isn't meant to be advice, or "go do this," but rather, "here's the playbook that worked well for us, with a specific product, at a specific moment in time."</p><h2 id="why-founder-led-sales-is-important"><a href="#why-founder-led-sales-is-important" aria-label="why founder led sales is important permalink" target="_blank"></a>Why founder-led sales is important</h2><p><strong>Sales should to be driven by at least one founder until you stop learning new things about your customers, the problem you are solving, and how to position your solution.</strong></p><p>At our last company, we had all three founders involved in sales at some level for almost 2 years.</p><p>No one is going to understand the product and problem it solves better than the founders. If that's not the case, you have bigger problems than sales.</p><p><strong>Sales conversations are also your most important feedback loop.</strong> As a founder, you need a front row seat to drive product, pricing and marketing decisions.</p><h2 id="why-i-wrote-this"><a href="#why-i-wrote-this" aria-label="why i wrote this permalink" target="_blank"></a>Why I wrote this</h2><p>I've done a lot of sales. I've worked at, built, founded, and sold a couple companies. Everything about a startup is sales: you're selling a product or service to a customer, you're pitching the best people to join your team, you're pitching investors, you're selling a vision to your team, you're striking a critical partnership.</p><p><strong>Everything is sales, so we might as well get good at it.</strong></p><p>I didn't write this alone. Our team at my new company <a href="https://laskie.co/" target="_blank">Laskie</a> encouraged me to write this, and helped out a lot.</p><p><strong>Please reach out with questions: <a href="mailto:chris@laskie.co" target="_blank">chris@laskie.co</a>.</strong></p><hr></div></div></div>]]>
            </description>
            <link>https://laskie.co/playbooks/bootstrapping-b2b-sales</link>
            <guid isPermaLink="false">hacker-news-small-sites-25019737</guid>
            <pubDate>Sat, 07 Nov 2020 21:38:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Marketers are addicted to bad data]]>
            </title>
            <description>
<![CDATA[
Score 303 | Comments 93 (<a href="https://news.ycombinator.com/item?id=25016532">thread link</a>) | @iamacyborg
<br/>
November 7, 2020 | https://www.jacquescorbytuech.com/writing/marketers-addicted-bad-data | <a href="https://web.archive.org/web/*/https://www.jacquescorbytuech.com/writing/marketers-addicted-bad-data">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content">
<article>
<header>

</header>
<p><small><time datetime="2020-11-07T15:45:00+00:00">
      Sat 07 November 2020
    </time></small>
</p>
<div>
<p>Modern marketing is all about data and however hard you might try, you can't spend any time around marketers online without <a href="https://blog.marketo.com/2013/11/prove-your-worth10-kpis-for-marketers.html">being</a> <a href="https://www.searchenginejournal.com/paid-owned-earned-content/242075/">subjected</a> <a href="https://blogs.oracle.com/oracledatacloud/effectively-measuring-advertising-performance-your-guide-to-success">to</a> <a href="https://searchengineland.com/using-auction-insights-for-better-ppc-competitor-analysis-343264">endless</a> <a href="https://www.searchenginewatch.com/2020/07/28/10-reasons-why-marketers-use-data-to-make-budgeting-decisions/">think</a> <a href="https://www.oberlo.co.uk/blog/spent-200000-facebook-ads-heres-learned">pieces</a>, how-to guides, ebooks or other dreck about how we need to track and measure and count every little thing.</p>
<p>We've got click rates, impressions, conversion rates, open rates, ROAS, pageviews, bounces rates, ROI, CPM, CPC, impression share, average position, sessions, channels, landing pages, KPI after never ending KPI.</p>
<p>That'd be fine if all this shit meant something and we knew how to interpret it. But <em>it doesn't</em> and <strong>we don't</strong>. </p>
<p>The reality is much simpler, and therefore much more complex.  Most of us don't understand how data is collected, how these mechanisms work and most importantly where and how they <em>don't</em> work.</p>
<ul>
<li><a href="https://www.statista.com/statistics/874736/ad-blocker-usage-in-united-kingdom/">36% percent of people in the UK</a> use an adblocker, which means your javascript based website tracking is meaningless</li>
<li>Email open rates <a href="https://developermedia.com/email-open-rates-misleading-metrics-best-practices-2/">don't <em>actually</em> indicate that an email was opened</a>, merely that a request was made to a server</li>
<li>The black boxes inside Facebook and other ad exchanges give you <a href="https://www.etcentric.org/facebook-agrees-to-40-million-fine-for-incorrect-ad-metrics/">flat out wrong</a> data about how your ads are performing</li>
<li>The audiences you're targeting on Google, Bing, etc <a href="https://www.forbes.com/sites/augustinefou/2020/11/02/got-large-budgets-you-need-to-spend-fraudsters-will-help-you-spend-it/?sh=54b93f867a9f">are fraudulent</a> and don't even exist</li>
<li>The exchanges you're purchasing media space from are <a href="https://www.adexchanger.com/mobile/is-ubers-new-ad-fraud-lawsuit-futile-or-game-changing/">cheating you</a></li>
</ul>
<p>And even if we know how the data is collected, what it means and what it's actually tracking, most of us don't have the technical chops to analyse the data we've collected<sup id="fnref:1"><a href="#fn:1">1</a></sup>. I don't mean to rag on anyone by saying this, but we do need a reality check.</p>
<p>And look. I get it. Having tangible data allows us to demonstrate that we're doing our job and we're trying to measure and improve what we're doing. But as Bob Hoffman rightly points out - <a href="http://adcontrarian.blogspot.com/2020/09/the-mystery-of-modern-media.html">that's not how brands are built</a>. </p>
<p>The numbers are often all we have to prove our case, to get more budget and in extreme cases, to continue to stay employed. We'll remain in this mess until we can separate marketing from short sighted and poorly informed decision making. Until leaders can lead on the strength of their conviction and experience instead of second guessing themselves and their staff based on the inadequacy of data.</p>
<p>I don't know what the way out of this mess is, or what the path to success looks like. All I know is this.</p>
<p><em>We're addicted to bad data</em>.</p>

<p>Cheers,</p>
<p><img src="https://www.jacquescorbytuech.com/images/jacques.png">
</p></div>
<div>
<h4>Subscribe for updates</h4>

<p>Updates, whenever I've got something valuable to say.</p>
</div>
</article>
</section></div>]]>
            </description>
            <link>https://www.jacquescorbytuech.com/writing/marketers-addicted-bad-data</link>
            <guid isPermaLink="false">hacker-news-small-sites-25016532</guid>
            <pubDate>Sat, 07 Nov 2020 17:27:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learn how to design and defend an embedded Linux device]]>
            </title>
            <description>
<![CDATA[
Score 121 | Comments 32 (<a href="https://news.ycombinator.com/item?id=25015821">thread link</a>) | @sprado
<br/>
November 7, 2020 | https://embeddedbits.org/introduction-embedded-linux-security-part-1/ | <a href="https://web.archive.org/web/*/https://embeddedbits.org/introduction-embedded-linux-security-part-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
  <div>
    <div>
      <article role="main">
        <p>This article is going to be an introduction to <strong>embedded Linux security</strong>.</p>
<p>Since this topic is quite extensive, I divided into two parts. In this first part, we will have a small introduction to security concepts and threat modeling and then focus on some mitigation techniques to improve the security of an embedded Linux device, including secure boot, code/data encryption and secure key storage.</p>
<p>If you prefer a one hour talk instead of reading this article, you can also watch the webinar <a href="https://www.youtube.com/watch?v=QcUKAgVKSxQ">“Introduction to embedded Linux security”</a> I recorded for <a href="https://www.toradex.com/">Toradex</a>. I also gave the same talk at Embedded Linux Conference North America 2020, but as I write this article it was not yet published on YouTube.</p>
<p>Let’s first start with some concepts…</p>
<h2 id="security-concepts">Security concepts</h2>
<p>Security is all about risk mitigation.</p>
<p>On the one hand, we have <strong>owners</strong>, those who benefit from a product or service (user, manufacturer, business owner, etc). And owners want to protect <strong>assets</strong>, anything that has some value in the product or service (data, code, reputation, etc).</p>
<p>On the other hand, we have <strong>threat actors</strong>, a person or thing (malicious hacker, government, etc) that can manifest a <strong>threat</strong>, anything that is capable of acting against an asset in a manner that can result in harm.</p>
<p>To manifest a threat, the threat actor will explore <strong>vulnerabilities</strong> (weakness in the system) via an <strong>attack vector</strong>, a method or pathway used by the threat actor to access or penetrate the target system.</p>
<p>The diagram below express very well all those concepts:</p>
<p><a href="https://www.enisa.europa.eu/publications/hardware-threat-landscape/at_download/fullReport"><img src="https://embeddedbits.org/images/20200906-security-concepts.png" alt="Security Concepts"></a></p>
<p>In the end, is a cat-and-mouse game between owners and threat actors. How far will the owner go to protect the assets? How far will the threat actor go to compromise the assets? It really depends on the value of the assets. Indeed, the perception of value may not be the same for owners and threat actors.</p>
<p>Identifying assets (and their value) to mitigate the risks of being compromised can be done in a process called <strong>threat modeling</strong>.</p>
<h2 id="threat-modeling">Threat modeling</h2>
<p>Threat modeling is a process where potential threats can be identified, enumerated, and mitigations can be prioritized. It is basically a risk assessment process where you evaluate the value of your assets and the cost to protect them. The result of a threat modeling is the <strong>threat model</strong> of your product.</p>
<p><img src="https://embeddedbits.org/images/20200906-threat-modeling.png" alt="Threat modeling"></p>
<p>There are several techniques and methodologies that can help during threat modeling, including STRIDE, DREAD, VAST, OCTAVE, and many others.</p>
<p>To have a very basic introduction to the topic, let’s talk about STRIDE and DREAD.</p>
<p>The <a href="https://en.wikipedia.org/wiki/STRIDE_(security)">STRIDE model</a> is a very useful tool to help classify threats. It was developed by Microsoft and the name is an acronym for the six main types of threats: <strong>S</strong>poofing, <strong>T</strong>ampering, <strong>R</strong>epudiation, <strong>I</strong>nformation disclosure, <strong>D</strong>enial of service and <strong>E</strong>scalation of privileges. STRIDE can be used to identify all threats the assets of a system could be exposed to.</p>
<p><a href="https://allabouttesting.org/stride-acronym-of-threat-modeling-system/"><img src="https://embeddedbits.org/images/20200906-stride.png" alt="STRIDE"></a></p>
<p>The <a href="https://en.wikipedia.org/wiki/DREAD_(risk_assessment_model)">DREAD methodology</a> is a tool for risk-assessing computer security threats. The name is an acronym for five categories of security threats: <strong>D</strong>amage (how bad would an attack be), <strong>R</strong>eproducibility (how easy is it to reproduce the attack), <strong>E</strong>xploitability (how much work is it to launch the attack), <strong>A</strong>ffected users (how many people would be impacted) and <strong>D</strong>iscoverability (how easy is it to discover the threat).</p>
<p><a href="https://www.slideshare.net/SecurityInnovation/threat-modeling-to-reduce-software-security-risk"><img src="https://embeddedbits.org/images/20200906-dread.png" alt="DREAD"></a></p>
<p>While the STRIDE model helps to identify the threats, the DREAD methodology helps to rank them. For each threat in the system, you would go over each threat category and classify it in low (1 point), medium (2 points), or high (3 points). In the end, you would have a ranked list of threats and mitigation strategies. Example:</p>
<p><img src="https://embeddedbits.org/images/20200906-threat-modeling-example.png" alt="Threat modeling example"></p>
<p>We can see that threat modeling will provide a very clear view of what we want to protect, how we plan to protect it, and associated costs. This is part of the <strong>threat model</strong> of the product, which needs to be re-evaluated for every development cycle. As a result, the threat model will provide a prioritized list of threats to work on, so we can focus on implementing the mitigations to improve the security of the product.</p>
<p>How to protect the integrity and authenticity of your code? How to ensure the privacy of the data? Where to store cryptographic keys? How to minimize the risks of an application to be exploited? Let’s try to answer all of those questions and many more, starting with secure boot!</p>
<h2 id="secure-boot">Secure Boot</h2>
<p>How to make sure the code you are running was built by a trustworthy person or company? Implementing a <strong>secure boot</strong> process.</p>
<p>The objective of a secure boot process is to protect the integrity and authenticity of the code.</p>
<p>Secure boot is usually based on the verification of digital signatures. An embedded Linux system normally has three major components: bootloader, kernel and root filesystem (rootfs). All these components are signed and the signatures are checked during boot.</p>
<p>For example, some hardware mechanism can be used to check the signature of the bootloader, that will check the signature of the kernel, that will use a ramdisk image to check the signature of the root filesystem. Since we have one component checking the signature of the next one in the boot chain, this process is often called a <strong>chain-of-trust</strong>.</p>
<p><img src="https://embeddedbits.org/images/20200906-secure-boot-1.png" alt="Secure boot"></p>
<p>Let’s take a look at a real example on an <a href="https://www.nxp.com/imx6">NXP iMX6</a> device.</p>
<p>Everything starts in the ROM code inside the SoC. On NXP iMX6, there is a hardware component called High Assurance Boot (HAB) that it is able to validate the signature of the first stage bootloader, making it possible to implement a secure boot process. The High Assurance Boot inside iMX6 devices can also be called the <strong>Root of Trust</strong>, since if it is compromised, all the secure boot process is also compromised.</p>
<p>The ROM code inside the iMX6 SoC, using the HAB component, will check the signature of the bootloader. For that, it is necessary to generate a pair of keys (public and private), sign the bootloader with the private key and store the public key inside the SoC. On iMX6, OTP fuses are used to store the keys. Actually, to make it less expensive, only the hash of the public key is stored in the SoC.</p>
<p>When the bootloader boots (e.g. <a href="https://www.denx.de/wiki/U-Boot">U-Boot</a>), it will have to check the signature of the Linux kernel. For that, it is common to use an image format called <strong>FIT image</strong>. The FIT image is a container for multiple binaries with hashing and signature support, and usually contains the Linux kernel image, device tree files and an initial ramdisk. After generating a pair of keys, we need to sign the binaries inside the FIT image with the private key e configure U-Boot to use the public key to check the signature of the FIT image.</p>
<p>After the kernel boots, it will run the <em>init</em> program from the ramdisk image. The ramdisk will have the logic to verify the integrity of the final root filesystem before mounting it. There are some options to implement this. One common option is using the device-mapper verity (<a href="https://www.kernel.org/doc/html/latest/admin-guide/device-mapper/verity.html">dm-verity</a>) kernel module. The <strong>dm-verity</strong> kernel module provides integrity checking of block devices and requires a read-only rootfs (squashfs can be a good solution). Other approaches would be <a href="https://wiki.gentoo.org/wiki/Integrity_Measurement_Architecture">IMA</a> or <a href="https://www.kernel.org/doc/html/latest/admin-guide/device-mapper/dm-integrity.html">dm-integrity</a> if you want a read-write root filesystem.</p>
<p>Here is a diagram of the complete secure boot process:</p>
<p><img src="https://embeddedbits.org/images/20200906-secure-boot-2.png" alt="Secure boot on NXP iMX6"></p>
<p>This is only one example of a secure boot implementation, although it could be applied to a different set of boards and ARM SoCs.</p>
<p>Yet nothing is 100% secure!</p>
<p>Secure boot vulnerabilities in the ROM code of several NXP devices (i.MX6, i.MX50, i.MX53, i.MX7, i.MX28 and Vybrid families) were <a href="https://blog.quarkslab.com/vulnerabilities-in-high-assurance-boot-of-nxp-imx-microprocessors.html">publicly disclosed</a> on July 17th, 2017. And if your chain of trust is compromised, everything is compromised! So we need to be aware of these types of vulnerabilities (in this case, they were fixed with new silicon).</p>
<p>While secure boot ensures authenticity and integrity, it does not protect the device from being counterfeited or threat actors from extracting code/data from the device. So if you want to protect your intellectual property or ensure data confidentiality, you will need to use encryption.</p>
<h2 id="code-and-data-encryption">Code and data encryption</h2>
<p>You may want to encrypt data or code in an embedded Linux device.</p>
<p>Data encryption is a common approach when you need to protect the privacy and confidentiality of the users. Data is any information generated during the executing of the device, including databases, configuration files, and so on.</p>
<p>Code encryption depends on the situation, and encrypting the full root filesystem is not that common. Usually, most of the components are free and open source software, so there is nothing to hide. There is also the issue of GPLv3 and Tivoization (using any GPLv3 software will force you to provide a mechanism for the user to update the software, and that would make it more difficult if you are encrypting it). A more common use case is to encrypt only the applications you developed for the device. It’s usually where your intellectual property is.</p>
<p>There are basically two main approaches to encryption in Linux: <strong>full disk encryption</strong> and <strong>file-based encryption</strong>.</p>
<p>Full disk encryption provides encryption at the block level and the whole disk or a disk partition is encrypted. For that, we can use <a href="https://en.wikipedia.org/wiki/Dm-crypt">dm-crypt</a>, the Linux kernel’s device mapper crypto target.</p>
<p>File-based encryption provides encryption at the file system level, where each directory may be separately and optionally encrypted with a different key. The two most common implementations of file-based encryption are <a href="https://wiki.archlinux.org/index.php/Fscrypt">fscrypt</a> and <a href="https://wiki.archlinux.org/index.php/ECryptfs">eCryptFS</a>. fscrypt is an API available on some filesystems like EXT4, UBIFS and F2FS, and eCryptFS is a more generic solution implemented as a layer that stacks on top of an existing filesystem.</p>
<p>But what about the keys used for encryption?</p>
<h2 id="encryption-keys">Encryption keys</h2>
<p>Since an asymmetric key algorithm is too slow to be used in encryption, usually a symmetric-key algorithm is used in encryption. That means the same key is used for encryption and decryption, and the key should be available somewhere in the filesystem so the encrypted code/data can be decrypted.</p>
<p>But we can’t just leave the key lying around in the filesystem, right?</p>
<p>There are several cases where companies …</p></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://embeddedbits.org/introduction-embedded-linux-security-part-1/">https://embeddedbits.org/introduction-embedded-linux-security-part-1/</a></em></p>]]>
            </description>
            <link>https://embeddedbits.org/introduction-embedded-linux-security-part-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25015821</guid>
            <pubDate>Sat, 07 Nov 2020 16:05:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why not use GraphQL?]]>
            </title>
            <description>
<![CDATA[
Score 410 | Comments 380 (<a href="https://news.ycombinator.com/item?id=25014582">thread link</a>) | @jensneuse
<br/>
November 7, 2020 | https://wundergraph.com/blog/why_not_use_graphql | <a href="https://web.archive.org/web/*/https://wundergraph.com/blog/why_not_use_graphql">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>I think GraphQL will change the world. There will be a future where you can query any system in the world using GraphQL. I'm building this future. So why would I argue against using GraphQL? My personal pet peeve is when the community keeps advertising benefits of GraphQL that are very generic and really have nothing to do with GraphQL. If we want to drive adoption, we should be honest and take off the rose-tinted glasses. This post is a response to "Why use GraphQL" by Kyle Schrade (<a href="https://www.apollographql.com/blog/why-use-graphql/" target="_blank" rel="noopener noreferrer">https://www.apollographql.com/blog/why-use-graphql/</a>). It’s not meant to be direct criticism. The article is just an excellent base to work with as it represents opinions I keep hearing a lot in the community. If you read the whole article, it’ll take some time, you’ll fully understand why I think Kyle’s article should be named “Why use Apollo”.</p><p>If you haven't read Kyles's article already, I think it makes most sense if you read it first: <a href="https://www.apollographql.com/blog/why-use-graphql/" target="_blank" rel="noopener noreferrer">https://www.apollographql.com/blog/why-use-graphql/</a></p><p>The author states that REST APIs come with a set of downsides and how GraphQL solves all of them:
Over-fetching
Multiple requests for multiple resources
Waterfall network requests on nested data
Each client need to know the location of each service</p><p>The first three issues could be solved by writing another REST API as a facade for a specific user interface. Take Next.JS as an example. Next lets you define APIs with a very lightweight syntax. Instead of making multiple requests from the client, you can wrap those calls into an API and make them server-side. Over and underfetching can be solved with this approach too, as you can manipulate the data before sending it back to the client. The pattern described is named "backend for frontend" (BFF). It's not limited to full stack frameworks like Next.JS. You can build a BFF for your mobile apps as well.</p><p>With the BFF pattern, the client itself doesn't have to know the location of each service. However, the developer who implements the BFF needs to understand the service landscape. Hopefully you have Open API Specifications for all your services, nicely presented in a developer portal. If that's the case, it should be easy to write a BFF.</p><p>With GraphQL, there still needs to be a developer who implements the resolvers. Implementing the resolvers is more or less the same task as building a BFF, the logic is very similar. So, what's the real difference?</p><p>The BFF is easier to implement as there's a lot more tooling available. E.g. if you use a framework like Next.JS in combination with swr hooks (stale while revalidate) you get automatic caching with Etags and cache invalidation out of the box. This reduces the amount of data sent between server and client. It's even less data than GraphQL, because you're not sending query payloads and the server responds with 304 (Not Modified) if the response is still valid. Additionally, you don't have to use a heavyweight client like Apollo. The library swr by Vercel is small and very easy to use. It comes with support for pagination, hooks, and helps to navigate back and forth very efficiently.</p><p>GraphQL has persisted queries but it comes with additional overhead to implement this. If you don't use a client like Relay, which persists Queries by default, you have to do it on your own or use some third party library to implement it. Compared to the BFF approach using e.g. Next.JS there's a lot more complexity involved in getting to the same results on the frontend. How would you implement Etags with GraphQL? How do you make your GraphQL server return 304 status codes if nothing changed? Don't you first have to turn all Queries into GET requests? If so, does your GraphQL client and server easily support this?</p><p>When it comes to user experience and ease of development, the BFF is the clear winner. Less data transfer between client and server. Easier to implement. Smaller client, less moving parts.</p><p>But there's a catch. You have to build a BFF for each individual frontend. If you have many of them this can be a lot of work. You have to maintain all the BFFs. You have to operate them. You have to secure them.</p><p>Wouldn't it be nice if you could have the benefits of both without making tradeoffs? This is exactly what WunderGraph is. A framework to build BFFs using GraphQL.</p><p>In the next paragraph, Kyle goes on with the problems involved with versioned APIs. He's absolutely right that having too many versions of an API makes it very hard to keep track of. He then concludes that in GraphQL, there's only one version of the graph and changes can be tracked in a schema registry, a paid feature of Apollo. For that reason you won’t have any problems with versioning, he says.</p><p>I have problems coming to the same conclusion. Just because GraphQL schemas don’t support versioning natively doesn’t mean the problem goes away. You get the same effect if you just don’t version your REST APIs. In fact, many experts say that you should always try to not introduce versions of an API if you don’t have to. That being said, what holds you off running two versions of your GraphQL schema? Not that I think this is a good idea but it's technically possible.</p><p>If having too many versions of your REST APIs is a problem in your organization, before throwing a new tool like GraphQL at the problem, maybe you should have a look at the organization first. What are the reasons for having so many versions? Maybe the change of a process or new team structures can help? GraphQL does absolutely nothing to solve your versioning problems. Instead I think it actually makes the situation worse.</p><p>Do you have to support mobile applications? You should be aware that shipping native apps takes time. You have to wait for app store approval and you can expect many of your users to never (or slowly) install the new version. What if you want to introduce a breaking change in this scenario without breaking a client? It's impossible. You have to introduce this change in a non-breaking way. It would be interesting to hear from Facebook how they avoided breaking clients.</p><p>Evolving your schema in the case of GraphQL would mean, you deprecate the old field and add a new one. New clients use the new field while you hope that the number of clients using the old field will get less and less. Hopefully, you have a system in place that forces your users to download a new version at some point in time. Otherwise, you might be forced to support the deprecated field indefinitely. If that's the case, the deprecation model of GraphQL doesn't help you at all.</p><p>With REST you could create a new endpoint or another version of an existing one. The problem is the same, the solution just looks a bit different.</p><p>To make it clear, if you cannot control your clients you really want some kind of versioning. If all you have is a single web application you won’t need this feature. But then again GraphQL might be overkill as well.</p><p>In this paragraph, the author states that RESTful APIs don't allow partial responses.</p><p>This is just wrong. Here's an example:</p><div><div><div tabindex="0"><div><p><span>GET /users?fields=results(gender,name)</span></p></div></div></div></div><p>What does the author actually mean? I'm pretty sure he's aware of partial responses. I guess what he's trying to say is that someone needs to implement partial responses. Actually, it looks very familiar to GraphQL as you're selecting subfields from a resource. With GraphQL we have this feature out of the box.</p><p>On the other hand, with the BFF approach, you don't need this. Just return exactly the data you need. Again, a full-stack framework like Next.JS makes it simpler to implement this, makes caching easier and gives you Etag based cache invalidation for free.</p><p>To sum this section up, GraphQL gives you exactly the data you need. Partial responses can achieve the same result. BFFs come with the additional cost of implementation and maintenance but have a better UX &amp; DX.</p><p>In this paragraph, Kyle addresses the issues of REST APIs not being strictly typed. He talks about the problems with APIs where it's not clear if you get an array of posts or something different and how query parameters complicate the situation. He also states that GraphQL, because of its strict type system, doesn't have this problem.</p><p>I think what Kyle is talking about is an organizational problem for which you need an organizational solution.</p><p>You have the kind of problems he describes, when you allow developers to deploy REST APIs without publishing Open API Specifications (OAS) or similar. With OAS all resources can be described very easily. OAS also allows you to describe OAuth2 flows and required scopes per endpoint. Additionally, you can describe the exact types and validation rules for query parameters, a feature that GraphQL is lacking.</p><p>Looking at GraphQL, there's no way to describe Authentication, Authorization and input validation. GraphQL is lacking these features because the inventors at Facebook solved this problem at a different layer. There was no need for them to add these features to GraphQL. You can add custom directives to your schema to achieve similar results like OAS but this would be a custom implementation which you have to maintain yourself.</p><p>You might be thinking that OAS doesn't guarantee the response of an API to be compliant with the specification. You would be right. But how does a GraphQL schema guarantee anything?</p><p>GraphQL introspection is the act of sending a specific GraphQL query to the server to get information about the GraphQL schema. The GraphQL server is free to answer with whatever types it wants to. If you send a Query, the server can answer with a response that doesn't adhere to the GraphQL schema from the introspection response. Take Apollo Federation as an example. You upload your schema into a schema registry and then, by error, deploy the wrong version of your GraphQL server. If you change the type of a field, the client might be confused.</p><p>When we talk about type safety in GraphQL, what we actually mean is that we trust in a GraphQL server to behave exactly as advertised by the introspection Query …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wundergraph.com/blog/why_not_use_graphql">https://wundergraph.com/blog/why_not_use_graphql</a></em></p>]]>
            </description>
            <link>https://wundergraph.com/blog/why_not_use_graphql</link>
            <guid isPermaLink="false">hacker-news-small-sites-25014582</guid>
            <pubDate>Sat, 07 Nov 2020 11:57:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Advanced Join Patterns for the Actor Model Based on CEP Techniques]]>
            </title>
            <description>
<![CDATA[
Score 82 | Comments 19 (<a href="https://news.ycombinator.com/item?id=25014513">thread link</a>) | @mpweiher
<br/>
November 7, 2020 | https://programming-journal.org/2021/5/10/ | <a href="https://web.archive.org/web/*/https://programming-journal.org/2021/5/10/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
            


            
            
            <p>Humberto Rodriguez Avila<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>, Joeri De Koster<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>, and Wolfgang De Meuter<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup></p>

<p>The Art, Science, and Engineering of Programming, 2021, Vol. 5, Issue 2, Article 10</p>

<p>Submission date: 2020-02-06<br>
Publication date: 2020-11-02<br>
DOI: <a href="https://doi.org/10.22152/programming-journal.org/2021/5/10">https://doi.org/10.22152/programming-journal.org/2021/5/10</a><br>
Full text: <a href="https://arxiv.org/pdf/2010.16301v1">PDF</a></p>

<h3 id="abstract">Abstract</h3>
<p>Context: Actor-based programming languages offer many essential features for developing modern distributed reactive systems. These systems exploit the actor model’s isolation property to fulfill their performance and scalability demands. Unfortunately, the reliance of the model on isolation as its most fundamental property requires programmers to express complex interaction patterns between their actors to be expressed manually in terms of complex combinations of messages sent between the isolated actors.</p>

<p>Inquiry: In the last three decades, several language design proposals have been introduced to reduce the complexity that emerges from describing said interaction and coordination of actors. We argue that none of these proposals is satisfactory in order to express the many complex interaction patterns between actors found in modern reactive distributed systems.</p>

<p>Approach:  We describe seven smart home automation scenarios (in which an actor represents every smart home appliance) to motivate the support by actor languages for five radically different types of message synchronization patterns, which are lacking in modern distributed actor-based languages. Fortunately, these five types of synchronisation patterns have been studied extensively by the Complex Event Processing (CEP) community. Our paper describes how such CEP patterns are elegantly added to an actor-based programming language.</p>

<p>Knowledge: Based on our findings, we propose an extension of the single-message matching paradigm of contemporary actor-based languages in order to support a multiple-message matching way of thinking in the same way as proposed by CEP languages. Our proposal thus enriches the actor-model by ways of declaratively describing complex message combinations to which an actor can respond.</p>

<p>Grounding: We base the problem-statement of the paper on an online poll in the home automation community that has motivated the real need for the CEP-based synchronisation operators between actors proposed in the paper. Furthermore, we implemented a DSL —— called Sparrow —— that supports said operators and we argue quantitatively (in terms of LOC and in terms of a reduction of the concerns that have to be handled by programmers) that the DSL outperforms existing approaches.</p>

<p>Importance: This work aims to provide a set of synchronization operators that help actor-based languages to handle the complex interaction required by modern reactive distributed systems. To the best of our knowledge, our proposal is the first one to add advanced CEP synchronization operators to the —— relatively simplistic single-message based matching —— mechanisms of most actor-based languages.</p>



          </section></div>]]>
            </description>
            <link>https://programming-journal.org/2021/5/10/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25014513</guid>
            <pubDate>Sat, 07 Nov 2020 11:36:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Arch Conf 2020]]>
            </title>
            <description>
<![CDATA[
Score 110 | Comments 34 (<a href="https://news.ycombinator.com/item?id=25014421">thread link</a>) | @todsacerdoti
<br/>
November 7, 2020 | https://media.ccc.de/c/arch-conf-2020 | <a href="https://web.archive.org/web/*/https://media.ccc.de/c/arch-conf-2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://media.ccc.de/c/arch-conf-2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-25014421</guid>
            <pubDate>Sat, 07 Nov 2020 11:09:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Raspberry Pi 400 – First Impressions]]>
            </title>
            <description>
<![CDATA[
Score 234 | Comments 138 (<a href="https://news.ycombinator.com/item?id=25014025">thread link</a>) | @martinpeck
<br/>
November 7, 2020 | https://martinpeck.com/blog/2020/11/06/Raspberry-Pi-400/ | <a href="https://web.archive.org/web/*/https://martinpeck.com/blog/2020/11/06/Raspberry-Pi-400/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p>I grew up programming on my TV, with a Sinclair ZX81 followed by a ZX Spectum. Computers built into keyboards, that you can easily plug into a TV, are part of my DNA. So, given this, how could I resist buying the new <a href="https://www.raspberrypi.org/products/raspberry-pi-400/">Raspberry Pi 400</a>!?</p>

<p>The following are my initial thoughts on the hardware, and on using it for light weight development.</p>

<p>TL;DR: I like it :)</p>

<h2 id="tech-specs">Tech Specs</h2>

<p>The Raspberry Pi 400 is, essentially, a Raspberry Pi 4 housed within a keyboard. You can read much better descriptions elseewhere, but the main points from the tech specs are:</p>

<ul>
  <li>Broadcom BCM2711 quad-core Cortex-A72 (ARM v8) 64-bit SoC @ 1.8GHz</li>
  <li>4GB LPDDR4-3200</li>
  <li>Dual-band (2.4GHz and 5.0GHz) IEEE 802.11b/g/n/ac wireless LAN</li>
  <li>Bluetooth 5.0, BLE</li>
  <li>Gigabit Ethernet</li>
  <li>2 × USB 3.0</li>
  <li>1 × USB 2.0 ports</li>
  <li>Horizontal 40-pin GPIO header</li>
  <li>2 × micro HDMI ports (supports up to 4Kp60)</li>
  <li>MicroSD card slot for operating system and data storage</li>
  <li>79-key compact keyboard</li>
</ul>

<p>(full specs can be found <a href="https://www.raspberrypi.org/products/raspberry-pi-400/specifications/">here</a>)</p>

<p>The 400 comes with a 16GB SD card pre-installed with Raspbian, and a host of apps (LibreOffice), dev tools (Geany, Mathematica, Scratch), utilities (Chromium, VLC Media Player), and games (Minecraft).</p>

<h2 id="first-impressions-on-the-hardware">First Impressions on the Hardware</h2>

<p>It was <em>very</em> easy to plug the 400 in and get it up and running. It’s a neat device, with a good collection of ports and connectors at the back. The keyboard is…ok. The device is £67 in the UK. I bought the kit (which includes a mouse, power supply, HDMI cable, and official guide) for £94. Given the price point the keyboard is absolutely fine, but it does feel a tiny bit “plasticy”.</p>

<p>The 400 doesn’t have an audio-out. Audio is delivered via the HDMI output. For me, that’s a problem because my monitor doesn’t have speakers. It’s not a BIG problem, but it’s something I hadn’t considered.</p>

<p>The other thing the 400 doesn’t have is the connector for the Raspberry Pi camera module. Again, this isn’t a big deal for me but if you were expecting to build any camera projects then the 400 isn’t the right choice.</p>

<p>The 400has the GPIO header at the back, so with a ribbon cable you can build electronics projects very easily. I have an <a href="https://www.adafruit.com/product/2028">Adafruit T-Cobbler Plus</a> which makes it very easy to connect the 400 to a breadboard and build…stuff!</p>

<p><img src="https://martinpeck.com/images/rpi400/gpio.jpg" alt="GPIO"></p>

<p>The 400 starts up quickly, and is very capable as a general purpose desktop device. I’ve spent most of today browsing the web on it, while also installing apps, running docker containers, and building code, and it’s felt fast/snappy pretty much most of the time.</p>

<p>Overall, the hardware is pretty good and I love the form factor. I can see schools/code clubs purchasing these devices and using the in their computing labs.</p>

<h2 id="developer-experience">Developer Experience</h2>

<p>I’ve spent the day setting my Raspberry Pi 400 up, and I’m pretty impressed. My setup has included:</p>

<ul>
  <li>Set up Chromium, and installed the <a href="https://1password.com/">1Password extension</a></li>
  <li>Installed <a href="https://code.visualstudio.com/">Visual Studio Code</a> using <a href="https://pimylifeup.com/raspberry-pi-visual-studio-code/">these instructions</a></li>
  <li>Installed the <a href="https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers">VS Code Remote Containers extension</a> so that I can use Docker dev containers to develop code within</li>
</ul>

<p>On the whole, this setup was easy. So easy it was almost boring! I had a couple of issues, but on the whole it was very easy to set my Raspberry Pi 400 up so that I can write code, use Docker, and push changes to GitHub. For example, I’m currently writing this blog post within VS Code, building it using <a href="https://jekyllrb.com/">Jekyll</a> within a Docker container.</p>

<p>The only issue that I hit is the ARM support for various Docker images. The default Ruby dev container image wouldn’t build because it had some dependencies that didn’t have ARM variants. In the end I took the Ruby 2.7 docker image as a base, and copy/pasted into my own <code>Dockerfile</code> the parts of the defintion I needed (removing Node, Zsh, Oh my Zsh and a few other things). I’m not sure exactly what it was that was failng to build, so I need to go back and work it out, but it’s worth remembering that if the Rasberry Pi is ARM based, and not all development tools have ARM builds.</p>

<p>Having installed tools, and played around, I’ve built some very basic Rust code (with build times comparible to my MacBook!), I’ve written some <a href="https://gpiozero.readthedocs.io/en/stable/">GPIOZero</a> based Python 3 code (controlling butons and LEDs), and I’ve set up a Jekyll/Ruby dev container and built/updated my blog.</p>

<h2 id="conclusion">Conclusion</h2>

<p>I own several Raspberry Pi computers (1, 2 and 3). Most of them are the Model B format, but I have couple of Zeros too. All of them sit in a box, unused. I’ve played with them, then put them away. Part of that is because the performance hasn’t been that great, but the form factor is a major factor. It feels like the Raspberry Pi 400 has the power I need (for casual projects), and comes in a form factor that I can happily leave plugged in on my desk.</p>

<p>On top of that…it gives me a massive nostalgia rush using it!</p>

<p><img src="https://martinpeck.com/images/rpi400/desktop.jpg" alt="GPIO"></p>

<p>In the picture below I have two instances of VS Code (both running dev containers), plus I’m browsing. It takes it all in its stride.</p>

<p><img src="https://martinpeck.com/images/rpi400/pi-400-desktop.png" alt="GPIO"></p>

<p>I’ve not tried building anything huge…but that’s not what it’s for. It’s for having fun…</p>

<p>…and I’m <strong>absolutely having fun</strong>!</p>

			</div></div>]]>
            </description>
            <link>https://martinpeck.com/blog/2020/11/06/Raspberry-Pi-400/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25014025</guid>
            <pubDate>Sat, 07 Nov 2020 09:19:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[US Government Continues Encryption War]]>
            </title>
            <description>
<![CDATA[
Score 235 | Comments 84 (<a href="https://news.ycombinator.com/item?id=25013802">thread link</a>) | @freddyym
<br/>
November 7, 2020 | https://blog.privacytools.io/us-government-continues-encryption-war/ | <a href="https://web.archive.org/web/*/https://blog.privacytools.io/us-government-continues-encryption-war/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.privacytools.io/content/images/size/w300/2020/10/binarycrypto.png 300w,
                            https://blog.privacytools.io/content/images/size/w600/2020/10/binarycrypto.png 600w,
                            https://blog.privacytools.io/content/images/size/w1000/2020/10/binarycrypto.png 1000w,
                            https://blog.privacytools.io/content/images/size/w2000/2020/10/binarycrypto.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.privacytools.io/content/images/size/w2000/2020/10/binarycrypto.png" alt="US Government Continues Encryption War">
            </figure>

            <section>
                <div>
                    <p>Wars can be fought in the real world but there is also a virtual battlefield - and it is just as harmful. The <a href="https://www.judiciary.senate.gov/press/rep/releases/graham-cotton-blackburn-introduce-balanced-solution-to-bolster-national-security-end-use-of-warrant-proof-encryption-that-shields-criminal-activity">Lawful Access to Encrypted Data Act</a> is the latest attempt to access people's encrypted data and it serves as another reinforcement.</p><blockquote>This type of “warrant-proof” encryption adds little to the security of the communications of the ordinary user, but it is a serious benefit for those who use the internet for illicit purposes.</blockquote><p>This statement is plainly false. Encryption has as much benefit, if not more, for ordinary users. Encryption is used in every website that has the padlock sign (HTTP<strong>S</strong>), in every iPhone app since 2016, in every Android app since 2018 and in almost every modern application - and for good reason. Encryption helps protect sensitive information (such as that shared with your bank, or any time you use a password on a website). It may also help protect files which are not in use (at rest), or in the event the server is accessed by an unauthorised person (such as a criminal attempting to siphon off important data).</p><p>In 2016, Bruce Schneier wrote an article on <a href="https://www.schneier.com/essays/archives/2016/04/the_value_of_encrypt.html">the value of encryption</a> clearly outlining why encryption is needed. Schneier went on to say that when the US Government was <a href="https://blog.privacytools.io/us-government-wages-war-on-encryption/">previously</a> <a href="https://en.wikipedia.org/wiki/Crypto_Wars">fighting cryptography</a>, he wondered if they were aware how much they relied on it themselves. No-one is above the law, so if you ban strong encryption, the FBI should not use it either. Attorney General Barr, <a href="https://www.theregister.com/2019/07/23/us_encryption_backdoor/">gives the impression</a> that the government, along with certain large companies, should have an exception to the law. Barr recognises that there are some things that are secret, but he doesn't recognise that regular citizens might also want to enjoy privacy as well.</p><blockquote>“We are not talking about protecting the nation’s nuclear launch codes,” Barr told the International Conference on Cyber Security at Fordham University.</blockquote><blockquote>“Nor are we necessarily talking about the customized encryption used by large business enterprises to protect their operations. We are talking about consumer products and services such as messaging, smart phones, email, and voice and data applications."</blockquote><p>Somehow, because your average Joe does not have government level secrets, he is no longer entitled to encryption. We are all humans, and we all need privacy. By taking away encryption, you are taking away privacy online.</p><p>This act is aimed at Section 230, which ensures that no interactive computer service provider shall be treated as the publisher or speaker of content published by their users - an essential part of the survival of all search engines, social media platforms and video sharing sites. Without it, the internet would become a self-censored platform – one that is more concerned with fending off lawsuits than providing a medium for ideas and innovation as it originally was.</p><p>It is easy to sympathise with an act that is being pushed through on the grounds that terrorists, paedophiles and drug-dealers all use encryption. Reading the <a href="https://www.nytimes.com/interactive/2019/09/28/us/child-sex-abuse.html">New York Times</a>' <a href="https://www.nytimes.com/2020/02/19/podcasts/the-daily/child-sex-abuse.html">reporting</a> on online images of &nbsp;sexual abuse would leave some wondering why this sort of Act has not been passed already. Equally, if no-one had encryption then it would certainly be easier to catch above mentioned crooks and fellons.</p><p>Encryption, however, did not create these problems; these crimes were around long before it came into existence. In addition, those who partake in illicit activity will always find loopholes and ways to do so, such as using products or encryption tools that don't have backdoors. Criminals do not obey laws by definition. Furthermore, many innocent people use similar encryption to these criminals, but only to protect privacy, not hide any illegalities and yet they could still be subject to some kind of prosecution. It is assumed the use or possession of non-backdoored software would also become an offence if too many people used that instead. Statistically, it's agreed there are many more innocent people in society than criminals; those innocent people would be punished as a result of the bad actions of a few.</p><p>It is not feasible for a government to make a law of this sort that can apply outside of it's own country. Governments around the world would almost certainly disagree on which countries should be allowed access to the backdoor. As a result, this backdoor would most certainly lead to every unauthorised party having access, as the key to decrypt the data would be discovered by third parties, this would result in completely broken encryption for all. In federated networks, such as Matrix, it's not even possible to add a backdoor to every homeserver. Federation decentralises trust, which means that the person deploying the server isn't necessarily the same entity who makes the client software or server software. Matrix has even written a <a href="https://matrix.org/blog/2020/10/19/combating-abuse-in-matrix-without-backdoors">thorough article</a> on how to combat this sort of abuse without backdoors. </p><p>Weakening encryption will only result in criminals using strong encryption anyway, without fighting any of the problems that the the law claims to solve. There is no easy solution, and it is down to politicians to provide one. Yes, encryption can be used by people with bad intentions, but it is also used by so many ordinary people who would never think to use it in a malicious way. Nearly every tool in life can be used for nefarious purposes, but does not mean it should be unavailable for legitimate non-criminal uses. You could hit someone with a hammer, but it doesn't mean hammers should be made out of foam, because if they were, people would just use knives instead. Weakening encryption will not solve these issues, and that's probably because they were not the the focus of the Act. Instead, it seems that this law seeks to criminalises strong encryption that does not have backdoors, even though the government knows full well that this will not stop criminals. The US Government should stop devising new ways to breach its citizens privacy, and focus on combating the issues that this Act fails to.</p><p>In 1988, Timothy May <a href="https://activism.net/cypherpunk/crypto-anarchy.html">predicted</a> that “the State will of course try to slow or halt the spread of [encryption], citing national security concerns, use of the technology by drug dealers and tax evaders, and fears of societal disintegration”. He was spot on.</p><p><em>Cover artwork by <a href="https://setofprinciples.com/">Zan</a></em></p>
                </div>
            </section>


            

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.privacytools.io/us-government-continues-encryption-war/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25013802</guid>
            <pubDate>Sat, 07 Nov 2020 08:22:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is this Mahler? This sounds like Mahler]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25012900">thread link</a>) | @luu
<br/>
November 6, 2020 | http://sarabee.github.io/2020/09/13/is-this-mahler/ | <a href="https://web.archive.org/web/*/http://sarabee.github.io/2020/09/13/is-this-mahler/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="http://sarabee.github.io/images/whatnow-crop.jpg" width="180">
One of the most delightful parts of being a software engineer and hardware
tinkerer is having the ability to solve my own specific (and often niche)
problems. In this post, the particular problem I’ll be solving is the burning
need to know what is currently playing on <a href="https://www.wqxr.org/">WQXR</a>, NYC’s classical radio station.</p>

<p>A typical Saturday for me looks like this: I wake up and make a coffee, bring
it to the couch in the living room, pick up my knitting, and turn on the radio. Maybe midway through the morning
a halfway-familiar piece comes on, but I’ve left my phone in the other room and won’t be
able to go check the WQXR website without disentangling myself from my
knitting and missing a bit of the piece that has captured my attention.</p>

<p>Or how about a weekday: I’m working on a project, elbows deep in the code, with the WQXR livestream open in one of my million
browser tabs. I feel a glimmer of recognition, but I’m fully focused on my
work and don’t want to break my concentration to go hunt down the livestream
player and find out what it is.</p>

<p>To solve this particular problem, I needed two things: a way to find out what
was on the radio, and a place to display it.</p>

<p>There are a couple of different ways you could find out what’s playing,
including music identification services like Shazam. But those rely on already
having a recording in their database to match against, and I’m listening to
classical music where I could be hearing any one of dozens of different
recordings (and even live performances) for any given piece, making it
unlikely that such a service would be able to find a match. So I started with
the source I was already using to get this information: the WQXR website.</p>

<p>If you leave the website open long enough, you’ll notice that it automatically
updates to reflect what’s currently playing. This was great news for me,
because it meant that somewhere in the page a script is periodically making
ajax requests to get that information, requests that I could also make myself.
To find out what these requests were, I eavesdropped on my browser’s network
calls using the developer console.</p>

<p><img src="http://sarabee.github.io/images/wqxr-network.jpg" width="500"></p>

<p>There are two calls being made here, one to an endpoint called streams,
and one to something very promisingly named <code>whats_on</code>. Making a request to
that second endpoint, we get a beautiful json response containing information
about what’s playing on New York Public Radio’s various livestreams. Great!
This is exactly what I need to satisfy the first piece of this project.</p>

<p>(I honestly can’t remember how I figured this out, but you can append the call
letters for the particular station you’re interested in to the URI to just get
information for that stream, but the full response would also have worked just
fine.)</p>

<p>Okay, cool, so I have the data. How do I get this information in front of my
eyeballs when I’m listening to the radio?</p>

<p>You already know from the teaser photo at the top of the post that
I ultimately put it on my mantel, but I took an iterative approach to getting
there.</p>

<p>I use tmux to manage my terminal sessions, and it occurred to me that the
status bar, always there along the bottom of my terminal, might be a nice
place to have information about what’s currently playing. I wrote some
lightweight python classes for fetching and parsing the radio’s API response,
and a tiny script, <code>tmux.py</code> that outputs the information in the format I want for this
purpose.</p>

<p>Adding something to the tmux status bar is just a matter of adding a couple of
lines to <code>.tmux.conf</code>:</p>

<figure><pre><code data-lang="bash"><span>set</span> <span>-g</span> status-right-length 200
<span>set</span> <span>-g</span> status-right <span>'#[bg=#d7ff5f] #(python3
/home/sarabee/development/nowplaying/tmux.py)  |  [%H:%M] '</span></code></pre></figure>

<p>This overwrote the clock that was there by default, so I added one back in. By
default, scripts run in <code>.tmux.conf</code> are executed once every 15 seconds, which
was more than fast enough for my purpose. My status bar then looks like this:</p>

<p><img src="http://sarabee.github.io/images/now-playing.jpg"></p>

<p>This fixed the problem of not wanting to leave my terminal to find out what
I’m listening to, but what about when I’m in the living room? I knew I wanted
a display, that I wanted it to update automatically, like the tmux status bar,
that I wanted it to be constantly running, like an indoor thermometer readout,
and that I wanted it to be readable from any position in the room, with good
view angles and readability under a variety of lighting conditions.  This all
sounded to me like the <em>perfect</em> excuse to work with e-paper.</p>

<p><a href="http://shop.pimoroni.com/">Pimoroni</a> was having a sale, so I picked up two e-ink displays: the smaller inkypHAT, and the
larger inkywHAT. I also got a couple of Raspberry Pi Zero Ws to pop them on
top of (quick aside: these things cost $10 and have wifi and bluetooth, wowww).</p>

<p>Starting with the inkypHAT and the code I’d already written for handling radio
data, I prototyped my idea, creating a tiny display that sits on top of my
monitor. I set the Pi Zeroes up the way I set up my larger Raspberry Pi 3,
with Raspbian Lite. Without worrying too much about styling the display
aesthetically, I learned how to work with the
<a href="https://github.com/pimoroni/inky">Inky</a> and
<a href="https://pillow.readthedocs.io/en/stable/">Pillow</a> libraries and
wrote a script to get the composer and title chopped up to fit across multiple
lines on the screen:</p>

<p><img src="http://sarabee.github.io/images/wqxr-phat.jpg" width="500"></p>

<p>I have it running once a minute on a cron, and to avoid refreshing the e-ink
display unnecessarily, I keep the last piece written to the display in memory and
update only if I’ve gotten something new back from WQXR.</p>

<p>Reworking this script for the larger inkywHAT display wasn’t difficult; it
mostly involved tweaking font size to take advantage of the larger screen. But
since this is meant to live on my mantel and be highly visible in my living
room, I wanted to make it look a bit nicer than just throwing the text on
there. I found a clip-art scrollwork frame, and using only the MacOS Preview
app and ImageMagick, got it into the right size and format
for the e-ink display.</p>

<p>In Preview, I grabbed a corner of the frame and pasted it in again three more
times, rotated 90 degrees each time, and carefully bumped each corner around
until they were lined up and could be scaled down reasonably to the right
dimensions (400x300px). Even though the image appeared to be entirely black
and white, a closer look shows this wasn’t true at all! It’s actually full of
many different shades of gray:</p>

<p><img src="http://sarabee.github.io/images/whatnow-corner.png" width="300"></p>

<p>To get the image into the right format and flatten it down to just two colors,
I used the <a href="https://imagemagick.org/script/command-line-processing.php">ImageMagick command-line
tools</a>. While <a href="http://www.imagemagick.org/Usage/quantize/#two_color">this
extremely thorough page</a> in the IM docs goes pretty far in-depth with the
various ways you can convert an image to black and white, I ultimately ended
up going with:</p>

<figure><pre><code data-lang="bash">magick input.png <span>-colorspace</span> gray <span>-colors</span> 2 <span>-normalize</span> PNG8:output.png</code></pre></figure>

<p>Which produces a frame that looks like this:</p>

<p><img src="http://sarabee.github.io/images/whatnow-frame.png"></p>

<p>It’s a little rough when you see it on a relatively high resolution monitor, but looks great on the 400x300 e-ink
display! After that, adding the text was pretty straightforward;
earlier when only displaying text, I was still actually using Pillow to create an empty
image in the correct dimensions that I drew the text onto:</p>

<figure><pre><code data-lang="python"><span>img</span> <span>=</span> <span>Image</span><span>.</span><span>new</span><span>(</span><span>"P"</span><span>,</span> <span>(</span><span>inky_display</span><span>.</span><span>WIDTH</span><span>,</span> <span>inky_display</span><span>.</span><span>HEIGHT</span><span>))</span></code></pre></figure>

<p>To use the frame, I simply started with the frame image instead:</p>

<figure><pre><code data-lang="python"><span>img</span> <span>=</span> <span>Image</span><span>.</span><span>open</span><span>(</span><span>os</span><span>.</span><span>path</span><span>.</span><span>join</span><span>(</span><span>current_dir</span><span>,</span>
<span>"whatnow.png"</span><span>)).</span><span>resize</span><span>(</span><span>inky_display</span><span>.</span><span>resolution</span><span>)</span></code></pre></figure>

<p>The last little bit of clean-up work involved getting the text centered in the
frame, and setting the margins in my script so that the line breaks were
a comfortable distance from its edges.</p>

<p><img src="http://sarabee.github.io/images/whatnow-closeup.jpg" width="500"></p>

<p>I’m happy with where this project is at; the text is clear and legible from
anywhere in my living room, and my Saturday morning listening experience has
been greatly improved. Eventually, it’ll get custom wooden housing, which will
be its own post, I’m sure! Feel free to dig around in <a href="https://github.com/SaraBee/nowplaying">the project’s repo on
GitHub</a> to get an even better idea of how this all works.</p>
</div></div>]]>
            </description>
            <link>http://sarabee.github.io/2020/09/13/is-this-mahler/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25012900</guid>
            <pubDate>Sat, 07 Nov 2020 02:49:38 GMT</pubDate>
        </item>
    </channel>
</rss>
