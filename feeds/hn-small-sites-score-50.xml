<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 20 Sep 2020 08:24:01 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 20 Sep 2020 08:24:01 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[How can we, as web professionals, help to make the web more energy efficient?]]>
            </title>
            <description>
<![CDATA[
Score 107 | Comments 223 (<a href="https://news.ycombinator.com/item?id=24513427">thread link</a>) | @giuliomagnifico
<br/>
September 17, 2020 | https://cmhb.de/web-design-and-carbon-impact | <a href="https://web.archive.org/web/*/https://cmhb.de/web-design-and-carbon-impact">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
<section>
    <div><blockquote>
<p>How can we, as web professionals, help to make the web more energy efficient?</p>
</blockquote>
<p>From data centres to transmission networks to the devices that we hold in our hands, it is all consuming electricity, and in turn producing carbon emissions. According to recent estimates, the entire network already consumes 10% of global electricity production, with data traffic doubling roughly every two years. It’s probably something very few people think about, or are even aware of as being an issue. But the fact of the matter is that the Internet consumes a huge amount of electricity. And when it comes to web design, there is a lot that can be done to make the web far more energy efficient.</p>
<hr>
<h2>Attitudes</h2>
<p>Creating a website is a lot more accessible today, made simpler by the emergence of no-code site builders. But it might be asking a lot for your typical web user or amateur creator to be aware of the environmental impact of their site. This, however, shouldn’t really be the case for any digital professional. Naturally, web developers will be more conscious of the weight of their pages, given that they are fully immersed in the code and content management that serves what you see on a web page. But even then, many developers simply look for the quickest route to completing a project, rather than the best way to produce the quickest and most efficient site. </p>
<p>So they load a website with bulky Javascript and third-party tools to meet the visual specification of the client or designer. As long as it works, right? They probably don’t care. They’re probably happy with their site that loads quickly on their 500Mbps connection. Who cares if they’re wasting expensive data on mobile connections in other countries? “But Carl, some of us don’t have the luxury of building super high-performance, lightweight, and optimised sites due to client budgets and deadlines.” Well, I think you need to work on your craft, change your attitude and your priorities, or find another profession.</p>
<p>When we talk about the energy efficiency of websites, it’s easy to assume that it’s a purely technical topic. However, efficiency can be improved before we even build a website. Design and content have a big impact on energy efficiency.</p>
<p>Therefore, some of the biggest contributors to heavy sites and large CO2 emissions, are <em>designers</em>. Large moving imagery, multiple web fonts, animation, sound, autoplaying video, and generally esoteric design is prevalent these days. We see showcase after showcase of the <em>best of the web</em>, where the only criteria is: “Does it look well-designed?” Well, look under the hood. It’s pretty terrifying. And that’s not even getting into the many accessibility concerns. If only more designers would ask themselves, “When was the last time I considered page size when designing something? When was the last time I decided that page weight was more important than aesthetics?” </p>
<p>These are questions I have put to designers before, and the response quite often is, “I’m just experimenting with technologies and trying to improve my UI skills. What harm is there in that?” Well, <em>Site of the Day</em>, the harm is your energy usage, and the likelihood that nobody—besides an echo chamber of fellow designers—give a shit about your over-design. People just want to access content quickly, without distraction, without friction, and without it using a tonne of data. That’s not to say aesthetics aren’t important—they certainly are. The visual design of a site can play a significant role in user experience, readability, and conversion, but as with most things, there is a balance to be achieved. And there is a responsibility to be shared.</p>
<hr>
<h2>Solutions</h2>
<p>Fortunately, there are a growing number of web professionals who do care about the impact sites have on the planet, and there are many solutions designers and developers alike can find to improve their sites without overly compromising their designs. Solutions that I am actively looking into to improve my own work.</p>
<p>So how can we be more energy efficient in web design? Well, the folks over at <a href="https://www.wholegraindigital.com/blog/website-energy-efficiency/">Wholegrain Digital</a> put together a comprehensive list, but here are some key considerations:</p>
<h3>Reduce Images</h3>
<p>The single largest contributors to page weight. The more images, the more data needs to be transferred and the more energy is used. A good starting point is to ask oneself:</p>
<ul>
<li>Does the image genuinely add value to the user?</li>
<li>Does it communicate useful information?</li>
<li>Could the same impact be achieved if the image was smaller?</li>
<li>Could we achieve the same effect with a vector graphic (or even CSS style) instead of a photo?</li>
</ul>
<h3>Optimise Images</h3>
<p>Some designs are focused almost entirely on imagery, in which case optimisation is vital to better performance. There are technical decisions that significantly affect the file size of images displayed on a page. These include:</p>
<ul>
<li>Load images at the correct scale instead of relying on CSS to resize them, so that you avoid loading images that are larger than the scale they will be displayed at.</li>
<li>Use image optimisation tools before you upload them to your site. I personally use <a href="https://imageoptim.com/mac">ImageOptim</a>.</li>
<li>Use the most efficient file format for each image, such as WebP instead of JPEG (although this is not supported by all browsers).</li>
<li>Use image processing tools to resize, crop, and enhance your images that are served. I use <a href="https://www.imgix.com/">imgimx</a> for this, which works well for image-heavy sites such as <a href="https://minimalissimo.com/">Minimalissimo</a>.</li>
</ul>
<h3>Reduce Video</h3>
<p>By far the most data intensive and processing intensive form of content. As with images, ask yourself if videos are really necessary. If they are, never autoplay a video. It creates a much higher load on the users CPU, resulting in vastly greater energy consumption. Plus, it’s annoying as hell. Let the user decide whether or not to play a video.</p>
<h3>Font Selection and Optimisation</h3>
<p>Web fonts can enhance the visual appeal of site designs, as well as improve readability, but they can add significant file weight to the sites on which they are used. A single font file could be as much as 250Kb, and that might only be for the standard weight. If you want bold, add another 250Kb! A couple of options worth considering:</p>
<ul>
<li>Use system fonts where possible.</li>
<li>Use fewer font variations.</li>
<li>Stick to modern web font file formats like WOFF and WOFF2.</li>
<li>Subset fonts to only include the characters needed on the site.</li>
</ul>
<h3>Write Clean Code</h3>
<p>Tidy and streamlined code is a fundamentally good thing. Keep code clean and simple, avoid duplication, and write efficient queries. The code behind the scenes should be a well oiled, lean machine. And I’ll take this opportunity to share a controversial opinion: <em>all designers should learn to code.</em> At least if they want a website. No-code site builders can be very good, but if you’re not aware of the underlying code, then you’ll be less aware of ways to optimise your site.</p>
<h3>Use Less Javascript</h3>
<p>JS impacts website efficiency in two ways: by adding file weight to the web page and by increasing the amount of processing required by the user’s device. The second of these is something that applies to JS much more than to other types of files. Look for ways to achieve front-end interactions, functionality, and animations using more efficient technologies like CSS, or at least use JS efficiently. A particular mention should be given here to tracking and advertising scripts that rarely offer any value to the user, but can add significant file weight. Don’t let advertising get in the way of craftsmanship.</p>
<h3>Use Server Caching</h3>
<p>Using caching technologies such as <a href="https://memcached.org/">Memcached</a> or <a href="https://varnish-cache.org/">Varnish</a> pre-generate static versions of each page so that the server overhead can be significantly reduced for most visitors. This significantly reduces server energy consumption and makes a big difference to page load times. </p>
<h3>SEO</h3>
<p>When optimising a site for search engines, we are helping people find the information they want quickly and easily. When SEO is successful, it results in people spending less time browsing the web looking for information, and visiting fewer pages that don’t meet their needs.</p>
<hr>
<p>No site is perfect, but appreciating that we have a responsibility to produce better digital design for the planet and for users is a good place to start. Web efficiency is an attitude and the result of a mindful approach to building for the web.</p>
<hr>
<h2>Useful Resources</h2>
<ul>
<li><a href="https://www.websitecarbon.com/">Website Carbon</a> (test your site’s carbon footprint)</li>
<li><a href="https://imageoptim.com/mac">ImageOptim</a> (image optimisation tool)</li>
<li><a href="https://www.imgix.com/">imgix</a> (image processing tool)</li>
<li><a href="https://developers.google.com/speed/pagespeed/insights/">Google PageSpeed Insights</a> (test your site’s performance)</li>
<li><a href="https://solar.lowtechmagazine.com/low-tech-solutions.html">Low-tech Solutions</a> (by Low-tech Magazine)</li>
</ul></div>
</section>
    </div></div>]]>
            </description>
            <link>https://cmhb.de/web-design-and-carbon-impact</link>
            <guid isPermaLink="false">hacker-news-small-sites-24513427</guid>
            <pubDate>Fri, 18 Sep 2020 06:02:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Introduction to Data Oriented Design with Rust]]>
            </title>
            <description>
<![CDATA[
Score 398 | Comments 134 (<a href="https://news.ycombinator.com/item?id=24506744">thread link</a>) | @headalgorithm
<br/>
September 17, 2020 | https://jamesmcm.github.io/blog/2020/07/25/intro-dod/ | <a href="https://web.archive.org/web/*/https://jamesmcm.github.io/blog/2020/07/25/intro-dod/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In the post we will investigate the main concepts of <a href="https://en.wikipedia.org/wiki/Data-oriented_design">Data-oriented
Design</a> using Rust.</p>

<p>The source code for this example is <a href="https://github.com/jamesmcm/data-oriented-example">available on Github</a>.</p>

<!--more-->

<h2 id="what-is-data-oriented-design">What is data-oriented design?</h2>

<p>Data-oriented design is an approach to optimising programs by carefully
considering the memory layout of data structures, and their implications
for auto-vectorisation and use of the CPU cache. I highly recommend
watching Mike Acton’s <a href="https://www.youtube.com/watch?v=rX0ItVEVjHc">“Data-Oriented Design and C++”</a> talk
if you haven’t seen it already.</p>

<p>In this post we will cover 4 cases, using <a href="https://docs.rs/criterion/0.3.3/criterion/">criterion</a> for
benchmarking. The cases are:</p>

<ul>
  <li>Struct of arrays vs. array of structs</li>
  <li>The cost of branching inside a hot loop</li>
  <li>Linked List vs. Vector iteration</li>
  <li>The cost of dynamic dispatch vs. monomorphisation</li>
</ul>

<h2 id="struct-of-arrays-vs-array-of-structs">Struct of Arrays vs. Array of Structs</h2>

<p>The <a href="https://en.wikipedia.org/wiki/AoS_and_SoA">Struct of Arrays vs. Array of Structs</a> 
refers to two contrasting ways of organising entity data to be operated
over.</p>

<p>For example, imagine we are writing a video game and we would like to
have a Player struct with the following fields:</p>

<div><div><pre><code><span>pub</span> <span>struct</span> <span>Player</span> <span>{</span>
    <span>name</span><span>:</span> <span>String</span><span>,</span>
    <span>health</span><span>:</span> <span>f64</span><span>,</span>
    <span>location</span><span>:</span> <span>(</span><span>f64</span><span>,</span> <span>f64</span><span>),</span>
    <span>velocity</span><span>:</span> <span>(</span><span>f64</span><span>,</span> <span>f64</span><span>),</span>
    <span>acceleration</span><span>:</span> <span>(</span><span>f64</span><span>,</span> <span>f64</span><span>),</span>
<span>}</span>
</code></pre></div></div>

<p>Then at each frame, we want to update the locations and velocities of all
Players. We could write something like:</p>

<div><div><pre><code><span>pub</span> <span>fn</span> <span>run_oop</span><span>(</span><span>players</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Vec</span><span>&lt;</span><span>Player</span><span>&gt;</span><span>)</span> <span>{</span>
    <span>for</span> <span>player</span> <span>in</span> <span>players</span><span>.iter_mut</span><span>()</span> <span>{</span>
        <span>player</span><span>.location</span> <span>=</span> <span>(</span>
            <span>player</span><span>.location</span><span>.</span><span>0</span> <span>+</span> <span>player</span><span>.velocity</span><span>.</span><span>0</span><span>,</span>
            <span>player</span><span>.location</span><span>.</span><span>1</span> <span>+</span> <span>player</span><span>.velocity</span><span>.</span><span>1</span><span>,</span>
        <span>);</span>
        <span>player</span><span>.velocity</span> <span>=</span> <span>(</span>
            <span>player</span><span>.velocity</span><span>.</span><span>0</span> <span>+</span> <span>player</span><span>.acceleration</span><span>.</span><span>0</span><span>,</span>
            <span>player</span><span>.velocity</span><span>.</span><span>1</span> <span>+</span> <span>player</span><span>.acceleration</span><span>.</span><span>1</span><span>,</span>
        <span>);</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>This would be the usual object-oriented approach to this problem. The
issue here is that in memory the structs are stored as follows (assuming
no field re-ordering i.e. <code>#[repr(C)]</code>), on a 64-bit architecture each field will be 64
bits (8 bytes, so each Player is 64 bytes):</p>

<div><div><pre><code>-- Vec&lt;Player&gt;
name  (pointer to heap)  -- Player 1
health    
location0  (tuple split for clarity) 
location1
velocity0
velocity1
acceleration0
acceleration1
name  (pointer to heap)  -- Player 2
location0    
location1
velocity0
velocity1
acceleration0
acceleration1
...
</code></pre></div></div>

<p>Note the parts we want to operate on (locations, velocities and
accelerations) are not stored contiguously across different Players.
This prevents us from using vector operations to operate on multiple
players at once (since they cannot be loaded in the same CPU cache
line, usually ~64 bytes).</p>

<p>In contrast, the data-oriented approach is to design around this
limitation and optimise for auto-vectorisation. Instead of using a
struct per Player, we now use one struct for all Players and each Player
has their values stored at their index in the separate attribute Vectors:</p>

<div><div><pre><code><span>pub</span> <span>struct</span> <span>DOPlayers</span> <span>{</span>
    <span>names</span><span>:</span> <span>Vec</span><span>&lt;</span><span>String</span><span>&gt;</span><span>,</span>
    <span>health</span><span>:</span> <span>Vec</span><span>&lt;</span><span>f64</span><span>&gt;</span><span>,</span>
    <span>locations</span><span>:</span> <span>Vec</span><span>&lt;</span><span>(</span><span>f64</span><span>,</span> <span>f64</span><span>)</span><span>&gt;</span><span>,</span>
    <span>velocities</span><span>:</span> <span>Vec</span><span>&lt;</span><span>(</span><span>f64</span><span>,</span> <span>f64</span><span>)</span><span>&gt;</span><span>,</span>
    <span>acceleration</span><span>:</span> <span>Vec</span><span>&lt;</span><span>(</span><span>f64</span><span>,</span> <span>f64</span><span>)</span><span>&gt;</span><span>,</span>
<span>}</span>
</code></pre></div></div>

<p>Now we can do the same calculation as in the OOP case as follows:</p>

<div><div><pre><code><span>pub</span> <span>fn</span> <span>run_dop</span><span>(</span><span>world</span><span>:</span> <span>&amp;</span><span>mut</span> <span>DOPlayers</span><span>)</span> <span>{</span>
    <span>for</span> <span>(</span><span>pos</span><span>,</span> <span>(</span><span>vel</span><span>,</span> <span>acc</span><span>))</span> <span>in</span> <span>world</span>
        <span>.locations</span>
        <span>.iter_mut</span><span>()</span>
        <span>.zip</span><span>(</span><span>world</span><span>.velocities</span><span>.iter_mut</span><span>()</span><span>.zip</span><span>(</span><span>world</span><span>.acceleration</span><span>.iter</span><span>()))</span>
    <span>{</span>
        <span>*</span><span>pos</span> <span>=</span> <span>(</span><span>pos</span><span>.</span><span>0</span> <span>+</span> <span>vel</span><span>.</span><span>0</span><span>,</span> <span>pos</span><span>.</span><span>1</span> <span>+</span> <span>vel</span><span>.</span><span>1</span><span>);</span>
        <span>*</span><span>vel</span> <span>=</span> <span>(</span><span>vel</span><span>.</span><span>0</span> <span>+</span> <span>acc</span><span>.</span><span>0</span><span>,</span> <span>vel</span><span>.</span><span>1</span> <span>+</span> <span>acc</span><span>.</span><span>1</span><span>);</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>In this case the memory layout is as follows:</p>
<div><div><pre><code>-- DOPlayers
name1    -- names
name2
...
health1    -- health
health2
...
location1    -- locations
location2
...
</code></pre></div></div>

<p>The relevant fields are now stored contiguously. Given that each
location tuple will be 16 bytes, we could now feasibly load 4 location
tuples on the same cache line to operate on them simultaneously with
SIMD instructions.</p>

<h3 id="benchmark">Benchmark</h3>

<p>Here are the results of the criterion benchmark for the above code (the
full code and benchmark code is available <a href="https://github.com/jamesmcm/data-oriented-example">in the Github repo</a>):</p>

<p><img src="https://jamesmcm.github.io/images/soa.svg" alt="AoS vs. SoA benchmark" title="AoS vs. SoA benchmark"></p>

<p>Overall, we see that the data-oriented approach finishes in half the
time. This would seem to be due to the data-oriented case operating on
two Players at a time - we can confirm this by reviewing the compiled
assembly.</p>

<p>Reviewing the <a href="https://godbolt.org/z/d8bjMb">output on Godbolt</a> we see the following:</p>

<pre><code>// Relevant OOP loop
.LBB0_2:
        movupd  xmm0, xmmword ptr [rax + rdx + 32]
        movupd  xmm1, xmmword ptr [rax + rdx + 48]
        movupd  xmm2, xmmword ptr [rax + rdx + 64]
        addpd   xmm0, xmm1
        movupd  xmmword ptr [rax + rdx + 32], xmm0
        addpd   xmm2, xmm1
        movupd  xmmword ptr [rax + rdx + 48], xmm2
        add     rdx, 80
        cmp     rcx, rdx
        jne     .LBB0_2

// ...
// Relevant DOP loop
.LBB1_7:
        movupd  xmm0, xmmword ptr [rcx + rdx - 16]
        movupd  xmm1, xmmword ptr [rax + rdx - 16]
        addpd   xmm1, xmm0
        movupd  xmmword ptr [rcx + rdx - 16], xmm1
        movupd  xmm0, xmmword ptr [r9 + rdx - 16]
        movupd  xmm1, xmmword ptr [rax + rdx - 16]
        addpd   xmm1, xmm0
        movupd  xmm0, xmmword ptr [rax + rdx]
        movupd  xmmword ptr [rax + rdx - 16], xmm1
        add     rdi, 2
        movupd  xmm1, xmmword ptr [rcx + rdx]
        addpd   xmm1, xmm0
        movupd  xmmword ptr [rcx + rdx], xmm1
        movupd  xmm0, xmmword ptr [rax + rdx]
        movupd  xmm1, xmmword ptr [r9 + rdx]
        addpd   xmm1, xmm0
        movupd  xmmword ptr [rax + rdx], xmm1
        add     rdx, 32
        cmp     rsi, rdi
        jne     .LBB1_7
        test    r8, r8
        je      .LBB1_5
</code></pre>

<p>We can see in the data-oriented case, the loop is unrolled to operate on
two elements at once - resulting in the 50% speed up overall!</p>

<p><strong>Addendum</strong>: As noted by <a href="https://www.reddit.com/r/rust/comments/hxqwom/an_introduction_to_data_oriented_design_with_rust/fz8lxcq/">/u/five9a2 on Reddit</a>
the above output is specifically for the default target, which is
misleading since <code>cargo bench</code> uses the native target by default (i.e.
all possible features on your CPU), so our benchmarks are not using the
above assembly code.</p>

<p>By setting the compiler flag to <code>-C target-cpu=skylake-avx512</code> to enable 
Skylake features, we get the <a href="https://godbolt.org/z/PEPdvn">following output</a>:</p>

<pre><code>// OOP loop
.LBB0_2:
        vmovupd ymm0, ymmword ptr [rax + rdx + 32]
        vaddpd  ymm0, ymm0, ymmword ptr [rax + rdx + 48]
        vmovupd ymmword ptr [rax + rdx + 32], ymm0
        add     rdx, 80
        cmp     rcx, rdx
        jne     .LBB0_2

...
// DOP loop
.LBB1_19:
        vmovupd zmm0, zmmword ptr [rsi + 4*rax - 64]
        vaddpd  zmm0, zmm0, zmmword ptr [rcx + 4*rax - 64]
        vmovupd zmmword ptr [rsi + 4*rax - 64], zmm0
        vmovupd zmm0, zmmword ptr [rcx + 4*rax - 64]
        vaddpd  zmm0, zmm0, zmmword ptr [r10 + 4*rax - 64]
        vmovupd zmmword ptr [rcx + 4*rax - 64], zmm0
        vmovupd zmm0, zmmword ptr [rsi + 4*rax]
        vaddpd  zmm0, zmm0, zmmword ptr [rcx + 4*rax]
        vmovupd zmmword ptr [rsi + 4*rax], zmm0
        vmovupd zmm0, zmmword ptr [rcx + 4*rax]
        vaddpd  zmm0, zmm0, zmmword ptr [r10 + 4*rax]
        vmovupd zmmword ptr [rcx + 4*rax], zmm0
        add     r11, 8
        add     rax, 32
        add     rdi, 2
        jne     .LBB1_19
        test    r9, r9
        je      .LBB1_22
</code></pre>

<p>Here we see the OOP loop making use of the 256-bit ymm registers for the
position tuple and velocity tuple, and another for the velocity tuple
and acceleration tuple. This is possible because they are adjacent in
memory (due to the ordering of the fields). In the DOP loop,
the 512-bit zmm register is used.</p>

<p>It seems the performance differences comes from the bandwidth between
cache levels, since the performance is identical for the small examples.
This can be demonstrated further by removing the extra fields from the
struct - in this case we see only a 25% performance difference (<a href="https://godbolt.org/z/Th91Wa">godbolt
link</a>), and this
corresponds to Player struct now being 384 bits (and so 1/4 of the
512-bit read/write is unused).</p>

<p>This emphasises how important it is to consider your deployment target,
and if deploying performance-sensitive code, to consider setting the
target-cpu explicitly to benefit from all of its features.</p>

<p>It also demonstrates how the ordering of fields can be important to
performance. By default Rust will re-order fields automatically, but you can set
<code>#[repr(C)]</code> to disable this (necessary for C interoperability for
example).</p>

<h3 id="summary">Summary</h3>

<p>This example demonstrates the importance of considering memory layout
when aiming for performant code and auto-vectorisation.</p>

<p>Note that the same logic can also apply when working with arrays of
structs - making your struct smaller will allow you to load more
elements on the same cache line and possibly lead to autovectorisation.
<a href="https://github.com/Rene-007/flake_growth/blob/master/src/helpers.rs">Here is an example</a> of
a crate (which was shared on the <a href="https://www.reddit.com/r/rust/comments/hmqjvs/growing_gold_with_rust/">Rust subreddit</a>) that achieved a 40% performance
improvement by doing just that.</p>

<p>This particular re-organisation has a direct analogue in database design. A
major difference between databases aimed at transactional (OLTP)
workloads and analytical (OLAP) workloads is that the latter tend to use
columnar-based storage. Just like the case above, this means that
operations on one column can take advantage of the contiguous storage
and use vector operations, which tends to be the main access pattern for
analytical workloads (e.g. calculate the average purchase size across all rows,
rather than updating and retrieving entire, specific rows).</p>

<p>In the case of analytical databases this is actually a double win, since it also
applies to the serialisation of the data to disk, where compression can
now be applied along the column (where the data is guaranteed to be of the
same type) leading to much better compression ratios.</p>

<p>If you are working on a problem that might benefit from the struct of
arrays approach, and want to run a quick benchmark, you might be
interested in the <a href="https://github.com/lumol-org/soa-derive">soa-derive</a>
crate that will allow you to derive the struct of arrays from your
struct.</p>

<h2 id="branching-in-a-hot-loop">Branching in a hot loop</h2>

<p>Another optimisation tactic is to avoid branching in any “hot” parts of
the code (i.e. any part that will be executed many, many times).</p>

<p>Branching can arise in subtle ways, often by trying to use one struct for many
different cases. For example, we might define some general Node type …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jamesmcm.github.io/blog/2020/07/25/intro-dod/">https://jamesmcm.github.io/blog/2020/07/25/intro-dod/</a></em></p>]]>
            </description>
            <link>https://jamesmcm.github.io/blog/2020/07/25/intro-dod/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24506744</guid>
            <pubDate>Thu, 17 Sep 2020 16:34:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thinking Clearly About Correlations and Causation (2018) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 61 | Comments 10 (<a href="https://news.ycombinator.com/item?id=24506243">thread link</a>) | @Anon84
<br/>
September 17, 2020 | https://dacemirror.sci-hub.tw/journal-article/7fe084d6885f9339910bf080b718c012/rohrer2018.pdf?download=true | <a href="https://web.archive.org/web/*/https://dacemirror.sci-hub.tw/journal-article/7fe084d6885f9339910bf080b718c012/rohrer2018.pdf?download=true">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://dacemirror.sci-hub.tw/journal-article/7fe084d6885f9339910bf080b718c012/rohrer2018.pdf?download=true</link>
            <guid isPermaLink="false">hacker-news-small-sites-24506243</guid>
            <pubDate>Thu, 17 Sep 2020 15:58:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Favorite Rust Function Signature]]>
            </title>
            <description>
<![CDATA[
Score 234 | Comments 111 (<a href="https://news.ycombinator.com/item?id=24505436">thread link</a>) | @brundolf
<br/>
September 17, 2020 | https://www.brandonsmith.ninja/blog/favorite-rust-function | <a href="https://web.archive.org/web/*/https://www.brandonsmith.ninja/blog/favorite-rust-function">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemprop="articleBody">
      

      

      

      


      <p>I've gotten really into writing parsers lately, and Rust has turned out to be
        the perfect language for that. In the course of my adventures, I came up with
        the following:</p>
      <pre><code><span>fn</span> tokenize<span>&lt;</span><span>'a</span><span>&gt;</span><span>(</span>code<span>:</span> <span>&amp;</span><span>'a</span> str<span>)</span> <span>-&gt;</span> <span>impl</span> Iterator<span>&lt;</span>Item<span>=</span><span>&amp;</span><span>'a</span> str<span>&gt;</span> <span>{</span>
  <span>...</span>
<span>}</span>
</code></pre>
      <p>and it really deepened my appreciation for Rust.</p>
      <h2 id="what-does-this-function-do%3F">What does this function do? </h2>
      <p>For those not familiar with parsing, tokenization is the first step of the
        process. It takes a raw code string, like this:</p>
      <pre><code>let a = "foo";
</code></pre>
      <p>and turns it into a linear series of meaningful tokens, like so:</p>
      <pre><code>["let", "a", "=", "\"foo\"", ";"]
</code></pre>
      <p>This phase isn't terribly complicated, but it simplifies the mental model for
        the next pass: constructing an "abstract syntax tree". It removes whitespace
        from the equation, bundles up segments like strings and numbers, and just
        generally makes the code in the next pass cleaner.</p>
      <p>The downside is that, if you perform this as a separate pass, your parser now
        has to iterate over all of the source code <em>twice</em>. This may not be the end of
        the world: tokenizing isn't the most expensive operation. But it isn't ideal,
        so some parsers combine the two passes into a single one, saving cycles at the
        expense of readability.</p>
      <h2 id="what's-going-on-in-the-rust-version%3F">What's going on in the Rust version? </h2>
      <p>I'll copy the signature here again for reference:</p>
      <pre><code><span>fn</span> tokenize<span>&lt;</span><span>'a</span><span>&gt;</span><span>(</span>code<span>:</span> <span>&amp;</span><span>'a</span> str<span>)</span> <span>-&gt;</span> <span>impl</span> Iterator<span>&lt;</span>Item<span>=</span><span>&amp;</span><span>'a</span> str<span>&gt;</span> <span>{</span>
  <span>...</span>
<span>}</span>
</code></pre>
      <p>There are several things going on here.</p>
      <p><code>&amp;str</code>, in Rust, is a "string slice". It's effectively a character pointer and a
        length. The contents of the slice are guaranteed to be in valid, alive memory.
        <code>&amp;'a str</code> is a string slice <em>with a lifetime</em>. The lifetime <code>'a</code>, to be
        exact. This lifetime describes a limited span of time in which the
        reference (and the full contents of the slice) are guaranteed to be in valid,
        alive memory. More on this later.</p>
      <p><code>Iterator&lt;Item=&amp;'a str&gt;</code> is an iterator over elements of type <code>&amp;'a str</code>. This
        is a <em>trait</em>, though, not a concrete type. Rust needs a concrete type with a
        fixed size when you're defining something like a function, but luckily we can
        say <code>impl Iterator&lt;Item=&amp;'a str&gt;</code>, which tells Rust, "fill in some type that
        implements <code>Iterator&lt;Item=&amp;'a str&gt;</code>, to be inferred at compile-time". This is
        very helpful because in Rust there are lots and lots of different concrete types
        for <code>Iterator</code>; applying something like a <code>map()</code> or a <code>filter()</code> returns a whole
        new concrete type. So this way, we don't have to worry about keeping the
        function signature up to date as we work on the logic.</p>
      <h2 id="so-what's-so-great-about-all-this%3F">So what's so great about all this? </h2>
      <p>Okay, so we have a function that takes a reference to a string slice and returns
        an iterator over string slices. Why's that special? There are two reasons.</p>
      <h3 id="iterators-let-you-treat-one-pass-like-it's-two">Iterators let you treat one pass like it's two </h3>
      <p>Remember how I said you traditionally have to pick between doing a separate
        tokenization pass, and doing a single pass with all the logic interleaved? With
        an iterator, you can have the best of both worlds.</p>
      <p>When this function completes, it hasn't yet iterated over the string. It hasn't
        allocated any kind of collection in memory. It returns a structure that's
        <em>prepared</em> to iterate over the input string slice and produce a sequence of new
        slices. When this value later gets <code>map()</code>ed into something else, or
        <code>filter()</code>ed, or any other <code>Iterator</code> transformations get applied, the stages
        of the process get interleaved, and the "loops" effectively get folded into a
        single one. By doing this, we're able to get the clean abstraction of a
        tokenizing "pass" without the runtime overhead of a second loop!</p>
      <p>But other languages have iterators. Rust's may be extra powerful and ergonomic,
        but they aren't a totally unique feature. The next part is very much unique to
        Rust.</p>
      
      <p>The <code>tokenize()</code> function doesn't allocate any new memory for a collection of
        tokens. That's great. But what may be less obvious is that it <em>also</em> doesn't
        allocate any memory for the tokens themselves! Each string slice representing a
        token is a <em>direct pointer to part of the original string</em>.</p>
      <p>You can do this in C/C++, of course, but there's a danger: if those tokens are
        ever accessed after the original code string has been freed, you'll have a
        memory error.</p>
      <p>For example: let's say you open a file and load the source code from it, and
        store the result in a local variable. Then you <code>tokenize()</code> it and send the
        tokens on to somewhere else outside of the function where the original string
        lived. Voilà, you've got a <a href="https://en.wikipedia.org/wiki/Dangling_pointer">use-after-free error</a>.</p>
      <p>One way to guard against this is by copying each string segment into a <em>new</em>
        string, allocated on the heap, which allows you to safely pass it on after the
        original string is gone. But this comes with a cost: creating, copying, and
        eventually disposing of each of those new strings takes time (and memory). Code
        down the line also has to be aware that it's responsible for de-allocating those
        strings, otherwise they'll leak.</p>
      <p>This is where the magic of lifetimes comes into play.</p>
      <p>Rust prevents the above situation entirely. Normally, though, to accomplish this
        a <code>&amp;str</code> coming into a function from elsewhere must be assumed to be <em>static</em>,
        or to be alive for the entire duration of the program's execution. This is the
        status assigned to, for example, a string literal that you've manually entered
        into your Rust code. Rust doesn't know, in the context of the function, how
        long that reference will be valid, so it must be pessimistic.</p>
      <p><strong>But.</strong> That little <code>'a</code> says: "these things all live for the same span of time". We
        can <em>assert</em> that the original source code string lives at least as long as the
        <em>tokens</em> that reference it. By doing so, Rust can reason about whether or not
        those resulting token references are valid at a given point, and therefore
        doesn't have to assume them to be static! We can do <em>whatever we want</em> with
        those tokens and the compiler will guarantee that they always point to something
        valid, even if the source code is loaded in dynamically at runtime (from a file
        or otherwise). If we find out later via a compiler error that they really do
        need to outlive the source string, then we can copy them ("take ownership") at
        that point. If the compiler doesn't force us to do so, we know we're safe,
        and we know we can continue using the most efficient possible approach,
        <em>fearlessly</em>.</p>
      <p>What we've effectively done is written the most optimistic possible function
        (in terms of memory safety), with no downsides, because the Rust compiler will
        tell us if we're misusing it and force us to then "step down" to whatever level
        of extra accommodation is needed.</p>
      <h2 id="conclusion">Conclusion </h2>
      <p>I've been using (and loving) Rust for about a year and a half now. And there are
        many things to love, but when I got this function working I immediately saw it
        as a microcosm of what really sets the language apart. This is something that
        you <strong>cannot do</strong> both a) this safely and b) this efficiently <strong>in any other
language</strong>. This is the power of Rust.</p>


    </article></div>]]>
            </description>
            <link>https://www.brandonsmith.ninja/blog/favorite-rust-function</link>
            <guid isPermaLink="false">hacker-news-small-sites-24505436</guid>
            <pubDate>Thu, 17 Sep 2020 15:00:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Shutting Down NavHere]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 31 (<a href="https://news.ycombinator.com/item?id=24505232">thread link</a>) | @jermaustin1
<br/>
September 17, 2020 | https://jeremyaboyd.com/post/shutting-down-navhere | <a href="https://web.archive.org/web/*/https://jeremyaboyd.com/post/shutting-down-navhere">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://jeremyaboyd.com/post/shutting-down-navhere</link>
            <guid isPermaLink="false">hacker-news-small-sites-24505232</guid>
            <pubDate>Thu, 17 Sep 2020 14:45:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[UK government’s plans to regulate the internet are a threat to free speech]]>
            </title>
            <description>
<![CDATA[
Score 225 | Comments 176 (<a href="https://news.ycombinator.com/item?id=24505074">thread link</a>) | @timthorn
<br/>
September 17, 2020 | https://freespeechunion.org/why-the-governments-plans-to-regulate-the-internet-are-a-threat-to-free-speech/ | <a href="https://web.archive.org/web/*/https://freespeechunion.org/why-the-governments-plans-to-regulate-the-internet-are-a-threat-to-free-speech/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-17831" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">

	
	
<div>

	
	<!-- .entry-header -->

	
	<div itemprop="text">

		
		
<p>Dr Radomir Tylecote</p>



<p>September 2020</p>



<p><a href="https://freespeechunion.org/fsu-briefing-online-harms/">Full Report</a><br><a href="https://www.gofundme.com/f/the-free-speech-union-fighting-fund">GoFundMe appeal</a></p>



<figure><div>
<p><iframe title="How the Government’s plans to regulate the internet are a threat to free speech" width="1200" height="675" src="https://www.youtube.com/embed/CQac6mzC444?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
</div></figure>







<h3>The Government’s proposed new internet regulator will infringe free speech</h3>



<p>The Government published the Online Harms White Paper in April 2019 and intends to put a Bill before Parliament next year. The proposals aim to make the UK “the safest place in the world to go online”, but they will seriously infringe free speech.</p>



<p>Some of the harms the White Paper identifies are real, including distributing images of child abuse and online activities by terrorists. But these would be better dealt with by simpler legislation and more resources for law enforcement.</p>



<p>However, some of the harms the White Paper describes are vague, such as “unacceptable content” and “disinformation”. These are not fixed but would be determined by a future regulator. This will lead to sweeping censorship. Online Harms does not even properly define “harm”, so the definition risks being outsourced to activists and lobby groups.</p>



<p>A proposed new regulator will even have the power to censor lawful content: the government says new regulation should prohibit material “that may directly or indirectly cause harm” even if “not necessarily illegal”. The Government also singled out “offensive material”, as if giving offence is a harm the public should be protected from by the state.</p>



<h3>The proposals move the UK towards the internet laws of China, Russia and Belarus</h3>



<p>The Government’s proposals are partly inspired by Germany’s 2017 “NetzDG” internet law, but Human Rights Watch has called for Germany to scrap the law, saying it “turns internet companies into censors”. President Lukashenko of Belarus, Vladimir Putin’s United Russia Party and the Venezuelan government have cited NetzDG as the model for their online laws.</p>



<p>Our government’s plans also bear a worrying similarity to Beijing’s internet censorship policies. Beijing censors “rumours” because they cause “social harms”. Our government’s proposals describe “disinformation” as “harmful”, and will make “content which has been disputed by reputable fact-checking services less visible to users”, forcing companies to promote “authoritative news sources”. This contradicts our government’s claim that “the regulator will not be responsible for policing truth and accuracy online”.</p>



<p>While the authors of the White Paper believe their proposals will mean more “tolerance” and less “hate”, they will likely have the opposite effect, as people respond angrily to censorship and conspiracy theorists enjoy the cachet of being banned by the state.</p>



<p>In this briefing we outline the Government’s Online Harms plans and explain why they are a danger to freedom of speech. Later this year, the Free Speech Union will propose alternative regulation to protect the vulnerable without jeopardising free speech.</p>



<p><a href="https://freespeechunion.org/fsu-briefing-online-harms/">Full Report</a><br><a href="https://www.gofundme.com/f/the-free-speech-union-fighting-fund">GoFundMe appeal</a></p>



<p><em>FSU research papers are designed to promote discussion of free speech issues. As with all FSU publications, the views expressed are those of the author(s) and not those of the FSU, its directors, Advisory Councils or other senior staff.</em></p>

		
		
			</div><!-- .entry-content .clear -->
</div>

	
</article></div>]]>
            </description>
            <link>https://freespeechunion.org/why-the-governments-plans-to-regulate-the-internet-are-a-threat-to-free-speech/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24505074</guid>
            <pubDate>Thu, 17 Sep 2020 14:31:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Data-Oriented Programming in Python]]>
            </title>
            <description>
<![CDATA[
Score 68 | Comments 14 (<a href="https://news.ycombinator.com/item?id=24504947">thread link</a>) | @jbredeche
<br/>
September 17, 2020 | https://www.moderndescartes.com/essays/data_oriented_python/ | <a href="https://web.archive.org/web/*/https://www.moderndescartes.com/essays/data_oriented_python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
	

<p> Originally posted 2020-09-13</p>
<p> Tagged: <a href="https://www.moderndescartes.com/essays/tags/optimization">optimization</a>, <a href="https://www.moderndescartes.com/essays/tags/computer_science">computer_science</a>, <a href="https://www.moderndescartes.com/essays/tags/python">python</a></p>
<p> <em>Obligatory disclaimer: all opinions are mine and not of my employer </em></p>
<hr>

<p>Many users of Python deprioritize performance in favor of soft benefits like ergonomics, business value, and simplicity. Users who prioritize performance typically end up on faster compiled languages like C++ or Java.</p>
<p>One group of users is left behind, though. The scientific computing community has lots of raw data they need to process, and would very much like performance. Yet, they struggle to move away from Python, because of network effects, and because Python’s beginner-friendliness is appealing to scientists for whom programming is not a first language. So, how can Python users achieve some fraction of the performance that their C++ and Java friends enjoy?</p>
<p>In practice, scientific computing users rely on the NumPy family of libraries e.g.&nbsp;NumPy, SciPy, TensorFlow, PyTorch, CuPy, JAX, etc.. The sheer proliferation of these libraries suggests that the NumPy model is getting something right. In this essay, I’ll talk about what makes NumPy so effective, and where the next generation of Python numerical computing libraries (e.g.&nbsp;TensorFlow, PyTorch, JAX) seems to be headed.</p>
<h2 id="data-good-pointers-bad">Data good, pointers bad</h2>
<p>A pesky fact of computing is that computers can compute far faster than we can deliver data to compute on. In particular, data transfer <em>latency</em> is the Achille’s heel of data devices (both RAM and storage). Manufacturers disguise this weakness by emphasizing improvements in data transfer <em>throughput</em>, but latency continues to stagnate. Ultimately, this means that any chained data access patterns, where one data retrieval must be completed before the next may proceed, are the worst case for computers.</p>
<p>These worst-case chained data access patterns are unfortunately quite common – so common that they have a name you may be familiar with: a pointer.</p>
<p>Pointers have always been slow. In the ’80s and ’90s, our hard drives were essentially optimized record players, with a read head riding on top of a spinning platter. These hard drives had physical limitations: The disk could only spin so fast without shattering, and the read head was also mechanical, limiting its movement speed. Disk seeks were slow, and the programs that were most severely affected were databases. Some ways that databases dealt with these physical limitations are:</p>
<ul>
<li>Instead of using binary trees (requiring <span>\(\log_2 N\)</span> disk seeks), B-trees with a much higher branching factor <span>\(k\)</span> were used, only requiring <span>\(\log_k N\)</span> disk seeks.</li>
<li>Indices were used to query data without having to read the full contents of each row.</li>
<li>Vertically-oriented databases optimized for read-heavy workloads (e.g.&nbsp;summary statistics over one field, across entire datasets), by reorganizing from <a href="https://en.wikipedia.org/wiki/AoS_and_SoA">arrays of structs to structs of arrays</a>. This maximized effective disk throughput, since no extraneous data was loaded.</li>
</ul>
<p>Today, compute speed is roughly <span>\(10^5 - 10^6\)</span> times faster than in 1990. Today, RAM is roughly <span>\(10^5\)</span> times faster than HDDs from 1990. I was amused and unsurprised to find that Raymond Hettinger’s <a href="https://www.youtube.com/watch?v=npw4s1QTmPg">excellent talk on the evolution of Python’s in-memory <code>dict</code> implementation</a> plays out like a brief history of early database design. Time, rather than healing things, has only worsened the compute-memory imbalance.</p>
<h2 id="numpys-optimizations">NumPy’s optimizations</h2>
<h3 id="boxing-costs">Boxing costs</h3>
<p>In many higher-level languages, raw data comes in boxes containing metadata and a pointer to the actual data. In Python, the PyObject box holds reference counts, so that the garbage collector can operate generically on all Python entities.</p>
<p>Boxing creates two sources of inefficiency:</p>
<ul>
<li>The metadata bloats the data, reducing the data density of our expensive memory.</li>
<li>The pointer indirection creates another round trip of memory retrieval latency.</li>
</ul>
<p>A NumPy array can hold many raw data within a single PyObject box, <em>provided that all of those data are of the same type</em> (int32, float32, etc.). By doing this, NumPy amortizes the cost of boxing over multiple data.</p>
<p>In <a href="https://www.moderndescartes.com/essays/deep_dive_mcts">my previous investigations into Monte Carlo tree search</a>, a naive UCT implementation performed poorly because it instantiated millions of UCTNode objects whose sole purpose was to hold a handful of float32 values. In the optimized UCT implementation, these nodes were replaced with NumPy arrays, reducing memory usage by a factor of 30.</p>
<h3 id="attribute-lookup-function-dispatch-costs">Attribute lookup / function dispatch costs</h3>
<p>Python’s language design forces an unusually large amount of pointer chasing. I mentioned boxing as one layer of pointer indirection, but really it’s just the tip of the iceberg.</p>
<p>Python has no problem handling the following code, even though each of these multiplications invokes a completely different implementation.</p>
<pre><code>&gt;&gt;&gt; mixed_list = [1, 1.0, 'foo', ('bar',)]
&gt;&gt;&gt; for obj in mixed_list:
...     print(obj * 2)

2
2.0
'foofoo'
('bar', 'bar')</code></pre>
<p>Python accomplishes this with a minimum of two layers of pointer indirection:</p>
<ol type="1">
<li>Look up the type of the object.</li>
<li>Look up and execute the <code>__mul__</code> function from that type’s operation registry.</li>
</ol>
<p>Additional layers of pointer indirection may be required if the <code>__mul__</code> method is defined on a superclass: the chain of superclasses must be traversed, one pointer at a time, until an implementation is found.</p>
<p>Attribute lookup is similarly fraught; <code>@property</code>, <code>__getattr__</code>, and <code>__getattribute__</code> provide users with flexibility that incurs pointer chasing overhead with something as simple as executing <code>a.b</code>. Access patterns like <code>a.b.c.d</code> create exactly the chained data access patterns that are a worst-case for data retrieval latency.</p>
<p>To top it all off, merely <em>resolving</em> the object is expensive: there’s a stack of lexical scopes (local, nonlocal, then global) that are checked in order to find the variable name. Each check requires a dictionary lookup, another source of pointer indirection.</p>
<p>As the saying goes: “We can solve any problem by introducing an extra level of indirection… except for the problem of too many levels of indirection”. The NumPy family of libraries deals with this indirection, not by removing it, but again by sharing its cost over multiple data.</p>
<pre><code>&gt;&gt;&gt; homogenous_array = np.arange(5, dtype=np.float32)
&gt;&gt;&gt; multiply_by_two = homogenous_array * 2
&gt;&gt;&gt; print(multiply_by_two)
array([ 0.,  2.,  4.,  6.,  8.], dtype=float32)</code></pre>
<p>Sharing a single box for multiple data allows NumPy to retain the expressiveness of Python while minimizing the cost of the dynamism. As before, this works because of the additional constraint that all data in a NumPy array must have identical type.</p>
<h2 id="the-frontier-jit">The Frontier: JIT</h2>
<p>So far, we’ve seen that NumPy doesn’t solve any of Python’s fundamental problems when it comes to pointer overhead. Instead, it merely puts a bandaid on the problem by sharing those costs across multiple data. It’s a pretty successful strategy – in my hands (<a href="https://www.moderndescartes.com/essays/vectorized_pagerank">1</a>, <a href="https://www.moderndescartes.com/essays/deep_dive_mcts">2</a>), I find that NumPy can typically achieve 30-60x speedups over pure Python solutions to dense numerical code. However, given that C code typically achieves <a href="https://www.moderndescartes.com/essays/data_oriented_python/(https://benchmarksgame-team.pages.debian.net/benchmarksgame/fastest/python3-gcc.html)">100-200x performance</a> over pure Python on dense numerical code (common in scientific computing), it would be nice if we could further reduce the Python overhead.</p>
<p>Tracing <a href="https://en.wikipedia.org/wiki/Just-in-time_compilation">JITs</a> promise to do exactly this. Roughly, the strategy is to trace the execution of the code and record the pointer chasing outcomes. Then, when you call the same code snippet, reuse the recorded outcomes! NumPy amortizes Python overhead over multiple data, and JIT amortizes Python overhead over multiple function calls.</p>
<p>(I should note that I’m most familiar with the tracing JITs used by TensorFlow and JAX. <a href="https://doc.pypy.org/en/latest/">PyPy</a> and <a href="https://numba.pydata.org/">Numba</a> are two alternate JIT implementations that have a longer history, but I don’t know enough about them to treat them fairly, so my apologies to readers.)</p>
<p>Tracing unlocks many wins typically reserved for compiled languages. For example, once you have the entire trace in one place, operations can be fused together (e.g., to make use of the <a href="https://en.wikipedia.org/wiki/FMA_instruction_set">fused multiply-add instructions</a> common to most modern computers), memory layouts can be optimized, and so on. TensorFlow’s <a href="https://www.tensorflow.org/guide/graph_optimization">Grappler</a> is one such implementation of this idea. Traces can also be <a href="https://en.wikipedia.org/wiki/Backpropagation">walked backwards</a> to automatically compute derivatives. Traces can be compiled for different hardware configurations, so that the same Python code executes on CPU, GPU, and TPU. JAX can <a href="https://jax.readthedocs.io/en/latest/notebooks/quickstart.html#Auto-vectorization-with-vmap">autovectorize traces</a>, adding a batch dimension to all operations. Finally, a trace can be exported in a language-agnostic manner, allowing a program defined in Python to be executed in <a href="https://www.tensorflow.org/js">Javascript</a>, <a href="https://www.tensorflow.org/tfx/guide/serving">C++</a>, or more.</p>
<p>Unsurprisingly, there’s a catch to all this. NumPy can amortize Python overhead over multiple data, but only if that data is the same type. JIT can amortize Python overhead over multiple function calls, but only if the function calls would have resulted in the same pointer chasing outcomes. Retracing the function to verify this would defeat the purpose of JIT, so instead, TensorFlow/JAX JIT uses array shape and dtype to guess at whether a trace is reusable. This heuristic is necessarily conservative, rules out otherwise legal programs, often requires unnecessarily specific shape information, and doesn’t make any guarantees against mischievous tinkering. Furthermore, data-dependent tracing is a known issue (<a href="https://pytorch.org/docs/stable/generated/torch.jit.trace.html">1</a>, <a href="https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html#python-control-flow-+-JIT">2</a>). I worked on <a href="https://blog.tensorflow.org/2018/07/autograph-converts-python-into-tensorflow-graphs.html">AutoGraph</a>, a tool to address data-dependent tracing. Still, the engineering benefits of a shared tracing infrastructure are too good to pass up. I expect to see JIT-based systems flourish in the future and iron out their user experience.</p>
<h2 id="conclusion">Conclusion</h2>
<p>The NumPy API’s specifically addresses Python’s performance problems for the kinds of programs that scientific computing users want to write. It encourages users to write code in ways that minimize pointer overhead. Coincidentally, this way of writing code is a fruitful abstraction for tracing JITs targeting vastly parallel computing architectures like GPU and TPU. (Some people argue that <a href="https://dl.acm.org/citation.cfm?id=3321441">machine learning is stuck in a rut</a> due to this NumPy monoculture.) In any case, tracing JITs built on top of …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.moderndescartes.com/essays/data_oriented_python/">https://www.moderndescartes.com/essays/data_oriented_python/</a></em></p>]]>
            </description>
            <link>https://www.moderndescartes.com/essays/data_oriented_python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24504947</guid>
            <pubDate>Thu, 17 Sep 2020 14:21:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Retro Unix Operating System]]>
            </title>
            <description>
<![CDATA[
Score 79 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24504891">thread link</a>) | @elvis70
<br/>
September 17, 2020 | https://www.singlix.com/runix | <a href="https://web.archive.org/web/*/https://www.singlix.com/runix">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div width="390">

            
<p>
<span lang="en-us"><span face="Arial" color="#003366" size="2">
Retro UNIX 8086 v1 operating system has been developed by Erdogan Tan as a 
special purposed derivation of original UNIX v1 (by Ken Thompson, 1970-1972).</span></span></p>

<p>
<span face="Arial" color="#003366" size="2"><span lang="en-us">Source code has 
been ported from PDP-11 Unix assembler syntax to Microsoft Macro Assembler 
(INTEL x86 real mode) syntax and original unix source code has been modified for 
IBM PC/AT compatibility with standard ROM BIOS functions, without 
dropping/removing original UNIX v1 multitasking (time-sharing) features.</span></span></p>

<p><span lang="en-us">
<span face="Arial" size="2" color="#003366">Retro UNIX 386 v1 is 32 bit (80386 
protected mode) version of Retro UNIX 8086 v1. Retro UNIX 386 v1 operating 
system kernel and binaries have been written in assembly language syntax of 
Netwide Assembler (NASM). </span>
</span></p>

<p>
<span face="Arial" color="#003366" size="2"><span lang="en-us">Retro UNIX is a 
predecessor to SINGLIX operating system project.<br>
&nbsp;</span></span></p>
            </div></div>]]>
            </description>
            <link>https://www.singlix.com/runix</link>
            <guid isPermaLink="false">hacker-news-small-sites-24504891</guid>
            <pubDate>Thu, 17 Sep 2020 14:16:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Toward a Technological Cage for the Masses]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 74 (<a href="https://news.ycombinator.com/item?id=24503179">thread link</a>) | @sT370ma2
<br/>
September 17, 2020 | https://cheapskatesguide.org/articles/techno-cage.html | <a href="https://web.archive.org/web/*/https://cheapskatesguide.org/articles/techno-cage.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://cheapskatesguide.org/articles/techno-cage.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24503179</guid>
            <pubDate>Thu, 17 Sep 2020 11:05:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Is 1 World Trade Center Missing from Spider-Man?]]>
            </title>
            <description>
<![CDATA[
Score 170 | Comments 114 (<a href="https://news.ycombinator.com/item?id=24502706">thread link</a>) | @tosh
<br/>
September 17, 2020 | https://www.stevenbuccini.com/why-1wtc-isnt-in-spiderman | <a href="https://web.archive.org/web/*/https://www.stevenbuccini.com/why-1wtc-isnt-in-spiderman">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Like many people across the world, I’m using my quarantine effectively: by catching up on all the video games I wasn’t able to play while traveling. The game at the top of my list? <a href="https://en.wikipedia.org/wiki/Spider-Man_(2018_video_game)">Spider-Man</a>, which was widely recognized as one of the top games of 2018. The game is features an open-world, which means you can travel around the game map as you see fit. And since Spider-Man, canonically, lives in real-life New York City, this means you’ll spend hours webbing around an incredibly detailed version of the city that never sleeps.</p>

<p>If you’ve spent any appreciable amount of time in New York, the in-game world will immediately feel familiar. The developers nailed the look and feel of the city. I found myself using real-world landmarks to orient myself as I slinged (slunged?) across Manhattan. The game leans into this realism—it even includes a challenge where you can take photos of in-game landmarks. While some are unique to the Marvel universe, like Avengers Tower and Uncle Ben’s grave, many exist in the real world and are faithfully reproduced within the game: Williamsburg/Brooklyn/Manhattan/Queensboro Bridges all make an appearance, as does Grand Central, Madison Square Garden, Saint Patrick’s Cathedral, Columbus Circle, the High Line and many more points of reference. As you’re swinging through the city, you’re treated to great views of Manhattan’s skyline, anchored by the Empire State Building, Chrysler Building, and Freedom Tower. Except, it’s <em>not</em> the Freedom Tower, despite being located in the exact same location as its real-life counterpart. Why are equally famous buildings like the Empire State Building accurately depicted, but the Freedom Tower isn’t?</p>

<p>Here’s what the “Freedom Tower” looks like in the game:
<img src="https://www.stevenbuccini.com/assets/spiderman/spiderman-1wtc.png" alt="In-Game 1WTC">
<em>(credit to Polygon because I was too lazy to get this off my PS4 myself)</em></p>

<p>Interestingly enough, the in-game design looks to be based on Libeskind’s original design for Freedom Tower (an interesting recap of the changes can be found <a href="https://www.newyorker.com/business/currency/daniel-libeskinds-world-trade-center-change-of-heart">here</a>), lending further credence to the theory that this building is supposed to be 1WTC.</p>

<p>My curiosity was further piqued when I learned that the <em>real</em> One World Trade Center was actually in the game during a demo at E3 in June of 2018, less than 4 months before the final game was set to be released to the public!</p>

<p><img src="https://www.stevenbuccini.com/assets/spiderman/1wtc_e3.png" alt="Real-life 1WTC in Spider-Man demo from E3 2018"></p>

<p>This deadline is even closer than it appears at first glance as the <a href="https://en.wikipedia.org/wiki/Software_release_life_cycle#RTM">“gold master”</a> is finalized weeks before release date so manufacturers have time to make and distribute the game to retailers. This change must have been implemented at the 11th hour.</p>

<p>And even after swapping the model out, they featured the building prominently on the home screen in the released version of the video game!
<img src="https://www.stevenbuccini.com/assets/spiderman/spiderman-start.png" alt="Start screen">
<em>(<a href="https://www.noobfeed.com/features/1119/marvel-s-spider-man-how-do-you-access-new-game-plus-and-ultimate-difficulty">credit</a>)</em></p>

<p>So <em>why</em> isn’t the real-life 1 WTC featured? At this point, we can eliminate time and budget constraints because we know the model already existed and was implemented before launch. We know that the designers thought this building was important as it’s the first thing you notice when starting the game.</p>

<p>I wish to briefly introduce <strong>Buccini’s razor</strong>—if something fun disappears unexpectedly, the cause is litigation (real or imagined).</p>

<p>It turns out that just like an author can copyright their book and a musician can copyright a song, an architect can copyright a building. Sure enough, here’s the copyright record for One World Trade Center:
<img src="https://www.stevenbuccini.com/assets/spiderman/copyright_record.png" alt="Record from [copyright.gov](https://www.copyright.gov/); can't deeplink the record but you can find it yourself by using the document record seen above"></p>

<p>At this point, I had a strong feeling copyright law was the reason for the change. The <a href="https://www.reddit.com/r/SpidermanPS4/comments/9grnr8/freedom_tower/">internet</a> <a href="https://www.reddit.com/r/SpidermanPS4/comments/9d3paw/the_real_reason_for_the_redesigned_freedom_tower/">seems</a> <a href="https://gamefaqs.gamespot.com/boards/191635-marvels-spider-man/76988485">to</a> <a href="https://www.neogaf.com/threads/one-world-trade-center-has-been-removed-from-spider-man-ps4.1465315/">agree</a>.</p>

<p>As luck<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> would have it, there was <a href="https://www.nexsenpruet.com/professionals/jeff-reichard">an expert in architectural copyright</a> right around the corner from my house here in Greensboro! Jeffrey was kind enough to spend a few minutes of his time thinking about this not-at-all-important question.</p>

<p>First, Jeffrey noted that <em>copyrights expire</em>. Just as music and books can pass into the public domain for anyone to replicate freely, you can also build an exact replica of the Empire State Building here in the United States if you so choose. Generally, any building constructed after December 1, 1990 is covered by the <a href="https://www.djc.com/news/ae/11151054.html">Architectural Works Copyright Protection Act</a>. This would explain why older structures are replicated faithfully but the Freedom Tower is not.</p>

<p>However, this doesn’t tell the full story. As Jeffrey noted, <a href="https://www.law.cornell.edu/uscode/text/17/120">17 U.S. Code § 120(a)</a> “provides an exception related to pictorial representations of of buildings that are visible from a public place. Therefore, I am not sure exactly why they changed it in the video game.”</p>

<p>The final piece of the puzzle lies at the <a href="https://www.youtube.com/watch?v=vo5A_fuDgtk&amp;feature=youtu.be&amp;t=2666">end of the credits</a>, where the creators of the game specifically thank the owners of certain famous buildings in New York, including the Empire State Building. I found this curious as the Empire State Building should be doubly safe: it was constructed long before 1990 so it is not covered under copyright law, and it is visible from a public place so it should be exempt from any potential copyrights. But look closer. You’ll see that they are acknowledging the <em>trademark</em> holders, NOT the <em>copyright</em> holders.</p>

<p><a href="https://www.photosecrets.com/buildings-copyright-and-trademarks">As this page</a> helpfully explains, applying a trademark to the building limits how the building’s image can be used in the sale of goods and services (like video games)! The credits hint that the video game creators obtained limited licenses to use the trademark, i.e. the distinctive design and appearance of the building, for certain buildings such as the Flatiron Building.<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup></p>

<p>Therefore, the most likely answer is that the distinctive shape of 1 World Trade Center is either trademarked (although I could not find it within USPTO databases) or is so recognizable that it is easily defensible via a common law trademark and the game developers were unable to secure a license to use the trademark before their deadline.</p>

<p>However, <a href="https://www.youtube.com/watch?v=gHzuHo80U2M">Sony just announced</a> an expansion to the Spider-Man video game, so perhaps the additional time and the demonstrated popularity of the first installment will help resolve this issue for the upcoming title.</p>



  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://www.stevenbuccini.com/why-1wtc-isnt-in-spiderman</link>
            <guid isPermaLink="false">hacker-news-small-sites-24502706</guid>
            <pubDate>Thu, 17 Sep 2020 09:38:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I overslept because iOS 14 disabled my alarm]]>
            </title>
            <description>
<![CDATA[
Score 474 | Comments 306 (<a href="https://news.ycombinator.com/item?id=24502697">thread link</a>) | @dewey
<br/>
September 17, 2020 | https://annoying.technology/posts/e82ff3bde8b225e6/ | <a href="https://web.archive.org/web/*/https://annoying.technology/posts/e82ff3bde8b225e6/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://d33wubrfki0l68.cloudfront.net/9261d105b12f5c6c5928c9532d1f8721b84005cd/62d1b/media/oversleeping.jpg"></p><p>I’m using the iOS <a href="https://support.apple.com/en-us/HT208655">Bedtime</a> feature for years now. With yesterday’s iOS 14 update the feature got moved from the Clock app to the Health app. Unfortunately the migration is done by disabling your existing alarm and showing a button to open the Health app to set it up again.</p><p>I woke up late and well rested today.</p></div></div>]]>
            </description>
            <link>https://annoying.technology/posts/e82ff3bde8b225e6/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24502697</guid>
            <pubDate>Thu, 17 Sep 2020 09:36:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Infosec Apocalypse]]>
            </title>
            <description>
<![CDATA[
Score 153 | Comments 97 (<a href="https://news.ycombinator.com/item?id=24501803">thread link</a>) | @chillax
<br/>
September 16, 2020 | https://blog.rickasaurus.com/2020/08/31/The-Infosec-Apocalypse.html | <a href="https://web.archive.org/web/*/https://blog.rickasaurus.com/2020/08/31/The-Infosec-Apocalypse.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>The rise of tooling for vulnerability detection combined with pressure driven by Vendor Due Diligence is causing a massive enterprise freezeout for non-mainstream technologies across the board. Of particular concern is the impact this will have on the adoption of functional programming in enterprise and small business B2B development.</p>

<p>I see now that the last 10 years were “easy mode” for the growth of new programming tools and infrastructure, with many new breakthrough technologies seeing rapid adoption. Languages like Node, Go and to some degree Scala saw breakaway success, not to mention all of the new cloud tech, NoSQL tech, containerization and data processing platforms along with their custom query DSLs. Other languages like Haskell saw success in small companies and skunkworks style teams solving very difficult problems.</p>

<h3 id="the-rise-of-vulnerability-scanning">The Rise of Vulnerability Scanning</h3>

<p>Just this past year I’ve come to see we’re in the middle of a massive change across the industry. There are new forces at play which will calcify current software stacks and make it extremely hard for existing or new entrants to see similar success without a massive coordinated push backed by big enterprise companies. This force is the rise of InfoSec and vulnerability detection tooling.</p>

<p>Tools like <a href="https://owasp.org/www-community/Source_Code_Analysis_Tools">Blackduck, WhiteSource, Checkmarx, Veracode</a> are exploding in popularity, there are too many to list and many variations on the same theme. In the wake of so many data leaks and hacking events enterprises no longer trust their developers and SREs to take care of security, and so protocols are being implemented top down. This isn’t just on the code scanning side, there is a similar set of things going on with network scanning as well which impacts programming languages less, but similarly will calcify server stacks.</p>

<p>These tools are quickly making their way into SOC2 and SDLC policies across industry, and if your language or new infrastructure tool isn’t supported by them there’s little chance you will get the previously already tenuous approval to use them. This sets the already high bar for adoption much higher. As you might expect, vendors will only implement support for languages that meet some threshold for profitability of their tools. Not only do you need to build a modern set of tools for your language to compete, now you also need support from external vendors.</p>

<h3 id="vendor-due-diligence">Vendor Due Diligence</h3>

<p>Maybe we just cede this territory to enterprise tools with big backers like Microsoft and Oracle, we never more than a few small inroads anyway. The use of these tools is arguably a good thing overall for software security. Unfortunately, the problem cannot be sidestepped so easily, and I’m afraid this is where things look very bleak. The biggest new trend is in enforcement of these tools through Vendor Due Diligence.</p>

<p>You may not be familiar with Vendor Due Diligence if you aren’t in a manager role. The basic idea is your customer will send you a long list of technical questions about your product which you must fill out to their satisfaction before they buy your product or service. In the B2B space where I work these lists are nothing new, but have been getting longer and longer over the last 10 years, now often numbering in the hundreds of questions.</p>

<p>Most recently I’ve seen more and more invasive questions being asked, some even going into how teams are organized, but important to this article is that across the board they now all ask about vulnerability scanning and now often request specific outputs for well-known vulnerability scanning tools. The implication being that if you’re not scanning with these tools they won’t buy your software, and the list of supported languages is small.</p>

<p>Any experienced technology manager sees the natural tradeoff here. When it comes down to making money versus using cool tech, cool tech will lose every time. You’re just burning money if you’re building cool things with cool tech if you know no one will buy it.</p>

<h3 id="so-what-now">So What Now?</h3>

<p>Potentially we will see a resurgence of “compile-to” functional programming with mainstream language targets to sidestep the issue. I suppose though that the extra build complexity and problems debugging will prevent this from ever being mainstream, not to mention that the vulnerability tools look for specific patterns and likely won’t behave well on generated code.</p>

<p>There is some hope in the form of projects like SonarCube which enables users to come together and <a href="https://github.com/SonarSource/sonar-custom-plugin-example">build custom plugins</a>. Will functional programming communities come together to build and maintain such boring tech? I somewhat doubt it. This kind of work is not what most programmers would choose to do in their off time. Similarly, vulnerability detection is unlikely to be a good target to be advanced a little at a time with academic papers. It would take true functional programming fanatics to build companies or tools dedicated to the cause. If you are interested in helping out, pay attention to the <a href="https://owasp.org/www-project-top-ten/">OWASP Top 10</a> as this list drives focus for many infosec teams.</p>

<p>Where does this leave us? If our communities do nothing then smaller B2B software operations focused mom and pop shops or consumer focused web applications likely won’t see any impact unless static analysis makes it into data protection law. Beyond these use cases FP will be relegated to tiny boxes on the back end where vulnerabilities are much less of a concern and the mathematical skills of functional programmers can bring extreme amounts of value.</p>

<p>I know there are many deeper facets I didn’t cover here, if you want to continue the discussion <a href="https://twitter.com/rickasaurus/status/1300487826782420995">join the thread on twitter</a>.</p>


  </div></div>]]>
            </description>
            <link>https://blog.rickasaurus.com/2020/08/31/The-Infosec-Apocalypse.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24501803</guid>
            <pubDate>Thu, 17 Sep 2020 06:34:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hacking on Bug Bounties for Four Years]]>
            </title>
            <description>
<![CDATA[
Score 64 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24500198">thread link</a>) | @infosecau
<br/>
September 16, 2020 | https://blog.assetnote.io/2020/09/15/hacking-on-bug-bounties-for-four-years/ | <a href="https://web.archive.org/web/*/https://blog.assetnote.io/2020/09/15/hacking-on-bug-bounties-for-four-years/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <ul>
  <li><a href="https://blog.assetnote.io/2020/09/15/hacking-on-bug-bounties-for-four-years/#intro">Intro &amp; Motivations</a></li>
  <li><a href="https://blog.assetnote.io/2020/09/15/hacking-on-bug-bounties-for-four-years/#findings">Findings</a></li>
  <li><a href="https://blog.assetnote.io/2020/09/15/hacking-on-bug-bounties-for-four-years/#analysis">Analysis</a></li>
  <li><a href="https://blog.assetnote.io/2020/09/15/hacking-on-bug-bounties-for-four-years/#collaboration">Collaboration</a></li>
  <li><a href="https://blog.assetnote.io/2020/09/15/hacking-on-bug-bounties-for-four-years/#methodology">Methodology</a></li>
</ul>

<hr>





<p>I value transparency a lot, especially when it comes to the bug bounty space. Bug bounty hunters all around the world are submitting a range of reports where the issues found span across multiple domains, often leveraging numerous techniques and methodologies. However, if you’re not already an active bug bounty hunter who has a good understanding of what a bounty program expects, or will pay out for, you have a major disadvantage compared to someone who does have this knowledge. I hope through this blog post, I can demystify the sort of issues bug bounty programs pay for.</p>

<p>The last blog post I did in this series was around four years ago, <a href="https://shubs.io/high-frequency-security-bug-hunting-120-days-120-bugs/">120 days, 120 bugs</a>. In the last four years, a lot has happened. I moved to Europe for six months, I moved interstate in Australia twice, I won a <a href="https://www.youtube.com/watch?v=VojwIY4GL-4">live hacking event</a>, I co-founded a company and helped build an <a href="https://assetnote.io/">attack surface management platform</a> with a team of people I consider family.</p>

<p>Unlike my previous blog post, I did not set myself a goal to find a bug a day. Instead, I participated in bug bounties whenever time allowed. There were many months where I found nothing at all, which often terrified me when it came to evaluating my self worth as a hacker. I also admitted to myself, that I might be a good hacker, but there is always going to be a better hacker out there, and I’ve made my peace with that as a hyper-competitve person.</p>

<p>If you don’t have an excellent understanding of fundamental application security <a href="http://projects.webappsec.org/w/page/13246978/Threat%20Classification">attacks and weaknesses</a> before you approach bug bounties, in my opinion, you are wasting your time. <a href="https://portswigger.net/web-security">Practice and learn more here</a>.</p>

<p>If you’re looking for a paid, more extensive resource, check out and practice with <a href="https://pentesterlab.com/">PentesterLab</a>.</p>

<p>Participating so heavily in bug bounties has given us the knowledge at Assetnote about what security teams <em>actually</em> care about. It’s the reason we can maintain high signal when we are continuously finding exposures.</p>

<p>My primary motivation for this blog post is to educate the masses on what bug bounty programs are paying out for.</p>

<p>For example, would you know that you could submit a dangling EC2 IP (subdomain pointing to an EC2 IP that is no longer owned by the company) as a bug report without reading the proof in the pudding below? I’ve been paid for this by programs, so clearly they value this sort of information.</p>

<hr>




<p>Below are all of my findings for the last four years. I’ve redacted information where necessary, but by reading the titles, it should give you a good understanding of what I was reporting to programs.</p>

<table data-order="[[ 0, &quot;desc&quot; ]]" id="bugs">
<thead><tr><th title="Field #1">Date</th>
<th title="Field #2">Bug</th>
<th title="Field #3">Payout</th>
</tr></thead>
<tbody><tr>
<td>2020-09-02 14:04:11 UTC</td>
<td>[redacted] Hosted Zone Takeover</td>
<td>$1,000.00</td>
</tr>
<tr>
<td>2020-07-16 18:39:22 UTC</td>
<td>Spring debugging endpoints exposed leading to disclosure of all secrets via heapdump on [redacted] &amp; Account takeover by Trace</td>
<td>$2,500.00</td>
</tr>
<tr>
<td>2020-06-30 22:54:07 UTC</td>
<td>Blind SSRF on [redacted] through invoicing API - access to internal hosts</td>
<td>$60.00</td>
</tr>
<tr>
<td>2020-06-10 13:53:43 UTC</td>
<td>Full Account takeover through subdomain takeover via [redacted]</td>
<td>$300.00</td>
</tr>
<tr>
<td>2020-06-10 13:24:10 UTC</td>
<td>Full Account takeover through subdomain takeover via [redacted]</td>
<td>$300.00</td>
</tr>
<tr>
<td>2020-06-10 13:21:57 UTC</td>
<td>Full Account takeover through subdomain takeover via  [redacted]</td>
<td>$300.00</td>
</tr>
<tr>
<td>2020-06-08 14:28:05 UTC</td>
<td>Amazon S3 Subdomain Hijack - [redacted]</td>
<td>$256.00</td>
</tr>
<tr>
<td>2020-06-08 05:29:58 UTC</td>
<td>Route53 Hosted Zone Takeover of [redacted]</td>
<td>$500.00</td>
</tr>
<tr>
<td>2020-06-05 16:27:42 UTC</td>
<td>Admin panel for Cisco IP Conference Station CP-7937G exposed on the internet on [redacted] IP ranges</td>
<td>$400.00</td>
</tr>
<tr>
<td>2020-06-03 21:07:51 UTC</td>
<td>Pre-auth Blind MSSQL Injection affecting [redacted]</td>
<td>$1,024.00</td>
</tr>
<tr>
<td>2020-06-03 14:18:24 UTC</td>
<td>Pre-auth MSSQL Injection affecting [redacted]</td>
<td>$1,024.00</td>
</tr>
<tr>
<td>2020-06-02 15:28:50 UTC</td>
<td>Pre-auth SQL Injection affecting [redacted]</td>
<td>$1,024.00</td>
</tr>
<tr>
<td>2020-06-02 15:26:58 UTC</td>
<td>RCE via arbitrary file write and path traversal [redacted]</td>
<td>$1,024.00</td>
</tr>
<tr>
<td>2020-06-02 15:25:08 UTC</td>
<td>RCE via arbitrary file write and path traversal [redacted]</td>
<td>$1,024.00</td>
</tr>
<tr>
<td>2020-05-18 10:12:38 UTC</td>
<td>Route53 Hosted Zone Takeover of [redacted]</td>
<td>$1,000.00</td>
</tr>
<tr>
<td>2020-05-18 10:11:58 UTC</td>
<td>Route53 Hosted Zone Takeover of [redacted]</td>
<td>$1,000.00</td>
</tr>
<tr>
<td>2020-05-18 10:06:22 UTC</td>
<td>Route53 Hosted Zone Takeover of [redacted]</td>
<td>$1,000.00</td>
</tr>
<tr>
<td>2020-05-18 10:05:20 UTC</td>
<td>Route53 Hosted Zone Takeover of [redacted]</td>
<td>$1,000.00</td>
</tr>
<tr>
<td>2020-05-11 18:47:54 UTC</td>
<td>Route53 Hosted Zone Takeover of [redacted]</td>
<td>$100.00</td>
</tr>
<tr>
<td>2020-05-11 14:59:23 UTC</td>
<td>Account takeover through Subdomain Takeover of [redacted] (Cookie Disclosure -&gt; Account Takeover)</td>
<td>$2,500.00</td>
</tr>
<tr>
<td>2020-05-11 14:31:18 UTC</td>
<td>Account takeover through Subdomain Takeover of [redacted] (Cookie Disclosure -&gt; Account Takeover)</td>
<td>$2,500.00</td>
</tr>
<tr>
<td>2020-05-07 01:47:49 UTC</td>
<td>View all metadata for any [redacted] IDOR [redacted]</td>
<td>$1,000.00</td>
</tr>
<tr>
<td>2020-04-29 22:58:57 UTC</td>
<td>IDOR view all [redacted]</td>
<td>$4,000.00</td>
</tr>
<tr>
<td>2020-04-29 22:57:55 UTC</td>
<td>IDOR view the [redacted]</td>
<td>$2,500.00</td>
</tr>
<tr>
<td>2020-04-24 18:19:23 UTC</td>
<td>Subdomain takeover of [redacted] through Heroku</td>
<td>$300.00</td>
</tr>
<tr>
<td>2020-04-24 18:18:45 UTC</td>
<td>Subdomain takeover of [redacted] through Heroku</td>
<td>$300.00</td>
</tr>
<tr>
<td>2020-04-23 19:45:04 UTC</td>
<td>Ability to horizontal bruteforce [redacted] accounts by abusing [redacted] sign up flow</td>
<td>$500.00</td>
</tr>
<tr>
<td>2020-04-22 17:44:29 UTC</td>
<td>View all metadata for any [redacted] IDOR [redacted]</td>
<td>$500.00</td>
</tr>
<tr>
<td>2020-04-22 17:42:51 UTC</td>
<td>IDOR view the [redacted] for any [redacted] for today [redacted]</td>
<td>$500.00</td>
</tr>
<tr>
<td>2020-04-22 17:42:06 UTC</td>
<td>IDOR view all [redacted] for a [redacted] [redacted]</td>
<td>$500.00</td>
</tr>
<tr>
<td>2020-04-06 19:13:19 UTC</td>
<td>Facebook - Payout For [redacted]</td>
<td>$5,000.00</td>
</tr>
<tr>
<td>2020-03-07 15:12:24 UTC</td>
<td>Accessing Querybuilder on [redacted] to gain access to secrets</td>
<td>$3,000.00</td>
</tr>
<tr>
<td>2020-02-25 15:02:20 UTC</td>
<td>Subdomain takeover of [redacted] via Amazon S3</td>
<td>$750.00</td>
</tr>
<tr>
<td>2020-02-20 23:01:58 UTC</td>
<td>HTML injection, DOS of email receipts and potentially template injection within [redacted] via "Expense Info" section</td>
<td>$500.00</td>
</tr>
<tr>
<td>2020-02-18 14:45:40 UTC</td>
<td>Admin account bruteforce via [redacted]/libs/granite/core/content/login.html</td>
<td>$500.00</td>
</tr>
<tr>
<td>2020-02-15 12:24:57 UTC</td>
<td>Blind XSS via registering on [redacted]</td>
<td>$500.00</td>
</tr>
<tr>
<td>2020-02-04 03:45:38 UTC</td>
<td>HTML Injection in email when contributing to a [redacted]</td>
<td>$700.00</td>
</tr>
<tr>
<td>2020-01-21 17:13:58 UTC</td>
<td>Ability to attach malicious attachments (of any name and of any content type) to [redacted] support staff via [redacted]</td>
<td>$2,000.00</td>
</tr>
<tr>
<td>2020-01-15 11:41:59 UTC</td>
<td>No authentication required to view and delete Terraform locks at [redacted]</td>
<td>$250.00</td>
</tr>
<tr>
<td>2019-12-12 16:25:11 UTC</td>
<td>[redacted] Webhook URL + object leaked in JavaScript on [redacted]</td>
<td>$3,000.00</td>
</tr>
<tr>
<td>2019-11-21 22:15:20 UTC</td>
<td>AWS &amp; Screenhero JWT Credentials from [redacted] not rotated, still working</td>
<td>$1,000.00</td>
</tr>
<tr>
<td>2019-10-17 13:44:23 UTC</td>
<td>RCE on [redacted] via IBM Aspera exploit leading to compromise of secure file storage </td>
<td>$1,000.00</td>
</tr>
<tr>
<td>2019-10-15 14:29:25 UTC</td>
<td>SSO bypass on [redacted] leading to access of internal documents and portals</td>
<td>$250.00</td>
</tr>
<tr>
<td>2019-10-11 18:07:51 UTC</td>
<td>Admin access to [redacted] via guessing credentials</td>
<td>$1,500.00</td>
</tr>
<tr>
<td>2019-10-11 18:06:15 UTC</td>
<td>3rd party subdomain hijack - EC2 IP of [redacted] is no longer controlled by [redacted]</td>
<td>$250.00</td>
</tr>
<tr>
<td>2019-09-30 16:56:50 UTC</td>
<td>Multiple server-side issues affecting [redacted] (SSRF, admin panels)</td>
<td>$2,660.00</td>
</tr>
<tr>
<td>2019-09-25 22:10:00 UTC</td>
<td>Read any [redacted] details using UUID - IDOR in [redacted]</td>
<td>$1,000.00</td>
</tr>
<tr>
<td>2019-09-10 16:17:59 UTC</td>
<td>SSRF in [redacted]</td>
<td>$2,000.00</td>
</tr>
<tr>
<td>2019-09-03 15:28:36 UTC</td>
<td>SSRF in [redacted]</td>
<td>$17,900.00</td>
</tr>
<tr>
<td>2019-08-29 00:43:00 UTC</td>
<td>Bypassing email whitelists for organisation signup flows on [redacted]</td>
<td>$250.00</td>
</tr>
<tr>
<td>2019-08-09 05:15:44 UTC</td>
<td>[Pre-Submission] SSRF in [redacted] (Iframely)</td>
<td>$2,970.30</td>
</tr>
<tr>
<td>2019-07-29 16:32:59 UTC</td>
<td>[Bypass] SSRF via [redacted] leads to internal network access, ability to read internal JSON responses</td>
<td>$23,000.00</td>
</tr>
<tr>
<td>2019-07-24 02:52:42 UTC</td>
<td>PHPInfo exposed at [redacted]</td>
<td>$100.00</td>
</tr>
<tr>
<td>2019-07-24 02:46:02 UTC</td>
<td>SSRF on [redacted] leading to AWS breach via security credentials</td>
<td>$5,000.00</td>
</tr>
<tr>
<td>2019-07-08 14:44:23 UTC</td>
<td>Remote command execution on production [redacted] (via tsi parameter) - CVE-2017-12611</td>
<td>$2,000.00</td>
</tr>
<tr>
<td>2019-06-12 17:42:53 UTC</td>
<td>Username/Password for Aspera and other secrets leaked in [redacted]</td>
<td>$1,500.00</td>
</tr>
<tr>
<td>2019-06-12 17:42:08 UTC</td>
<td>SSO/Authorization bypass for APIs hosted on [redacted]</td>
<td>$1,500.00</td>
</tr>
<tr>
<td>2019-06-12 14:45:09 UTC</td>
<td>Remote Code Execution (many endpoints) - [redacted]</td>
<td>$4,500.00</td>
</tr>
<tr>
<td>2019-06-10 17:29:35 UTC</td>
<td>Extract email, dob, full address, federal tax ID and other PII for all leads in [redacted]</td>
<td>$1,800.00</td>
</tr>
<tr>
<td>2019-06-10 16:53:22 UTC</td>
<td>Obtain email, mobile of customers of [redacted] by iterating through Lead IDs via the API</td>
<td>$12,600.00</td>
</tr>
<tr>
<td>2019-06-10 16:52:40 UTC</td>
<td>Ability to pull out all opportunities (IDOR) extract PII for customers of [redacted]</td>
<td>$12,600.00</td>
</tr>
<tr>
<td>2019-06-07 18:51:24 UTC</td>
<td>[redacted][IDOR] - Accessing all accounts via regression / new attack vector by abusing [redacted] (regression?)</td>
<td>$2,500.00</td>
</tr>
<tr>
<td>2019-06-07 18:17:31 UTC</td>
<td>Blind SSRF on [redacted] through RPC call to checkAvailableLivechatAgents</td>
<td>$62.50</td>
</tr>
<tr>
<td>2019-06-07 18:07:22 UTC</td>
<td>HTML injection in emails when adding a reviewer to [redacted]</td>
<td>$125.00</td>
</tr>
<tr>
<td>2019-06-07 17:42:09 UTC</td>
<td>[IDOR] Impersonating an [redacted] employee via /api/readHandler on [redacted]</td>
<td>$1,500.00</td>
</tr>
<tr>
<td>2019-06-07 15:33:31 UTC</td>
<td>Extract mobile number and [redacted] using only an email address, for any [redacted]</td>
<td>$750.00</td>
</tr>
<tr>
<td>2019-06-07 14:36:01 UTC</td>
<td>Zendesk Ticket IDOR / Ability to enumerate  IDs via [redacted]</td>
<td>$125.00</td>
</tr>
<tr>
<td>2019-06-07 14:24:15 UTC</td>
<td>Extract mobile number and [redacted] using only an email address, for any [redacted] user</td>
<td>$750.00</td>
</tr>
<tr>
<td>2019-06-07 14:11:20 UTC</td>
<td>HTML Injection in [redacted] receipts if printed from [redacted]</td>
<td>$100.00</td>
</tr>
<tr>
<td>2019-06-07 13:56:46 UTC</td>
<td>Ability to access the airwatch admin panels and APIs in [redacted]</td>
<td>$1,000.00</td>
</tr>
<tr>
<td>2019-06-07 13:21:31 UTC</td>
<td>IDOR on [redacted] allows you to access [redacted] information for any [redacted] user</td>
<td>$250.00</td>
</tr>
<tr>
<td>2019-06-07 10:13:20 UTC</td>
<td>[redacted][IDOR] - Accessing all accounts via regression / new attack vector by abusing [redacted] (regression?)</td>
<td>$15,000.00</td>
</tr>
<tr>
<td>2019-05-22 19:33:27 UTC</td>
<td>SQLi and Authentication Bypass in [redacted]</td>
<td>$4,500.00</td>
</tr>
<tr>
<td>2019-04-29 14:14:42 UTC</td>
<td>Reflected XSS in [redacted]</td>
<td>$500.00</td>
</tr>
<tr>
<td>2019-04-29 14:14:29 UTC</td>
<td>SSRF in [redacted]</td>
<td>$1,500.00</td>
</tr>
<tr>
<td>2019-04-25 07:33:22 UTC</td>
<td>Local file disclosure through Rails CVE-2019-5418 in [redacted]</td>
<td>$100.00</td>
</tr>
<tr>
<td>2019-04-19 02:28:54 UTC</td>
<td>SSRF - [redacted]</td>
<td>$4,950.00</td>
</tr>
<tr>
<td>2019-04-19 02:28:35 UTC</td>
<td>SSRF at [redacted] via the 'url' parameter</td>
<td>$4,950.00</td>
</tr>
<tr>
<td>2019-03-29 11:23:14 UTC</td>
<td>AWS S3 secrets leaked in [redacted] meeting connector …</td></tr></tbody></table></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.assetnote.io/2020/09/15/hacking-on-bug-bounties-for-four-years/">https://blog.assetnote.io/2020/09/15/hacking-on-bug-bounties-for-four-years/</a></em></p>]]>
            </description>
            <link>https://blog.assetnote.io/2020/09/15/hacking-on-bug-bounties-for-four-years/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24500198</guid>
            <pubDate>Thu, 17 Sep 2020 01:29:10 GMT</pubDate>
        </item>
    </channel>
</rss>
