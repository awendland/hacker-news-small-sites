<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 07 Mar 2021 12:40:34 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 07 Mar 2021 12:40:34 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Compensation as a Reflection of Values]]>
            </title>
            <description>
<![CDATA[
Score 134 | Comments 83 (<a href="https://news.ycombinator.com/item?id=26348836">thread link</a>) | @timf
<br/>
March 4, 2021 | https://oxide.computer/blog/compensation-as-a-reflection-of-values/ | <a href="https://web.archive.org/web/*/https://oxide.computer/blog/compensation-as-a-reflection-of-values/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Compensation: the word alone is enough to trigger a fight-or-flight reaction in many. But we in technology have the good fortune of being in a well-compensated domain, so why does this issue induce such anxiety when our basic needs are clearly covered? If it needs to be said, it's because compensation isn't merely about the currency we redeem in exchange for our labors, but rather it is a proxy for how we are <em>valued</em> in a larger organization. This, in turn, brings us to our largest possible questions for ourselves, around things like meaning and self-worth.</p><p>So when we started Oxide -- as in any new endeavor -- compensation was an issue we had to deal with directly. First, there was the thorny issue of how we founders would compensate ourselves. Then, of course, came the team we wished to hire: hybrid local and remote, largely experienced to start (on account of <a href="https://www.youtube.com/watch?v=vvZA9n3e5pc">Oxide's outrageously ambitious mission</a>), and coming from a diverse set of backgrounds and experiences. How would we pay people in different geographies? How could we responsibly recruit experienced folks, many of whom have families and other financial obligations that can't be addressed with stock options? How could we avoid bringing people's compensation history -- often a reflection of race, gender, class, and other factors rather than capability -- with them?</p><p>We decided to do something outlandishly simple: take the salary that Steve, Jess, and I were going to pay ourselves, and pay that to everyone. The three of us live in the San Francisco Bay Area, and Steve and I each have three kids; we knew that the dollar figure that would allow us to live without financial distress -- which we put at $175,000 a year -- would be at least universally adequate for the team we wanted to build. And we mean everyone literally: as of this writing we have 23 employees, and that's what we all make.</p><p>Now, because compensation is the hottest of all hot buttons, it can be fairly expected that many people will have a reaction to this. Assuming you've made it to this sentence it means you are not already lighting us up in your local comments section (thank you!), and I want to promise in return that we know some likely objections, and we'll address those. But before we do, we want to talk about the benefits of transparent uniform compensation, because they are, in a word, profound.</p><p>Broadly, our compensation model embodies our <a href="https://oxide.computer/about/">mission, principles, and values</a>. First and foremost, we believe that our compensation model reflects our principles of <b>honesty</b>, <b>integrity</b>, and <b>decency</b>. To flip it around: sadly, we have seen extant comp structures in the industry become breeding grounds for dishonesty, deceit, and indecency. Beyond our principles, our comp model is a tangible expression of several of our values in particular:</p><ul><li><p>It has set the tone with respect to <b>teamwork</b>. In my experience, the need to "quantify" one's performance in exchange for justifying changes to individual compensation are at the root of much of what's wrong in the tech industry. Instead of incentivizing people to achieve together as a team, they are incentivized to advance themselves -- usually with sophisticated-sounding jargon like OKRs or MBOs, or perhaps reasonable-sounding (but ultimately misguided) mantras like "measure everything." Even at their very best, these individual incentives represent a drag on a team, as their infrequent calibration can prevent a team from a necessary change in its direction. And at worst, they leave individuals perversely incentivized and operating in direct opposition to the team's best interest. When comp is taken out of the picture, everyone can just focus on what we need to focus on: getting this outlandish thing built, and loving and serving the customers who are taking a chance on it.</p></li><li><p>It is an expression of our <b>empathy</b>. Our approach to compensation reflects our belief in treating other people the way that we ourselves want to be treated. There are several different dimensions for this, but one is particularly visceral: because we have not talked about this publicly, candidates who have applied to Oxide have done so assuming that we have a traditional comp model, and have braced themselves for the combat of a salary negotiation. But we have spoken about it relatively upfront with candidates (before they talk to the team, for example), and (as the one who has often had this discussion) the relief is often palpable. As one recent candidate phrased it to me: "if I had known about this earlier, I wouldn't have wasted time stressing out about it!"</p></li><li><p>It is (obviously?) proof-positive of our <b>transparency</b>. Transparency is essential for building <i>trust</i>, itself one of the most important elements of doing something bold together. One of the interesting pieces of advice we got early on from someone who has had outsized, repeated success: modulo private personnel meetings, make sure that every meeting is open to everyone. For those accustomed to more opaque environments, our level of transparency can be refreshing: for example, new Oxide employees have been pleasantly surprised that we always go through our board decks with everyone -- but we can't imagine doing it any other way. Transparent compensation takes this to an unusual (but not unprecedented) extreme, and we have found it to underscore how seriously we take transparency in general.</p></li><li><p>It has allowed whole new levels of <b>candor</b>. When everyone can talk about their salary, other things become easier to discuss directly. This candor is in all directions; without comp to worry about, we can all be candid with respect to our own struggles -- which in turn allows us to address them directly. And we can be candid too when giving public positive feedback; we don't need to be afraid that by calling attention to someone's progress, someone else will feel shorted.</p></li></ul><p>These are (some of!) the overwhelming positives; what about those objections?</p><ul><li><p>Some will say that this salary is too low. While cash compensation gets exaggerated all of the time, it's unquestionable that salaries in our privileged domain have gotten much higher than our $175,000 (and indeed, many at Oxide have taken a cut in pay to work here). But it's also true that $175,000 per year puts us each in the top 5% of US individual earners -- and it certainly puts a roof over our families' heads and food in their bellies. Put more viscerally: this is enough to not fret when your kids toss the organic raspberries into the shopping cart -- or when they devour them before you've managed to get the grocery bags out of the car! And speaking of those families: nothing is more anxiety-producing than having a healthcare issue compounded by financial distress due to inadequate insurance; Oxide not only offers the best healthcare plans we could find, but we also pay 100% of monthly premiums -- a significant benefit for those with dependents.</p></li><li><p>Some will say that we should be paying people differently based on different geographical locations. I know there are thoughtful people who pay folks differently based on their zip code, but (respectfully), we disagree with this approach. Companies spin this by explaining they are merely paying people based on their cost of living, but this is absurd: do we increase someone's salary when their spouse loses their job or when their kid goes to college? Do we slash it when they inherit money from their deceased parent or move in with someone? The answer to all of these is no, of course not: we pay people based on their work, not their costs. The truth is that companies pay people less in other geographies for a simple reason: because they can. We at Oxide just don't agree with this; we pay people the same regardless of where they pick up their mail.</p></li><li><p>Some will say that this doesn't scale. This is, at some level, surely correct: it's hard to envision a multi-thousand employee Oxide where everyone makes the same salary -- but it has also been (rightly) said that startups should do things that don't scale. And while it seems true that the uniformity won't necessarily scale, we believe that the values behind it very much will!</p></li><li><p>Some will say that this makes us unlikely to hire folks just starting out in their career. There is truth to this too, but the nature of our problem at Oxide (namely, technically very broad and very deep), the size of our team (very small), and the stage of our company (still pretty early!) already means that engineers at the earliest stages of their career are unlikely to be a fit for us right now. That said, we don't think this is impossible; and if we felt that we had someone much earlier in their career who was a fit -- that is, if we saw them contributing to the company as much as anyone else -- why wouldn't we reflect that by paying them the same as everyone else?</p></li><li><p>Some will say that this narrows the kind of roles that we can hire for. In particular, different roles can have very different comp models (sales often has a significant commission component in exchange for a lower base, for example). There is truth to this too -- but for the moment we're going to put this in the "but-this-can't-scale" bucket.</p></li><li><p>Some will say that this doesn't offer a career ladder. Uniform compensation causes us to ask some deeper questions: namely, what <em>is</em> a career ladder, anyway? To me, the true objective for all of us should be to always be taking on new challenges -- to be unafraid to learn and develop. I have found traditional ladders to not serve these ends particularly well, because they focus us on competition rather than collaboration. By eliminating the rung of compensation, we can put the focus on career development where it belongs: on supporting one another in our self-improvement, and working together to do things that are beyond any one of us.</p></li><li><p>Some will say that we should be talking about equity, not cash compensation. While it's true that startup equity is important, it's also true that startup equity doesn't pay the orthodontist's bill or get the basement …</p></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://oxide.computer/blog/compensation-as-a-reflection-of-values/">https://oxide.computer/blog/compensation-as-a-reflection-of-values/</a></em></p>]]>
            </description>
            <link>https://oxide.computer/blog/compensation-as-a-reflection-of-values/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26348836</guid>
            <pubDate>Thu, 04 Mar 2021 21:44:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reverse-engineering Rosetta 2 Part 1: Analyzing AoT files and the runtime]]>
            </title>
            <description>
<![CDATA[
Score 103 | Comments 15 (<a href="https://news.ycombinator.com/item?id=26346980">thread link</a>) | @my123
<br/>
March 4, 2021 | https://ffri.github.io/ProjectChampollion/part1/ | <a href="https://web.archive.org/web/*/https://ffri.github.io/ProjectChampollion/part1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-md-component="container">
      
      
        
      
      <main data-md-component="main">
        <div>
          
            
              
              
            
            
              
              
            
          
          <div>
            <article>
              
                
                  <a href="https://github.com/FFRI/ProjectChampollion/edit/master/docs/part1.md" title="Edit this page">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"></path></svg>
                  </a>
                
                
                
<p>date: 2021/2/19</p>
<p>author: Koh M. Nakagawa</p>
<h2 id="introduction">Introduction</h2>
<p>Apple announced that it would be moving from Intel processors to Arm-based Apple Silicon CPUs for Macs at WWDC 2020.
The Apple Silicon-based Mac Book Air and Pro were released in October 2020 with great fanfare.</p>
<p>One of the issues that arise with the CPU transition is application compatibility.
Since Apple Silicon is an Arm-based processor, applications built for Intel-based Macs will no longer work.
To solve this problem, Apple offers the following two technologies:</p>
<ul>
<li>Universal Binary 2</li>
<li>Rosetta 2</li>
</ul>
<p>Universal Binary 2 is a mechanism to encapsulate binaries built for multiple architectures into a single binary, which is also called Fat Binary.
Apple has been using this technology for a long time to maintain backward compatibility.
A Mach-O loader selects the binary with the best architecture for the machine it is running on, then loads only that binary into memory to run the program.
Most macOS Big Sur system binaries are currently Fat Binaries, containing binaries built for both Arm and Intel architectures.</p>
<p>Rosetta 2 is a technology that translates Intel-based binaries or JIT-generated code into Arm-based binaries or code.
It is the successor to Rosetta, which was also used in the past processor transition.
There is not much information officially released by Apple.
Of course, there is no source code available, unlike the XNU kernel.
Also, at the time of writing this article, there seems to be no article that examines it in detail.</p>
<p>In this article, I introduce some reverse engineering results of Rosetta 2.</p>
<p>Why I take a closer look at Rosetta 2?</p>
<p>The reason is that I'm interested in translated binaries in Rosetta 2 and examining the possibility of exploiting them.
I presented <a href="https://www.blackhat.com/eu-20/briefings/schedule/index.html#jack-in-the-cache-a-new-code-injection-technique-through-modifying-x-to-arm-translation-cache-21324">a new code injection technique in Windows 10 on Arm at Black Hat EU</a> last December.
The code injection is achieved by modifying x86 to Arm (XTA) binary translation cache files.
This research encourages me to examine whether similar code injection techniques can be achieved with Rosetta 2.</p>
<p>In this part, I will cover the following points:</p>
<ul>
<li>The executables associated with Rosetta 2 and their roles</li>
<li>Analysis results of the translated binaries</li>
<li>JIT binary translation capabilities of Rosetta 2 (mainly focusing on x86_64 machine code decoding process)</li>
</ul>
<p>In the following, I will follow Apple's terminology when referring to architecture.</p>
<ul>
<li>arm64: The architecture specified when generating binaries to run on an Apple Silicon Mac</li>
<li>x86_64: The architecture specified when generating binaries to run on an Intel-based Mac</li>
</ul>
<h2 id="setting-up-the-analysis-environment">Setting up the analysis environment</h2>
<p>First, I show you how to set up the analysis environment.</p>
<p>Rosetta 2 is not installed by default on an Apple Silicon Mac.
So, you need to install it following the pop-up that appears when you run an x86_64 code for the first time.</p>
<figure>
    <img src="https://ffri.github.io/ProjectChampollion/assets/macos-big-sur-software-update-rosetta-alert.jpg">
    <figcaption>Figure 1 Rosetta 2 installation popup (https://support.apple.com/en-us/HT211861).</figcaption>
</figure>

<p>After the installation, a folder named <code>/Library/Apple/usr/libexec/oah/</code> (hereinafter referred to as the oah folder) is created, and you can see the following binaries installed.</p>
<figure>
    <img src="https://ffri.github.io/ProjectChampollion/assets/rosetta_binaries.png">
    <figcaption>Figure 2 Binaries installed after Rosetta 2 installation.</figcaption>
</figure>

<p>The role of each binary will be explained later.</p>
<p>The next step is to disable System Integrity Protection (SIP).
This is because the folder that contains the translated binaries is protected by SIP and cannot be accessed by default even with administrative privileges.</p>
<p>Please follow the steps below to disable SIP.</p>
<ul>
<li>Restart the OS</li>
<li>Press and hold Touch ID to boot in the recovery mode</li>
<li>Select Terminal from "Utilities" at the top of the screen</li>
<li>Type <code>csrutil disable</code> and execute</li>
<li>Restart the OS again</li>
</ul>
<p>In addition to this, please install Xcode and Command Line Tools for Xcode to use Clang and LLDB.</p>
<h2 id="roles-of-oahd-and-oahd-helper">Roles of <code>oahd</code> and <code>oahd-helper</code></h2>
<p>First, let's create a command line application built for x86_64 and monitor system events (e.g., process creation, file-system activities, and memory mapping) when the x86_64 application runs.</p>
<pre><code>$ cat hello.c
#include &lt;stdio.h&gt;
int main() {
    puts("Hello World");
    return 0;
}
$ clang -arch x86_64 hello.c -o hello.out # specify x86_64 as the target architecture
$ file hello.out
hello.out: Mach-O 64-bit executable x86_64
</code></pre>
<p>To obtain several system events, I used EventMonitor created using the <a href="https://developer.apple.com/documentation/endpointsecurity">Endpoint Security Framework</a>.
I will release EventMonitor as an OSS soon.</p>
<p>Start EventMonitor and run <code>hello.out</code>.
The following jsonl file contains logs obtained by EventMonitor. The only events related to Rosetta 2 are extracted.</p>
<p><a href="https://ffri.github.io/ProjectChampollion/assets/event.jsonl">event.jsonl</a></p>
<p>When you look at the first line of the logs, you can see an event where <code>/bin/zsh</code> executes <code>hello.out</code>.</p>
<pre><code>{"event":{"log":{"args":[".\/hello.out"],"cwd":{"path":"\/Users\/konakagawa.ffri","path_truncated":false},"last_fd":4,"target":{"executable_path":"\/Users\/konakagawa.ffri\/hello.out","group_id":54132,"pid":54132,"ppid":48492,"session_id":48491}},"type":"exec"},"target_process":{"executable_path":"\/bin\/zsh","group_id":54132,"pid":54132,"ppid":48492,"session_id":48491}}
</code></pre>
<p>After the exec system call, <code>oahd</code> daemon checks for the file <code>/var/db/oah/16c6785d8fdab5ee2435f23dc2962ceda2e76042ea2ad1517687c5bb7358bf00/065b3f057e68a5474d378306e41d8b1e3e8e612b9cf9010b76449e02b607d7f0/hello.out.aot</code>.</p>
<pre><code>... (the oahd checks for the AOT file)
{"event":{"log":{"relative_target":"var\/db\/oah\/16c6785d8fdab5ee2435f23dc2962ceda2e76042ea2ad1517687c5bb7358bf00\/065b3f057e68a5474d378306e41d8b1e3e8e612b9cf9010b76449e02b607d7f0\/hello.out.aot","source_dir":{"path":"\/","path_truncated":false}},"type":"lookup"},"target_process":{"executable_path":"\/Library\/Apple\/usr\/libexec\/oah\/oahd","group_id":426,"pid":426,"ppid":1,"session_id":426}}
</code></pre>
<p>The file with the extension <code>.aot</code> contains the result of the translation from x86_64 to arm64.
We refer to this file as the AOT file.
The name <code>.aot</code> comes from Ahead-Of-Time, which means that the translation is performed before a thread actually starts.
The <code>oahd</code> is the management daemon for the AOT files.</p>
<p>Since this is the first time we run <code>hello.out</code>, the <code>oahd</code> cannot find the corresponding AOT file. So, it creates a new AOT file.
If the same binary in the same path has already been executed and the AOT file has been created, the <code>oahd</code> uses it.</p>
<p>You can see the folder named <code>/var/db/oah</code> in the above logs.
This folder has a <code>Oah.version</code> file at the top, which is supposed to contain the version information for Rosetta 2.
Also, this folder has <code>16c6785d8fdab5ee2435f23dc2962ceda2e76042ea2ad1517687c5bb7358bf00</code> folder.
We can see that multiple folders are containing AOT files in it.
The names of these folders are SHA-256 hash values that are calculated from both the contents of the file in x86_64 code and the path where it was executed.</p>
<pre><code># /var/db/oah contains the Oah.version file and 16c6785d8fdab5ee2435f23dc2962ceda2e76042ea2ad1517687c5bb7358bf00 folder
$ ls -l /var/db/oah
total 8
drwxr-xr-x  6528 _oahd  _oahd  208896  2 13 22:22 16c6785d8fdab5ee2435f23dc2962ceda2e76042ea2ad1517687c5bb7358bf00
-rw-------     1 _oahd  _oahd      32  1 27 14:44 Oah.version
# show some AOT files
$ ls -l /var/db/oah/16c6785d8fdab5ee2435f23dc2962ceda2e76042ea2ad1517687c5bb7358bf00/* | head -n 10
/var/db/oah/16c6785d8fdab5ee2435f23dc2962ceda2e76042ea2ad1517687c5bb7358bf00/00088a4116103832383ae2866e61d745d3d0013c5073ed032dabf6a785611db9:
total 40
-rwxr-xr-x  1 _oahd  _oahd  17656  1 27 14:45 FlashlightModule.aot

/var/db/oah/16c6785d8fdab5ee2435f23dc2962ceda2e76042ea2ad1517687c5bb7358bf00/0008a5059fda4b8aee7110b04a3e65f175a80ea55a64129a7660c7d3ed77a9d5:
total 56
-rwxr-xr-x  1 _oahd  _oahd  25928  1 27 14:47 libswiftAccelerate.dylib.aot

/var/db/oah/16c6785d8fdab5ee2435f23dc2962ceda2e76042ea2ad1517687c5bb7358bf00/00091f4ca51a770fa7a398f4320efe920fa8c3fc611247dcf55ca025f22301d4:
total 600
-rwxr-xr-x  1 _oahd  _oahd  304536  1 27 14:45 AirPlayRoutePrediction.aot

/var/db/oah/16c6785d8fdab5ee2435f23dc2962ceda2e76042ea2ad1517687c5bb7358bf00/000a1ab017d7e24b25cd58739ae01120b8a6d3a9cff37235156dced0123f2c3c:
total 24
-rwxr-xr-x  1 _oahd  _oahd  12280  1 27 14:46 NanoNewsComplications.aot

/var/db/oah/16c6785d8fdab5ee2435f23dc2962ceda2e76042ea2ad1517687c5bb7358bf00/001dac33f82e558695268fb4a4285f47e9806766e7398e377d9dff59235399f5:
total 1192
-rwxr-xr-x  1 _oahd  _oahd  606347  1 27 14:46 TSCoreSOS.aot
</code></pre>
<p>Note that the folders and files under <code>/var/db/oah</code> are protected by SIP, so we cannot access even with admin privileges.
After disabling SIP, we can access these folders and files with admin privileges.</p>
<p>Now, back to the analysis of the logs.
<code>oahd</code> checks for the AOT file, and if not found, it runs <code>oahd-helper</code> to create a new AOT file.</p>
<pre><code>... (oahd creates hello.out.aot.in_progress file)
{"event":{"log":{"dest_path":{"path":"\/private\/var\/db\/oah\/16c6785d8fdab5ee2435f23dc2962ceda2e76042ea2ad1517687c5bb7358bf00\/065b3f057e68a5474d378306e41d8b1e3e8e612b9cf9010b76449e02b607d7f0\/hello.out.aot.in_progress","path_truncated":false},"dest_type":0,"filename":null},"type":"create"},"target_process":{"executable_path":"\/Library\/Apple\/usr\/libexec\/oah\/oahd","group_id":426,"pid":426,"ppid":1,"session_id":426}}
... (creates a child process)
{"event":{"log":{"child":{"executable_path":"\/Library\/Apple\/usr\/libexec\/oah\/oahd","group_id":426,"pid":54133,"ppid":426,"session_id":426}},"type":"fork"},"target_process":{"executable_path":"\/Library\/Apple\/usr\/libexec\/oah\/oahd","group_id":426,"pid":426,"ppid":1,"session_id":426}}</code></pre></article></div></div></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ffri.github.io/ProjectChampollion/part1/">https://ffri.github.io/ProjectChampollion/part1/</a></em></p>]]>
            </description>
            <link>https://ffri.github.io/ProjectChampollion/part1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26346980</guid>
            <pubDate>Thu, 04 Mar 2021 19:27:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Female Founder Secrets: Fertility]]>
            </title>
            <description>
<![CDATA[
Score 438 | Comments 665 (<a href="https://news.ycombinator.com/item?id=26345226">thread link</a>) | @femfosec
<br/>
March 4, 2021 | https://femfosec.com/fertility/ | <a href="https://web.archive.org/web/*/https://femfosec.com/fertility/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>Because of our biological clocks, women need to consider the timing of children a lot more urgently than men.</p><p>Startups take much longer than you’d think before they become successful. You should have a 5-10 year horizon, at least.</p><p>And the period between when you start the startup and when you can relax a little is grueling and all-consuming. The focus that’s required at first will probably force you to cut back on almost everything in your life, making a healthy work/life balance nearly impossible.</p><p>Startups are also unpredictable. In the early stages, you can’t plan too far in the future and arrange your life neatly around your plans, as you might with a job as an employee in the corporate world.</p><p>So you are working around the clock—so busy that you can’t focus on much outside of work, not knowing what startup disaster is around the corner, and maybe with no end in sight for years. But you know you want a family someday, either with your current partner or someone you haven’t even had the time to meet yet.</p><p>Because startups can cause you to neglect much of your own life, women founders need to be really proactive about their fertility. Especially if you want to buy more time before the window shuts on your childbearing years.</p><p>My advice: Freeze your eggs/embryos.</p><p>I wish I had. Life with my company whizzed by and it wasn’t until my late 30s when I had a child. After a year, I started working on baby #2. Three miscarriages later, I finally woke up to the urgency of the situation and went to a fertility doctor.</p><p>The next few years were consumed by IVF cycles. My obsession to have another baby grew with each failed cycle. I’d be on an emotional roller coaster waiting for the various results, praying that this time was the magical one. It never was. My eggs were just too old, I think. After 8 rounds with not one viable embryo to transfer, I decided I had to move on, to focus on my kid and all the really great things in my life. But the what-ifs still haunt me, privately.</p><p>Aspects of getting your eggs retrieved and/or frozen can be really awful. It’s extremely expensive if not covered by your medical insurance. The drugs can wreak havoc on moods and emotions. Between all the doctor’s appointments and the various shots (which cause serious bruising) you have to give yourself several times each day, it’s quite time consuming. &nbsp;And it’s stressful. At least it was for me. The stakes feel so high.</p><p>But nothing is as awful as it not working out. It’s a type of depressing that’s difficult to describe concisely.</p><p>It might seem weird or somehow frivolous to freeze your eggs—and especially to freeze embryos if you’re already married. (Though it’s becoming more mainstream as companies offer egg freezing as an employee benefit.) But freezing is worth it simply because it gives you more options as you get older.</p><p>Until they go through it themselves, few people realize how hard Mother Nature can be in the fertility department. The older you are, the tougher the blows. So if you want a biological child, the best thing you can do is prepare. You don’t want to be like me and wake up one day and it’s too late.</p>
			</section></div>]]>
            </description>
            <link>https://femfosec.com/fertility/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26345226</guid>
            <pubDate>Thu, 04 Mar 2021 17:28:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tips for Shipping Data Products Fast]]>
            </title>
            <description>
<![CDATA[
Score 149 | Comments 37 (<a href="https://news.ycombinator.com/item?id=26341032">thread link</a>) | @oedmarap
<br/>
March 4, 2021 | https://shopify.engineering/shipping-data-products-fast | <a href="https://web.archive.org/web/*/https://shopify.engineering/shipping-data-products-fast">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
  <p>Shipping a new product is hard. Doing so under tight time constraints is even harder. It’s no different for data-centric products. Whether it’s a forecast, a classification tool, or a dashboard, you may find yourself in a situation where you need to ship a new data product in a seemingly impossible timeline.&nbsp;</p>
<p>Shopify’s Data Science team has certainly found itself in this situation more than a few times over the years. Our team focuses on creating data products that support our merchants’ entrepreneurial journeys, from their initial interaction with Shopify, to their first sale, and throughout their growth journey on the platform. Commerce is a fast changing industry, which means we have to build and ship fast to ensure we’re providing our merchants with the best tools to help them succeed.</p>
<p>Along the way, our team learned a few key lessons for shipping data products quickly, while maintaining focus and getting things done efficiently—<em>but also done right.</em> Below are four tips that are proven to help you ship new products fast.&nbsp;</p>

<p>Investing time in a design sprint pays off down the line as you approach deadlines. The design sprint (created by <a href="https://www.gv.com/sprint/" target="_blank" title="Google Ventures" rel="nofollow noopener noreferrer">Google Ventures</a>) is “a process for answering critical business questions through design, prototyping and testing ideas with customers.” Sprints are great for getting a new data product off the ground quickly because they carve out specific time blocks and resources for you and your team to work on a problem. The Shopify Data Science teams make sprints a common practice, especially when we’re under a tight deadline. When setting up new sprints, here are the steps we like to take:</p>
<ol>
<li>
<strong><em>Choose an impactful problem to tackle. </em></strong>We focus on solving problems for our merchants, but in order to do that, we first have to uncover what those problems are by asking questions. <em>What</em> is the problem we’re trying to solve? <em>Why </em>are we solving this problem? Asking questions empowers you to find a problem worth tackling, identify the right technical solution and ultimately drive impact.</li>
<li>
<strong><em>Assemble a small sprint team</em></strong>: Critical to the success of any sprint is assembling a small team (no more than 6 or 7) of highly motivated individuals. Why a small team? It’s easier to stay aligned in a smaller group due to better communication and transparency, which means it’s easier to move fast.</li>
<li>
<strong><em>Choose a sprint Champion:</em></strong> This individual should be responsible for driving the direction of the project and making decisions when needed (should we use solution A or B?). Assigning a Champion helps remove ambiguity and allow the rest of the team to focus their energy on solving the problem in front of them.</li>
<li>
<strong><em>Set your sprint dates:</em></strong> Timeboxing is one of the main reasons why sprints are so effective. By setting fixed dates, you're committing your team to focus on shipping on a precise timeline. Typically, a sprint lasts up to five days. However, the timeline can be shortened based on the size of the project (for example, three days is likely enough time for creating the first version of a dashboard that follows the impact of COVID-19 on the business’s acquisition funnel).</li>
</ol>
<p>With your problem identified, your team set up, and your dates blocked off, it’s now time to sprint. Keep in mind while exploring solutions that solving a data-centric problem with a non-data focused approach can sometimes be simple and time efficient. For instance, asking a user for its preferred location rather than inferring it using a complex heuristic.</p>

<p>Speed is critical! The first iterations of a brand new product often go through many changes. Prototypes allow for quick and cheap learning cycles. They also help prevent the sunk cost fallacy (when a past investment becomes a rationale for continuing).&nbsp;</p>
<p>In the data world, a good rule of thumb is to leverage spreadsheets for building a prototype. Spreadsheets are a versatile tool that help accelerate build times, yet are often underutilized by data scientists and engineers. By design, spreadsheets allow the user to make sense of data in messy contexts, with just a few clicks. The built-in functions cover most basic use cases:&nbsp;</p>
<ul>
<li>cleaning data by hand rapidly</li>
<li>displaying graphs</li>
<li>computing basic ranking indices</li>
<li>formatting output data.</li>
</ul>
<p>While creating a robust system is desirable, it often comes at the expense of longer building times. When releasing a brand new data product under a tight timeline, the focus should be on developing prototypes fast.&nbsp;</p>
<figure><img alt="A sample Google Sheet dashboard evaluating Inbound Leads.  The dashboard consists of 6 charts.  The 3 line charts on the left measure Lead Count, Qualification Rate %, and Time to Qualification in Minutes.  The 3 bar charts on the right  measure Leads by Channel, Leads by Country, and Leads by Last Source Touched." data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/google-sheets-dashboard-prototype_8e7a900e-b66d-4618-a4d0-fdb26359a44b.jpg?v=1614705455" src="https://cdn.shopify.com/s/files/1/0779/4361/files/google-sheets-dashboard-prototype_8e7a900e-b66d-4618-a4d0-fdb26359a44b.jpg?v=1614705455">
<figcaption>An example of a dashboard prototype created within Google Sheets.</figcaption>
</figure>
<p>Despite a strong emphasis on speed, a prototype should still look and feel professional. For example, the first iteration of the <a href="https://www.shopify.my/blog/marketing-attribution" target="_blank" title="Marketing Attribution: Seeing the Customer Journey More Clearly" rel="noopener noreferrer">Marketing attribution tool</a> developed for Shopify’s Revenue team was a collection of SQL queries automated by a bash script. The output was then formatted in a spreadsheet. This allowed us to quickly make changes to the prototype and compare it to out-of-the-box tools. We avoided any wasted effort spinning up dashboards, production code, as well as any sentimental attachment to the work, which made it easier for the best solution to win.</p>

<p>When building a new data product, it’s tempting to spend lots of time on a flashy machine learning algorithm. This is especially true if the product is supposed to be “smart”. Building a machine learning model for your first iteration can cost a lot of time. For example, when sprinting to build a lead scoring system for our Sales Representatives, our team spent 80% of the sprint gathering features and training a model. This left little time to integrate the product with the existing <a href="https://en.wikipedia.org/wiki/Customer_relationship_management" target="_blank" title="Customer Relationship Management on Wikipedia" rel="nofollow noopener noreferrer">customer relationship management</a> (CRM) infrastructure, polish it, and ask for feedback. A simple ranking using a proxy metric would be much faster to implement for the first iteration. The time gained would allow for more conversations with the users about the impact, use and engagement with the tool.&nbsp;</p>
<p>We took that lesson to heart in our next project when we built a sales forecasting tool. We started with a linear regression using only two input variables that allowed us to have a prototype ready in a couple of hours. Using a simple model allowed us to ship fast and quickly learn whether it solved our user’s problem. Knowing we were on the right track, we then built a more complex model using machine learning.</p>
<p>Focus on building models that solve problems and can be shipped quickly. Once you’ve proven that your product is effective and delivers impact, then you can focus your time and resources on building more complex models.&nbsp;</p>

<p>Shipping fast also means shipping the right product. In order to stay on track, gathering feedback from users is invaluable! It allows you to build the right solution for the problem you’re tackling. Take the time to talk to your users, before, during, and after each build iteration. Shadowing them, or even doing the task yourself is a great return on investment.</p>
<p>Gathering feedback is an art. Entire books and research papers are dedicated to it. Here are the two tips we use at Shopify that increased the value of feedback we’ve received:</p>
<ul>
<li>
<em>Ask specific questions.</em> Asking, “Do you have any feedback?” doesn’t help the user direct their thoughts. Questions like, “How do you feel about the speed at which the dashboard loads?” or “Are you able to locate the insights you need on this dashboard to report on top of funnel performance?” are more targeted and will yield richer feedback.</li>
</ul>
<ul>
<li>
<em>Select a diverse group of users for feedback</em>. Let’s suppose that you are building a dashboard that’s going to be used by three regional teams. It’s more effective to send a request for feedback to one person in each team rather than five people in a single team.</li>
</ul>
<figure><img alt="A sample Google Form that measures Prototype A's Scoring.  The form consists of 2 questions. The first question is &quot;Is the score easy to parse and interpret? It is scored using a ranking from 1 - 5 with 1 = Very Hard and 5 = Very Easy. The 2nd question is &quot;Additional Comments&quot; and has a text field for the answer." data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/sample-google-form.jpg?v=1614705664" src="https://cdn.shopify.com/s/files/1/0779/4361/files/sample-google-form.jpg?v=1614705664">
<figcaption>Feedback our team asked for the scoring system we created. When asking for feedback, you want to ask specific questions so you can yield better feedback.</figcaption>
</figure>
<p>We implemented the two tips when requesting feedback from users of the sales forecasting tool highlighted in the previous section. We asked a diverse group specific questions about our product, and learned that displaying a numerical score (0 - 100) was confusing. The difference between scores wasn’t clear to the users. Instead, it was suggested to display grades (A, B, C) which turned out to be much quicker to interpret and led to a better user experience.</p>
<p>At Shopify, following these tips has provided the team with a clearer path for launching brand new data products under tight time constraints. More importantly, it helped us avoid common pitfalls like getting stuck during neverending design phases, overengineering complex machine learning systems, or building data products that users don’t use.&nbsp;</p>
<p>Next time you’re under a tight timeline to ship a new data product, remember to:</p>
<ol>
<li>
<strong><em>Utilize design sprints</em></strong> to help focus your team’s efforts and remove the stress of the ticking clock</li>
<li>
<strong><em>Don’t skip on prototyping,</em></strong> it’s a great way to fail early</li>
<li>
<strong><em>Avoid machine learning</em></strong> (for first iterations) to avoid being slowed down by unnecessary complexity</li>
<li>
<strong><em>Talk to your users</em></strong> so you can get a better sense of what problem they’re facing and what they need in a product</li>
</ol>
<p>If you’d like to read more about shipping new products fast, we recommend checking out <a href="https://www.thesprintbook.com/" target="_blank" title="Sprint (How to Solve Big Problems and Test New Ideas in Just Five Days)" rel="nofollow noopener noreferrer">The Design Sprint</a> book, by Jake Knapp et al. which provides a complete framework for testing new ideas.</p>
<hr>
<p>If you’re interested in helping us ship great data products, quickly, we’re looking for talented data scientists to <a href="https://www.shopify.com/careers/teams/data?itcat=EngBlog&amp;itterm=Post&amp;shpxid=73b80879-3076-43E8-7604-FE14CE1EBEED" target="_blank">join our team</a>.</p>
</div></div>]]>
            </description>
            <link>https://shopify.engineering/shipping-data-products-fast</link>
            <guid isPermaLink="false">hacker-news-small-sites-26341032</guid>
            <pubDate>Thu, 04 Mar 2021 11:13:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don’t blindly prefer emplace_back to push_back]]>
            </title>
            <description>
<![CDATA[
Score 171 | Comments 140 (<a href="https://news.ycombinator.com/item?id=26339893">thread link</a>) | @todsacerdoti
<br/>
March 4, 2021 | https://quuxplusone.github.io/blog/2021/03/03/push-back-emplace-back/ | <a href="https://web.archive.org/web/*/https://quuxplusone.github.io/blog/2021/03/03/push-back-emplace-back/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>In one of my recent training courses, a student informed me that both clang-tidy
and PVS-Studio were complaining about some code of the form</p>

<div><div><pre><code>std::vector&lt;Widget&gt; widgets;
~~~
widgets.push_back(Widget(foo, bar, baz));
</code></pre></div></div>

<p>Both tools flagged this line as “bad style.”
clang-tidy even offered a (SARCASM ALERT) helpful fixit:</p>

<div><div><pre><code>warning: use emplace_back instead of push_back [modernize-use-emplace]
    widgets.push_back(Widget(foo, bar, baz));
            ^~~~~~~~~~~~~~~~~             ~
            emplace_back(
</code></pre></div></div>

<p>The student dutifully changed the line, and both tools reported their
satisfaction with the replacement:</p>

<div><div><pre><code>widgets.emplace_back(Widget(foo, bar, baz));
</code></pre></div></div>

<p>The original line materializes a temporary <code>Widget</code> object on the stack;
takes an rvalue reference to it; and passes that reference to
<code>vector&lt;Widget&gt;::push_back(Widget&amp;&amp;)</code>, which move-constructs a <code>Widget</code>
into the vector. Then we destroy the temporary.</p>

<p>The student’s replacement materializes a temporary <code>Widget</code> object on the stack;
takes an rvalue reference to it; and passes that reference to
<code>vector&lt;Widget&gt;::emplace_back&lt;Widget&gt;(Widget&amp;&amp;)</code>, which move-constructs
a <code>Widget</code> into the vector. Then we destroy the temporary.</p>

<p><em>Absolutely no difference.</em></p>

<p>The change clang-tidy meant to suggest — and in fact <em>did</em> suggest,
if you pay very close attention to the underlining in the fixit — was actually this:</p>

<div><div><pre><code>widgets.emplace_back(foo, bar, baz);
</code></pre></div></div>

<p>This version does <em>not</em> materialize any <code>Widget</code> temporaries. It simply
passes <code>foo, bar, baz</code> to <code>vector&lt;Widget&gt;::emplace_back&lt;Foo&amp;, Bar&amp;, Baz&amp;&gt;(Foo&amp;, Bar&amp;, Baz&amp;)</code>,
which constructs a <code>Widget</code> into the vector using whatever
constructor of <code>Widget</code> best matches that bunch of arguments.</p>

<h2 id="emplace_back-is-not-magic-c11-pixie-dust"><code>emplace_back</code> is not magic C++11 pixie dust</h2>

<p>Even a decade after C++11 was released, I still sometimes see programmers assume
that <code>emplace_back</code> is somehow related to move semantics. (In the same way that
some programmers assume lambdas are somehow the same thing as <code>std::function</code>,
you know?) For example, they’ll rightly observe that this code makes an
unnecessary copy:</p>

<div><div><pre><code>void example() {
    auto w = Widget(1,2,3);
    widgets.push_back(w);  // Copy-constructor alert!
}
</code></pre></div></div>

<p>So they’ll change it to this:</p>

<div><div><pre><code>void example() {
    auto w = Widget(1,2,3);
    widgets.emplace_back(w);  // Fixed? Nope!
}
</code></pre></div></div>

<p>The original line constructs a <code>Widget</code> object into <code>w</code>, then
passes <code>w</code> by reference to <code>vector&lt;Widget&gt;::push_back(const Widget&amp;)</code>,
which copy-constructs a <code>Widget</code> into the vector.</p>

<p>The replacement constructs a <code>Widget</code> object into <code>w</code>, then
passes <code>w</code> by reference to <code>vector&lt;Widget&gt;::emplace_back&lt;Widget&amp;&gt;(Widget&amp;)</code>,
which copy-constructs a <code>Widget</code> into the vector.</p>

<p><em>Absolutely no difference.</em></p>

<p>What the student should have done is ask the compiler to make an
<em>rvalue</em> reference to <code>w</code>, by saying either</p>

<div><div><pre><code>widgets.push_back(std::move(w));
</code></pre></div></div>

<p>or</p>

<div><div><pre><code>widgets.emplace_back(std::move(w));
</code></pre></div></div>

<p>It doesn’t matter which verb you use; what matters is the value category of
<code>w</code>. You must explicitly mention <code>std::move</code>, so that the language (and the
human reader) understand that you’re done using <code>w</code> and it’s okay for
<code>widgets</code> to pilfer its guts.</p>

<p><code>emplace_back</code> was added to the language at the same time as <code>std::move</code> — just
like lambdas were added at the same time as <code>std::function</code> — but that doesn’t
make them the same thing. <code>emplace_back</code> may “look more C++11-ish,” but it’s
not magic move-enabling pixie dust and it will never insert a move in a place
you don’t explicitly request one.</p>

<h2 id="when-all-else-is-equal-prefer-push_back-to-emplace_back">When all else is equal, prefer <code>push_back</code> to <code>emplace_back</code></h2>

<p>So, given that these two lines do the same thing and are equally efficient
at runtime, which should I prefer, stylistically?</p>

<div><div><pre><code>widgets.push_back(std::move(w));
widgets.emplace_back(std::move(w));
</code></pre></div></div>

<p>I recommend sticking with <code>push_back</code> for day-to-day use. You should definitely
use <code>emplace_back</code> when you need its particular set of skills — for example, <code>emplace_back</code>
is your only option when dealing with a <code>deque&lt;mutex&gt;</code> or other non-movable type —
but <code>push_back</code> is the appropriate default.</p>

<p>One reason is that <code>emplace_back</code> is more work for the compiler.
<code>push_back</code> is an overload set of two non-template member functions.
<code>emplace_back</code> is a single variadic template.</p>

<div><div><pre><code>void push_back(const Widget&amp;);
void push_back(Widget&amp;&amp;);

template&lt;class... Ts&gt;
reference emplace_back(Ts&amp;&amp;...);
</code></pre></div></div>

<p>When you call <code>push_back</code>, the compiler must do overload resolution, but that’s all.
When you call <code>emplace_back</code>, the compiler must do template type deduction, followed
by (easy-peasy) overload resolution, followed by function template instantiation and
code generation. That’s a much larger amount of work for the compiler.</p>

<h2 id="the-benchmark-program">The benchmark program</h2>

<p>I wrote a simple test program to demonstrate the difference in compiler workload.
Of course <a href="https://en.wikipedia.org/wiki/Amdahl%27s_law">Amdahl’s Law</a> applies:
my benchmark displays a massive difference because it’s doing <em>nothing but</em>
instantiating <code>emplace_back</code>, whereas any production codebase will be doing vastly
more other stuff relative to the number of times it instantiates <code>emplace_back</code>.
Still, I hope this benchmark gives you a sense of why I recommend “<code>push_back</code> over
<code>emplace_back</code>” and not vice versa.</p>

<p>This Python 3 script generates the benchmark:</p>

<div><div><pre><code>import sys
print('#include &lt;vector&gt;')
print('#include &lt;string&gt;')
print('extern std::vector&lt;std::string&gt; v;')
for i in range(1000):
    print('void test%d() {' % i)
    print('    v.%s_back("%s");' % (sys.argv[1], 'A' * i))
    print('}')
</code></pre></div></div>

<p>Generate like this:</p>

<div><div><pre><code>python generate.py push &gt;push.cpp
python generate.py emplace &gt;emplace.cpp
time g++ -c push.cpp
time g++ -c emplace.cpp
</code></pre></div></div>

<p>With Clang trunk on my laptop, I get consistently about 1.0s for the <code>push</code> version,
and 4.2s for the <code>emplace</code> version. This big difference is due to the fact that the
<code>push</code> version is merely code-generating a thousand <code>test</code> functions, whereas
the <code>emplace</code> version is code-generating that same thousand <code>test</code> functions <em>and</em>
another thousand template instantiations of <code>emplace_back</code> with different parameter
types:</p>

<div><div><pre><code>vector&lt;string&gt;::emplace_back&lt;const char(&amp;)[1]&gt;(const char (&amp;)[1])
vector&lt;string&gt;::emplace_back&lt;const char(&amp;)[2]&gt;(const char (&amp;)[2])
vector&lt;string&gt;::emplace_back&lt;const char(&amp;)[3]&gt;(const char (&amp;)[3])
vector&lt;string&gt;::emplace_back&lt;const char(&amp;)[4]&gt;(const char (&amp;)[4])
~~~
</code></pre></div></div>

<p>See, <code>push_back</code> knows that it expects a <code>string&amp;&amp;</code>, and so it knows to call the
non-explicit constructor <code>string(const char *)</code> on the caller’s side. The same
constructor is called in each case, and the temporary <code>string</code> is passed to
the same overload of <code>push_back</code> in each case. <code>emplace_back</code>, on the other hand,
is a dumb perfect-forwarding template: it doesn’t know that the relevant constructor
overload will end up being <code>string(const char *)</code> in each case. So it takes
an lvalue reference to the specific <em>array type</em> being passed by the caller.
Perfect-forwarding has no special cases for <code>const char *</code>!</p>

<p>If we change <code>vector&lt;string&gt;</code> to <code>vector&lt;const char *&gt;</code>, the compile-time-performance
gap widens: now it’s 0.7s for <code>push</code>, 3.8s for <code>emplace</code>. This is because we’ve cut
out some of the work that was common to both versions (constructing <code>std::string</code> objects)
without affecting the source of the gap (that one version instantiates a
thousand copies of <code>emplace_back</code> and the other doesn’t). Amdahl’s Law in action!</p>

<p>My conclusions:</p>

<blockquote>
  <p>Use <code>push_back</code> by default.</p>
</blockquote>

<blockquote>
  <p>Use <code>emplace_back</code> where it is semantically significant to your algorithm
(such as when the element type’s move-constructor is absent or has been
benchmarked as expensive).</p>
</blockquote>

<blockquote>
  <p>Avoid mixing string literals and perfect-forwarding templates,
especially in repetitive machine-generated code.</p>
</blockquote>

<hr>

<p>Previously on this blog:</p>

<ul>
  <li><a href="https://quuxplusone.github.io/blog/2018/06/26/cost-of-static-lifetime-constructors/">“The surprisingly high cost of static-lifetime constructors”</a> (2018-06-26)</li>
</ul>

  </div></div>]]>
            </description>
            <link>https://quuxplusone.github.io/blog/2021/03/03/push-back-emplace-back/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26339893</guid>
            <pubDate>Thu, 04 Mar 2021 08:02:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bitsquatting Windows.com]]>
            </title>
            <description>
<![CDATA[
Score 248 | Comments 69 (<a href="https://news.ycombinator.com/item?id=26338244">thread link</a>) | @vikrum
<br/>
March 3, 2021 | https://remyhax.xyz/posts/bitsquatting-windows/ | <a href="https://web.archive.org/web/*/https://remyhax.xyz/posts/bitsquatting-windows/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><figure><img src="https://remyhax.xyz/image/dns.jpg"></figure><p>Earlier this month, I came back around to seriously considering an attempt at <a href="http://dinaburg.org/bitsquatting.html">bitsquatting</a>. While the prior link goes into great depth on the topic, I will attempt to give a <em>very</em> high level overview here:</p><p>If this sort of thing interests you: I tend to do stuff like this weekly. Give me a follow <a href="https://twitter.com/_mattata">@_mattata</a></p><p>When you try to access a site by it’s domain, that domain is stored in the memory of your computer, device, whatever… in a structure that looks something like this.</p><table><thead><tr><th>01110111</th><th>01101001</th><th>01101110</th><th>01100100</th><th>01101111</th><th>01110111</th><th>01110011</th></tr></thead><tbody><tr><td>w</td><td>i</td><td>n</td><td>d</td><td>o</td><td>w</td><td>s</td></tr></tbody></table><p>Now let’s say that the computer is running too hot, a solar flare is happening, or a cosmic ray (very real thing) flips a bit on the computer.</p><table><thead><tr><th>01110111</th><th>01101000</th><th>01101110</th><th>01100100</th><th>01101111</th><th>01110111</th><th>01110011</th></tr></thead><tbody><tr><td>w</td><td><strong>h</strong></td><td>n</td><td>d</td><td>o</td><td>w</td><td>s</td></tr></tbody></table><p>Oh no! Now the value stored in memory is w<strong>h</strong>ndows.com instead of windows.com! When the time comes to make a connection to that domain, what happens?</p><blockquote><p>nslookup whndows.com</p></blockquote><blockquote><p>*** can’t find whndows.com: Non-existent domain</p></blockquote><p>The domain doesn’t resolve to an IP!</p><hr><p>In fact, out of the 32 valid domain names that are 1-bitflip away from windows.com 14 were available for purchase! This is a rather odd occurance as usually these are bought up by a company like Microsoft to prevent their use for phishing attempts. So I bought them. All of them. For ~$126.</p><p>(<em>If you’re a verifiably responsible party, I’m more than happy to transfer ownership of the domains. Otherwise, I’ll just hold on to them and continue to sinkhole.</em>)</p><blockquote><p>windnws.com
windo7s.com
windkws.com
windmws.com
winlows.com
windgws.com
wildows.com
wintows.com
wijdows.com
wiodows.com
wifdows.com
whndows.com
wkndows.com
wmndows.com</p></blockquote><p>Now we need to point these domains somewhere. So I rent a VPS and configure IPv4/IPv6, and create wildcard DNS entries to point to them.</p><p>Wildcard DNS works so that if I create a record saying that whndows.com points to 123.123.123.123 and someone requests abs.xyz.whndows.com, they will still get the same 123.123.123.123 DNS record as a reply. Due to the nature of this research dealing with bits being flipped, this allows me to capture any DNS lookup for a subdomain of windows.com where multiple bits have flipped.</p><p>Once we have DNS configured, we use <a href="https://www.wireshark.org/docs/man-pages/tshark.html">tshark</a> to perform a packet capture on the public interface of our VPS and wait for something interesting to happen.</p><p>Below is a short snippet of some interesting things that can be shared without uniquely indentifying any users.</p><p>Usage of <strong><a href="https://greynoise.io/tech">GreyNoise.io</a></strong> was key in helping to differentiate between opportunistic scanning and actual bitflip scenarios. Great product!</p><h2 id="ntp-udp-port-123-timewindowscom">NTP UDP port 123 time.windows.com</h2><p>UDP packets destined for port 123 attempting to set their computer clock using the Network Time Protocol (NTP).
time.windows.com is the default NTP server configured for all Windows machines and they check for the time regularly. If they don’t succeed in getting the time, they try again, and again, and again.</p><p>In total, over the course of 14 days, my server recieved <strong>199,180 NTP Client connections from 626 unique IP addresses.</strong></p><p>The NTP client for windows OS has no inherent verification of authenticity, so there is nothing stopping a malicious person from telling all these computers that it’s after <a href="https://en.wikipedia.org/wiki/Year_2038_problem">03:14:07 on Tuesday, 19 January 2038</a> and wreaking unknown havoc as the memory storing the signed 32-bit integer for time overflows.</p><p>As it turns out though, for ~30% of these computers doing that would make little to no difference at all to those users because their clock is already <em>broken</em>.</p><p>Using the tshark filter “ntp.xmt” we can extract the Transmit Timestamp, which is the time that the computer thinks it is when it asks to update the time.</p><blockquote><p>tshark -r capture.pcap -T fields -e ntp.xmt -2 -R ntp.xmt | sort -u</p></blockquote><pre><code>Sep 28, 1984 19:41:12.638290998 EDT
Sep 28, 2012 11:59:42.976403314 EDT
Sep 28, 2029 21:50:47.552079831 EDT
Sep 28, 2100 18:13:09.180229791 EST
Sep 29, 1975 08:36:52.200231052 EDT
Sep 29, 1980 23:44:14.142299217 EDT
Sep 29, 2036 11:54:11.410350275 EDT
Sep 29, 2038 06:18:34.082394858 EDT
Sep 29, 2046 16:00:00.102963544 EST
Sep 29, 2050 06:39:18.880921186 EST
Sep 29, 2074 07:31:58.701524704 EST
Sep 30, 1999 00:29:32.120677896 EDT
Sep 30, 2009 02:54:33.318870579 EDT
Sep 30, 2049 00:14:59.396552253 EST
Sep 30, 2075 13:56:14.492526678 EST
Sep 30, 2081 01:56:58.477295064 EST
</code></pre><h2 id="http-tcp-port-80-sg2pwswindowscom">HTTP TCP port 80 sg2p.w.s.windows.com</h2><p>No active DNS record exists for the correct domain sg2p.w.s.windows.com</p><p>However, the User-Agent and timing of requests suggest that this activity is directly linked to the same application that generated the traffic shown below for client.wns.windows.com and skydrive.wns.windows.com</p><pre><code>GET / HTTP/1.1
Host: sg2p.w.s.windo7s.com
User-Agent: Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.109 Safari/537.36
Accept: */*
</code></pre><h2 id="http-tcp-port-80-clientwnswindowscom">HTTP TCP port 80 client.wns.windows.com</h2><p>These appear to be directly related to <a href="https://docs.microsoft.com/en-us/windows/uwp/design/shell/tiles-and-notifications/windows-push-notification-services--wns--overview">Windows Push Notification Services (WNS)</a> enable third-party developers to send toast, tile, badge, and raw updates from their own cloud service. DNS record is a CNAME to wns.notify.trafficmanager.net</p><p>DNS Records:</p><pre><code>client.wns.windows.com.        IN    CNAME   wns.notify.trafficmanager.net.
wns.notify.trafficmanager.net. IN    A       52.177.166.224
</code></pre><p>HTTP Request:</p><pre><code>GET / HTTP/1.1
Host: client.wns.wkndows.com
User-Agent: Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.109 Safari/537.36
Accept: */*
</code></pre><h2 id="http-tcp-port-80-skydrivewnswindowscom">HTTP TCP port 80 skydrive.wns.windows.com</h2><p>Skydrive is what <a href="https://www.microsoft.com/en-us/microsoft-365/onedrive/online-cloud-storage">OneDrive</a> was called before it’s name change.</p><p>DNS Records:</p><pre><code>skydrive.wns.windows.com.      IN      CNAME   client.wns.windows.com.
client.wns.windows.com.        IN      CNAME   wns.notify.trafficmanager.net.
wns.notify.trafficmanager.net. IN      A       52.179.224.121
</code></pre><p>HTTP Request:</p><pre><code>GET / HTTP/1.1
Host: skydrive.wns.windo7s.com
User-Agent: Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.109 Safari/537.36
Accept: */*
</code></pre><h2 id="http-tcp-port-80-timewindowscom">HTTP TCP port 80 time.windows.com</h2><p>I have no idea where the hell this request came from or why they were fetching HTTP on a server that should be an NTP server. WHOIS for the IP that made this request shown below:</p><pre><code>inetnum:        123.112.0.0 - 123.127.255.255
netname:        UNICOM-BJ
descr:          China Unicom Beijing province network
descr:          China Unicom
country:        CN
admin-c:        CH1302-AP
tech-c:         SY21-AP
mnt-by:         APNIC-HM
mnt-lower:      MAINT-CNCGROUP-BJ
mnt-routes:     MAINT-CNCGROUP-RR
mnt-irt:        IRT-CU-CN

GET / HTTP/1.1
Host: time.wiodows.com
Connection: close
User-Agent: Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/48.0.2564.116 Safari/537.36
Accept-Encoding: gzip
Accept-Language: zh-cn,zh-tw
Accept: */*
</code></pre><p><strong>Even stranger, shortly after the above request occurred, this happened!</strong> Baidu is one of China’s largest search engines. Keep in mind that I configured my DNS servers to resolve in wildcard mode. There is only a small number of ways Baiduspider could know that time.wiodows.com existed. Especially considering that only a single request had ever been made for this domain previously (seen above).</p><pre><code>GET / HTTP/1.1
Host: time.wiodows.com
Connection: close
User-Agent: Mozilla/5.0 (compatible; Baiduspider/2.0; +http://www.baidu.com/search/spider.html)
Accept-Encoding: gzip
Accept-Language: zh-cn,zh-tw
Accept: */*
</code></pre><h2 id="http-tcp-port-80-windowscomstopcode">HTTP tcp port 80 windows.com/stopcode</h2><p>When you get a blue screen of death on Windows, you are prompted to visit <a href="https://www.windows.com/stopcode">https://www.windows.com/stopcode</a>
Naturally, as the computer has crashed, they can’t just open the link. Most people would probably just scan the QR code, but those who misspell things ended up here.
<img src="https://remyhax.xyz/bitsquatting/bsod.png" alt="stopcode)"></p><pre><code>GET /stopcode HTTP/1.1
Host: wildows.com
Connection: keep-alive
Upgrade-Insecure-Requests: 1
User-Agent: Mozilla/5.0 (Linux; Android 5.0.1; ALE-L21) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.111 Mobile Safari/537.36
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9
Accept-Encoding: gzip, deflate
Accept-Language: en-US,en;q=0.9
</code></pre><p>The following request was particularly interesting. Due to the nature of the request, I’m going to be very general with some details or censor entirely because it’s not exactly clear what’s going on.</p><p>An IP from somewhere in the range 113.96.0.0 - 113.111.255.255 (CHINANET-GD) makes a request from an android phone.</p><pre><code>GET /topode HTTP/1.1
Upgrade-Insecure-Requests: 1
User-Agent: Mozilla/5.0 (Linux; Android 7.1.2; M6 Note Build/N2G47H; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/77.0.3865.120 MQQBrowser/6.2 TBS/045223 Mobile Safari/537.36 MMWEBID/9551 MicroMessenger/7.0.14.1660(0x27000E37) Process/tools NetType/4G Language/zh_CN ABI/arm64 WeChat/arm64 wechatdevtools
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9
Accept-Encoding: gzip, deflate
Accept-Language: en-US
Host: wintows.com
Via: 1.1 TENCENT64.site (squid/3.5.20)
X-Forwarded-For: &lt;Department of Defence IP&gt;
Cache-Control: max-age=259200
Connection: keep-alive
</code></pre><p>It would appear the some user in China is using <a href="http://www.squid-cache.org/">squid</a> to inject HTTP headers in every request originating in their network, including their mobile phone. Their computer gets a BSOD, so they try to look up the stopcode at windows.com/stopcode on their phone. They mis-type the url and end up at my server where we can see that they’re injecting an HTTP header for <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-Forwarded-For">X-Forwarded-For</a> that attempts to make the request appear as if it originated from an IP belonging to the US Department of Defense.</p><p>When I looked up the source IP on <a href="https://greynoise.io/">GreyNoise</a> it showed that “This IP address has been opportunistically scanning the Internet, and has completed a full TCP connection. Reported activity could not be spoofed. This IP address has been observed by GreyNoise scanning the Internet on the following ports: 443 / TCP”</p><p>Seeing as how my traffic was recieved on 80 / TCP, this seems like it may be something they did not intend to do.</p><h2 id="http-tcp-port-80-windowscomfbclid">HTTP TCP port 80 …</h2></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://remyhax.xyz/posts/bitsquatting-windows/">https://remyhax.xyz/posts/bitsquatting-windows/</a></em></p>]]>
            </description>
            <link>https://remyhax.xyz/posts/bitsquatting-windows/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26338244</guid>
            <pubDate>Thu, 04 Mar 2021 03:24:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It Can Happen to You]]>
            </title>
            <description>
<![CDATA[
Score 1586 | Comments 396 (<a href="https://news.ycombinator.com/item?id=26337046">thread link</a>) | @mooreds
<br/>
March 3, 2021 | https://www.mattkeeter.com/blog/2021-03-01-happen/ | <a href="https://web.archive.org/web/*/https://www.mattkeeter.com/blog/2021-03-01-happen/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<!-- End header -->



<h2>It Can Happen to You</h2>
<p>A few days ago, a <a href="https://nee.lv/2021/02/28/How-I-cut-GTA-Online-loading-times-by-70/">fascinating article</a>
about Grand Theft Auto Online
made the rounds of the tech news ecosystem.</p>
<p>I'd encourage you to read the whole thing, but in short,
GTA Online had <a href="https://accidentallyquadratic.tumblr.com/">accidentally quadratic</a>
performance when parsing a large JSON blob
(due to repeated calls to <code>strlen</code>);
fixing this improved loading time by almost 70%.</p>
<p>This sparked a <a href="https://news.ycombinator.com/item?id=26296339">great deal</a> of discussion:
Was this C's fault?
Perhaps <a href="https://twitter.com/Jonathan_Blow/status/1366452792563359744">"web shit"</a>?
<a href="https://twitter.com/fasterthanlime/status/1366187333507293184">Capitalism and incentives</a>?</p>
<p>Still, folks in the comments section generally agreed:
<em>they</em> wouldn't write anything that silly.</p>
<p>(<em>do you feel the foreshadowing?</em>)</p>
<hr>
<p>One of my side projects is a high-performance 3D viewer named <a href="https://www.mattkeeter.com/projects/erizo">Erizo</a>.</p>
<p><img src="https://www.mattkeeter.com/blog/2021-03-01-happen/porsche.png" alt="Porsche"></p>
<p>Thanks to a lot of careful programming, it will open a 97 MB binary STL
file in about 165 milliseconds flat, on a <em>2013</em> Macbook Pro.
This is <strong>blinding</strong> fast.</p>
<p>In the interest of compatibility, I wrote a small parser for
<a href="https://en.wikipedia.org/wiki/STL_(file_format)#ASCII_STL">ASCII STLs</a> as well.</p>
<p>ASCII STLs are a poorly-specified plain-text format that looks like this:</p>
<pre><code>solid cube_corner
          facet normal 0.0 -1.0 0.0
            outer loop
              vertex 0.0 0.0 0.0
              vertex 1.0 0.0 0.0
              vertex 0.0 0.0 1.0
            endloop
          endfacet
          facet normal 0.0 0.0 -1.0
            outer loop
              vertex 0.0 0.0 0.0
              vertex 0.0 1.0 0.0
              vertex 1.0 0.0 0.0
            endloop
          endfacet
          ...
endsolid
</code></pre>
<p>I wrote an extremely <a href="https://en.wikipedia.org/wiki/Robustness_principle">robust</a>
parser, described in a comment as</p>
<pre><code>/*  The most liberal ASCII STL parser:  Ignore everything except
 *  the word 'vertex', then read three floats after each one. */
</code></pre>
<p>Loading ASCII STLs always seemed a little slow, but I assumed
that's what you get for using an inefficient textual format.</p>
<p>(<em>foreshadowing intensifies</em>)</p>
<hr>
<p>Over the course of a few days, several things happened:</p>
<ul>
<li>I revisited Erizo for the first time in a few years to fix a <a href="https://github.com/mkeeter/erizo/commit/d4683f94a4aa0b674bdde0fa53fb6f92d6e1979c">focus issue on macOS</a></li>
<li>The GTA Online article was published</li>
<li>In a follow-up discussion, I learned that
<a href="https://news.ycombinator.com/item?id=26302744">parsing could be quadratic due to repeated calls to <code>sscanf</code></a></li>
<li>I noticed that ASCII STL loading was <em>really quite</em> slow.</li>
</ul>
<p>Here's the timestamped logs (in seconds), loading a 1.5 MB ASCII STL:</p>
<pre><code>[erizo] (0.000000) main.c:10      | Startup!
[erizo] (0.162895) window.c:91    | Created window
[erizo] (0.162900) window.c:95    | Made context current
[erizo] (0.168715) window.c:103   | Initialized GLEW
[erizo] (0.178329) window.c:91    | Created window
[erizo] (0.178333) window.c:95    | Made context current
[erizo] (1.818734) loader.c:109   | Parsed ASCII STL
[erizo] (1.819471) loader.c:227   | Workers have deduplicated vertices
[erizo] (1.819480) loader.c:237   | Got 5146 vertices (7982 triangles)
[erizo] (1.819530) loader.c:240   | Waiting for buffer...
[erizo] (1.819624) loader.c:326   | Allocated buffer
[erizo] (1.819691) loader.c:253   | Sent buffers to worker threads
[erizo] (1.819883) loader.c:258   | Joined worker threads
[erizo] (1.819887) loader.c:279   | Loader thread done
[erizo] (1.821291) instance.c:32  | Showed window
</code></pre>
<p>From startup to showing the window, it took over 1.8 seconds!</p>
<p>Looking at the ASCII parser with fresh eyes, the cause was glaringly obvious:</p>
<pre><code>    /*  The most liberal ASCII STL parser:  Ignore everything except
     *  the word 'vertex', then read three floats after each one. */
    const char VERTEX_STR[] = "vertex ";
    while (1) {
        data = strstr(data, VERTEX_STR);
        if (!data) {
            break;
        }

        /* Skip to the first character after 'vertex' */
        data += strlen(VERTEX_STR);

        for (unsigned i=0; i &lt; 3; ++i) {
            SKIP_WHILE(isspace);
            float f;
            const int r = sscanf(data, "%f", &amp;f);
            ABORT_IF(r == 0 || r == EOF, "Failed to parse float");
            if (buf_size == buf_count) {
                buf_size *= 2;
                buffer = (float*)realloc(buffer, buf_size * sizeof(float));
            }
            buffer[buf_count++] = f;

            SKIP_WHILE(!isspace);
        }
    }
</code></pre>
<p>You may notice <code>sscanf</code>, happily sitting there, reading a single float off
the front of the data stream and <strong>checking the length of the whole string each time</strong>.</p>
<p>Yes, I had made the exact same mistake as the programmers working on GTA Online:
I had an accidentally quadratic parser!</p>
<p>Replacing the <code>sscanf</code> call with <code>strtof</code> improved startup by nearly a factor of
10: from 1.8 seconds to 199 milliseconds.</p>
<pre><code>[erizo] (0.000000) main.c:10      | Startup!
[erizo] (0.178082) window.c:91    | Created window
[erizo] (0.178086) window.c:95    | Made context current
[erizo] (0.184226) window.c:103   | Initialized GLEW
[erizo] (0.194469) window.c:91    | Created window
[erizo] (0.194472) window.c:95    | Made context current
[erizo] (0.196126) loader.c:109   | Parsed ASCII STL
[erizo] (0.196866) loader.c:227   | Workers have deduplicated vertices
[erizo] (0.196871) loader.c:237   | Got 5146 vertices (7982 triangles)
[erizo] (0.196921) loader.c:240   | Waiting for buffer...
[erizo] (0.197013) loader.c:326   | Allocated buffer
[erizo] (0.197082) loader.c:253   | Sent buffers to worker threads
[erizo] (0.197303) loader.c:258   | Joined worker threads
[erizo] (0.197306) loader.c:279   | Loader thread done
[erizo] (0.199328) instance.c:32  | Showed window
</code></pre>
<p>This is back down in the noise of
"how long does the OS take to give us an OpenGL context",
which is a great place for a high-performance tool.</p>
<hr>
<p>As someone that has been programming for many years,
this was a perfectly-timed reminder that there are <em>always</em> pitfalls out there.
The <a href="https://en.cppreference.com/mwiki/index.php?title=cpp/io/c/fscanf&amp;oldid=125683">documentation for <code>sscanf</code></a>
does not include a time complexity,
so this is particularly tricky <a href="https://en.wiktionary.org/wiki/footgun">footgun</a>,
and I'm sure it's not the only one lurking in the darkness.</p>
<p>You may not get such a perfectly-timed reminder, but it's worth remembering –
next time you read a fascinating story about bad programming –
that it <em>can</em> happen to you!</p>
<p>(Obviously, the moral of the story is to not use <code>sscanf</code> to repeatedly
parse single tokens off the front of a string; I'm sure you'll do <em>fine</em>
if you can just avoid <strong>that</strong>)</p>
<hr>
<h2>Follow-up and related discussions</h2>
<ul>
<li><a href="https://news.ycombinator.com/item?id=26337046">Hacker News</a> (lots of discussion)</li>
<li><a href="https://lobste.rs/s/0obriy/it_can_happen_you">Lobste.rs</a>, including an <a href="https://lobste.rs/s/0obriy/it_can_happen_you#c_giuxfq">interesting survey</a> across different C libraries</li>
<li><a href="https://reviews.freebsd.org/D29007">Relevant FreeBSD patch</a></li>
<li><a href="https://sourceware.org/bugzilla/show_bug.cgi?id=17577"><code>glibc</code> bug tracker</a></li>
<li>The <a href="https://en.cppreference.com/w/cpp/io/c/fscanf">cppreference.com page for <code>sscanf</code></a> now mentions this pitfall</li>
</ul>

<!-- Begin footer -->
</div></div>]]>
            </description>
            <link>https://www.mattkeeter.com/blog/2021-03-01-happen/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26337046</guid>
            <pubDate>Thu, 04 Mar 2021 00:37:45 GMT</pubDate>
        </item>
    </channel>
</rss>
