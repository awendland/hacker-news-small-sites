<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Tue, 29 Dec 2020 12:51:04 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Tue, 29 Dec 2020 12:51:04 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[API pagination design]]>
            </title>
            <description>
<![CDATA[
Score 208 | Comments 61 (<a href="https://news.ycombinator.com/item?id=25547716">thread link</a>) | @fagnerbrack
<br/>
December 26, 2020 | https://solovyov.net/blog/2020/api-pagination-design/ | <a href="https://web.archive.org/web/*/https://solovyov.net/blog/2020/api-pagination-design/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><p>Returning all results for a given query could be a challenge for an API, especially if there are thousands of results. It puts a load on a server, on a client, on a network, and often is unnecessary. Thus people invented pagination.</p>
<p>The usual way to paginate is an offset or a page number. So you make a request like that:</p>
<pre><code>GET /api/products?page=10
{"items": [...100 products]}
</code></pre>
<p>and to continue you make a request like that:</p>
<pre><code>GET /api/products?page=11
{"items": [...another 100 products]}
</code></pre>
<p>In case of a simple offset it’ll look like <code>?offset=1000</code> and <code>?offset=1100</code> — it’s the same old soup, just reheated. It’ll either go straight into SQL query like <code>OFFSET 1000 LIMIT 100</code> or will be multiplied by page size (that <code>LIMIT</code> value). In any case, it’s a suboptimal solution, since every database has to skip that 1000 rows. And to skip them it needs to identify them. It does not matter if it’s PostgreSQL, or ElasticSearch, or MongoDB, it’ll have to order them, count them, and throw them away.</p>
<p>This is a kind of work which no one needs. But it repeats over and over again since it’s <em>easy</em> to implement — you directly map your API onto your query to a database.</p>
<p>What do you do then? We could look at what databases do! They have this concept, called <a href="https://en.wikipedia.org/wiki/Cursor_(databases)">cursor</a> — it’s a pointer to a row. So you can say to a database “return me 100 rows after <strong>that</strong> one”. And it’s much easier for a database to do since there is a good chance that you’ll identify the row by a field with an index. And suddenly you don’t need to fetch and skip those rows, you’ll go directly past them.</p>
<p>An example:</p>
<pre><code>GET /api/products
{"items": [...100 products],
 "cursor": "qWe"}
</code></pre>
<p>API returns an (opaque) string, which you can use then to retrieve the next page:</p>
<pre><code>GET /api/products?cursor=qWe
{"items": [...100 products],
 "cursor": "qWr"}
</code></pre>
<p>Implementation-wise there are many options. Generally, you have some ordering criteria, for example, product id. In this case, you’ll encode your product id with some reversible algorithm (let’s say <a href="https://hashids.org/">hashids</a>). And on receiving a request with the cursor you decode it and generate a query like <code>WHERE id &gt; :cursor LIMIT 100</code>.</p>
<p>Just a little performance comparison, look at how offsets work:</p>
<pre><code>=# explain analyze select id from product offset 10000 limit 100;
                                                           QUERY PLAN                                                            
---------------------------------------------------------------------------------------------------------------------------------
 Limit  (cost=1114.26..1125.40 rows=100 width=4) (actual time=39.431..39.561 rows=100 loops=1)
   -&gt;  Seq Scan on product  (cost=0.00..1274406.22 rows=11437243 width=4) (actual time=0.015..39.123 rows=10100 loops=1)
 Planning Time: 0.117 ms
 Execution Time: 39.589 ms
</code></pre>
<p>And how where works:</p>
<pre><code>=# explain analyze select id from product where id &gt; 10000 limit 100;
                                                          QUERY PLAN                                                          
------------------------------------------------------------------------------------------------------------------------------
 Limit  (cost=0.00..11.40 rows=100 width=4) (actual time=0.016..0.067 rows=100 loops=1)
   -&gt;  Seq Scan on product  (cost=0.00..1302999.32 rows=11429082 width=4) (actual time=0.015..0.052 rows=100 loops=1)
         Filter: (id &gt; 10000)
 Planning Time: 0.164 ms
 Execution Time: 0.094 ms
</code></pre>
<p>That is a difference of several orders of magnitude! Of course, the actual numbers depend on a size of a table, on your filters and on a store implementation. There <a href="https://use-the-index-luke.com/no-offset">a great article</a> with more technical information - there are slides embedded, see slide 42 for performance comparison.</p>
<p>Of course, nobody orders products by an id — you usually order them by some relevancy (and then by id as a <a href="https://stackoverflow.com/a/17330992/46854">tie breaker</a>). In the real world, you’ll have to look at your data to determine what to do. Orders can be ordered by id (as it’s monotonically increasing). Wishlist items can be ordered like that as well — by wishlisting time. In our case products come from ElasticSearch, which naturally supports this cursor stuff.</p>
<p>One deficiency you can see is that it’s impossible to generate a “previous page” link with a stateless API. So in case of a user-facing pagination, if it’s important to have prev/next and “go directly to page 10” buttons there is no way around this offset/limit stuff. But in other cases using cursor-based pagination can greatly improve performance, especially on really big tables with really deep pagination.</p>
</div></div>]]>
            </description>
            <link>https://solovyov.net/blog/2020/api-pagination-design/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25547716</guid>
            <pubDate>Sun, 27 Dec 2020 00:38:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kit FUI – User interfaces found in films]]>
            </title>
            <description>
<![CDATA[
Score 96 | Comments 17 (<a href="https://news.ycombinator.com/item?id=25547352">thread link</a>) | @ChrisArchitect
<br/>
December 26, 2020 | https://www.saji8k.com/kit-fui/ | <a href="https://web.archive.org/web/*/https://www.saji8k.com/kit-fui/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<div>
				
				<p>User interfaces from film, television, video games and the designers that created them.</p>
				<p>Keep track of updates to Kit FUI on my <a href="https://www.saji8k.com/blog/">blog</a> or by following me on <a href="https://twitter.com/saji8k">Twitter</a> or <a href="https://www.facebook.com/saji8k">Facebook</a>.</p>
				<p>If you have suggestions for the site or would like to submit your work, send me a <a href="https://twitter.com/saji8k">tweet</a>.</p>
			</div>
		</div><div>
			<div>
				<h3>What is FUI?</h3>
				<p>Fantasy User Interfaces, Fictional User Interfaces, Fake User Interfaces, Futuristic User Interfaces, Film User Interfaces, Future User Interfaces. Regardless of what the F stands for, they all represent the same thing, the user interfaces (UIs) and heads up displays (HUDs) found in many popular movies and television shows.</p>
				<p>Most FUIs are not actual computer programs but simply animations being played back at the correct time or added in post production. These graphics and animations are designed in applications like Adobe Illustrator, Adobe After Effects and Maxon Cinema 4D.</p>
			</div>
		</div></div>]]>
            </description>
            <link>https://www.saji8k.com/kit-fui/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25547352</guid>
            <pubDate>Sat, 26 Dec 2020 23:34:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Run More Stuff in Docker]]>
            </title>
            <description>
<![CDATA[
Score 139 | Comments 178 (<a href="https://news.ycombinator.com/item?id=25547205">thread link</a>) | @psxuaw
<br/>
December 26, 2020 | https://jonathan.bergknoff.com/journal/run-more-stuff-in-docker/ | <a href="https://web.archive.org/web/*/https://jonathan.bergknoff.com/journal/run-more-stuff-in-docker/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>
	
	<h6>
		<span>2020-03-10</span>

		
		<span>
			
			<a href="https://jonathan.bergknoff.com/tags/tech/">tech</a>
			
			<a href="https://jonathan.bergknoff.com/tags/programming/">programming</a>
			
		</span>
		
	</h6>
	<hr>
	<p>In 2020, <strong>Docker is the best medium for distributing and running most developer-facing software</strong>. It’s widely accepted that Docker is great for building and deploying the artifacts for your enterprise web app, but this is less well known when it comes to things like developer tools. However, running tools in containers has many benefits over installing and running them in the conventional way, and we should all start doing it more.</p>
<h2 id="why">Why?</h2>
<p>I install very few things on either my personal or work computer. I don’t have <code>terraform</code>, <code>aws</code>, <code>node</code>, or <code>pip</code> installed, but I use them all the time. I have a Docker image for each, and I run them in containers with minimal privileges. I’m definitely <a href="https://github.com/jessfraz/dockerfiles">not the only one</a>, but it’s not as popular as it should be. None of these tools actually need full access to my computer to do their work, but that is normally how they’re run.</p>
<p>Here are some benefits of running these tools in Docker.</p>
<h4 id="cross-platform">Cross-platform</h4>
<p>At this point in time, Docker is ubiquitous and you get cross-platform support for free, thanks to Docker Inc’s investments in that area (Docker for Mac &amp; Windows). This is useful both for people developing/distributing tools, and for people working on a team that needs to share tooling. You have one Docker image and it will run pretty much everywhere. OS package managers can be great, but they’re very much not cross-platform. Things like <code>pip install</code> will sometimes work cross-platform, but have other serious drawbacks.</p>
<p>While every platform has its own sandboxing mechanisms, running with Docker lets you specify runtime context and enforce a sandbox in a cross-platform way, which is useful when you expect anybody else to run the same command as you.</p>
<h4 id="sandboxed">Sandboxed</h4>
<p>When you <code>docker run</code>, you have to be explicit about privileges. A container is mostly sandboxed and unprivileged by default. It doesn’t have access to ambient environment variables. It doesn’t have access to the host system’s disk. A tool like <code>jq</code> just needs to read stdin and print to stdout. It doesn’t need access to my shell’s environment variables (or, if it does, I explicitly pass those through to the container). <code>yarn</code> should be fine operating on just the working directory, and maybe a cache directory. I don’t want it to have access to my ~/.aws directory (for <a href="https://securityboulevard.com/2020/01/malicious-npm-package-exfiltrating-data-from-unix-systems/">obvious reasons</a>).</p>
<p>Some tools do need access to things. I want my <code>aws</code> CLI to be able to read ~/.aws, so I grant that explicitly. This makes running the tool more verbose but less magical.</p>
<h4 id="simple-uniform-interface">Simple, uniform interface</h4>
<p>Running a program in a container is a lot like running it normally, but the user doesn’t need to jump through hoops to configure the system, build and install. The developer of the image jumps through those hoops and produces a runnable artifact with a simple interface. That interface is the same whether the tool was written in Python or Rust or C or anything else.</p>
<p>Downloading a pre-compiled binary is almost like this, except with worse odds. Maybe there’s a build for your architecture. If it was statically linked, you’re golden. Otherwise, use <code>ldd</code> to reverse engineer the fact that you need to install <code>libjpeg</code>.</p>
<p>A Docker image “just works”. It comes bundled with what it needs to run.</p>
<p>If you think about it, it’s pretty strange to execute <a href="https://github.com/aws/aws-cli/tree/0b3d9a4260fdda5c6a8b736439e0776bc2252f41#installation"><code>pip install awscli</code></a>. It’s immaterial to an end user that the tool is written in Python, and requiring him or her to set up and use Python tooling doesn’t make sense. I don’t mean to pick on <code>pip</code> or <code>awscli</code> in particular, but this is a poor mechanism for distributing non-library software. It leaves <a href="https://github.com/aws/aws-cli/issues?q=is%3Aissue+pip">far too much to chance</a>. It’s a clumsy and leaky interface for tool distribution. So is <code>npm install</code>. So is telling somebody to install your tool by installing golang, and then running <code>go build</code>. No, thanks. If I’m hacking on the project, then by all means. But don’t foist that on end users.</p>
<h4 id="facilitates-version-pinning">Facilitates version pinning</h4>
<p>When collaborating, it’s important that people run the same versions of software to get consistent results. Version pinning is essential to that. Pinning dependency manifests is good, but it’s not enough: it only covers the one situation of installing things with a language package manager. It may not cover using the same linter version, or the same version of <code>node</code>, <code>aws</code>, <code>ansible</code>, <code>terraform</code>, or any libraries installed at the OS level. Invoking <code>docker run node:13.10.1</code>, instead of whatever the user happens to have installed as <code>node</code>, solves this problem in general. Having the ability to specify the versions at the point of use, rather than out-of-band as part of some other installation process, is also convenient and tidy.</p>
<p>It’s easy to run different versions of a tool side by side with Docker. Docker solves this more generally than things like virtualenv for Python, rvm for Ruby, etc. You specify what version of the tool to use when you’re invoking it, and it pins a whole lot of context more than just the tool’s version, which is always preferable for reproducibility.</p>
<p>In one recent situation at work, we had a test case start failing when we upgraded our runtime from Python 3.6.5 to Python 3.6.8. Having the ability to easily run the tests with any version of Python made it easy to bisect and identify a change in 3.6.7 as the cause. This could have been debugged without Docker, but it was particularly natural and easy with Docker.</p>
<h4 id="reproducible">Reproducible</h4>
<p>Invoking a tool with <code>docker run</code> should specify everything needed to reproducibly run it somewhere else. It’s running some specific version of the tool? Okay. It needs my AWS credentials? Okay. It needs some specific combination of environment variables set? Okay.</p>
<p>I cringe when I see a Makefile or build instructions saying to run <code>yarn</code> or <code>terraform</code> or <code>go</code>. What version? What’s being assumed about my environment? Maybe this worked on your <a href="https://martinfowler.com/bliki/SnowflakeServer.html">unique snowflake of a machine</a> 18 months ago, but good luck with it now. (My laptop is a unique snowflake too. Everyone’s is, until we all figure out how to use NixOS.)</p>
<p>Running tools in Docker, there are few expectations of the runtime environment beyond having Docker installed. All the other requirements should be made explicit in the <code>docker run</code> command. The command that you’re running locally will work the same on your colleague’s machine, and in any CI with minimal configuration (or none). This is absolutely critical, especially when working on a team. This is a far more robust approach than expecting (requiring) anybody’s system, or a CI slave, to be set up “just so”.</p>
<h4 id="minimizes-global-state">Minimizes global state</h4>
<p>I have very few things installed on my host system beyond the base OS. There’s less to remember when setting up a new machine, fewer things to go wrong during upgrades, and fewer opportunities for conflicts over shared libraries.</p>
<h2 id="examples">Examples</h2>
<h4 id="one-offs">One-offs</h4>
<p>I have bash aliases for a bunch of tools that I run all the time. These are just for my own convenience. For anything shared with other people, I’d use a project’s Makefile (see below).</p>
<ul>
<li>
<p><strong>Some basics</strong></p>
<pre><code>alias aws='docker run --rm -v ~/.aws:/.aws -v "$(pwd)":"$(pwd)" -w "$(pwd)" -u 1000:1000 -e AWS_PROFILE mikesir87/aws-cli:1.18.11 aws'
alias jq='docker run -i --rm jess/jq jq'
alias terraform='docker run -it --rm -v ~/.aws:/.aws -v "$(pwd)":"$(pwd)" -w "$(pwd)" -u 1000:1000 hashicorp/terraform:0.12.23'
</code></pre><p>With these aliases, I can <code>AWS_PROFILE=... aws sts get-caller-identity | jq -r .Arn</code> as if they were “really” installed.</p>
</li>
<li>
<p><strong>zoom</strong></p>
<p>Here’s zoom (video conferencing):</p>
<pre><code>alias zoom='xhost +local:docker \
    &amp;&amp; docker run -it --rm -v /tmp/.X11-unix:/tmp/.X11-unix -e DISPLAY \
    --device /dev/video0 --device /dev/snd:/dev/snd --device /dev/dri -v /dev/shm:/dev/shm \
    -v ~/.config/zoom/.zoom:/root/.zoom -v ~/.config/zoom/.config/zoomus.conf:/root/.config/zoomus.conf \
    jess/zoom-us'
</code></pre><p>Notice that <a href="https://medium.com/bugbountywriteup/zoom-zero-day-4-million-webcams-maybe-an-rce-just-get-them-to-visit-your-website-ac75c83f4ef5">port 19421</a> remains stubbornly closed unless we explicitly let the container claim it on the host.</p>
</li>
<li>
<p><strong>Snes9x</strong></p>
<p>I do this with other stuff, too. Here’s Snes9x (can you imagine <a href="http://www.snes9x.com/phpbb3/viewtopic.php?t=23603">installing it</a>?):</p>
<pre><code>alias snes9x='docker run -it --rm -u 1000:1000 -v /tmp/.X11-unix:/tmp/.X11-unix -e DISPLAY \
    -v /run/dbus:/run/dbus -v /dev/shm:/dev/shm \
    --device /dev/snd --device /dev/dri --device /dev/input/js0 \
    -e PULSE_SERVER=unix:$XDG_RUNTIME_DIR/pulse/native -v $XDG_RUNTIME_DIR/pulse/native:$XDG_RUNTIME_DIR/pulse/native \
    --group-add $(getent group audio | cut -d: -f3) \
    -v ~/.config/snes9x:/.snes9x/ -v ~/Games/SNES:/SNES -v ~/.local/share:/.local/share \
    danniel/snes9x'
</code></pre></li>
</ul>
<h4 id="projects">Projects</h4>
<p>For things that are project-specific, or in a team setting, all useful commands should be codified in something like a Makefile. This wraps the complexity and verbosity of the <code>docker run</code> incantations, makes it possible to share them easily, and makes them passably ergonomic.</p>
<ul>
<li>
<p><strong>hugo</strong></p>
<p>When I’m writing an article for this site, I run <code>make hugo-watch</code> and load http://localhost:1313 in a web browser:</p>
<pre><code>hugo = docker run --rm -u $$(id -u):$$(id -g) -v "$$(pwd)":/src -v "$$(pwd)"/output:/target $(2) klakegg/hugo:0.54.0-ext-alpine $(1)

hugo-watch:
    mkdir -p output
    $(call hugo, server, -it -p 1313:1313)
</code></pre></li>
<li>
<p><strong>prettier</strong></p>
<p>To format a JavaScript project, we might have the make targets</p>
<pre><code>prettier = docker run -i --rm -v "$$(pwd)":"$$(pwd)" -w "$$(pwd)" elnebuloso/prettier:1.19.1 $(1) "src/**/*.js"

format:
    $(call prettier)

format-check:
    $(call prettier, --check)
</code></pre><p>We would run <code>make format</code> to format the code and <code>make format-check</code> to check the style. It runs on my Linux box, it runs on my colleague’s Mac, and it runs in any Docker-equipped CI. None of those machines need to have <code>node</code>, <code>npm</code>, or <code>prettier</code> installed. We completely trivialize the issues of versioning and of synchronizing our environments: the version is specified once, here in the Makefile, and it’s obeyed everywhere.</p>
<p>In a language like Python, where libraries are forced to fight to the death for control of transitive dependency versions, lifting a tool like <code>black</code> or <code>flake8</code> out of the project’s requirements.txt, and into a self-contained Docker image, can be a big …</p></li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jonathan.bergknoff.com/journal/run-more-stuff-in-docker/">https://jonathan.bergknoff.com/journal/run-more-stuff-in-docker/</a></em></p>]]>
            </description>
            <link>https://jonathan.bergknoff.com/journal/run-more-stuff-in-docker/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25547205</guid>
            <pubDate>Sat, 26 Dec 2020 23:10:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lost nuclear device atop of Nanda Devi]]>
            </title>
            <description>
<![CDATA[
Score 164 | Comments 75 (<a href="https://news.ycombinator.com/item?id=25547123">thread link</a>) | @hudvin
<br/>
December 26, 2020 | https://www.livehistoryindia.com/cover-story/2020/09/18/nanda-devi-nuclear-device | <a href="https://web.archive.org/web/*/https://www.livehistoryindia.com/cover-story/2020/09/18/nanda-devi-nuclear-device">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <section>
                        <div id="container">
                          
  <div>
    


<div id="story-f889b712-c891-4d7d-b740-a08c112f512d" data-public-preview="">
  <article data-story-url="" data-story-content-id="f889b712-c891-4d7d-b740-a08c112f512d" data-story-version-id="f2394ab5-e6e4-492d-a5d0-8de23eb757bc" data-story-headline="Nanda Deviâ€™s Nuclear Secret and a Botched CIA Operation" data-loader="story">
    
          <div>
    <figure>
        <img src="https://images.assettype.com/indynetwork%2F2020-09%2Fde00724b-9ea2-4f38-82dc-ca78b3e6dee0%2FImage_9.jpg?w=1500">
    </figure>
</div>
<div>
  <div>
    
    <div itemprop="articleBody" data-story-content-id="f889b712-c891-4d7d-b740-a08c112f512d" data-story-version-id="f2394ab5-e6e4-492d-a5d0-8de23eb757bc">
      
                        
              <div data-card-content-id="efdfb573-ba3e-4852-b9ee-0486b7498411" data-card-version-id="49dda451-df77-4ea6-9f9b-3d28a0f6cf13">
        
      <div id="inf-card-b26a2f55-462c-4ea2-bbd2-fa63429051da" data-story-element-id="b26a2f55-462c-4ea2-bbd2-fa63429051da" data-story-element-type="text">
          <div>
    <p>The past few months have seen a rise in volatility along the Indo-Tibetan border, with the forces of both India and China coming to blows. While these events are extraordinary in present times, the border has witnessed far more heated exchanges, most notably during the 1962 <a href="https://www.livehistoryindia.com/in-the-news/2020/06/21/across-the-karakorams">Indo-China</a> War.</p><p>The unforgiving terrain that marks the frontier creates an additional dimension to the already complex nature of these clashes, whether in regard to more conventional manoeuvres, or other irregular military activity which is far more frequent. This is the story of the latter kind of action, that of daring espionage against Communist China, played for the highest stakes with the greatest risks.</p>
  </div>
</div>



      <div id="inf-card-33d483b8-2c77-4958-ae3b-52863623292b" data-story-element-id="33d483b8-2c77-4958-ae3b-52863623292b" data-story-element-type="text">
          <div>
    <p>Cold, harsh, inviolate. Straddling between the <a href="https://www.livehistoryindia.com/snapshort-histories/2017/06/21/kumaon-echoes-of-the-past">Kumaon</a> and Garhwal districts of Uttarakhand, deep in the Himalayas, stands Nanda Devi. The second-highest mountain in India, towering at an astonishing 25,646 feet, it is named after the patron goddess of Uttarakhandâ€” the mountain being her temporal manifestation.</p><p>Its unique topographical environment makes it one of the most inaccessible places on Earth. Surrounded on three sides by massive mountain rampartsâ€”its natural fortifications measuring at no point below 17,000 feetâ€” only the narrow and dangerously steep Rishi Ganga river gorge allows access to it. The mountain in itself is a citadel of rock and ice, with steep, angled faces and avalanche-prone ridges guarding its summit. Its immense proportions make it far tougher to climb than Everest. It is at once a supremely magnificent and terrifyingly intimidating mountain.</p>
  </div>
</div>



      <div id="inf-card-67773953-dcf2-46a7-97f1-a20310e389b8" data-story-element-id="67773953-dcf2-46a7-97f1-a20310e389b8" data-story-element-type="image">
  <div>
  <figure>
    <img alt="Map of the Nanda Devi Sanctuary, the thick hachures marking the semi-circular natural fortifications in the form of mountains that surround most of the Nanda Devi" src="https://images.assettype.com/indynetwork%2F2020-09%2F65d1a1da-2c67-4059-aeb0-c5437f7f191d%2FImage_3.jpg?w=1170">
  </figure>
              
  
</div></div>



      <div id="inf-card-ec4beaa1-a291-4fc9-9b8c-2d33f3d21e38" data-story-element-id="ec4beaa1-a291-4fc9-9b8c-2d33f3d21e38" data-story-element-type="text">
          <div>
    <p>For much of the 19th and early 20th century, before it was finally summited in 1936, it was considered to be the third pole â€“ a point of virtual inaccessibility. However, this awe-inspiring creation of nature shelters a device, abhorrent to nature, manufactured by man. Somewhere high on the harrowing slopes of Nanda Devi, buried deep in snow, lies a lost nuclear listening device slowly depleting its plutonium cores. Containing 5kg of plutonium â€“ 1 kg less than the nuclear bomb dropped on Nagasaki â€“ with a predicted lifespan of 900 years, this nuclear trespasser has been forfeited to the mountain forever.</p><p>This is the story behind one of the most audacious acts of espionage in the 20th century.</p>
  </div>
</div>



  </div>

              <div data-card-content-id="5350a04d-7e5b-48a5-9ccc-0c0b06771394" data-card-version-id="b82a93e5-a227-4175-b91c-b1fe616b5c7c">
        
      <div id="inf-card-d8876be2-71a7-431c-833b-2d0c39d14b6e" data-story-element-id="d8876be2-71a7-431c-833b-2d0c39d14b6e" data-story-element-type="text">
          <div>
    <p><strong>Cold War In High Places</strong></p><p>The year was 1965, and the Cold War was reaching its apogee, with America stretching its geopolitical reach to all corners of the world in order to counter the communist influence. Closer to home, the War of â€™62 had left India intensely wary of its neighbour, China. To add fuel to simmering embers, China carried out its first nuclear test in 1964 in Xinjiang, a province that borders the northern tip of India. In this atmosphere of intense mutual suspicion and paranoia, the Pentagon began concocting a plan that would help both India and America keep a closer eye on China, especially with regard to its nuclear programme.</p><p>With satellites that could gather useful photographic intelligence still a few years away, Americaâ€™s Central Intelligence Agency (CIA) along with the Indian Intelligence Bureau (IB) planned on placing a powerful listening device at a point of extreme prominence along the Indo-Tibetan border. The site where the device would be placed was key as it would need to have uninterrupted access in order to intercept Chinese radio signals. This meant it would have to be positioned on a mountain that was high as well as close to the Tibetan plateau. With an unparalleled height advantage and an unobstructed view of China from its summit, there was no better choice than Nanda Devi.</p>
  </div>
</div>



      <div id="inf-card-21631012-ab2e-4940-a233-267421b9382d" data-story-element-id="21631012-ab2e-4940-a233-267421b9382d" data-story-element-type="text">
        <div>
     <hr>
  <div>
    <blockquote>To ensure the longevity and endurance of the device, which was supposed to work at an altitude of nearly 26,000 feet, it was decided that it would be nuclear-powered. </blockquote>
  </div>
  <hr>
</div>
  </div>



      <div id="inf-card-ac913b24-39b9-4cc4-9553-78b1b163d63d" data-story-element-id="ac913b24-39b9-4cc4-9553-78b1b163d63d" data-story-element-type="text">
          <div>
    <p>A System for Nuclear Auxiliary Power (SNAP) generator was designed so that it would power the telemetry functions of the device, a power unit similar to the ones being used in space at the time.</p><p>It was within the SNAP that seven plutonium fuel rods would be stored, made from a compound of Pu-238 and Pu-239. Once activated, the SNAP would constantly be converting radioactive heat energy created by the rods into electricity, which would power the multiple-sensor device as well as its six-foot-long antenna.</p><p>With the technical aspect settled, the question of who would carry and set up all this equipment remained. Only two expeditions had summited the mountain up until then, and more than a few climbers had died. There was no doubt that only the very best mountaineers could be trusted to carry a nuclear payload up one of the most difficult mountains in the world.</p>
  </div>
</div>



  </div>

              <div data-card-content-id="5aeaa671-5f93-450a-971d-b5690e92888f" data-card-version-id="58f0cfc2-71cc-46c3-a836-d90e638e4071">
        
      <div id="inf-card-a3cc2b9a-78bd-4006-bf8a-64632fc034d2" data-story-element-id="a3cc2b9a-78bd-4006-bf8a-64632fc034d2" data-story-element-type="text">
          <p><strong>League of Extraordinary Climbers</strong></p>
</div>



      <div id="inf-card-44cd66b4-c4c0-4956-b7f2-a5354b09a54c" data-story-element-id="44cd66b4-c4c0-4956-b7f2-a5354b09a54c" data-story-element-type="image">
  <div>
  <figure>
    <img alt="Captain MS Kohli AVSM, leader of the covert climbing expeditions, now at the ripe old age of 88. " src="https://images.assettype.com/indynetwork%2F2020-09%2Faea6959e-2270-436f-bbd2-426467f4f81b%2FImage_8.jpg?w=1170">
  </figure>
              
  
</div></div>



      <div id="inf-card-9a85c853-4586-48c3-95f7-70072afd02f2" data-story-element-id="9a85c853-4586-48c3-95f7-70072afd02f2" data-story-element-type="text">
          <div>
    <p>A group of 14 American and four Indian mountaineers was assembled. In totality, they represented the cream of a mountaineering generation. Among the Americans, some of the more famous climbers were Dr Robert Schaller, Tom Frost and Jim McCarthy. The Indian contingent consisted of Captain M S Kohli, Sonam Wangyal, H C S Rawat and G S Bhangu. All four had been members of the successful 1965 Indian Everest Expedition, which had put a record nine climbers on the summit. They were in fact enlisted for this covert expedition just a few days after returning from Everest. Together, the entire group was no less than a mountaineering dream team.</p><p>After having sworn their respective oaths of secrecy, the climbing team was flown to Mount McKinley in Alaska, the highest mountain in North America, to prepare for the arduous expedition ahead. While all of them were without doubt among the most experienced climbers at the time, they were rather new to the more idiosyncratic aspect of the expedition â€“ that of dealing with nuclear material.</p><p>American climber Jim McCarthy was appointed as the designated member of the team who would handle the plutonium rods. Through the summer of 1965, officials from Americaâ€™s Atomic Energy Commission trained McCarthy to load and unload the device without disturbing its deadly occupant. Other team members were briefed on the dangers of their special load as well, and ways to ensure minimum exposure to the deadly radioactive isotopes.</p><p>All climbers were going to be paid $1,000 per month, a hefty amount in the 1960s. While there would be personal gratification from having been of service to their respective nations, they were on no account to tell anyone about the nature of their expedition. The cover for the entire team was that they were a joint Indo-American mountaineering team conducting research for high-altitude flight for the American Air Force. Before departing for India, the covert operation was finally given its official codename: Operation Hat.</p>
  </div>
</div>



      <div id="inf-card-368b8863-5e90-4a6b-8a7e-47a26beda04f" data-story-element-id="368b8863-5e90-4a6b-8a7e-47a26beda04f" data-story-element-type="image">
  <div>
  <figure>
    <img alt="A Nanda Devi Temple at Munsiyari. This particular temple, and itâ€™s idol inside, is among the oldest of Uttarakhand" src="https://images.assettype.com/indynetwork%2F2020-09%2F49dfca8c-132b-43f5-b063-81b86f25e855%2FImage_5.jpg?w=1170">
  </figure>
              
  
</div></div>



      <div id="inf-card-5a316079-59a0-4a73-9dd2-5edab677f0f6" data-story-element-id="5a316079-59a0-4a73-9dd2-5edab677f0f6" data-story-element-type="text">
          <div>
    <p><strong>Into the Sanctuary of the Goddess</strong></p><p>In an effort to attract minimal attention, most of the mountaineers were flown into base camp by helicopter in September 1965. However, the climbing equipment, rations, and of course the listening device itself â€” stored inside a solid lead casket â€” were transported in the time-honoured fashion, carried by nearly 150 <em>dotial</em> porters through the Rishi Ganga gorge. The special load did not go unnoticed among the porters, and apart from its unusual weight, many of them alleged to have felt heat emanating from the casket. Mounted on poles, some climbers later noted its uncanny resemblance to the Biblical Ark of the Covenant, in the manner it was transported as well as the supreme power it possessed.</p><p>After having established themselves at the base of the mountain, the mountaineers methodically began making their way up Nanda Devi. Establishing a series of camps along the climbing route, the team was finally positioned to make an attempt on the summit in the middle of October. It was then that catastrophe struck.</p><p>A violent storm hit the mountain and made it impossible to continue. The summit team, along with the device, was encamped just 2,000 feet below their objective. The extreme conditions, however, greatly endangered their position. Keeping in mind the extreme volatility of such storms, Captain Kohli â€” the leader of the climbing team â€” called for an immediate retreat.</p>
  </div>
</div>



  </div>

              <div data-card-content-id="65e7e1e4-a3b0-4ec4-9aaa-c4696502703a" data-card-version-id="344b6037-e7b7-4181-b199-8bea1745da05">
        
      <div id="inf-card-6d7e221c-28e2-4bd3-ac8f-475267b102e9" data-story-element-id="6d7e221c-28e2-4bd3-ac8f-475267b102e9" data-story-element-type="text">
          <div>
    <p>Carrying the 56 kg listening device in deteriorating weather conditions at 23,000 feet was going to be a Herculean task. Prioritising the need for a quick descent to minimise the risk to the lives of his fellow climbers, Kohli decided to ditch the equipment in the high camp. He reasoned that another expedition could always be mounted when weather conditions improved, in order to retrieve the device. On the other hand, the life of a fellow climber was irreplaceable.</p><p>Thus, with all the climbers having safely descended, the expedition came to an end. Being late in the year, the weather window to climb Nanda Devi was now closed. Any new expedition would have to bide their time till the following year. The nuclear device too, abandoned on a high precipice of the mountain, would have to wait.</p><p><strong>Plan B</strong></p><p>With the arrival of spring in 1966, a second expedition was launched to locate the equipment, and most importantly the nuclear device, that had been left the previous autumn. The composition of the climbing team was more or less the same, and soon they were scouring the slopes of Nanda Devi, trying to find their highly valuable and potentially dangerous belongings. But it was all …</p></div></div></div></div></div></div></article></div></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.livehistoryindia.com/cover-story/2020/09/18/nanda-devi-nuclear-device">https://www.livehistoryindia.com/cover-story/2020/09/18/nanda-devi-nuclear-device</a></em></p>]]>
            </description>
            <link>https://www.livehistoryindia.com/cover-story/2020/09/18/nanda-devi-nuclear-device</link>
            <guid isPermaLink="false">hacker-news-small-sites-25547123</guid>
            <pubDate>Sat, 26 Dec 2020 22:58:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Dunning-Kruger Effect Is Probably Not Real]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 61 (<a href="https://news.ycombinator.com/item?id=25546787">thread link</a>) | @ingve
<br/>
December 26, 2020 | https://www.mcgill.ca/oss/article/critical-thinking/dunning-kruger-effect-probably-not-real | <a href="https://web.archive.org/web/*/https://www.mcgill.ca/oss/article/critical-thinking/dunning-kruger-effect-probably-not-real">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>I want the Dunning-Kruger effect to be real. First described in<a href="https://doi.apa.org/doiLanding?doi=10.1037%2F0022-3514.77.6.1121"> a seminal 1999 paper</a> by David Dunning and Justin Kruger, this effect has been the darling of journalists who want to explain why dumb people don’t know they’re dumb. There’s even<a href="https://youtu.be/BdnH19KsVVc"> video of a fantastic pastiche</a> of Turandot’s famous aria, <i>Nessun dorma,</i> explaining the Dunning-Kruger effect. “They don’t know,” the opera singer belts out at the climax, “that they don’t know.”</p>

<p>I was planning on writing a very short article about the Dunning-Kruger effect and it felt like shooting fish in a barrel. Here’s the effect, how it was discovered, what it means. End of story.</p>

<p>But as I double-checked the academic literature, doubt started to creep in. While trying to understand the criticism that had been leveled at the original study, I fell down a rabbit hole, spoke to a few statistics-minded people, corresponded with Dr. Dunning himself, and tried to understand if our brain really was biased to overstate our competence in activities at which we suck... or if the celebrated effect was just a mirage brought about by the peculiar way in which we can play with numbers.</p>

<p>Have we been overstating our confidence in the Dunning-Kruger effect?</p>

<h5><b>A misunderstood effect</b></h5>

<p>The most important mistake people make about the Dunning-Kruger effect, according to Dr. Dunning, has to do with who falls victim to it. “The effect is about us, not them,” he wrote to me. “The lesson of the effect was always about how we should be humble and cautious about ourselves.” The Dunning-Kruger effect is not about dumb people. It’s mostly about all of us when it comes to things we are not very competent at.</p>

<p>In a nutshell, the Dunning-Kruger effect was originally defined as a bias in our thinking. If I am terrible at English grammar and am told to answer a quiz testing my knowledge of English grammar, this bias in my thinking would lead me, according to the theory, to believe I would get a higher score than I actually would. And if I excel at English grammar, the effect dictates I would be likely to slightly underestimate how well I would do. I might predict I would get a 70% score while my actual score would be 90%. But if my actual score was 15% (because I’m terrible at grammar), I might think more highly of myself and predict a score of 60%. This discrepancy is the effect, and it is thought to be due to a specific problem with our brain’s ability to assess its skills.</p>

<p>This is what student participants went through for Dunning and Kruger’s research project in the late 1990s. There were assessments of grammar, of humour, and of logical reasoning. Everyone was asked how well they thought they did and everyone was also graded objectively, and the two were compared.</p>

<p>Since then, many studies have been done that have reported this effect in other domains of knowledge. Dr. Dunning tells me he believes the effect “has more to do with being <i>misinformed</i> rather than uninformed.” If I am asked the boiling point of mercury, it is clear my brain does not hold the answer. But if I am asked what is the capital of Scotland, I may think I know enough to say Glasgow, but it turns out it’s Edinburgh. That’s misinformation and it’s pushing down on that confidence button in my brain.</p>

<p>So case closed, right? On the contrary. In 2016 and 2017, two papers were published in a mathematics journal called <i>Numeracy</i>. In them, the authors argued that the Dunning-Kruger effect was a mirage. And I tend to agree.</p>

<h5><b>The effect is in the noise</b></h5>

<p>The<a href="https://scholarcommons.usf.edu/numeracy/vol9/iss1/art4/"> two</a><a href="https://scholarcommons.usf.edu/numeracy/vol10/iss1/art4/"> papers</a>, by Dr. Ed Nuhfer and colleagues, argued that the Dunning-Kruger effect could be replicated by using random data. “We all then believed the [1999] paper was valid,” Dr. Nuhfer told me via email. “The reasoning and argument just made so much sense. We never set out to disprove it; we were even fans of that paper.” In Dr. Nuhfer’s own papers, which used both computer-generated data and results from actual people undergoing a science literacy test, his team disproved the claim that most people that are unskilled are unaware of it (“a small number are: we saw about 5-6% that fit that in our data”) and instead showed that both experts and novices underestimate and overestimate their skills with the same frequency. “It’s just that experts do that over a narrower range,” he wrote to me.</p>

<p>Wrapping my brain around all this took weeks. I recruited a husband-and-wife team, Dr. Patrick E. McKnight (from the Department of Psychology at George Mason University, also on the advisory board of Sense About Science and STATS.org) and Dr. Simone C. McKnight (from Global Systems Technologies, Inc.), to help me understand what was going on. Patrick McKnight not only believed in the existence of the Dunning-Kruger effect: he was teaching it to warn his students to be mindful of what they actually knew versus what they thought they knew. But after replicating Dr. Nuhfer’s findings using a different platform (the statistical computing language R instead of Nuhfer’s Microsoft Excel), he became convinced the effect was just an artefact of how the thing that was being measured was indeed measured.</p>

<p>We had long conversations over this as I kept pushing back. As a skeptic, I am easily enticed by stories of the sort “everything you know about this is wrong.” That’s my bias. To overcome it, I kept playing devil’s advocate with the McKnights to make sure we were not forgetting something. Every time I felt my understanding crystallize, doubt would creep in the next day and my discussion with the McKnights would resume.</p>

<p>I finally reached a point where I was fairly certain the Dunning-Kruger effect had not been shown to be a bias in our thinking but was just an artefact. Here then is the simplest explanation I have for why the effect appears to be real.</p>

<p>For an effect of human psychology to be real, it cannot be rigorously replicated using random noise. If the human brain was predisposed to choose heads when a coin is flipped, you could compare this to random predictions (heads or tails) made by a computer and see the bias. A human would call more heads than the computer would because the computer is making random bets whereas the human is biased toward heads. With the Dunning-Kruger effect, this is not the case. Random data actually mimics the effect really well.</p>

<p>The effect as originally described in 1999 makes use of a very peculiar type of graph. “This graph, to my knowledge, is quite unusual for most areas of science,” Patrick McKnight told me. In the original experiment, students took a test and were asked to guess their score. Therefore, each student had two data points: the score they thought they got (self-assessment) and the score they actually got (performance). In order to visualize these results, Dunning and Kruger separated everybody into quartiles: those who performed in the bottom 25%, those who scored in the top 25%, and the two quartiles in the middle. For each quartile, the average performance score and the average self-assessed score was plotted. This resulted in the famous Dunning-Kruger graph.</p>

<p><img height="627" width="725" src="https://www.mcgill.ca/oss/files/oss/figure_1_3.png" alt=""></p>

<p>Plotted this way, it looks like those in the bottom 25% thought they did much better than they did, and those in the top 25% underestimated their performance. This observation was thought to be due to the human brain: the unskilled are unaware of it. But if we remove the human brain from the equation, we get this:</p>

<p><img height="451" width="1086" src="https://www.mcgill.ca/oss/files/oss/figure_2_1.png" alt=""></p>

<p>The above Dunning-Kruger graph was created by Patrick McKnight using computer-generated results for both self-assessment and performance. The numbers were random. There was no bias in the coding that would lead these fictitious students to guess they had done really well when their actual score was very low. And yet we can see that the two lines look eerily similar to those of Dunning and Kruger’s seminal experiment. A<a href="https://www.sciencedirect.com/science/article/pii/S019188690100174X"> similar simulation</a> was done by Dr. Phillip Ackerman and colleagues three years after the original Dunning-Kruger paper, and the results were similar.</p>

<p>Measuring someone’s perception of anything, including their own skills, is fraught with difficulties. How well I think I did on my test today could change if the whole thing was done tomorrow, when my mood might differ and my self-confidence may waver. This measurement of self-assessment is thus, to a degree, unreliable. This unreliability--sometimes massive, sometimes not--means that any true psychological effect that does exist will be measured as smaller in the context of an experiment. This is called attenuation due to unreliability. “Scores of books, articles, and chapters highlight the problem with measurement error and attenuated effects,” Patrick McKnight wrote to me. In his simulation with random measurements, the so-called Dunning-Kruger effect actually becomes <i>more</i> visible as the measurement error increases. “We have no instance in the history of scientific discovery,” he continued, “where a finding improves by increasing measurement error. None.”</p>

<h5><b>Breaking the spell</b></h5>

<p>When I plug “Dunning-Kruger effect” into Google News, I get over 8,500 hits from media outlets like <i>The New York Times</i>, <i>New Scientist</i>, and the CBC. So many simply endorse the effect as a real bias of the brain, so it’s no wonder that people are not aware of the academic criticism that has existed since the effect was first published. It’s not just Dr. Nuhfer and his <i>Numeracy </i>papers. Other academic critics have pointed the finger, for example, at regression to the mean.</p>

<p>But as Patrick McKnight points out, regression to the mean occurs when the same measure is taken over time and we track its evolution. If I take my temperature every morning and one day spike a fever, that same measure will (hopefully) go down the next day and return to its mean value as my fever abates. That’s regression to the mean. But in the context of the Dunning-Kruger effect, nothing is measured over time, and self-assessment and performance are different measures entirely, so regression to the mean should not apply. The unreliability of the self-assessment …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mcgill.ca/oss/article/critical-thinking/dunning-kruger-effect-probably-not-real">https://www.mcgill.ca/oss/article/critical-thinking/dunning-kruger-effect-probably-not-real</a></em></p>]]>
            </description>
            <link>https://www.mcgill.ca/oss/article/critical-thinking/dunning-kruger-effect-probably-not-real</link>
            <guid isPermaLink="false">hacker-news-small-sites-25546787</guid>
            <pubDate>Sat, 26 Dec 2020 22:02:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting rid of NPM scripts]]>
            </title>
            <description>
<![CDATA[
Score 65 | Comments 38 (<a href="https://news.ycombinator.com/item?id=25546460">thread link</a>) | @efortis
<br/>
December 26, 2020 | https://blog.uidrafter.com/engineering/getting-rid-of-npm-scripts | <a href="https://web.archive.org/web/*/https://blog.uidrafter.com/engineering/getting-rid-of-npm-scripts">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">

<article>
<header>


</header>
<p>
In 2016, Sam Saccone <a rel="noopener" target="_blank" href="https://www.kb.cert.org/vuls/id/319816">discovered a vulnerability</a> that
allows adversaries to run arbitrary scripts when installing an NPM package of
theirs. As mitigation, NPM co-founder Laurie Voss <a rel="noopener" target="_blank" href="https://blog.npmjs.org/post/141702881055/package-install-scripts-vulnerability">
suggests</a>:
</p>
<ul>
<li>
<b>Option 1</b>: adding <code>--ignore-scripts</code> when running <code><span>npm</span>
install</code>
</li>
<li>
<b>Option 2</b>: permanently adding <code>ignore-scripts=true</code> to <code>.npmrc</code>
</li>
</ul>
<p>
UI Drafter uses the latter because it avoids having to
remember the flag everytime. But that option disables NPM
<code>"scripts"</code>. Therefore, we end up with two alternatives:
</p>
<ul>
<li>
<b>Option A</b>: overriding: <code><span>npm</span> run --ignore-scripts=false
<b>test</b></code>
</li>
<li>
<b>Option B</b>: using this shell script or a <a href="#-Makefile">Makefile</a>:
</li>
</ul>
<pre><span>#!/bin/sh</span>

<span>case</span> <span>$1</span> <span>in</span>
  <b>dev</b>)   ./make-dev.js <span>;;</span>
  <b>test</b>)  mocha <span>"src/**/*.test.js"</span><span></span> <span>;;</span>
  <b>lint</b>)  eslint src <span>;;</span>
  <b>slint</b>) stylelint <span>"src/**/*.css"</span><span></span> <span>;;</span>

  <b>prod</b>)  <span>time</span> ./make-production.js <span>;;</span>
  <b>all</b>)   <span>$0</span> <b>test</b> &amp;&amp; <span>$0</span> <b>lint</b> &amp;&amp; <span>$0</span> <b>slint</b> &amp;&amp; <span>$0</span> <b>prod</b> <span>;;</span>

  *)     <span>echo</span> <span>"Invalid task: <span>$1</span>"</span><span>;</span> <span>exit</span> <span>1</span> <span>;;</span>
<span>esac</span>
</pre>
<p>Which can be ran as:</p>
<pre>./<span>make</span> <b>test</b>
</pre>
<p>
If the package is not globally installed, prefix the path. For example:
</p>
<pre><b>lint</b>) <span>node_modules/.bin/</span>eslint src <span>;;</span>
</pre>
<h3>Overriding at installation</h3>
<p>
If you need to install packages that install binary dependencies, or rely
on running an NPM script, override the <code>.npmrc</code>:
</p>
<pre><span>npm</span> install <span>--ignore-scripts=false</span> <i>package-name</i>
</pre>

<p>
EDIT: (Dec/27/2020) As suggested in the <a rel="noopener" target="_blank" href="https://news.ycombinator.com/item?id=25546460">Hacker News thread</a>:
</p>
<a id="-Makefile"></a>
<details>
<summary>
<h3>
Makefile
</h3>
</summary>
<pre><b>dev</b>:
	./make-dev.js
<b>test</b>:
	mocha <span>"src/**/*.test.js"</span>
<b>lint</b>:
	eslint src
<b>slint</b>:
	stylelint <span>"src/**/*.css"</span>

<b>prod</b>:
	sh -c 'time ./make-production.js'

<b>all</b>: test lint slint prod

<span>.PHONY: dev test lint slint prod all</span>
</pre>
<pre><span>make</span> <b>test</b>
</pre>
</details>
</article>
<article>
<hr>
<h2>Engineering Blog</h2>
<ul>
<li><a rel="noopener" href="https://blog.uidrafter.com/engineering/isolated-tls-certificate-creation">Isolated Creation of Let's Encrypt TLS Certificates</a></li>
<li><a rel="noopener" href="https://blog.uidrafter.com/engineering/bitwise-table-lookup">Bitwise Table Lookup</a></li>
<li><a rel="noopener" href="https://blog.uidrafter.com/engineering">More…</a></li>
</ul>
</article>
</div></div>]]>
            </description>
            <link>https://blog.uidrafter.com/engineering/getting-rid-of-npm-scripts</link>
            <guid isPermaLink="false">hacker-news-small-sites-25546460</guid>
            <pubDate>Sat, 26 Dec 2020 21:06:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mastering Pinterest SEO: An insider's guide]]>
            </title>
            <description>
<![CDATA[
Score 92 | Comments 46 (<a href="https://news.ycombinator.com/item?id=25546430">thread link</a>) | @jmilinovich
<br/>
December 26, 2020 | https://blog.aesthetic.com/blog/pinterest-guide/ | <a href="https://web.archive.org/web/*/https://blog.aesthetic.com/blog/pinterest-guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="__next"><div><div><div><div><p>Pinterest is an extraordinarily powerful tool for consumers, but is still misunderstood by marketers. I worked at Pinterest for 2 years helping build their core content understanding technology, and learned a lot about what makes for a successful Pinterest marketing strategy. I hope this guide helps demystify how marketers can get the most from Pinterest as a marketing channel. </p><p>If you have any questions, please <a href="https://twitter.com/intent/tweet?text=Hey%20@jmilinovich">Tweet @jmilinovich</a>! </p><ol><li><a href="#Why-is-Pinterest-marketing-important">Why is Pinterest marketing important?</a></li><li><a href="#How-does-Pinterest-marketing-work">How does Pinterest marketing work?</a></li><li><a href="#How-to-create-a-Pinterest-marketing-plan">How to create a Pinterest marketing plan?</a></li><li><a href="#How-to-make-Pinterest-pins">How to make Pinterest pins?</a></li><li><a href="#How-to-make-Pinterest-Pins-popular">How to make Pinterest Pins popular?</a></li><li><a href="#Conclusion">Conclusion</a></li></ol><h2>Pinterest as a distribution channel</h2><p>Pinterest is a powerful tool that helps people all over the world discover ideas for things to do in their lives. Whether it’s finding recipes, figuring out what to wear, finding new beauty tips or literally any other use case imaginable… people are doing it on Pinterest.</p><p>While search engines like Google focus on the bottom of the purchase funnel (ie, once someone knows that they have a need and are actively looking for it) and social networks like Facebook and Instagram focus on the top of the funnel (ie, when customers are passively looking to consume content with no intent), Pinterest is the only place on the internet that lets marketers reach consumer in the consideration phase. </p><p><img src="https://d33wubrfki0l68.cloudfront.net/2514c6be4877df4b7599580c5af4d1c3c2f54f86/453eb/img/posts/pinterest-guide/consideration.png" alt="The marketing consideration funnel"></p><p>This creates a big opportunity for businesses to get their products, goods and services in front of potential buyers while they’re deciding what they want to buy, but haven’t made the decision yet. That’s one of the most powerful things about Pinterest- people go there to find ideas, not just to make purchasing decisions. This means that marketers are able to reach consumers before they’ve made up their mind on what they’re looking to do.</p><h2>Pinterest as a source of inbound links</h2><p>While the most clear first-order effect to a strong Pinterest presence is creating a powerful new referral traffic source, there’s also a misunderstood but very powerful second-order effect: creating more inbound links to your website. </p><p>Have you noticed how no matter what you search for, it seems that you almost always see Pinterest results on the first page of Google? Pinterest’s core growth strategy has been about getting excellent at SEO, or search engine optimization. Practically speaking this means that the company has spent a lot of effort creating millions of high quality landing pages with the explicit purpose of being indexed by Google. Each of these landing pages shows dozens of Pins, and each contains a link to that Pin’s page on Pinterest. </p><p>As your content becomes more popular, it will begin showing up on more of Pinterest’s SEO pages, which means that it will be more readily indexed by Google. Since Google gives Pinterest’s domain a high authority and quality score, this means that over time you will start to accumulate some of this authority if your Pins are shown in prominent places. So, getting good at Pinterest doesn’t just help improve your Pinterest referral traffic, it can also improve your traffic from places like Google! </p><p><img src="https://d33wubrfki0l68.cloudfront.net/bbc3082cbd708936207fcc8fed30415b5077ee03/32add/img/posts/pinterest-guide/pinterest-results.png" alt="Example of Pinterest landing pages"></p><h2>Pinterest is a search engine</h2><p>The most important thing to understand about Pinterest is that at its core it’s a search engine, not a social network.  People don’t use Pinterest to “follow” specific brands but rather to follow interests and search for ideas. A “Pin” is simply a visual bookmark to a webpage, and under the hood Pinterest’s technology stack is focused on figuring out what interests a Pin is about, and which users are interested in which interests. Content on Pinterest isn’t temporal like other social networks, but evergreen like on Google.</p><h2>Help Pinterest understand your content</h2><p>This means that the most important thing to get right for Pinterest marketing is helping Pinterest understand what interests your Pins are about. This means that the key underlying concept for Pinterest marketing is to create Pins for all of your web content, and then make sure that Pinterest has a clear understanding of what interests they align to. </p><p>Once Pinterest understands what a given Pin is about, it can start showing it to users to see how they interact with it. If they engage with it (ie, Save it to one of their boards or Click on it to see the underlying content), Pinterest uses this as a positive sign that this is quality content and will begin showing it to more people. </p><p>As such, one of the most important things to get right is having a clear strategy for how to communicate to Pinterest what your Pins are about and getting engagement signals on the Pins early. </p><p><img src="https://d33wubrfki0l68.cloudfront.net/db6e047a9650880cd7f0be4c4718c0791790c2e0/18ef8/img/posts/pinterest-guide/pinterest-interests.png" alt="Example of Pinterest interests"></p><h2>Choose your Interests</h2><p>The most critical thing to get right in your Pinterest marketing plan is determining what Interests are most important to your business. There are <a href="https://docs.google.com/spreadsheets/d/1HxL-0Z3p2fgxis9YBP2HWC3tvPrs1hAuHDRtH-NJTIM/edit#gid=118370875">over 10,000 interests on Pinterest today</a>, ranging from highly broad to highly specific. Start by brainstorming what interests your target audience has today, as well as what interests your content is actually about. Look for the overlap of these two sets and choose the 10-15 that have the most promise to focus in on first. </p><h2>Create your Boards</h2><p>Once you’ve chosen the interests that you want to focus on, the next step is to decide on the architecture of your Pinterest for Business account. Pinterest accounts for users and businesses alike are defined by the boards that they create and post Pins to. You can think of a board as a folder of visual bookmarks that are public by default. When someone looks at your Pinterest account, the fastest way that they will understand what you’re about is by the names of the boards that you create. </p><p>Start by creating boards whose names are the same as the 10-15 interests you chose to focus on. It’s OK if they have more words in them as well, but make sure that the Interest name itself is very prominent. Make sure that each board has a very specific description that explains the core ideas that you’ll be pinning to the board.</p><p><img src="https://d33wubrfki0l68.cloudfront.net/dadf2e2890dde22bbff64a7ded8e0dcf6b592fe9/31afa/img/posts/pinterest-guide/boards.png" alt="Example of Pinterest boards"></p><p>Next, you need to decide what content to start posting onto these boards. </p><h2>Pinning existing content</h2><p>There are only two kinds of Pins on Pinterest: Pins from your own website, and Pins from other people’s websites. Both are equally important to a strong Pinterest strategy. The first thing you should do is to fill your boards with Pins that are already on Pinterest and were created by other people. Spend some time saving 20-30 Pins to each of your boards. As you do this, Pinterest will also begin recommending new Pins in your homefeed that are related to what you’ve been Pinning. </p><p>The reason you’re seeing the Pins that Pinterest is recommending to you is because Pinterest already knows a lot about them and has a high confidence that users like you will find them interesting. When you save them to your boards, you’re giving Pinterest even more signal about what your board is about. This is extremely important, because Pinterest learns a lot about new Pins based on the other Pins that it shows up on boards with. </p><p><img src="https://d33wubrfki0l68.cloudfront.net/a3580f834d291668bd22cae46f7854ddb0106853/de8da/img/posts/pinterest-guide/existing-pin.png" alt="Example of Pinterest pins"></p><p>Each week you should also continue to save new, existing content to your boards to keep giving Pinterest more signal and context for what your Pins are about. </p><h2>Pinning your own content</h2><p>Once you create a good base of existing Pins on your boards, you can start to plan your strategy for getting your own original content into Pinterest. First, go through all of your existing website content and map out what content would be relevant for the Pinterest audience. Generally speaking, the best content will be things like blog posts or eCommerce product landing pages. You should skip things like your homepage, about page, contact us page or other informational pages that don’t provide highly specific and useful content about a specific concept. </p><p>On social networks, it’s important that you have a steady pace of posting content into your feed so that you stay top of mind and also don’t inundate followers by posting 100 things at once. Pinterest is much more like Google, however, where you want them to know about your content upfront and all at once. </p><p>You should post all of your existing, relevant content to Pinterest upfront and then consistently add new content as it’s published online. Save it to the most relevant board to give Pinterest a clear understanding of what your content’s about. You can also post it to more than one board if it’s relevant to multiple categories. </p><p>The Pins that perform best on Pinterest have been created specifically for Pinterest following their <a href="https://business.pinterest.com/en-gb/content/creative-best-practices/">creative best practices</a>. Practically speaking this means that each Pin will require some editing work within a graphics editor tool. Generally speaking, each Pin can take anywhere from 5-20 minutes to create by hand if using a tool like Photoshop, Canva or Adobe Spark. This can be quite burdensome, especially if you’re trying to create dozens or hundreds of Pins for your site. </p><p><a href="https://www.aesthetic.com/?utm_source=blog&amp;utm_medium=post&amp;utm_campaign=pinterest-guide">Aesthetic’s software</a> is able to generate on-brand Pinterest Pins from a company’s website automatically. Simply enter a URL, and our app will create dozens of variations of graphics to promote that webpage, including several that follow Pinterest’s best practices guide. We’ve seen our users cut down the time it takes to create a Pin by 95% using our tool. </p><p>Once you’ve created your Pin graphics, you can upload them into the Pinterest system. Add the URL for each Pin along with a detailed description that touches upon what the Pins about and ideally mentions the specific interests that it’s related to. Post these to the right boards, and you’re off to the races! </p><p><img src="https://d33wubrfki0l68.cloudfront.net/4ab1dd02738de6695f0118fd169a78c4e10d21bb/09e8b/img/posts/pinterest-guide/aesthetic-pins.png" alt="Example of Pinterest pins made with Aesthetic"></p><p>Once you’ve uploaded your content to Pinterest, you will see the impressions slowly start to trickle in as the system understands more about what your content’s about. Generally speaking it can take months for new content on Pinterest to get enough exposure for Pinterest to determine whether it’s sufficiently interesting enough for it to be promoted more widely within the system.</p><p>Another option to fast track the distribution of your Pins is to run small budget ads for your own Pins, targeting the Interests that they’re related …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.aesthetic.com/blog/pinterest-guide/">https://blog.aesthetic.com/blog/pinterest-guide/</a></em></p>]]>
            </description>
            <link>https://blog.aesthetic.com/blog/pinterest-guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25546430</guid>
            <pubDate>Sat, 26 Dec 2020 21:01:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fun with IP address parsing]]>
            </title>
            <description>
<![CDATA[
Score 424 | Comments 113 (<a href="https://news.ycombinator.com/item?id=25545967">thread link</a>) | @mr_tyzic
<br/>
December 26, 2020 | https://blog.dave.tf/post/ip-addr-parsing/ | <a href="https://web.archive.org/web/*/https://blog.dave.tf/post/ip-addr-parsing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>
		<p><span>Written by</span>
        David Anderson
        <br>
        <span>on&nbsp;</span><time datetime="2020-12-25 00:00:00 +0000 UTC">December 25, 2020</time>
</p>
		


		

		<p>In my quest to write a fast IPv4+6 parser, I wrote a
slow-but-I-think-correct parser, to use as a base of comparison. In
doing so, I discovered more cursed IP address representations that I
was previously unaware of. Let’s explore together!</p>

<p>We start out simple, with IPv4 and IPv6 in what I’ll call their
“canonical form”: <code>192.168.0.1</code> and <code>1:2:3:4:5:6:7:8</code>. Various specs
call these “dotted quad” (more specifically, “dotted decimal”),
dot-separated fields each representing 1 byte; and “colon-hex”,
colon-separated fields each representing 2 bytes.</p>

<p>The first bits of complexity come from IPv6. In canonical form, common
addresses would end up with long runs of zeros in the middle. So, <code>::</code>
allows you to elide 1 or more 16-bit blocks of zeros: <code>1:2::3:4</code> means
<code>1:2:0:0:0:0:3:4</code></p>

<p>Next up, for cursed historical reasons, IPv6 permits you to write the
final 32 bits of the address in dotted quad form. Effectively, you can
splat an IPv4 address onto the end of IPv6 addresses!
<code>1:2:3:4:5:6:77.77.88.88</code> means <code>1:2:3:4:5:6:4d4d:5858</code>.</p>

<p>And of course, you can combine the two! <code>fe80::1.2.3.4</code> means <code>fe80:0:0:0:0:0:102:304</code></p>

<p>The existence of <code>::</code> introduces an annoying edge case in parsing: the
<code>::</code> can be at the start or end of the address, and the “empty” side
of the address is not one of the 16-bit fields. <code>::1</code> means
<code>0:0:0:0:0:0:0:1</code>, <code>1::</code> means <code>1:0:0:0:0:0:0:0</code>, and <code>::</code> means
<code>0:0:0:0:0:0:0:0</code>. This is a natural consequence of the <code>::</code> rule, but
it makes the parser slightly more annoying to write.</p>

<p>One final rule for IPv6: technically, each colon-hex field is 4 hex
digits, but you can elide leading zeros, as I’ve been doing so
far. Fully canonically, <code>::</code> is
<code>0000:0000:0000:0000:0000:0000:0000:0000</code>. My apologies to trypophobic
readers.</p>

<p>That’s it for IPv6, mostly. Now, on to IPv4!</p>

<p>Fun fact, the textual representation of IPv4 was never standardized in
any document before IPv6 needed a grammar for its weirdo “trailing
dotted quad” notation. So, it’s a de-facto standard that boils down to
mostly “what did 4.2BSD understand?”, and “what did other OSes keep
when they copied 4.2BSD?”</p>

<p>And hoo boy, strap yourselves in, because 4.2BSD sure had some whacky
opinions! Let’s use <code>192.168.140.255</code> as an example. That’s an IPv4
address that people would look at and go “yes, that sure is an IPv4
address.” How else can we write that exact same address?</p>

<p>This is the same IP address: <code>3232271615</code>. You get that by
interpreting the 4 bytes of the IP address as a big-endian unsigned
32-bit integer, and print that. This leads to a classic parlor trick:
if you try to visit <a href="http://192.168.140.255/">http://3232271615</a> , Chrome will load
<a href="http://192.168.140.255/">http://192.168.140.255</a>.</p>

<p>Okay, but that’s sort-of sensible, right? An IPv4 address is 4 bytes,
so printing it as a single number is a bit human-unfriendly, but
broadly plausible, right?</p>

<p>How about <code>0300.0250.0214.0377</code> ? That’s still the same
address. Dotted quad, except each field is written out in octal.</p>

<p>And if octal is supported, you might be wondering about hex. And you’d
be right! <code>192.168.140.255</code> is also <code>0xc0.0xa8.0x8c.0xff</code>, according
to 4.2BSD.</p>

<p>Now, remember before we had CIDR (Classless Inter-Domain Routing) ?
IPv4 addresses were Class A, Class B or Class C. It was a weird time.</p>

<p>And that weird time made it into IP addresses! The familiar
<code>192.168.140.255</code> notation is technically the “Class C” notation. You
can also write that address in “class B” notation as <code>192.168.36095</code>,
or in “Class A” notation as <code>192.11046143</code>. What we’re doing is
coalescing the final bytes of the address into either a 16-bit or a
24-bit integer field.</p>

<p>This, by the way, is why utilities like <code>ping</code> will accept weird
looking addresses like <code>127.1</code> for <code>127.0.0.1</code>. Unlike IPv6, it’s not
doing some kind of “missing fields are zero” expansion. <code>127.1</code> is the
Class A notation for “host 1 of network 127”, where the 1 is a 24-bit
number.</p>

<p>And finally, we come to one last bit of unspecified behavior: do IPv4
addresses permit an unlimited number of leading zeros in each quad? Or
is there a maximum of 3 digits? <code>001.002.003.004</code> is universally
recognized as valid. What about
<code>0000000001.0000000002.0000000003.000000004</code>?</p>

<p>You might also be wondering if either of these numbers should be read
in as octal, since we said earlier that a leading zero might be
interpreted as octal. It depends! There are implementations that do
both, but <em>most</em> modern implementations have abandoned the octal and
hex notation, and treat leading 0s as decimal.</p>

<p>The leading zero debate also infects IPv6, to some extent. Is
<code>000001::00001.00002.00003.00004</code> is a valid IPv6 address (“common”
form <code>1::1.2.3.4</code>, or <code>1::102:304</code>)? Most modern parsers seem to allow
an unlimited amount of leading zeros in their representations,
probably because they’re leaning on some “parse integer” library that
implements that behavior.</p>

<p>And so, we reach the bitter end. If you want to <em>truly</em> parse IP
addresses, this is the bullshit you have to put up with.</p>

<p>Currently, my slow reference parser jettisons a lot of old baggage,
and sticks to what I think is a sensible subset of these
possibilities. It understands:</p>

<ul>
<li>Classic v4 dotted decimal, with any number of leading zeros.</li>
<li>It does not process Class A/B notation, or hex or octal notation.</li>
<li>It does not process the “uint32 to the knee” representation.</li>
<li>For IPv6, it understands canonical colon-hex form, as well as ::
and trailing-IPv4 style (where the trailing IPv4 follows the same
rules as the previous tweet). Each field is allowed any number of
leading zeros.</li>
</ul>

<p>I’m on the fence about that last one, the “IPv6 with an embedded
dotted decimal” form. My reference parser (Go’s <code>net.ParseIP</code>)
understands it, but it’s not really that useful any more in the real
world. At the dawn of IPv6, the idea was that you could upgrade an
address to IPv6 by prepending a pair of colons, as in <code>::1.2.3.4</code>, but
modern transition mechanisms no longer offer anything as clear-cut as
this, so the notation doesn’t really show up in the wild.</p>

		
	</div>

	
</div></div>]]>
            </description>
            <link>https://blog.dave.tf/post/ip-addr-parsing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25545967</guid>
            <pubDate>Sat, 26 Dec 2020 19:56:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What’s the best non-smart TV sold today?]]>
            </title>
            <description>
<![CDATA[
Score 208 | Comments 241 (<a href="https://news.ycombinator.com/item?id=25544831">thread link</a>) | @thomas
<br/>
December 26, 2020 | https://helpatmyhome.com/best-non-smart-tv/ | <a href="https://web.archive.org/web/*/https://helpatmyhome.com/best-non-smart-tv/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><main id="genesis-content"><article aria-label="What’s The Best Non-Smart TV Sold Today?"><div itemprop="text">
<p>With the industry-wide transition to smart TVs many of us have felt like there is no option but to get one. And the walls are closing in — it seems like almost every TV sold today is a smart one, which means a lack of control of what’s happening on our device, the possibility of the company deciding one day to show us ads (as Samsung as done), and the certainty that our viewing and usage data is being sent off to all sorts of third parties. </p>



<p>The solution? Buy a dumb TV!</p>



<h2><span id="What_Is_A_Dumb_TV">What Is A Dumb TV?</span></h2>



<p>The alternative to Smart TVs are, of course, non-smart TVs or, as people have taken to calling them, dumb TVs. These are televisions without an internet connection, without built-in HBO Max or Disney, without Amazon Alexa, and lacking apps of any kind. A dumb TV is the television equivalent of a flip phone. </p>



<p>Just because your TV is dumb doesn’t mean you can’t use Roku or Apple TV, etc. In this case you are simply opting to plug those devices into your TV via HDMI rather than having them built in. In almost all cases the plugged in device is better than having the software version built into your TV, so you are making your TV be smart instead of being forced to have one. </p>



<h2><span id="Why_Not_Buy_An_Old_TV">Why Not Buy An Old TV?</span></h2>



<p>You can definitely buy an old TV to solve this problem instead of hunting around for an increasingly rare non-smart in 2021. Televisions age pretty well, so as long as you can find something relatively high quality and made in the last 8 (or so) years you are good to go. </p>



<p>You’ll mainly need to ensure that your older model is in good physical condition, has enough HDMI ports to suit a current user, has no burn-in or wear issues, has a working remote, doesn’t have cracked or wrecked speakers, and that the color hasn’t gone crazy over time. You’ll also want to make sure your TV is an LED TV, so it’s power efficient and looks great, instead of using an outdated technology (like plasma). </p>



<p>For example, I have a Samsung dumb TV from 2012 (or so) that works perfectly well, has sufficient volume, and completely gets the job done. It was a good TV when I bought it, and it’s a great TV now, because it doesn’t have any of the features that I don’t want — and can’t avoid — today. </p>



<h2><span id="Just_Dont_Connect_It_To_the_Internet">Just Don’t Connect It To the Internet</span></h2>



<p>A smart TV can’ the smart without an internet connection so one thing you can do to get a dumb TV is to simply not connect it to your WiFi network. Your TV will will work since it’s connect through coax but the rest of the data cannot flow because the television doesn’t have an internet connection!</p>



<p>You can then go ahead and add a Nvidia Shield or Apple TV and connect that to the internet. This way the auxiliary devices will have internet connection <em>while you are using them</em>, but the TV itself (the hypervisor in this scenario) stays blissfully unaware of that internet connection. </p>



<p>Note, there have been scattered reports of some TVs, including those from Samsung, simply searching for open WiFi signals and attempting to connect to them, but this is an extreme and user-hostile example that hopefully won’t be repeated (assuming its true in the first place).</p>



<p>Some smart TV will force you to connect them to the internet for firmware updates and will resort to frequent nagging to get you to do this, but very few will force you to do it or not work entirely without the connection (yet). </p>



<h2><span id="Best_Dumb_TVs">Best Dumb TVs</span></h2>



<p>Here are some intelligent picks in non-smart TVs. </p>



<figure><img loading="lazy" src="https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/scapter-1024x606.jpg" alt="" width="433" height="256" srcset="https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/scapter-1024x606.jpg 1024w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/scapter-350x207.jpg 350w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/scapter-768x454.jpg 768w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/scapter-1536x908.jpg 1536w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/scapter.jpg 1782w" sizes="(max-width: 433px) 100vw, 433px"></figure><h2><span id="Sceptre_50-inch_4K_LED_TV">Sceptre 50-inch 4K LED TV</span></h2>



<p>Sceptre has generally been considered a mid-tier TV company, but they have done a good job of not transitioning entirely to Smart TVs. The <a href="https://amzn.to/3mZUDAp" target="_blank" rel="noreferrer noopener nofollow external" title="https://amzn.to/3mZUDAp" data-wpel-link="external">Sceptre U518CV-UM</a> is a 50-inch 4K that’s completely non-smart TV that is from the 2019 model year, so you are getting recent tech without the connectivity features that you don’t want.</p>



<ul><li>4K Television (3840×2160, UHD resolution)</li><li>Dimensions: 44.6 x 28.5 x 10.8 inches</li><li>Weight: 29.3 pounds</li></ul><p>Sceptre has the same non-smart TV in larger sizes as well, <a href="https://amzn.to/2VGHSyD" target="_blank" rel="noreferrer noopener nofollow external" title="https://amzn.to/2VGHSyD" data-wpel-link="external">up to 65-inches</a> if you need the extra size or have a big room to fill. </p>



<div><figure><img loading="lazy" src="https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/insing-1024x622.jpg" alt="" width="341" height="207" srcset="https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/insing-1024x622.jpg 1024w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/insing-350x213.jpg 350w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/insing-768x466.jpg 768w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/insing.jpg 1258w" sizes="(max-width: 341px) 100vw, 341px"></figure></div>



<h3><span id="Insignia_55-inch_Class_LED">Insignia 55-inch Class LED</span></h3>



<p>If you live near a Best Buy then you will have access to their house brand, Insignia. The Insignia 55-inch (NS-55D420NA20) is a LED-lit 1080p television that sells for about $300. It’s devoid of smart features but it has three HDMI ports and was first released in 2019. </p>



<p>This line of Insignia dumb TVs is sold from 19 inches up to 58 inches so there will be a TV for every room size. </p>



<div><figure><img loading="lazy" src="https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/smasungbuns-1024x625.jpg" alt="" width="451" height="275" srcset="https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/smasungbuns-1024x625.jpg 1024w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/smasungbuns-350x214.jpg 350w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/smasungbuns-768x469.jpg 768w, https://125mq93n6tbi2g5emb29ys7u-wpengine.netdna-ssl.com/wp-content/uploads/2020/12/smasungbuns.jpg 1170w" sizes="(max-width: 451px) 100vw, 451px"></figure></div>



<h2><span id="Samsung_Business_BER_43-Inch">Samsung Business BER 43-Inch </span></h2>



<p>This <a href="https://amzn.to/2VFc4di" target="_blank" rel="noreferrer noopener nofollow external" title="https://amzn.to/2VFc4di" data-wpel-link="external">Samsung Business line TV</a> (model BE43R) is a full HD (1080p) LED TV that is part of Samsung’s commercial line, but doesn’t have the crazy price tag to reflect it. Commercial TV’s can get super experience for what seems like a normal TV — and for what will function like a normal TV if you are simply using it like one! The smartest feature this TV has is the ability to play images from a USB stick.</p>



<p>This TV has all the features you’d expect from a normal television, like HDMI input, and isn’t missing anything obvious. For example it still has integrated speakers and 1080p (1920×1080) resolution.</p>



<p>If you are open to commercial TVs there <a href="https://amzn.to/3gdIm8R" target="_blank" rel="noreferrer noopener nofollow external" title="https://amzn.to/3gdIm8R" data-wpel-link="external">are a huge number to explore</a>.</p>



<h2><span id="Dumb_TV_Alternatives">Dumb TV Alternatives</span></h2>



<p>Of course there are other ways to avoid a smart TV. Here are some bright ideas…</p>



<ul><li><strong>Projector:</strong> The smart device revolution has really come to projectors yet, so you can watch your TV and movies through a projector without having to worry about your privacy or ads</li><li><strong>Monitor:</strong> Computer monitors haven’t gotten smart (since they are connected to something smart) so if you watch television on a computer monitor you’ll have no need to worry about built-in Alexa or Google Home</li><li><strong>Business TV (aka Commercial Display):</strong> A <a href="https://www.neweggbusiness.com/s/commercial-tvs/id-3672" target="_blank" rel="noreferrer noopener nofollow external" title="https://www.neweggbusiness.com/s/commercial-tvs/id-3672" data-wpel-link="external">business-focused TV</a> (something you’d see hung in an office or airport and playing CNN all day on mute) is designed for simplicity and long-lasting performance. These haven’t yet gotten smart and will likely stay dumb for years as they need to have error- and update-free operation for years on end</li><li><strong>Outdoor TV:</strong> For some reason outdoor and weatherproof televisions have yet to go smart. Here is a <a href="https://amzn.to/3lMr0B0" target="_blank" rel="noreferrer noopener nofollow external" title="https://amzn.to/3lMr0B0" data-wpel-link="external">good example of one from Furrion</a>.</li></ul><h2><span id="FAQs">FAQs</span></h2>


<div><ol><li><strong>Can I use PiHole or a similar device to block the ads and privacy leaks from my smart TV?</strong><p>You'd think this would work, but manufacturers have gotten wise to the PiHole and other methods of blocking tracking and advertising injection so, no, you really can't. At this point many manufacturers will take measures like building ads into the core technology of their software so blocking ads will break other features. Also many manufacturers will hardcode their DNS to their preferred vendor, not allowing you to override their option with your PiHole. </p></li></ol></div></div></article></main></div></div></div>]]>
            </description>
            <link>https://helpatmyhome.com/best-non-smart-tv/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25544831</guid>
            <pubDate>Sat, 26 Dec 2020 17:26:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lawyers automate this, so why don't airlines?]]>
            </title>
            <description>
<![CDATA[
Score 178 | Comments 145 (<a href="https://news.ycombinator.com/item?id=25543861">thread link</a>) | @leejo
<br/>
December 26, 2020 | https://leejo.github.io/2020/12/26/EZY1952/ | <a href="https://web.archive.org/web/*/https://leejo.github.io/2020/12/26/EZY1952/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<p>
				<center>Lawyers Automate This, So Why Don't Airlines?</center>
			</p>
			<div>
				<center>
				
				
				

				December 26, 2020 (
				
				
					<a href="https://leejo.github.io/2020/11/19/some_kind_of_paypal_refund_scam/">Prev</a>
				
				/
				
					Next
				
			)

			
				</center>
			</div>
			<p>My working title for this blog post was “Why I’ll Never Fly With easyJet Again”, but that was far too clickbaity. Also it’s probably worth prefixing this post with two things. The first being the caveat that whether or not i ever fly with easyJet again is immaterial to their business, given that the model of budget airlines is one of opportunistic sales. Their loyalty programmes are minimal to non-existent<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> (although that may change in the near future<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>) because the nature of their passengers is not one of loyalty. When you’re looking for a short haul cheap flight you’re unlikely to be attracted to schemes that only benefit you after years, or hundreds of thousands of air miles, worth of loyalty.</p>

<p>The reality of the budget airlines is they don’t have to worry about losing future passengers, thousands of them even, because there will always be enough replacement passengers. Budget airlines’ flights average above a 90% occupancy rate<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup>.</p>

<p>So the point of me never flying with easyJet again is not because i am under any illusion that it will be detrimental to their business, it won’t, but rather to protect <em>myself</em> should the situation happen again. They’re not the first airline to make my “list”, but the others have reasons that aren’t interesting enough to require a blog post.</p>

<p>What i am hoping with this post is that it gives the reader enough information that, should they find themselves in a similar situation, they are more informed as to their options and the potential ramifications of the choice they make. This is going to affect more travelers when the UK leaves the EU.</p>

<p>The second prefix is that easyJet recently posted their first year of losses<sup id="fnref:10" role="doc-noteref"><a href="#fn:10">4</a></sup>, due to the current global situation. I started writing this post sometime in 2019, way before the pandemic royally fucked the airline industry. It’s arguable that the airline industry being royally fucked was only a matter of time, and the consequences of <em>that</em> could mean the details here are now even more relevant - It may become even harder to claim refunds and compensation from them in the future. Airline companies will probably double down on their approach to handling compensation claims to avoid yet more financial loss.</p>

<p><strong>EZY1952</strong></p>

<p>On 23rd December 2018 my partner and I were due to fly from Geneva to Manchester on easyJet flight EZY1952, aircraft registration G-EZRU, which was scheduled to depart at 16:50 CET and arrive at 17:50 GMT. I had booked these flights a couple of months earlier, which combined with the date of our departure and return lead to a total cost of 619.38 CHF.</p>

<p>The 600+ CHF didn’t include any of the optional extras, priority boarding, seat choice, checked bags, etc. It was the “basic” cost of the “cheap” flights. This cost is four to five times more than the normal cost of this route, as I said due to the relatively late booking (two months in advance) and the dates of the flights. This route is normally far cheaper:</p>

<p><img width="625px" src="https://leejo.github.io/images/2020/EZY1952/typical_cost.png"></p>

<p>Anyway, given the alternatives and the limited options for our dates these were the flights we settled on and decide the cost was worth it to spend Xmas with the family. The flight was delayed by just a few minutes, which isn’t unusual for this route, but then took off as normal at 17:14:05 CET.</p>

<p>A few moments after take off, the literal wheels no longer being on the ground part of it, I felt my ears pop quite suddenly. That might not be taken as unusual either, but I live at altitude and my ears don’t normally pop on flights. The plane then spent several minutes in low cloud, another unusual thing given the cloud line is normally cut through quicker. I turned to my partner and suggested that something was off.</p>

<p>A couple of minutes later the pilot informed us that the flight would be returning to Geneva airport as the cabin pressure system, and its backup, had failed. Given the potentially catastrophic consequences of the cabin pressure system failing at cruising altitude, I considered that everyone on the plane had been very lucky.</p>

<p>The plane landed safely at Geneva airport at 17:41:00 CET, meaning a total flight time of about 25 minutes<sup id="fnref:4" role="doc-noteref"><a href="#fn:4">5</a></sup>. I contacted my parents to let them know we wouldn’t be arriving as planned and would keep them informed as to any updates:</p>

<p><img width="625px" src="https://leejo.github.io/images/2020/EZY1952/messages_to_mum.png"></p>

<p>We remained on the plane, after the pilot informed us that the technical crew were going to look into the issue. We were then told the parts would be replaced/fixed and this would take three to four hours. At this point I knew that we would not be flying until the next day as a) it was now 19:00 and Geneva airport has strict limitations on flights after 22:00, and b) it would be massively irresponsible of the airline to let this plane fly without a more comprehensive test that would probably take longer than the three to four hour estimate<sup id="fnref:6" role="doc-noteref"><a href="#fn:6">6</a></sup>.</p>

<p>Since it was going to take a few hours all passengers disembarked and returned to the departure gate. I’m not sure how long we were on the plane, while it was on the ground, but looking at the evidence I kept afterwards it appears that we were on it for approximately one hour fifteen minutes. This is from the time it landed to receiving a text message from easyJet apologising for the delay:</p>

<p><img width="625px" src="https://leejo.github.io/images/2020/EZY1952/sorry_for_delay.png"></p>

<p>As soon as we got back into the gate I sat down and checked to see if there were any other flights available. Sure enough there was: we could get a one way easyJet flight to Liverpool, so I booked two seats for a total of 189.26 CHF. This flight would depart at 21:25 CET and arrive at 22:20 GMT, four hours and thirty minutes after our original arrival time.</p>

<p>It should be said at this point I was reasonably confident of a few things:</p>

<ul>
  <li>It was highly unlikely the original fight was going to depart that night</li>
  <li>In fact, it would probably be delayed until the next afternoon</li>
  <li>We would have all the inconvenience of that, and lose one third of our time in the UK</li>
  <li>Given the original arrival time was delayed by more than three hours we were covered by EU Regulation 261/2004</li>
  <li>So the airline would have to compensate €250 for each of us, which would at least cover the alternate flights I had booked</li>
</ul>

<p>I was correct on four out of five of these:</p>

<p><img width="625px" src="https://leejo.github.io/images/2020/EZY1952/delayed_overnight.png"></p>

<p>Our flight to Liverpool went without issue, and we weren’t the only people to have rebooked from the delayed flight as we overheard some other passengers explaining their situation to the cabin crew<sup id="fnref:7" role="doc-noteref"><a href="#fn:7">7</a></sup>.</p>

<p><strong>Contacting easyJet Customer Service</strong></p>

<p>The next day I used easyJet’s contact form to submit a claim under EC261/2004 regulations. I knew this was going to take a long time so figured I may as well start the process as soon as possible. My claim was made on the basis that the original flight had been delayed overnight and I had booked alternate travel arrangements to get to my destination.</p>

<p>I considered the cost of the original flights a sunk cost. I wasn’t actually interested in compensation and I just wanted the cost of the alternate flights refunded, which came in at less than half the amount of compensation EC261/2004 would give considering the length of the delay to the original flight.</p>

<p>The response from easyJet came back quickly, the next day: <em>As you were a no show on the flight we would not be able t reimburse the costs for alternate transport.</em> - well that didn’t read like a response by someone/thing that had actually looked into the details. We had shown up for the flight, given we were on it when the pressure systems failed, and clearly we wouldn’t show up for the <em>rescheduled</em> flight if we arranged alternate transport as we can’t be in two places at once.</p>

<p>I assumed this was just a first level response of “refuse all claims, through a semantic dispute, because this will cause a not insignificant number of people to give up”<sup id="fnref:8" role="doc-noteref"><a href="#fn:8">8</a></sup>. The contact form doesn’t have a place to describe the reason for the claim in detail so I needed to call easyJet to explain.</p>

<p><strong>EU Regulation 261/2004</strong></p>

<p>I’ll spare you too much detail, as you can search for it if you want to (or read a summary on <a href="https://en.wikipedia.org/wiki/Flight_Compensation_Regulation">Wikipedia</a>). Essentially - EU 261/2004 allows compensation if your flight is from or to an EU/EAA area and is either delayed or cancelled [less than one week before the flight date]. The level of compensation depends on the distance of the flight.</p>

<p>In this particular case the delay was more than four hours, and the flight was less than 1,500km, so would qualify for €250 compensation (per passenger).</p>

<p>The regulation also says the passengers must be given assistance, and in this particular case of the flight being delayed overnight would mean hotel accommodation and transport between the airport and the hotel. This was Geneva two days from Xmas, so that would probably mean another €250.</p>

<p>So a reasonable estimate is easyJet would be paying in the region of €750 per passenger on this delayed flight. Given it was full (at least to my recollection) easyJet were looking at a bill of at least €100,000 for compensation + accommodation expenses<sup id="fnref:9" role="doc-noteref"><a href="#fn:9">9</a></sup>.</p>

<p>To go off on a tangent slightly - all of this is going to be up in the air when the UK leaves the EU. Of course that depends what the UK government <a href="https://en.wikipedia.org/wiki/Flight_Compensation_Regulation#Brexit_and_British_Consumers">decide to do about it</a>. Given everything else on their plate don’t be surprised if this one gets forgotten about until the claims start to appear.</p>

<p><strong>Contacting easyJet Customer Service Again</strong></p>

<p>As my claim, via easyJet’s web form, was rejected relatively quickly I decided to pick up the phone and see if speaking to someone would make a difference. I explained the situation and they agreed to pass this on to someone who would look at it in more detail, given the time of year this would take a few days at the least.</p>

<p>A couple of weeks later I received an email stating “Unfortunately as you were a no show on the transferred flight there is no reimbursement for EUC216 Compensation”. But also “As a goodwill gesture I have created a flight voucher to the value of the 51.90 GBP”.</p>

<p>Slightly odd - no …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leejo.github.io/2020/12/26/EZY1952/">https://leejo.github.io/2020/12/26/EZY1952/</a></em></p>]]>
            </description>
            <link>https://leejo.github.io/2020/12/26/EZY1952/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25543861</guid>
            <pubDate>Sat, 26 Dec 2020 15:08:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[They want us to be compliant, not secure]]>
            </title>
            <description>
<![CDATA[
Score 191 | Comments 165 (<a href="https://news.ycombinator.com/item?id=25543818">thread link</a>) | @_wldu
<br/>
December 26, 2020 | https://www.go350.com/posts/they-want-us-to-be-compliant-not-secure/ | <a href="https://web.archive.org/web/*/https://www.go350.com/posts/they-want-us-to-be-compliant-not-secure/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Some years ago, I worked for an organization that was involved in federally funded research. Occasionally, government IT auditors (or contractors that they hired) would visit our facilities to audit our systems.</p><p>We used a wide variety of operating systems on several different hardware platforms. Windows, Mac, Linux and Unix systems were scattered throughout our buildings running on desktops, laptops, workstation, servers and embedded devices. We ran several different Linux distributions, multiple Unixes and had standardized on <a href="https://en.wikipedia.org/wiki/Bcrypt">bcrypt</a> hashes to store user passwords.</p><p>Bcrypt was released in 1999 and is based on <a href="https://www.schneier.com/academic/blowfish/">Blowfish</a>. Blowfish is a fast, unpatented block cipher that was developed by <a href="https://en.wikipedia.org/wiki/Bruce_Schneier">Bruce Schneier</a> in 1993. It’s been in the mainline Linux kernel since the 2.6 release.</p><p>Bcrypt is a fast and efficient password hash yet strong and hard to attack. At the time, it was the strongest password hash that we could use and as an added bonus, it worked on all of our Linux and Unix systems.</p><p>One particular year, the IT auditors realized that we were using bcrypt hashes to store user passwords. They said that it was not a <a href="https://csrc.nist.gov/publications/detail/fips/180/4/final">FIPS approved algorithm</a> and by using bcrypt hashes, we were noncompliant. They insisted that we switch to a SHA-2 based hash function right away.</p><p>We ran several tests that demonstrated how the SHA-2 hashes were much easier to crack than the bcrypt hashes (see below for a performance comparison on a semi-modern GPU). But the auditors were adamant. They did not care that the approved algorithms were weaker. Nothing would change their decision.</p><p>In their minds, it was a simple matter. Bcrypt was not on the list. It was not an approved hashing function. They would not discuss it further.</p><p>To satisfy the auditors, we switched all the systems to an approved SHA-2 hash function. This action probably made our systems more vulnerable to cyber attacks.</p><p>A colleague said, <em>“They want us to be compliant, not secure.”</em></p><div><pre><code data-lang="bash">$ hashcat -b -m <span>1800</span>
hashcat <span>(</span>v5.1.0<span>)</span> starting in benchmark mode...

OpenCL Platform <span>#1: NVIDIA Corporation</span>
<span>======================================</span>
* Device <span>#1: GeForce GTX 1060 6GB, 1519/6077 MB allocatable, 10MCU</span>

Benchmark relevant options:
<span>===========================</span>
* --optimized-kernel-enable

Hashmode: <span>1800</span> - sha512crypt $6$, SHA512 <span>(</span>Unix<span>)</span> <span>(</span>Iterations: 5000<span>)</span>

Speed.#1.........:    <span>78810</span> H/s <span>(</span>51.36ms<span>)</span> @ Accel:512 Loops:128 Thr:32 Vec:1
</code></pre></div><div><pre><code data-lang="bash">$ hashcat -b -m <span>3200</span>
hashcat <span>(</span>v5.1.0<span>)</span> starting in benchmark mode...

OpenCL Platform <span>#1: NVIDIA Corporation</span>
<span>======================================</span>
* Device <span>#1: GeForce GTX 1060 6GB, 1519/6077 MB allocatable, 10MCU</span>

Benchmark relevant options:
<span>===========================</span>
* --optimized-kernel-enable

Hashmode: <span>3200</span> - bcrypt $2*$, Blowfish <span>(</span>Unix<span>)</span> <span>(</span>Iterations: 32<span>)</span>

Speed.#1.........:     <span>7570</span> H/s <span>(</span>41.13ms<span>)</span> @ Accel:16 Loops:8 Thr:8 Vec:1
</code></pre></div><ul><li><a href="https://www.go350.com/tags/compliance">compliance</a></li><li><a href="https://www.go350.com/tags/passwords">passwords</a></li></ul></div></div>]]>
            </description>
            <link>https://www.go350.com/posts/they-want-us-to-be-compliant-not-secure/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25543818</guid>
            <pubDate>Sat, 26 Dec 2020 14:56:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Executable PNGs]]>
            </title>
            <description>
<![CDATA[
Score 219 | Comments 39 (<a href="https://news.ycombinator.com/item?id=25543191">thread link</a>) | @todsacerdoti
<br/>
December 26, 2020 | https://djharper.dev/post/2020/12/26/executable-pngs/ | <a href="https://web.archive.org/web/*/https://djharper.dev/post/2020/12/26/executable-pngs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<article>

<p>
<time datetime="2020-12-26">Saturday, December 26, 2020</time>
</p>
<figure>
<a href="https://djharper.dev/img/peek.webm"><video src="https://djharper.dev/img/peek.webm" loop="true" width="100%" title="The pixels have been adjusted in colour slightly." autoplay=""></video></a>
<figcaption><br>It's an image <i>and</i> a program</figcaption>
</figure>
<p>A few weeks ago I was reading about <a href="https://www.lexaloffle.com/pico-8.php">PICO-8</a>, a fantasy games console with limited constraints. What really piqued my interest about it was the novel way games are distributed, you encode them into a PNG image. This includes the game code, assets, everything. The image can be whatever you want, screenshots from the game, cool artwork or just text. To load them you pass the image as input to the PICO-8 program and start playing.</p>
<p>This got me thinking, wouldn’t it be cool if you could do that for programs on Linux? No! I hear you cry, that’s a dumb idea, but whatever, herein lies an overview of possibly the dumbest things I’ve worked on this year.</p>
<h2 id="encoding">Encoding</h2>
<p>I’m not entirely sure what PICO-8 is actually doing, but at a guess it’s probably use <a href="https://en.wikipedia.org/wiki/Steganography">Steganography</a> techniques to ‘hide’ the data within the raw bytes of the image. There are a lot of resources out there that explain how Steganography works, but the crux of it is quite simple, your image your want to hide data into is made up of bytes, an image is made up of pixels. Pixels are made up of 3 Red Green and Blue (RGB) values, represented as 3 bytes. To hide your data (the “payload”) you essentially “mix” the bytes from your payload with the bytes from the image.</p>
<p>If you just replaced each byte in your cover image with the bytes from your payload, you would end up with sections of the image looking distorted as the colours probably wouldn’t match with what your original image was. The trick is to be as subtle as possible, or <em>hide in plain sight</em>. This can be achieved by <em>spreading</em> your payload bytes over the bytes of the cover image by using the <em>least significant bits</em> to hide them in. In other words, make subtle adjustments to the byte values so the colour changes are not drastic enough to be perceptive by the human eye.</p>
<p>For example if your payload was the letter <code>H</code>, represented as <code>01001000</code> in binary (72), and your image contained a series of black pixels</p>
<figure>
<a href="https://djharper.dev/img/byte-replace1.png"><img src="https://djharper.dev/img/byte-replace1.png" title="The bits from the input bytes are spread across 8 output bytes by hiding them in the least significant bit"></a>
<figcaption><br>The bits from the input bytes are spread across 8 output bytes by hiding them in the least significant bit</figcaption>
</figure>
<p>The output is two-and-a-bit pixels that are slightly less black than before, but can you tell the difference?</p>
<figure>
<a href="https://djharper.dev/img/pixels1.png"><img src="https://djharper.dev/img/pixels1.png" title="The pixels have been adjusted in colour slightly."></a>
<figcaption><br>The pixels have been adjusted in colour slightly.</figcaption>
</figure>
<p>Well, an exceptionally trained colour connoisseur might be able to, but in reality these subtle shifts can really only be noticed by a machine. Retrieving your super secret <code>H</code> is just a matter of reading 8 bytes from the resulting image and re-assembling them back into 1 byte. Obviously hiding a single letter is lame, but this can scale to anything you want, a super secret sentence, a copy of <em>War and Peace</em>, a link to your soundcloud, the go compiler, the only limit is the amount of bytes available in your cover image as you’ll require at least 8x whatever your input is.</p>
<h2 id="hiding-programs">Hiding programs</h2>
<p>So, back to the whole linux-executables-in-an-image thing, that old chestnut. Well, seeing as executables are just bytes, they can be hidden in images. Just like in the PICO-8 thing.</p>
<p>Before I could achieve this I decided to write my own <a href="https://github.com/djhworld/steg">Steganography library</a> and <a href="https://github.com/djhworld/stegtool">tool</a> to support encoding and decoding data into PNGs. Yes, there are lots of steganography libraries and tools out there but I learn better by building.</p>
<figure>
<div><pre><code data-lang="bash">$ stegtool encode <span>\
</span><span></span>--cover-image htop-logo.png <span>\
</span><span></span>--input-data /usr/bin/htop <span>\
</span><span></span>--output-image htop.png
$
$ <span>echo</span> <span>"Super secret hidden message"</span> | stegtool encode <span>\ </span>
--cover-image image.png <span>\
</span><span></span>--output-image image-with-hidden-message.png
$ stegtool decode --image image-with-hidden-message.png
Super secret hidden message</code></pre></div>
</figure>
<p>As it’s all written in <a href="https://www.rust-lang.org/">Rust</a> it wasn’t that difficult to compile to WASM, so feel free to play with it here:</p>

<p>Anyway, now that can embed data, including executables into an image, how do we run them?</p>
<h2 id="get-it-running">Get it running</h2>
<p>The simple option would be to just run the tool above, <code>decode</code> the data into a new file, <code>chmod +x</code> it and then run it. It works but that’s not fun enough. What I wanted was something similar to the PICO-8 experience, you pass something a PNG image and it takes care of the rest.</p>
<p>However, as it turns out, you can’t just load some arbitrary set of bytes into memory and tell Linux to jump to it. Well, not in a direct way anyway, but you <em>can</em> use some cheap tricks to fudge it.</p>
<h2 id="memfd-create">memfd_create</h2>
<p>After reading <a href="https://magisterquis.github.io/2018/03/31/in-memory-only-elf-execution.html">this blogpost</a> it became apparent to me you can create an in-memory file and mark it as executable</p>
<blockquote>
<p>Wouldn’t it be cool to just grab a chunk of memory, put our binary in there, and run it without monkey-patching the kernel, rewriting execve(2) in userland, or loading a library into another process?</p>
</blockquote>
<p>This method uses the syscall <a href="https://man7.org/linux/man-pages/man2/memfd_create.2.html">memfd_create(2)</a> to create a file under the <code>/proc/self/fd</code> namespace of your process and load any data you want in it using <code>write</code>. I spent quite a while messing around with the <a href="https://crates.io/crates/libc">libc</a> bindings for Rust to get this to work, and had a lot of trouble understanding the data types you pass around, the documentation for these Rust bindings doesn’t help much.</p>
<p>I got something working eventually though</p>
<figure>
<div><pre><code data-lang="rust"><span>unsafe</span><span> </span>{<span>
</span><span>    </span><span>let</span><span> </span>write_mode<span> </span><span>=</span><span> </span><span>119</span>;<span> </span><span>// w
</span><span></span><span>    </span><span>// create executable in-memory file
</span><span></span><span>    </span><span>let</span><span> </span>fd<span> </span><span>=</span><span> </span>syscall(libc::SYS_memfd_create,<span> </span><span>&amp;</span>write_mode,<span> </span><span>1</span>);<span>
</span><span>    </span><span>if</span><span> </span>fd<span> </span><span>==</span><span> </span><span>-</span><span>1</span><span> </span>{<span>
</span><span>        </span><span>return</span><span> </span><span>Err</span>(<span>String</span>::from(<span>"memfd_create failed"</span>));<span>
</span><span>    </span>}<span>
</span><span>
</span><span>    </span><span>let</span><span> </span>file<span> </span><span>=</span><span> </span>libc::fdopen(fd,<span> </span><span>&amp;</span>write_mode);<span> 
</span><span>
</span><span>    </span><span>// write contents of our binary
</span><span></span><span>    </span>libc::fwrite(<span>
</span><span>        </span>data.as_ptr()<span> </span><span>as</span><span> </span><span>*</span><span>mut</span><span> </span>libc::c_void,<span> 
</span><span>        </span><span>8</span><span> </span><span>as</span><span> </span><span>usize</span>,<span>
</span><span>        </span>data.len()<span> </span><span>as</span><span> </span><span>usize</span>,<span>
</span><span>        </span>file,<span>
</span><span>    </span>);<span>
</span><span></span>}<span>
</span></code></pre></div>
</figure>
<p>Invoking <code>/proc/self/fd/&lt;fd&gt;</code> as a child process from the parent that created it is enough to run your binary.</p>
<figure>
<div><pre><code data-lang="rust"><span>let</span><span> </span>output<span> </span><span>=</span><span> </span>Command::new(format<span>!</span>(<span>"/proc/self/fd/{}"</span>,<span> </span>fd))<span>
</span><span>    </span>.args(args)<span>
</span><span>    </span>.stdin(std::process::Stdio::inherit())<span>
</span><span>    </span>.stdout(std::process::Stdio::inherit())<span>
</span><span>    </span>.stderr(std::process::Stdio::inherit())<span>
</span><span>    </span>.spawn();<span>
</span></code></pre></div>
</figure>
<p>Given these building blocks, I wrote <a href="https://github.com/djhworld/pngrun">pngrun</a> to run the images. It essentially…</p>
<ol>
<li>Accepts an image that has had our binary embedded in it from the steganography tool, and any arguments</li>
<li>Decodes it (i.e. extracts and re-assembles the bytes)</li>
<li>Creates an in-memory file using <code>memfd_create</code></li>
<li>Puts the bytes of the binary into the in-memory file</li>
<li>Invokes the file <code>/proc/self/fd/&lt;fd&gt;</code> as a child process, passing any arguments from the parent</li>
</ol>
<p>So you can run it like this</p>
<figure>
<div><pre><code data-lang="bash">$ pngrun htop.png
&lt;htop output&gt;
$ pngrun go.png run main.go
Hello world!</code></pre></div>
</figure>
<p>Once <code>pngrun</code> exits the in-memory file is destroyed.</p>
<h2 id="binfmt-misc">binfmt_misc</h2>
<p>It’s annoying having to type <code>pngrun</code> every time though, so my last cheap trick to this pointless gimmick was to use <a href="https://en.wikipedia.org/wiki/Binfmt_misc">binfmt_misc</a>, a system that allows you to “execute” files based on its file types. I think it was mainly designed for interpreters/virtual machines, like Java. So instead of typing <code>java -jar my-jar.jar</code> you can just type <code>./my-jar.jar</code> and it will invoke the <code>java</code> process to run your JAR. The caveat is your file <code>my-jar.jar</code> needs to be marked as executable first.</p>
<p>So adding an entry to binfmt_misc for <code>pngrun</code> to attempt to run any <code>png</code> files that have the <code>x</code> flag set was as simple as</p>
<figure>
<div><pre><code data-lang="bash">$ cat /etc/binfmt.d/pngrun.conf
:ExecutablePNG:E::png::/home/me/bin/pngrun:
$ sudo systemctl restart binfmt.d
$ chmod +x htop.png
$ ./htop.png
&lt;output&gt;</code></pre></div>
</figure>
<h2 id="what-s-the-point">What’s the point</h2>
<p>Well, there isn’t one really. I was seduced by the idea of making PNG images run programs and got a bit carried away with it, but it was fun none the less. There’s something amusing to me about distributing programs as an image, remember the ridiculous cardboard boxes PC software used to come in with artwork on the front, why not bring that back! (lets not)</p>
<p>It’s really dumb though and comes with a lot of caveats that make it completely pointless and impractical, the main one being needing the stupid <code>pngrun</code> program on your machine. But I also noticed some weird stuff around programs like <code>clang</code>. I encoded it into this fun LLVM logo and while it runs OK, it fails when you try to compile something.</p>
<figure>
<a href="https://djharper.dev/img/DragonMedium.png"><img src="https://djharper.dev/img/DragonMedium.png" title="Clang/LLVM logo"></a>
</figure>
<figure>
<div><pre><code data-lang="bash">$ ./clang.png --version
clang version <span>11</span>.0.0 <span>(</span>Fedora <span>11</span>.0.0-2.fc33<span>)</span>
Target: x86_64-unknown-linux-gnu
Thread model: posix
InstalledDir: /proc/self/fd
$ ./clang.png main.c
error: unable to execute command: Executable <span>""</span> doesn<span>'</span>t exist!</code></pre></div>
</figure>
<p>This is probably a product of the anonymous file thing, which can probably be overcome if I could be bothered to investigate.</p>
<h3 id="additional-reasons-why-this-is-dumb">Additional reasons why this is dumb</h3>
<p>A lot of binaries are quite large, and given the constraints of needing to fit them into an image, sometimes these need to be <em>big</em>, meaning you end up with comically large files.</p>
<p>Also most software isn’t just one executable so the dream of just distributing a PNG kinda falls flat for more complex software like games.</p>
<h2 id="conclusion">Conclusion</h2>
<p>This is probably the dumbest project I’ve worked on all year but it’s been fun, I’ve learned about Steganography, <code>memfd_create</code>, <code>binfmt_misc</code> and played a little more with Rust.</p>
</article>
</div></div>]]>
            </description>
            <link>https://djharper.dev/post/2020/12/26/executable-pngs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25543191</guid>
            <pubDate>Sat, 26 Dec 2020 13:04:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Manga Guide to Lisp]]>
            </title>
            <description>
<![CDATA[
Score 131 | Comments 13 (<a href="https://news.ycombinator.com/item?id=25541919">thread link</a>) | @joubert
<br/>
December 25, 2020 | http://lambda.bugyo.tk/cdr/mwl/ | <a href="https://web.archive.org/web/*/http://lambda.bugyo.tk/cdr/mwl/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://lambda.bugyo.tk/cdr/mwl/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25541919</guid>
            <pubDate>Sat, 26 Dec 2020 06:57:48 GMT</pubDate>
        </item>
    </channel>
</rss>
