<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Fri, 02 Oct 2020 16:28:14 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Fri, 02 Oct 2020 16:28:14 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Ontario doctors sign letter to Premier advising against sweeping lockdowns]]>
            </title>
            <description>
<![CDATA[
Score 103 | Comments 148 (<a href="https://news.ycombinator.com/item?id=24645821">thread link</a>) | @mrfusion
<br/>
September 30, 2020 | https://beta.ctvnews.ca/local/ottawa/2020/9/30/1_5126193.html | <a href="https://web.archive.org/web/*/https://beta.ctvnews.ca/local/ottawa/2020/9/30/1_5126193.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>



<div>
    
        <p>Published Sept. 30, 2020 9:40 a.m. ET</p>
        <p>Updated  Sept. 30, 2020 7:26 p.m. ET</p>
    
</div>



  


    
        
        
    
    
    <amp-iframe resizable="" width="16" height="17" layout="responsive" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation" allowfullscreen="" frameborder="0" src="https://ampvideo.ctvnews.ca/content/ctvnews/en/local/ottawa/2020/9/30/1_5126193.vidi.root-responsivegrid-vidicomponent.html?preventDefault=true">
        
        <p>Click to Expand</p>
    </amp-iframe>





    <p>OTTAWA -- 	Twenty-one Ontario doctors have signed a joint letter to Premier Doug Ford, urging him not to issue a new lockdown this fall because of rising COVID-19 case numbers.</p><p>	Daily numbers of new cases have risen dramatically in recent days, with Ontario recording <a href="https://toronto.ctvnews.ca/new-covid-19-cases-in-ontario-reach-highest-mark-ever-1.5122863" target="_blank">700 new cases of COVID-19 on Monday</a> – the highest number of new cases recorded in a single day.</p><p>	However, the 21 doctors who signed the letter to the premier say another provincewide lockdown—similar to what was in place in the spring—would not be helpful.</p><ul>	<li>		<a href="#Full letter"><i>Read the full letter below</i></a></li></ul><p>	"We are writing this letter in support of the governments’ plan to use a tactical localized approach, rather than sweeping new lockdown measures, to deal with the increasing COVID case numbers in Ontario," the letter says.&nbsp;</p><p>	"Lockdowns have been shown not to eliminate the virus. While they slow the spread of the virus, this only lasts as long as the lockdown lasts. This creates a situation where there is no way to end the lockdown, and society cannot move forward in vitally important ways including in the health sector, the economy and other critically important instrumental goods including education, recreation, and healthy human social interactions."</p><p>	Speaking on Newstalk 580 CFRA's "The Morning Rush with Bill Carroll" in Ottawa, CTV's infectious disease specialist Dr. Neil Rau—a signatory of the letter—pointed to two data points to consider when looking at the spread of COVID-19.</p><p>	"We're reacting to increased aggregate case numbers, but the percentage positive is not really as bad as it used to be," he said. "We're testing more people, so we're finding more cases […] We're driving our numbers up, it's worse than it was in the summer, but it's not what it was last winter and life has to go on."</p><ul>	<li>		<a href="https://www.iheartradio.ca/580-cfra/podcasts/the-morning-rush-dr-neil-rau-interview-why-we-don-t-want-another-lockdown-1.13612912?mode=Article" target="_blank"><strong>LISTEN NOW: "The Morning Rush": Dr. Neil Rau - Why we don't want another lockdown</strong></a></li></ul><p>	Monday's 700 cases in Ontario came from 41,111 total tests, for a positive percentage rate of 1.7 per cent. On April 24, <a href="https://toronto.ctvnews.ca/highest-number-of-new-covid-19-cases-in-a-single-day-reported-by-ontario-health-officials-1.4910216" target="_blank">the previous watermark of 640 new cases in a single day</a>, the result came from 12,295 tests, for a positive percentage rate of 5.2 per cent.</p><p>	Testing capacity was lower in the spring than it is now, and testing criteria has changed over time; however, Dr. Rau and the other signatories of the letter said the increasing case numbers are not leading to unmanageable levels of hospitalizations.</p><p>	"In Ontario and other parts of the world, such as the European Union, increasing case loads are not necessarily translating into unmanageable levels of hospitalizations and ICU admissions," the letter says.</p><p>	The letter also points to other health impacts linked to the lockdown.</p><p>	"Hard data now exist showing the significant negative health effects shutting down society has caused. Overdoses have risen 40% in some jurisdictions. Extensive morbidity has been experienced by those whose surgery has been cancelled, and the ramifications for cancer patients whose diagnostic testing was delayed has yet to be determined," the letter states.</p><p>	"Economic harms are health harms," Dr. Rau told CFRA. "It sounds horrible to say, but it's true. Health is wealth. We all know this."</p><h2>	<strong>LETTER POINTS TO DISAGREEMENT AMONG HEALTH PROFESSIONALS</strong></h2><p>	Other Ontario health professionals have been arguing for increased restrictions as cases rise.</p><p>	Last week, the Ontario Hospital Association released a letter signed by 38 health professionals which <a href="https://ottawa.ctvnews.ca/ontario-hospital-association-calls-for-return-to-restrictions-on-non-essential-businesses-1.5119832" target="_blank">called for immediate restrictions to be re-imposed on non-essential businesses</a>, such as gyms, dine-in restaurants and bars, nightclubs, and theatres. It also calls on restrictions on other places where people can gather, such as places of worship.</p><p>	The letter from the OHA said regions where the speed of transmission was underestimated are “now facing the consequence of increased hospitalization rates, including a rise in intensive care unit (ICU) admissions and more deaths.”</p><p>	Hospitalizations in Ontario have been increasing, but have not yet reached the same level that was seen in the spring.</p><p>	According to <a href="https://covid-19.ontario.ca/data" target="_blank">data from the Ontario government</a>, there were 128 people in hospital in Ontario with COVID-19 complications on Monday—the day 700 new cases were recorded—up from 65 a week before; however, on April 24—when 640 new cases were recorded—government data shows that there were 910 people in hospital. The peak for hospitalizations in Ontario came in May, when there were days when more than 1,000 people were hospitalized. That number steadily decreased from May through the summer before it began going up again in September.</p><p>	Speaking on CTV Morning Live Ottawa, infectious disease specialist Dr. Abdu Sharkawy suggested t<a href="https://ottawa.ctvnews.ca/video?clipId=2045684" target="_blank">emporary restrictions on gathering would help curb the spread of COVID-19</a>.&nbsp;</p><p>	"We don't want to see our hospitals overwhelmed," he said. "We're still waiting for flu season and a whole bunch of other respiratory viruses to hit us and our capacity to be challenged. We don't want that to happen. We need everybody to try and simplify their lives and minimize anything that's non-essential."</p><p>	Dr. Sharkawy said regions where cases are rapidly rising may need to impose new restrictions to get the spread of the virus under control.</p><p>	"I think it's abundantly clear that, particularly in hot spots like Ottawa, Toronto and Peel region, the situation is not well controlled," he said. "Sometimes you need blunt instruments, even if they're temporary in nature, to make sure that you curtail the spread of this virus because it gets away from us a lot more quickly than many of us can anticipate sometimes."</p><p>	Dr. Sharkawy suggested hot spots follow the lead of Quebec, which imposed <a href="https://montreal.ctvnews.ca/life-in-the-red-zone-here-s-what-you-can-and-can-t-do-1.5125093" target="_blank">harsh restrictions on three areas in the province</a>, including Montreal and Quebec City, banning private gatherings and closing bars and restaurant dining rooms.</p><p>	"I think we should do it now," Dr. Sharkawy said of Ontario. "I think we all need to adopt an attitude and an approach that recognizes that we have to do what's absolutely necessary to keep everybody safe."</p><h2>	<strong>FULL LETTER FROM ONTARIO DOCTORS TO THE PREMIER</strong></h2><p>	Dear Premier Ford,</p><p>	We are writing this letter in support of the governments’ plan to use a tactical localized approach, rather than sweeping new lockdown measures, to deal with the increasing COVID case numbers in Ontario. Lockdowns have been shown not to eliminate the virus. While they slow the spread of the virus, this only lasts as long as the lockdown lasts. This creates a situation where there is no way to end the lockdown, and society cannot move forward in vitally important ways including in the health sector, the economy and other critically important instrumental goods including education, recreation, and healthy human social interactions.</p><p>	In Ontario the increase in cases at this time are in people under 60 years of age who are unlikely to become very ill. At the peak of the pandemic in Ontario in mid-April, 56% of cases were in ≥60 year olds, now in Sept only 14% of cases are in ≥60 year olds. In Ontario and other parts of the world, such as the European Union, increasing case loads are not necessarily translating into unmanageable levels of hospitalizations and ICU admissions. This is not a result of a lag in reporting of severe and fatal cases. While we understand the concerns that these cases could spill into vulnerable communities, we also need to balance the actual risk. As the virus circulates at manageable levels within the community, we need to continue the gains we have made in the protection of the vulnerable in long-term care and retirement institutions, and continue to educate other people about their individual risk, so that they can observe appropriate protective measures.</p><p>	Lockdowns have costs that have, to this point, not been included in the consideration of further measures. A full accounting of the implications on health and well-being must be included in the models, and be brought forward for public debate. Hard data now exist showing the significant negative health effects shutting down society has caused. Overdoses have risen 40% in some jurisdictions. Extensive morbidity has been experienced by those whose surgery has been cancelled, and the ramifications for cancer patients whose diagnostic testing was delayed has yet to be determined. A huge concern is the implication of closure of schools, and the ongoing reluctance we have seen in the large urban centers of sending children back to the classroom due to safety concerns. Global data clearly now show that children have an extremely low risk of serious illness, but they are disproportionately harmed by precautions. Children’s rights to societal care, mental health support and education must be protected. This cannot be achieved with ongoing or rotating lockdown.</p><p>	The invitation and involvement of other health experts to advise the government’s response beside individuals in Public Health and Infectious Diseases in addition to leaders in the business, securities and arts communities is essential. We also call for increased open debate, in the public forum, that hears voices from outside the medical and public health communities, in order to consider all points of view from society. This is a fundamental principle upon which democratic societies are built. All stakeholders should have an equal right to participation in public discourse when it comes to setting such fundamental and sweeping societal interventions.</p><p>	All have the right to feel their voices have been heard, and moreover to ensure factual credible data is openly debated, in contrast to the personal and political slants that have had apparent significant impacts on the management of the virus to date. Our society has borne enormous pain over the past 6 months. It’s time to do something different.</p><p>	Sincerely,</p><p>	Jane Batt MD, PhD, FRCPC. Respirologist, Associate Professor, Department of …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://beta.ctvnews.ca/local/ottawa/2020/9/30/1_5126193.html">https://beta.ctvnews.ca/local/ottawa/2020/9/30/1_5126193.html</a></em></p>]]>
            </description>
            <link>https://beta.ctvnews.ca/local/ottawa/2020/9/30/1_5126193.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24645821</guid>
            <pubDate>Thu, 01 Oct 2020 00:23:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A housing industry of endless one-offs is holding our society back]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 133 (<a href="https://news.ycombinator.com/item?id=24645525">thread link</a>) | @jseliger
<br/>
September 30, 2020 | https://blokable.com/news/the-housing-market-is-building-snowflakes-an-endless-series-of-one-offs/ | <a href="https://web.archive.org/web/*/https://blokable.com/news/the-housing-market-is-building-snowflakes-an-endless-series-of-one-offs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2><strong>By Aaron Holm and Nelson Del Rio,<br>Co-CEOs, Blokable Inc.</strong></h2><h2>The following post breaks down the high cost of building housing as part of a series exploring the root causes of the U.S. housing crisis and how private and public sector collaboration can chart a different course.&nbsp;</h2><figure><img width="1200" height="800" src="data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjA0OCAxMzY0IiB3aWR0aD0iMjA0OCIgaGVpZ2h0PSIxMzY0IiBkYXRhLXU9IiUyRndwLWNvbnRlbnQlMkZ1cGxvYWRzJTJGMjAyMCUyRjA5JTJGQmxvZy0yLWltYWdlLTIwNDh4MTM2NC5qcGciIGRhdGEtdz0iMjA0OCIgZGF0YS1oPSIxMzY0IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPjwvc3ZnPg==" data-spai="1" alt="" sizes="(max-width: 1200px) 100vw, 1200px"></figure><p>In mid-2018 we met with Washington State Governor Jay Inslee to discuss the insatiable need for affordable housing in the Pacific Northwest. We gave him a tour of Blokable’s prototype factory in Vancouver, Wash., and shared our R&amp;D work to reimagine how housing is built. Afterward, we drove up to Seattle in a rented Nissan Maxima, wondering aloud what it would cost to build our rental car from scratch in a driveway — exactly how nearly all housing is built today.&nbsp;&nbsp;&nbsp;</p><p>We would have to design, engineer, and fabricate all of the car’s systems and components, specify and source the materials, identify the regulatory requirements and work with different agencies to test our systems and sign off on safety and environmental requirements, create a working set of engineering drawings to track the build, order the equipment necessary to complete the assembly, and hire at least a small team of people to put the car together. A car that retails for just under $35,000 would cost tens of millions of dollars to build, and there would be no guarantees of quality and reliability.&nbsp;</p><p>Every time a new residential real estate project appears on the landscape, it’s a bespoke process that can directly involve hundreds of people, including a developer and a general contractor, various architects and engineers, and the investors who are funding the project. For each participant in the process, the singular goal is to extract a profit from that specific patch of dirt, and their profits are circumscribed by the value of the land, the applicable building regulations, and the prevailing labor and capital costs.&nbsp;</p><p>The result of this one-off approach is soaring project costs that make housing simply unaffordable to most people in many parts of the U.S.. Conventional housing development is like building a snowflake every time. And if the glut of empty luxury condo towers in downtown San Francisco is any indication, many of these snowflake projects are indeed melting as soon as they touch the ground.&nbsp;</p><p>How did this one-off approach to development take shape? Everything from ovens to stereos were all once clunky prototypes built as one-offs in the same location as their eventual use. Over time with innovation, standardization, and market demand, they evolved into products. In the early days of the automobile and aviation industries, prototypes and projects were built at high cost and yielded low quality results that resembled the current market products in their most basic functionality: they could drive and fly. Early automobile and airplane prototypes were unsafe and expensive. But through investment in product design, engineering, prototyping, and manufacturing, these prototypes eventually evolved into products. Increasingly stable designs and specifications enabled greater standardization, repeatability, and mass production resulting in lower costs, higher quality, and broader distribution.&nbsp;</p><p>Coupled with clear market demand, this standardization led to the formation of entire industries to build roads and airports, manufacture tires, test safety under federal guidelines, and so on. If you visit the automotive and aviation manufacturing hubs around Detroit and Seattle you’ll find vibrant supply chains competing for business and investing in innovation to provide better products and services. Continuously improving engines, seats, windshields, and bathrooms. All of this activity creates ever-improving products and fierce competition for performance, quality, and price.&nbsp;&nbsp;</p><p>If we compare product manufacturing in the automotive and aviation industries to how we build housing — whether it is an Accessory Dwelling Unit (ADU), single family home, multi-family apartment building, or a high rise — the steps in the process are largely the same. To simplify the housing development process, let’s assume the land is entitled, there are no environmental mitigation issues, financing is secured, and development will not be opposed by regulatory agencies or local city council. What does it take to build a snowflake?</p><figure><img width="1200" height="800" src="data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjA0OCAxMzY0IiB3aWR0aD0iMjA0OCIgaGVpZ2h0PSIxMzY0IiBkYXRhLXU9IiUyRndwLWNvbnRlbnQlMkZ1cGxvYWRzJTJGMjAyMCUyRjA5JTJGQmxvZy0yLWJvZHktaW1hZ2UtMjA0OHgxMzY0LmpwZyIgZGF0YS13PSIyMDQ4IiBkYXRhLWg9IjEzNjQiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyI+PC9zdmc+" data-spai="1" alt="Housing creation is an endless series of one-offs" sizes="(max-width: 1200px) 100vw, 1200px"><figcaption><em>Conventional housing development is like building a snowflake every time.</em></figcaption></figure><p>Let’s look at the absolute bare minimum of steps in the process from the perspective of the developer. Broadly speaking, the developer identifies and ties up the site, conducts preliminary site review and discussions with impacted parties, manages entitlements, financing, and the project approval process for the site, oversees all building and owns the project along with any equity investors they have brought in to finance the deal. With respect to the building process itself, the developer will partner with an architect to work up a site massing and design that will satisfy the intended program — the mix of units, floorplans, common spaces, revenue generating and non-revenue generating space — as well as the code requirements for the building and the site. Once the basic architecture is in place, the project heads over to engineers, which are typically separate firms with separate contracts, costs, regulatory oversight, and liability, to specify structural engineering, MEP (mechanical, electrical, plumbing), and site and offsite engineering.&nbsp;</p><p>With the initial design and engineering complete, the developer sends a construction set of drawings to a general contractor (GC) for final pricing. The GC will take the specifications and build out a schedule and budget to determine how much work they intend to do themselves (self-perform) vs. how much work they will contract out to sub-contractors (subs). The GC will oversee all of the work necessary to build this custom-designed and engineered project on-site, including civil, foundation, pulling utilities, framing, rough-in and waterproofing, siding and cladding, roofing, windows and doors, MEP, paint and trim, fixtures and finishes, and ultimately certificate of occupancy.&nbsp; It is important to note that at this stage the GC’s quote is just an estimate. We haven’t built anything yet.</p><p>With approved drawings, financing, budget, and schedule in hand, the developer can start the snowflake build. Every step listed in the paragraph above must be completed by the corresponding specialists, and getting the work done on schedule is much more of an art than a science. Each contractor and subcontractor has their own contractual obligations, risks, and liability. Getting to the certificate of occupancy means the developer has navigated the process and can now bring in buyers or renters to start paying off the decades of debt that were secured to finance the build.&nbsp; When the developer moves on to the next project, all of the steps must be performed again, without exception. The finished project may be beautiful, energy efficient, or last 100 years, but it will still be a one-off.&nbsp;&nbsp;</p><p>All of this work is done for every project every time, regardless of size. A home or apartment is not more complicated than a car or plane, and while the unique attributes of individual sites and real estate do add challenges to repeatability, it is possible to decouple the building from the dirt.</p><p>We can’t be surprised that building costs for new housing continue to escalate. We can’t be surprised that it’s even more expensive to create affordable housing. Yet we continue to shrug our shoulders and say, “That’s just how it is.” We dig around the edges of the problem, foraging for scraps by looking for cost savings in commodities, underpaying labor, cutting corners on quality and performance, and building on cheaper land further and further from work and community.&nbsp;</p><p>Housing development is antiquated and the only group benefitting is the real estate development and building industry, who in fact have every incentive to restrict the supply. We’re making Version 1 of the oven, stereo, car, and plane over and over again, in a housing market that is chronically under-served. The failure to build adequate housing has generational effects on health, education, and opportunity.&nbsp;</p><p>There has to be a better way. We have to re-imagine the housing market and build better. More on that to come in our next post.</p></div></div></div>]]>
            </description>
            <link>https://blokable.com/news/the-housing-market-is-building-snowflakes-an-endless-series-of-one-offs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24645525</guid>
            <pubDate>Wed, 30 Sep 2020 23:48:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DigitalOcean's Hacktoberfest Is Hurting Open Source]]>
            </title>
            <description>
<![CDATA[
Score 671 | Comments 308 (<a href="https://news.ycombinator.com/item?id=24643894">thread link</a>) | @domenicd
<br/>
September 30, 2020 | https://blog.domenic.me/hacktoberfest/ | <a href="https://web.archive.org/web/*/https://blog.domenic.me/hacktoberfest/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>For the last couple of years, <a href="https://www.digitalocean.com/">DigitalOcean</a> has run
<a href="https://hacktoberfest.digitalocean.com/">Hacktoberfest</a>, which purports to “support open source” by giving free
t-shirts to people who send pull requests to open source repositories.</p>

<p>In reality, <strong>Hacktoberfest is a corporate-sponsored distributed denial of service attack against the open source
maintainer community</strong>.</p>

<p>So far today, on <a href="https://github.com/whatwg/html/pulls?q=is%3Apr+is%3Aclosed+label%3Aspam">a single repository</a>, myself
and fellow maintainers have closed 11 spam pull requests. Each of these generates notifications, often email, to the 485
watchers of the repository. And each of them requires maintainer time to visit the pull request page, evaluate its
spamminess, close it, tag it as spam, lock the thread to prevent further spam comments, and then report the spammer to
GitHub in the hopes of stopping their time-wasting rampage.</p>

<p>The rate of spam pull requests is, at this time, around four per hour. <em>And it’s not even October yet in my timezone.</em></p>

<p><img src="https://blog.domenic.me/images/hacktoberfest-spam-listing.png" alt="A screenshot showing a spam query for the whatwg/html repository, which is at this time up to 14 spam PRs"></p>

<p>Myself and other maintainers of the whatwg/html repository are not alone in suffering this deluge.
<a href="https://twitter.com/gravitystorm/status/1311386082982924289">My tweet</a> got commiseration from
<a href="https://mobile.twitter.com/gravitystorm/status/1311386082982924289">OpenStreetMap, phpMyAdmin</a>,
<a href="https://mobile.twitter.com/ulmerleben/status/1311378655231332355">PubCSS</a>,
<a href="https://mobile.twitter.com/JakeDChampion/status/1311389420638138370">GitHub, the Financial Times</a>,
<a href="https://twitter.com/slicknet/status/1311377444188770312">ESLint</a>, a
<a href="https://mobile.twitter.com/zekjur/status/1311411780162326531">computer club website</a>, and
<a href="https://mobile.twitter.com/juliusvolz/status/1311412919196844038">a conference website</a>, just within the first couple
of hours. Since then a dedicated account “<a href="https://twitter.com/shitoberfest">@shitoberfest</a>” has arisen to document the
barrage. Some <a href="https://github.com/search?q=is%3Apr+%22improve+docs%22+created%3A%3E2020-09-29&amp;type=Issues">cursory</a>
<a href="https://github.com/search?q=is%3Apr+label%3Ainvalid+created%3A%3E2020-09-29&amp;type=Issues">searches</a> show thousands of
spam pull requests, and rising.</p>

<p>DigitalOcean seems to be aware that they have a spam problem. Their solution, per their
<a href="https://hacktoberfest.digitalocean.com/faq">FAQ</a>, is to put the burden solely on the shoulders of maintainers. If we go
out of our way to tag a contribution as spam, then… we slightly decrease the chance of the spammer getting their free
t-shirt. In reality, the spammer will just keep going, submitting more pull requests to more repositories, until they
finally find a repository where the maintainer doesn’t bother to tag the PR as spam, or where the maintainer isn’t
available during the seven-day window DigitalOcean uses for spam-tracking.</p>

<p>To be clear, myself and my fellow maintainers did not ask for this. This is not an opt-in situation. If your open source
project is public on GitHub, DigitalOcean will incentivize people to spam you. There is no consent involved. Either we
contribute to DigitalOcean’s marketing project, or,
<a href="https://twitter.com/SudoFox/status/1311431141702819840">they suggest, we should quit open source</a>.</p>

<p>Hacktoberfest does not support open source. Instead, it drives open source maintainers even closer to
<a href="https://www.google.com/search?q=open+source+burnout">burnout</a>.</p>

<p><img src="https://blog.domenic.me/images/hacktoberfest-spam-pr.png" alt="A screenshot of a spam PR which adds the heading &quot;Great Work&quot; to the HTML Standard README"></p>

<h2 id="what-can-we-do">What can we do?</h2>

<p>My most fervent hope is that DigitalOcean will see the harm they are doing to the open source community, and put an end
to Hacktoberfest. I hope they can do it as soon as possible, before October becomes another lowpoint in the hell-year
that is 2020. In 2021, they could consider relaunching it as an opt-in project, where maintainers consent on a
per-repository basis to deal with such t-shirt–incentivized contributors.</p>

<p>To protect ourselves, maintainers have a few options. First, you can take the feeble step of ensuring that any spam
against your repositories doesn’t contribute to the spammer’s “t-shirt points”, by tagging pull requests with a “spam”
label, and <a href="https://twitter.com/MattIPv4/status/1311390498888781824">emailing hacktoberfest@digitalocean.com</a>.
DigitalOcean themselves, however, admit that
<a href="https://twitter.com/MattIPv4/status/1311390054334554113">this won’t stop the problem they’ve unleashed on us</a>. But
maybe it will contribute to the <a href="https://github.com/MattIPv4/hacktoberfest-data">metrics</a> they collect, which last year
showed that “only” 3,712 pull requests were labeled as spam by project maintainers.</p>

<p>If you’re comfortable cutting off genuine contributions from new users, you can try enabling GitHub’s
<a href="https://docs.github.com/en/free-pro-team@latest/github/building-a-strong-community/limiting-interactions-in-your-repository">interaction limits</a>.
However, <del>you have to do this every 24 hours, and</del> it has the drawback of also disabling issue creation and
comments. <ins>Update: GitHub has made the limit configurable, and has
<a href="https://twitter.com/github/status/1311772722234560517">a nice cheeky announcement tweet</a> zooming in on the “1 month”
option.</ins></p>

<p>Another promising route would be if GitHub would cut off DigitalOcean’s API access, as
<a href="https://twitter.com/__agwa/status/1311399074814472194">Andrew Ayer has suggested</a>. It’s not clear whether DigitalOcean
is committing a terms of service violation that would support such measures. But they’re certainly making GitHub a
less-pleasant place to be, and I hope GitHub can think seriously about how to discourage such corporate-sponsored
attacks on the open source community.</p>

<p>Finally, and most importantly, we can remember that this is how DigitalOcean treats the open source maintainer
community, and stay away from their products going forward. Although we’ve enjoyed using them for hosting the
<a href="https://whatwg.org/">WHATWG</a> standards organization, this kind of behavior is not something we want to support, so
we’re starting to investigate alternatives.</p>

  </div>

</article></div>]]>
            </description>
            <link>https://blog.domenic.me/hacktoberfest/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24643894</guid>
            <pubDate>Wed, 30 Sep 2020 21:10:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Defer Reference Implementation for C]]>
            </title>
            <description>
<![CDATA[
Score 72 | Comments 50 (<a href="https://news.ycombinator.com/item?id=24643034">thread link</a>) | @cyber1
<br/>
September 30, 2020 | https://gustedt.gitlabpages.inria.fr/defer/ | <a href="https://web.archive.org/web/*/https://gustedt.gitlabpages.inria.fr/defer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="text-1-1">
<p>
In the following code snippet we
have one <i>guarded block</i> and three <i>deferred statements</i>.
</p>

<div>
<pre>guard {
  <span>void</span> * <span>const</span> <span>p</span> = malloc(25);
  <span>if</span> (<span>!</span>p) <span>break</span>;
  <span>defer</span> <span>free</span>(p);

  <span>void</span> * <span>const</span> <span>q</span> = malloc(25);
  <span>if</span> (<span>!</span>q) <span>break</span>;
  <span>defer</span> <span>free</span>(q);

  <span>if</span> (mtx_lock(&amp;mut)==thrd_error) <span>break</span>;
  <span>defer</span> <span>mtx_unlock</span>(&amp;mut);

  <span>// </span><span>all resources acquired</span>
}

</pre>
</div>

<p>
The idea is that we indicate with a <b><code>defer</code></b> keyword that the
statement, e.g a call to <b><code>free</code></b>, is only to be executed at the end of
the guarded block, and, that we want this action to happen
unconditionally in which way ever the guarded block is left.  For the
three deferred statements together it says that they should be
executed in the inverse order than they were encountered. So the
control flow for this code example can be visualized as follows:
</p>



<p><img src="https://gustedt.gitlabpages.inria.fr/defer/defer-image.png" alt="defer-image.png">
</p>

<p>
Here, the dashed lines represent circumstancial control flow that
might arise when some resources are not available or when the
execution is interrupted by a signal.
</p>

<p>
This new technique has at least two advantages to commonly used <code>C</code> or
<code>C++</code> techniques:
</p>

<dl>
<dt>proximity</dt><dd>The cleanup code (<code>free</code> or <code>mtx_unlock</code>) is coded
close to the place where its need arises.</dd>

<dt>visibility</dt><dd>The cleanup code is not hidden in some previously
defined function (such as for <code>atexit</code> handlers) or
constructor/destructor pairs (<code>C++</code>)</dd>
</dl>


<p>
For normal control flow (without intermediate <b><code>return</code></b>, <code>exit</code>, …)
code with similar properties can be coded with existing tools. The
above is equivalent to something like the following
</p>

<div>
<pre>{
   <span>void</span> * <span>const</span> <span>p</span> = malloc(25);
   <span>if</span> (<span>!</span>p) <span>goto</span> <span>DEFER0</span>;
   <span>if</span> (<span>false</span>) {
     <span>DEFER1</span>:
       free(p);
       <span>goto</span> <span>DEFER0</span>;
   }

   <span>void</span> * <span>const</span> <span>q</span> = malloc(25);
   <span>if</span> (<span>!</span>q) <span>goto</span> <span>DEFER1</span>;

   <span>if</span> (<span>false</span>) {
     <span>DEFER2</span>:
       free(q);
       <span>goto</span> <span>DEFER1</span>;
   }

   <span>if</span> (mtx_lock(&amp;mut)==thrd_error) <span>goto</span> <span>DEFER2</span>;

   <span>if</span> (<span>false</span>) {
     <span>DEFER3</span>:
       mtx_unlock(&amp;mut);
       <span>goto</span> <span>DEFER2</span>;
   }

   <span>// </span><span>all resources acquired</span>

   <span>goto</span> <span>DEFER3</span>;
   <span>DEFER0</span>:;
}

</pre>
</div>

<p>
Here, the <b><code>if(false)</code></b> clauses guarantee that the deferred statements
are jumped over when they are first met, and the labels and <b><code>goto</code></b>
statements implement the hops from back to front to execute the
deferred statements eventually.
</p>

<p>
Obviously, most <code>C</code> programmers would not code like this but they
would prefer to write down a <i>linearization</i> of the above, which is a
quite common idiom for cleanup handling in <code>C</code>:
</p>

<div>
<pre>{
   <span>void</span> * <span>const</span> <span>p</span> = malloc(25);
   <span>if</span> (<span>!</span>p) <span>goto</span> <span>DEFER0</span>;

   <span>void</span>*<span>const</span> <span>q</span> = malloc(25);
   <span>if</span> (<span>!</span>q) <span>goto</span> <span>DEFER1</span>;

   <span>if</span> (mtx_lock(&amp;mut)==thrd_error) <span>goto</span> <span>DEFER2</span>;

   <span>// </span><span>all resources acquired</span>

   mtx_unlock(&amp;mut);

 <span>DEFER2</span>:
   free(q);
 <span>DEFER1</span>:
   free(p);
 <span>DEFER0</span>:;
}

</pre>
</div>

<p>
This has the advantage of only making the circumstantial control flow
explicit (with three *=goto=) but it does that for the price of
proximity; the cleanup code is far from the place where its need
arises.
</p>

<p>
Nevertheless, even this linearization needs some form of naming
convention for the labels. For more complicated code the maintenance
of these jumps can be tricky and prone to errors.  This shows another
advantage of the <a href="#org63e5a5c"><code>defer</code></a> approach:
</p>

<dl>
<dt>maintainability</dt><dd>The cleanup specification is not dependent on
arbitrary naming such as labels (<code>C</code>) or RAII classes
(<code>C++</code>) and does not change when <a href="#org63e5a5c"><code>defer</code></a> or <b><code>break</code></b>
statements are added or removed.</dd>
</dl>

<p>
Another important property that is much more difficult to implement in
<code>C</code> (and that needs <b><code>try/catch</code></b> blocks in <code>C++</code>) is that <b>all</b> exits
from the guarded block are detected and acted upon: <b><code>break</code></b>, <b><code>return</code></b>,
<a href="#org18b8cc4"><code>thrd_exit</code></a>, <a href="#org9db677d"><code>exit</code></a>, <a href="#org7f6c106"><code>panic</code></a>, or
an interruption by a signal. That is, unless there are nasal deamons
flying around, we have a forth important property
</p>


<dl>
<dt>robustness</dt><dd>Any deferred statement is guaranteed to be executed
eventually.</dd>
</dl>

<p>
This is different from <code>C++</code>'s handling of destructors, which are only
guaranteed to be executed if there is a <b><code>try/catch</code></b> block underneath.
</p>

<p>
This principle of deferred execution extends to nested
guarded blocks in a natural way, even if they are stacked in
different function calls.
</p>
</div></div>]]>
            </description>
            <link>https://gustedt.gitlabpages.inria.fr/defer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24643034</guid>
            <pubDate>Wed, 30 Sep 2020 19:55:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Energy Efficiency across Programming Languages [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 173 | Comments 141 (<a href="https://news.ycombinator.com/item?id=24642134">thread link</a>) | @Malfunction92
<br/>
September 30, 2020 | https://greenlab.di.uminho.pt/wp-content/uploads/2017/10/sleFinal.pdf | <a href="https://web.archive.org/web/*/https://greenlab.di.uminho.pt/wp-content/uploads/2017/10/sleFinal.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://greenlab.di.uminho.pt/wp-content/uploads/2017/10/sleFinal.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24642134</guid>
            <pubDate>Wed, 30 Sep 2020 18:43:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why is Snowflake so Valuable?]]>
            </title>
            <description>
<![CDATA[
Score 225 | Comments 145 (<a href="https://news.ycombinator.com/item?id=24641481">thread link</a>) | @malisper
<br/>
September 30, 2020 | https://www.freshpaint.io/blog/why-is-snowflake-so-valuable | <a href="https://web.archive.org/web/*/https://www.freshpaint.io/blog/why-is-snowflake-so-valuable">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Two weeks ago, Snowflake had the largest IPO ever for a software company. On the first day of trading, the stock price doubled, giving Snowflake a market cap of over $60 billion. Snowflake became all that everyone was talking about. There was so much hype, my mom, who doesn't even know what Snowflake is, decided to invest in Snowflake.</p><p>At first glance, the valuation of $60 billion seems absurd. Not only is Snowflake not profitable, having a net loss of $349 million in 2019, but their revenue is also small relative to their valuation. Their revenue over the last 12 months was $403 million. Based on that, their market cap is around 150x their revenue. So why exactly is their market cap so high? Besides revenue and profitability, there are a number of other metrics that investors look at. Compared to similar software businesses, Snowflake has god-like metrics. In this post, I'm going to go through a number of metrics from Snowflake's S-1, explain what the metrics mean, and give context on just how exceptional Snowflake's metrics are.</p><p>The first metric that stands out is Snowflakes 121% year over year growth. To give you a sense of how fantastic it is, you can compare it to the growth rates of other companies at IPO. <a href="https://techcrunch.com/2013/08/24/how-fast-should-you-be-growing/">Institutional Venture Partners looked at how quickly Internet and software companies were growing at IPO</a>.</p><figure><p><img src="https://uploads-ssl.webflow.com/5dad2b1e508f04886d0245c3/5f74c44d240d4de932d463c4_growth1.jpeg" alt="growth1"></p></figure><p>Based on their numbers, only 25% of companies that are between $75M-$500M in annual revenue are growing at just over 60% year over year. Snowflake's growth rate is nearly twice that! Snowflake's revenue was also $403M for the last 12 months, which would put them at the high end of that range. Not only are they growing significantly faster than other companies, but they are already significantly larger!</p><p>For companies that sell software to businesses an important number to look at is their retention rate. For Snowflake, their net retention rate is 158%. You may be asking, how do they have a retention rate over 100%? That's because companies that use Snowflake pay more for Snowflake over time. For every $1 of revenue Snowflake received from their customers a year ago, that same pool of customers are now paying $1.58. That means Snowflake could acquire no new customers, and they would still be doubling revenue every 18 months.</p><p>To compare that to other companies, <a href="https://www.lennyrachitsky.com/p/what-is-good-retention-issue-29">Lenny Rachitsky surveyed a number of industry experts on what they thought good and great net retention would be</a>. On average, for enterprise subscription software, the category Snowflake would fall under, the experts surveyed said 110% net retention would be good and 130% net retention would be great. He also pulled the net retention rates for a number of public companies:</p><ul role="list"><li><strong>Alteryx</strong>: 135% (<a href="https://docs.google.com/spreadsheets/d/1ogELPtct2s6jj9wRBpOgqGUE5k4cO73XXcvqmEZE89M/edit#gid=0">source</a>)</li><li><strong>Fastly</strong>: 130% (<a href="https://www.saastr.com/5-interesting-learnings-from-fastly-as-it-gets-ready-to-ipo/">source</a>)</li><li><strong>Okta</strong>: 124% (<a href="https://docs.google.com/spreadsheets/d/1ogELPtct2s6jj9wRBpOgqGUE5k4cO73XXcvqmEZE89M/edit#gid=0">source</a>)</li><li><strong>Anaplan</strong>: 124% (<a href="https://www.key.com/kco/images/Public_SaaS_Company_Retention_Metrics_2019.pdf">source</a>)</li><li><strong>Workday</strong>: 100%+ (<a href="https://www.workday.com/content/dam/web/en-us/documents/investor/workday-financial-analyst-day-2018.pdf">source</a>)</li><li><strong>ServiceNow</strong>: 97% (<a href="https://www.publiccomps.com/tickers/NOW">source</a>)</li></ul><p>You will notice that Snowflake's net retention rate of 158% is significantly higher than all of these!</p><p>Net promoter score (NPS) is a way of measuring customer satisfaction. It's convenient because it's easy to calculate and boils down customer satisfaction to a single number, making it easy to compare NPS between different companies. To compute NPS, a company performs a survey of their customers. The company asks "On a scale of 0 to 10, how likely are you to recommend this company’s product or service to a friend or a colleague?". Anyone that answers 9 or 10 is deemed a "promoter" of the product, while anyone that answers 6 or less is considered to be a "detractor". To compute the NPS, you take the percentage of users that are promoters and subtract the percentage of users that are detractors. This results in a number between -100 and 100 which is the NPS.</p><p>To give some examples, an NPS of 0 means your company has just as many promoters as detractors, whereas an NPS of 100 means everyone loves your product. Here are the NPS's for a few well known companies according to <a href="https://www.satmetrix.com/infographic/2020-us-consumer-benchmarks/">satmetrix</a>:</p><ul role="list"><li>Apple - 62</li><li>AirBnB - 43</li><li>AT&amp;T - 20</li></ul><p>What is Snowflake's NPS score? It's 71. According to NPS, Snowflake's customers like Snowflake more than Apple's customers like Apple.</p><p>The average Snowflake customer pays Snowflake $165k a year. Average contract value (ACV) is a useful metric to look at because it gives you a rough sense of how efficient a sales team is. To elaborate, there's a similar amount of work needed for a sales person to sell a $50k deal as there is for a sales person to sell a $100k deal. This is because most of the work a sales person does such as giving a demo, dealing with the paper process, and negotiating, have to happen regardless of how much the contract actually winds up being. Closing a $100k deal brings in twice as much revenue as a $50k deal does, but it's not usually twice as much work.</p><p>For this reason, higher average contract values are usually better. According to <a href="https://dskok-wpengine.netdna-ssl.com/wp-content/uploads/2020/08/2020-KBCM-SaaS-Survey.pdf">KBCM Technology Group</a>, 29% of software businesses have an ACV between $50k-$250k, and only 9% have an ACV greater than $250k. That gives Snowflake a relatively healthy ACV.</p><p>Not only does Snowflake have a high ACV, but their high end contract values are also really high. Snowflake has 56 customers that pay them over $1M a year. They also have Capital One, their largest customer, account for 11% of their 2019 revenue with approximately $29M.</p><p>Snowflake's net loss of $349M during 2019 does not sound good, but it does not tell the full story. There are two issues with using profit as a metric when looking at a subscription software business:</p><ul role="list"><li>Due to the generally accepted accounting principles (GAAP), a customer can give Snowflake money, but Snowflake can't count that money as revenue until a later date, even though that money is in Snowflake's bank account.</li><li>A net loss doesn't tell you where the money is coming in and where the money is going to.</li></ul><p>Addressing each of these points:</p><h3>Revenue under GAAP</h3><p>Under GAAP, Snowflake doesn't count revenue when a customer pays them, but instead when a customer uses the Snowflake product. To be more specific when a company pays Snowflake, they are purchasing a number of "Snowflake credits". When you are using the Snowflake product you exchange your credits for Snowflake compute time.</p><p>As an example, let's say a customer purchases one year of Snowflake credits for $100k. That money winds up in Snowflake's bank account, but Snowflake cannot count that $100k as revenue until Snowflake delivers the service, which is when the customer uses their credits for compute time. If the customer uses a quarter of the Snowflake credits within three months after purchases them, under GAAP, Snowflake would count that as $25k in revenue over those three months.</p><p>You can see the impact this has by looking at the $688M Snowflake has in "remaining performance obligations". This $688M is money that Snowflake's customers have either already given to Snowflake or have contractually committed to giving to Snowflake, but it won't show up as revenue until the customers use the credits they purchased.</p><h3>Where's the money going?</h3><p>The other thing to look at is what they are spending the money on. Snowflake is making money on every sale. They have a gross profit of 62% so they have no problem running the product. The thing is they are spending A LOT on sales and marketing. Their total net loss for the last six months was $171M while during the same time period they spent $191M on sales and marketing. If they wanted to, they could stop investing in growth, lay off their entire sales and marketing team, and they would become profitable. In other words, Snowflake could be profitable if they wanted to, but they are intentionally choosing not to, and are instead focusing on growing the customer base.</p><p>Not that they should. If we assume the $191M they spent in sales and marketing over the last six months was responsible for the $81M increase in revenue in the last six months compared to the prior six months, every $1 Snowflake invests in sales and marketing results in $.42 of revenue. With Snowflake's 158% net retention rate, that customer will pay back the initial investment in sales and marketing after around two years and then return many times the investment in the years following that.</p><p>In practice, Snowflake probably sees a return on investment much sooner. A company pays for Snowflake well before Snowflake is able to count that money as revenue.</p><p>So does it make sense for Snowflake's market cap to be 150x their revenue. I definitely think it's high, but I it's certainly plausible. They're growing faster, have higher customer satisfaction, and just have phenomenal metrics across the board when compared to similar businesses.</p><p>‍</p></div></div>]]>
            </description>
            <link>https://www.freshpaint.io/blog/why-is-snowflake-so-valuable</link>
            <guid isPermaLink="false">hacker-news-small-sites-24641481</guid>
            <pubDate>Wed, 30 Sep 2020 17:50:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Failed Promise of Web Components]]>
            </title>
            <description>
<![CDATA[
Score 330 | Comments 200 (<a href="https://news.ycombinator.com/item?id=24640151">thread link</a>) | @lemonberry
<br/>
September 30, 2020 | https://lea.verou.me/2020/09/the-failed-promise-of-web-components/ | <a href="https://web.archive.org/web/*/https://lea.verou.me/2020/09/the-failed-promise-of-web-components/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p>Web Components had so much potential to empower HTML to do more, and make web development more accessible to non-programmers and easier for programmers. Remember how exciting it was every time we got new shiny HTML elements that actually <em>do stuff</em>? Remember how exciting it was to be able to do sliders, color pickers, dialogs, disclosure widgets straight in the HTML, without having to include any widget libraries?</p>



<p>The promise of Web Components was that we’d get this convenience, but for a much wider range of HTML elements, developed much faster, as nobody needs to wait for the full spec + implementation process. We’d just include a script, and boom, we have more elements at our disposal!</p>



<p>Or, that was the idea. Somewhere along the way, the space got flooded by JS frameworks aficionados, who revel in complex APIs, overengineered build processes and dependency graphs that look like the roots of a banyan tree.</p>



<figure><img src="https://live.staticflickr.com/2025/32441377780_e3acf6de12_b.jpg" alt=""><figcaption>This is what the roots of a Banyan tree look like. <a href="https://www.flickr.com/photos/79721788@N00/32441377780/">Photo by David Stanley on Flickr (CC-BY)</a>. </figcaption></figure>



<p>Perusing the components on <a href="https://www.webcomponents.org/">webcomponents.org</a> fills me with anxiety, and I’m perfectly comfortable writing JS — I write JS for a living! What hope do those who can’t write JS have? Using a custom element from the directory often needs to be preceded by a ritual of npm flugelhorn, import clownshoes, build quux, all completely unapologetically because “here is my truckload of dependencies, yeah, what”. Many steps are even omitted, likely because they are “obvious”. Often, you wade through the maze only to find the component doesn’t work anymore, or is not fit for your purpose.</p>



<p>Besides setup, the main problem is that HTML is not treated with the appropriate respect in the design of these components. They are not designed as closely as possible to standard HTML elements, but <em>expect</em> JS to be written for them to do anything. HTML is simply treated as a shorthand, or worse, as merely a marker to indicate where the element goes in the DOM, with all parameters passed in via JS. I recall <a href="https://adactio.com/articles/12839#webcomponents">a wonderful talk by Jeremy Keith</a> a few years ago about this very phenomenon, where he discussed <a href="https://shop.polymer-project.org/">this e-shop Web components demo by Google</a>, which is the poster child of this practice. These are the entire contents of its <code>&lt;body&gt;</code> element:</p>



<pre><code>&lt;body&gt;
	&lt;shop-app unresolved=""&gt;SHOP&lt;/shop-app&gt;
	&lt;script src="node_assets/@webcomponents/webcomponentsjs/webcomponents-loader.js"&gt;&lt;/script&gt;
	&lt;script type="module" src="src/shop-app.js"&gt;&lt;/script&gt;
	&lt;script&gt;window.performance&amp;&amp;performance.mark&amp;&amp;performance.mark("index.html");&lt;/script&gt;
&lt;/body&gt;</code></pre>



<p>If this is how Google is leading the way, how can we hope for contributors to design components that follow established HTML conventions?</p>



<p>Jeremy criticized this practice from the aspect of backwards compatibility: when JS is broken or not enabled, or the browser doesn’t support Web Components, the entire website is blank. While this is indeed a serious concern, my primary concern is one of <strong>usability</strong>: <strong>HTML is a lower barrier to entry language</strong>. Far more people can write HTML than JS. Even for those who do eventually write JS, it often comes after spending years writing HTML &amp; CSS.</p>



<p>If components are designed in a way that requires  JS, this excludes thousands of people from using them. And even for those who <em>can</em> write JS, HTML is often easier: you don’t see many people rolling their own sliders or using JS-based ones once <code>&lt;input type="range"&gt;</code> became widely supported, right?</p>



<p>Even when JS is unavoidable, it’s not black and white. A well designed HTML element can reduce the amount and complexity of JS needed to a minimum. Think of the <code><a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/dialog">&lt;dialog&gt;</a></code> element: it usually does require *some* JS, but it’s usually rather simple JS. Similarly, the <code>&lt;video&gt;</code> element is perfectly usable just by writing HTML, and has a comprehensive JS API for anyone who wants to do fancy custom things.</p>



<p>The other day I was looking for a simple, dependency free, tabs component. You know, the canonical example of something that is easy to do with Web Components, the example 50% of tutorials mention. I didn’t even care what it looked like, it was for a testing interface. I just wanted something that is small and works like a normal HTML element. Yet, it proved so hard I ended up writing my own!</p>



<h3>Can we fix this?</h3>



<p>I’m not sure if this is a design issue, or a documentation issue. Perhaps for many of these web components, there are easier ways to use them. Perhaps there are vanilla web components out there that I just can’t find. Perhaps I’m looking in the wrong place and there is another directory somewhere with different goals and a different target audience. </p>



<p>But if not, and if I’m not alone in feeling this way, we need a directory of web components with strict inclusion criteria:</p>



<ul><li><strong>Plug and play.</strong> No dependencies, no setup beyond including one <code>&lt;script&gt;</code> tag. If a dependency is absolutely <em>needed</em> (e.g. in a map component it doesn’t make sense to draw your own maps), the component loads it automatically if it’s not already loaded.</li><li>Syntax and API follows <a href="https://www.smashingmagazine.com/2017/02/designing-html-apis/"><strong>conventions established by built-in HTML elements</strong></a> and anything that <em>can</em> be done without the component user writing JS, <em>is</em> doable without JS, per <a href="https://www.w3.org/2001/tag/doc/leastPower.html">the W3C principle of least power</a>.</li><li><strong>Accessible by default</strong> via sensible ARIA defaults, just like normal HTML elements.</li><li><strong>Themable</strong> via <code><a href="https://developer.mozilla.org/en-US/docs/Web/CSS/::part">::part()</a></code>, selective inheritance and custom properties. Very minimal style by default. Normal CSS properties should just “work” to the the extent possible.</li><li><strong>Only one component of a given type</strong> in the directory, that is <strong>flexible</strong> and <strong>extensible</strong> and continuously iterated on and improved by the community. Not 30 different sliders and 15 different tabs that users have to wade through. No branding, no silos of “component libraries”. Only elements that are designed as closely as possible to what a browser would implement in every way the current technology allows.</li></ul>



<p>I would be up for working on this if others feel the same way, since that is not a project for one person to tackle. <em>Who’s with me?</em></p>



<p><strong>UPDATE:</strong> Wow this post blew up! Thank you all for your interest in participating in a potential future effort. I’m currently talking to stakeholders of some of the existing efforts to see if there are any potential collaborations before I go off and create a new one. <a href="https://twitter.com/leaverou">Follow me on Twitter to hear about the outcome</a>!</p>

		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>https://lea.verou.me/2020/09/the-failed-promise-of-web-components/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24640151</guid>
            <pubDate>Wed, 30 Sep 2020 15:59:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Ruby One-Liners Cookbook]]>
            </title>
            <description>
<![CDATA[
Score 174 | Comments 29 (<a href="https://news.ycombinator.com/item?id=24637797">thread link</a>) | @asicsp
<br/>
September 30, 2020 | https://learnbyexample.github.io/learn_ruby_oneliners/one-liner-introduction.html | <a href="https://web.archive.org/web/*/https://learnbyexample.github.io/learn_ruby_oneliners/one-liner-introduction.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
        <!-- Provide site root to javascript -->
        

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        

        <!-- Set the theme before any content is loaded, prevents flash -->
        

        <!-- Hide / unhide sidebar before it is displayed -->
        

        <nav id="sidebar" aria-label="Table of contents">
            
            
        </nav>

        <div id="page-wrapper">

            <div class="page">
                
                
                

                
                
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                

                <div id="content">
                    <main>
                        
<p>This chapter will give an overview of <code>ruby</code> syntax for command line usage and some examples to show what kind of problems are typically suited for one-liners.</p>
<h2><a href="#why-use-ruby-for-one-liners" id="why-use-ruby-for-one-liners">Why use Ruby for one-liners?</a></h2>
<p>I assume you are already familiar with use cases where command line is more productive compared to GUI. See also this series of articles titled <a href="https://sanctum.geek.nz/arabesque/series/unix-as-ide/">Unix as IDE</a>.</p>
<p>A shell utility like <code>bash</code> provides built-in commands and scripting features to make it easier to solve and automate various tasks. External *nix commands like <code>grep</code>, <code>sed</code>, <code>awk</code>, <code>sort</code>, <code>find</code>, <code>parallel</code> etc can be combined to work with each other. Depending upon your familiarity with those tools, you can either use <code>ruby</code> as a single replacement or complement them for specific use cases.</p>
<p>Here's some one-liners (options will be explained later):</p>
<ul>
<li><code>ruby -e 'puts readlines.uniq' *.txt</code> — retain only one copy if lines are duplicated from the given list of input file(s)</li>
<li><code>ruby -e 'puts readlines.uniq {|s| s.split[1]}' *.txt</code> — retain only first copy of duplicate lines using second field as duplicate criteria</li>
<li><code>ruby -rcommonregex -ne 'puts CommonRegex.get_links($_)' *.md</code> — extract only the URLs, using a third-party <a href="https://github.com/talyssonoc/CommonRegexRuby">CommonRegexRuby</a> library</li>
<li><a href="https://stackoverflow.com/questions/63954081/bash-remove-duplicate-of-key-values-with-preserving-order">stackoverflow: merge duplicate key values while preserving order</a> — a recent Q&amp;A that I answered with a simpler <code>ruby</code> solution compared to <code>awk</code></li>
</ul>
<p>The main advantage of <code>ruby</code> over tools like <code>grep</code>, <code>sed</code> and <code>awk</code> includes feature rich regular expression engine, standard library and third-party libraries. If you don't already know the syntax and idioms for <code>sed</code> and <code>awk</code>, learning command line options for <code>ruby</code> would be the easier option. The main disadvantage is that <code>ruby</code> is likely to be slower compared to those tools.</p>
<h2><a href="#command-line-options" id="command-line-options">Command line options</a></h2>
<table><thead><tr><th><strong>Option</strong></th><th><strong>Description</strong></th></tr></thead><tbody>
<tr><td><code>-0[octal]</code></td><td>specify record separator (<code>\0</code>, if no argument)</td></tr>
<tr><td><code>-a</code></td><td>autosplit mode with <code>-n</code> or <code>-p</code> (splits <code>$_</code> into <code>$F</code>)</td></tr>
<tr><td><code>-c</code></td><td>check syntax only</td></tr>
<tr><td><code>-Cdirectory</code></td><td>cd to directory before executing your script</td></tr>
<tr><td><code>-d</code></td><td>set debugging flags (set <code>$DEBUG</code> to true)</td></tr>
<tr><td><code>-e 'command'</code></td><td>one line of script. Several <code>-e</code>'s allowed. Omit [programfile]</td></tr>
<tr><td><code>-Eex[:in]</code></td><td>specify the default external and internal character encodings</td></tr>
<tr><td><code>-Fpattern</code></td><td><code>split()</code> pattern for autosplit (<code>-a</code>)</td></tr>
<tr><td><code>-i[extension]</code></td><td>edit <code>ARGV</code> files in place (make backup if extension supplied)</td></tr>
<tr><td><code>-Idirectory</code></td><td>specify <code>$LOAD_PATH</code> directory (may be used more than once)</td></tr>
<tr><td><code>-l</code></td><td>enable line ending processing</td></tr>
<tr><td><code>-n</code></td><td>assume <code>'while gets(); ... end'</code> loop around your script</td></tr>
<tr><td><code>-p</code></td><td>assume loop like <code>-n</code> but print line also like <code>sed</code></td></tr>
<tr><td><code>-rlibrary</code></td><td>require the library before executing your script</td></tr>
<tr><td><code>-s</code></td><td>enable some switch parsing for switches after script name</td></tr>
<tr><td><code>-S</code></td><td>look for the script using PATH environment variable</td></tr>
<tr><td><code>-v</code></td><td>print the version number, then turn on verbose mode</td></tr>
<tr><td><code>-w</code></td><td>turn warnings on for your script</td></tr>
<tr><td><code>-W[level=2|:category]</code></td><td>set warning level; 0=silence, 1=medium, 2=verbose</td></tr>
<tr><td><code>-x[directory]</code></td><td>strip off text before #!ruby line and perhaps cd to directory</td></tr>
<tr><td><code>--jit</code></td><td>enable JIT with default options (experimental)</td></tr>
<tr><td><code>--jit-[option]</code></td><td>enable JIT with an option (experimental)</td></tr>
<tr><td><code>-h</code></td><td>show this message, <code>--help</code> for more info</td></tr>
</tbody></table>
<p>This chapter will show examples with <code>-e</code>, <code>-n</code>, <code>-p</code> and <code>-a</code> options. Some more options will be covered in later chapters, but not all of them are discussed in this book.</p>
<h2><a href="#executing-ruby-code" id="executing-ruby-code">Executing Ruby code</a></h2>
<p>If you want to execute a <code>ruby</code> program file, one way is to pass the filename as argument to the <code>ruby</code> command.</p>
<pre><code>$ echo 'puts "Hello Ruby"' &gt; hello.rb
$ ruby hello.rb
Hello Ruby
</code></pre>
<p>For short programs, you can also directly pass the code as an argument to the <code>-e</code> option.</p>
<pre><code>$ ruby -e 'puts "Hello Ruby"'
Hello Ruby

$ # multiple statements can be issued separated by ;
$ ruby -e 'x=25; y=12; puts x**y'
59604644775390625
$ # or use -e option multiple times
$ ruby -e 'x=25' -e 'y=12' -e 'puts x**y'
59604644775390625
</code></pre>
<h2><a href="#filtering" id="filtering">Filtering</a></h2>
<p><code>ruby</code> one-liners can be used for filtering lines matched by a regexp, similar to <code>grep</code>, <code>sed</code> and <code>awk</code>. And similar to many command line utilities, <code>ruby</code> can accept input from both <code>stdin</code> and file arguments.</p>
<pre><code>$ # sample stdin data
$ printf 'gate\napple\nwhat\nkite\n'
gate
apple
what
kite

$ # print all lines containing 'at'
$ # same as: grep 'at' and sed -n '/at/p' and awk '/at/'
$ printf 'gate\napple\nwhat\nkite\n' | ruby -ne 'print if /at/'
gate
what

$ # print all lines NOT containing 'e'
$ # same as: grep -v 'e' and sed -n '/e/!p' and awk '!/e/'
$ printf 'gate\napple\nwhat\nkite\n' | ruby -ne 'print if !/e/'
what
</code></pre>
<p>By default, <code>grep</code>, <code>sed</code> and <code>awk</code> will automatically loop over input content line by line (with <code>\n</code> as the line distinguishing character). The <code>-n</code> or <code>-p</code> option will enable this feature for <code>ruby</code>. As seen before, the <code>-e</code> option accepts code as command line argument. Many shortcuts are available to reduce the amount of typing needed.</p>
<p>In the above examples, a regular expression (defined by the pattern between a pair of forward slashes) has been used to filter the input. When the input string isn't specified in a conditional context (for example: <code>if</code>), the test is performed against global variable <code>$_</code>, which has the contents of the input line (the correct term would be input <strong>record</strong>, see <a href="https://learnbyexample.github.io/learn_ruby_oneliners/record-separators.html#record-separators">Record separators</a> chapter). To summarize, in a conditional context:</p>
<ul>
<li><code>/regexp/</code> is a shortcut for <code>$_ =~ /regexp/</code></li>
<li><code>!/regexp/</code> is a shortcut for <code>$_ !~ /regexp/</code></li>
</ul>
<p><code>$_</code> is also the default argument for <code>print</code> method, which is why it is generally preferred in one-liners over <code>puts</code> method. More such defaults that apply to the <code>print</code> method will be discussed later.</p>
<blockquote>
<p><img src="https://learnbyexample.github.io/learn_ruby_oneliners/images/info.svg" alt="info"> See <a href="https://ruby-doc.org/core-2.7.1/doc/globals_rdoc.html">ruby-doc: Pre-defined global variables</a> for documentation on <code>$_</code>, <code>$&amp;</code>, etc.</p>
</blockquote>
<p>Here's an example with file input instead of <code>stdin</code>.</p>
<pre><code>$ cat table.txt
brown bread mat hair 42
blue cake mug shirt -7
yellow banana window shoes 3.14

$ # same as: grep -oE '[0-9]+$' table.txt
$ ruby -ne 'puts $&amp; if /\d+$/' table.txt
42
7
14
</code></pre>
<blockquote>
<p><img src="https://learnbyexample.github.io/learn_ruby_oneliners/images/info.svg" alt="info"> The <a href="https://github.com/learnbyexample/learn_ruby_oneliners/tree/master/example_files">learn_ruby_oneliners repo</a> has all the files used in examples.</p>
</blockquote>
<h2><a href="#substitution" id="substitution">Substitution</a></h2>
<p>Use <code>sub</code> and <code>gsub</code> methods for search and replace requirements. By default, these methods operate on <code>$_</code> when the input string isn't provided. For these examples, <code>-p</code> option is used instead of <code>-n</code> option, so that the value of <code>$_</code> is automatically printed after processing each input line.</p>
<pre><code>$ # for each input line, change only first ':' to '-'
$ # same as: sed 's/:/-/' and awk '{sub(/:/, "-")} 1'
$ printf '1:2:3:4\na:b:c:d\n' | ruby -pe 'sub(/:/, "-")'
1-2:3:4
a-b:c:d

$ # for each input line, change all ':' to '-'
$ # same as: sed 's/:/-/g' and awk '{gsub(/:/, "-")} 1'
$ printf '1:2:3:4\na:b:c:d\n' | ruby -pe 'gsub(/:/, "-")'
1-2-3-4
a-b-c-d
</code></pre>
<p>You might wonder how <code>$_</code> is modified without the use of <code>!</code> methods. The reason is that these methods are part of Kernel (see <a href="https://ruby-doc.org/core-2.7.1/Kernel.html">ruby-doc: Kernel</a> for details) and are available only when <code>-n</code> or <code>-p</code> options are used.</p>
<ul>
<li><code>sub(/regexp/, repl)</code> is a shortcut for <code>$_.sub(/regexp/, repl)</code> and <code>$_</code> will be updated if substitution succeeds</li>
<li><code>gsub(/regexp/, repl)</code> is a shortcut for <code>$_.gsub(/regexp/, repl)</code> and <code>$_</code> gets updated if substitution succeeds</li>
</ul>
<blockquote>
<p><img src="https://learnbyexample.github.io/learn_ruby_oneliners/images/info.svg" alt="info"> This book assumes you are already familiar with regular expressions. If not, you can check out my free <a href="https://learnbyexample.github.io/Ruby_Regexp/">Ruby Regexp</a> book.</p>
</blockquote>
<h2><a href="#field-processing" id="field-processing">Field processing</a></h2>
<p>Consider the sample input file shown below with fields separated by a single space character.</p>
<pre><code>$ cat table.txt
brown bread mat hair 42
blue cake mug shirt -7
yellow banana window shoes 3.14
</code></pre>
<p>Here's some examples that is based on specific field rather than the entire line. The <code>-a</code> option will cause the input line to be split based on whitespaces and the field contents can be accessed using <code>$F</code> global variable. Leading and trailing whitespaces will be suppressed and won't result in empty fields. More details is discussed in <a href="https://learnbyexample.github.io/learn_ruby_oneliners/field-separators.html#default-field-separation">Default field separation</a> section.</p>
<pre><code>$ # print the second field of each input line
$ # same as: awk '{print $2}' table.txt
$ ruby -ane 'puts $F[1]' table.txt
bread
cake
banana

$ # print lines only if last field is a negative number
$ # same as: awk '$NF&lt;0' table.txt
$ ruby -ane 'print if $F[-1].to_f &lt; 0' table.txt
blue cake mug shirt -7

$ # change 'b' to 'B' only for the first field
$ # same as: awk '{gsub(/b/, "B", $1)} 1' table.txt
$ ruby -ane '$F[0].gsub!(/b/, "B"); puts $F * " "' table.txt
Brown bread mat hair 42
Blue cake mug shirt -7
yellow banana window shoes 3.14
</code></pre>
<h2><a href="#begin-and-end" id="begin-and-end">BEGIN and END</a></h2>
<p>You can use a <code>BEGIN{}</code> block when you need to execute something before input is read and a <code>END{}</code> block to execute something after all of the input has been processed.</p>
<pre><code>$ # same as: awk 'BEGIN{print "---"} 1; END{print "%%%"}'
$ # note the use of ; after BEGIN block
$ seq 4 | ruby -pe 'BEGIN{puts "---"}; END{puts "%%%"}'
---
1
2
3
4
%%%
</code></pre>
<h2><a href="#env-hash" id="env-hash">ENV hash</a></h2>
<p>When it comes to automation and scripting, you'd often need to construct commands that can accept input from user, file, output of a shell command, etc. As mentioned before, this book assumes <code>bash</code> as the shell being used. To access environment variables of the shell, you can call the special hash variable <code>ENV</code> with the name of the environment variable as a string key.</p>
<pre><code>$ # existing environment variable
$ # output shown here is for my machine, would differ for you
$ ruby -e 'puts ENV["HOME"]'
/home/learnbyexample
$ ruby -e 'puts ENV["SHELL"]'
/bin/bash

$ # defined along with ruby command
$ # note that the variable is placed before the shell command
$ word='hello' ruby -e 'puts ENV["word"]'
hello
$ # the input characters are preserved as is
$ ip='hi\nbye' ruby -e 'puts ENV["ip"]'
hi\nbye
</code></pre>
<p>Here's another example when a regexp is passed as an environment variable content.</p>
<pre><code>$ cat word_anchors.txt
sub par
spar
apparent effort
two spare computers
cart part tart mart

$ # assume 'r' is a shell variable that has to be passed to the ruby command
$ r='\Bpar\B'
$ rgx="$r" ruby -ne 'print if /#{ENV["rgx"]}/' word_anchors.txt
apparent effort
two spare computers
</code></pre>
<blockquote>
<p><img src="https://learnbyexample.github.io/learn_ruby_oneliners/images/info.svg" alt="info"> As an example, see my repo <a href="https://github.com/learnbyexample/command_help/blob/master/ch">ch: command help</a> for a practical shell script, where commands are constructed …</p></blockquote></main></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://learnbyexample.github.io/learn_ruby_oneliners/one-liner-introduction.html">https://learnbyexample.github.io/learn_ruby_oneliners/one-liner-introduction.html</a></em></p>]]>
            </description>
            <link>https://learnbyexample.github.io/learn_ruby_oneliners/one-liner-introduction.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24637797</guid>
            <pubDate>Wed, 30 Sep 2020 11:57:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Six Figures in 6 days]]>
            </title>
            <description>
<![CDATA[
Score 587 | Comments 274 (<a href="https://news.ycombinator.com/item?id=24637405">thread link</a>) | @brunojppb
<br/>
September 30, 2020 | https://tr.af/6 | <a href="https://web.archive.org/web/*/https://tr.af/6">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-lax-preset="fadeIn">
        <p>This title is a little misleading.</p>

<p>Sure, it took me 6 days to amass 3,626 sales for a total of $101,528, but like any overnight success, it was years in the making. In my case, about 7 years.</p>

<p>In 2013, the jailbreaking days of iOS were in full effect. Inspired, I created and sold an icon set titled 'Greyish HD' on the Cydia store for $0.99. It was the first few dollars I ever made on the internet. I think I made a total of $17, and it was magical.</p>

<p>It wasn't about the $17, obviously; it was how I earned it. I spent time creating something that I thought was cool, then hit publish. After a few days, random strangers I've never met before decided to spend their hard-earned cents on my icon set, oftentimes while I was working on something else entirely. Without realizing it, I just discovered digital content leverage: <strong>create something once with sufficient effort, then sell it repeatedly with minimal effort.</strong></p>

<p>Fast forward 7 years later, minus 6 days. I saw some people sharing screenshots of their iPhones after discovering that iOS 14 now allows you to add custom icons to your home screen using the Siri Shortcuts app. This was the first time you can really customize iOS, and it was catching on. </p>

<p>This is something people have been doing for years on jailbroken iOS and Android devices, except this time, you can do it natively on iOS.</p>

<p>As soon as I noticed the hype, I put together some <a href="https://icons.tr.af/">icons</a> in my own style, downloaded some widgets, and tried it all out. I thought it looked cool, so I shared a screenshot of it on Twitter. Right away, people started asking about the icons in the screenshot. So I quickly packaged them, uploaded them to <a href="https://gumroad.com/">Gumroad</a>, and embedded them on a <a href="https://notion.so/">Notion</a> site using <a href="https://super.so/">Super</a>. All of this took about two hours.</p>

<p>The next day, the tweet had hundreds of retweets, thousands of likes, and over 100k impressions. The day after that, almost a million. The next thing I knew, it was everywhere. My icons got published on notable tech sites like <a href="https://www.cultofmac.com/723490/ios-14-iphone-home-screen-customization/">Cult of Mac</a>, <a href="https://www.imore.com/people-are-making-real-money-selling-icon-sets-ios-14-home-screens">iMore</a>, <a href="https://allthingst3ch.com/ios14homescreen">AllThingsTech</a>, and <a href="https://gridfiti.com/aesthetic-ios-home-screen-ideas">Gridfiti</a>. I think at this time I was around the $6k mark in sales.</p>

<p>Then, MKBHD happened. He shared a <a href="https://youtu.be/cH66LWWluVE">video</a> about all of this—using my icons for his setup, and linked them in the description. The next thing I knew, I was making $28 what felt like every 28 seconds. My phone turned into the ultimate dopamine dispenser (if it wasn't already). I had to disable notifications.</p>

<p>The day after, sales jumped from $6k to about $40k, and during the time of this writing, sales are at $116,147 from 4,188 customers.</p>

<p>All from one. Single. <a href="https://twitter.com/traf/status/1307707156788060160">Tweet</a>.</p>

<p>The right content, posted at the right time, can create unimaginable results. Although there's likely plenty of other variables that went into making this work, there are a few key insights that I think increased my odds.</p>

<h3>Publish often</h3>

<p>Continually putting things out into the world creates proof of work. The difference between where you are and where you want to be could be as little as sharing what you build, or even what you know.</p>

<p>There's only so much we can control once pushing something out into the world, but publishing often will increase your odds at finding something that sticks. They say that fortune favors the bold. In the internet age, the bold are those that aren't afraid to publish their work for the world to see. The internet is a never-ending stream of content, the idea of being annoying or over-sharing is only an idea that you invent to stop you from sharing. </p>

<h3>Act immediately</h3>

<p>I could have easily ignored the requests for the icons, or directed people to icon sets that already existed, but that would be a missed opportunity. Since I've done similar icon sets so many times already in the past, I was ready for it. Acting quickly is crucial if you plan on riding the wave. </p>

<h3>Be transparent</h3>

<p>I shared <a href="https://twitter.com/traf/status/1308158718975111175">this tweet</a> the day after posting my home screen with details of all the hype, and it created even more hype. It brought another 540,000 impressions and added fuel to an already growing fire. <strong>Share what works, and share what doesn't.</strong> Transparency is visibility.</p>

<h3>Have a clear schedule</h3>

<p>A lot of this was happening on a Monday morning. If I were working a more traditional job, or had time commitments that I had previously scheduled, I wouldn't have been able to act on my ideas as quickly as I did. I get that not everyone has the privilege of a flexible schedule, but almost anyone can start to move towards it if they want it badly enough. Freedom of a clear schedule allowed me to take action as soon as the inspiration hit, which was incredibly important to maximize exposure. Inspiration is a productivity-multiplier, but it's perishable—so act quickly.</p>

<h3>Charge more</h3>

<p>If I would have asked anyone what to price these at, most would have said $2, or maybe $5. One thing I knew for sure was that the people most likely to buy these were not the same people who were jailbreaking their iOS devices in the past. These are first time iOS customizers, so there's no notion of what an iOS icon set should be priced at.</p>

<h3>Do it for the art</h3>

<p>If I would have done this exclusively for the goal of making money, I'm convinced it wouldn't have worked nearly as well as it did. I see copycats showing up everywhere. They see success, and try to replicate exactly how it happened, but it won't work. At least not nearly as well. The reasons for this post is not to teach you how to sit on the edge of your seat, foaming at the mouth at the chance to exploit the next big internet trend, but it's to push you to keep working at the things you enjoy, share them with the world, and letting the internet do the rest.</p>

<h3>Aftermath</h3>

<p>So what came of all this? I suspect this is why most of you are here reading this, so here's a recap of everything that came from last week in numbers, from the time of this writing:</p>

<h4>Short-term metrics:</h4>

<ul><li>4,188 total icon sales</li><li>$116,147 in revenue</li><li>97% profit margins</li><li>6.2m impression</li><li>216,800 visitors</li></ul>

<h4>Long-term metrics:</h4>

<ul><li>5,216 email subscribers</li><li>4,620 Twitter followers</li><li>180 <a href="https://super.so/">Super</a> customers</li></ul>

<h3>What's next?</h3>

<p>In the same way that creating icon sets 7 years ago prepared me for last week, this whole experiment has likely prepared me for what's to come years from now.</p>

<p>The best part about this is the freedom its bought me, to keep building things that'll create even more freedom. <strong>Spending time on things that will buy you time is always a good use of it.</strong> When people buy into what ever it is you're selling, they're not only giving you money, but they're contributing to your future freedom.</p>

<p>The market will decide a huge part of what comes after sharing something, so continually increase your odds by building, publishing, then repeating. Try many things once to figure out what you want to do twice. Figure out what you've got stored in your brain that can be of value to others, then share it with the world. You might be surprised of what comes of it.</p>

<p>Thanks for reading.</p>

<p>PS. For proof that I did this in 2013, here's my <a href="https://deviantart.com/jtraf">DeviantArt profile</a>.<br>PPS. For details about the Notion/Super/Gumroad combo: <a href="https://www.makerpad.co/deep-dives/the-community-creator-how-to-run-a-low-cost-membership-community-or-creator-business-with-circle-memberspace-gumroad-notion-super-so">Makerpad deep-dive</a>.</p>

<p>— <a href="https://twitter.com/traf">@traf</a></p>
      </div></div>]]>
            </description>
            <link>https://tr.af/6</link>
            <guid isPermaLink="false">hacker-news-small-sites-24637405</guid>
            <pubDate>Wed, 30 Sep 2020 10:59:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It Is Never a Compiler Bug Until It Is]]>
            </title>
            <description>
<![CDATA[
Score 236 | Comments 128 (<a href="https://news.ycombinator.com/item?id=24636326">thread link</a>) | @nullc
<br/>
September 30, 2020 | http://r6.ca/blog/20200929T023701Z.html | <a href="https://web.archive.org/web/*/http://r6.ca/blog/20200929T023701Z.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>Last week I was trying to add some <a href="https://github.com/bitcoin-core/secp256k1/pull/822/commits/aa833603a6b4c947c21da04aeac40d80444ebcc1#diff-b04459e37839cd223176618536295715R425">testing code to libsecp256k1</a> and I was pulling out my hair trying to get it to work.
No amount of <code>printf</code> was working to illuminate what I was doing wrong.
Finally, out of desperation, I thought I would do a quick check to see if there are any compiler bugs related to <code>memcmp</code>, and lo and behold, I found <a href="https://gcc.gnu.org/bugzilla/show_bug.cgi?id=95189">GCC bug #95189: memcmp being wrongly stripped like strcmp</a>.</p><p>Honestly this was a pretty horrifying bug to read about.
Under some circumstances GCC 9 and 10 will cause <code>memcmp</code> to return an incorrect value when one of the inputs is statically known array that contains <code>NULL</code> bytes.
As I rushed to <a href="https://gist.githubusercontent.com/roconnor/2b8e22e829ed80088ed6690cc3c7f3a8/raw/455571a6d9053c597c1585debe6f9dbd6af85071/gistfile1.txt">recompile my computer system using GCC 8</a>, I contemplated the vast consequences of such a bug could be, and pondered how it was possible that computers could function at all.</p><p>However over the week, with the help of my colleagues, we managed to get a better understanding of the scope of the bug.
The bug can only convert non-zero values to zero values.
The static array needs to have a <code>NULL</code> byte within the first 4 bytes.
Most importantly, the <code>memcmp</code> result must not immediately be compared to <code>0</code> for equality or inequality, or any equivalent test.
A different code path is taken in the compiler in that case.
That explained why computers were still functioning.
I expect the vast majority of the uses of <code>memcmp</code> does an immediate test for equality with <code>0</code>.</p><p>I still wondered though, how much code was being affected. My colleague Tim suggested that it would be possible to instrument GCC to emit a message when it was about to miscompile a program.
Together we came up with <a href="https://gcc.gnu.org/bugzilla/attachment.cgi?id=49276&amp;action=diff">a patch</a> to GCC 9 and 10 that would print a debugging message.
Once again, I recompiled my entire system, to see what GCC was miscompiling.
This is what I found:</p><ul>
<li><a href="https://github.com/unicode-org/icu/blob/4fb47b12a70737ee12326220e71c2d73c5ec658f/icu4c/source/common/uniset_props.cpp#L709">https://github.com/unicode-org/icu/blob/4fb47b12a70737ee12326220e71c2d73c5ec658f/icu4c/source/common/uniset_props.cpp#L709</a></li>
<li><a href="https://github.com/xiph/flac/blob/ce6dd6b5732e319ef60716d9cc9af6a836a4011a/src/flac/decode.c#L1310">https://github.com/xiph/flac/blob/ce6dd6b5732e319ef60716d9cc9af6a836a4011a/src/flac/decode.c#L1310</a></li>
<li><a href="https://github.com/torvalds/linux/blob/fb0155a09b0224a7147cb07a4ce6034c8d29667f/drivers/atm/zatm.c#L1172">https://github.com/torvalds/linux/blob/fb0155a09b0224a7147cb07a4ce6034c8d29667f/drivers/atm/zatm.c#L1172</a></li>
<li><a href="https://github.com/nss-dev/nss/blob/1f3746f5107535a47bb4e3969f561e1bd1314bab/gtests/pk11_gtest/pk11_chacha20poly1305_unittest.cc#L425">https://github.com/nss-dev/nss/blob/1f3746f5107535a47bb4e3969f561e1bd1314bab/gtests/pk11_gtest/pk11_chacha20poly1305_unittest.cc#L425</a></li>
<li><a href="https://github.com/GNOME/glib/blob/010569b3734f864fcf584f771915b78bd391eb5f/glib/tests/refstring.c#L70">https://github.com/GNOME/glib/blob/010569b3734f864fcf584f771915b78bd391eb5f/glib/tests/refstring.c#L70</a></li>
<li><a href="https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L390">https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L390</a>, <a href="https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L661">https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L661</a>, <a href="https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L1279">https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L1279</a></li>
<li><a href="https://github.com/zeromq/libzmq/blob/22d218a182855f28038e865cb75bf5897ff0c786/tests/test_mock_pub_sub.cpp#L203">https://github.com/zeromq/libzmq/blob/22d218a182855f28038e865cb75bf5897ff0c786/tests/test_mock_pub_sub.cpp#L203</a></li>
<li><a href="https://github.com/pigoz/mplayer-svn/blob/8d651873a9eb193f5155ffb51ece206f187cf00f/sub/sub_cc.c#L391-L412">https://github.com/pigoz/mplayer-svn/blob/8d651873a9eb193f5155ffb51ece206f187cf00f/sub/sub_cc.c#L391-L412</a></li>
</ul>
<p>On my entire system I only found 10 lines of code that were miscompiled.
Three lines are tests.
All of the lines could be rewritten as a comparison to 0.
None of the lines looked that serious.
I am not sure which one is the worse: the reduced message integrity code(?) from some ARCFOUR implementation or the something something from an ATM driver?</p><p>The mplayer miscompilation is the most mysterious.
The code surrounding that function all appears to be immediately compare <code>memcmp</code> with <code>0</code>.
And given that my debug message refused to point to exactly what line is being miscompiled in that function, I fear some set of optimizations has happened to allow this code to be miscompiled in some way.</p><p>With more hardware I could do <a href="https://hydra.nixos.org/jobset/nixpkgs/trunk#tabs-jobs">a more thorough investigation</a> of the consequences of this GCC bug.
Until then I am going to stick with GCC 8 until GCC 9 and 10 have a new point releases.

</p></div></div>]]>
            </description>
            <link>http://r6.ca/blog/20200929T023701Z.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24636326</guid>
            <pubDate>Wed, 30 Sep 2020 07:01:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding How UUIDs Are Generated]]>
            </title>
            <description>
<![CDATA[
Score 119 | Comments 43 (<a href="https://news.ycombinator.com/item?id=24636204">thread link</a>) | @aryamansharda
<br/>
September 29, 2020 | https://digitalbunker.dev/2020/09/30/understanding-how-uuids-are-generated/ | <a href="https://web.archive.org/web/*/https://digitalbunker.dev/2020/09/30/understanding-how-uuids-are-generated/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="mainEntityOfPage">
<h2><strong>Introduction</strong></h2>
<p>You’ve likely used UUIDs in projects before and assumed them to be unique. Today, we’ll take a look at the main aspects of the implementation and understand why UUIDs are <em>practically </em>unique, though an incredibly small potential for duplication exists.&nbsp;</p>
<p>The modern day implementation of UUIDs can be tied back to <a href="https://tools.ietf.org/html/rfc4122" target="_blank" rel="noreferrer noopener">RFC 4122 </a>which introduced 5 different approaches for generating these identifiers. We’ll take a look at each one and we’ll step through the implementation details of Version 1 &amp; Version 4 in a moment.&nbsp;</p>
<h2><strong>Background</strong></h2>
<p>UUIDs, or universally unique IDentifiers, are simply a 128 bit number used to uniquely identify items in software development. Their canonical textual representation is as a series of 32 hexadecimal characters which are separated into five groups by hyphens in the form 8-4-4-4-12.&nbsp;</p>
<p>For example,&nbsp;</p>
<p><code>3422b448-2460-4fd2-9183-8000de6f8343</code></p>
<p>Embedded inside this seemingly random series of hexadecimal characters is information about the UUID implementation.&nbsp;</p>
<p><code>xxxxxxxx-xxxx-<strong>M</strong>xxx-<strong>N</strong>xxx-xxxxxxxxxxxx</code></p>
<p>The values in the M and N locations uniquely identify the UUID version and variant respectively.</p>
<h4><strong>Version</strong></h4>
<p>The version number is identified by looking at the most significant 4 bits of the value in the M position.&nbsp;</p>
<p>The following table lists the currently defined versions:</p>
<div><figure><img src="https://lh3.googleusercontent.com/1ePxhp-OP2JdmdHVLd3rbfDc9dcNP5J9QQncT0bYPdJ5W3_2pAHfGZ9a7Q7m3mav6VA1syO22nTIavepVicTMW9YxqiuGcSePUOanJeyz67K_bZwDbd_KO25oLgPirr53qj1wZq9" alt="" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>
<h4><strong>&nbsp;Variant</strong></h4>
<p>The variant field determines the layout of the information embedded in the UUID. The interpretation of all other bits in the UUID depends on the value of the variant.&nbsp;</p>
<p>We identify the variant by considering the first 1-3 most significant bits of N.&nbsp;</p>
<div><figure><img src="https://lh3.googleusercontent.com/FeXxFJcHdVVJA7IorpHtQx67F3eiSkMJVAr2Q5E4t3IierXggi-DR1uthMBOgRBXRP4JzcdRMuHbVqMMkCWZ47fo7sUO8sDBQcwgALwr45qLdpC9bSUBoXKQF9Bhdnnc9kN-g8p9" alt="" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>
<p>The most common implementation nowadays is Variant 1 where the MSB0&nbsp; is fixed as 1 and MSB1 is fixed as 0. This means that considering our wildcard values – the bits marked with an <code>x</code> above – the only possible values are 8, 9, A, or B.</p>
<blockquote><p><strong>Quick Reminder:&nbsp;</strong></p><p>1 0 0 0 = 8&nbsp;</p><p>1 0 0 1 = 9</p><p>1 0 1 0 = A</p><p>1 0 1 1 = B</p></blockquote>
<p>So, if you ever see a UUID with these values in the N position, you’ll know it’s the common Variant 1 type.&nbsp;</p>
<h4><strong>Version 1 (Time Based + Unique or Random Host Identifier)&nbsp;</strong></h4>
<p>In this version, the UUID is generated by taking the current timestamp and some identifying property of the device generating the UUID – most commonly, the MAC address (also called the node ID).&nbsp;</p>
<p>This UUID is generated by concatenating the 48 bit MAC address, a 60 bit-timestamp, and a 14 bit “uniquifying” clock sequence, along with the 6 reserved bits for version and variant to generate a unique UUID.&nbsp;</p>
<blockquote><p>The clock sequence is simply a value incremented every time the clock is modified.&nbsp;</p></blockquote>
<p>The timestamp used in this version is the number of 100 nanosecond time intervals since October 15, 1582 – the date of Gregorian reform to the Christian calendar.&nbsp;</p>
<blockquote><p>You may be familiar with Unix systems and time since epoch. This is simply just a different Day 0. There are several algorithms online that allow you to convert one time representation to the other, so we won’t go over this here.</p></blockquote>
<p>Though this implementation seems fairly straightforward and robust, because it reveals the MAC address of the machine it was generated on, this approach is not suitable for all use cases.&nbsp; Especially, when security is a major concern. Instead, some implementations will use 6 random bytes sourced from a cryptographically secure random number generator as a replacement for the node ID.&nbsp;</p>
<p>&nbsp;To assemble a Version 1 UUID, we’ll do the following steps:&nbsp;</p>
<ol><li>Take the low 32 bits of the current UTC timestamp. This will be the first 4 bytes / 8 hex characters of our UUID [TimeLow]</li><li>Take the middle 16 bits of the current UTC timestamp. These will be the following 2 bytes / 4 hex characters. [TimeMid]</li><li>The next 2 bytes / 4 hex characters will concat the 4 bit UUID version with the remaining high 12 bits of the current UTC timestamp (which is 60 bits in total). [TimeHighAndVersion]</li><li>Now, the next 1-3 bits will specify the variant of the UUID version. The remaining bits will contain the clock sequence which is meant to contribute some small amount of randomness to this implementation. In doing so, it helps avoid collisions in the event multiple UUID generators are running on the same system, a system clock for a UUID generator is set backwards, or the system clock doesn’t advance fast enough. [ClockSequenceHiAndRes &amp;&amp; ClockSequenceLow]</li><li>The final 6 bytes / 12 hex characters / 48 bits are the “node id” which is most commonly the MAC address of the issuing device. [NodeID]</li></ol>
<p>Putting everything together, our Version 1 UUID is generated by concatenating:</p>
<p><code>TimeLow + TimeMid + TimeHighAndVersion + (ClockSequenceHiAndRes &amp;&amp; ClockSequenceLow) + NodeID&nbsp;</code></p>
<p>Due to this implementation’s reliance on the clock, there are some edge cases we’ll need to handle. Firstly, to minimize correlation across systems, the clock sequence is defaulted to a random number – this will only happen once in the lifetime of a system. This has the added benefit of allowing us to support node identifiers that may move from system to system as the initial value of the clock sequence is completely agnostic of the node identifier.&nbsp;</p>
<p>Remember that the main purpose of the clock sequence is to introduce some amount of randomness into the equation. The bits allocated for the clock sequence help us extend the timestamp and account for situations where multiple UUIDs are generated before the processor clock advances. This helps us avoid the potential creation of duplicates when the clock is set backwards in time (device is powered off) or the node ID changes. If the clock is set backwards, or might have been set backwards (e.g., while the system was powered off), and the UUID generator can not be sure that no UUIDs were generated with timestamps larger than the value to which the clock was set, then the clock sequence has to be changed. If the previous value of the clock sequence is known, it can just be incremented; otherwise it should be set to a random or high-quality pseudo-random value.</p>
<h4><strong>Version 2 (Distributed Computing Environment Security)</strong></h4>
<p>The main difference between this version and Version 1 is that this implementation uses some identifier specific to the system in place of the “randomness” generated by using the least significant bits of the clock sequence. This value is often just the current user’s ID. This version is less common and only a small deviation from Version 1, so we won’t explore it any further.&nbsp;</p>
<h4><strong>Version 3 (Name-based + MD5 Hash)</strong></h4>
<p>In the event that you want to have unique identifiers for information within a namespace or for “nameable” information more generally, UUID version 3 and version 5 are your preferred options.&nbsp;</p>
<p>They’ll encode any “nameable” entity (website, DNS information, plain text, etc) into the UUID value. The main takeaway here is that for the same namespace and text, the generated UUID will be the same.&nbsp;</p>
<p>Take note that the namespace itself is a UUID.</p>
<pre><code>let namespace = “digitalbunker.dev”
let namespaceUUID = UUID3(.DNS, namespace)

// Ex: 
UUID3(namespaceUUID, “/category/things-you-should-know-1/”) 
4896c91b-9e61-3129-87b6-8aa299028058

UUID3(namespaceUUID, “/category/things-you-should-know-2/”) 
29be0ee3-fe77-331e-a1bf-9494ec18c0ba

UUID3(namespaceUUID, “/category/things-you-should-know-3/”) 
33b06619-1ee7-3db5-827d-0dc85df1f759
</code></pre>
<p>In this implementation, the UUID of the namespace is transformed to a string of bytes, concatenated with the input name, then hashed with MD5, yielding the 128 bits for the UUID. Then, we’ll overwrite some of those bits to accurately reflect the version and variant information leaving the rest unchanged.&nbsp;</p>
<p>It’s also important to understand that neither the namespace nor the inputted name can be generated from the UUID. This is a one-way operation. The only exception here would be through a brute force approach if one of the values (namespace or text) were known by the attacker.</p>
<p>For Version 3 and Version 5, as long as you use the same inputs, the generated UUID will be deterministic.&nbsp;</p>
<h4><strong>Version 4 (PRNG)</strong></h4>
<p>This is probably the simplest implementation of the bunch.</p>
<p>As we’ve now seen, 6 bits are reserved for the version and variant information leaving us 122 bits free to decide. This version simply generates all 128 random bits and then fills in the values for the version and variant information as a secondary step.&nbsp;</p>
<p>UUIDs of this variety rely heavily on the quality of the PRNG in use (pseudo-random number generator). If the PRNG is lacking a sophisticated algorithm or the correct seed and initialization values, the likelihood of a duplicate can increase. To better understand how computers generate random numbers, <a href="https://digitalbunker.dev/2020/09/08/how-do-computers-generate-random-numbers/" target="_blank" rel="noreferrer noopener">check out my previous article.</a>&nbsp;</p>
<p>Version 4 is what you’ll find most commonly implemented in modern programming languages.</p>
<p>It’s implementation is reasonably simple.&nbsp;</p>
<ol><li>Generate 128 random bits</li><li>Now, we’ll need to overwrite some of these bits with the correct version and variant information&nbsp;<ol><li>Take the 7th byte and perform an AND operation with <code>0x0F</code> to clear out the high nibble. Then, OR it with <code>0x40</code> to set the version number to 4.&nbsp;</li><li>Next, take the 9th byte and perform an AND operation with <code>0x3F</code> and then OR it with <code>0x80</code>.&nbsp;</li></ol></li><li>Convert the 128 bits to hexadecimal representation and insert the hyphens to achieve the canonical text representation.&nbsp;</li></ol>
<h4><strong>Version 5 (Name-based + SHA-1 Hash)</strong></h4>
<p>This version is no different than Version 3 with the exception that the <code>SHA-1</code> hashing algorithm is used here in place of <code>MD5</code>. This version is preferred to Version 3 (SHA-1 &gt; MD5).&nbsp;</p>
<h2><strong>In Practice</strong></h2>
<p>One of the notable benefits of UUIDs is that their uniqueness does not depend on a central authority or coordination between different systems. Anyone can create UUIDs with reasonable assurance that a duplicate value does not exist and will conceivably not be made in the future.&nbsp;</p>
<p>This has the added benefit of allowing UUIDs generated by independent parties to be combined into a single database or moved across databases with a trivial probability of duplication / collision.&nbsp;</p>
<p>Due to this uniqueness, you can use UUIDs as primary keys in databases, unique filenames for uploaded files, unique names for any web resource, or …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://digitalbunker.dev/2020/09/30/understanding-how-uuids-are-generated/">https://digitalbunker.dev/2020/09/30/understanding-how-uuids-are-generated/</a></em></p>]]>
            </description>
            <link>https://digitalbunker.dev/2020/09/30/understanding-how-uuids-are-generated/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24636204</guid>
            <pubDate>Wed, 30 Sep 2020 06:31:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple’s T2 security chip jailbreak]]>
            </title>
            <description>
<![CDATA[
Score 699 | Comments 345 (<a href="https://news.ycombinator.com/item?id=24636166">thread link</a>) | @Yeri
<br/>
September 29, 2020 | https://reportcybercrime.com/hackers-jailbreak-apples-t2-security-chip-powered-by-bridgeos/ | <a href="https://web.archive.org/web/*/https://reportcybercrime.com/hackers-jailbreak-apples-t2-security-chip-powered-by-bridgeos/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>The Apple T2 security chip has finally been jailbroken! Here’s all you need to know about it.&nbsp; &nbsp; &nbsp;</p>
<h2><span id="The_Apple_T2_Security_chip_now_has_a_jailbreak"><strong>The Apple T2 Security chip now has a jailbreak</strong><span></span></span></h2>
<p>The <a href="https://yalujailbreak.net/checkra1n-jailbreak-ios-14/">latest update of checkra1n</a> adds support for bridgeOS – the operating system that powers the Apple T2 security chip.</p>
<p>For what it’s worth, the T2 chip is not A10 per se but it is derived from the Apple A10 Fusion architecture.&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p><strong>bridgeOS</strong> is a proprietary operating system created by Apple for its hardware. It is responsible for operating the Touch Bar and managing secure data.&nbsp;&nbsp;&nbsp;</p>
<p>Here’s what hacker Jamie Bishop had to say about this development.&nbsp;&nbsp;</p>
<blockquote data-width="550" data-dnt="true">
<p lang="en" dir="ltr">With <a href="https://twitter.com/checkra1n?ref_src=twsrc%5Etfw" target="_blank" rel="nofollow noopener noreferrer">@checkra1n</a> 0.11.0, you can now jailbreak the T2 chip in your Mac. An incredible amount of work went into this and it required changes at multiple levels.</p>
<p>There’s too many people to tag, but shoutout to everyone who worked on getting this incredible feature shipped.</p>
<p>— Jamie Bishop (@jamiebishop123) <a href="https://twitter.com/jamiebishop123/status/1308355178307948545?ref_src=twsrc%5Etfw" target="_blank" rel="nofollow noopener noreferrer">September 22, 2020</a></p>
</blockquote>
<p>Since checkra1n is still in beta, there are a few issues you need to be aware of. Firstly, you might have to reconnect your device after jailbreaking for bootstrap upload.</p>
<p>Secondly, macOS takes over the USB connection and blocks communication after bootup.&nbsp;</p>
<p>If you are interested in jailbreaking the T2 chip, download checkra1n jailbreak v0.11 from this <a href="https://yalujailbreak.net/checkra1n-jailbreak-ios-14/">link</a>.&nbsp;</p>
<h2><span id="What_can_a_bridgeOS_jailbreak_be_used_for"><strong>What can a bridgeOS jailbreak be used for?&nbsp;</strong><span></span></span></h2>
<p>The T2 security processor and the Touch Bar can run while the operating system is shutdown.</p>
<p>Apparently, jailbreak tweak developers could develop tweaks for the Touch Bar if it gets Substrate support in the future.</p>
<p>At present, there are no publicly dumped headers available for bridgeOS. It lacks a MobileSubstrate port too. However, that could change in the future because it shares some of the components of watchOS and iOS frameworks.</p>
<p>Once we get Substrate working, <strong>tweaking and theming could become possible.</strong></p>

<p>The ability to exploit the T2 processor could also allow you to bypass the anti-repair mechanism built into the Touch Bar. Further, it may allow hackers to get rid of the password or unlock MDM-locked systems.&nbsp;</p>
<p>As far as the OS goes, we could also add secure boot certificates like Microsoft’s secure boot signing or a self-signed Linux certificate.&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p>It will definitely be interesting to see what the future holds for the <em>T2 security chip</em> following the release of checkra1n.&nbsp; &nbsp; &nbsp;</p>
<p>Don’t forget to follow us on Twitter and Facebook for the latest jailbreak news and updates.&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</p>
</div></div>]]>
            </description>
            <link>https://reportcybercrime.com/hackers-jailbreak-apples-t2-security-chip-powered-by-bridgeos/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24636166</guid>
            <pubDate>Wed, 30 Sep 2020 06:19:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[From zero to main(): How to write a bootloader from scratch]]>
            </title>
            <description>
<![CDATA[
Score 323 | Comments 44 (<a href="https://news.ycombinator.com/item?id=24635383">thread link</a>) | @tigerlily
<br/>
September 29, 2020 | https://interrupt.memfault.com/blog/how-to-write-a-bootloader-from-scratch | <a href="https://web.archive.org/web/*/https://interrupt.memfault.com/blog/how-to-write-a-bootloader-from-scratch">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        <p>This is the third post in our <a href="https://interrupt.memfault.com/blog/tag/zero-to-main">Zero to main() series</a>,
where we bootstrap a working firmware from zero code on a
cortex-M series microcontroller.</p>

<p>Previously, <a href="https://interrupt.memfault.com/blog/zero-to-main-1">we wrote a startup file to bootstrap our C environment</a>, and <a href="https://interrupt.memfault.com/blog/how-to-write-linker-scripts-for-firmware">a linker
script to get the right data at the right addresses</a>. These two will allow us to
write a monolithic firmware which we can load and run on our microcontrollers.</p>

<p>In practice, this is not how most firmware is structured. Digging through vendor
SDKs, you’ll notice that they all recommend using a <em>bootloader</em> to load your
applications. A bootloader is a small program which is responsible for loading
and starting your application.</p>

<!-- excerpt start -->
<p>In this post, we will explain why you may want a
bootloader, how to implement one, and cover a few advanced techniques you may
use to make your bootloader more useful.
<!-- excerpt end --></p>

<p>Like Interrupt? <a href="http://eepurl.com/gpRedv" target="_blank">Subscribe</a> to get our latest posts straight to your mailbox.</p>



<h2 id="why-you-may-need-a-bootloader">Why you may need a bootloader</h2>

<p>Bootloaders serve many purposes, ranging from security to software architecture.</p>

<p>Most commonly, you may need a bootloader to load your software. Some
microcontrollers like Dialog’s
<a href="https://www.dialog-semiconductor.com/products/connectivity/bluetooth-low-energy/smartbond-da14580-and-da14583">DA14580</a>
have little to no onboard flash and instead rely on an external device to store
firmware code. In that case, it is the bootloader’s job to copy code from
non-executable storage, such as a SPI flash, to an area of memory that can be
executed from, such as RAM.</p>

<p>Bootloaders also allow you to decouple parts of the program that are mission
critical, or that have security implications, from application code which
changes regularly.  For example, your bootloader may contain firmware update
logic so your device can recover no matter how bad a bug ships in your
application firmware.</p>

<p>Last but certainly not least, bootloaders are an essential component of a
trusted boot architecture.  Your bootloader can, for example, verify a
cryptographic signature to make sure the application has not been replaced or
tampered with.</p>

<h2 id="a-minimal-bootloader">A minimal bootloader</h2>
<p>Let’s build a simple bootloader together. To start, our bootloader must do two
things:</p>

<ol>
  <li>Execute on MCU boot</li>
  <li>Jump to our application code</li>
</ol>

<p>We’ll need to decide on a memory map, write some bootloader code, and update our
application to make it bootload-able.</p>

<h3 id="setting-the-stage">Setting the stage</h3>

<p>For this example, we’ll be using the same setup as we did in our previous Zero
to Main posts:</p>
<ul>
  <li>Adafruit’s <a href="https://www.adafruit.com/product/3505">Metro M0 Express</a> as our
development board,</li>
  <li>a simple <a href="https://www.adafruit.com/product/2764">CMSIS-DAP Adapter</a></li>
  <li>OpenOCD (the <a href="https://github.com/arduino/OpenOCD">Arduino fork</a>) for
programming</li>
</ul>

<h3 id="deciding-on-a-memory-map">Deciding on a memory map</h3>

<p>We must first decide on how much space we want to dedicate to our bootloader.
Code space is precious - your application may come to need more of it - and you
will not be able to change this without updating your bootloader, so make
this as small as you possibly can.</p>

<p>Another important factor is your flash sector size: you want to make sure you
can erase app sectors without erasing bootloader data, or vice versa.
Consequently, your bootloader region must end on a flash sector boundary
(typically 4kB).</p>

<p>I decided to go with a 16kB region, leading to the following memory map:</p>

<div><div><pre><code>        0x0 +---------------------+
            |                     |
            |     Bootloader      |
            |                     |
     0x4000 +---------------------+
            |                     |
            |                     |
            |     Application     |
            |                     |
            |                     |
    0x30000 +---------------------+
</code></pre></div></div>

<p>We can transcribe that memory into a linker script:</p>

<div><div><pre><code>/* memory_map.ld */
MEMORY
{
  bootrom  (rx)  : ORIGIN = 0x00000000, LENGTH = 0x00004000
  approm   (rx)  : ORIGIN = 0x00004000, LENGTH = 0x0003C000
  ram      (rwx) : ORIGIN = 0x20000000, LENGTH = 0x00008000
}

__bootrom_start__ = ORIGIN(bootrom);
__bootrom_size__ = LENGTH(bootrom);
__approm_start__ = ORIGIN(approm);
__approm_size__ = LENGTH(approm);
</code></pre></div></div>

<p>Since linker scripts are composable, we will be able to <code>include</code> that memory
map into the linker scripts we write for our bootloader and our application.</p>

<p>You’ll notice that the linker script above declares some variables. We’ll need
those for our bootloader to know where to find the application. To make them
accessible in C code, we declare them in a header file:</p>

<div><div><pre><code><span>/* memory_map.h */</span>
<span>#pragma once
</span>
<span>extern</span> <span>int</span> <span>__bootrom_start__</span><span>;</span>
<span>extern</span> <span>int</span> <span>__bootrom_size__</span><span>;</span>
<span>extern</span> <span>int</span> <span>__approm_start__</span><span>;</span>
<span>extern</span> <span>int</span> <span>__approm_size__</span><span>;</span>
</code></pre></div></div>

<h3 id="implementing-the-bootloader-itself">Implementing the bootloader itself</h3>
<p>Next up, let’s write some bootloader code. Our bootloader needs to start
executing on boot and then jump to our app.</p>

<p>We know how to do the first part from our previous post: we need a valid stack
pointer at address <code>0x0</code> , and a valid <code>Reset_Handler</code>  function setting up our
environment at address <code>0x4</code>. We can reuse our previous startup file and linker
script, with one change: we use  <code>memory_map.ld</code> rather than define our own
<code>MEMORY</code> section.</p>

<p>We also need to put our code in the <code>bootrom</code> region from our memory rather than
the <code>rom</code> region in our previous post.</p>

<p>Our linker script therefore looks like this:</p>

<div><div><pre><code>/* bootloader.ld */
INCLUDE memory_map.ld

/* Section Definitions */
SECTIONS
{
    .text :
    {
        KEEP(*(.vectors .vectors.*))
        *(.text*)
        *(.rodata*)
        _etext = .;
    } &gt; bootrom
  ...
}
</code></pre></div></div>

<p>To jump into our application, we need to know where the <code>Reset_Handler</code> of the
app is, and what stack pointer to load.  Again, we know from our previous post
that those should be the first two 32-bit words in our binary, so we just need
to dereference those addresses using the <code>__approm_start__</code> variable from our
memory map.</p>

<div><div><pre><code><span>/* bootloader.c */</span>
<span>#include &lt;inttypes.h&gt;
#include "memory_map.h"
</span>
<span>int</span> <span>main</span><span>(</span><span>void</span><span>)</span> <span>{</span>
  <span>uint32_t</span> <span>*</span><span>app_code</span> <span>=</span> <span>(</span><span>uint32_t</span> <span>*</span><span>)</span><span>__approm_start__</span><span>;</span>
  <span>uint32_t</span> <span>app_sp</span> <span>=</span> <span>app_code</span><span>[</span><span>0</span><span>];</span>
  <span>uint32_t</span> <span>app_start</span> <span>=</span> <span>app_code</span><span>[</span><span>1</span><span>];</span>
  <span>/* TODO: Start app */</span>
  <span>/* Not Reached */</span>
  <span>while</span> <span>(</span><span>1</span><span>)</span> <span>{}</span>
<span>}</span>
</code></pre></div></div>

<p>Next we must load that stack pointer and jump to the code. This will require a
bit of assembly code.</p>

<p>ARM MCUs use the <a href="http://www.keil.com/support/man/docs/armasm/armasm_dom1361289882044.htm"><code>msr</code> instruction
</a> to
load immediate or register data into system registers, in this case the MSP
register or “Main Stack Pointer”.</p>

<p>Jumping to an address is done with a branch, in our case with a <a href="http://www.keil.com/support/man/docs/armasm/armasm_dom1361289866466.htm"><code>bx</code>
instruction</a>.</p>

<p>We wrap those two into a <code>start_app</code> function which accepts our <code>pc</code> and <code>sp</code> as
arguments, and get our minimal bootloader:</p>

<div><div><pre><code><span>/* app.c */</span>
<span>#include &lt;inttypes.h&gt;
#include "memory_map.h"
</span>
<span>static</span> <span>void</span> <span>start_app</span><span>(</span><span>uint32_t</span> <span>pc</span><span>,</span> <span>uint32_t</span> <span>sp</span><span>)</span> <span>__attribute__</span><span>((</span><span>naked</span><span>))</span> <span>{</span>
    <span>__asm</span><span>(</span><span>"           </span><span>\n</span><span>\
          msr msp, r1 /* load r1 into MSP */</span><span>\n</span><span>\
          bx r0       /* branch to the address at r0 */</span><span>\n</span><span>\
    "</span><span>);</span>
<span>}</span>

<span>int</span> <span>main</span><span>(</span><span>void</span><span>)</span> <span>{</span>
  <span>uint32_t</span> <span>*</span><span>app_code</span> <span>=</span> <span>(</span><span>uint32_t</span> <span>*</span><span>)</span><span>__approm_start__</span><span>;</span>
  <span>uint32_t</span> <span>app_sp</span> <span>=</span> <span>app_code</span><span>[</span><span>0</span><span>];</span>
  <span>uint32_t</span> <span>app_start</span> <span>=</span> <span>app_code</span><span>[</span><span>1</span><span>];</span>
  <span>start_app</span><span>(</span><span>app_start</span><span>,</span> <span>app_sp</span><span>);</span>
  <span>/* Not Reached */</span>
  <span>while</span> <span>(</span><span>1</span><span>)</span> <span>{}</span>
<span>}</span>
</code></pre></div></div>

<blockquote>
  <p>Note: hardware resources initialized in the bootloader must be de-initialized
before control is transferred to the app. Otherwise, you risk breaking
assumptions the app code is making about the state of the system</p>
</blockquote>

<h3 id="making-our-app-bootloadable">Making our app bootloadable</h3>

<p>We must update our app to take advantage of our new memory map. This is again
done by updating our linker script to include <code>memory_map.ld</code> and changing our
sections to go to the <code>approm</code> region rather than <code>rom</code>.</p>

<div><div><pre><code>/* app.ld */
INCLUDE memory_map.ld

/* Section Definitions */
SECTIONS
{
    .text :
    {
        KEEP(*(.vectors .vectors.*))
        *(.text*)
        *(.rodata*)
        _etext = .;
    } &gt; approm
  ...
}
</code></pre></div></div>

<p>We also need to update the <a href="https://developer.arm.com/docs/dui0552/latest/the-cortex-m3-processor/exception-model/vector-table"><em>vector
table</em></a>
used by the microcontroller. The vector table contains the address of every
exception and interrupt handler in our system. When an interrupt signal comes
in, the ARM core will call the address at the corresponding offset in the vector
table.</p>

<p>For example, the offset for the Hard fault handler is <code>0xc</code>, so when a hard
fault is hit, the ARM core will jump to the address contained in the table at
that offset.</p>

<p>By default, the vector table is at address <code>0x0</code>, which means that when our chip
powers up, only the bootloader can handle exceptions or interrupts! Fortunately, ARM
provides the <a href="https://developer.arm.com/docs/dui0552/latest/cortex-m3-peripherals/system-control-block/vector-table-offset-register">Vector Table Offset
Register</a>
to dynamically change the address of the vector table. The register is at
address <code>0xE000ED08</code> and has a simple layout:</p>

<div><div><pre><code>31                                  7              0
+-----------------------------------+--------------+
|                                   |              |
|              TBLOFF               |   Reserved   |
|                                   |              |
+-----------------------------------+--------------+
</code></pre></div></div>

<p>Where <code>TBLOFF</code> is the address of the vector table. In our case, that’s the start
of our text section, or <code>_stext</code>. To set it in our app, we add the following to
our <code>Reset_Handler</code>:</p>

<div><div><pre><code><span>/* startup_samd21.c */</span>
<span>/* Set the vector table base address */</span>
<span>uint32_t</span> <span>*</span><span>vector_table</span> <span>=</span> <span>(</span><span>uint32_t</span> <span>*</span><span>)</span> <span>&amp;</span><span>_stext</span><span>;</span>
<span>uint32_t</span> <span>*</span><span>vtor</span> <span>=</span> <span>(</span><span>uint32_t</span> <span>*</span><span>)</span><span>0xE000ED08</span><span>;</span>
<span>*</span><span>vtor</span> <span>=</span> <span>((</span><span>uint32_t</span><span>)</span> <span>vector_table</span> <span>&amp;</span> <span>0xFFFFFFF8</span><span>);</span>
</code></pre></div></div>

<p>One quirk of the ARMv7-m architecture is the alignment requirement for the
vector table, as specified in section B1.5.3 of the <a href="https://static.docs.arm.com/ddi0403/eb/DDI0403E_B_armv7m_arm.pdf">reference
manual</a>:</p>

<blockquote>
  <p>The Vector table must be naturally aligned to a power of two whose alignment value is greater than or equal
to (Number of Exceptions supported x 4), with a minimum alignment of 128 bytes.The entry at offset 0 is
used to initialize the value for SP_main, see The SP registers on page B1-8. All other entries must have bit
[0] set, as the bit is used to define the EPSR T-bit on exception entry (see Reset behavior on page B1-20 and
Exception entry behavior on page B1-21 for details).</p>
</blockquote>

<p>Our SAMD21 MCU has 28 interrupts on top of the 16 system reserved exceptions,
for a total of 44 entries in the table. Multiply that by 4 and you get 176. The
next power of 2 is 256, so our vector table must be 256-byte aligned.</p>

<h3 id="putting-it-all-together">Putting it all together</h3>

<p>Because it is hard to witness the bootloader execute, we add a print line to
each of our programs:</p>

<div><div><pre><code><span>/* boootloader.c */</span>
<span>#include &lt;inttypes.h&gt;
#include "memory_map.h"
</span>
<span>static</span> <span>void</span> <span>s…</span></code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://interrupt.memfault.com/blog/how-to-write-a-bootloader-from-scratch">https://interrupt.memfault.com/blog/how-to-write-a-bootloader-from-scratch</a></em></p>]]>
            </description>
            <link>https://interrupt.memfault.com/blog/how-to-write-a-bootloader-from-scratch</link>
            <guid isPermaLink="false">hacker-news-small-sites-24635383</guid>
            <pubDate>Wed, 30 Sep 2020 03:19:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How India Censors the Web]]>
            </title>
            <description>
<![CDATA[
Score 172 | Comments 47 (<a href="https://news.ycombinator.com/item?id=24633490">thread link</a>) | @srean
<br/>
September 29, 2020 | http://iamkush.me/how-india-censors-the-web/ | <a href="https://web.archive.org/web/*/http://iamkush.me/how-india-censors-the-web/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p><b>Update (11th April 2020): This paper has been accepted at <a href="https://websci20.webscience.org/">ACM Web Science 2020</a>. A preprint can be accessed on <a href="https://arxiv.org/pdf/1912.08590.pdf" target="_blank">arXiv</a>.</b></p>

<p>Nation states around the world engage in web censorship using a variety of legal and technical methods. India is no different in this regard: the Government of India can legally order internet service providers (ISPs) operating in its jurisdiction to block access to certain websites for its users. This makes the situation different from jurisdictions like Iran and China, where internet censorship is largely centralised. Legal provisions in India, namely Section 69A and Section 79 of the Information Technology (IT) Act, allow the Central Government and the various courts in the country to issue website-blocking orders that ISPs are legally bound to comply with. <strong>Most of these orders are not publically available</strong>.</p>

<p>Recent events and the opaque nature of internet censorship in India motivated us at <a href="https://cis-india.org/" target="_blank">The Center for Internet and Society</a> to study India's censorship mechanism in detail. We spent the last year trying to answer two questions pertaining to how internet users in India experience web censorship:</p>

<ol>  
<li>What are the technical methods of censorship used by ISPs in India?</li>  
<li>Are all ISPs blocking the same websites?</li>  
</ol>

<p><strong>Our work has been so far the largest study of web censorship in India</strong>, both in terms of the number of censorship mechanisms that we test for and the number of potentially-blocked websites (PBWs). </p>

<h3 id="datacuration">Data curation</h3>

<p>We compiled a list of PBWs from three sources:  </p>

<ul>  
<li><b>Government orders</b>: A website/URL blocking order may come from the Government of India (Section 69A, IT Act). These orders are usually not in the public domain, as a confidentiality clause prevents any party from disclosing its contents. We collect published and leaked Government orders.</li>  
<li><b>Court orders</b>: The various courts in India also have the power to issue website blocking orders (Section 79, IT Act). Not all such orders are available in the public domain. However, the Government and BSNL (a public company operating as an ISP) have provided portions of this list when under pressure to respond to Right to Information (RTI) requests.</li>  
<li><b>User reports</b>: <a href="https://internetfreedom.in/" target="_blank">The Internet Freedom Foundation</a> collects and publishes reports from internet users who notice blocked websites.</li>  
</ul>

<p>Collecting data from these sources led to a total of 9673 unique URLs, which yielded 5798 unique websites. To limit ourselves to active websites, we exclude all websites for which we could not resolve via Tor circuits, culminating in a corpus of 4379 PBWs.</p>

<h3 id="networktestsfordetectingcensorship">Network tests for detecting censorship</h3>

<p>We designed four network tests that probe the existence of censorship at the DNS, TCP, HTTP, and TLS level. For the sake of brevity, I'll skip elaborating on the tests in this post; the details can be found in our <a href="https://arxiv.org/pdf/1912.08590.pdf" target="_blank">preprint</a>.</p>

<p>We run these tests for each website in our corpus from connections of six different ISPs (Jio, Airtel, Vodafone, MTNL, BSNL, and ACT), <strong>which together serve more than 98% of Internet users in India</strong>. Our findings not only confirm that ISPs are using different techniques to block websites, but also demonstrate that different ISPs are not blocking the same websites.</p>

<h3 id="results">Results</h3>

<p>In terms of censorship methods, our results confirm that ISPs in India are at liberty to use any technical filtering mechanism they wish: there was, in fact, no single mechanism common across ISPs. </p>

<p>We observe ISPs to be using a melange of techniques for blocking access, such as DNS poisoning and HTTP host header inspection. <b>Our tests also discern the use of SNI inspection being employed by the largest ISP in India (Jio) to block HTTPS communication, the use of which is previously undocumented in the Indian context</b>.</p>

<p><img src="https://i.imgur.com/vDAgGnf.png" alt="img">
</p><center>Censorship techniques employed by Indian ISPs</center>

<p>Further, we notice that all ISPs using multiple censorship mechanisms are not blocking the same websites with each mechanism. For instance, ACT uses only DNS censorship for blocking 233 websites, only HTTP censorship for 1873 websites, and both to block 1615 websites. Such irregularities are illustrated below.</p>

<p><img src="https://i.imgur.com/azWaVJW.png" alt="img">
</p><center>Censorship techniques used by (i) ACT, (ii) Airtel, and (iii) Jio for blocking websites. We notice the same ISP using multiple techniques for blocking different websites.</center>

<h3 id="somealarmingdiscoveries">Some alarming discoveries</h3>

<p>Our study has recorded large inconsistencies in website blocklists of different Indian ISPs. From our list of 4379 PBWs, we find that 4033 are being blocked by at least one ISP’s blocklist. In terms of absolute numbers, we notice that ACT blocks the maximum number of websites (3721). Compared to ACT, Airtel blocks roughly half the number of websites (1892).</p>

<p>Perhaps most surprisingly, we find that only 1115 websites out of the 4033 (just 27.64%) are blocked by all six ISPs. <b>Simply stated, we find conclusive proof that Internet users in India can have wildly different experiences of web censorship.</b></p>

<p><img src="https://i.imgur.com/XXaRpuf.png" alt="img"></p>

<p>Analysing inconsistencies in blocklists also makes it clear that ISPs in India are:</p>

<ol>  
<li>Not properly complying with website blocking (or subsequent unblocking orders), and/or </li>  
<li>Arbitrarily blocking websites without the backing of a legal order.</li>  
</ol>

<p>This has important legal ramifications: <b>India’s <a href="https://bit.ly/netneutralityframework" target="_blank">Net Neutrality regulations</a>, codified in the license agreements that ISPs enter with the Government of India, explicitly prohibit such behaviour</b>.</p>

<p>Our study also points to how the choice of technical methods used by ISPs to censor websites can decrease transparency about state-ordered censorship in India. While some ISPs were serving censorship notices, other ISPs made no such effort. For instance, Airtel responded to DNS queries for websites it wishes to block with <strong>NXDOMAIN</strong>. Jio used <strong>SNI-inspection</strong> to block websites, a choice which makes it <strong>technically impossible for them to serve censorship notices</strong>. Thus, the selection of certain technical methods by ISPs exacerbates the concerns created by the opaque legal process that allows the Government to censor websites.</p>

<h3 id="summingup">Summing up</h3>

<p>Web censorship is a curtailment of the right to freedom of expression guaranteed to all Indians. There is an urgent need to reevaluate the legal and technical mechanisms of web censorship in India to make sure the curtailment is transparent, and the actors accountable. </p>

<p>The whimsical attitude towards web censorship from both ISPs and the Government necessitates the development of a crowdsourced tool to <strong>monitor and measure such censorship from different vantage points in the country</strong>. This will shed further light into the geographical variation of censorship practices by ISPs across India, which is still unclear.</p>

<p>To probe this further we have ported our network tests into an android application, and are looking for volunteers who are willing to run it on their mobile networks. The entire process will be <strong>completely anonymous</strong>; we will not be collecting any user-specific information. If you live in India, please consider running <a href="https://play.google.com/store/apps/details?id=com.censorwatch.netprobesapp">Censorwatch</a>.</p>

<p><strong>Acks</strong> - This study was done in collaboration with <a href="https://gurshabad.github.io/" target="_blank">Gurshabad Grover</a> and <a href="https://www.linkedin.com/in/bansalvarun96/" target="_blank">Varun Bansal</a> at <a href="https://cis-india.org/" target="_blank">The Center for Internet and Society</a>, graciously supported by the <a href="https://www.macfound.org/" target="_blank">MacArthur Foundation</a>.</p>
			</section></div>]]>
            </description>
            <link>http://iamkush.me/how-india-censors-the-web/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24633490</guid>
            <pubDate>Tue, 29 Sep 2020 21:55:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A request to a YouTube video downloads the title 14 times and displays it twice]]>
            </title>
            <description>
<![CDATA[
Score 79 | Comments 58 (<a href="https://news.ycombinator.com/item?id=24631698">thread link</a>) | @anderspitman
<br/>
September 29, 2020 | https://apitman.com/25/#a-request-to-a-youtube-video-downloads-the-title-14-times-and-displays-it-twice | <a href="https://web.archive.org/web/*/https://apitman.com/25/#a-request-to-a-youtube-video-downloads-the-title-14-times-and-displays-it-twice">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
            <div>
              <p>I have a project idea that could involve doing some scraping of YouTube videos, so I started poking
around the HTML output of curling YT links. These things are a site (sp) to behold. If you curl the following
well-known URL and store it in a file:</p>
<p><code>https://www.youtube.com/watch?v=dQw4w9WgXcQ</code></p>
<p>Just searching for the title yields 14 results, spread throughout random HTML and JS. But it's only actually
displayed to the user once on the page, and probably again in the browser tab. It's not just the title
either, there's a ton of duplicated data and bloat throughout the file. I'm guessing it compresses well. I
checked a few other files and they all had between 10 and 18 copies of the title.</p>
<p>I'm not sure what conclusions to draw from this. A lot of them are obviously intended to be
machine-readable for things like <a href="https://ogp.me/">ogp</a>, but do you really need 14 identical copies?</p>
<p>EDIT:</p>
<p>Since this errant observation somehow made it to the <a href="https://news.ycombinator.com/item?id=24631698">Hacker News front page</a>, and eventually got flagged, I have a few more thoughts:</p>
<ul>
<li><p>Sorry the title ended up more clickbatey than intended. It's not making 14 extra HTTP requests just for the title. It originally started with "An HTTP request" but it was a few characters too long for HN, and I didn't spend much time rethinking it.</p>
</li>
<li><p>I agree the extra text isn't a problem (like I said, that'll compress well). I'm more concerned about the underlying complexity it signals. There is more obvious evidence of this complexity (it makes 70 network requests when you load the page even if you pause the video immediately), this is just a novel one for me.</p>
</li>
<li><p>I appreciate the copies which are intended to interoperate with other systems like Twitter and OGP.</p>
</li>
<li><p>I actually appreciate the fact that a JSON blob of all the video metadata is embedded in the HTML. It'll make my scraping task much simpler.</p>
</li>
</ul>

            </div>
          </div></div>]]>
            </description>
            <link>https://apitman.com/25/#a-request-to-a-youtube-video-downloads-the-title-14-times-and-displays-it-twice</link>
            <guid isPermaLink="false">hacker-news-small-sites-24631698</guid>
            <pubDate>Tue, 29 Sep 2020 19:08:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust 2021: GUI]]>
            </title>
            <description>
<![CDATA[
Score 359 | Comments 228 (<a href="https://news.ycombinator.com/item?id=24631611">thread link</a>) | @clarkmoody
<br/>
September 29, 2020 | https://raphlinus.github.io/rust/druid/2020/09/28/rust-2021.html | <a href="https://web.archive.org/web/*/https://raphlinus.github.io/rust/druid/2020/09/28/rust-2021.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>This is a response to the Rust <a href="https://blog.rust-lang.org/2020/09/03/Planning-2021-Roadmap.html">call for blogs 2021</a> and also a followup to <a href="https://raphlinus.github.io/rust/druid/2019/10/31/rust-2020.html">last year’s entry</a>. It will be entirely focused on GUI.</p>

<p>There is considerable interest in GUI toolkits for Rust. As one data point, it was the 6th highest rated challenge for adoption in the <a href="https://blog.rust-lang.org/2020/04/17/Rust-survey-2019.html#rust-adoption---a-closer-look">2019 Rust survey</a>, just behind async I/O. There is also a fair amount of activity towards this goal, though as a community it still feels a bit unfocused. A characteristic sign is that a new GUI toolkit seems to pop up every couple of months or so.</p>

<p>I believe there is great potential for a high-quality GUI toolkit in Rust. At the same time, it’s an incredibly ambitious task. Subtasks within it, for example accelerated GPU drawing and text layout, are in and of themselves incredibly ambitious tasks. I wouldn’t consider a toolkit “ready” for production use until it supported accessibility, and as far as I know there is nothing in the Rust space even starting to work on this.</p>

<p>Yet, perhaps against my better judgment, I find myself devoting most of my time and energy towards building GUI in Rust. In this post I will set out my hopes but also frankly discuss the challenges.</p>

<h2 id="why-gui-in-rust">Why GUI in Rust?</h2>

<p>Simply put, I believe that the strengths of Rust translate well to writing GUI applications, and that the missing piece is the existence of a good toolkit. One strength is Rust’s wide “dynamic range” – the ability to describe application logic in high level terms while still being attentive to low level details. Another is <em>strong</em> cross-platform compatibility. The increasingly rich crate ecosystem is compelling in many domains. And don’t lose sight of the importance of safety. In traditional object-oriented GUI in C++ especially, object lifetimes can be complicated, and it’s not hard to cause crashes, especially on takeoffs and landings.</p>

<p>I do pay attention to the competitive space, and one thing I see is Electron being used more and more, because it solves real problems. But I also believe that the success of Electron creates a real opportunity for a higher performance, lighter weight alternative. And in general for the projects I see in other languages, I find myself <em>wanting</em> to compete against them.</p>

<h2 id="about-druid">About Druid</h2>

<p>The <a href="https://github.com/linebender/druid">Druid</a> toolkit has made impressive progress in the last year, but is still nowhere near stable or complete. If you are looking for a GUI toolkit to develop your application today, Druid is not it.</p>

<p>We are developing the font editor <a href="https://github.com/linebender/runebender">Runebender</a> as the primary motivating application, but, while a lot of pieces are in place, it is sadly not yet usable for day to day font creation work. One of my goals for the rest of the year is to start creating a font in it.</p>

<p>That said, I am very proud of the work that’s been done in the last year. To hit on some of the highlights, we’re just landing basic but capable <a href="https://www.cmyr.net/blog/piet-text-work.html">rich text layout</a>. The keyboard event is close to browser quality (based on <a href="https://crates.io/crates/keyboard-types">keyboard-types</a>). There is incremental painting based on damage regions. Multi-window support is solid, with support for controlling window placement and dynamic hi-dpi. There is tab-focusing between text boxes. All of these are hard problems. Even more so, I am pleased that a lot of the work came from people in the community.</p>

<h2 id="converging-a-vision">Converging a vision</h2>

<p>Imagine a thought experiment for a bit. Obviously Rust is promising for implementing async, but there isn’t a consensus on the best way to do it. Some people feel it should be done with callbacks, and invest considerable effort into overcoming the serious problems with that approach. Others feel it should be done with a polling future trait, but there are multiple versions of that trait: some get the context from thread local storage, others pass it into the poll method. And of course some people feel the syntax should be <code>future.await</code> while others insist on <code>await!(future)</code>. Every couple of months somebody pops up on /r/rust with a new crate that promises to solve “the async problem,” complete with a nice-looking echo server demo.</p>

<p>That’s about where we are today with GUI toolkits. In many ways, I think converging on a single vision in GUI is a harder problem than for async. For one, people have different things they want to do. I’m personally most interested in things that resemble document editors. Others want 3D or video content. In the future, there might be commercial interest in enterprise line-of-business apps or interfaces for medical devices. These all have quite different requirements in the best ways to express UI logic, and how to build them. Not to mention the endless opportunities to bikeshed.</p>

<p>I am not (yet) proposing Druid as the singular vision that the Rust community should converge on. I’m enjoying reading codebases and learning from other Rust GUI projects. In particular, I’m finding lots to like about <a href="https://github.com/hecrj/iced">Iced</a>: it has good solutions to async, 3D graphics (through wgpu), being able to function in a guest window (important for VST plug-ins), among other problems. And I’m getting the sense that it’s easier for developers. The Elm-like reactive architecture maps nicely to Rust, and depending on exactly what you’re trying to do, it’s not hard to figure out how to express your app-specific logic. By contrast, Druid’s reactive model, while efficient and powerful in many ways, has complex concepts such as Haskell-like lenses, and places a burden on the developer to carefully design the “app data” to fit the Druid model. The <a href="https://raphlinus.github.io/rust/druid/2020/09/25/principled-reactive-ui.html">Crochet research prototype</a> is an active exploration into making that simpler. I am thankful to Iced (and other toolkits) for being a model to study.</p>

<p>The work to build consensus is complex and multifaceted, and it cannot be rushed. From my side, I hope to improve the designs and implementations to the point where they are compelling. I also hope to listen to criticisms, many of which are valid. I also think there is more work the community can be doing here. I’d love to see more active effort in trying to learn from the ongoing work and try to synthesize it. The GUI-related threads on /r/rust are sadly not a place where that happens; they most often consist of a statement of requirements (usually presented very informally), followed by a bit of bikeshedding. I don’t have a good answer for how to improve this situation, but put it out there as a problem I’m feeling.</p>

<p>While I think a converged vision is an admirable and ambitious goal, it may not be necessary for a successful GUI ecosystem in Rust. It’s possible that different types of GUI programs will simply require different infrastructure, so even in the long term it makes sense to have ecosystem diversity. Certainly that’s the case in the short and medium term as well, just to explore the space. And even without a grand unifying vision, there is lots of scope to work on infrastructural crates for important pieces of the GUI story, including text layout and related problems.</p>

<h2 id="learning-and-community">Learning and community</h2>

<p>Many Rust projects these days come with what’s basically a marketing pitch: “adopt this codebase, it’s awesome.” I am starting to see the Druid project in a somewhat different light. I consider its primary mission to be <em>teaching and learning</em> the knowledge required to build GUI. To that extent, the community we’re building, hosted on <a href="https://xi.zulipchat.com/">our Zulip instance,</a> is just as important as the code.</p>

<p>The knowledge needed to build GUI has many aspects, and is at all levels. Some of it is at a high level, like the best way to express reactive UI. Some of it is at a low level, like the keyboard event processing. A common thread is that a lot of it is very arcane, not really written down properly anywhere. Fortunately, a lot of it is accessible through reading the code of other open source projects, whether in Rust or in other languages (I’ve found both Chromium and Gecko to be especially useful).</p>

<p>So I consider this a goal, a success criterion, of the Druid project. If somebody wants to know how to solve a problem in GUI, the Druid codebase should be one of the best places to look for answers.</p>

<p>I love research more than most anything, and a lot of my own work has a strong research flavor. That has caused some confusion; some of the things I’m exploring are very speculative and will likely take years to come to fruition. Certainly my research into compute-centric GPU rendering is of that nature; I’m excited about the fact that it promises dramatic performance improvements over the current state of the art, but it’s nowhere near ready to put into production yet. I’m striving for clearer communication so people can have a better idea what is speculative, based on grand futuristic visions, and what is on track to being usable reasonably soon. But both are important aspects of what I consider to be the main mission: fostering learning about how to build GUI.</p>

<h2 id="baby-steps">Baby steps</h2>

<p>While I am driven by a long-term, ambitious vision, the goal of Druid in 2021 is not to deliver a general UI toolkit. Rather, we are deliberately continuing to follow a narrow scope. The primary goal remains the font editor project, and we plan to re-focus attention on that. I do think this is an attainable goal. I also think that what we learn from trying to build a real application with users will be extremely valuable to the more ambitious task.</p>

<p>One project management technique that is proving effective is “cycles.” Instead of trying to solve the most ambitious version of a problem, we choose up front what to push to a future cycle, reducing the scope for the current implementation cycle. An example is the choice to defer BiDi from our recent text work. This is obviously an essential feature for a real GUI toolkit, but we also know it could take weeks or months to get it right. To have any chance of shipping, we have to carefully budget our time and energy on subprojects that easily could expand to absorb our full attention.</p>

<p>A common development pattern for a fledgling GUI toolkit is to have a “hero app” that drives development. It really helps clarify requirements, and also makes it …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://raphlinus.github.io/rust/druid/2020/09/28/rust-2021.html">https://raphlinus.github.io/rust/druid/2020/09/28/rust-2021.html</a></em></p>]]>
            </description>
            <link>https://raphlinus.github.io/rust/druid/2020/09/28/rust-2021.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24631611</guid>
            <pubDate>Tue, 29 Sep 2020 19:00:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fourier Filtering]]>
            </title>
            <description>
<![CDATA[
Score 109 | Comments 38 (<a href="https://news.ycombinator.com/item?id=24629172">thread link</a>) | @gus_massa
<br/>
September 29, 2020 | http://bigwww.epfl.ch/demo/ip/demos/FFT-filtering/ | <a href="https://web.archive.org/web/*/http://bigwww.epfl.ch/demo/ip/demos/FFT-filtering/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Running ...</p><div id="main">
    
    <p>
        Your browser does not support the HTML5 canvas element. Please, try with a newer browser.<br>
    </p>
    

    <div id="imageChooser">
        <div id="imagesContainer">
            <p><img src="http://bigwww.epfl.ch/demo/ip/demos/icons/open_file.png">
                <span>from disk</span>
            </p>

            <p><img src="http://bigwww.epfl.ch/demo/ip/demos/icons/open_url.png">
                <span>from url</span>
            </p>
            
        </div>
        </div>

    
    

     <p id="animationBlock">Steps<br>
         <progress id="animationSteps" min="0" value="1" max="10"></progress> <span>0/5</span>
    </p>

    <div>
        

        <div title="SNR">
            <div>
                <p>SNR:</p>
                <p>0.0</p>
            </div>
        </div>

        <!-- <div class="container-item" title="save a screenshot">
            <a id="export1">
                <div id="export_container">
                    <img id="export_img" src="http://bigwww.epfl.ch/demo/ip/demos/icons/screenshot.png"/>
                </div>
            </a>
        </div>

        <div class="container-item" title="save a screenshot">
            <a id="export2">
                <div id="export_container">
                    <img id="export_img" src="http://bigwww.epfl.ch/demo/ip/demos/icons/screenshot.png"/>
                </div>
            </a>
        </div> -->
    </div>

</div><p>
	© 2018 Image Processing Online Demonstration, Biomedical Imaging Group, EPFL.
	<br>
	The Javascript/HTML5/ImageAccess library (<a href="http://bigwww.epfl.ch/publications/sage0303.html">Reference</a>) 
	was written by <b>Cyril Favre</b>, <b>Robin Lang</b>, and <a href="mailto:daniel.sage@epfl.ch">Daniel Sage</a>.
	</p></div>]]>
            </description>
            <link>http://bigwww.epfl.ch/demo/ip/demos/FFT-filtering/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24629172</guid>
            <pubDate>Tue, 29 Sep 2020 15:42:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Benchmarking TensorFlow on Nvidia GeForce RTX 3090]]>
            </title>
            <description>
<![CDATA[
Score 100 | Comments 101 (<a href="https://news.ycombinator.com/item?id=24628189">thread link</a>) | @rkwasny
<br/>
September 29, 2020 | https://www.evolution.ai/post/benchmarking-deep-learning-workloads-with-tensorflow-on-the-nvidia-geforce-rtx-3090 | <a href="https://web.archive.org/web/*/https://www.evolution.ai/post/benchmarking-deep-learning-workloads-with-tensorflow-on-the-nvidia-geforce-rtx-3090">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>NVIDIA recently released the much-anticipated GeForce RTX 30 Series of Graphics cards, with the largest and most powerful, the RTX 3090, boasting 24GB of memory and 10,500 CUDA cores. This is the natural upgrade to 2018’s 24GB RTX Titan and we were eager to benchmark the training performance performance of the latest GPU against the Titan with modern deep learning workloads.</p><p>Based on the specs alone, the 3090 RTX offers a great improvement in the number of CUDA cores, which should give us a nice speed up on FP32 tasks. However, NVIDIA decided to cut the number of tensor cores in GA102 (compared to GA100 found in A100 cards) which might impact FP16 performance.<br></p><p>‍<br></p><div>
<table>
  <tbody><tr>
    <th></th>
    <th>Titan RTX</th>
    <th>3090 RTX</th>
  </tr>
  <tr>
    <td><i>Architecture</i></td>
    <td>Turing TU102</td>
    <td>Ampere GA102</td>
  </tr>
  <tr>
    <td><i>Cuda cores</i></td>
    <td>4,609</td>
    <td>10,496</td>
  </tr>
  <tr>
    <td><i>Tensor cores</i></td>
    <td>576</td>
    <td>328</td>
  </tr>
  <tr>
    <td><i>Memory</i></td>
    <td>24GB</td>
    <td>24GB</td>
  </tr>
  <tr>
    <td><i>Memory bandwidth</i></td>
    <td>672 GB/sec</td>
    <td>936 GB/sec</td>
  </tr>
  <tr>
    <td><i>TDP (watts)</i></td>
    <td>285</td>
    <td>350</td>
  </tr>
</tbody></table></div><p>System:<br></p><p><em>Ubuntu 18.04.3</em></p><p><em>Driver Version: 455.23.05</em></p><p><em>CUDA Version: 11.1</em></p><p><em>Tensorflow: tf-nightly 2.4.0.dev20200928</em></p><p>It is very important to use the latest version of CUDA (11.1) and latest tensorflow, some features&nbsp;like TensorFloat are not yet available in a stable release at the time of writing.</p><p><br>We use our own fork of the <a href="https://github.com/lambdal/lambda-tensorflow-benchmark/tree/tf2">Lambda Tensorflow Benchmark</a> which measures the training performance for several deep learning models trained on ImageNet.</p><p>‍</p><div>


<table>
	<caption>Training performance in images processed per second</caption>
  <thead>
    <tr>
      <th></th>
      <th colspan="2">FP16</th>
      <th colspan="2">FP32</th>
    </tr>
    <tr>
      <th></th>
      <th>Titan RTX</th>
      <th>RTX 3090</th>
      <th>Titan RTX</th>
      <th>RTX 3090</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><i>AlexNet</i></td>
      <td>6634.31</td>
      <td>8255.43</td>
      <td>4448.46</td>
      <td>6493.16</td>
    </tr>
    <tr>
      <td><i>Inception3</i></td>
      <td>656.13</td>
      <td>616.25</td>
      <td>222.95</td>
      <td>337.31</td>
    </tr>
    <tr>
      <td><i>Inception4</i></td>
      <td>298.11</td>
      <td>132.73</td>
      <td>99.74</td>
      <td>143.65</td>
    </tr>
    <tr>
      <td><i>ResNet152</i></td>
      <td>423.92</td>
      <td>484.02</td>
      <td>134.47</td>
      <td>203.58</td>
    </tr>
    <tr>
      <td><i>ResNet150</i></td>
      <td>966.77</td>
      <td>1259.95</td>
      <td>335.96</td>
      <td>525.88</td>
    </tr>
    <tr>
      <td><i>VGG16</i></td>
      <td>339.73</td>
      <td>442.49</td>
      <td>212.06</td>
      <td>325.60</td>
    </tr>
  </tbody>
</table></div><p>‍</p><p>‍</p><p>‍</p><figure id="w-node-81c38bb21f8c-a8a0c0ce"><p><img src="https://assets.website-files.com/5f286b01a607cf5cd1531aa9/5f731993be0980f19dfb79a2_gpu_benchmark.svg" loading="lazy" alt=""></p><figcaption>Speedup of RTX 3090 over Titan RTX</figcaption></figure><p>‍</p><p>We're able to achieve a 1.4-1.6x training speed-up for all the models training with FP32! As expected, the FP16 is not quite as significant, with a 1.0-1.2x speed-up for most models and a drop for Inception.</p><p>‍</p><p>Please get in touch at <a href="mailto:hello@evolution.ai">hello@evolution.ai</a> with any questions or comments!</p></div></div></div></div>]]>
            </description>
            <link>https://www.evolution.ai/post/benchmarking-deep-learning-workloads-with-tensorflow-on-the-nvidia-geforce-rtx-3090</link>
            <guid isPermaLink="false">hacker-news-small-sites-24628189</guid>
            <pubDate>Tue, 29 Sep 2020 14:24:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Identifying Airtel middleboxes that censor HTTPS traffic]]>
            </title>
            <description>
<![CDATA[
Score 391 | Comments 122 (<a href="https://news.ycombinator.com/item?id=24626388">thread link</a>) | @justDankin
<br/>
September 29, 2020 | http://iamkush.me/sni-airtel/ | <a href="https://web.archive.org/web/*/http://iamkush.me/sni-airtel/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>Back in November 2019, <a target="blank" href="https://cis-india.org/internet-governance/blog/reliance-jio-is-using-sni-inspection-to-block-websites">we reported</a> that Reliance Jio is able to block HTTPS internet traffic by means of a deep packet inspection (DPI) technique. In response, some readers messaged us saying that they ran our test and were able to reproduce similar behaviour on Airtel mobile networks. According to <a href="https://trai.gov.in/sites/default/files/PIR_08012020_0.pdf" target="_blank">TRAI's Performance Indicators report for Jul-Sep 2019</a>, Reliance Jio and Airtel serve roughly 52% and 23% of internet subscribers in India respectively. <strong>This essentially means that SNI inspection based censorship is now impacting every 3 out of 4 internet connections in India.</strong></p>

<p>Although the previous test was able to detect the presence of SNI inspection based censorship, it was not very insightful. In this post, we delve into a more informative test which not only confirms the presence of SNI inspection based censorship, but also helps us identify the exact mechanism. Furthermore, it also allows us to identify middleboxes which are actively inspecting SNI in TLS handshakes and censoring requests. <strong>Using this method, we were able to discover 25 different middleboxes registered to Airtel, which are actively censoring HTTPS traffic.</strong></p>

<p>Quick links to different sections of this post: <br>
1. <a href="#secTLS">Transport Layer Security</a> <br>
1.1 <a href="#secSNI">Server Name Indication</a> <br>
2. <a href="#secSNICensor">SNI Inspection based censorship</a> <br>
3. <a href="#secINT">Iterative Network Tracing</a> <br>
4. <a href="#secData">Data Preparation</a> <br>
5. <a href="#secMethod">Methodology</a> <br>
6. <a href="#secAirtel">Examining Airtel's behaviour</a> <br>
7. <a href="#secRef">References</a></p>

<p>All the code for replicating this experiment, as well as the logs from our test runs can be found in <a target="_blank" href="https://github.com/kush789/INT-SNI">this repository</a>. Big shout-out to <a href="https://ipinfo.io/" target="_blank">IPinfo</a> for giving us access to their IP address dataset, and <a href="https://gurshabad.github.io/" target="_blank">Gurshabad Grover</a> for his suggestions while ideating the methodology and for editing this post.</p>





<p>Transport Layer Security (TLS) is a cryptographic protocol for providing communication confidentiality and authenticity, commonly used for encrypting web traffic (as done in HTTPS). Normally TLS is used over TCP, as it requires a reliable in-order data stream. A <a href="https://www.cloudflare.com/learning/ssl/transport-layer-security-tls" target="_blank">quick refresher</a> on TLS by Cloudflare.</p>

<p><img src="https://i.imgur.com/OlMYujg.png" alt="img">
</p><center>A TCP handshake followed by a TLS Handshake. The ClientHello is a message sent by the client, which initiates the TLS handshake. This message can contain extensions such as SNI. Image credits - <a href="https://www.cloudflare.com/learning/ssl/what-happens-in-a-tls-handshake/">Cloudflare</a></center>



<h3 id="servernameindication">Server Name Indication</h3>

<p>Server Name Indication (SNI), defined first in <a href="https://tools.ietf.org/html/rfc4366" target="_blank">RFC4366</a> and then in <a href="https://tools.ietf.org/html/rfc6066" target="_blank">RFC6066</a>, is a TLS extension designed to facilitate the hosting of multiple HTTPS websites on the same IP address. While sending a <code>ClientHello</code> message (which initiates the establishment of a secure connection), the client is expected to fill in the SNI attribute with the hostname of the website it wishes to connect to. SNI, unfortunately, travels on the network in cleartext, i.e. <strong>network operators can not only see the websites you’re visiting, but also filter traffic based on this information.</strong></p>

<hr>





<p>Since the SNI present is in cleartext, anyone in the network can inspect and filter traffic based on its value. As seen in other countries, ISPs can leverage this to deny access to certain websites. We can observe the same by attempting a TLS connection using openssl and monitoring packets to the host.  </p>

<pre><code>openssl s_client -state -connect 103.224.212.222:443 -servername fullhd720.com  
</code></pre>

<p><img src="https://raw.githubusercontent.com/kush789/INT-SNI/master/images/airtel_103.224.212.222_fullhd720.com.png" alt="img">
</p><center>An attempted TLS connection to <code>103.224.212.222</code>, with SNI <code>fullhd720.com</code>. We observe a RST packet immediately after the ClientHello message containing the SNI is sent.</center>

<p>For instance, using Airtel, we can see that the client receives a TCP RST packet when it tries to connect to a blocked website "fullhd720.com". The RST packet seems to be originating from the actual host, and is received right after the ClientHello message containing the SNI is sent. <a href="https://github.com/kush789/INT-SNI/blob/master/pcaps/airtel_103.224.212.222_fullhd720.com.pcap" target="_blank">PCAP</a>.</p>

<p>To confirm that the connection termination was indeed due to the SNI, we can reattempt the connection with a different SNI which we don't expect to be blocked (in this case we use <code>facebook.com</code>).</p>

<pre><code>openssl s_client -state -connect 103.224.212.222:443 -servername facebook.com  
</code></pre>

<p><img src="https://raw.githubusercontent.com/kush789/INT-SNI/master/images/airtel_103.224.212.222_facebook.com.png" alt="img">
</p><center>An attempted TLS connection to <code>103.224.212.222</code> with a different SNI, <code>facebook.com</code>. In this case, we observe a successful TLS handshake</center>

<p>This time we notice a successful connection, indicating that the RST in the previous attempt was indeed due to the specified SNI. <a href="https://github.com/kush789/INT-SNI/blob/master/pcaps/airtel_103.224.212.222_facebook.com.pcap" target="_blank">PCAP</a>.</p>

<p>Although this test does demonstrate the presence of SNI inspection based censorship, the packet dumps are not sufficient to prove that the RST packet was actually forged by a middlebox belonging to the ISP.</p>

<hr>  





<p>For a given host, let's call the minimum Time to Live (<a href="https://packetpushers.net/ip-time-to-live-and-hop-limit-basics/" target="_blank">TTL</a>) required for a packet to reach from the client to the host, <code>min_ttl</code>. Any packet where the TTL set is less than <code>min_ttl</code> would expire in transit, and never reach the host. Ideally, the router at which the TTL of the packet expired should respond with an ICMP Time Exceeded (<a href="http://www.networksorcery.com/enp/protocol/icmp/msg11.htm" target="_blank">ICMP message type 11</a>) message. However, this is not guaranteed, and some routers are even configured to not send them (in order to hide the topology of the network).</p>

<p><img src="https://i.imgur.com/aSrR375.png" alt="img">
</p><center>Iterative Network Tracing; we send ClientHello messages with increasing TTL. In this particular case, the minimum TTL required is 9. A middlebox which censors requests would send back a censored response even when the TTL is less than 9. Image credits - <a href="#cite1">Yadav et al.</a></center>

<p>So if the RST received is forged by a middlebox, we should receive it even when we send the ClientHello message with TTL less than <code>min_ttl</code>. This approach, known as Iterative Network Tracing (INT), has been previously used to ascertain the presence of middleboxes which censor DNS and HTTP traffic in India [<a href="#cite1">Yadav et al.</a>] and China <a href="#cite2">Xu et al.</a> Similar to these studies, we use INT to detect censorship of TLS traffic (explained further in the <a href="#secMethod">methodology</a> section).</p>

<hr>  





<p>We run our tests using a list of potentially blocked websites (PBWs), curated from leaked court and government orders. The list and more information pertaining to it can be found <a href="https://github.com/kush789/How-India-Censors-The-Web-Data" target="_blank">here</a>.</p>

<p>Using Google's DNS over HTTPS (DoH) <a href="https://developers.google.com/speed/public-dns/docs/doh" target="_blank">service</a>, each hostname was resolved to its correct IP address. Using DoH here is important as it ensures that no DNS based censorship intervenes with the test. This resulted in roughly 5000 (hostname, ip) pairs. Next we selected a random subset and checked for TCP connectivity to port 443 to each of those ips (since not all would support HTTPS traffic), filtering our list down to 1370 pairs.</p>

<p>For each of these test points, we establish a TCP connection with the resolved_ip, and send a TLS ClientHello with the SNI set as the correct_hostname. We sniff and save these ClientHello packets (just the SSL layer) for use later. Similarly, we save the ClientHello packet with the SNI set as <code>facebook.com</code>. These sniffed packets can be found <a href="https://github.com/kush789/INT-SNI/tree/master/tls_client_hellos" target="_blank">here</a>.</p>

<hr>  





<p>The input to the test is a 2-tuple, (<code>correct_hostname</code>, <code>resolved_ip</code>). We would like to understand the behaviour of a middlebox when it observes a ClientHello message containing an SNI for a website it wishes to block.</p>

<p>First, we calculate the <code>min_ttl</code> for a given test point. We begin by establishing a TCP connection with <code>resolved_ip</code>.</p>

<pre><code>import socket  
import random  
from scapy.all import *

resolved_ip = "103.224.212.222"  
dport = 443 # TLS connection  
sport = random.randint(1024, 65535) # Random source port

def create_connection(resolved_ip):  
    s = socket.socket(socket.AF_PACKET, socket.SOCK_RAW)
    s.bind(("usb0", 0)) # Was using a tethered mobile connection for the experiment

    IP_PACKET = IP(dst = resolved_ip)

    seq = random.randint(12345, 67890) # Randomise initial seq number
    SYN = TCP(sport = sport, dport = dport, flags = "S", seq = seq)
    SYNACK = sr1(IP_PACKET / SYN)
    ACK = TCP(sport = sport, dport = dport, flags = "A", seq = seq + 1, ack = SYNACK.seq + 1)
    send(IP_PACKET / ACK)
    return IP_PACKET, ACK
</code></pre>

<p><strong>Note</strong>: When the linux kernel feature gets a TCP packet to an unknown socket, it sends a RST back to the originator. Since we'll be creating our own raw sockets, we need to suppress these outbound RSTs from the kernel using iptables before running experiments.</p>

<pre><code>sudo iptables -A OUTPUT -p tcp --tcp-flags RST RST -j DROP  
</code></pre>

<p>Once the TCP connection has been established, we send ClientHello messages (containing <code>facebook.com</code> in SNI) after updating the TTL (<code>probe_ttl</code>) in the underlying IP header. We specify <code>facebook.com</code> in the SNI so that the middlebox doesn't attempt to terminate the connection. <code>min_ttl</code> would be the minimum TTL at which we receive a TLS ServerHello or TLS Alert from the host.</p>

<pre><code># Load ClientHello with garbled hostname in SNI (sniffed earlier, read Data Preparation)
max_ttl = 35

def find_min_ttl(resolved_ip)

    with open("tls_client_hellos/facebook.com", 'rb') as fp:
        tls_client_hello_facebook_com_sni = fp.read()

    for probe_ttl in range(1, max_ttl):
        IP_PACKET, ACK = create_connection(resolved_ip)
        IP_PACKET.ttl = probe_ttl
        del IP_PACKET.chksum # Will force scapy to recalculate checksum after TTL update

        resp, _ = sr(IP_PACKET / ACK / tls_client_hello_facebook_com_sni, timeout = 2, retry = 0, multi = True)

        for _, ans_packet in resp:
            tls_alert = ans_packet.get(tls.TLS, {}).get(tls.TLSAlert)
            tls_server_hello = ans_packet.get(tls.TLS, {}).get(tls.TLSHandshakes, {}).get(tls.TLSServerHello)

            if tls_alert or tls_server_hello:
                return probe_ttl # min_ttl found!
</code></pre>

<p>Next, we send ClientHello messages containing the <code>correct_hostname</code> in the SNI with TTL increasing from 1 to <code>min_ttl</code> - 1. If there is no middlebox interfering with the connection, all such requests should receive either an ICMP Time Exceeded in response or no response at all. If at any point we receive an RST packet which seems to be originating from <code>resolved_ip</code>, we can say with certainty that the packet was forged by a middlebox.</p>

<pre><code>min_ttl = find_min_ttl(resolved_ip, tls_client_hello)

with open("tls_client_hellos/fullhd720.com", 'rb') as fp:  
    tls_client_hello_correct_sni = fp.read()

for probe_ttl in range(1, min_ttl):  
    IP_PACKET, ACK = create_connection(resolved_ip)
    IP_PACKET.ttl …</code></pre></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://iamkush.me/sni-airtel/">http://iamkush.me/sni-airtel/</a></em></p>]]>
            </description>
            <link>http://iamkush.me/sni-airtel/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24626388</guid>
            <pubDate>Tue, 29 Sep 2020 11:33:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fun Yet Effective Meetings]]>
            </title>
            <description>
<![CDATA[
Score 80 | Comments 42 (<a href="https://news.ycombinator.com/item?id=24624819">thread link</a>) | @thesnide
<br/>
September 28, 2020 | https://blog.pwkf.org/2020/09/27/we-should-only-have-fun-meetings.html | <a href="https://web.archive.org/web/*/https://blog.pwkf.org/2020/09/27/we-should-only-have-fun-meetings.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <blockquote>
  <p>⚠️ This article is extreme &amp; satirical on the purpose of being thought-provoking. Therefore, please, do take it with some grain of salt.</p>

  <p>This is a followup of my <a href="https://blog.pwkf.org/2020/09/26/remote-working-is-a-paradigm-shift.html">Remote-mostly working is a paradigm shift</a>.</p>
</blockquote>



<p>My #1 advice about distributed teams is actually even the case in colocated teams:
<strong>Try as hard as possible to avoid meetings, use textual IM instead</strong> as <a href="https://blog.codinghorror.com/meetings-where-work-goes-to-die/">meetings are where work goes to die</a>.
I know it sounds pretty dull, but if you really think about it you’ll see that it’s usually wasted time.
The usual pattern of decision taking is:</p>

<div><div><pre><code>1. if you don’t have a clue, ask someone else.
2. to ask him, schedule a meeting
3. to schedule a meeting, you have to find a slot
4. that usually postpones the decision
</code></pre></div></div>

<p>Postponing the decision is usually what one really wants, even unknowingly: “<em>to be able to have an excuse not to decide at once</em>”.</p>

<p>It’s a very very fair humane reaction, I also fell myself into that trap.</p>

<p><img src="https://blog.pwkf.org/assets/images/out-of-window.jpg" alt="Thrown out of the fence for proposing an textual chat"></p>



<p>I end up having the following workflow:</p>

<ul>
  <li>Avoid email loops. Those have too much overhead, and will divide your audience pretty quickly.</li>
  <li>Create a slack channel instead of the email loop. This will retain the whole conversation in 1 central place.</li>
  <li>Systematically push back on any meetings. Accept them only if you have a clear statement of who will drive it.</li>
  <li>
    <p>Meetings should be a broadcast mode. All the Q&amp;A should go back to the slack channel.</p>

    <ul>
      <li>Having everything searchable makes it super easy for
        <ul>
          <li>newcomers that can simply scroll back</li>
          <li>old timers such as me that forget and can also simply scroll back</li>
        </ul>
      </li>
      <li>
        <p>Even recorded meetings are a vast of time if you need to find an information, as it’s not indexed.</p>
      </li>
      <li>If not recorded, sending the minutes afterwards are usually a loss of information.
        <ul>
          <li>It’s still very important to extract “executive summaries” from those meetings, even only textual. As can be posted on a public place for massive &amp; broad sharing.</li>
          <li>Yet, the real context on those summaries will be kept inside the whole meeting</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<blockquote>
  <p><strong>Context effectively fights Cargo Cult</strong></p>

  <p>Usually the why of decisions are not provided in a “<a href="https://english.stackexchange.com/questions/120739/a-peek-into-the-sausage-factory">build the sausage</a>” manner. But after a while, the hypothesis of the decision are not true anymore, and therefore another decision has to be taken.</p>

  <p>This is not possible when loss of information occurs and that’s when <a href="https://en.wikipedia.org/wiki/Cargo_cult_programming">Cargo cult</a> begins to creep in.</p>
</blockquote>

<p>In a record-everything scenario, context switch is just a matter of reading back some previous messages. Otherwise you’ll spend numerous times “explaining the context” in a meeting to everyone. And then everyone will just move to something else, and you’ll have pitiful engagement, while still spending time on it.</p>

<p><strong>A company that use its time effectively, is a company that moves much faster than its competitors</strong>, no matter the skillsets in that company. Even if you have the brightest minds, if you waste their talents in boring activities, you’ll dry them up. And either they’ll leave, or worse, they <a href="https://www.sbnonline.com/article/the-quit-and-stay-syndrome-a-business-epidemic-thats-a-silent-profit-killer/">quit &amp; stay</a>.</p>

<blockquote>
  <p>💡 This enabled me to scale to a reasonable multitasking ability while curbing its overhead to a manageable level</p>
</blockquote>

<p><strong>That’s why “startups” are so effective</strong> : they are small and therefore very fast. Being fast brings capacity to try &amp; fail, and therefore agility.</p>

<blockquote>
  <p>💡 <strong>time is the only really scarse resource in a company</strong> : you can’t buy it back, no matter the price.</p>
</blockquote>

<h2 id="why-you-should-only-have-fun-ones">Why you should only have fun ones</h2>

<p>That said, I do agree that travelling is necessary. But we should name the real usecase of travelling : having <em>fun</em> <strong>together</strong>.</p>

<p>The nicest part of that purpose is :</p>

<ul>
  <li>you can plan it far in advance</li>
  <li>you can also budget it in advance</li>
  <li>you can mentally map yourself in those fun times, and focus on actual work right now.</li>
</ul>



<p>The most used reason for meetings is “alignments”, but it is very usually wasted as :</p>

<ul>
  <li>There’s always someone missing for that meeting</li>
  <li>No-one really wants to write the minutes out of it</li>
  <li>If written nonetheless, those minutes are only seldom capturing the <em>why</em> the decision is reached. Which is the most important part!</li>
</ul>

<p>The “<em>there’s always someone missing from that meeting</em>” is the worst part, as usually, that is the one that says “what you decided cannot be done”. And you’ll end up with yet another round of thinking at best. At worst you’ll try to shoehorn your precious alignment (that did sink a huge travel budget) into the needs of that missing person.</p>

<blockquote>
  <p>💡 We can draw a parallel to the paradigm shift I mentioned earlier:</p>
</blockquote>

<ul>
  <li><strong>F2F</strong> Meetings are the <strong>monolith</strong> way.</li>
  <li>Informal, dedicated &amp; <strong>textual meetings</strong> are the <strong>micro-services</strong> way.</li>
</ul>

<p>Now, one immediately notices the following:</p>

<ul>
  <li><strong>People are very much at ease with monoliths</strong>. It takes a huge mental leap to go micro-services.</li>
  <li><strong>Micro-services have an overhead</strong>. But no-one will argue that they can scale way better.</li>
  <li>Monoliths can seldomly be distributed the way micro-services can : you’ll quickly end up with that infamous distributed monolith pattern.</li>
</ul>

<blockquote>
  <p>💡 Now, let’s travel only for “team building” purposes.</p>

  <p>You can plan them in advance, and you won’t have over-budget ones. As their outcome is predictable, and if there’s someone missing, it won’t jeopardy the whole travelling.</p>
</blockquote>

<p>A final word of caution, the reference to scaling is <strong>not about runtime performance</strong>. It’s more about <strong>organisation size</strong>. As Martin Fowler said : <em>don’t even consider microservices unless you have a system that’s too complex to manage as a monolith</em>.</p>

<p>So, it usually makes very much sense to start with a small, colocated team, that has traditional meetings. The trick is to recognize the need to change the paradigm when the team grows, as it always done smoothly over the months. Just don’t forget to have good meeting hygiene (written inputs &amp; outputs), as <strong>even monoliths should be nicely modular</strong>.</p>

<blockquote>
  <p>I posted those 2 articles (<a href="https://blog.pwkf.org/2020/09/26/remote-working-is-a-paradigm-shift.html">Remote-mostly working</a>, <a href="https://blog.pwkf.org/2020/09/27/we-should-only-have-fun-meetings.html">Effective Meetings</a>) internally to my company some years ago, but I’m republishing those publicly to help others the same way it helped us.</p>
</blockquote>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://blog.pwkf.org/2020/09/27/we-should-only-have-fun-meetings.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24624819</guid>
            <pubDate>Tue, 29 Sep 2020 06:54:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[City of Amsterdam’s Algorithm Register]]>
            </title>
            <description>
<![CDATA[
Score 142 | Comments 40 (<a href="https://news.ycombinator.com/item?id=24623639">thread link</a>) | @cpeterso
<br/>
September 28, 2020 | https://algoritmeregister.amsterdam.nl/en/ai-register/ | <a href="https://web.archive.org/web/*/https://algoritmeregister.amsterdam.nl/en/ai-register/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-pm="normal" data-desktopportraitmargin="5|*|0|*|65|*|0|*|px+" data-tabletportraitmargin="0|*|0|*|0|*|0|*|px+" data-mobileportraitmargin="-20|*|0|*|0|*|0|*|px+" data-desktopportraitheight="0" data-has-maxwidth="1" data-desktopportraitmaxwidth="520" data-tabletportraitmaxwidth="430" data-mobileportraitmaxwidth="295" data-cssselfalign="inherit" data-desktopportraitselfalign="inherit" data-sstype="layer" data-rotation="0" data-desktopportrait="1" data-desktoplandscape="1" data-tabletportrait="1" data-tabletlandscape="1" data-mobileportrait="1" data-mobilelandscape="1" data-adaptivefont="0" data-desktopportraitfontsize="100" data-tabletportraitfontsize="90" data-mobileportraitfontsize="120" data-plugin="rendered"><div><p><br>The Algorithm Register is an overview of the artificial intelligence systems and algorithms used by the City of Amsterdam. Through the register, you can get acquainted with the quick overviews of the city's algorithmic systems or examine their more detailed information based on your own interests. You can also give feedback and thus participate in building human-centered algorithms in Amsterdam. The register is still under development.</p></div></div></div>]]>
            </description>
            <link>https://algoritmeregister.amsterdam.nl/en/ai-register/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24623639</guid>
            <pubDate>Tue, 29 Sep 2020 02:27:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenBSD on the Desktop (Part I)]]>
            </title>
            <description>
<![CDATA[
Score 86 | Comments 51 (<a href="https://news.ycombinator.com/item?id=24622788">thread link</a>) | @upofadown
<br/>
September 28, 2020 | https://paedubucher.ch/articles/2020-09-05-openbsd-on-the-desktop-part-i.html | <a href="https://web.archive.org/web/*/https://paedubucher.ch/articles/2020-09-05-openbsd-on-the-desktop-part-i.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Let's install OpenBSD on a Lenovo Thinkpad X270. I used this computer for my
computer science studies. It has both Arch Linux and Windows 10 installed as
dual boot. Now that I'm no longer required to run Windows, I can ditch the dual
boot and install an operating system of my choice.</p>

<p>First, I grab my work Thinkpad running Arch Linux and some USB dongle big enough
for the <a href="https://cdn.openbsd.org/pub/OpenBSD/6.7/amd64/miniroot67.fs">amd64 miniroot
image</a> (roughly
five megabytes, that is). This small image does not include the file sets, which
will be downloaded during installation instead. I also download the <a href="https://mirror.ungleich.ch/pub/OpenBSD/6.7/amd64/SHA256">SHA256
checksums</a> from the
Swiss mirror, and verify the downloaded image, before I copy it on my dongle:</p>
<pre><code>$ sha256sum -c --ignore-missing SHA256 
miniroot67.fs: OK
$ sudo dd if=miniroot67.fs of=/dev/sda bs=1M
</code></pre>

<p>The Thinkpad X270 is connected to my network through Ethernet. The WiFi firmware
usually needs to be installed separately, so only Ethernet will work out of the
box. The BIOS has UEFI activated. OpenBSD and UEFI has issues on older hardware
(at least on a 2014 Dell laptop I have), but let's try it on this laptop,
anyway.</p>
<p>I plug in the dongle prepared before, and start the computer. I interrupt
the regular boot with Enter and pick an alternative boot method by pressing F12.
Now I pick my USB dongle. After roughly a minute, the installer has been
started. Now I follow these steps:</p>
<ul>
<li>I choose the option <code>I</code> to install OpenBSD.</li>
<li>For the keyboard layout, I pick <code>sg</code>, for Swiss German.</li>
<li>As a hostname, I simply pick <code>x270</code>, because it's a Thinkpad X270, and I'm not
  very creative when it comes to naming things.</li>
<li>From the available network options (<code>iwm0</code>: WiFi, <code>em0</code>: Ethernet, and
  <code>vlan0</code>: Virtual LAN), I pick <code>em0</code>.</li>
<li>I try to get an IPv4 address over DHCP, which seems to work very quickly.</li>
<li>Next, I type in my very secret root password twice.</li>
<li>I do <em>not</em> start <code>sshd</code> by default, because I don't need to connect to this
  machine through SSH. It's supposed to be a workstation, not a server.</li>
<li>The X Window System should not be started by <code>xnodm(1)</code>, so I leave it to
  <code>no</code>.</li>
<li>Neither do I want to change the default to <code>com0</code>.</li>
<li>I set up my user <code>patrick</code> with my proper name <code>Patrick Bucher</code>, and a decent
  password.</li>
<li>The time zone has been detected properly as <code>Europe/Zurich</code>, which I just
  leave the way it is.</li>
<li>The installer detected two disks: <code>sd0</code> and <code>sd1</code>. Since <code>sd0</code> is the detected
  SSD in my laptop, the UEFI issue from my Dell laptop doesn't exist on this
  computer. I pick <code>sd0</code> for the root disk, since <code>sd1</code> is my USB dongle.</li>
<li>I choose to use the whole disk with a GPT partitioning schema, because it's
  2020.</li>
<li>An auto-allocated layout for <code>sd0</code> is presented. It looks decent to me, so I
  just go with that auto layout.</li>
<li>I don't want to initialize another disk, so I just press Enter (<code>done</code>).</li>
<li>Since the miniroot image does not come with the file sets, I pick <code>http</code> as
  the location for the sets.</li>
<li>I don't use a proxy, and use the mirror <code>mirrog.ungleich.ch</code> and the server
  directory <code>pub/OpenBSD/6.7/amd64</code> as proposed.</li>
<li>Next, I unselect the game sets by entering <code>-game*</code>. (I heard that they're not
  much fun to play.) I leave all the other sets activated, including the <code>x</code>
  sets, which will be required for the GUI later on.</li>
<li>After those sets are installed, I press Enter (<code>done</code>). Now the installer
  performs various tasks, after which I choose to <code>halt</code> the computer. This
  gives me time to remove the USB dongle.</li>
</ul>

<p>I now restart my laptop, and OpenBSD boots. This takes more time than booting
Arch Linux, which uses <code>systemd</code>, whereas OpenBSD uses <code>rc</code>, which performs the
startup tasks sequentially.</p>
<p>There's a message showing up that various firmware (<code>intel-firmware</code>,
<code>iwm-firmware</code>, <code>inteldrm-firmware</code>, <code>uvideo-firmware</code>, and <code>vmm-firmware</code>) has
been installed automatically. Very nice, indeed.</p>
<h2>WiFi Connection</h2>
<p>Now that the <code>iwm-firmware</code> has been installed, I can connect right away to my
WiFi network <code>frzbxpdb5</code>. I create a file called <code>/etc/hostname.iwm0</code>, wich
<code>hostname</code> being a literal string, and <code>iwm0</code> being the WiFi network card. The
connection to my WiFi network consists of a single line:</p>
<pre><code>dhcp nwid frzbxpdb5 wpakey [my-wpakey]
</code></pre>
<p>Whereas <code>frzbxpdb5</code> is my WiFi network's ESSID, and <code>[my-wpakey]</code> needs to be
replaced by the actual WPA key.</p>
<p>Then the networking can be restarted for that device:</p>
<pre><code># sh /etc/netstart iwm0
</code></pre>
<p>This script is kind enough to set the file permissions of <code>/etc/hostname.iwm0</code>
to <code>640</code>, and then connects to my WiFi network.</p>
<p>I unplug the Ethernet cable and <code>ping openbsd.org</code>, which works fine, even after
a restart.</p>

<p>My GUI on Unix-like systems is based on the Dynamic Window Manager (<code>dwm</code>) and a
couple of other tools, such as <code>dmenu</code>, <code>st</code>, <code>slstatus</code>, <code>slock</code>, all created and
maintained by the <a href="http://suckless.org/">Suckless</a> community.</p>
<p>This software doesn't come with configuration facilities, but needs to be
configured in the respective C header file <code>config.h</code>, and then re-compiled.
Even though OpenBSD offers <code>dwm</code> as a package, customizing and configuring that
window manager requires to build it from source.</p>
<h2>Building <code>dwm</code> and Friends</h2>
<p>First, I need to install <code>git</code> to fetch the source code:</p>
<pre><code># pkg_add git
</code></pre>
<p>Then I fetch the source code for <code>dwm</code>, <code>dmenu</code>, <code>st</code>, and <code>slstatus</code> from <a href="http://suckless.org/">Suckless</a>:</p>
<pre><code>$ git clone https://git.suckless.org/dwm
$ git clone https://git.suckless.org/dmenu
$ git clone https://git.suckless.org/st
$ git clone https://git.suckless.org/slstatus
</code></pre>
<h3>Building <code>dwm</code></h3>
<p>Next, I try to build <code>dwm</code>:</p>
<pre><code>$ cd dwm
$ make
</code></pre>
<p>This fails with an error message (<code>'ft2build.h' file not found</code>), which reminds
me of building <code>dwm</code> on FreeBSD roughly a month before. Since I can finde the
header file at another location:</p>
<pre><code># find / -type f -name ft2build.h
/usr/X11R6/include/freetype2/ft2build.h
</code></pre>
<p>I simply can modify the <code>config.mk</code> accordingly by changing</p>
<pre><code>FREETYPEINC = /usr/include/freetype2
</code></pre>
<p>to</p>
<pre><code>FREETYPEINC = $(X11INC}/freetype2
</code></pre>
<p>Actually, I only need to comment the above line, and uncomment the line below</p>
<pre><code># OpenBSD (uncomment)
</code></pre>
<p>The Suckless folks obviously are friendly towards OpenBSD, which is also
noticable in other places (more evidence to be shown further below).</p>
<p>The next compilation attempt succeeds:</p>
<pre><code>$ make
</code></pre>
<p>So let's install <code>dwm</code>, too:</p>
<pre><code># make install
</code></pre>
<p>By default, and as to be seen in <code>config.h</code>, the keyboard combination
<code>[Alt]+[Shift]+[Enter]</code> (deeply engraved into the muscle memories of many <code>dwm</code>
users) starts the <code>st</code> terminal. This will be built in a while. However, I
prefer to use the <em>Super</em> or <em>Windows</em> key instead of <code>Alt</code>, since the former
is of no use in OpenBSD, and the latter still comes in handy when working with
the emacs readline mode. Therefore, I change the <code>MODKEY</code> from</p>
<pre><code>#define MODKEY Mod1Mask
</code></pre>
<p>to</p>
<pre><code>#define MODKEY Mod4Mask
</code></pre>
<p>Then I rebuild and reinstall <code>dwm</code>:</p>
<pre><code># make install
</code></pre>
<h3>Building <code>st</code></h3>
<p>Let's switch over to the <code>st</code> source directory and just try to compile it:</p>
<pre><code>$ cd ../st
$ make
</code></pre>
<p>Here, we get a warning that the function <code>pledge</code> (an OpenBSD mitigation, which
is built into the <code>master</code> branch, but surrounded by an <code>ifdef</code> preprocessor
statement, so that it will only be compiled for OpenBSD) is imported implicitly.
Let's just ignore this warning for now.</p>
<p>What's worse, the compilation fails with the error message:</p>
<pre><code>ld: error: unable to find library -lrt
</code></pre>
<p>Here, the FAQ comes in handy, stating that</p>
<pre><code>If you want to compile st for OpenBSD you have to remove -lrt from
config.mk, ...
</code></pre>
<p>Having done so in <code>config.mk</code>, <code>st</code> compiles without any further issues, and,
thus, can be rebuilt and installed:</p>
<pre><code># make install
</code></pre>
<h3>Building <code>dmenu</code></h3>
<p>Even OpenBSD users with Suckless tools have to open another GUI application than
a terminal emulator once in a while. For this purpose, Suckless offers <code>dmenu</code>.
Let's switch over to it and compile it:</p>
<pre><code>$ cd ../dmenu
$ make
</code></pre>
<p>Again, we have the issue with <code>ft2build.h</code>, which can be resolved as above with
<code>dwm</code>: by using the proper path for <code>FREETYPEINC</code> in <code>config.mk</code>. Afterwards,
the build succeeds, and <code>dmenu</code> can be installed:</p>
<pre><code># make install
</code></pre>
<h3>Building <code>slstatus</code></h3>
<p><code>dwm</code> has a status bar on the top right, which can be used to show various
information. I used to write some shell commands in <code>.xinitrc</code> to compose such a
status line, and then set it by <code>xset -b</code> once every five seconds or so. This
approach generates a multitude of processes every couple of seconds.</p>
<p><code>slstatus</code> is a C programm that is capable of showing various kinds of more or
less useful information. Let's switch over to <code>slstatus</code> and see, what is
available in <code>config.def.h</code>:</p>
<pre><code>$ cd ../slstatus
$ less config.def.h
</code></pre>
<p>The comments section lists different functions (<code>battery_perc</code> for the battery
percentage, <code>datetime</code> for date and time information, <code>temp</code> for thermal
information, etc.). I usually display the CPU load, the battery percentage, the
memory usage, the current keyboard layout, and the current date and time.</p>
<p>Before configuring those, let's try to compile <code>slstatus</code>:</p>
<pre><code>$ make
</code></pre>
<p>This worked fine, so let's configure the information to be displayed in
<code>config.h</code>:</p>
<pre><code>static const struct arg args[] = {
    /* function    format    argument */
    { datetime,    "%s",     "%F %T" },
};
</code></pre>
<p>This renders the current date as follows:</p>
<pre><code>$ date +"%F %T"
2020-09-05 19:26:38
</code></pre>
<p>I also like to have the weekday included, but not the seconds, so I define a
different argument string:</p>
<pre><code>$ date +"%a %Y-%m-%d %H:%M"
Sat 2020-09-05 19:27
</code></pre>
<p>That's better, so let's use it in <code>config.h</code> (surrounded with some spaces in the
format string):</p>
<pre><code>static const struct arg args[] = {
    /* function    format    argument */
    { datetime,    " %s ",   "%a %Y-%m-%d %H:%M" },
};
</code></pre>
<p>The other settings I like to have do not require any arguments, at least not on
OpenBSD, so I only need to define a decent format string (with <code>|</code> as a
seperator) for those:</p>
<pre><code>static const struct arg args[] = {
    /* function    format           argument */
    { cpu_perc,     " cpu: %s%% |", NULL },
    { battery_perc, " bat: %s%% |", NULL },
    { ram_used,     " mem: %s |",   NULL },
    { keymap,       " %s |"         NULL },
    { datetime,     " %s ",         "%a %Y-%m-%d %H:%M" },
};
</code></pre>
<p>This actually compiles, so let's install it:</p>
<pre><code># make install
</code></pre>
<h2>Configuring X Startup</h2>
<p>Now that all software is compiled and installed, let's run X. To do so, a file
<code>.xinitrc</code> in the user's directory is …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://paedubucher.ch/articles/2020-09-05-openbsd-on-the-desktop-part-i.html">https://paedubucher.ch/articles/2020-09-05-openbsd-on-the-desktop-part-i.html</a></em></p>]]>
            </description>
            <link>https://paedubucher.ch/articles/2020-09-05-openbsd-on-the-desktop-part-i.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24622788</guid>
            <pubDate>Tue, 29 Sep 2020 00:23:20 GMT</pubDate>
        </item>
    </channel>
</rss>
