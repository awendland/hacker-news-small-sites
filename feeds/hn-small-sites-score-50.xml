<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 21 Feb 2021 08:33:53 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 21 Feb 2021 08:33:53 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[12 requests per second: A realistic look at Python web frameworks]]>
            </title>
            <description>
<![CDATA[
Score 267 | Comments 105 (<a href="https://news.ycombinator.com/item?id=26188765">thread link</a>) | @gilad
<br/>
February 18, 2021 | https://suade.org/dev/12-requests-per-second-with-python/ | <a href="https://web.archive.org/web/*/https://suade.org/dev/12-requests-per-second-with-python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<article>

<figure>
<img src="https://suade.org/content/images/2021/01/The_Tortoise_and_the_Hare_-_Project_Gutenberg_etext_19993-1.jpeg" alt="12 requests per second">
</figure>
<section>
<div>
<blockquote>
<p>A realistic look at Python web frameworks</p>
</blockquote>
<p>If you take a look around the blogosphere at various benchmarks for Python web frameworks, you might start to feel pretty bad about your own setup. Or, alternatively, super-hyped about the possibilities.</p><p>Consider, for instance, the incredible work of the guys at <a href="https://magic.io/blog/uvloop-blazing-fast-python-networking/">magic stack</a>, getting <strong>100,000 requests per second</strong> from <a href="https://github.com/MagicStack/uvloop">uvloop</a> in a single thread. This is on par with compiled language like Go's performance.</p><p>But that benchmark doesn't really cover a fully fleshed out web framework, right? We need a lot more functionality and structure from our frameworks than reading and writing bytes. What about fully fleshed-out web-frameworks in python?</p><p>One such framework is <a href="https://github.com/sanic-org/sanic">Sanic</a>, which again has been shown to have similar performance: <strong>100,000</strong> requests per-second. Or there's <a href="https://vibora.io/">Vibora</a>. Not only does this claim to be a drop-in replacement for <a href="https://github.com/pallets/flask">Flask</a>, but it also has its own templating engine. And it handles <strong>350,000 requests per second</strong>!</p><p>Even more mind-blowing is <a href="https://github.com/squeaky-pl/japronto">Japronto</a> which claims an insane <strong>1.2 million requests per-second</strong> in a single thread ü§Ø trouncing the performance of other languages and frameworks:</p><p><img src="https://raw.githubusercontent.com/squeaky-pl/japronto/master/benchmarks/results.png" alt="https://github.com/squeaky-pl/japronto"></p><p>Recently we've been doing a lot of work improving the performance of our Python APIs. Currently we're running <a href="https://github.com/pallets/flask">Flask</a>, and we initially had a single question: <em>how can we serve more requests from a single worker thread? </em>But looking at these benchmarks had us asking more:</p><ol><li>Can we meaningfully compare them to our setup?</li><li>How realistic are they for a full production application?</li><li>Would we be better using one of these frameworks over Flask?</li></ol><p>In other words, how much should we trust these benchmarks? And to what extent should they influence our choice of technology?</p><p>In order to answer these questions, in this post, I benchmark a realistic Flask application along with it's <a href="https://github.com/sanic-org/sanic">Sanic</a> equivalent. I'm going to guess that most readers come from a background with one of the more "traditional" Python frameworks (<a href="https://github.com/pallets/flask">Flask</a> or <a href="https://www.djangoproject.com/">Django</a>), and it's certainly more relevant to devs here at Suade Labs. For this reason, I run the Flask app in a number of different ways, to see what the best bang for our buck is: how performant can we make our application with (almost) zero changes to the code? Along the way we'll pick up some tips for the original question: <em>how can we serve more requests from a single worker thread?</em></p><p><strong>Sidenote: </strong>if you're new to Python's web frameworks, or its asynchronous libraries, take a look at [1] from the addenda at the bottom of this post for a quick explainer. This post mostly assumes you know these things.</p><h2 id="the-baseline">The baseline</h2><p>First let's run some simple "Hello, World!" benchmarks on our system to get a meaningful baseline for comparison. For reference, the Flask benchmarks on <a href="https://www.techempower.com/benchmarks/#section=data-r18&amp;hw=ph&amp;test=fortune&amp;l=zijzen-f">techempower</a> give 25,000 requests per second.</p><p>Here's our Flask app:</p><pre><code>app = Flask(__name__)

@app.route("/", methods=["GET", "POST"])
def hello():
    if request.method == "GET":
        return "Hello, World!"

    data = request.get_json(force=True)
    try:
        return "Hello, {id}".format(**data)
    except KeyError:
        return "Missing required parameter 'id'", 400</code></pre><p>I ran it under a variety of conditions. First "raw" via <code>python app.py</code>, and then under <a href="https://gunicorn.org/">Gunicorn</a> with a single <code>sync</code> worker via <code>gunicorn -k sync app:app</code> and finally Gunicorn with a single <a href="https://github.com/gevent/gevent">gevent</a> worker via <code>gunicorn -k gevent app:app</code>. In theory Gunicorn should handle concurrency and dropped connections much better than the raw python, and using the gevent worker should allow us to do asynchronous IO without changing our code [2a]. We also ran these benchmarks under <a href="https://www.pypy.org/">PyPy</a>, which in theory should speed up any CPU-bound code without making any changes (if you haven't heard of PyPy see [2b] in the addenda below for a quick explanation and some terminology).</p><p>And what about Sanic? Well, here's the "rewrite" of our app:</p><pre><code>app = Sanic(__name__)

@app.route("/", methods=["GET", "POST"])
async def hello(request):
    if request.method == "GET":
        return text("Hello, World!")

    data = request.json
    try:
        return text("Hello, {id}".format(**data))
    except KeyError:
        raise InvalidUsage("Missing required parameter 'id'")</code></pre><p>And here are the results:</p><figure><img src="https://suade.org/content/images/2021/01/hello_world-3.png" alt="" srcset="https://suade.org/content/images/size/w600/2021/01/hello_world-3.png 600w, https://suade.org/content/images/size/w1000/2021/01/hello_world-3.png 1000w, https://suade.org/content/images/2021/01/hello_world-3.png 1161w" sizes="(min-width: 720px) 720px"></figure><div><p>Some technical details: I used Python 3.7 with the regular CPython interpreter and Python 3.6 with PyPy 7.3.3. At the time of writing, running 3.6 is the latest PyPy interpreter, and their Python 2.7 interpreter is faster in some edge cases, but as Python 2 is <a href="https://www.python.org/doc/sunset-python-2/">officially dead</a>, I don't believe it productive to benchmark. My system details are available in the addenda [3]. I used <a href="https://github.com/wg/wrk">wrk</a> to actually execute the benchmarks.</p><p>I'll break the results down in two parts. First: Sanic dominates, with 23,000 requests a second, although running our Flask app under Guncorn + gevent and PyPy does a pretty good job at keeping up. Second: what's going on with the performance range for our Flask app?</p></div><p>Under CPython, we see that using Gunicorn quadruples the number of Flask requests per second from 1,000 to 4,000 and using a gevent worker adds a mild (sub 10%) speed boost to this. The PyPy results are more impressive. In the raw test, it is churning through 3,000 requests a second; it received the same 4x speed boost from Gunicorn, getting us to 12,000 requests a second; finally with the addition of gevent, it cranks up to 17,000 requests a second, 17x more than the raw CPython version without changing a single line of code.</p><p>I was quite struck by the fact that gevent had such little effect on the CPython process - probably this is because the CPU is maxed out at this point. On the other hand, it seems that PyPy's better speed means it is still spending time waiting on system calls / IO, even under Gunicorn. Adding gevent to the mix means that it switches between concurrent connections, processing them as fast as the CPU will let it.</p><p>To get a real sense of this, I ran the benchmark whilst monitoring CPU usage. Here's a short test against the raw app under PyPy:</p><figure><img src="https://suade.org/content/images/2021/01/sync_cpu_usage.png" alt="" srcset="https://suade.org/content/images/size/w600/2021/01/sync_cpu_usage.png 600w, https://suade.org/content/images/2021/01/sync_cpu_usage.png 919w" sizes="(min-width: 720px) 720px"></figure><p>You can see that the program hops between CPU cores and rarely utilises 100% of a given core. On the other hand, here's part of a much longer test against the Gunicorn gevent worker under PyPy:</p><figure><img src="https://suade.org/content/images/2021/01/gevent_cpu_usage.png" alt="" srcset="https://suade.org/content/images/size/w600/2021/01/gevent_cpu_usage.png 600w, https://suade.org/content/images/2021/01/gevent_cpu_usage.png 900w" sizes="(min-width: 720px) 720px"></figure><p>Now it's evident that there is no switching between CPU cores (the process has become "sticky") and the individual core is being utilised to a far higher degree.</p><p><strong>Key takeaways</strong>: Sanic wins. PyPy is fast. Run your "traditional" app under Gunicorn.</p><h2 id="realistic-benchmarks">Realistic benchmarks</h2><div><p>The benchmark above, while fun, is pretty meaningless for real-world applications. Let's add some more functionality to our app!</p><p>First, we'll allow users to actually store data in a database, which we'll retrieve via an ORM (in our case <a href="https://www.sqlalchemy.org/">SQLAlchemy</a>, the de-facto stand-alone ORM in python). Second, we'll add input-validation to make sure our users get meaningful error messages, and that we're not accepting junk that crashes our app. Finally we'll add a response marshaller to automate the process of converting our database object to JSON.</p></div><p>We'll write a simple book store app, for a publishing house. We have a number of authors each writing zero or more books in several genres. For simplicity, each book has only a single author, but can have multiple genres - for example we could have a book which is in both the "Existential Fiction" and "Beatnik Poetry" categories. We're going to add 1 million authors to our database and roughly 10 million books. [4]</p><p>Our SQLAlchemy models look a little like this:</p>
<pre><code>class Author(db.Model):
    id = db.Column(UUIDType, primary_key=True)
    name = db.Column(db.String, nullable=False)
    ... # snip!

class Book(db.Model):
    author_id = db.Column(
        UUIDType, db.ForeignKey("author.id"), nullable=False, index=True
    )
    author = db.relationship("Author", backref="books")
    ... # snip!
</code></pre>
<p>To marshal these, we use <a href="https://marshmallow.readthedocs.io/en/stable/">Marshmallow</a>, which is a popular Python marshalling library. Here's an example of the Marshmallow model for the Author overview:</p>
<pre><code>class Author(Schema):
    id = fields.Str(dump_only=True)
    name = fields.Str(required=True)
    country_code = EnumField(CountryCodes, required=True)
    email = fields.Str(required=True)
    phone = fields.Str(required=True)
    contact_address = fields.Str(required=True)
    contract_started = fields.DateTime(format="iso")
    contract_finished = fields.DateTime(format="iso")
    contract_value = fields.Integer()
</code></pre>
<p>In our endpoints these are used for validating input and returning results like so:</p>
<pre><code>@bp.route("/author", methods=["GET", "POST"])
def author():
    """View all authors, or create a new one."""

    if request.method == "GET":
        args = validate_get(marshallers.LimitOffsetSchema())
        limit = args["limit"]
        offset = args["offset"]

        authors = Author.query.limit(limit).offset(offset).all()
        return jsonify(marshallers.authors.dump(authors))

    if request.method == "POST":
        author = Author(**validate_post(marshallers.author))

        db.session.add(author)
        db.session.commit()

        return jsonify({"id": author.id})
</code></pre>
<p>The full source code can be viewed in the <a href="https://github.com/olliemath/async_python">GitHub repo</a>. Here, the thing to note is that <code>marshallers.foo</code> is an instance of a <a href="https://marshmallow.readthedocs.io/en/stable/">Marshmallow</a> schema, which can be used both to validate a Foo input, for instance in a POST request, as well as to marshal Foo instances ready for returning as JSON.</p>
<p>In order to actually perform asynchronous database requests, some fancy footwork is required with patching libraries, which depends on which postgres connector you use. SQLAlchemy does not support this out of the box, and in fact its primary developer has a great post arguing that <a href="https://techspot.zzzeek.org/2015/02/15/asynchronous-python-and-databases/">an async ORM is not always a great idea</a>. Juicy technical details in addenda [5], but beware that just using a Gunicorn gevent worker will not necessarily get you what you want.</p><p>PyPy tends to suffer a performance hit when using C-extensions and libraries instead of pure python, conversely CPython should get a performance boost from the C-based libs. To take account of this I tested two different underlying database connectors: both <a href="https://github.com/psycopg/psycopg2">psycopg2</a> and a ‚Ä¶</p></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://suade.org/dev/12-requests-per-second-with-python/">https://suade.org/dev/12-requests-per-second-with-python/</a></em></p>]]>
            </description>
            <link>https://suade.org/dev/12-requests-per-second-with-python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26188765</guid>
            <pubDate>Fri, 19 Feb 2021 02:21:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Texas power outage is a nation-wide problem]]>
            </title>
            <description>
<![CDATA[
Score 241 | Comments 395 (<a href="https://news.ycombinator.com/item?id=26186645">thread link</a>) | @gwoplock
<br/>
February 18, 2021 | https://garrettbattaglia.com/post/texas-power/ | <a href="https://web.archive.org/web/*/https://garrettbattaglia.com/post/texas-power/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
        <p>Let me preface this with an explanation. Over the last few days I read online people saying that Texas' power outages had been caused by Texas being on its own grid‚Ä¶ deregulation‚Ä¶ Not following national standards‚Ä¶  had Texas been connected to the Eastern Interconnection or the Western Interconnection none of this would have happened. But not one post shows any evidence or requirements that backed up these claims. So, I went looking for proof and instead of finding requirements, I found a nationwide problem with winterization. As an aside I am not an expert in the grid or electricity, I am a software developer, and this is my best interpretation of the requirements I could find.</p>
<p>Let‚Äôs start off with how the electrical grid works in the US. The grid is made up of 3 interconnections: the Eastern Interconnection, the Western Interconnection, and the Texas Interconnect. Each of these interconnections operate in (near) isolation with their own frequency, voltage, and phase. There are several high voltage DC interconnects (HVDC or DC-DC) between them. In each of these interconnections there is at least one grid operators, for example ERCOT in Texas. These grid operators manage the generation and load of their interconnection, acting as almost as an electric clearing house. They are also responsible for keeping voltage and frequency within range and directing distributors (like ONCOR in north Texas) to shed load during Electrical Emergency Alerts (EEA). An important thing to note for later, from the best I can tell the different grid operators in the Eastern Interconnect share power in a ‚Äúnon-firm, as-available basis‚Äù.</p>
<p>What happened in Texas, starting 12:30 AM February 15. The long and short of it is an estimated 34GW of generation went offline in about 2 hours[1]. Looking at ERCOT‚Äôs tweets [2,3,4], generation was starting to have an issue at 00:17:45 and some load needed to be shed so ERCOT issued the first EEA (EEA1). In the February EEA tools document[5] EEA1 can open up around 1.6GW of ‚Äúpeeker‚Äù generation and importation from the Eastern and Western Interconnections. But by 1:12:06 that wasn‚Äôt enough and additional load had to be shed.  A second EEA was issued (EEA2) shedding another 1.6GW. But just a few minutes later the house came crashing down and at 1:25:40 the third EEA (EEA3) was issued. In addition to starting rolling blackouts to shed most of the load it also allowed for other actions to free .1-.2GW of load.</p>
<p>The 34GW of generation lost was from every fuel source used. Most of it was frozen-off natural gas (gas) wells, some of it was frozen wind turbines, solar panels that had snow on them and even a nuclear plant had to go offline due to issues with feedwater pressure sensing issues related to the cold.
What do the North American Electric Reliability Corporation (NERC) standards say about protecting any of these sources? Not much.</p>
<p>Let‚Äôs start by looking at the least complex, wind turbines. On September 12, 2012 NERC published a Lesson Learned document in regards to Texas‚Äôs issues with some of the wind farms freezing in extreme winter weather[6]. According to the document the event that was predicted over a week beforehand brought 4 days of low temperature, high winds and wind chills, ice and snow that limited the generation facility to just 25% of capacity. The facility did have a SOP for icing conditions that was implemented. However, the facility never defined it‚Äôs minimum operating temperature. When lightning knocked out some of the sensing equipment, the turbines had to be stop for safety. The repair crews couldn‚Äôt immediately get to the turbines and they had to sit, this gave the oil a chance to cool and partly freeze. When the turbines were returned to service, they tripped back off due to high oil pressure. Eventually after working with the manufacturer they were able to safely heat the oil and restart the turbines. One of the big lessons from this was to install cold weather packs for wind turbines and watch the oil temperature. You‚Äôd think that would solve future outage, but no, in 2019 in the midwestwind turbines failed due to exceptionally low temperatures, around -21. Again the cold weather package hadn‚Äôt been installed and was one of the root causes of the failure[7].</p>
<p>The nuclear plant‚Äôs sensing problems had happened before too. Although it wasn‚Äôt a nuclear plant, there are several documented cases on NERC‚Äôs website citing cold weather and sensor issues [8,9]. This repeated in Texas (2011) and in the south east (2018)[10].</p>
<p>Let‚Äôs discuss natural gas next. It appears that most of the issues in the problematic natural gas fired facilities was due to low gas supplies. In 2012 NERC warned of the interconnectivity of natural gas and electric[11]. Natural gas coming out of the ground has a naturally high water content. This water can freeze the extraction equipment during sub-freezing weather in improperly winterized wells creating what is know as a freeze-off. businesses, residential customers, and powerplants all run off the same supply, once wells start freezing off the supply dwindles for all. Natural gas companies prioritize residential customers as needed and will cut businesses and powerplants. This obviously creates issues in electrical generation.</p>
<p>In this latest case, much of the gas generation loss was due to under pressure conditions at the generation site. When generation sites detect this kind of fault, they are taken offline for safety. Not only is this what happened this year, but it has happened many, many times before</p>
<p>The most resent case I could find was 2018 in the south east[10]. Starting on January 18, 2018 a large area in the south east US experienced unusually cold weather. This caused 183 generation facilities to go offline or operate with greatly reduced output. At the peak there was nearly 30GW of production lost. This caused several grid operators to issue EEAs and begin rolling blackouts. In the ‚Äúevent area‚Äù 14% of the failures could be directly attributed to the cold weather. And another 30% could be indirectly linked to weather, including mechanical failures know to happen in cold weather and gas supply issues. NERC found that more than 33% of the failed powerplants didn‚Äôt have a winterization plan.</p>
<p>Why didn‚Äôt these plants have a winterization plan? Because it wasn‚Äôt required[10,12].</p>
<p>This wouldn‚Äôt be so bad if this wqs the first time it happened, it wasn‚Äôt even the second time it happened. In 2014 a polar vortex hit the US. bringing temperatures well below normal. During this event 55% of the outages were at gas power plants and in all 90GW of generation was lost[13].</p>
<p>The earliest report I could find was from the 2011 winter event in Texas[14]. A very strong cold front hit Texas (and other parts of the south central US) bringing temperatures below freezing for over 4 days and winds over 30 MPH. Leading up to the event, ERCOT and other grid operators in surrounding areas felt that there wouldn‚Äôt be a need for rolling blackouts. At the beginning of the event ERCOT had 3.1GW of reserve, nearly 1GW over the minimum required. However, over the next 2 days ERCOT lost nearly 30GW of production in 193 generation facilities. ERCOT was able to stabilize the grid with rolling blackouts and the other EEA methods[5]. Other grids suffered problems as well, EPE (El Paso) and SRP (Arizona) lost nearly 1.4GW due to cold weather. Another issue in ERCOT‚Äôs region was nearly 50% of the ‚Äúblack start‚Äù facilities were either down for scheduled maintenance or failed on startup. One of the main causes again was the loss of gas during this blackout period. 14.8 Bcf of natural gas production was lost due to freeze-offs, electrical outages (ironically) and customer curtailments. following the previous equivalent storm in 1989, the PUCT (Public Utility Commission of Texas) issued several recommendations and guidelines for winterization of power plants and gas wells. However, due to the infrequency of these storms the implementation lacked. With many of the same facilities that failed in 1989 also failed in 2011.  My guess is these same sites failed again in 2021. Interestingly the NERC found that it is quite possible that gas production in these unusually cold conditions may be impossible.</p>
<p>What has been done since 2011? Not a whole lot. A request for a new standard was issued to NERC in late 2012, however a few months later it was denied.[15] Also in 2012 NERC put out a set of guidelines for developing a plan for winter weather[16]. In 2017 NERC put out a special reliability report on the relationship between gas and electricity[17]. Finally, after the 2018 event NERC received another standard request that was approved[23], however it won‚Äôt be finalized until late 2021[18,19,20].</p>
<p>From what I can see, ERCOT has more restrictive rules in their Generator Winter Weatherization Workshop than NERC[21]. All generation stations must have plans for emergencies, address abnormal weather, critical failure points, weather design limits, alternative fuels and testing[21,22]. ERCOT reports that there were 80 spot checks done in the 2019/2020 season with 71 being gas plants and 6 being black start gas plants. 23 had to improve and would be reinspected in early 2021 the rest passed.</p>
<p>The issue of extreme cold weather and electrical outages is a national issue that needs to be addressed. However, after repeated failings it hasn‚Äôt really been addressed. Hopefully with the new NERC requirements and the Texas legislature in session progress can be made.</p>
<hr>
<p>[1] <a href="http://www.ercot.com/news/releases/show/225244">http://www.ercot.com/news/releases/show/225244</a><br>
[2] <a href="https://twitter.com/ERCOT_ISO/status/1361197991659503618">https://twitter.com/ERCOT_ISO/status/1361197991659503618</a><br>
[3] <a href="https://twitter.com/ERCOT_ISO/status/1361211669788176384">https://twitter.com/ERCOT_ISO/status/1361211669788176384</a><br>
[4] <a href="https://twitter.com/ERCOT_ISO/status/1361215084010352644">https://twitter.com/ERCOT_ISO/status/1361215084010352644</a><br>
[5] <a href="http://www.ercot.com/content/wcm/lists/219692/EEA_Tools_One_Pager_Winter_2021_2-13-2021.pdf">http://www.ercot.com/content/wcm/lists/219692/EEA_Tools_One_Pager_Winter_2021_2-13-2021.pdf</a><br>
[6] <a href="https://www.nerc.com/pa/rrm/ea/Lessons%20Learned%20Document%20Library/LL20120901_Wind_Farm_Winter_Storm_Issues.pdf">https://www.nerc.com/pa/rrm/ea/Lessons%20Learned%20Document%20Library/LL20120901_Wind_Farm_Winter_Storm_Issues.pdf</a><br>
[7] <a href="https://www.nerc.com/pa/rrm/ea/Lessons%20Learned%20Document%20Library/LL20200601_Unanticipated_Wind_Generation_Cutoffs_during_a_Cold_Weather_Event.pdf">https://w‚Ä¶</a></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://garrettbattaglia.com/post/texas-power/">https://garrettbattaglia.com/post/texas-power/</a></em></p>]]>
            </description>
            <link>https://garrettbattaglia.com/post/texas-power/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26186645</guid>
            <pubDate>Thu, 18 Feb 2021 22:26:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gleam 0.14 ‚Äì type-safe language for the Erlang VM]]>
            </title>
            <description>
<![CDATA[
Score 244 | Comments 38 (<a href="https://news.ycombinator.com/item?id=26185690">thread link</a>) | @lpil
<br/>
February 18, 2021 | https://gleam.run/news/gleam-v0.14-released/ | <a href="https://web.archive.org/web/*/https://gleam.run/news/gleam-v0.14-released/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <div>
<p>Hot on the heels of Gleam v0.13 comes another release, <a href="https://github.com/gleam-lang/gleam/releases/tag/v0.14.0">Gleam v0.14</a>!
As always, let‚Äôs take a look at some of the highlights.</p>

<h2 id="dialyzer--erlang-typespecs">Dialyzer &amp; Erlang typespecs</h2>

<p>Many dynamically typed BEAM languages support Erlang‚Äôs typespecs, type
annotations that can be analysed with the <a href="https://erlang.org/doc/man/dialyzer.html">Dialyzer</a> tool. While
not as powerful or reliable as Gleam‚Äôs type system it can be a useful tool
for finding problems with your Erlang or Elixir code. Dialyzer doesn‚Äôt
require typespecs but it can work better if they are added to the code.</p>

<p>Starting with this release Gleam will generate typespecs for all functions
and Erlang type definitions for all declared types within a Gleam program,
giving you one extra tool to help you write robust and reliable code when
using Gleam alongside Elixir or Erlang.</p>

<p>For a quick example, here‚Äôs some code in Gleam:</p>

<div><div><pre><code><span>pub</span> <span>type</span> <span>LinkedList</span><span>(</span><span>element</span><span>)</span> <span>{</span>
  <span>Empty</span>
  <span>Node</span><span>(</span><span>element</span><span>,</span> <span>LinkedList</span><span>(</span><span>element</span><span>))</span>
<span>}</span>

<span>pub</span> <span>fn</span> <span>is_empty</span><span>(</span><span>list</span><span>)</span> <span>{</span>
  <span>list</span> <span>==</span> <span>Empty</span>
<span>}</span>

<span>pub</span> <span>fn</span> <span>map</span><span>(</span><span>list</span><span>,</span> <span>fun</span><span>)</span> <span>{</span>
  <span>case</span> <span>list</span> <span>{</span>
    <span>Empty</span> <span>-&gt;</span> <span>Empty</span>
    <span>Node</span><span>(</span><span>i</span><span>,</span> <span>list</span><span>)</span> <span>-&gt;</span> <span>Node</span><span>(</span><span>fun</span><span>(</span><span>i</span><span>),</span> <span>map</span><span>(</span><span>list</span><span>,</span> <span>fun</span><span>))</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>And here‚Äôs the Erlang code and typespecs it compiles to:</p>

<div><div><pre><code><span>-</span><span>module</span><span>(</span><span>linked_list</span><span>).</span>
<span>-</span><span>compile</span><span>(</span><span>no_auto_import</span><span>).</span>

<span>-</span><span>export</span><span>([</span><span>is_empty</span><span>/</span><span>1</span><span>,</span> <span>map</span><span>/</span><span>2</span><span>]).</span>
<span>-</span><span>export_type</span><span>([</span><span>linked_list</span><span>/</span><span>1</span><span>]).</span>

<span>-</span><span>type</span> <span>linked_list</span><span>(</span><span>H</span><span>)</span> <span>::</span> <span>empty</span> <span>|</span> <span>{</span><span>node</span><span>,</span> <span>H</span><span>,</span> <span>linked_list</span><span>(</span><span>H</span><span>)}.</span>

<span>-</span><span>spec</span> <span>is_empty</span><span>(</span><span>linked_list</span><span>(</span><span>any</span><span>()))</span> <span>-&gt;</span> <span>boolean</span><span>().</span>
<span>is_empty</span><span>(</span><span>List</span><span>)</span> <span>-&gt;</span>
    <span>List</span> <span>=:=</span> <span>empty</span><span>.</span>

<span>-</span><span>spec</span> <span>map</span><span>(</span><span>linked_list</span><span>(</span><span>R</span><span>),</span> <span>fun</span><span>((</span><span>R</span><span>)</span> <span>-&gt;</span> <span>U</span><span>))</span> <span>-&gt;</span> <span>linked_list</span><span>(</span><span>U</span><span>).</span>
<span>map</span><span>(</span><span>List</span><span>,</span> <span>Fun</span><span>)</span> <span>-&gt;</span>
    <span>case</span> <span>List</span> <span>of</span>
        <span>empty</span> <span>-&gt;</span>
            <span>empty</span><span>;</span>

        <span>{</span><span>node</span><span>,</span> <span>I</span><span>,</span> <span>List</span><span>@</span><span>1</span><span>}</span> <span>-&gt;</span>
            <span>{</span><span>node</span><span>,</span> <span>Fun</span><span>(</span><span>I</span><span>),</span> <span>map</span><span>(</span><span>List</span><span>@</span><span>1</span><span>,</span> <span>Fun</span><span>)}</span>
    <span>end</span><span>.</span>
</code></pre></div></div>

<p>No annotations are required at all in your Gleam code to get full typespec
coverage, Gleam‚Äôs compiler reuses the type information from its powerful type
inference algorithm to determine the correct typespecs.</p>

<p>Thank you <a href="https://gitlab.com/greggreg">Greg</a> for this brilliant new feature!</p>

<h2 id="erlang-escripts">Erlang escripts</h2>

<p>Erlang projects are unusual in that typically instead of having a <code>main</code>
function as the entrypoint of your application you define a tree of actors to
come online and process items of work while your program is running.</p>

<p>This can be a powerful way to write long-lived services that make use of the
runtime‚Äôs fault tolerance features, but it does not lend itself well to
short-lived programs such as command line scripts. It can be confusing to
newcomers from other languages too.</p>

<p>For these short lived programs Erlang <a href="https://erlang.org/doc/man/escript.html">escripts</a> are typically used.
These are lightweight Erlang programs that have a <code>main</code> function as an entrypoint.</p>

<p>To make it easier to use these from Gleam the <code>gleam new</code> command now has an
escript template that can be used to create an escript project without any
further configuration required.</p>

<div><div><pre><code>gleam new my_script <span>--template</span> escript
</code></pre></div></div>

<p>A world class developer experience is a key goal of the Gleam project.
Further tooling improvements are right around the corner!</p>

<h2 id="night-mode">Night mode</h2>

<p>Gleam has the ability to render <a href="https://hexdocs.pm/gleam_stdlib/">HTML documentation</a> 
for your code, ready to upload to Hexdocs.</p>

<p>Thanks to <a href="https://github.com/tynanbe">Tynan Beatty</a> the documentation is
looking better than ever! There‚Äôs too many improvements to list but the big
one is they now have a night mode! If you‚Äôre a night owl like me I‚Äôm sure you
will enjoy the lower contrast dark tones when doing some late evening coding.</p>

<p><img src="https://gleam.run/images/news/gleam-v0.14-released/night-mode.png" alt="A screenshot of Gleam's rendered docs showing a beautiful dark theme"></p>

<h2 id="better-errors-again">Better errors, again</h2>

<p>At the risk of sounding like a broken record Gleam‚Äôs error messages have been
improved yet again. Here‚Äôs an example of one of the improvements:</p>

<p>Before:</p>

<div><div><pre><code>error: Syntax error
    ‚îå‚îÄ /src/thing.gleam:115:18
    ‚îÇ
115 ‚îÇ pub fn overlappedBy(compare, a, b) -&gt; Bool {
    ‚îÇ                  ^^ I was not expecting this.

Expected one of: "("
</code></pre></div></div>

<p>Now:</p>

<div><div><pre><code>error: Syntax error
    ‚îå‚îÄ /src/thing.gleam:115:18
    ‚îÇ
115 ‚îÇ pub fn overlappedBy(compare, a, b) -&gt; Bool {
    ‚îÇ                  ^^ This is not a valid name.

Hint: Names start with a lowercase letter and contain a-z, 0-9, or _.
Try: overlapped_by
</code></pre></div></div>

<p>Thank you to <a href="https://github.com/samontea">Samuel Mercier</a> and <a href="https://github.com/pd-andy">Andy
Thompson</a> for these.</p>

<h2 id="static-bit-string-validation">Static bit string validation</h2>

<p>Bit string syntax is a feature that Gleam inherits from Erlang. It provides a
way to declartively and concisely construct and manipulate raw bits of data
through literals and pattern matching.</p>

<p>With this Gleam release we apply further static analysis to bit string
literals and patterns used in Gleam programs to catch invalid or incorrect
code.</p>

<p>Here‚Äôs an example of one of the errors that may be reported:</p>

<div><div><pre><code>error: Syntax error
  ‚îå‚îÄ /Users/a/parser_test/src/a.gleam:2:20
  ‚îÇ
2 ‚îÇ   &lt;&lt;1:size(1)-unit(0)&gt;&gt;
  ‚îÇ                    ^ This is not a valid BitString unit value.

Hint: unit must be an integer literal &gt;= 1 and &lt;= 256
See: https://gleam.run/book/tour/bit-strings
</code></pre></div></div>

<p>Thank you <a href="https://gitlab.com/greggreg">Greg</a> for this bit string safety net.</p>

<h2 id="docker-images">Docker images</h2>

<p>Up until now <a href="https://github.com/CrowdHailer">Peter Saxton</a> has been very kindly
building Gleam docker images for use in <a href="https://sendmemo.app/">Memo</a> and the
wider community.</p>

<p>With this release he has ported his build automation over to the Gleam repo
so we have automation creation of OCI/Docker images built and published
automatically with each release.</p>

<p>We are building these variants:</p>

<ul>
  <li><code>gleam-erlang</code>: Gleam and the Erlang tooling on Ubuntu Linux</li>
  <li><code>gleam-erlang-slim</code>: Gleam and the Erlang tooling on slim Debian Linux</li>
  <li><code>gleam-erlang-alpine</code>: Gleam and the Erlang tooling on Alpine Linux</li>
  <li><code>gleam-elixir</code>: Gleam and the Elixir tooling on Ubuntu Linux</li>
  <li><code>gleam-elixir-slim</code>: Gleam and the Elixir tooling on slim Debian Linux</li>
  <li><code>gleam-elixir-alpine</code>: Gleam and the Elixir tooling on Alpine Linux</li>
</ul>

<p>For all the images see the <a href="https://github.com/orgs/gleam-lang/packages/container/package/gleam">Gleam image registry</a>. Thanks Peter!</p>

<h2 id="other-stuff">Other stuff</h2>

<p>These are just some of the highlights, but there‚Äôs plenty more improvements
made to the compiler and the standard library since the last release. For all
the details check out the changelog files:</p>

<ul>
  <li><a href="https://github.com/gleam-lang/gleam/blob/main/CHANGELOG.md">Gleam‚Äôs changelog</a></li>
  <li><a href="https://github.com/gleam-lang/stdlib/blob/main/CHANGELOG.md">Gleam stdlib‚Äôs changelog</a></li>
</ul>

<h2 id="discord-chat">Discord chat</h2>

<p>It‚Äôs time to plug the Gleam Discord server again! The community continues to
grow and it would be great to have you there too, so please click on the
button below.</p>

<center>
  <a href="https://discord.gg/Fm8Pwmy"><img src="https://img.shields.io/discord/768594524158427167?color=blue" alt="Discord chat"></a>
</center>

<h2 id="try-it-out">Try it out</h2>

<p>If you want to try out the new version of Gleam head over to the <a href="https://gleam.run/getting-started/">getting started
page</a>. I‚Äôd love to hear how you find it and get your feedback so
Gleam can continue to improve.</p>

<p>Want to view some existing Gleam projects? Head on over to the
<a href="https://github.com/gleam-lang/awesome-gleam">awesome-gleam</a> list. Looking for something to build in
Gleam? Check out <a href="https://github.com/gleam-lang/suggestions/issues">the suggestions tracker</a>.</p>

<h2 id="supporting-gleam">Supporting Gleam</h2>

<p>If you would like to help make strongly typed programming on the Erlang
virtual machine a production-ready reality please consider <strong><a href="https://github.com/sponsors/lpil">sponsoring
Gleam</a></strong> via the GitHub Sponsors program.</p>

<p>‚≠ê Or alternatively give us a star on <a href="https://github.com/gleam-lang/gleam">GitHub</a>! ‚≠ê</p>

<p>This release would not have been possible without the support of all the
people who have <a href="https://github.com/sponsors/lpil">sponsored</a> and contributed
to it, so a huge thank you to them.</p>

<ul>
  <li><a href="https://github.com/adamnbowen">Adam Bowen</a></li>
  <li><a href="https://github.com/amokan">Adam Mokan</a></li>
  <li><a href="https://github.com/aditya7iyengar">Adi Iyengar</a></li>
  <li><a href="https://github.com/scripttease">Al Dee</a></li>
  <li><a href="https://github.com/mudriyjo">Alexander Babin</a></li>
  <li><a href="https://github.com/farhadi">Ali Farhadi</a></li>
  <li><a href="https://github.com/pd-andy">Andy Thompson</a></li>
  <li><a href="https://github.com/bees">Arian Daneshvar</a></li>
  <li><a href="https://github.com/arnodirlam">Arno Dirlam</a></li>
  <li><a href="https://github.com/benmyles">Ben Myles</a></li>
  <li><a href="https://github.com/nono">Bruno Michel</a></li>
  <li><a href="https://github.com/brightly-salty">Caden Haustein</a></li>
  <li><a href="https://github.com/choonkeat">Chew Choon Keat</a></li>
  <li><a href="https://github.com/chrislloyd">Chris Lloyd</a></li>
  <li><a href="https://github.com/worldofchris">Chris Young</a></li>
  <li><a href="https://github.com/tlvenn">Christian Meunier</a></li>
  <li><a href="https://github.com/clangley">clangley</a></li>
  <li><a href="https://github.com/cleverbunny">Clever Bunny LTD</a></li>
  <li><a href="https://github.com/codec-abc">codec-abc</a></li>
  <li><a href="https://github.com/colelawrence">Cole Lawrence</a></li>
  <li><a href="https://github.com/connorlay">Connor Lay (Clay)</a></li>
  <li><a href="https://github.com/cschembor3">Connor Schembor</a></li>
  <li><a href="https://github.com/unthought">Dan Mueller</a></li>
  <li><a href="https://github.com/davydog187">Dave Lucia</a></li>
  <li><a href="https://github.com/rawkode">David McKay</a></li>
  <li><a href="https://github.com/davidpdrsn">David Pedersen</a></li>
  <li><a href="https://github.com/dangdennis">Dennis Dang</a></li>
  <li><a href="https://github.com/lostbean">Edgar Gomes</a></li>
  <li><a href="https://github.com/ericmj">Eric Meadows-J√∂nsson</a></li>
  <li><a href="https://github.com/eterps">Erik Terpstra</a></li>
  <li><a href="https://github.com/floriank">Florian Kraft</a></li>
  <li><a href="https://github.com/itsgreggreg">greggreg</a></li>
  <li><a href="https://github.com/ggpasqualino">Guilherme Pasqualino</a></li>
  <li><a href="https://github.com/hendi">Hendrik Richter</a></li>
  <li><a href="https://github.com/hhandoko">Herdy Handoko</a></li>
  <li><a href="https://github.com/human154">human154</a></li>
  <li><a href="https://github.com/Ian-GL">Ian Gonz√°lez</a></li>
  <li><a href="https://github.com/igagen">Ingmar Gagen</a></li>
  <li><a href="https://github.com/ivarvong">Ivar Vong</a></li>
  <li><a href="https://github.com/gampleman">Jakub Hampl</a></li>
  <li><a href="https://github.com/jamesmacaulay">James MacAulay</a></li>
  <li><a href="https://github.com/janpieper">Jan Pieper</a></li>
  <li><a href="https://github.com/jechol">Jechol Lee</a></li>
  <li><a href="https://github.com/jeffkreeftmeijer">Jeff Kreeftmeijer</a></li>
  <li><a href="https://github.com/jiangplus">jiangplus</a></li>
  <li><a href="https://github.com/joecorkerton">Joe Corkerton</a></li>
  <li><a href="https://github.com/Jwsonic">John Palgut</a></li>
  <li><a href="https://github.com/josevalim">Jos√© Valim</a></li>
  <li><a href="https://github.com/jveiga">Jo√£o Veiga</a></li>
  <li><a href="https://github.com/jmn">Jussi Norlund</a></li>
  <li><a href="https://github.com/kapp-technology">Kapp Technology</a></li>
  <li><a href="https://github.com/kodeFant">Lars Lillo Ulvestad</a></li>
  <li><a href="https://github.com/lawik">Lars Wikman</a></li>
  <li><a href="https://github.com/leandrocp">Leandro Cesquini Pereira</a></li>
  <li><a href="https://github.com/malcolmseyd">Malcolm Seyd</a></li>
  <li><a href="https://github.com/mario-mazo">mario</a></li>
  <li><a href="https://github.com/mvellandi">Mario Vellandi</a></li>
  <li><a href="https://github.com/markmark206">Mark Markaryan</a></li>
  <li><a href="https://github.com/markusfeyh">Markus</a></li>
  <li><a href="https://github.com/derhechi">Markus Hechenberger</a></li>
  <li><a href="https://github.com/MattCheely">Matthew Cheely</a></li>
  <li><a href="https://github.com/bausano">Michael Bausano</a></li>
  <li><a href="https://github.com/michaeljones">Michael Jones</a></li>
  <li><a href="https://github.com/michallepicki">Micha≈Ç ≈Åƒôpicki</a></li>
  <li><a href="https://github.com/mroach">Mike Roach</a></li>
  <li><a href="https://github.com/slashmili">Milad</a></li>
  <li><a href="https://github.com/ndreynolds">Nick Reynolds</a></li>
  <li><a href="http://www.ninefx.com/">NineFX</a></li>
  <li><a href="https://github.com/jraregris">Oddmund Str√∏mme</a></li>
  <li><a href="https://github.com/sorentwo">Parker Selbert</a></li>
  <li><a href="https://github.com/phiat">Patrick Ryan</a></li>
  <li><a href="https://github.com/PeteJodo">Pete Jodo</a></li>
  <li><a href="https://github.com/CrowdHailer">Peter Saxton</a></li>
  <li><a href="https://github.com/praveenperera">Praveen Perera</a></li>
  <li><a href="https://github.com/qingliangcn">qingliangcn</a></li>
  <li><a href="https://github.com/happysalada">Raphael Megzari</a></li>
  <li><a href="https://github.com/chouzar">Ra√∫l  Humberto Chouza Delgado</a></li>
  <li><a href="https://github.com/redmar">Redmar Kerkhoff</a></li>
  <li><a href="https://github.com/reneklacan">Ren√© Klaƒçan</a></li>
  <li><a href="https://github.com/romatthe">Robin Mattheussen</a></li>
  <li><a href="https://github.com/rvcas">rvcas</a></li>
  <li><a href="https://github.com/samaaron">Sam Aaron</a></li>
  <li><a href="https://github.com/samontea">samontea</a></li>
  <li><a href="https://github.com/mrgleam">Santi</a></li>
  <li><a href="https://github.com/sascha-wolf">Sascha Wolf</a></li>
  <li><a href="https://github.com/sasa1977">Sa≈°a Juriƒá√ß</a></li>
  <li><a href="https://github.com/scottwey">Scott Wey</a></li>
  <li><a href="https://github.com/seanjensengrey">Sean Jensen-Grey</a></li>
  <li><a href="https://github.com/sporto">Sebastian</a></li>
  <li><a href="https://github.com/shanesveller">Shane Sveller</a></li>
  <li><a href="https://github.com/shritesh">Shritesh Bhattarai</a></li>
  <li><a href="https://github.com/simonewebdesign">Simone Vittori</a></li>
  <li><a href="https://github.com/syukronrm">Syukron Rifail M</a></li>
  <li><a href="https://github.com/terkiterje">Terje Bakken</a></li>
  <li><a href="https://github.com/timbuchwaldt">Tim Buchwaldt</a></li>
  <li><a href="https://github.com/tomekowal">Tomasz Kowal</a></li>
  <li><a href="https://github.com/thara">Tomochika Hara</a></li>
  <li><a href="https://github.com/topherhunt">Topher Hunt</a></li>
  <li><a href="https://github.com/tsloughter">Tristan Sloughter</a></li>
  <li><a href="https://github.com/twilco">Tyler Wilcock</a></li>
  <li><a href="https://github.com/tynanbe">tynanbe</a></li>
  <li><a href="https://github.com/wojtekmach">Wojtek Mach</a></li>
</ul>

<p>Thanks for reading! Have fun! üíú</p>

</div>

</article></div>]]>
            </description>
            <link>https://gleam.run/news/gleam-v0.14-released/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26185690</guid>
            <pubDate>Thu, 18 Feb 2021 21:16:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ruby Garbage Collection Deep Dive: Tri-Color Mark and Sweep]]>
            </title>
            <description>
<![CDATA[
Score 132 | Comments 15 (<a href="https://news.ycombinator.com/item?id=26182796">thread link</a>) | @mooreds
<br/>
February 18, 2021 | https://jemma.dev/blog/gc-mark-and-sweep | <a href="https://web.archive.org/web/*/https://jemma.dev/blog/gc-mark-and-sweep">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>In the <a href="https://jemma.dev/blog/gc-internal">first post</a> in the Ruby Garbage Collection Deep Dive series, we went through a few definitions to give us a picture of how Ruby stores values in memory. If you haven‚Äôt read it yet, <a href="https://jemma.dev/blog/gc-internal">read it first</a>! We‚Äôll build on those definitions in this post. Particularly, we‚Äôll talk more about the Ruby Heap, Pages, Slots and RVALUES.</p>

<p>Okay, now that we have those baseline definitions out of the way, this post is going to explain the algorithm Ruby‚Äôs garbage collector uses to determine which objects it can collect: the Tri-Color Mark and Sweep algorithm. There are two phases to this algorithm. You guessed it: marking and sweeping. In the marking phase, the garbage collector marks all slots which contain accessible RVALUES. In the sweeping phase, the garbage collector clears the RVALUES out of all slots which are not marked. Let‚Äôs dig in!</p>

<h2 id="tri-color-mark-and-sweep">Tri-Color Mark and Sweep</h2>

<h3 id="marking">Marking</h3>

<p>We‚Äôll start off by discussing the marking phase. This is most straightforward to understand if we imagine the <a href="https://ruby-doc.org/core-3.0.0/ObjectSpace.html">Ruby ObjectSpace</a> to be a directed graph with root nodes. All of the nodes in the graphs are RVALUES. All of the edges in the graph are references from one RVALUE to another.</p>

<p>Ruby‚Äôs garbage collector starts at the root nodes and traces every edge it can access from these root nodes, marking every RVALUE it sees through this process. At the end, any RVALUE which was not traced, and therefore not accessible from a root RVALUE will be garbage collected.</p>

<h4 id="tri-color">Tri-Color</h4>

<p>Okay, but the algorithm Ruby uses for garbage collection is called a Tri-Color Mark and Sweep algorithm, so what‚Äôs the Tri-Color part all about? The Tri-Color algorithm is a model we can use to understand what Ruby‚Äôs garbage collector is doing, and how tracks its progress. The three colors in the Tri-Color algorithm (three shades, really) are white, black and grey.</p>

<p>At the beginning of garbage collection, every slot in the Ruby Heap is white. Then, as part of the initial setup, all slots which contain root RVALUEs are marked as grey.</p>

<p>Root RVALUES are all of the RVALUES that a Ruby program knows it will need to run. Examples of these are RVALUES that exist on the stack of instructions that the program is following, or protected global variables.</p>

<p>With all root slots grey, and all other slots white, we then get to the crux of the algorithm:</p>

<div><div><pre><code><span>while</span> <span>(</span><span>!</span><span>grey_slots</span><span>.</span><span>empty?</span><span>)</span>
  <span>current_slot</span> <span>=</span> <span>grey_slots</span><span>.</span><span>pop</span>
  <span>grey_slots</span> <span>+=</span> <span>current_slot</span><span>.</span><span>referenced_slots</span>
  <span>black_slots</span> <span>&lt;&lt;</span> <span>current_slot</span>
<span>end</span>
</code></pre></div></div>

<p>We iterate over all grey slots, coloring the slots that their RVALUES reference grey, and coloring themselves black. The algorithm continues until there are no grey slots left. At this point, any black slots contain RVALUES which were reachable by the RVALUEs in the root slots, and any white slots do not contain RVALUES which were reachable so can be swept away!</p>

<p>For the visual learners, here‚Äôs a gif of what the algorithm is doing:</p>

<p><img src="https://jemma.dev/assets/mark.gif" alt="mark-gif"></p>

<h4 id="references">References</h4>

<p>There is one detail which needs further explanation here: how does an RVALUE know which other RVALUES it references?</p>

<p>It depends on the type of object. For Ruby builtins, tracing the references are just baked into the garbage collector code itself. For example, to find all references from an array RVALUE, the collector iterates each element in the array and finds its references. For a hash, it will do this for both the keys and the values. This all happens in the garbage collector‚Äôs <a href="https://github.com/ruby/ruby/blob/296a2cab07ce530809ee74dee61180fbb3ca6f91/gc.c#L6269"><code>mark_children</code></a> method.</p>

<p>But, when objects are defined by C extensions, the C extensions must mark all child objects on their own. We‚Äôll dive more into this in a future C extensions post (which I‚Äôll backlink here).</p>

<p>Okay, so now that we understand how we find all accessbile objects, we need to learn how to dispose of all unaccessible objects.</p>

<h3 id="sweeping">Sweeping</h3>

<p>At this point, we have two sets: black slots and white slots. Internally, these are represented as a <code>marked</code> bitmap. Every Page on the Ruby Heap has its own <code>marked</code> bitmap with one bit per slot. A <code>1</code> bit means the slot is accessible, or Black in our Tri-Color scheme. A <code>0</code> bit means that the slot is no longer accessible, or White in our Tri-Color scheme.</p>

<p>In addition to holding this <code>marked</code> bitmap, each page also has a <code>freelist</code> which represents slots on that page which do not have live objects. The garbage collector iterates over all pages, finding all slots which are not marked. Where applicable, the garbage collector then adds the unmarked slots to each page‚Äôs freelist. If the RVALUES which were occupying these slots are also taking up space in the operating system heap, it also frees this memory.</p>

<p>Once pages have been swept, there might be pages which are now completely unallocated; they have no slots which contain RVALUES. These pages are referred to as ‚ÄúTomb Pages.‚Äù Tomb pages have their memory completely returned to the operating system‚Äôs heap. This is really helpful for memory management. It means that sweeping can result in freeing memory, or diminishing the overall size of the Ruby Heap.</p>

<p>Any pages with at least one occupied slot are called ‚ÄúEden Pages‚Äù. The sweeping phase might reduce the number of occupied slots in an Eden Page. The garbage collector will use the freelists from Eden Pages for future object allocations. That is to say, if you instantiate an object, the garbage collector will look for one of these free slots in an Eden Page and place the RVALUE representing your object in there.</p>

<p><img src="https://jemma.dev/assets/eden-and-tomb.png" alt="eden-and-tomb"></p>

<p>There is one more nuance here. As of Ruby 3.0, if auto-compaction is enabled, compaction will actually happen as part of the sweeping phase. A more in depth explanation of how and why this happens will follow in a later post about compaction in this Garbage Collection Deep Dive Series.</p>

<h3 id="tldr">TL;DR</h3>

<p>The Tri-Color mark and sweep algorithm is what Ruby‚Äôs garbage collector uses to determine which slots hold objects which no longer have accessible references. It marks all of the slots it has references to by following the Tri-Color algorithm in which it follows all references from root RVALUES. Once the garbage collector knows which objects are accessible from the roots, it can begin the sweep phase, where it will add the unoccupied slots to each page‚Äôs freelist, and release any operating system memory those RVALUES held. This enables the slots to be reused for new object allocation.</p>

<p>Here are a few new definitions we learned:</p>

<ul>
  <li><strong>Eden page</strong>: A page which contains slots with RVALUES, might also have empty slots</li>
  <li><strong>Tomb page</strong>: A page which contains only empty slots</li>
  <li><strong>Free list</strong>: A linked list per Heap Page of empty slots</li>
</ul>

<p>And that‚Äôs it for this post! I‚Äôm going to continue writing blog posts in this series, and am also writing a book about managed garbage collection, with a focus on Ruby. If this interests you, join the newsletter below or follow me <a href="https://twitter.com/jemmaissroff">on twitter</a> for updates!</p>


  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://jemma.dev/blog/gc-mark-and-sweep</link>
            <guid isPermaLink="false">hacker-news-small-sites-26182796</guid>
            <pubDate>Thu, 18 Feb 2021 17:32:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Coq 8.13]]>
            </title>
            <description>
<![CDATA[
Score 113 | Comments 38 (<a href="https://news.ycombinator.com/item?id=26180078">thread link</a>) | @infruset
<br/>
February 18, 2021 | https://coq.inria.fr/news/coq-8-13-0-is-out.html | <a href="https://web.archive.org/web/*/https://coq.inria.fr/news/coq-8-13-0-is-out.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>





<p>
The Coq development team is proud to announce the immediate availability of
<a href="https://github.com/coq/coq/releases/tag/V8.13.0">Coq 8.13.0</a>
</p>

<p>
Highlights:
</p><ul>
<li>Introduction of primitive persistent arrays in the core language, implemented using imperative persistent arrays. </li>
<li>Introduction of definitional proof irrelevance for the equality type defined in the SProp sort. </li>
<li>Many improvements to the handling of notations, including number notations, recursive notations and notations with bindings. A new algorithm chooses the most precise notation available to print an expression, which might introduce changes in printing behavior.</li>
</ul>



<p>Please see <a href="https://coq.github.io/doc/v8.13/refman/changes.html#version-8-13" rel="nofollow">the changelog</a> to learn more about this release.</p>




</div></div>]]>
            </description>
            <link>https://coq.inria.fr/news/coq-8-13-0-is-out.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26180078</guid>
            <pubDate>Thu, 18 Feb 2021 14:23:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Browsers eating RAM]]>
            </title>
            <description>
<![CDATA[
Score 131 | Comments 134 (<a href="https://news.ycombinator.com/item?id=26179817">thread link</a>) | @todsacerdoti
<br/>
February 18, 2021 | https://www.flotato.com/post/memory-chrome-safari-flotato | <a href="https://web.archive.org/web/*/https://www.flotato.com/post/memory-chrome-safari-flotato">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>I reached a point where I could barely hear the podcast I was trying to listen to. That's how loud the fan was. Then I&nbsp;closed down all open Chrome windows, and a few minutes after, the fan went silent. So I decided to see if it was just me.</p><div href=""><h3>How I&nbsp;measured</h3><p>I&nbsp;ran the 2-tab test in a completely fresh macOS install on a virtual machine. Then I ran the 54-tabs test on my own Big Sur installation, but with all extensions disabled. To record a usage snapshot ~250 times per second, I&nbsp;used <a href="https://github.com/astrofrog/psrecord">psrecord.</a></p></div><div><h2>2&nbsp;tabs:&nbsp;Twitter, then Gmail</h2><p>To simulate a realistic environment, I&nbsp;did the same steps on Safari, then Chrome:&nbsp;Go to twitter.com, scroll around, then open a new tab with Gmail and open an email. A dot means I interacted with the system. You can hover a dot to see what I&nbsp;did. </p></div><div><h3>Putting Flotato to the test</h3><p>To be light-weight, Flotato doesn't just run a stripped down, Safari-backed web view, it also defaults to the mobile version if one is available. Here's Flotato compared to a regular session in Safari. Note the slightly lower CPU usage. It's kind of hard to put a finger on what exactly the mobile version isn't calculating that the desktop version is; the two versions are almost identical when you use them.</p></div><div><h2>54 tabs:&nbsp;the stress test</h2><p>I&nbsp;bet you have more than 2 tabs open right now, I&nbsp;sure have more. So here's a stress test where I&nbsp;open 54 tabs while measuring the impact on my Mac's RAM and CPU. A dot means I&nbsp;opened a new tab. Hover the dot to see which site I&nbsp;opened.</p></div><div><h2>Is it bad?</h2><p>When I saw the results I got suspicious. Chrome was using way more memory than I thought it would. Maybe it was the virtual machine blocking Chrome's direct access to my Macbook's* GPU?&nbsp;I&nbsp;decided to run the next test, the one with 54 tabs directly on my own Big Sur installation. The results were, well, slightly worse.</p><h3>The graphs don't tell the full story</h3><p>But it's probably not as bad as it looks. It's not a terrible thing that an app actually <em>uses</em> your computer. And you've got to hand it to Chrome:&nbsp;it is fast! </p><p>I'm sure Chrome is going out of its way to manage its memory usage across tabs, keeping the current tab fast and responsive. That's great if you're not running any other macOS apps than Chrome, effectively using Chrome as your operating system, and macOS&nbsp;as a kind of bootloader. </p><p>But when you're using Sketch, Final Cut, Photoshop next to Chrome, that seems to be a problem. MacOS&nbsp;likely tries to tell Chrome to take it easy, and Chrome likely <em>does</em> take it easy. These graphs don't tell that story. </p><p>So no, it's most likely not as bad as it looks, but that doesn't change the fact since switching to Safari, I almost forgot what my fan sounds like.</p><p>And then there's <em>this</em> chart. As we can see, the two browsers heat up the computer almost to the exact same level - Safari even getting slightly warmer. This probably points to psutil not being able to see all Safari's child processes, but only the main ones ‚Äî despite the fact that Activity Monitor is able to group them. That's a little confusing. </p><figure><p><img src="https://uploads-ssl.webflow.com/5e78c687e58e25134b3fb751/602feb36d1388bb94f881998_EumcL7jXYAEBG_4.png" alt="Image"></p></figure><p>‚Äç</p><p>‚Äç</p><p><em>*&nbsp;Macbook 16" from 2019 with2.4 GHz, 8-Core Intel Core i9 with 32&nbsp;GB&nbsp;2667 MHz DDR4 RAM and an AMD&nbsp;Radeon Pro 5500M 8GB GPU</em></p></div></div>]]>
            </description>
            <link>https://www.flotato.com/post/memory-chrome-safari-flotato</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179817</guid>
            <pubDate>Thu, 18 Feb 2021 13:56:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Curl is C (2017)]]>
            </title>
            <description>
<![CDATA[
Score 81 | Comments 65 (<a href="https://news.ycombinator.com/item?id=26179601">thread link</a>) | @taf2
<br/>
February 18, 2021 | https://daniel.haxx.se/blog/2017/03/27/curl-is-c/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2017/03/27/curl-is-c/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>For some reason, this post got picked up again and is <a href="https://news.ycombinator.com/item?id=26179601">debated today</a> in 2021, almost 4 years since I wrote it. Some things have changed in the mean time and I might‚Äôve phrased a few things differently if I had written this today. But still, what‚Äôs here below is what I wrote back then. Enjoy!</p>



<div><figure><a href="https://daniel.haxx.se/blog/wp-content/uploads/2017/01/The_C_Programming_Language_cover.svg_.png"><img loading="lazy" width="348" height="450" src="https://daniel.haxx.se/blog/wp-content/uploads/2017/01/The_C_Programming_Language_cover.svg_-348x450.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2017/01/The_C_Programming_Language_cover.svg_-348x450.png 348w, https://daniel.haxx.se/blog/wp-content/uploads/2017/01/The_C_Programming_Language_cover.svg_-155x200.png 155w, https://daniel.haxx.se/blog/wp-content/uploads/2017/01/The_C_Programming_Language_cover.svg_-768x992.png 768w, https://daniel.haxx.se/blog/wp-content/uploads/2017/01/The_C_Programming_Language_cover.svg_.png 792w" sizes="(max-width: 348px) 100vw, 348px"></a></figure></div>



<p>Every once in a while someone suggests to me that curl and libcurl would do better if rewritten in a ‚Äúsafe language‚Äù. Rust is one such alternative language commonly suggested. This happens especially often when we publish new security vulnerabilities. (Update: I think Rust is a fine language! This post and my stance here has nothing to do with what I think about Rust or other languages, safe or not.)</p>



<h2>curl is written in C</h2>



<p>The curl code guidelines mandate that we stick to using C89 for any code to be accepted into the repository. C89 (sometimes also called C90) ‚Äì the oldest possible ANSI C standard. Ancient and conservative.</p>



<h2>C is everywhere</h2>



<p>This fact has made it possible for projects, companies and people to adopt curl into things using basically any known operating system and whatever CPU architecture you can think of (at least if it was 32bit or larger). No other programming language is as widespread and easily available for <em>everything</em>. This has made curl one of the most portable projects out there and is part of the explanation for curl‚Äôs success.</p>



<p>The curl project was also started in the 90s, even long before most of these alternative languages you‚Äôd suggest, existed. Heck, for a truly stable project it wouldn‚Äôt be responsible to go with a language that isn‚Äôt even old enough to start school yet.</p>



<h2>Everyone knows C</h2>



<p>Perhaps not necessarily true anymore, but at least the knowledge of C is very widespread, where as the current existing alternative languages for sure have more narrow audiences or amount of people that master them.</p>



<h2>C is not a safe language</h2>



<p>Does writing safe code in C require more carefulness and more ‚Äútricks‚Äù than writing the same code in a more modern language better designed to be ‚Äúsafe‚Äù ? Yes it does. But we‚Äôve done most of that job already and maintaining that level isn‚Äôt as hard or troublesome.</p>



<p>We keep scanning the curl code regularly with static code analyzers (we maintain a <em>zero <a href="https://scan.coverity.com/projects/curl">Coverity</a> problems</em> policy) and we run the test suite with <a href="http://valgrind.org/">valgrind</a> and <a href="https://en.wikipedia.org/wiki/AddressSanitizer">address sanitizers</a>.</p>



<h2>C is not the primary reason for our past vulnerabilities</h2>



<p>There. The simple fact is that most of our past vulnerabilities happened because of logical mistakes in the code. Logical mistakes that aren‚Äôt really language bound and they would not be fixed simply by changing language.</p>



<p>Of course that leaves a share of problems that could‚Äôve been avoided if we used another language. Buffer overflows, double frees and out of boundary reads etc, but the bulk of our security problems has not happened due to curl being written in C.</p>



<h2>C is not a new dependency</h2>



<p>It is easy for projects to add a dependency on a library that is written in C since that‚Äôs what operating systems and system libraries are written in, still today in 2017. That‚Äôs the default. Everyone can build and install such libraries and they‚Äôre used and people know how they work.</p>



<p>A library in another language will add that language (and compiler, and debugger and whatever dependencies a libcurl written in that language would need) as a new dependency to a large amount of projects that are themselves written in C or C++ today. Those projects would in many cases downright ignore and reject projects written in ‚Äúan alternative language‚Äù.</p>



<h2>curl sits in the boat</h2>



<p>In the curl project we‚Äôre deliberately conservative and we stick to old standards, to remain a viable and reliable library for everyone. Right now and for the foreseeable future. Things that worked in curl 15 years ago still work like that today. The same way. Users can rely on curl. We stick around. We don‚Äôt knee-jerk react to modern trends. We sit still in the boat. We don‚Äôt rock it.</p>



<h2>Rewriting means adding heaps of bugs</h2>



<p>The plain fact, that also isn‚Äôt really about languages but is about plain old software engineering: translating or rewriting curl into a new language will introduce a lot of bugs. Bugs that we don‚Äôt have today.</p>



<p>Not to mention how rewriting would take a huge effort and a lot of time. That energy can instead today be spent on improving curl further.</p>



<h2>What if</h2>



<p><em>If I would start the project today, would I‚Äôve picked another language?</em> Maybe. Maybe not. If memory safety and related issues was the primary concern I had, then sure. But as I‚Äôve mentioned above there are several others concerns too so it would really depend on my priorities.</p>



<h2>Finally</h2>



<p>At the end of the day the question that remains is: would we gain more than we would pay, and over which time frame? Who would gain and who would lose?</p>



<p>I‚Äôm sure that there will be or it may even already exist, curl and libcurl competitors and potent alternatives written in most of these new alternative languages. Some of them are absolutely really good and will get used and reach fame and glory. Some of them will be crap. Just like software always work. Let a thousand curl competitors bloom!</p>



<p>Will curl be rewritten at some point in the future? I won‚Äôt rule it out, but I find it unlikely. I find it even more unlikely that it will happen in the short term or within the next few years.</p>



<p>Discuss this post on <a href="https://news.ycombinator.com/item?id=13966241">Hacker news</a> or <a href="https://www.reddit.com/r/programming/comments/61rh9j/curl_is_c/">Reddit</a>!</p>



<p><strong>Followup-post: </strong><a href="https://daniel.haxx.se/blog/2017/03/30/yes-c-is-unsafe-but/">Yes, C is unsafe, but‚Ä¶</a></p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2017/03/27/curl-is-c/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179601</guid>
            <pubDate>Thu, 18 Feb 2021 13:34:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenZFS ‚Äì dRAID, Finally]]>
            </title>
            <description>
<![CDATA[
Score 161 | Comments 46 (<a href="https://news.ycombinator.com/item?id=26179566">thread link</a>) | @throw0101a
<br/>
February 18, 2021 | https://klarasystems.com/articles/openzfs-draid-finally/ | <a href="https://web.archive.org/web/*/https://klarasystems.com/articles/openzfs-draid-finally/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>




<div>
<h3><em>This is part of our article series published as ‚ÄúOpenZFS in Depth‚Äù. <a href="https://klarasystems.com/articles/"><strong><span>Subscribe to our article series</span></strong> </a>to find out more about the secrets of OpenZFS</em></h3>



<hr>



<p><strong><em>Isaac Huang‚Äôs <a href="https://www.youtube.com/watch?v=xPU3rIHyCTs">talk at the OpenZFS 2017 developers summit</a> witnessed the expansion of the ZFS storage endurance envelope for large installations.&nbsp; dRAID or distributed RAID is a new vdev type that complements existing ZFS data protection capabilities for very large storage arrays.&nbsp; Starting with the RAID-Z-like underpinnings, dRAID permutes, or mixes, disk blocks together in a way where accesses are evenly spread across all the drives. Fast spindle replacement is accomplished by using all members of the pool, using pre-allocated virtual spares, spread evenly over all the spindles. Contributors include Intel, Lawrence Livermore Labs, and HP Enterprise, which have material interest in storage at datacenter scale and high reliability. The OpenZFS user community are the benefactors of this enhancement if we apply it well.</em></strong></p>



<h3><strong>Avoiding the Death Spiral</strong></h3>



<p>Admins will often use wide RAID stripes to maximize usable storage given a number of spindles. RAID-Z deployments with large stripe widths, ten or larger, are subject to poor resilver performance for a number of reasons. Resilvering a full vdev means reading from every healthy disk and continuously writing to the new spare. This will saturate the replacement disk with writes while scattering seeks over the rest of the vdev. For 14 wide RAID-Z2 vdevs using 12TB spindles, rebuilds can take weeks. Resilver I/O activity is deprioritized when the system has not been idle for a minimum period. Full zpools get fragmented and require additional I/O‚Äôs to recalculate data during reslivering. A pool can degenerate into a never ending cycle of rebuilds or loss of the pool Aka: the Death Spiral.</p>



<p>As spindles age together, disks may fail in groups as defect counts and mechanical failure are not independent random processes with respect to age. SSD‚Äôs further complicate this math as the wear leveling endurance will be very closely matched and clusters of devices under identical load may fail together.&nbsp; Manufacturer provided mean time to failure is a forward-looking statement and is not suitable for replenishment planning. One manufacturer claims 1.2 Million hour MTBF: a dubious 137 year commitment to quality. It‚Äôs poor planning to assume any drive isn‚Äôt going to pick today to dramatically fail.&nbsp;</p>



<p>dRAID is an option providing rapid parity rebuild that can mitigate the death spiral behaviour of wide RAIDZ stripes, but as reflected in its default width setting of eight, it does not encourage wide stripes. Dedicating sufficient parity increases the durability of the ZFS pool and the investment in parity should be informed by the risk of losing the pool.</p>



<h3><strong>Distributed Spares?</strong></h3>



<p>Spare disks are a way of keeping a disk warm and ready to replace a failed member. Usually, a spare‚Äôs life is leisurely idle until they are scrammed into action during a rebuild. That idleness is a wasted opportunity to do useful work. There are no specific spare disks in a dRAID. Rather, enough blocks are allocated throughout out the vdev to act as spares. The distributed spare is a clever redistribution of work so that all disks are always in use. A disk failure precipitates a rebuild into that dedicated space. After replacement disks are available, the vdev can be re-balanced to return the spare block and put the replacement disk in to use.</p>



<h3><strong><strong><strong>Fixed Stripe Width</strong></strong></strong></h3>



<p>Unlike RAID-Z, an entire stripe in dRAID is allocated at once, no matter how many disk blocks are needed to store the object. The stripe width is determined by the disk sector size multiplied by the number of data drives in the RAID group.</p>



<div data-columns="3" data-layout="50-25-25"><div>




<div><div>
<p>Did you know?</p>



<h2>You can maximize the <strong>power of your FreeBSD</strong> infrastructure with our <strong>Support Subscription!</strong></h2>




</div></div>




</div></div>



<p>RAID-Z has a method of optimizing block layout to minimize block allocations for small files. dRAID however priorities the speed of rebuilding parity and does not make the same space preserving attempt. If your files are a small fraction of the stripe size, dRAID will not be able to use all the disk blocks fully. For example, a default dRAID vdev has a stripe with of 32k (4k per disk, 8 disks); any allocation will require at least 32k. Internal padding is allocated to fill out the stripe width after the request object is stored. Using a smaller stripe width or providing a special mirror vdev will suit smaller allocations and improve drive utilization.</p>



<h3><strong>A Tale of Two Resilvers</strong></h3>



<p>After a failure, the real or distributed spare is written to in sequence, following only the parity layout in the space map to rebuild the drive according to parity data. Sequential reconstruction can be accomplished rapidly by issuing large I/O blocks, reducing seeks, and avoiding tree indirection overhead. The rebuilt disk‚Äôs contents are not necessarily consistent with the Merkle tree that proves the zpools data is intact.&nbsp; It‚Äôs important to reconstruct this bitwise copy of the disk first, allowing the system to return to mostly intact state and return to service. That is to say, the sequential reconstruction process restores the redundancy level of the pool, but without being able to verify the checksums of the data. The advantage to this is that it can be completed much more quickly, reducing the window during which additional disk failures might put the pool at risk.</p>



<p>A healing resilver is triggered automatically after a sequential resilver, it is a final operation that verifies that all the contents of the drives match their initial checksums via block pointer traversal. The healing resilver has a number of optimizations to quickly find and reconstruct writes to the failed disk. When a replacement drive can be added to the pool, the rebalance operation is another sequential resilver followed by a healing resilver.</p>



<p>A scrub is the gold standard for a pool health; however, a scrub might be a prohibitive amount of work, visiting every block allocated in the pool. The healing resilver allows a practical return to operation in an environment where failures must be repaired routinely.</p>



<h3><strong><em>‚ÄúAre We There Yet? When Can I Play With it?‚Äù</em></strong></h3>



<p>According to a report from the January OpenZFS leadership meeting, OpenZFS 2.1 will support dRAID in early 2021. If you must have it now; the head branch of the OpenZFS build against recently supported operating systems: FreeBSD 12.1+, Linux 5.10+, Illumos, NetBSD et al. The OpenZFS regression test suite ztest is a good indication that dRAID satisfies the ZFS commitment to data protection. Corporate customers at IBM and Panasas have been flogging other distributed RAID systems for more than ten years. It‚Äôs a mature concept that complements the ZFS tool set.</p>



<h4><strong>Quick Start</strong></h4>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; There is no better way to learn software than to run headlong into mistakes.&nbsp;</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; We‚Äôll install ZFS head from source and gin up some ‚Äòmd‚Äô file backed disks.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ‚Äòzpool create r2dRAID dRAID2:3d:1s:14c /dev/md1 /dev/md2 ‚Ä¶.&nbsp; /dev/md13 /dev/md14‚Äô</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; There it is, a zpool with a dRAID vdev, ready to go to work.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The OpenZFS wiki has a good description of <a href="https://openzfs.github.io/openzfs-docs/Basic%20Concepts/dRAID%20Howto.html">dRAID care, resilvering and rebalancing</a></p>



<p>Following the life cycle of failure and replacement in the documentation is recommended before those skills are tested in production.</p>



<h4><strong>dRAID Nomenclature</strong></h4>



<p>Let‚Äôs decode the nomenclature that describes the geometry of a dRAID vdev. A string such as ‚ÄúdRAID2:3d:14c:1s‚Äù encodes the following about a dRAID vdev.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -dRAID[&lt;parity&gt;][:&lt;data&gt;d][:&lt;children&gt;c][:&lt;spares&gt;s]</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -parity: Required, the number of spindles to use to store parity information. Eg: A dRAID3 can survive until a fourth disk failure without losing data. Parity may be 1,2 or 3.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -[d] data: (spindles per RAID group): Determines the width of the data stripe, 8 is the default. Larger values will increase the stripe width and reduce total parity.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -[c] children: This parameter should match the number of device entries that you feed to the vdev. A helpful check will warn you if you don‚Äôt get the right number of disks named correctly: ‚Äúinvalid number of dRAID children; 14 required but 13 provided‚Äù</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -[s] spares: The number of disk areas to mix in as distributed spares. No spares are created by default, a maximum of four are welcome. Each spare will remove a fraction of space from every disk.</p>



<h2><strong>Parting Short</strong></h2>



<p>The dRAID offers a solution for large arrays, vdevs with fewer than 20 spindles will have limited benefits from the new option. The performance and resilver result will be similar to RAIDZ for small numbers of spindles. Installations with many spindles will see the best results with regards to performance, fast spare activation and replacement. The benefits come with the associated cost of whole stripe at a time allocation for small objects in the pool. This overhead should be calculated in the design of the pool before it‚Äôs an operational surprise.</p>



<p>There is no free lunch with dRAID for in saving parity or spare drives, they are your defense against data loss. As drives increase in size, their time to resilver increases and the amount of data they can destroy increases.</p>



<h2><strong>Like this article? Share it!</strong></h2>


</div>




</div></div>]]>
            </description>
            <link>https://klarasystems.com/articles/openzfs-draid-finally/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179566</guid>
            <pubDate>Thu, 18 Feb 2021 13:31:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I am a heroin user. I do not have a drug problem]]>
            </title>
            <description>
<![CDATA[
Score 261 | Comments 625 (<a href="https://news.ycombinator.com/item?id=26179003">thread link</a>) | @CapitalistCartr
<br/>
February 18, 2021 | http://m.nautil.us/issue/96/rewired/i-am-a-heroin-user-i-do-not-have-a-drug-problem | <a href="https://web.archive.org/web/*/http://m.nautil.us/issue/96/rewired/i-am-a-heroin-user-i-do-not-have-a-drug-problem">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
			<p><span>C</span>arl Hart is a neuroscientist and Ziff Professor of Psychology at Columbia University‚Äîhe was the first tenured African-American professor of sciences at Columbia. His research focuses on the ‚Äúbehavioral and neuropharmacological effects of psychoactive drugs in humans.‚Äù Hart‚Äôs new book, <i>Drug Use For Grown-Ups</i>, is a bold and engaging effort to counter what he sees as generations of misinformation and moral grandstanding about drug use. Today‚Äôs ‚Äúsensationalistic media coverage of the opioid crisis continues a long, awful tradition of exploiting ignorance and fear to vilify certain members of our society,‚Äù Hart writes. The media is not the only problem. Scientists, he states, ‚Äúhave frequently overinterpreted and distorted‚Äù drugs‚Äô effects on the brain.</p><p>Hart reports that more than 70 percent of drug users‚Äîwhether they use alcohol, cocaine, prescription medications, or heroin‚Äîdo not meet the health criteria for drug addiction. In <i>Drug Use for Grown-Ups</i>, Hart strives to ‚Äúpresent a more realistic image of the typical drug user: a responsible professional who happens to use drugs in his pursuit of happiness.‚Äù With genial candor, Hart presents himself as a model drug user. ‚ÄúI am now entering my fifth year as a regular heroin user,‚Äù he writes. ‚ÄúI do not have a drug-use problem. Never have. Each day, I meet my parental, personal, and professional responsibilities. I pay my taxes, serve as a volunteer in my community on a regular basis, and contribute to the global community as an informed and engaged citizen. I am better for my drug use.‚Äù</p><p><i>Nautilus</i> caught up with Hart to discuss his drug use and his sharp points about science and society. He was as casually bold in conversation as he is in <i>Drug Use for Grown-Ups</i>.</p><figure data-alt="MacNamara_BREAKER"><img src="http://static.nautil.us/18174_0f004440ba0c8f1ccc5c355f3d77207f.png" width="733" alt=""><figcaption><span><strong>HABIT OF A HIGHLY EFFECTIVE PERSON:</strong> ‚ÄúMy heroin use is as rational as my alcohol use,‚Äù Carl Hart writes. ‚ÄúLike vacation, sex, and the arts, heroin is one of the tools that I use to maintain my work-life balance.‚Äù</span><span>Courtesy of Carl Hart</span></figcaption></figure><p><b>You say ‚Äúmost drug-use scenarios cause little or no harm and that some responsible drug-use scenarios are actually beneficial for human health and functioning.‚Äù How so?</b></p><p>Let‚Äôs just talk about alcohol first. When you‚Äôre at a wedding reception, alcohol serves as a social lubricant. People are more gregarious. They talk, they interact. The same is true with cocaine at parties, heroin among friends, or opium among friends, NDMA among lovers. It enhances empathy, openness, and forgiveness, all of these pro-social attributes.</p><p><b>Drug research, you write, is full of bad science. If you had to name one example, what would it be?</b></p><p>The notion that drug addiction is a brain disease. That encapsulates all that‚Äôs wrong with today‚Äôs science in this area. There is absolutely no data in humans to show that drug addiction is a brain disease. Yet the narrative, the dogma, the dominant perspective is that it does. Even though nobody will dispute that, there‚Äôs absolutely no data in humans to support that statement.</p><p><b>Yet opioids do change the brain biologically, do they not?</b></p><p>Yes, opioids bind to a class of receptors called endogenous opioids, which you find in endorphins, for example. Opioids bind to these receptors‚Äîjust like natural chemicals do‚Äîwhich results in a response. In some cases, because of decreased sensitivities and certain types of pain, they may enhance a sense of euphoria. So it‚Äôs really just facilitating what‚Äôs already in the body naturally, a system that helps in our survival. Think of fructose or glucose. We add sugar to our tea, our coffee, whatever we have, we add more and more because we like it, it tastes good, and it enhances pleasure. It can give you energy. It can make life more interesting. Humans do not live on logic alone. And so sometimes we do these things, and that‚Äôs OK.</p><blockquote><p>People become addicted because they once had a middle-class-paying job that made them someone in their community.</p> </blockquote><p><b>How have scientists ‚Äúoverinterpreted and distorted‚Äù the effects of drugs on the brain?</b><br></p><p>Take brain imaging. People often show one image of someone‚Äôs brain. Let‚Äôs say this person is addicted to methamphetamine, according to DSM criteria, versus the brain of someone who‚Äôs not addicted. If you see some difference, some researchers have a propensity to make more out of the differences than are there. There‚Äôs a wide range of brain structural sizes, such that when we think about one person‚Äôs size of their nucleus accumbens, it may be smaller or larger than somebody else‚Äôs nucleus accumbens. But both of the nucleus accumbens, despite their sizes, are within the normal range of human variability. It‚Äôs like height. One guy might be 5‚Äô10‚Äù, another guy might be 6‚Äô2‚Äù. But we don‚Äôt say the guy who‚Äôs 5‚Äô10‚Äù is height deficient. We just say that he‚Äôs in a normal range, and he‚Äôs not as tall as the other guy. We wouldn‚Äôt say one is deficient versus the other. In neuroscience, one of the things that has happened, particularly when it comes to drugs, people have over-interpreted the differences to mean pathology, when, in fact, both of the brain structures are within the normal range of human variability. The overinterpretation is to interpret it as being pathological.</p><p><b>You say the opioid crisis has been sensationalized, and write, ‚ÄúPeople are not dying because of opioids; they are dying because of ignorance.‚Äù What do you mean?</b></p><p>Some people don‚Äôt know not to mix specific sedatives with opioids. For example, they don‚Äôt know not to mix large amounts of alcohol or large amounts of antihistamines. Specific combinations can lead to respiratory depression, which can lead to death. Another point of ignorance involves people who buy street drugs and don‚Äôt necessarily know if the drugs contain contaminants. That‚Äôs the kind of ignorance I‚Äôm talking about.</p><div>
<article>
<p><a href="http://m.nautil.us/issue/16/Nothingness/this-is-where-your-childhood-memories-went" data-trval="this-is-where-your-childhood-memories-went" data-trlbl="foc_rec" data-tract="internal_art">
<img src="http://static.nautil.us/3978_a8badd37c221a3f19d9ad0ac2196849a.png" alt="Sapolsky_TH-F1" width="314" height="177">
</a>
</p>


</article>
</div><p><b>So it‚Äôs the mix of drugs that is the problem, not opioids like heroin themselves?&nbsp;</b></p><p>Yes, the majority of opioid deaths occur as a result of combining opioids with multiple sedatives. But there are certain opioids that do concern us if taken alone and the person isn‚Äôt aware that they have this particular opioid. Those are fentanyl and the fentanyl analogs. These drugs are a lot more potent than something like heroin, meaning they require less of it to produce the effect. Most of the public aren‚Äôt seeking fentanyl or its analogs, but people are tainting things like heroin and oxycodone pills with fentanyl or an analog.</p><p>One way to deal with this tainting, this contamination, is to have free drug-checking facilities, where people can submit samples of their drug and get a chemical readout of what is contained in the substance. That way they‚Äôll know whether to take the substance or how much of it to take. The public also needs to know that most people who use these drugs are not addicts. If you understand that, then you know that for the people who do become addicted, we have to look beyond the drug and look at the person‚Äôs environment, their life. Do they have co-occurring psychiatric illnesses? Do they have pain that is not treated? All of these kinds of issues become important.</p><p><b>At what point does biological change in the brain lead to physical addiction?</b></p><p>Physical addiction occurs as a result of opioids‚Äîor any other drug, alcohol too‚Äîbeing in the body for consecutive weeks or periods, in particularly high doses. And then the body tries to compensate. For example, with opioids, one of the things that happens is that your gut, your gastrointestinal system, slows down the receptors. Your body is trying to compensate by speeding up the gastrointestinal tract. So when the drug abruptly leaves after several weeks of constant administration of the opioid, now the body is unprepared for the drug not being there and it overcompensates. It really ramps up the motility of the gastrointestinal tract, which causes diarrhea, among other things.</p><blockquote><p>It can give you energy. It can make life more interesting. Humans do not live on logic alone.</p> </blockquote><p><b>Why do some people get addicted and not others?</b><br></p><p>The amount of drugs they take, the period at which they take it. Some people can take opioids for extended periods of time. As long as they keep the doses fairly low and they don‚Äôt take multiple doses a day, they probably won‚Äôt experience physical dependence. It‚Äôs just like with alcohol. Most people drink alcohol on a regular basis, but they don‚Äôt become physically dependent. Whereas others drink every day in large amounts, and they will become physically dependent.</p><p><b>Why can‚Äôt people overcome addiction?</b></p><p>One of the major reasons people can‚Äôt overcome it is because we‚Äôre not very good at treating addiction in this country. Just think about why people become addicted. A large number become addicted because of co-occurring psychiatric illnesses, because of pain issues, because they once had a middle-class-paying job that made them someone in their home, someone in their community. Those jobs are gone. Then there‚Äôs no healthcare or there‚Äôs poor education. If your treatment is not addressing these issues, people are not going to overcome it. But if we have treatments that are holistic, and they‚Äôre looking at the individual, and not so much the drug, then we‚Äôre good. But if we‚Äôre just talking about the drug, then we‚Äôre already behind the eight ball, then we will lose that battle.</p><p><b>Your definition of addiction follows the DSM-5, which refers to a ‚Äúsubstance use disorder‚Äù and values functioning over regular ingestion of a substance. How do you define ‚Äúfunctioning‚Äù?</b></p><p>Functioning is determined by whether a user is happy in meeting their obligations, whatever they may be, whether they‚Äôre work-related, whether they‚Äôre family-related, or other social sorts of things. The person is not stressed out about their substance use. In fact, they‚Äôre cool with it. That‚Äôs functioning. The person‚Äôs happiness is more important. That supersedes any other thing.</p><p><b>You write that, contrary to the cultural myth, regular use of recreational drugs doesn‚Äôt damage the brain. What‚Äôs the frequency associated with recreational?</b></p><p>Yeah, I‚Äôm sorry. I couldn‚Äôt think of a ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://m.nautil.us/issue/96/rewired/i-am-a-heroin-user-i-do-not-have-a-drug-problem">http://m.nautil.us/issue/96/rewired/i-am-a-heroin-user-i-do-not-have-a-drug-problem</a></em></p>]]>
            </description>
            <link>http://m.nautil.us/issue/96/rewired/i-am-a-heroin-user-i-do-not-have-a-drug-problem</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179003</guid>
            <pubDate>Thu, 18 Feb 2021 12:23:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The frame rate of the universe (2009)]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 55 (<a href="https://news.ycombinator.com/item?id=26178259">thread link</a>) | @codesections
<br/>
February 18, 2021 | https://www.librador.com/2009/01/16/The-frame-rate-of-the-universe/ | <a href="https://web.archive.org/web/*/https://www.librador.com/2009/01/16/The-frame-rate-of-the-universe/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
      
<div id="page-2009-2009-01-16-The-frame-rate-of-the-universe-">
  
  <p><abbr title="2009-01-16T01:04:00+01:00">16 Jan 2009</abbr></p><div>
    <p>

    I stumbled upon <a href="http://www.newscientist.com/article/mg20126911.300-our-world-may-be-a-giant-hologram.html?full=true">this
article</a> which presents the hypothesis that the universe is a 3D projection of a 2D
surface, like a giant hologram. I like to read about modern physics. It is so weird and I can't say
I really understand very much of it. But the descriptions provoke strange and fascinating images
and thoughts in my head. Like this one:</p><p>The article mentions the <a href="http://en.wikipedia.org/wiki/Planck_length">Planck length</a>, which as I understand it is
the smallest distance there is. It's extremely small: 1.6 √ó 10<sup>-35</sup> meters, which makes
it billions and billions of times smaller than an atom (or even a proton). I'm used to thinking
about computer graphics, so I imagine the Planck length as the size of one "pixel" of the universe.
Nothing can be smaller than a pixel. (The pixels of the universe are small, I calculate the
resolution to correspond to 2.19 √ó 10<sup>33</sup> DPI.) The radius of the observable universe is
4.4 √ó 10<sup>26</sup> meters. If we want to fit the universe into a box, its sides would have to
be twice that size. That is 5.4 √ó 10<sup>61</sup> Planck lengths. So that's the width, height and
depth of the universe in pixels. Quite a good resolution. (Actually since they are 3D cubes instead
of 2D squares, I should call them voxels instead of pixels. All 1.61 √ó 10<sup>185</sup> of
them.)</p><p>There is also the <a href="http://en.wikipedia.org/wiki/Planck_time">Planck time</a>
which is the time it takes for light to travel one Planck length. As light is fast and the Planck
length is tiny (tiniest there is!), you can image that it's a very short period of time. Certainly.
The Planck time is 5.39 √ó 10<sup>-44</sup> seconds. No measurable time can be shorter than that
according to quantum physics. Thinking about graphics again, this is like a limit on the frame rate
of the universe. Inverting the Planck time, I get 1.855 √ó 10<sup>43</sup>. So by my surely
incorrect logic, we get the value of the universe's frame rate:</p><p>One thousand eight hundred
and fifty-five billion billion billion billion frames per second.</p><p>I'll say that
again:</p><p>18.55 septillion FPS!</p><p>Video cameras won't be perfect until they can record at
that speed.</p><p>I hope I got the calculations right, but I'm pretty sure my interpretation of the
quantum physics behind this are way off. It's still fascinating to think of the universe as a
computer simulation. Modern physics make it seem more like a video game than ever.<br>


</p>
  </div>
  
  
  <p><a href="http://disqus.com/">blog comments powered by </a>
</p></div>

    </div></div>]]>
            </description>
            <link>https://www.librador.com/2009/01/16/The-frame-rate-of-the-universe/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26178259</guid>
            <pubDate>Thu, 18 Feb 2021 10:37:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lithuania plans to hold drills in case of accident at the Belarus nuclear plant]]>
            </title>
            <description>
<![CDATA[
Score 156 | Comments 132 (<a href="https://news.ycombinator.com/item?id=26178235">thread link</a>) | @maury91
<br/>
February 18, 2021 | https://www.lrt.lt/en/news-in-english/19/1346034/lithuania-plans-to-hold-evacuation-drills-after-belarus-launches-nuclear-plant | <a href="https://web.archive.org/web/*/https://www.lrt.lt/en/news-in-english/19/1346034/lithuania-plans-to-hold-evacuation-drills-after-belarus-launches-nuclear-plant">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<article id="article1346034">    

    
    
    <div>

        <div id="article_text1346034">
            <p>Lithuania‚Äôs Interior Ministry plans to hold drills and assess the need to evacuate Vilnius‚Äô residents in case of an accident at the Astravyets nuclear plant in Belarus, located some 50 kilometres from the Lithuanian capital.</p>
            
            <p>"That will be one of the key questions during the drafting of the exercises schedule and probably going back to the scenarios: do we or do we not need to evacuate Vilnius residents,‚Äù Vitalij Dmitrijev, vice minister of the interior, told LRT RADIO.</p>
            <p>The so-called Astravyets drill was held in October 2019 in Vilnius and Svenƒçionys districts, which are located close to the Belarusian border. During the exercises, authorities prepared to evacuate people from radiation-affected territories, distribute iodine pills, as well as simulated a resident cleanup and monitoring operation.</p>
            <p>The exercise involved around 300 officers, troops and civil servants from six municipalities and 24 institutions. Due to a dispute over the exercise scenario with the Vilnius authorities, officers from the capital did not take part in the drills.</p>
                

            <p><em>Read more: <a href="https://www.lrt.lt/en/news-in-english/19/1103053/lithuanians-stage-mock-evacuations-to-train-for-nuclear-accident-photos">Lithuanians stage mock evacuations to train for nuclear accident ‚Äì photos</a></em></p>
            <!--googleoff: all--><!--googleon: all-->            <p>Previously, the Vilnius authorities cancelled another exercise, planned in early September, to simulate an accident at the nuclear power plant in Belarus.</p>
            <p>Based on the information available to BNS, Vilnius Municipality faced resistance from the government at the time.</p>
            <p>Lithuanian officials say that the nuclear power plant built by the Russian state atomic corporation Rosatom and funded by a loan from the Kremlin was built in breach of international safety standards. Minsk denies all accusations.</p>
            <p>Estonia, Latvia, and Lithuania are also due to unplug from the Moscow-controlled energy grid that links them with Belarus. Vilnius says that the Kremlin may use the plant to derail the move.</p>
<!--googleoff: all--><div>
            
<div id="mlb2-1612938">
    <div>
        <div>
            <div>
                <div>
                    <p><img src="https://bucket.mlcdn.com/a/1239/1239192/templates/39/39540/5dcc95ea35753170c2955994a6fea7c948ffb283.png"></p><p>LRT English Newsletter<span><span><br></span><span><span>Every Friday morning.</span></span></span></p>
                    
                </div>
            </div>
            
        </div>
    </div>
</div>

<p><img src="https://track.mailerlite.com/webforms/o/1612938/i0s8k2?v4a60e9ef938a7fa0240ac9ba567062cb" width="1" height="1">
</p></div><!--googleon: all-->        </div>
    </div>
    <!--googleoff: all-->
        <!--googleon: all-->
        

<div data-id="gallery1346034"><div>
            <div>
                <div>
                    <div>
<p><img data-src="/img/2019/10/02/522637-581058-1287x836.jpg" alt="‚ÄòAstravyets drill‚Äô in Lithuania" title="‚ÄòAstravyets drill‚Äô in Lithuania" src="https://www.lrt.lt/img/2019/10/02/522637-581058-1287x836.jpg"></p>
<div>
    <div>
        <div>
<p>‚ÄòAstravyets drill‚Äô in Lithuania</p>            <p><span>1 / 5</span><span>D. Umbrasas / LRT</span></p>
        </div></div>
</div>
                    </div>
                    <div>
<p><img data-src="/img/2019/12/23/573047-835055-1287x836.jpg" alt="Lithuania has staged 'Astravyets drills' to prepare for nuclear emergencies" title="Lithuania has staged 'Astravyets drills' to prepare for nuclear emergencies" src="https://www.lrt.lt/img/2019/12/23/573047-835055-1287x836.jpg"></p>
<div>
    <div>
        <div>
<p>Lithuania has staged 'Astravyets drills' to prepare for nuclear emergencies</p>            <p><span>2 / 5</span><span>D. Umbrasas/LRT</span></p>
        </div></div>
</div>
                    </div>
                    <div>
<p><img data-src="/img/2019/10/02/522627-981621-1287x836.jpg" alt="‚ÄòAstravyets drill‚Äô in Lithuania" title="‚ÄòAstravyets drill‚Äô in Lithuania" src="https://www.lrt.lt/img/2019/10/02/522627-981621-1287x836.jpg"></p>
<div>
    <div>
        <div>
<p>‚ÄòAstravyets drill‚Äô in Lithuania</p>            <p><span>3 / 5</span><span>D. Umbrasas / LRT</span></p>
        </div></div>
</div>
                    </div>
                    <div>
<p><img data-src="/img/2019/10/02/522623-306261-1287x836.jpg" alt="‚ÄòAstravyets drill‚Äô in Lithuania" title="‚ÄòAstravyets drill‚Äô in Lithuania" src="https://www.lrt.lt/img/2019/10/02/522623-306261-1287x836.jpg"></p>
<div>
    <div>
        <div>
<p>‚ÄòAstravyets drill‚Äô in Lithuania</p>            <p><span>4 / 5</span><span>D. Umbrasas / LRT</span></p>
        </div></div>
</div>
                    </div>
                    <div>
<p><img data-src="/img/2019/10/02/522612-821132-1287x836.jpg" alt="‚ÄòAstravyets drill‚Äô in Lithuania" title="‚ÄòAstravyets drill‚Äô in Lithuania" src="https://www.lrt.lt/img/2019/10/02/522612-821132-1287x836.jpg"></p>
<div>
    <div>
        <div>
<p>‚ÄòAstravyets drill‚Äô in Lithuania</p>            <p><span>5 / 5</span><span>D. Umbrasas / LRT</span></p>
        </div></div>
</div>
                    </div>
                </div>
                
            </div>
        </div>
        
    </div>
 

    
    
</article>

        
    </div></div>]]>
            </description>
            <link>https://www.lrt.lt/en/news-in-english/19/1346034/lithuania-plans-to-hold-evacuation-drills-after-belarus-launches-nuclear-plant</link>
            <guid isPermaLink="false">hacker-news-small-sites-26178235</guid>
            <pubDate>Thu, 18 Feb 2021 10:34:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TLS certificates specifying hosts via the CommonName field is more or less gone]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 21 (<a href="https://news.ycombinator.com/item?id=26176448">thread link</a>) | @zdw
<br/>
February 17, 2021 | https://utcc.utoronto.ca/~cks/space/blog/tech/TLSCertificateCNMostlyGone | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/tech/TLSCertificateCNMostlyGone">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/tech/TLSCertificateCNMostlyGone</link>
            <guid isPermaLink="false">hacker-news-small-sites-26176448</guid>
            <pubDate>Thu, 18 Feb 2021 05:54:45 GMT</pubDate>
        </item>
    </channel>
</rss>
