<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 28 Jun 2020 16:16:41 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 28 Jun 2020 16:16:41 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[NeXTSTEP on the HP 712 Part 2: Getting Software]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 14 (<a href="https://news.ycombinator.com/item?id=23659277">thread link</a>) | @luu
<br/>
June 26, 2020 | https://blog.pizzabox.computer/posts/hp712-nextstep-part-2/ | <a href="https://web.archive.org/web/*/https://blog.pizzabox.computer/posts/hp712-nextstep-part-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
  
  <p><time datetime="2020-06-09T09:45:00-0400">Tue, Jun 9, 2020</time></p><p>In the <a href="https://blog.pizzabox.computer/posts/hp712-nextstep-part-1">last post of this series</a>, I set up NeXTstep on an HP PA-RISC <a href="https://blog.pizzabox.computer/pizzaboxes/hp712">workstation</a>. Today, I’m going to get down to business: configure networking, install system patches, outfit it with developer tools, and install some useful software!</p>
<p>As with the previous post, I’ve also made a YouTube video that covers roughly the same topics! If video is your speed, I’d love for you to check it out!</p>
<p>
  <iframe src="https://www.youtube.com/embed/_4hs4K7AEvQ" allowfullscreen="" title="YouTube Video"></iframe>
</p>

<!-- raw HTML omitted -->
<p>My goal is to end up with a capable machine that I can use like it might have been when new, and learn from the experience.</p>
<h2 id="foreshadowing-networking-woes">Foreshadowing networking woes</h2>
<p>While it is possible to transfer files from SCSI drives (or even floppies!), <strong>getting a pizzabox on my home network makes loading software much easier</strong>.
I first tried out NeXTstep on this workstation a couple years ago. The OS installed OK, but I ran in to trouble with networking. I was initially optimistic that I would figure it out:</p>
<blockquote><p lang="en" dir="ltr">I think I'm done for the day but soon if I can fight with NFS and NetInfo (lolololol) I can get screenshots off it and software on</p>— cron mom (@sophaskins) <a href="https://twitter.com/sophaskins/status/962427825608429568?ref_src=twsrc%5Etfw">February 10, 2018</a></blockquote>


<blockquote>
<p><strong>NARRATOR</strong>: she did not soon win the fight with NFS and NetInfo</p>
</blockquote>
<p>Hang on a second: NeXTstep is a workstation-focused Unix operating system from the 80s-90s - <strong>how could it be difficult to get it on a network</strong>? The answer is a thing called NetInfo.</p>
<p>In a surprise to exactly no one, NeXTstep, being from a company founded by Steve Jobs, had it’s own NeXT-only ecosystem of tools that fit together amazingly well. <strong>The cornerstone of NeXTstep networking was NetInfo</strong>. If you had a collection of NeXT computers on a network, NetInfo gave you a system to:</p>
<ul>
<li>manage user accounts that would work across all machines</li>
<li>configure file sharing</li>
<li>control permissions around access to network resources</li>
<li>assign IP addresses and hostnames</li>
<li>quickly bring new machines in to the network</li>
<li>serve this information in a highly-available manner</li>
</ul>
<p>which is to say: NetInfo is a “directory services” system. That’s all well and good - in the early 1990s that space had many competitors and a “right path” hadn’t yet been established, but…<strong>I don’t <em>want</em> my machine to be part of a directory</strong>, **I just want it to be on my existing TCP/IP network.</p>
<h2 id="starting-a-simple-network">Starting a “simple” network</h2>
<p>With that in mind, I (naively) attempted to use the “SimpleNetworkStarter” application.</p>


<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/simple-network-starter-1.png" alt="SimpleNetworkStarter">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/simple-network-starter-1.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>SimpleNetworkStarter</p>
      </figcaption>
  </figure>
</div>

<p>The SimpleNetworkStarter window has three “steps”:</p>
<ol>
<li>Select <strong>how we’ll integrate</strong> with an existing NetInfo network (since I don’t intend to interact with one at all, I have to choose “Provide the services specified below”, a sort of catch-all)</li>
<li>Specify <strong>my hostname and IP address</strong> - if I were connecting to an existing NetInfo network, I might not have to do this. “Network Options” lets me set more granular IP settings like netmask and gateway; “NetInfo Options” lets me choose how to integrate with existing domains (if relevant).</li>
<li>Setup <strong>network services</strong>: for my setup I don’t really want <em>any</em> of these things, but as a standalone NeXTstep system, I do have to “Maintain the master copy of network administrative data” (aka, the NetInfo database).</li>
</ol>



<div itemscope="" itemtype="http://schema.org/ImageGallery">
	  


<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/simple-network-starter-2.png" alt="Network Options">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/simple-network-starter-2.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>Network Options</p>
      </figcaption>
  </figure>
</div>



<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/simple-network-starter-3.png" alt="NetInfo Options">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/simple-network-starter-3.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>NetInfo Options</p>
      </figcaption>
  </figure>
</div>



<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/simple-network-starter-4.png" alt="Configuration Successful">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/simple-network-starter-4.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>Configuration Successful</p>
      </figcaption>
  </figure>
</div>


</div>

<p>So far, this feels like a really good start, but will it let me fetch files from an NFS share?</p>
<h2 id="networking-woes">Networking woes</h2>
<p>I immediately tried connecting to my NAS over NFS - after all, the main point of setting up networking was making it easier to transfer files. Unfortunately, it didn’t work - I could set up the NFS mount with NFSMananger (more on how to do that later), but the mountpoint would always be empty. Here you can see me attempting to reach it by IP address:</p>


<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/failing-nfs-mount.png" alt="a failing NFS mount">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/failing-nfs-mount.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>a failing NFS mount</p>
      </figcaption>
  </figure>
</div>

<p>So I had <em>some</em> sort of problem. To narrow down potential issues, I ran a few tests:</p>
<ul>
<li><strong>attempting to ping my NAS</strong> from the workstation - this turned out to not work because NeXTstep doesn’t seem to have any <code>ping</code> command. There are probably ways to accomplish something equivalent with the tools it <em>does</em> have, but I just moved on</li>
<li><strong>attempting to ping the workstation</strong> from elsewhere on my network. This worked - I was able to ping it from my laptop!</li>
<li><strong>attempting to connect to my NAS with FTP</strong> - one of the few network tools NeXTstep <em>does</em> seem to have is FTP, so I gave it a shot. To my surprise, this works!</li>
</ul>


<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/ftp-by-ip.png" alt="connecting to my NAS via FTP (successfully)">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/ftp-by-ip.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>connecting to my NAS via FTP (successfully)</p>
      </figcaption>
  </figure>
</div>

<p>It did not work via hostname, though, which points to at least some trouble with DNS. Taking a deeper look at the “NeXTstep 3.3 Network and
System Administration Manual” section on “<a href="http://www.nextcomputers.org/NeXTfiles/Docs/NeXTStep/3.3/nsa/11_MixedNet.htmld/index.html">NEXTSTEP Computers in a Mixed Network</a>” (which I probably should have done earlier) shows that <strong>I need to manually configure DNS</strong>. There’s no GUI options for it, you just have to write out an <code>/etc/resolv.conf</code>:</p>


<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/resolv-conf.png" alt="editing /etc/resolv.conf in vi">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/resolv-conf.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>editing /etc/resolv.conf in vi</p>
      </figcaption>
  </figure>
</div>

<p>After rebooting, I was able to access the NAS via FTP by hostname:


</p><div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/ftp-by-hostname.png" alt="connecting to my NAS via FTP (successfully) by hostname">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/ftp-by-hostname.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>connecting to my NAS via FTP (successfully) by hostname</p>
      </figcaption>
  </figure>
</div>

<p>But still couldn’t use NFS. What gives? I have network connectivity in both directions, and DNS is also now working! I believe this is as far as I got a few years ago, and man I was FRUSTRATED.</p>
<p>Eventually I thought to look in the system log (<code>/usr/adm/messages</code>) for hints:</p>


<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/dmesg.png" alt="an error from autonfsmount">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/dmesg.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>an error from autonfsmount</p>
      </figcaption>
  </figure>
</div>

<p>and there it was:</p>
<pre><code>autonfsmount: Can't get my address
</code></pre><p>Can’t get…<em>my</em> address? Doesn’t the computer know its own address? While I don’t know <em>why</em> it has to do this (googling has provided me a couple of <a href="https://rute.gerdesas.com/node31.html">quick asides</a> mentioning it, but not much detail), <strong>mounting an NFS server requires working <em>reverse</em> DNS for your IP</strong>.</p>
<p>I do have a real-ish DNS server for my home network, and it populates based on DHCP leases and IP reservations. This workstation, though, was just <strong>using an IP that I habitually hardcode for pizzaboxes (192.168.1.200)</strong>. I double-checked the DHCP server config, and it was indeed set up with a different host for that IP, and not set up at all for this hostname. I replaced that entry with one for <code>hp712</code> at <code>192.168.1.200</code> for the MAC address of my workstation, and crossed my fingers.</p>
<p>It worked! I could browse my NAS from the file-browser.</p>


<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/browse-nas.png" alt="browsing my NAS">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/browse-nas.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>browsing my NAS</p>
      </figcaption>
  </figure>
</div>

<h2 id="setting-up-an-nfs-mount">Setting up an NFS mount</h2>
<p>After all that rigamarole, the right way to configure a remote NFS mount goes through the NFSManager.app. While NFSManager lets you configure both “exports” (local directories I share with others) and “imports” (remote directories I want to mount locally).</p>


<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/empty-imports.png" alt="an empty list of nfs imports">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/empty-imports.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>an empty list of nfs imports</p>
      </figcaption>
  </figure>
</div>

<p>All I have to is click “Add” and fill in the details for my NAS:</p>


<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/new-import.png" alt="adding a new nfs import">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/new-import.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>adding a new nfs import</p>
      </figcaption>
  </figure>
</div>

<p>That’s it? A lot of struggle got me to this point, but <em>finally</em> I can transfer files.</p>
<h2 id="patch-tuesday">Patch Tuesday</h2>
<p>The first order of business is to <strong>run system updates</strong>. NeXTstep 3.3 was released in mid-1995, and it had three patch updates: the <a href="https://www.nextop.de/NeXTAnswers/2066.html">first</a> at the end of 1995, and the second and <a href="http://www.nextcomputers.org/NeXTfiles/Software/NEXTSTEP/Patches/NEXTSTEP_3.3_User_Patch_3/nextstep3.3_patch_3_overview.pdf">third</a> in late 1999. Since NeXT were acquired by Apple in 1997, this patch was made by Apple to address Y2k bugs and other longstanding issues. Thanks, Apple! <a href="https://youtu.be/gaI6kBVyu00?t=28"><em>Thapple</em></a>.</p>
<p>The third patch is a cumulative update, so that should be all I need. Nextcomputers.org generously <a href="http://www.nextcomputers.org/NeXTfiles/Software/NEXTSTEP/Patches/NEXTSTEP_3.3_User_Patch_3/">hosts</a> the patch for download. Because I’m using an HP PA-RISC machine, I need <code>NS33RISCUserPatch3.tar</code>. System updates need to be installed as the <code>root</code> user, and if you run them as <code>me</code> (the default user) NeXTstep doesn’t prompt to escalate privilges, it just gives an error. Thus, I need to log in as <code>root</code> directly. In order to do that, I need to give the <code>me</code> user a password so the system will stop automatically logging in at boot (giving me a chance to log in as <code>root</code>). To set a password, you go to Preferences.app and navigate to the lock icon.</p>



<div itemscope="" itemtype="http://schema.org/ImageGallery">
	  


<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/password-before.png" alt="no password!">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/password-before.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>no password!</p>
      </figcaption>
  </figure>
</div>



<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/password-set.png" alt="password set">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/password-set.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>password set</p>
      </figcaption>
  </figure>
</div>



<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/password-secure.png" alt="password secure">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/password-secure.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>password secure</p>
      </figcaption>
  </figure>
</div>


</div>

<p>After the next reboot, I then get the login screen (instead of automatically going to the desktop):</p>


<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/login-screen.png" alt="nextstep 3.3 login screen">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/login-screen.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>nextstep 3.3 login screen</p>
      </figcaption>
  </figure>
</div>

<p>By default, the <code>root</code> password is blank (you can of course fix this after login in the same way as setting a password for the <code>me</code> account). I navigated to where I had put the patch tarball on my NAS, copied it to the HP 712, and unarchived it.</p>



<div itemscope="" itemtype="http://schema.org/ImageGallery">
	  


<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/os-update-copy.png" alt="copying from NAS">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/os-update-copy.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>copying from NAS</p>
      </figcaption>
  </figure>
</div>



<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/os-update-untar.png" alt="untarring">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/os-update-untar.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>untarring</p>
      </figcaption>
  </figure>
</div>



<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/os-update-pkg.png" alt="the patch package">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/os-update-pkg.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>the patch package</p>
      </figcaption>
  </figure>
</div>


</div>

<p>Double-clicking the package brings up a familiar-feeling Installer.app</p>


<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/os-update-installer.png" alt="installer.app for OS update">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/os-update-installer.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>installer.app for OS update</p>
      </figcaption>
  </figure>
</div>

<p>Clicking “Install” prompts me to make sure I’m choosing the right architecture (in my case, PA-RISC), runs a program to determine compatibility, and runs the update.</p>



<div itemscope="" itemtype="http://schema.org/ImageGallery">
	  


<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/os-update-arch.png" alt="choose system arch">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/os-update-arch.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>choose system arch</p>
      </figcaption>
  </figure>
</div>



<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/os-update-install.png" alt="installation in progress">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/os-update-install.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>installation in progress</p>
      </figcaption>
  </figure>
</div>



<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/os-update-complete.png" alt="installation complete">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/os-update-complete.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>installation complete</p>
      </figcaption>
  </figure>
</div>


</div>

<p>After a reboot, I’m on the most recent version of NeXTstep for PA-RISC, and ready for the year 2000!</p>

<p>What’s next for making a usable system? Developer tools! <strong>NeXTstep came on two sets of discs - “User” for the main operating system, and the optional “Developer” disc</strong> with compilers, GUI building tools, libraries, and documentation. While there were separate versions of NeXTstep User for CISC (m68k and i386) and RISC (PA-RISC and SPARC) platforms, the Developer disc is “quad-fat” - it contains binaries for all four platforms. I …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.pizzabox.computer/posts/hp712-nextstep-part-2/">https://blog.pizzabox.computer/posts/hp712-nextstep-part-2/</a></em></p>]]>
            </description>
            <link>https://blog.pizzabox.computer/posts/hp712-nextstep-part-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23659277</guid>
            <pubDate>Sat, 27 Jun 2020 03:22:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Examining ARM vs. x86 Memory Models with Rust]]>
            </title>
            <description>
<![CDATA[
Score 141 | Comments 34 (<a href="https://news.ycombinator.com/item?id=23659037">thread link</a>) | @redbluemonkey
<br/>
June 26, 2020 | https://www.nickwilcox.com/blog/arm_vs_x86_memory_model/ | <a href="https://web.archive.org/web/*/https://www.nickwilcox.com/blog/arm_vs_x86_memory_model/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="text">
        
        <p>With Apple’s recent announcement that they are moving away from Intel X86 CPU’s to their own ARM CPU’s for future laptops and desktops I thought it would be a good time to take a look at the some differences that can affect systems programmers working in Rust.</p>

<p>One of the key areas where ARM CPU’s differ from X86 is their memory model. This article will take a look at what a memory model is and how it can cause code to be correct on one CPU but cause race conditions on another.</p>

<h2 id="memory-models">Memory Models</h2>

<p>The way loads and stores to memory interact between multiple threads on a specific CPU is called that architecture’s Memory Model.</p>

<p>Depending on the memory model of the CPU, multiple writes by one thread may become visible to another thread in a different order to the one they were issued in.</p>

<p>The same is true of a thread issuing multiple reads. A thread issuing multiple reads may receive “snapshots” of global state that represent points in time ordered differently to the order of issue.</p>

<p>Modern hardware needs this flexibility to be able to maximize the throughput of memory operations. While CPU clock rates and core counts have been increasing with each new CPU iteration, memory bandwidth has struggled to keep up. Moving data from memory to operate on is often the bottle neck in the performance of applications.</p>

<p>If you’ve never written multi-threaded code, or only done so using higher level synchronization primitives such as <code>std::sync::Mutex</code>, you’ve probably never been exposed to the details of the memory model. This is because the CPU, despite whatever reordering it’s memory model allows it to perform, always presents a consistent view of memory to the current thread.</p>

<p>If we look at the below snippet of code that writes to memory and then reads the same memory straight back, we will always get the expected value of <code>58</code> back when we read. There is never the case that we’d read some stale value from memory.</p>

<div><div><pre><code><span>pub</span> <span>unsafe</span> <span>fn</span> <span>read_after_write</span><span>(</span><span>u32_ptr</span><span>:</span> <span>*</span><span>mut</span> <span>u32</span><span>)</span> <span>{</span>
    <span>u32_ptr</span><span>.write_volatile</span><span>(</span><span>58</span><span>);</span>
    <span>let</span> <span>u32_value</span> <span>=</span> <span>u32_ptr</span><span>.read_volatile</span><span>();</span>
    <span>println!</span><span>(</span><span>"the value is {}"</span><span>,</span> <span>u32_value</span><span>);</span>
<span>}</span>
</code></pre></div></div>
<p><em>I’m using volatile operations because if I used normal pointer operations the compiler is smart enough to skip the memory read and just prints the value <code>58</code>. 
Volatile operations stop the compiler from reordering or skipping our memory operation. However they have no affect on hardware.</em></p>

<p>Once we introduce multiple threads, we’re now exposed to the fact that the CPU may be reordering our memory operations.</p>

<p>We can examine the snippet below in a multi-threaded context:</p>

<div><div><pre><code><span>pub</span> <span>unsafe</span> <span>fn</span> <span>writer</span><span>(</span><span>u32_ptr_1</span><span>:</span> <span>*</span><span>mut</span> <span>u32</span><span>,</span> <span>u32_ptr_2</span><span>:</span> <span>*</span><span>mut</span> <span>u32</span><span>)</span> <span>{</span>
    <span>u32_ptr_1</span><span>.write_volatile</span><span>(</span><span>58</span><span>);</span>
    <span>u32_ptr_2</span><span>.write_volatile</span><span>(</span><span>42</span><span>);</span>
<span>}</span>

<span>pub</span> <span>unsafe</span> <span>fn</span> <span>reader</span><span>(</span><span>u32_ptr_1</span><span>:</span> <span>*</span><span>mut</span> <span>u32</span><span>,</span> <span>u32_ptr_2</span><span>:</span> <span>*</span><span>mut</span> <span>u32</span><span>)</span> <span>-&gt;</span> <span>(</span><span>u32</span><span>,</span> <span>u32</span><span>)</span> <span>{</span>
    <span>(</span><span>u32_ptr_1</span><span>.read_volatile</span><span>(),</span> <span>u32_ptr_2</span><span>.read_volatile</span><span>())</span>
<span>}</span>
</code></pre></div></div>

<p>If we initialize the contents of both pointers to <code>0</code>, and then run each function in a different thread, we can list the possible outcomes for the reader. We know that there is no synchronization, but based on our experience with single threaded code we think the possible return values are <code>(0, 0)</code>, <code>(58, 0)</code> or <code>(58, 42)</code>. But the possibility of hardware reordering of memory writes affecting multi-threads means that there is a fourth option <code>(0, 42)</code>.</p>

<p>You might think there are more possibilities due to the lack of synchronization. But all hardware memory models guarantee that aligned loads and store up to the native word size are atomic (u32 or a 32-bit CPU, u64 on a 64-bit CPU). If we changed one of our writes to <code>0xFFFF_FFFF</code>, the read will only ever see the old value or the new value. It will never see a partial value like <code>0xFFFF_0000</code>.</p>

<p>If the details of the CPU’s memory model are hidden away when using regular memory accesses, it seems like we would have no way to control it in multi-threaded programs where it affects program correctness.</p>

<p>Luckily Rust provides as with the <code>std::sync::atomic</code> module containing types that gives us the control we need. We use these types to specify exactly the memory ordering requirements our code needs. We trade performance for correctness. We place restrictions on what order the hardware can perform memory operations, taking away any bandwidth optimizations the hardware would want to perform.</p>

<p>When working with the <code>atomic</code> module, we don’t worry about the actual memory models of individual CPU architectures. Instead the operation of the <code>atomic</code> module works on an abstract memory model that’s CPU agnostic. Once we’ve expressed our requirements on the loads and stores using this Rust memory model, the compiler does the job of mapping to the memory model of the target CPU.</p>

<p>The requirements we specify on each operation takes the form of what reordering we want to allow (or deny) on the operation. The orderings form a hierarchy, with each level placing more restrictions the CPU. For example <code>Ordering::Relaxed</code> means the CPU is free to perform any reordering it wants. <code>Ordering::Release</code> means that a store can only complete after all proceeding stores have finished.</p>

<p>Let’s look at how atomic memory writes are actually compiled, compared to a regular write.</p>

<div><div><pre><code><span>use</span> <span>std</span><span>::</span><span>sync</span><span>::</span><span>atomic</span><span>::</span><span>*</span><span>;</span>

<span>pub</span> <span>unsafe</span> <span>fn</span> <span>test_write</span><span>(</span><span>shared_ptr</span><span>:</span> <span>*</span><span>mut</span> <span>u32</span><span>)</span> <span>{</span>
    <span>*</span><span>shared_ptr</span> <span>=</span> <span>58</span><span>;</span>
<span>}</span>

<span>pub</span> <span>unsafe</span> <span>fn</span> <span>test_atomic_relaxed</span><span>(</span><span>shared_ptr</span><span>:</span> <span>&amp;</span><span>AtomicU32</span><span>)</span> <span>{</span>
    <span>shared_ptr</span><span>.store</span><span>(</span><span>58</span><span>,</span> <span>Ordering</span><span>::</span><span>Relaxed</span><span>);</span>
<span>}</span>

<span>pub</span> <span>unsafe</span> <span>fn</span> <span>test_atomic_release</span><span>(</span><span>shared_ptr</span><span>:</span> <span>&amp;</span><span>AtomicU32</span><span>)</span> <span>{</span>
    <span>shared_ptr</span><span>.store</span><span>(</span><span>58</span><span>,</span> <span>Ordering</span><span>::</span><span>Release</span><span>);</span>
<span>}</span>

<span>pub</span> <span>unsafe</span> <span>fn</span> <span>test_atomic_consistent</span><span>(</span><span>shared_ptr</span><span>:</span> <span>&amp;</span><span>AtomicU32</span><span>)</span> <span>{</span>
    <span>shared_ptr</span><span>.store</span><span>(</span><span>58</span><span>,</span> <span>Ordering</span><span>::</span><span>SeqCst</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>If we look at the <a href="https://godbolt.org/z/uVQM8T">X86 assembly</a> for the above code, we see the first three functions produce identical code. It’s not until the stricter <code>SeqCst</code> ordering that we get a different instruction being produced.</p>

<div><div><pre><code><span>example:</span><span>:</span><span>test_write:</span>
        <span>mov</span>     <span>dword</span> <span>ptr</span> <span>[</span><span>rdi</span><span>],</span> <span>58</span>
        <span>ret</span>

<span>example:</span><span>:</span><span>test_atomic_relaxed:</span>
        <span>mov</span>     <span>dword</span> <span>ptr</span> <span>[</span><span>rdi</span><span>],</span> <span>58</span>
        <span>ret</span>

<span>example:</span><span>:</span><span>test_atomic_release:</span>
        <span>mov</span>     <span>dword</span> <span>ptr</span> <span>[</span><span>rdi</span><span>],</span> <span>58</span>
        <span>ret</span>
        
<span>example:</span><span>:</span><span>test_atomic_consistent:</span>
        <span>mov</span>     <span>eax</span><span>,</span> <span>58</span>
        <span>xchg</span>    <span>dword</span> <span>ptr</span> <span>[</span><span>rdi</span><span>],</span> <span>eax</span>
        <span>ret</span>
</code></pre></div></div>
<p>The first two orderings use the <strong><code>MOV</code></strong> (<strong>MOV</strong>e) instruction to write the value to memory. Only the strictest ordering produces a different instruction, <strong><code>XCHG</code></strong> (atomic e<strong>XCH</strong>an<strong>G</strong>), to a raw pointer write.</p>

<p>We can compare that to the <a href="https://godbolt.org/z/wWQo8P">ARM assembly</a>.</p>

<div><div><pre><code><span>example:</span><span>:</span><span>test_write:</span>
        <span>mov</span>     <span>w8</span><span>,</span> <span>#</span><span>58</span>
        <span>str</span>     <span>w8</span><span>,</span> <span>[</span><span>x0</span><span>]</span>
        <span>ret</span>

<span>example:</span><span>:</span><span>test_atomic_relaxed:</span>
        <span>mov</span>     <span>w8</span><span>,</span> <span>#</span><span>58</span>
        <span>str</span>     <span>w8</span><span>,</span> <span>[</span><span>x0</span><span>]</span>
        <span>ret</span>

<span>example:</span><span>:</span><span>test_atomic_release:</span>
        <span>mov</span>     <span>w8</span><span>,</span> <span>#</span><span>58</span>
        <span>stlr</span>    <span>w8</span><span>,</span> <span>[</span><span>x0</span><span>]</span>
        <span>ret</span>
        
<span>example:</span><span>:</span><span>test_atomic_consistent:</span>
        <span>mov</span>     <span>w8</span><span>,</span> <span>#</span><span>58</span>
        <span>stlr</span>    <span>w8</span><span>,</span> <span>[</span><span>x0</span><span>]</span>
        <span>ret</span>
</code></pre></div></div>

<p>In contrast we can see there is a difference once we hit the release ordering requirement. The raw pointer and relaxed atomic store use <strong><code>STR</code></strong> (<strong>ST</strong>ore <strong>R</strong>egister) while the release and sequential ordering uses the instruction <strong><code>STLR</code></strong> (<strong>ST</strong>ore with re<strong>L</strong>ease <strong>R</strong>egister). <em>The <strong><code>MOV</code></strong> instruction is this disassembly is moving the constant <code>58</code> into a register, it’s not a memory operation.</em></p>

<p>We should be able to see the risk here. The mapping between the theoretical Rust memory model and the X86 memory model is more forgiving to programmer error. It’s possible for us to write code that is wrong with respect to the abstract memory model, but still have it produce the correct assembly code and work correctly on some CPU’s.</p>

<h2 id="writing-a-multi-threaded-program-using-atomic-operations">Writing a Multi-Threaded Program using Atomic Operations</h2>

<p>The program we’ll be exploring builds upon the concept of storing a pointer value being atomic across threads. One thread is going to perform some work using a mutable object it owns. Once it’s finished that work it’s going to publish that work as an immutable shared reference, using an atomic pointer write to both signal the work is complete and allow reading threads to use the data.</p>

<h2 id="the-x86-only-implementation">The X86 Only Implementation</h2>

<p>If we really want to test how forgiving the X86’s memory model is, we can write multi-threaded code that skips any use of the <code>std::sync::atomic</code> module. I want to stress this is not something you should ever actually consider doing. In fact this code is probably undefined behavior. This is an learning exercise only.</p>

<div><div><pre><code><span>pub</span> <span>struct</span> <span>SynchronisedSum</span> <span>{</span>
    <span>shared</span><span>:</span> <span>UnsafeCell</span><span>&lt;*</span><span>const</span> <span>u32</span><span>&gt;</span><span>,</span>
    <span>samples</span><span>:</span> <span>usize</span><span>,</span>
<span>}</span>

<span>impl</span> <span>SynchronisedSum</span> <span>{</span>
    <span>pub</span> <span>fn</span> <span>new</span><span>(</span><span>samples</span><span>:</span> <span>usize</span><span>)</span> <span>-&gt;</span> <span>Self</span> <span>{</span>
        <span>assert</span><span>!</span><span>(</span><span>samples</span> <span>&lt;</span> <span>(</span><span>u32</span><span>::</span><span>MAX</span> <span>as</span> <span>usize</span><span>));</span>
        <span>Self</span> <span>{</span>
            <span>shared</span><span>:</span> <span>UnsafeCell</span><span>::</span><span>new</span><span>(</span><span>std</span><span>::</span><span>ptr</span><span>::</span><span>null</span><span>()),</span>
            <span>samples</span><span>,</span>
        <span>}</span>
    <span>}</span>

    <span>pub</span> <span>fn</span> <span>generate</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>{</span>
        <span>// do work on data this thread owns</span>
        <span>let</span> <span>data</span><span>:</span> <span>Box</span><span>&lt;</span><span>[</span><span>u32</span><span>]</span><span>&gt;</span> <span>=</span> <span>(</span><span>0</span><span>..</span><span>self</span><span>.samples</span> <span>as</span> <span>u32</span><span>)</span><span>.collect</span><span>();</span>

        <span>// publish to other threads</span>
        <span>let</span> <span>shared_ptr</span> <span>=</span> <span>self</span><span>.shared</span><span>.get</span><span>();</span>
        <span>unsafe</span> <span>{</span>
            <span>shared_ptr</span><span>.write_volatile</span><span>(</span><span>data</span><span>.as_ptr</span><span>());</span>
        <span>}</span>
        <span>std</span><span>::</span><span>mem</span><span>::</span><span>forget</span><span>(</span><span>data</span><span>);</span>
    <span>}</span>

    <span>pub</span> <span>fn</span> <span>calculate</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>expected_sum</span><span>:</span> <span>u32</span><span>)</span> <span>{</span>
        <span>loop</span> <span>{</span>            
            <span>// check if the work has been published yet</span>
            <span>let</span> <span>shared_ptr</span> <span>=</span> <span>self</span><span>.shared</span><span>.get</span><span>();</span>
            <span>let</span> <span>data_ptr</span> <span>=</span> <span>unsafe</span> <span>{</span> <span>shared_ptr</span><span>.read_volatile</span><span>()</span> <span>};</span>
            <span>if</span> <span>!</span><span>data_ptr</span><span>.is_null</span><span>()</span> <span>{</span>
                <span>// the data is now accessible by multiple threads, treat it as an immutable reference.</span>
                <span>let</span> <span>data</span> <span>=</span> <span>unsafe</span> <span>{</span> <span>std</span><span>::</span><span>slice</span><span>::</span><span>from_raw_parts</span><span>(</span><span>data_ptr</span><span>,</span> <span>self</span><span>.samples</span><span>)</span> <span>};</span>
                <span>let</span> <span>mut</span> <span>sum</span> <span>=</span> <span>0</span><span>;</span>
                <span>for</span> <span>i</span> <span>in</span> <span>(</span><span>0</span><span>..</span><span>self</span><span>.samples</span><span>)</span><span>.rev</span><span>()</span> <span>{</span>
                    <span>sum</span> <span>+=</span> <span>data</span><span>[</span><span>i</span><span>];</span>
                <span>}</span>

                <span>// did we access the data we expected?</span>
                <span>assert_eq!</span><span>(</span><span>sum</span><span>,</span> <span>expected_sum</span><span>);</span>
                <span>break</span><span>;</span>
            <span>}</span>
        <span>}</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>The function that calculates the sum of the array starts by executing a loop that reads the value of the shared pointer. Because of the atomic store guarantee we know that <code>read_volatile()</code> will only ever return <code>null</code> or a pointer to our <code>u32</code> slice. We simply keep looping until the generate thread has …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.nickwilcox.com/blog/arm_vs_x86_memory_model/">https://www.nickwilcox.com/blog/arm_vs_x86_memory_model/</a></em></p>]]>
            </description>
            <link>https://www.nickwilcox.com/blog/arm_vs_x86_memory_model/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23659037</guid>
            <pubDate>Sat, 27 Jun 2020 02:26:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Xbox Architecture]]>
            </title>
            <description>
<![CDATA[
Score 189 | Comments 64 (<a href="https://news.ycombinator.com/item?id=23657231">thread link</a>) | @timeoperator
<br/>
June 26, 2020 | https://www.copetti.org/projects/consoles/xbox/ | <a href="https://web.archive.org/web/*/https://www.copetti.org/projects/consoles/xbox/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div class="page"><nav id="navbar"></nav><hr><h2 id="a-quick-introduction">A quick introduction</h2><p>It seems that Microsoft has decided to pick up where Sega left off. Their offer? A system with familiarities appreciated by developers and online services welcomed by users.</p><p>Please note that, due to consistency with other sources, this article separates storage units between the metric prefix (i.e. megabytes or ‘MB’) and the standardised binary prefix (i.e. mebibytes or ‘MiB’), thus:</p><ul><li>1 MB = 1000 KB</li><li>1 MiB = 1024 KiB</li></ul><p>… and so forth.</p><hr><h2 id="cpu">CPU</h2><p>The processor included in this console is a slightly customised version of the famous <strong>Intel Pentium III</strong> (an off-the-shelf CPU for computers) running at <strong>733 MHz</strong>. With this, one can assume this console is just a PC behind the scenes… I won’t tell you the answer, but I promise that at the end of the article you will be able to reach your own conclusion.</p><p>Anyhow, Pentiums, along with other lines of CPUs designed and manufactured by Intel, were incredibly popular in the computer market. Such was Intel’s market share that they became the de-facto reference point for quality: As a typical user, if you wanted a good computer and had the budget, you only had to look for <em>something</em> carrying an Intel CPU. We all know by now that there are more factors involved, but that’s what the marketing guys at Intel managed to project.</p><h4 id="technical-information">Technical information</h4><p>Now that we positioned Intel in the map, let’s go back to the topic of this console. During my research, I was expecting to find documentation with the level of depth as other CPUs (MIPS, SuperH, ARM, etc), but instead, I stumbled across an excessive amount of marketing terms that only diverted my search. So, for this article, I came up with a structure to organise all the necessary information which will help to understand how this CPU works. Furthermore, I will try to introduce some terminology that Intel used to brand this CPU.</p><p>Having said that, let us take a look:</p><div><ul><li id="tab-1-1-branding-link"><a href="#tab-1-1-branding">Branding</a></li><li id="tab-1-2-the-isa-link"><a href="#tab-1-2-the-isa">The ISA</a></li><li id="tab-1-3-the-microarchitecture-link"><a href="#tab-1-3-the-microarchitecture">The Microarchitecture</a></li><li id="tab-1-4-cisc-or-risc-link"><a href="#tab-1-4-cisc-or-risc">CISC or RISC</a></li><li id="tab-1-5-the-core-link"><a href="#tab-1-5-the-core">The Core</a></li></ul><div><div id="tab-1-1-branding"><h4>Branding</h4><div><a href="https://www.copetti.org/images/consoles/xbox/cpu/branding.113be6f183d200764d7cfc590548c60fe637af1411fccff6cb274c99c9a5fa28.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/xbox/cpu/branding.113be6f183d200764d7cfc590548c60fe637af1411fccff6cb274c99c9a5fa28.png" data-src="https://www.copetti.org/images/consoles/xbox/cpu/branding.113be6f183d200764d7cfc590548c60fe637af1411fccff6cb274c99c9a5fa28.png"></picture></a><figcaption>How is this study organised</figcaption></div><p>First things first, the Xbox’s CPU is identified as a <strong>Pentium III</strong>. So what does this mean? Back then (early 00s), the Pentium series represented the next-generation of CPUs. They were ‘new high-end’ that grouped all the fancy technology that made computers super-fast, plus it helped buyers decide which CPU they had to buy if they wanted <em>the best of the best</em>.</p><p>The Pentium III replaced Pentium II, which in turn replaced the original Pentium. Moreover, when the first Pentium came out, it replaced the 80486, which in turn replaced the 80386… You get the idea. What matters is that ‘Pentium’ is mainly a brand name, it’s not directly associated with its inner workings. Therefore, we must go deeper!</p><p>To dive further and not get lost in the way, I have catalogued the information into three sections which combined, make up the chip. The first the <strong>Instruction Set Architecture</strong> or ‘ISA’ (the group of instructions used to command the CPU), <strong>Microarchitecture</strong> (how is the ISA implemented in silicon) and the <strong>Core</strong> (what set of components are used to package the microarchitecture to form the specific CPU model).</p></div><div id="tab-1-2-the-isa"><h4>The ISA</h4><p>Indeed, after I mentioned the name Intel it was a matter of time before I introduce the famous <strong>x86</strong>, its instruction set.</p><p>Even though x86 first appeared with the release of the 16-bit CPU called <strong>Intel 8086</strong> in 1978, the ISA has been constantly expanded with more instructions as more Intel CPUs were released (80186, 80286 and so on). Consequently, x86 started to fragment as more ground-breaking features were added (i.e. ‘real mode’, vs ‘protected mode’ vs ‘long mode’). To tackle this, modern x86 applications commonly targeted the 80386 ISA (also referred as <strong>IA-32</strong> or <strong>i386</strong>) as a baseline, which among other things, operates in a 32-bit environment.</p><p>Subsequently, Intel presented enhancements of IA-32 in the form of <strong>extensions</strong>, meaning these may or may not be included in an IA-32 CPU. Programs can query the CPU to check if a specific enhancement is present. The Xbox’s CPU includes two extensions:</p><ul><li><strong>MMX</strong> (Multimedia Extension): Adds 57 SIMD instructions and 8 64-bit registers (integers only) that can speed up vector operations.</li><li><strong>SSE</strong> (Streaming SIMD extension): Another SIMD-type extension which addresses some of the limitations of MMX (lack of floating-point support and unable to use floating-point unit in parallel). It adds 8 128-bit registers (called ‘XMM’) that hold four 32-bit floats; and 56 new instructions.</li></ul><p>Good news is that since the console will always have the same CPU features, programmers can optimise their code to exploit these extensions as they will always be present.</p></div><div id="tab-1-3-the-microarchitecture"><h4>The Microarchitecture</h4><p>When it comes to building a circuit that can interpret x86 instructions, Intel has come up with so many different designs for their CPUs. Some designs were featured with the release of a new Pentium Series (i.e. Pentium 4) while others are featured when Intel releases an ‘enhanced’ version of a Pentium (such as the ‘Pentium Pro’). Nevertheless, since the release of the first Pentium, the microarchitecture is identified with a different name from the CPU model. For example, the original Pentium includes the ‘P5’ microarchitecture.</p><p>Now, the Xbox CPU, along with the rest of Pentium III processors, use the <strong>P6 Microarchitecture</strong> (also known as ‘i686’). This is the 6th generation (counting from the 8086) which features:</p><ul><li>A <em>massive</em> <strong>14-stage pipeline</strong>.</li><li><strong>Out-of-order execution</strong>: If possible, the CPU re-orders the sequence of instructions to increase efficiency and performance.</li><li><strong>Speculative prediction</strong>: Similar to <a href="https://www.copetti.org/projects/consoles/gamecube/#features">branch prediction</a>, but it also executes the branch that the CPU has predicted it will be chosen.</li></ul><p>Having said that, take a closer look at these features. It so happens they are very similar to <a href="https://www.copetti.org/projects/consoles/gamecube/#features">previous consoles</a>, however, the other CPUs are very different in terms of design compared to Intel ones. Historically, one could argue that Intel could have never been able to accomplish, let’s say, a pipelined CPU. Yet they managed to do so, so let us see why…</p></div><div id="tab-1-4-cisc-or-risc"><h4>CISC or RISC</h4><p>All of the competitor’s consoles previously analysed contain a <strong>RISC</strong> CPU whereas Intel’s x86 ones are <strong>CISC</strong>. RISC CPUs are known for having a simplified instruction set compared to CISC CPUs. This includes, for instance, not featuring instructions that operate values directly from memory (as opposed to registers).</p><p>One of the advantages of RISC processors is that their simplistic approach enables its CPUs to be designed with a modular sense, which in turn can be exploited to improve performance with parallelism techniques. This is why we have seen CPUs like MIPS and PowerPC debuting pipelining, superscalar, out-of-order, branch prediction, etc. On the other side, ‘CISC’ processors were design many years before the RISC processors appeared and aimed to solve different needs. Consequently, their designs are not as flexible as RISC ones.</p><p>Back to the original question, the P6 is an interesting design, because while the CPU only understands a CISC instruction set (x86), it interprets the ISA using <strong>microcode</strong> (called ‘micro-operations’) and the unit that executes that code is built around the guidelines of RISC. All in all, this allows Intel to apply the optimisations of RISC processors while keeping a ‘CISC layer’ for compatibility with x86.</p><p>Microcode is already embedded in the silicon but it can be patched, allowing Intel to fix its CPUs after production whenever a bug or a security vulnerability is discovered. If you have read previous articles (i.e. N64 or PS2), bear in mind that Intel’s microcode is <strong>not publicly accessible</strong> (let alone documented) and Intel is its solely ‘maintainer’.</p></div><div id="tab-1-5-the-core"><h4>The Core</h4><div><a href="https://www.copetti.org/images/consoles/xbox/cpu/core.63696b1d55e579495cbbb6e42a5ee66fe0ce7fee34e107f74c750a34546c309a.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/xbox/cpu/core.63696b1d55e579495cbbb6e42a5ee66fe0ce7fee34e107f74c750a34546c309a.png" data-src="https://www.copetti.org/images/consoles/xbox/cpu/core.63696b1d55e579495cbbb6e42a5ee66fe0ce7fee34e107f74c750a34546c309a.png"></picture></a><figcaption>Coppermine design</figcaption></div><p>There were numerous chips released using the P6 microarchitecture. Specifically, the Xbox includes one model called <strong>Coppermine</strong>. This was also released as the second revision of the Pentium III (replacing the ‘Katmai’ core) and includes the following components:</p><ul><li><strong>32 KiB L1</strong> cache: Divided between 16 KiB for instructions and 16 KiB for data.</li><li>Integrated <strong>128 KiB L2</strong> cache: This is <em>odd</em> since the off-the-shelf Coppermine has 256 KiB of L2. In fact, the Coppermine128 (found in the Intel ‘Celeron’ brand, the low-end Pentium alternative) has the same amount of L2. This is probably done to reduce manufacturing costs, and keep this console at a competitive price.</li><li>133 MHz <strong>Front-side bus</strong>: This is the bus that connects the L2 cache with the memory controller, we’ll see more about it later on.<ul><li>Intel names it ‘Front-side bus’ to distinguish it from another bus which connects the L2 (external cache) with the L1 (internal cache). The latter bus is called ‘Back-side bus’ and yes… It’s an unfortunate name to use from the UK.</li></ul></li></ul><p>Coppermine also features two ‘enhancements’ over their original implementation of L2 cache, these are the <strong>Advanced Transfer Cache</strong> and the <strong>Advanced System Buffering</strong>. To sum them up, L2 cache is on-chip and their buses are wider, which help to reduce possible bottlenecks found in the Front-side bus.</p><p>Finally, the chip uses the ‘Micro-PGA2’ socket to connect it to the motherboard, but like any other console, the Xbox has it soldered with a Ball Grid Array or ‘BGA’.</p></div></div></div><h4 id="p6-and-the-end-of-pentium-numbers">P6 and the end of Pentium numbers</h4><p>Here’s a bit more history: After the years of the P6, Intel planned to succeed it with the ‘Netburst’ microarchitecture (featured in the Pentium IV). However, the line of succession also ended there: The microarchitecture couldn’t be improved anymore. This prompted an Intel team in Israel to revisit the old P6 and develop a more efficient successor. The result was <strong>Pentium M</strong>, eventually extended to form the <strong>Core</strong> microarchitecture (and brand). ‘Core’ is the basis of present designs.</p><h4 id="motherboard-architecture">Motherboard architecture</h4><p>At some point in the history of the PC, motherboards grew so much in complexity that new designs had to be developed from the ground up to efficiently tackle new emerging needs.</p><div><div><a href="https://www.copetti.org/images/consoles/xbox/cpu/motherboard.8ddd164202ef59296b376029d383dac1a91e08eea715a6596e1eefe61af1a160.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/xbox/cpu/motherboard.8ddd164202ef59296b376029d383dac1a91e08eea715a6596e1eefe61af1a160.png" data-src="https://www.copetti.org/images/consoles/xbox/cpu/motherboard.8ddd164202ef59296b376029d383dac1a91e08eea715a6596e1eefe61af1a160.png"></picture></a><figcaption>Overview of Xbox Motherboard</figcaption></div><p>The new standard developed relied on two dedicated chips to handle most of the motherboard functions. These chips are:</p><ul><li>The <strong>Northbridge</strong>: Serves as a memory controller and interfaces the GPU.</li><li>Th…</li></ul></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.copetti.org/projects/consoles/xbox/">https://www.copetti.org/projects/consoles/xbox/</a></em></p>]]>
            </description>
            <link>https://www.copetti.org/projects/consoles/xbox/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23657231</guid>
            <pubDate>Fri, 26 Jun 2020 21:25:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building AI Trading Systems]]>
            </title>
            <description>
<![CDATA[
Score 171 | Comments 83 (<a href="https://news.ycombinator.com/item?id=23656369">thread link</a>) | @dennybritz
<br/>
June 26, 2020 | https://dennybritz.com/blog/ai-trading/ | <a href="https://web.archive.org/web/*/https://dennybritz.com/blog/ai-trading/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Lessons learned building a profitable algorithmic trading system using Reinforcement Learning techniques.</p><div id="post-content"><p>About two years ago I wrote a <a href="http://www.wildml.com/2018/02/introduction-to-learning-to-trade-with-reinforcement-learning/">little piece</a> about applying Reinforcement Learning to the markets. It was a project I had worked on for a while in various forms. A few people asked me what became of it. So this post covers some high-level things I've learned. It's more of a rant than an organized post, really. If there is enough interest in this topic I'd be happy to go into more technical detail in future posts, but that's TBD. Please let me know in the comments or on <a href="https://twitter.com/dennybritz">Twitter</a>.</p> <p>Over the past few years I've built around four and a half trading systems. The first one was a pile of crap. The second one I never finished because I realized early on that it was also a pile of crap. The third one was abandoned for personal and political reasons. The fourth one worked extremely well for 12-18 months. Then, profits started decreasing and I decided to move on to other things and I lacked the motivation to go back into it. Some of the systems I worked on were for the financial markets, but the last one was applied to the crypto markets. So keep that in mind while reading.</p>  <p>If you've taken some economics classes your first thought is perhaps something like</p> <blockquote> <p>Ha, newbie! Efficient Market Hypothesis! E!M!H! You can't beat the market! It's all just luck!</p> </blockquote> <p>And I would say that most economic theories like the EMH are so far removed from the real world that they don't matter. This doesn't necessarily mean they're wrong. They are interesting academic models that can be useful in certain contexts, like for writing papers or getting prizes. But they don't survive confrontations with a messy real world and emotional human beings. If you have no idea what the Efficient Market Hypothesis says then you are in luck - sometimes ignorance truly is bliss. I won't get into it here because you can find <a href="https://www.youtube.com/watch?v=bM9bYOBuKF4">smarter people</a> arguing about this. Suffice to say, I strongly believe and have seen myself that you can build profitable systems that consistently beat the market. Will the market eventually adjust to take away that opportunity? Probably, but that's irrelevant, because the market may take months, years or decades to adjust (just look at HFT), and you are free to evolve your system over time, looking for new opportunities and adjusting to the adjusting market yourself. That was the case for me. The market seemed to have adjusted to my system as profits started decreasing, but it took more than 12 months, and with the right motivation I probably could have adjusted and improved the system to work again.</p> <p>Rather than thinking about markets from an economics perspective, I prefer to think about them from a Game Theory or Reinforcement Learning perspective. <strong><strong>The market does not exist.</strong></strong> What people call the market is an emergent property of many agents acting in an environment trying to maximize their own objective. The objective may be slightly different for everyone. Some want to sell shares they obtained through a stock options plan at a good price. Some engage in arbitrage for quick profits. Some try to predict short-term movements based on news or charting patterns. Some engage long-term speculation based on fundamentals. Some are designated market makers providing liquidity for a specific asset or exchange in return for a fee. Each could be a human acting on gut feeling and emotion, a human following some kind of implicit fuzzy algorithm (e.g. charting), or an automated system acting on data. The combined behavior of all these agents gives rise to this illusive thing that people call <em>the market</em>. Your goal isn't to beat the market, it's to beat some of the other players in the market over a time horizon you care about. The time horizon part is important. Not every trade has a clear winner and loser, because agents are optimizing over different time horizons, ranging from microseconds to decades.</p>  <p>If you come from a tech or startup background, transitioning to trading may require a change in thinking. Products and engineering are often about <strong><strong>absolutes</strong></strong>. If your website takes 100ms to load that's pretty good. Making it load in 99ms provides negligible benefit to the end-user. It'd be a waste of engineering resources. The same is true for startups. Paul Graham likes to say that startups are rarely killed by competitors. Rather, they commit suicide. They fail because they cannot find customers, don't have a solid business model, or because of founder issues. Being killed by competition with a slightly better product is quite rare.</p> <p>Trading is different. It's about <strong><strong>relatives</strong></strong>. It's fine if your website takes a horrible 10 seconds to load if your competitor needs 11 seconds. Having crappy data is fine if everyone else's data is even crappier. Paying high trading fees is fine if everyone is paying the same. This is pretty obvious if you look at the market as a multiplayer game. Even if you're a bad player on an absolute scale, you can win if your competition is worse. This has direct effects on how you build software to trade in the markets.</p>  <p>What a focus on relative performance means for engineering can be quite counterintuitive.</p> <p>When building infrastructure for a product-based company you would prefer using battle-tested, robust frameworks that minimize risk. Why re-invent the wheel if someone else has already built it? It's safe to use something that has been adopted by thousands of people. This is where open source shines. Using AWS for hosting your server? Postgres for storing your data? JSON for serialization? Python or Node for data collection? An open source library for calling APIs? Download Keras and train a NN on your data? Reasonable ideas, but when you are building trading infrastructure, you should think twice about these.</p> <p>Widely adopted technologies are commodities. If you use the same technologies as everyone else, where will your advantage come from? When building a product this doesn't matter because it's about absolute SLAs. But trading is about relatives. <strong><strong>Each commoditized technology you can specialize and build yourself is an opportunity</strong></strong> to beat the competition. By being hybrid cloud you can reduce latencies. By storing data in an efficient binary format you can save serialization time, leading to faster iteration during development, and faster predictions in production. By creating custom integrations with exchanges instead of using off-the-shelf APIs you may be able to use specific order types that are not available to others, or gain an informational advantage by processing exchange-specific information. And so on. Building highly-specialized non-generic systems is what engineers hate. We love generalization and abstraction. But specialization is often where your advantage in trading comes from.</p> <p>You don't need to start from scratch and implement your own programming language to start trading. But you should be aware of the tradeoffs you are making when adopting commoditized technologies. Make conscious decisions about it. Some of the things above seem minor - but a large number of tiny advantages can add up to a significant edge.</p>  <p>You may say, well, this makes sense, but I really don't want to compete on the infrastructure side. Instead, I want to build a smarter model that makes better predictions. That's my edge! I've heard this a LOT, and I've never seen it work.</p> <p>AI is pretty commoditized. I would say it's more commoditized than excellent infrastructure engineering, data collection, or inductive biases from domain knowledge. These days, you can easily download state-of-the-art models and run them on your data. Unless you are at the forefront of some extremely relevant research, it's unlikely that you can gain a significant edge just from training a better model.</p> <p>When people realize that their fancy AI model built on crappy infrastructure trained with crappy data (that's also used by everyone else) doesn't work, they give up. AI can give you an edge, but not an edge so huge that it allows you to ignore other factors. You still need to build good infrastructure, get good data, have decent latencies, and so on. Few people seem to be willing to spend time on these unsexy things. Think of each as a multiplier. If one is close to zero, it doesn't matter how good your AI model is.</p> <p>So, what are some these other things?</p> <ul> <li><strong><strong>Market</strong></strong> - Pick the right market(s) to trade in. Don't go for the obvious choices that everyone is picking by default. The harder it is to get access to a market, both legally and technically, the more likely that you will find opportunities. Less liquid markets may be overlooked by sophisticated funds because they don't scale to their AUM. Again, this is often counterintuitive to engineers who go for "good APIs" - good APIs typically mean popular. Popular typically means commoditized.</li> <li><strong><strong>Data</strong></strong> - Think about data sources that others do not have access to, or are not willing to get. For example, there may be data that's difficult to crawl due to sophisticated rate restrictions IP bans. Most people will give up here. This is an opportunity for you. Be skeptical of popular APIs and open source software. It's the same data that everyone else uses.</li> <li><strong><strong>Latencies</strong></strong> - You're probably not planning to compete with HFT traders (bad idea), but that doesn't mean you can completely ignore latencies. Better latencies will probably lead to easier execution with less slippage. Be careful about where you host your systems, how you send data around, how you serialize data, and so on.</li> <li><strong><strong>Models</strong></strong> - In general, better data is more important than better models, but better models can also give you an edge. Note that you are often trading off model complexity with latencies.</li> <li><strong><strong>Execution</strong></strong> - A good model doesn't mean much if you can't execute. Historical data you collect may look quite different from what's actually happening on the exchange. You are not going to know until you start live trading.</li> </ul>  <p>More than two years after my <a href="http://www.wildml.com/2018/02/introduction-to-learning-to-trade-with-reinforcement-learning/">last post</a>, do I still believe that …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dennybritz.com/blog/ai-trading/">https://dennybritz.com/blog/ai-trading/</a></em></p>]]>
            </description>
            <link>https://dennybritz.com/blog/ai-trading/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23656369</guid>
            <pubDate>Fri, 26 Jun 2020 20:06:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Micronaut 2.0: a full stack Java framework for modular, testable applications]]>
            </title>
            <description>
<![CDATA[
Score 90 | Comments 52 (<a href="https://news.ycombinator.com/item?id=23653601">thread link</a>) | @el_duderino
<br/>
June 26, 2020 | https://docs.micronaut.io/2.0.0/guide/index.html | <a href="https://web.archive.org/web/*/https://docs.micronaut.io/2.0.0/guide/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
        
        
        <p>Natively Cloud Native</p>
        <p><strong>Version:</strong> </p>
    </div>
    





<p>Micronaut is a modern, JVM-based, full stack Java framework designed for building modular, easily testable JVM applications with support for Java, Kotlin and the Groovy language.</p>
<p>Micronaut is developed by the creators of the Grails framework and takes inspiration from lessons learnt over the years building real-world applications from monoliths to microservices using Spring, Spring Boot and Grails.</p>
<p>Micronaut aims to provide all the tools necessary to build JVM applications including:</p>
<div>
<ul>
<li>
<p>Dependency Injection and Inversion of Control (IoC)</p>
</li>
<li>
<p>Aspect Oriented Programming (AOP)</p>
</li>
<li>
<p>Sensible Defaults and Auto-Configuration</p>
</li>
</ul>
</div>
<p>With Micronaut you can build Message-Driven Applications, Command Line Applications, HTTP Servers and more whilst for Microservices in particular Micronaut also provides:</p>
<div>
<ul>
<li>
<p>Distributed Configuration</p>
</li>
<li>
<p>Service Discovery</p>
</li>
<li>
<p>HTTP Routing</p>
</li>
<li>
<p>Client-Side Load Balancing</p>
</li>
</ul>
</div>
<p>At the same time Micronaut aims to avoid the downsides of frameworks like Spring, Spring Boot and Grails by providing:</p>
<div>
<ul>
<li>
<p>Fast startup time</p>
</li>
<li>
<p>Reduced memory footprint</p>
</li>
<li>
<p>Minimal use of reflection</p>
</li>
<li>
<p>Minimal use of proxies</p>
</li>
<li>
<p>No runtime bytecode generation</p>
</li>
<li>
<p>Easy Unit Testing</p>
</li>
</ul>
</div>
<p>Historically, frameworks such as Spring and Grails were not designed to run in scenarios such as server-less functions, Android apps, or low memory-footprint microservices. In contrast, Micronaut is designed to be suitable for all of these scenarios.</p>
<p>This goal is achieved through the use of Java’s <a href="https://docs.oracle.com/javase/8/docs/api/javax/annotation/processing/Processor.html">annotation processors</a>, which are usable on any JVM language that supports them, as well as an HTTP Server and Client built on <a href="https://netty.io/">Netty</a>. In order to provide a similar programming model to Spring and Grails, these annotation processors precompile the necessary metadata in order to perform DI, define AOP proxies and configure your application to run in a low-memory environment.</p>
<p>Many of the APIs within Micronaut are heavily inspired by Spring and Grails. This is by design, and aids in bringing developers up to speed quickly.</p>

<h2 id="whatsNew"><a href="#whatsNew"></a>1.1 What's New?</h2>




<p>Micronaut 2.0.0 includes the following changes:</p>
<div>
<h3 id="_core_features">Core Features</h3>
<div>
<h4 id="_support_for_jdk_14">Support for JDK 14</h4>
<p>Micronaut has been updated to support JDK 14.</p>
</div>
<div>
<h4 id="_groovy_3">Groovy 3</h4>
<p>Micronaut now supports applications written in Groovy 3.</p>
</div>
<div>
<h4 id="_startup_performance_improvements">Startup Performance Improvements</h4>
<p>Startup time has been further improved in this release with typical startup time for a new application around 20% faster.</p>
</div>
<div>
<h4 id="_improvements_to_bean_introspections">Improvements to Bean Introspections</h4>
<p>Bean introspections have been improved to support static creator methods, interfaces and enums. This means you can define a bean introspection on an interface with a private implementation such as:</p>
<div>
<p>Introspections on interfaces</p>
<div>
<pre><code data-lang="java">import io.micronaut.core.annotation.Creator;

@io.micronaut.core.annotation.Introspected
interface Example {
    String getName();

    @Creator
    static Example create(String name) {
        return () -&gt; name;
    }
}</code></pre>
</div>
</div>
</div>
<div>
<h4 id="_support_for_analyzing_the_injection_point">Support for Analyzing the Injection Point</h4>
<p>Micronaut’s Dependency Injection implementation has been improved such that you can now receive an <a href="https://docs.micronaut.io/2.0.0/api/io/micronaut/inject/InjectionPoint.html">InjectionPoint</a> instance to any <a href="https://docs.micronaut.io/2.0.0/api/io/micronaut/context/annotation/Factory.html">@Factory</a> method. This makes it possible to customize how the bean is created based on the annotation metadata at the point at which the bean is injected.</p>
<p>For example consider the following definition:</p>
<div>
<div>
<pre><code data-lang="java">@Inject @Client("http://foo.com") RxHttpClient client;</code></pre>
</div>
</div>
<p>A factory method can receive the injection point and create a client based off of the value:</p>
<div>
<div>
<pre><code data-lang="java">@Bean
protected DefaultHttpClient httpClient(InjectionPoint&lt;?&gt; injectionPoint) {
    String url = metadata.stringValue(Client.class).orElse(null);
    if (url != null) {
        return new DefaultHttpClient(url);
    } else {
        return new DefaultHttpClient();
    }
}</code></pre>
</div>
</div>
</div>
<div>
<h4 id="_support_for_eager_initialization_of_beans">Support for Eager Initialization of Beans</h4>
<p>Eager initialization of beans is useful in certain cases, such as on AWS Lambda where more CPU resources are assigned to Lamdba construction than execution. Therefore as for Micronaut 2.0, you can specify whether you want to eager initialization configuration or all singletons using the <a href="https://docs.micronaut.io/2.0.0/api/io/micronaut/context/ApplicationContextBuilder.html">ApplicationContextBuilder</a> interface:</p>
<div>
<p>Enabling Eager Initialization</p>
<div>
<pre><code data-lang="java">public class Application {

    public static void main(String[] args) {
        Micronaut.build(args)
            .eagerInitSingletons(true) <i data-value="1"></i><b>(1)</b>
            .mainClass(Application.class)
            .start();
    }
}</code></pre>
</div>
</div>
<div>
<table>
<tbody><tr>
<td><i data-value="1"></i><b>1</b></td>
<td>Setting eager init to true initializes all singletons</td>
</tr>
</tbody></table>
</div>
<p>It is also possible to just eager init configuration using <code>eagerInitConfiguration</code> which will initialize all <a href="https://docs.micronaut.io/2.0.0/api/io/micronaut/context/annotation/ConfigurationProperties.html">@ConfigurationProperties</a> beans.</p>
</div>
<div>
<h4 id="_spot_bugs_instead_of_jsr_305_nullable_nonnull_annotations">Spot Bugs Instead of JSR-305 Nullable/NonNull Annotations</h4>
<p>In Micronaut 1.x the Google distributed JSR-305 annotations library (<code>com.google.code.findbugs:jsr305</code>) was used to specify <code>@Nullable</code> and <code>@NonNull</code> on interfaces of the Micronaut API using the annotations contained within the <code>javax.annotation</code> package.</p>
<p>Due to the fact that JSR-305 has been cancelled and that this dependency has potential licensing issues (by using the <code>javax</code> namespace) as well as problems with the cross packages on Java 9+ with the module system Micronaut 2.x switches to the <code>spotbugs-annotations</code> module provided by the <a href="https://spotbugs.github.io/">SpotBugs project</a>.</p>
<p>It is recommended users of Micronaut use this API instead (although the <code>javax.annotation.Nullable</code> and <code>javax.annotation.NotNull</code> annotations continue to be supported).</p>
</div>
</div>
<div>
<h3 id="_cli_features">CLI Features</h3>

<div>
<h4 id="_micronaut_launch">Micronaut Launch</h4>
<p>Create Micronaut 2.0 applications without having the CLI installed using <code>curl</code>:</p>
<div>
<div>
<pre><code data-lang="bash">$ curl https://launch.micronaut.io/demo.zip -o demo.zip
$ unzip demo.zip -d demo</code></pre>
</div>
</div>


</div>
<div>
<h4 id="_diff_command">Diff Command</h4>
<p>Run <code>mn feature-diff --features=[FEATURE NAME]</code> from the root of another Micronaut project to create a diff of the changes that need to be applied to enable the feature. For example:</p>
<div>
<p>Using <code>feature-diff</code></p>
<div>
<pre><code data-lang="bash">$ mn feature-diff --features=azure-function
--- micronaut-cli.yml
+++ micronaut-cli.yml
@@ -3,4 +3,4 @@
 testFramework: junit
 sourceLanguage: java
 buildTool: gradle
-features: [app-name, application, gradle, http-client, java, junit, logback, netty-server, shade, yaml]
+features: [app-name, application, azure-function, azure-function-http, gradle, java, junit, logback, yaml]


--- host.json
+++ host.json
@@ -1,0 +1,7 @@
+{
+  "version": "2.0",
+  "extensionBundle": {
+    "id": "Microsoft.Azure.Functions.ExtensionBundle",
+    "version": "[1.*, 2.0.0)"
+  }
+}</code></pre>
</div>
</div>
</div>
</div>
<div>
<h3 id="_graalvm_improvements">GraalVM Improvements</h3>
<p>Micronaut’s support for GraalVM Native Image has been moved out of experimental status, which solidifies our commitment to continue improving support for native images.</p>
<div>
<h4 id="_automatic_static_resource_detection_for_native_image">Automatic Static Resource Detection for Native Image</h4>
<p>It is not longer necessary to configure static resources for your Native Immage builds. The <code>micronaut-graal</code> annotation processor will automatically do this for you for all resources found in <code>src/main/resources</code>.</p>
</div>
<div>
<h4 id="_improved_support_for_jdbc_hibernate_in_native_image">Improved support for JDBC / Hibernate in Native Image</h4>
<p>It is no longer necessary to provide additional GraalVM related configuration to connect to databases via JDBC or Hibernate/JPA. Micronaut includes automatic support for the following drivers with GraalVM Native Image:</p>
<div>
<ul>
<li>
<p>Oracle</p>
</li>
<li>
<p>MariaDB</p>
</li>
<li>
<p>Postgres</p>
</li>
<li>
<p>MS SQL</p>
</li>
<li>
<p>H2</p>
</li>
<li>
<p>MySQL</p>
</li>
</ul>
</div>
</div>
<div>
<h4 id="_support_for_flyway_migrations_in_native_image">Support for Flyway Migrations in Native Image</h4>

</div>
<div>
<h4 id="_support_for_native_image_in_aws_sdk_v2">Support for Native Image in AWS SDK v2</h4>
<p>Version 2.0 of the Micronaut AWS module <a href="https://micronaut-projects.github.io/micronaut-aws/2.0.x/guide/index.html#sdkv2">includes support for Native Image</a> for the majority of the v2 AWS APIs including S3, Dynamo DB, SES, SNS, and SQS which will be helpful for those developing native AWS Lambda functions with Micronaut + GraalVM.</p>
</div>
<div>
<h4 id="_support_for_jooq_in_native_image">Support for jOOQ in Native Image</h4>

</div>
<div>
<h4 id="_support_for_redis_in_native_image">Support for Redis in Native Image</h4>
<p>The Micronaut Redis module <a href="https://micronaut-projects.github.io/micronaut-redis/latest/guide/index.html#graalvm">includes support for Native Image</a>. There are still some pending uses cases that won’t work because of how Lettuce driver works. Make sure you read the documentation.</p>
</div>
<div>
<h4 id="_support_for_elasticsearch_in_native_image">Support for Elasticsearch in Native Image</h4>

</div>
</div>
<div>
<h3 id="_build_improvements">Build Improvements</h3>
<div>
<h4 id="_new_maven_parent_pom">New Maven Parent POM</h4>
<p>Micronaut now provides a new parent POM that can be used in Maven projects to get setup quickly:</p>
<div>
<p>Using the Maven Parent POM</p>
<div>
<pre><code data-lang="xml">&lt;parent&gt;
    &lt;groupId&gt;io.micronaut&lt;/groupId&gt;
    &lt;artifactId&gt;micronaut-parent&lt;/artifactId&gt;
    &lt;version&gt;${micronaut.version}&lt;/version&gt;
&lt;/parent&gt;</code></pre>
</div>
</div>
</div>
<div>
<h4 id="_new_maven_plugin">New Maven Plugin</h4>
<p>The parent POM mentioned above includes a new Micronaut Maven Plugin that enables automatic application restart during development. Just run the following:</p>

<p>Whenever you make a change to a class file the server will restart automatically.</p>
</div>
<div>
<h4 id="_gradle_6_5_update">Gradle 6.5 Update</h4>
<p>For Gradle users who create new applications Gradle 6.5 is used which is compatible with JDK 14.</p>
</div>
<div>
<h4 id="_better_gradle_incremental_annotation_processing_support">Better Gradle Incremental Annotation Processing Support</h4>

</div>
</div>
<div>
<h3 id="_http_features">HTTP Features</h3>
<div>
<h4 id="_support_for_http_2">Support for HTTP/2</h4>
<p>Micronaut’s Netty-based HTTP client and server have been updated to support HTTP/2.</p>
<p>See the <a href="#http2Server">HTTP/2 documentation</a> for more information on how to enable support for HTTP/2.</p>
</div>
<div>
<h4 id="_threading_model_and_event_loop_group_improvements">Threading Model and Event Loop Group Improvements</h4>
<p>Micronaut 2.0 uses a new shared default Netty <code>EventLoopGroup</code> for server worker threads and client request threads. This reduces context switching and improves resource utilization.</p>
<p>See the <a href="#clientConfiguration">HTTP Client Configuration</a> section for information on how to configure the default <code>EventLoopGroup</code> and add additional `EventLoopGroup’s that are configured per client.</p>
<p>In addition, as of Micronaut 2.0 all operations are by default executed on the <code>EventLoop</code> and users can optionally use the new <a href="https://docs.micronaut.io/2.0.0/api/io/micronaut/scheduling/annotation/ExecuteOn.html">@ExecuteOn</a> annotation to specify a named executor to execute an operation on if required (for example to offload blocking operations such as interactions with JPA/JDBC to a specific thread pool).</p>
</div>
<div>
<h4 id="_support_for_code_requestbean_code">Support for <code>@RequestBean</code></h4>
<p>It is now possible to bind the properties of a POJO argument to a <code>@Controller</code> to request parameters, headers and so on using the <a href="https://docs.micronaut.io/2.0.0/api/io/micronaut/http/annotation/RequestBean.html">@RequestBean</a> annotation.</p>
<p>Thanks to Github user <a href="https://github.com/asodja">asodja</a> for this contribution.</p>
</div>
<div>
<h4 id="_micronaut_servlet">Micronaut Servlet</h4>
<p>Micronaut now includes support for creating <a href="https://github.com/micronaut-projects/micronaut-servlet">Servlet applications</a> and users can use the command line to create an application that targets popular Servlet containers:</p>
<div>
<div>
<pre><code data-lang="bash">$ mn create-app myapp --features jetty-server    # for Jetty
$ mn create-app myapp --features tomcat-server   # for Tomcat
$ mn …</code></pre></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://docs.micronaut.io/2.0.0/guide/index.html">https://docs.micronaut.io/2.0.0/guide/index.html</a></em></p>]]>
            </description>
            <link>https://docs.micronaut.io/2.0.0/guide/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23653601</guid>
            <pubDate>Fri, 26 Jun 2020 16:11:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Carving out a niche as a small artist on Spotify]]>
            </title>
            <description>
<![CDATA[
Score 368 | Comments 257 (<a href="https://news.ycombinator.com/item?id=23652545">thread link</a>) | @imartin2k
<br/>
June 26, 2020 | https://www.stevebenjamins.com/blog/music-in-the-age-of-algorithms-47syg | <a href="https://web.archive.org/web/*/https://www.stevebenjamins.com/blog/music-in-the-age-of-algorithms-47syg">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-nc-base="header" data-controller="AncillaryLayout">
      

      

      <div>

        

        <div>
          

          <main>
            
              <section data-content-field="main-content">
                <article id="post-5ef5dad9c1c000530253b9bf" data-item-id="5ef5dad9c1c000530253b9bf">

    
      
    

    <div data-layout-label="Post Body" data-type="item" data-updated-on="1593170960338" id="item-5ef5dad9c1c000530253b9bf"><div><div><div data-block-type="2" id="block-951a4eb12d4604fa593a"><div><p>I'm making over $800 per month with my music— almost exclusively through Spotify. This is up from <a href="https://www.stevebenjamins.com/blog/spotify-and-discover-weekly">$400 per month</a> last year.   </p><p>I don't tour, I don't sell merch and I'm not on a major label. I'm just a small indie artist making music in my evenings— and Spotify is making that possible. </p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1593170550434_54819"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1593170748322-P5RY1O7VWJM9MIUCOI2F/ke17ZwdGBToddI8pDm48kMWB_b-n6a50YzIZsjMYkmt7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0nHIEvVYSINmwchg1DeZrsBIoPZ3Gfj_FVJugF-nGL6izxVTmLKDD-oSa7oHWTxBOw/Earnings+Chart.png" data-image="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1593170748322-P5RY1O7VWJM9MIUCOI2F/ke17ZwdGBToddI8pDm48kMWB_b-n6a50YzIZsjMYkmt7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0nHIEvVYSINmwchg1DeZrsBIoPZ3Gfj_FVJugF-nGL6izxVTmLKDD-oSa7oHWTxBOw/Earnings+Chart.png" data-image-dimensions="2500x1085" data-image-focal-point="0.5,0.5" alt="Earnings Chart.png" data-load="false" data-image-id="5ef5db3b8575ee1ad665d981" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1593170748322-P5RY1O7VWJM9MIUCOI2F/ke17ZwdGBToddI8pDm48kMWB_b-n6a50YzIZsjMYkmt7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0nHIEvVYSINmwchg1DeZrsBIoPZ3Gfj_FVJugF-nGL6izxVTmLKDD-oSa7oHWTxBOw/Earnings+Chart.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1593170550434_55119"><div><p>I’ve been releasing music on the internet since 2013 and it’s crazy how much music has changed since then. Here’s what I’ve learned about where music is at in 2020 and how it’s possible to carve out a niche as a small artist.    </p><h3>1. Spotify Is The Streaming Service That Matters</h3><p>In terms of music streaming market share, Spotify is Google and Apple Music is Bing. At least, that’s what I see in my stats:</p><p>I get about 177,000 plays / month. <strong>Spotify is 96% of those plays. </strong></p><p>I earn around $800 / month from music streaming. <strong>Spotify is 93% of that income. </strong></p></div></div><div data-aspect-ratio="49.95918367346939" data-block-type="5" id="block-eb72151a66d662f8af68"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1592916283663-0UYU3X1SDZU5IEDBVVRU/ke17ZwdGBToddI8pDm48kHP34hgIrqdksCH8TYvFigB7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0jG2lbcDYBOeMi4OFSYem8C2mvP1fRqxz_kej_mjMmx3K3LA91PMAqEFB2wYydnw4g/Streaming-Bar-Graph.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1592916283663-0UYU3X1SDZU5IEDBVVRU/ke17ZwdGBToddI8pDm48kHP34hgIrqdksCH8TYvFigB7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0jG2lbcDYBOeMi4OFSYem8C2mvP1fRqxz_kej_mjMmx3K3LA91PMAqEFB2wYydnw4g/Streaming-Bar-Graph.jpg" data-image-dimensions="2500x1248" data-image-focal-point="0.5,0.5" alt="Streaming-Bar-Graph.jpg" data-load="false" data-image-id="5ef5dad9c1c000530253b9ae" data-type="image" src="https://www.stevebenjamins.com/blog/Streaming-Bar-Graph.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1593170550434_61183"><div><h3>2. Algorithmic Playlists (Like <em>Discover Weekly</em>) Are Enormously Important</h3><p><strong>Every Monday my music gets a spike in streams on Spotify</strong>. You could set a watch to it— it’s that consistent: </p></div></div><div data-block-type="5" id="block-06dcac609bc1a10bb8d0"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1592919512085-FCR4VZMBTDSZEIYU2GUK/ke17ZwdGBToddI8pDm48kIKogUPb2YHTlnaztcmfVcIUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYwL8IeDg6_3B-BRuF4nNrNcQkVuAT7tdErd0wQFEGFSnPD4rrHbC4KeGHcLT21XLDVbdTUj-MuZl2cMhGeQFdSzaAYFqs-j32vOCypc5QMhBw/Daily-Spotify-Streams.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1592919512085-FCR4VZMBTDSZEIYU2GUK/ke17ZwdGBToddI8pDm48kIKogUPb2YHTlnaztcmfVcIUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYwL8IeDg6_3B-BRuF4nNrNcQkVuAT7tdErd0wQFEGFSnPD4rrHbC4KeGHcLT21XLDVbdTUj-MuZl2cMhGeQFdSzaAYFqs-j32vOCypc5QMhBw/Daily-Spotify-Streams.jpg" data-image-dimensions="2500x976" data-image-focal-point="0.5,0.5" alt="Daily-Spotify-Streams.jpg" data-load="false" data-image-id="5ef5dad9c1c000530253b99f" data-type="image" src="https://www.stevebenjamins.com/blog/Daily-Spotify-Streams.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-f845b5a6a792d5434442"><div><p>What makes Monday so special? </p><p>Well every Monday Spotify sends out a new <em>Discover Weekly</em> playlist. Discover Weekly is an <em>algorithmic</em> playlist— which means its personalized with songs <em>Spotify</em> thinks the user would like.</p><p>Discover Weekly is massively popular and it’s the reason for those Monday spikes in my streams.  </p></div></div><div data-block-type="5" id="block-4a776c4d7eb7e02d2365"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1592999085261-APZRZMG2J7AOH4BO6B2E/ke17ZwdGBToddI8pDm48kJN0G_F3WP6my7lOVI5MswB7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UZp4hhut_HaIerbk5pFZ8oSyrnRibAambjs2gnBi-UefkvjJh3JJWsjdMZ66YIxKAg/discover-weekly.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1592999085261-APZRZMG2J7AOH4BO6B2E/ke17ZwdGBToddI8pDm48kJN0G_F3WP6my7lOVI5MswB7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UZp4hhut_HaIerbk5pFZ8oSyrnRibAambjs2gnBi-UefkvjJh3JJWsjdMZ66YIxKAg/discover-weekly.jpg" data-image-dimensions="2362x1498" data-image-focal-point="0.5,0.5" alt="This is what Discover Weekly looks like" data-load="false" data-image-id="5ef5dad9c1c000530253b9a2" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1592999085261-APZRZMG2J7AOH4BO6B2E/ke17ZwdGBToddI8pDm48kJN0G_F3WP6my7lOVI5MswB7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UZp4hhut_HaIerbk5pFZ8oSyrnRibAambjs2gnBi-UefkvjJh3JJWsjdMZ66YIxKAg/discover-weekly.jpg">
          </p>
        
          
        

        
          
          <figcaption>
            <p>This is what Discover Weekly looks like</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-d485b2d78d765ad48976"><div><p>Discover Weekly might not seem like much— after all, it looks like just another playlist— but its effect on streaming numbers is <em>enormous</em>. </p><p>And the effect of Discover Weekly isn’t limited to small, obscure artists like me— the same spikes are  visible in famous artists too: </p></div></div><div data-block-type="5" id="block-ba6f929a7737ac5cf3aa"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1592920721420-SCE25GI5ZRSZD13FC5YU/ke17ZwdGBToddI8pDm48kD3m4u8nI0SgVTwfGWCKndoUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYwL8IeDg6_3B-BRuF4nNrNcQkVuAT7tdErd0wQFEGFSnO7bu0kpYlCm0fzLGoiwLJTCHsT-6enuziktTU2MNXtHVB6mY_V2xBKRzGpHlGMZGw/Coldplay.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1592920721420-SCE25GI5ZRSZD13FC5YU/ke17ZwdGBToddI8pDm48kD3m4u8nI0SgVTwfGWCKndoUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYwL8IeDg6_3B-BRuF4nNrNcQkVuAT7tdErd0wQFEGFSnO7bu0kpYlCm0fzLGoiwLJTCHsT-6enuziktTU2MNXtHVB6mY_V2xBKRzGpHlGMZGw/Coldplay.jpg" data-image-dimensions="2500x982" data-image-focal-point="0.5,0.5" alt="Coldplay.jpg" data-load="false" data-image-id="5ef5dad9c1c000530253b9a5" data-type="image" src="https://www.stevebenjamins.com/blog/Coldplay.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="5" id="block-c576bcb5ad79ca58f7c2"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1592920734163-YDS79BET4FF7MXH3GTXY/ke17ZwdGBToddI8pDm48kD3m4u8nI0SgVTwfGWCKndoUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYwL8IeDg6_3B-BRuF4nNrNcQkVuAT7tdErd0wQFEGFSnO7bu0kpYlCm0fzLGoiwLJTCHsT-6enuziktTU2MNXtHVB6mY_V2xBKRzGpHlGMZGw/Beyonce.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1592920734163-YDS79BET4FF7MXH3GTXY/ke17ZwdGBToddI8pDm48kD3m4u8nI0SgVTwfGWCKndoUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYwL8IeDg6_3B-BRuF4nNrNcQkVuAT7tdErd0wQFEGFSnO7bu0kpYlCm0fzLGoiwLJTCHsT-6enuziktTU2MNXtHVB6mY_V2xBKRzGpHlGMZGw/Beyonce.jpg" data-image-dimensions="2500x982" data-image-focal-point="0.5,0.5" alt="Beyonce.jpg" data-load="false" data-image-id="5ef5dad9c1c000530253b9a8" data-type="image" src="https://www.stevebenjamins.com/blog/Beyonce.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="5" id="block-2703bf19dcbad1ce9d12"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1592920755190-CMSVZPPO7TM4NHYONU59/ke17ZwdGBToddI8pDm48kD3m4u8nI0SgVTwfGWCKndoUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYwL8IeDg6_3B-BRuF4nNrNcQkVuAT7tdErd0wQFEGFSnO7bu0kpYlCm0fzLGoiwLJTCHsT-6enuziktTU2MNXtHVB6mY_V2xBKRzGpHlGMZGw/Rihanna.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1592920755190-CMSVZPPO7TM4NHYONU59/ke17ZwdGBToddI8pDm48kD3m4u8nI0SgVTwfGWCKndoUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYwL8IeDg6_3B-BRuF4nNrNcQkVuAT7tdErd0wQFEGFSnO7bu0kpYlCm0fzLGoiwLJTCHsT-6enuziktTU2MNXtHVB6mY_V2xBKRzGpHlGMZGw/Rihanna.jpg" data-image-dimensions="2500x982" data-image-focal-point="0.5,0.5" alt="Rihanna.jpg" data-load="false" data-image-id="5ef5dad9c1c000530253b9ab" data-type="image" src="https://www.stevebenjamins.com/blog/Rihanna.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-f9c72d34909bce94a17f"><div><p>This is <em>CRAZY</em>. </p><p>No other promotional tactic in music comes close to Discover Weekly in delivering new listeners in such a low-effort, high volume way. </p><p>Back in 2013 I would spend hours cold-emailing bloggers. I would be lucky if I got a hit and got 1,000 plays on one of my songs. It was labour intensive. </p><p>Now algorithmic playlists like Discover Weekly send 1,000 new listeners every week without any work on my part. This is amazing. Cold outreach sucks. It sucks for the artist and it sucks for the bloggers. Spotify deserves a lot of credit for here. </p><h3>3. Songs Matter, Not Albums</h3><p>Spotify's algorithmic playlists rank songs— not albums. It's just like in SEO: Google indexes pages, not websites. </p><p>This has elevated the importance of songs and made albums more irrelevant than ever— especially for small artists like me. (Of course famous artists like Drake and Billie Eilish can still get massive press from an album release— but most artists are not at that level of fame.)</p><p>These days it’s almost always better to release individual songs rather than albums. (Plus as an artist, you’re limited to pitching one song at a time to Spotify’s human editors— and I’ll explain why human editors still matter in the next section). </p></div></div><div data-block-type="5" id="block-3d45ff76650d47ec036b"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1593088518969-V2ZSGRTIPC70DQU6DTY2/ke17ZwdGBToddI8pDm48kO97cLu6upMnNovRR-E7bzEUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dmbqkB0ZqjW5-e8O_uKcAuR8BQQi9T61LWwD7i0-QXfMoRwB-dUGsSquCnVTFQcaRg/stagger.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1593088518969-V2ZSGRTIPC70DQU6DTY2/ke17ZwdGBToddI8pDm48kO97cLu6upMnNovRR-E7bzEUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dmbqkB0ZqjW5-e8O_uKcAuR8BQQi9T61LWwD7i0-QXfMoRwB-dUGsSquCnVTFQcaRg/stagger.jpg" data-image-dimensions="1574x639" data-image-focal-point="0.5,0.5" alt="A 12-song album is better off being released as 12 staggered singles throughout the year." data-load="false" data-image-id="5ef5dad9c1c000530253b9b1" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1593088518969-V2ZSGRTIPC70DQU6DTY2/ke17ZwdGBToddI8pDm48kO97cLu6upMnNovRR-E7bzEUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dmbqkB0ZqjW5-e8O_uKcAuR8BQQi9T61LWwD7i0-QXfMoRwB-dUGsSquCnVTFQcaRg/stagger.jpg">
          </p>
        
          
        

        
          
          <figcaption>
            <p>A 12-song album is better off being released as 12 staggered singles throughout the year.</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-22e1940a7b25c119a57a"><div><p>I get why the growing irrelevance of albums bums some people out. Albums are big statements. Some of the most iconic releases in popular music have been albums. </p><p>… But things change and that’s okay. Plus I think asking listeners to listen to a full-length album don’t make sense in our attention-starved world. Asking listeners to listen to a single song might just be a more realistic ask. </p><h3>4. Human Editors Still Matter— Just Not How You Think</h3><p>The secret to getting your music on algorithmic playlists like Discover Weekly is to get on <em>human</em> playlists first. </p><p>It’s similar to SEO: playlists are like backlinks. When a song is added to a playlist it's a vote for the quality of the song. Not every playlist is equally authoritative though— just like how a link from The NY Times is more authoritative than other links in SEO.  </p><p>On Spotify, the most authoritative playlists are <em>editorial</em> playlists. These are  playlists curated by official Spotify editors. <strong>In my experience, it’s only when I get on an editorial playlist that my songs get heavily featured on algorithmic playlists like Discover Weekly.</strong></p></div></div><div data-block-type="5" id="block-d2618bdb9eb6fca6fb0b"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1593088707091-NCYBLFD641ENREFXBUZL/ke17ZwdGBToddI8pDm48kP049tvC-D_OFvuLSxtdDE0UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2ds5RHc3yZvuk382KqaWk56FRKl7OH-Mh-dlRKY4AnQFFCjLISwBs8eEdxAxTptZAUg/editor-playlists.png" data-image="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1593088707091-NCYBLFD641ENREFXBUZL/ke17ZwdGBToddI8pDm48kP049tvC-D_OFvuLSxtdDE0UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2ds5RHc3yZvuk382KqaWk56FRKl7OH-Mh-dlRKY4AnQFFCjLISwBs8eEdxAxTptZAUg/editor-playlists.png" data-image-dimensions="1884x738" data-image-focal-point="0.5,0.5" alt="Official Spotify editorial playlists have this icons in the top left." data-load="false" data-image-id="5ef5dad9c1c000530253b9b4" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1593088707091-NCYBLFD641ENREFXBUZL/ke17ZwdGBToddI8pDm48kP049tvC-D_OFvuLSxtdDE0UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2ds5RHc3yZvuk382KqaWk56FRKl7OH-Mh-dlRKY4AnQFFCjLISwBs8eEdxAxTptZAUg/editor-playlists.png">
          </p>
        
          
        

        
          
          <figcaption>
            <p>Official Spotify editorial playlists have this icons in the top left.</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-811f68956e11c14d5a36"><div><p>So how do you get on editorial playlists? I sincerely have no clue. I've been on editorial playlists 16 times but I have no idea how to replicate that.  </p><p><em>Note: In my experience, major label artists have an easier time getting on editorial playlists. This is discouraging— if major label artists have an easier time getting on editorial playlists, they’ll also get better placement in algorithmic playlists… But major label artists also only typically get 13% - 20% of streaming royalties… so there are still plenty of reasons to stay indie! </em></p><h3>5. Algorithms Make For Looser Relationships Between Artists And Listeners</h3><blockquote><p><em>"Music itself is going to become like running water or electricity." - David Bowie</em></p></blockquote><p>My most popular song 'Circles' has been played 1,350,00 times. And every month about 65,000 people listen to my music on Spotify. </p><p>Guess how many people follow me <a href="https://www.instagram.com/stevebenjamins/">on Instagram</a>? 480. </p><p>Just because people listen to me on Spotify, doesn’t mean they want a deep relationship. Most listeners just add 'Circles' to their library and move on with their life.</p><p>I’m definitely okay with this. I’d rather listeners follow me on Spotify rather than Instagram anyways. Plus only good things can come out of de-coupling fame from music. Make music because it’s what you love to do— not because you want to get famous. If you want to get famous I think you’re better off as a Youtuber or Tiktok influencer anyways! </p><p><strong>I think this is just the nature of algorithmic playlists— they lead to a high volume of listeners with a very loose connection to you as an artist:</strong></p></div></div><div data-block-type="5" id="block-a901b06fafc5a15411fa"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1593089202461-97Q8C0YXC24AJXHWAZS9/ke17ZwdGBToddI8pDm48kE0dBl2NH3FZqnEQ36vQk7d7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1USktP1TqXhY4Tkzt8R3NIMXp3WxE2w03r4EM8893BLC6ItbcvNsfhsWVcDwbNYmf2w/discovery-1.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1593089202461-97Q8C0YXC24AJXHWAZS9/ke17ZwdGBToddI8pDm48kE0dBl2NH3FZqnEQ36vQk7d7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1USktP1TqXhY4Tkzt8R3NIMXp3WxE2w03r4EM8893BLC6ItbcvNsfhsWVcDwbNYmf2w/discovery-1.jpg" data-image-dimensions="2000x1106" data-image-focal-point="0.5,0.5" alt="discovery-1.jpg" data-load="false" data-image-id="5ef5dad9c1c000530253b9b7" data-type="image" src="https://www.stevebenjamins.com/blog/discovery-1.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-a93c404fd14f000ea4f9"><div><h3>6. The Deepest Relationships Happen When Listeners Share Music With Friends</h3><p>Listeners sharing music among their friends leads to the deepest connections in my experience. </p><p>For example: last month I was interviewed on a college radio station by three guys. I was blown away by how closely these guys  listened to the music. They knew it so well and had spotted lyrical themes that I’ve repeated throughout songs that I thought I only noticed. It was clear there was a very deep connection.  </p><p>Hearing from listeners like that is nourishing in a way that a graph on Spotify just can't be.  It can be a very moving experience.</p><p>I’ve had similar experiences when high school students reach out to tell me everyone in their circle is listening to the music. Somehow they seem to just care about the music more— like their shared interest draws them deeper. </p><p>When you spend most of your time in an algorithmic world of music streaming, it can feel like magic when you meet listeners who found your music through friends. Sharing music between friends can’t much algorithms in sheer volume but it is by far the deepest way to build connections. </p></div></div><div data-block-type="5" id="block-9ce321c7732a79bf3e5a"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1593089242182-PUPZTVNS044OUUZMF106/ke17ZwdGBToddI8pDm48kE0dBl2NH3FZqnEQ36vQk7d7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1USktP1TqXhY4Tkzt8R3NIMXp3WxE2w03r4EM8893BLC6ItbcvNsfhsWVcDwbNYmf2w/discovery-2.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1593089242182-PUPZTVNS044OUUZMF106/ke17ZwdGBToddI8pDm48kE0dBl2NH3FZqnEQ36vQk7d7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1USktP1TqXhY4Tkzt8R3NIMXp3WxE2w03r4EM8893BLC6ItbcvNsfhsWVcDwbNYmf2w/discovery-2.jpg" data-image-dimensions="2000x1106" data-image-focal-point="0.5,0.5" alt="discovery-2.jpg" data-load="false" data-image-id="5ef5dad9c1c000530253b9ba" data-type="image" src="https://www.stevebenjamins.com/blog/discovery-2.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-47277ac585d98eee4d6a"><div><h3>7. Small And Obscure Is Wonderful </h3><p>I don’t tour, I don’t sell merch and I’m not on a major label. I just like making music. I'm an indie artist surfing the waves of the Spotify algorithm— and honestly… it’s been great. </p><p>Small and obscure is kind of wonderful: I get 3 or 4 people every week sending me an email or DM and it's all something sweet or kind— no one cares enough to troll or be a hater.</p></div></div><div data-block-type="5" id="block-33e58c22c9b6be9be03d"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1593089843440-HMK4D6UUZDPLG5KKJ34U/ke17ZwdGBToddI8pDm48kPnFvlbclLoR6gDHvfg1BsoUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcZ7nIHmprcfuov5dlvTnz74ZM4c50vsZUfNA6dMgd7y1l5gbUCHkpeEIHHwQ0bqKX/insta-love.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1593089843440-HMK4D6UUZDPLG5KKJ34U/ke17ZwdGBToddI8pDm48kPnFvlbclLoR6gDHvfg1BsoUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcZ7nIHmprcfuov5dlvTnz74ZM4c50vsZUfNA6dMgd7y1l5gbUCHkpeEIHHwQ0bqKX/insta-love.jpg" data-image-dimensions="1038x460" data-image-focal-point="0.5,0.5" alt="These kind of messages are really uplifting and mean a lot." data-load="false" data-image-id="5ef5dad9c1c000530253b9bd" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1593089843440-HMK4D6UUZDPLG5KKJ34U/ke17ZwdGBToddI8pDm48kPnFvlbclLoR6gDHvfg1BsoUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcZ7nIHmprcfuov5dlvTnz74ZM4c50vsZUfNA6dMgd7y1l5gbUCHkpeEIHHwQ0bqKX/insta-love.jpg">
          </p>
   …</figure></div></div></div></div></div></div></article></section></main></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.stevebenjamins.com/blog/music-in-the-age-of-algorithms-47syg">https://www.stevebenjamins.com/blog/music-in-the-age-of-algorithms-47syg</a></em></p>]]>
            </description>
            <link>https://www.stevebenjamins.com/blog/music-in-the-age-of-algorithms-47syg</link>
            <guid isPermaLink="false">hacker-news-small-sites-23652545</guid>
            <pubDate>Fri, 26 Jun 2020 14:46:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What I learned from writing for The Onion for a month (2015)]]>
            </title>
            <description>
<![CDATA[
Score 201 | Comments 108 (<a href="https://news.ycombinator.com/item?id=23651864">thread link</a>) | @bryanrasmussen
<br/>
June 26, 2020 | https://wordsbyevanporter.com/what-i-learned-from-writing-for-the-onion-for-a-month/ | <a href="https://web.archive.org/web/*/https://wordsbyevanporter.com/what-i-learned-from-writing-for-the-onion-for-a-month/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <!--kg-card-begin: markdown--><p><img src="https://wordsbyevanporter.com/content/images/2015/01/onionlogo.png" alt=""></p>
<p>In April/May of 2010, I spent four weeks as a freelance writer for The Onion News Network.</p>
<p>Besides looking great on a resume, it was an awesome gig and a huge learning experience. Not surprisingly, I get asked about it pretty often.</p>
<p>So here's everything I know about how to get a job writing for <a href="http://www.theonion.com/">The Onion</a>, and what I learned from my (short) time doing it.</p>
<hr>
<h2 id="howigotajobfreelancewritingfortheonion">How I Got a Job Freelance Writing for The Onion</h2>
<hr>
<p>Getting a job writing for The Onion is not easy. But there's no big secret to it, either.</p>
<p><a href="http://www.theonion.com/jobs">The Onion has a jobs page</a> on their website.</p>
<p>Yep. That's the big story behind how I got hired to write for The Onion: I went on their website and applied.</p>
<p>But here's the thing -- I did this at least twice with no luck before I got accepted.</p>
<p>Here's how it worked back then:</p>
<p>I would check the job listings frequently (obsessively), and every once in a blue moon, there'd be a position on there called Freelancer or Freelance Writer. You'd send in an email with your resume and samples, and they'd send back an application for you to complete. You had to return two things:</p>
<ol>
<li>
<p><strong>A list of 20 headlines</strong> and concepts for video sketches. (All the job listings I ever saw were for The Onion News Network -- their video leg. I never saw anything for editorial positions.)</p>
</li>
<li>
<p><strong>A completed script</strong> for one of their news segment sketches based on ideas or concepts they provided.</p>
</li>
</ol>
<p>Like I said, I went through this process (the final product is often known in the industry as a "packet") at least twice with no success. It doesn't sound like much, but it is TOUGH. I labored over those 20 headlines like you wouldn't believe. Even the best ideas start to look like shit after you've stared at them for a week.</p>
<p>And the scripts. Man, those were hard. They never gave you blockbuster concepts to work with, and I think that was on purpose. It was always some kind of dry, subtle joke -- they wanted to see what you could do and how far you would take it.</p>
<p>But the third time I applied was a charm. I'll never forget opening my email and seeing these words:</p>
<blockquote>
<p>The Onion News Network would like to congratulate you on being selected as a Contributor for the IFC series. We had a huge number of applicants, and we are thrilled with how strong this group is.</p>
</blockquote>
<p>I remember texting my wife -- girlfriend at the time. She was in class and stepped into the hall to call me. We both basically screamed on the phone for a couple of minutes.</p>
<p><strong>Side Note:</strong> I haven't seen any writing positions listed on The Onion's website in years. Granted, I don't check as frequently anymore, but I think the only way to get in with them these days is to be recruited, know someone there, or come up through the ranks as an intern or writer's assistant.</p>
<p>If you REALLY want to get a job writing for The Onion; email them. I've heard stories of people that have done this. They say they won't take anything unsolicited, and there's a 99% chance they won't, but who knows? Serendipity just might strike for you.</p>
<hr>
<h2 id="whatitwasliketowritefortheonion">What It Was Like to Write for The Onion</h2>
<hr>
<p>They put us to work right away. This was back in 2010, and The Onion was going into pre-production on its very first TV show -- The Onion News Network on IFC (The Independent Film Channel).</p>
<p>It would be a lot like the Onion video content we knew and loved, except in a half hour format and with recurring anchors as characters.</p>
<p>We were required to turn in 25 ideas a week; an "idea" being a headline or concept along with a short explanation of the joke and how the segment would play out.</p>
<p>Some weeks, we'd get really brief feedback on our lists. Other weeks, not. Then, by mid week, they'd compile all the ideas they liked. Some would be marked down as "one liners", or jokes that would be pulled in to scroll across the bottom of the screen during the show. Others were segmented by where in the show they might fit in, with some of them designated to move to the scripting stage (where the staff writers would take over).</p>
<p>The process moved fast. My job, along with the other freelancers, was to come up with ideas. We weren't really consulted or informed about anything else surrounding the show. No meetings to discuss casting. No phone calls to brainstorm around our jokes. It was our job to pump out creativity and let the full time staff filter everything out. Everything was done over email.</p>
<p>In the end, only one of my ideas actually made it into the show -- unless I missed a one-liner somewhere along the line, which would be easy to do.</p>
<p>Funny enough, the idea of mine that made it to production was one from my submission packet -- I'm pretty sure it's the reason they hired me. And they actually chose to open the entire series with it, which was pretty cool.</p>

<p>I recorded the pilot when it aired and probably watched it a dozen times with my family. One of the coolest moments I've ever had as a writer.</p>
<hr>
<h2 id="whatilearnedwritingfortheonion">What I Learned Writing for The Onion</h2>
<hr>
<p>This was a huge learning experience for me in a very short amount of time. I could probably talk for days about everything I learned working as a writer for The Onion for four weeks, but if I had to boil it down, here's what I'd say:</p>
<h3 id="ideasarecheap">Ideas are cheap.</h3>
<p>Or, in their case, jokes. They made us come up with so many sketch ideas and headlines. Huge lists of them. And once they were dead, they were dead. There was no reusing ideas that didn't quite make the cut in previous weeks. No iterating on almost-there jokes. When an idea was rejected, it was time to move on. Always bigger and better jokes, or ideas, out there to be found.</p>
<p>I also learned how to really dig into an idea to see if it had any potential. They were constantly pushing us to see past the headline. Is it just a funny sentence or is there room to explore and expand this into a 3 minute sketch? Is there substance?</p>
<h3 id="creativityisamuscle">Creativity is a muscle.</h3>
<p>What I loved about The Onion's writing process was the sheer volume of it. 25 ideas a week. No excuses. Often times, I'd turn in more than 25, along with a big list of one-liners I knew weren't big enough for full sketches. For one thing, it forced me to dig deep and get past those first initial ideas that came easily. It also helped me learn The Onion's editorial voice through repetition, which is something that can't be overstated.</p>
<h3 id="iamnotthatfunny">I am not that funny.</h3>
<p>I had one great idea and I used it up in my application to get the job. I wrote a few other funny jokes throughout, but nowhere near the level of The Onion's top writers. I wish I could show you these lists of approved ideas I got in my inbox each week. Reading through them was an absolute blast; these guys and girls are so freaking talented and funny.</p>
<p>At the end of the project, they opted to keep a few of the freelance writers on -- alas, I was not one of them. And I didn't expect to be. To be a professional humor writer, you have to be insanely funny and creative. I'm a good writer, and I got their voice, and I have a few good ideas, but I was never going to make it as a full-time writer for The Onion. And that's okay.</p>
<hr>
<h2 id="intheend">In The End</h2>
<hr>
<p>Writing for The Onion was one of the coolest experiences I've ever had, and I feel lucky to have gotten the opportunity.</p>
<p>I mean, I got to see an idea I had sitting in my living room acted out on TV with a real script, real actors, and real production value. That was awesome, and I'll never forget it. And to top it off, I actually got a paycheck. People paid me real money to come up with jokes. That was incredible.</p>
<p>And I'd like to think that, even though the gig was short lived, I learned a ton by being bold enough to jump into the deep end with pro comedy writers.</p>
<p>Even if I didn't really belong there.</p>
<hr>
<h2 id="nowreadthisworkingwithaneditorprotectingyourvoice">Now Read This: <a href="http://www.wordsbyevanporter.com/working-with-an-editor/">Working with an Editor &amp; Protecting Your Voice</a></h2>
<hr>
<!--kg-card-end: markdown-->
                </div>
            </section>


            


        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://wordsbyevanporter.com/what-i-learned-from-writing-for-the-onion-for-a-month/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23651864</guid>
            <pubDate>Fri, 26 Jun 2020 13:43:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Prisma Raises $12M Series A]]>
            </title>
            <description>
<![CDATA[
Score 104 | Comments 105 (<a href="https://news.ycombinator.com/item?id=23651605">thread link</a>) | @pimeys
<br/>
June 26, 2020 | https://www.prisma.io/blog/prisma-raises-series-a-saks1zr7kip6 | <a href="https://web.archive.org/web/*/https://www.prisma.io/blog/prisma-raises-series-a-saks1zr7kip6">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><div><hr><h3 id="contents"><a href="#contents" aria-label="contents permalink"></a>Contents</h3><ul><li><a href="#our-mission-making-databases-easy">Our mission: Making databases easy</a></li><li><a href="#where-we-are-today">Where we are today</a></li><li><a href="#whats-next-for-prisma">What's next for Prisma</a></li><li><a href="#we--our-community">We 💚 our community</a></li></ul><hr><h3 id="tldr"><a href="#tldr" aria-label="tldr permalink"></a>TLDR</h3><p>At Prisma, our goal is to <strong>revolutionize how application developers work with databases</strong>. Considering the <a target="_blank" rel="noopener noreferrer" href="https://dataguide.prisma.io/intro/comparing-database-types">vast number of different databases</a> and <a target="_blank" rel="noopener noreferrer" href="https://dataguide.prisma.io/types/relational/comparing-sql-query-builders-and-orms">variety of tools</a> for working with them, this is an extremely ambitious goal!</p><p>We are thrilled to enter the next chapter of pursuing this goal with a <strong>$12M Series A</strong> funding round led by <a target="_blank" rel="noopener noreferrer" href="https://amplifypartners.com/">Amplify Partners</a>. We are especially excited about this partnership as Amplify is an experienced investor in the developer tooling ecosystem and has led investments for numerous companies, such as <a target="_blank" rel="noopener noreferrer" href="https://www.datadoghq.com/">Datadog</a>, <a target="_blank" rel="noopener noreferrer" href="https://www.fastly.com/">Fastly</a>, and <a target="_blank" rel="noopener noreferrer" href="https://www.gremlin.com/">Gremlin</a>.</p><hr><h3 id="our-mission-making-databases-easy"><a href="#our-mission-making-databases-easy" aria-label="our mission making databases easy permalink"></a>Our mission: Making databases easy</h3><h4 id="database-tools-are-stuck-with-legacy-paradigms"><a href="#database-tools-are-stuck-with-legacy-paradigms" aria-label="database tools are stuck with legacy paradigms permalink"></a>Database tools are stuck with legacy paradigms</h4><p>Despite having been developed in the 1970s, relational <a target="_blank" rel="noopener noreferrer" href="https://dataguide.prisma.io/intro/what-are-databases">databases</a> are still the most commonly used databases today. While <a target="_blank" rel="noopener noreferrer" href="https://dataguide.prisma.io/intro/comparing-database-types">other database types have been developed in the meantime</a>, from <em>document</em>, to <em>graph</em> , to <em>key-value</em> databases, working with databases remains one of the biggest challenges in application development.</p><p>While almost any other part of the development stack has been modernized, database tools have been stuck with the same paradigms for the last decades.</p><p><span><img src="https://imgur.com/WwMdROo.png"></span></p><p>When working with relational databases, developers have the choice of working directly with SQL or using a higher-level abstraction called ORMs. <a href="https://www.prisma.io/docs/understand-prisma/why-prisma#problems-with-sql-orms-and-other-database-tools">None of these options is particularly compelling</a>.</p><p>Using SQL is very low-level resulting in reduced developer <em>productivity</em>. In contrast, ORMs are too high-level and developers sacrifice <em>control</em> over the executed database operations when using this approach. ORMs further suffer from a fundamentally misguided abstraction called the <a target="_blank" rel="noopener noreferrer" href="http://blogs.tedneward.com/post/the-vietnam-of-computer-science/">object-relational impedance mismatch</a>.</p><h4 id="prisma-modernizes-how-developers-work-with-databases"><a href="#prisma-modernizes-how-developers-work-with-databases" aria-label="prisma modernizes how developers work with databases permalink"></a>Prisma modernizes how developers work with databases</h4><p>Similar to how React.js modernized frontend development or how Serverless invented a new model for compute infrastructure, <strong>Prisma is here to bring a new and modern approach for working with databases</strong>!</p><p>Prisma's unique approach to solving database access with a <em>generated</em> query builder that's fully type-safe and can be tailored to any database schema sets it apart from previous attempts of solving the same problem.</p><p>A big part of the modernization comes from our <strong>major focus on developer experience</strong>. Database tools are often associated with friction, uncertainty, painful hours of debugging and costly performance bottlenecks.</p><div><p><strong>Developer experience is part of our DNA at Prisma.</strong> Working with databases is too often associated with friction and uncertainty when it should be fun, delightful and productive!</p></div><p>We want to make working with databases <em>fun</em>, <em>delightful</em> and <em>productive</em> while guiding developers towards proper patterns and best practices in their daily work with databases!</p><h4 id="learning-from-our-past-from-graphql-to-databases"><a href="#learning-from-our-past-from-graphql-to-databases" aria-label="learning from our past from graphql to databases permalink"></a>Learning from our past: From GraphQL to databases</h4><p>As a company we've gone through a number of major product iterations and pivots over the last years.</p><p><span><img src="https://imgur.com/4YPWyaW.png"></span></p><p>Our initial products, Graphcool and Prisma 1 were focused on <a target="_blank" rel="noopener noreferrer" href="http://graphql.org/">GraphQL</a> as a technology. However, as we were running both tools in production, we realized they didn't address the <em>core</em> problems developers had.</p><p>We realized that a lot of the value we provided with both tools didn't necessarily lie in the quick provision of a GraphQL server, but rather in the fact that developers didn't need to manage their <em>database workflows</em> explicitly.</p><p>This realization led to a pivot which ultimately manifested in the rewrite to Prisma 2. With this new version of Prisma, we have found the right level of abstraction that ensures developers keep full control and flexibility about their development stack while not needing to worry about database workflows!</p><h4 id="inspired-by-the-data-layers-of-big-companies-twitter-facebook-"><a href="#inspired-by-the-data-layers-of-big-companies-twitter-facebook-" aria-label="inspired by the data layers of big companies twitter facebook  permalink"></a>Inspired by the data layers of big companies (Twitter, Facebook, ...)</h4><p>The approach Prisma takes for this modernization is inspired by big tech companies such as Twitter, Facebook, or Airbnb. </p><p>To ensure productivity of application developers, it is a common practice in these organizations to introduce a <em>unified data access layer</em> that abstracts away the database infrastructure and provides developers with a more familiar and convenient way of accessing data.</p><p>Facebook developed a system called <a target="_blank" rel="noopener noreferrer" href="https://medium.com/coinmonks/tao-facebooks-distributed-database-for-social-graph-c2b45f5346ea">TAO</a> that fulfills the data needs of application developers. Twitter has built a "virtual database" called <a target="_blank" rel="noopener noreferrer" href="https://about.sourcegraph.com/graphql/graphql-at-twitter#schema">Strato</a> which <em>brings together multiple data sources so that they can be queried and mutated uniformly</em>. Airbnb <a target="_blank" rel="noopener noreferrer" href="https://medium.com/airbnb-engineering/reconciling-graphql-and-thrift-at-airbnb-a97e8d290712">combines GraphQL and Thrift</a> to abstract away the implementation details of querying data.</p><p><span><img src="https://imgur.com/Hb9VOWN.png"></span></p><p>Building these custom data access layers requires <em>a lot</em> of time and resources (as these are typically implemented by dedicated <em>infrastructure teams</em>) and thus is not a realistic approach for most companies and development teams.</p><p>Being based on the same core ideas and principles as these systems, <strong>Prisma democratizes the pattern of a uniform data access layer</strong> and makes it accessible as an open-source technology for development teams of all sizes.</p><hr><h3 id="where-we-are-today"><a href="#where-we-are-today" aria-label="where we are today permalink"></a>Where we are today</h3><h4 id="prisma-20-is-ready-for-production"><a href="#prisma-20-is-ready-for-production" aria-label="prisma 20 is ready for production permalink"></a>Prisma 2.0 is ready for production</h4><p>After running Preview and Beta versions for more than a year, we've recently <a href="https://www.prisma.io/blog/announcing-prisma-2-n0v98rzc8br1">launched Prisma 2.0 for production</a>. Having rewritten the core of Prisma from Scala to Rust for the transition, we've built a strong foundation to expand the Prisma toolkit to cover various database workflows in the future.</p><p>Prisma's main feature is <a href="https://www.prisma.io/docs/reference/tools-and-interfaces/prisma-client">Prisma Client</a>, an auto-generated and type-safe query builder which can be used to access a database in Node.js and TypeScript. Thanks to <a href="https://www.prisma.io/docs/reference/tools-and-interfaces/introspection">introspection</a>, Prisma Client can be used to work with any existing database!</p><blockquote><p><strong>Note</strong>: Prisma currently supports <strong>PostgreSQL</strong>, <strong>MySQL</strong> and <strong>SQLite</strong> databases –&nbsp;with more planned. Please create <a target="_blank" rel="noopener noreferrer" href="https://github.com/prisma/prisma/issues/new">new GitHub issues</a> or subscribe to existing ones (e.g. for <a target="_blank" rel="noopener noreferrer" href="https://github.com/prisma/prisma/issues?q=is%3Aissue+is%3Aopen+mongo">MongoDB</a> or <a target="_blank" rel="noopener noreferrer" href="https://github.com/prisma/prisma/issues/1676">DynamoDB</a>) if you'd like to see support for specific databases.</p></blockquote><h4 id="next-generation-web-frameworks-are-built-on-prisma"><a href="#next-generation-web-frameworks-are-built-on-prisma" aria-label="next generation web frameworks are built on prisma permalink"></a>Next-generation web frameworks are built on Prisma</h4><p>The Node.js ecosystem is known for lots of different frameworks that try to streamline workflows and prescribe certain conventions. We are extremely humbled that many framework authors decide to use Prisma as their data layer of choice.</p><h5 id="redwoodjs-bringing-full-stack-to-the-jamstack"><a href="#redwoodjs-bringing-full-stack-to-the-jamstack" aria-label="redwoodjs bringing full stack to the jamstack permalink"></a>Redwood.js: Bringing full-stack to the Jamstack</h5><p>The new <a target="_blank" rel="noopener noreferrer" href="https://redwoodjs.com/">RedwoodJS</a> framework by GitHub co-founder <a target="_blank" rel="noopener noreferrer" href="https://twitter.com/mojombo">Tom Preston-Werner</a> seeks to become the "Ruby on Rails" equivalent for Node.js. RedwoodJS is based on React and GraphQL and comes with a baked-in deployment model for serverless functions.</p><h5 id="blitzjs-the-fullstack-react-framework"><a href="#blitzjs-the-fullstack-react-framework" aria-label="blitzjs the fullstack react framework permalink"></a>Blitz.js: The Fullstack React Framework</h5><p>Another framework with increasing anticipation and excitement in the community is <a target="_blank" rel="noopener noreferrer" href="http://blitzjs.com/">Blitz.js</a>. Blitz is build on top of Next.js and takes a fundamentally different approach compared to Redwood. Its goal is to completely eliminate the API server and <a target="_blank" rel="noopener noreferrer" href="https://github.com/blitz-js/blitz/blob/canary/rfc-docs/01-architecture.md#introduction">"bring back the simplicity of server rendered frameworks"</a>.</p><h5 id="nexus-a-delightful-graphql-application-framework"><a href="#nexus-a-delightful-graphql-application-framework" aria-label="nexus a delightful graphql application framework permalink"></a>Nexus: A delightful GraphQL application framework</h5><p>At Prisma, we're huge fans of GraphQL and believe in its bright future. That's why we founded the <a target="_blank" rel="noopener noreferrer" href="https://github.com/prisma-labs/">Prisma Labs</a> team which dedicates its time to work on open source tools in the GraphQL ecosystem.</p><p>It is currently focused on building <a target="_blank" rel="noopener noreferrer" href="https://www.nexusjs.org/#/">Nexus</a>, a delightful application framework for developing GraphQL servers. As opposed to RedwoodJS, Nexus is a <em>backend-only</em> GraphQL framework and has no opinions on how you access the GraphQL API from the frontend.</p><h3 id="whats-next-for-prisma"><a href="#whats-next-for-prisma" aria-label="whats next for prisma permalink"></a>What's next for Prisma</h3><h4 id="database-migrations-with-prisma-migrate"><a href="#database-migrations-with-prisma-migrate" aria-label="database migrations with prisma migrate permalink"></a>Database migrations with Prisma Migrate</h4><p>Database migrations are a common pain point for many developers! Especially with applications running in production, it is often unclear what the best approach is to perform schema changes (e.g. in CI/CD environments). Many developers resort to manual migrations or custom scripts, making the process brittle and error-prone.</p><p><a href="https://www.prisma.io/docs/reference/tools-and-interfaces/prisma-migrate">Prisma Migrate</a> is our solution to this problem. Prisma Migrate lets developers map the declarative <a href="https://www.prisma.io/docs/reference/tools-and-interfaces/prisma-schema">Prisma schema</a> to their database. Under the hood, Prisma Migrate generates the required SQL statements to perform the migration.</p><blockquote><p><strong>Note</strong>: Prisma Migrate is currently in an experimental state and should not be used in production environments.</p></blockquote><h4 id="prisma-studio-a-visual-editor-for-your-database-workflows"><a href="#prisma-studio-a-visual-editor-for-your-database-workflows" aria-label="prisma studio a visual editor for your database workflows permalink"></a>Prisma Studio: A visual editor for your database workflows</h4><p><a href="https://www.prisma.io/docs/reference/tools-and-interfaces/prisma-studio">Prisma Studio</a> is your visual companion for various database workflows. It provides a modern GUI that lets you view and edit the data in your database. You can switch between the <em>table</em> and the <em>tree</em> view, the latter is especially convenient to drill deeply into nested data (explore the two views using the tabs below or try out the <a target="_blank" rel="noopener noreferrer" href="https://prisma.studio/">online demo</a>).</p><div><p><span><img src="https://imgur.com/Fc7BweP.png"></span></p></div><blockquote><p><strong>Note</strong>: Prisma Studio is currently in an experimental state and should not be used in production environments. .</p></blockquote><h4 id="beyond-nodejs--typescript-prisma-client-in-other-languages"><a href="#beyond-nodejs--typescript-prisma-client-in-other-languages" aria-label="beyond nodejs  typescript prisma client in other languages permalink"></a>Beyond Node.js &amp; TypeScript: Prisma Client in other languages</h4><p>Prisma Client is a thin, language-specific layer that delegates the heavy-lifting of query planning and execution to Prisma's <a href="https://www.prisma.io/docs/reference/tools-and-interfaces/prisma-client/query-engine">query engine</a>. The query engine is <a target="_blank" rel="noopener noreferrer" href="https://github.com/prisma/prisma-engines">written in Rust</a> and runs as a standalone process alongside your main application.</p><p>This architecture enables us to expand Prisma Client to other languages and bring its benefits to developers beyond the Node.js community. We are already working on <strong>Prisma Client in Go</strong> with a first <a target="_blank" rel="noopener noreferrer" href="https://github.com/prisma/prisma-client-go">alpha version</a> ready to try out!</p><h4 id="supporting-a-broad-spectrum-of-databases-and-other-data-sources"><a href="#supporting-a-broad-spectrum-of-databases-and-other-data-sources" aria-label="supporting a broad spectrum of databases and other data sources permalink"></a>Supporting a broad spectrum of databases and other data sources</h4><p>Prisma is designed in a way that it can potentially connect to <em>any</em> existing data source as long as there is the right <em>connector</em> for it!</p><p>As of today, we've built connectors for PostgreSQL, MySQL and SQLite. A <a target="_blank" rel="noopener noreferrer" href="https://github.com/prisma/prisma/issues/1277">connector for MongoDB</a> is already in the works and more are planned for the future.</p><p><span><img src="https://imgur.com/PQSljF7.png"></span></p><h4 id="building-commercial-services-to-sustain-the-oss-tools"><a href="#building-commercial-services-to-sustain-the-oss-tools" aria-label="building commercial services to sustain the oss tools permalink"></a>Building commercial services to sustain the OSS tools</h4><p>We are commited to building world-class open-source tools to solve common database problems of application developers. To be able to sustain our open-source work, we're planning to build commercial services that will enable development teams and organizations to collaborate better in projects that are using Prisma.</p><blockquote><p><strong>Note</strong>: The plans for commercial services do not affect the open-source tools we are building, those will remain free forever.</p></blockquote><hr><p>We are incredibly grateful for everyone who has accompanied us on our journey! It is fantastic to see our lively community on <a target="_blank" rel="noopener noreferrer" href="https://slack.prisma.io/">Slack</a>, <a target="_blank" rel="noopener noreferrer" href="https://github.com/prisma/prisma">GitHub</a>, <a target="_blank" rel="noopener noreferrer" href="https://twitter.com/search?q=%40prisma&amp;src=typed_query&amp;f=live">Twitter</a> and a lot of other channels where folks are chatting about Prisma and helping each other out!</p><h4 id="join-us-at-prisma-day"><a href="#join-us-at-prisma-day" aria-label="join us at prisma day permalink"></a>Join us at Prisma Day</h4><p>If you've become …</p></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.prisma.io/blog/prisma-raises-series-a-saks1zr7kip6">https://www.prisma.io/blog/prisma-raises-series-a-saks1zr7kip6</a></em></p>]]>
            </description>
            <link>https://www.prisma.io/blog/prisma-raises-series-a-saks1zr7kip6</link>
            <guid isPermaLink="false">hacker-news-small-sites-23651605</guid>
            <pubDate>Fri, 26 Jun 2020 13:17:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Taking Theatre Online with WebGL and WebRTC]]>
            </title>
            <description>
<![CDATA[
Score 51 | Comments 10 (<a href="https://news.ycombinator.com/item?id=23651117">thread link</a>) | @seacaster
<br/>
June 26, 2020 | https://chrisuehlinger.com/blog/2020/06/16/unshattering-the-audience-building-theatre-on-the-web-in-2020/ | <a href="https://web.archive.org/web/*/https://chrisuehlinger.com/blog/2020/06/16/unshattering-the-audience-building-theatre-on-the-web-in-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><em>[<strong>Ed. Note:</strong> This post contains a promotion! It basically *is* a promotion for my current online interactive show: Shattered Space.]</em></p>

<p><em>[But I’ve also got a lot of cool technical stuff to tell you about, so stick around and if this sounds interesting feel free to <a href="https://shatteredspace.live/" target="_blank">buy a ticket here</a>!]</em></p>

<h2 id="table-of-contents">Table of Contents</h2>

<ul>
  <li><a href="#intro">Intro</a></li>
  <li><a href="#other-peoples-computers">Other People’s Computers</a></li>
  <li><a href="#basic-platform-overview">Basic Platform Overview</a></li>
  <li>WebRTC/Janus
    <ul>
      <li><a href="#webrtc-and-janus">WebRTC and Janus</a></li>
      <li><a href="#webrtc-and-redux">WebRTC and Redux</a></li>
      <li><a href="#acquiring-media-devices">Acquiring Media Devices</a></li>
    </ul>
  </li>
  <li>WebGL/three.js
    <ul>
      <li><a href="#threejs-and-offscreencanvas">three.js and OffscreenCanvas</a></li>
      <li><a href="#threejs-and-memory-management">three.js and Memory Management</a></li>
    </ul>
  </li>
  <li><a href="#detecting-and-solving-issues-remotely">Detecting and Solving Issues Remotely</a></li>
  <li><a href="#come-see-shattered-space">Come See Shattered Space!</a></li>
</ul>

<h2 id="intro">Intro</h2>

<p>Safe to say that the past couple months have gone a lot different than many of us were expecting. In early March, as quarantine was starting and all of my projection design gigs were being cancelled, I hit up a couple close friends about building a non-linear theatre experience entirely online. A lot of folks have been trying to perform plays on Zoom (and have found a lot of interesting and clever ways of working with that medium), but I felt like we could make something really unique if we built our own custom video conferencing app.</p>

<p><img src="https://chrisuehlinger.com/images/shattered/initial-google-doc.png">
<strong>The Google Doc that started it all</strong></p>

<p>Crazy? It definitely would’ve been 10 years ago. But advances in the web platform (as well as the quality of cameras and hardware in mobile devices) took this down into the realm of “possible-if-slightly-quixotic”.</p>

<p>Three months later, we’ve done it: Shattered Space is a piece of interactive theatre about a binary star system whose twin stars (“The Mothers”) have disappeared. You and your fellow audience members are Star Jockeys, and have been conscripted to fly around in spaceships to get to know the denizens of the Matra System and see what you can do to help.</p>

<p><iframe src="https://www.youtube.com/embed/iifZPEHJM6c" frameborder="0" allowfullscreen=""></iframe></p>
<p><strong>Here’s a trailer if you want a better idea of what’s going on</strong></p>

<p>If you watched that trailer, you’ve probably figured out that this show involved 3D graphics (WebGL), videoconferencing (WebRTC) and perhaps also some music and audio processing (Web Audio). These were all technologies that I’d worked with on some level in the past, but this show required me to think about them completely differently. All because of the following central problem:</p>

<h2 id="other-peoples-computers">Other People’s Computers</h2>

<p><iframe src="https://www.youtube.com/embed/nGt8w9RbhvY" frameborder="0" allowfullscreen=""></iframe></p>
<p><strong>This WebRTC-based monitoring system allowed the backstage band to see the stage in real time and take cues from actors. The onstage portal was rendered with WebGL. (<em>Welcome to Shakesville</em>, Baltimore Rock Opera Society 2019)</strong></p>

<p>I’ve used WebGL and WebRTC to build projection/video effects for a number of shows the past couple years, but in every case I was writing code that would only run on <strong>my</strong> computer. If I ran into a device-specific bug that affected my computer (or my iPhone, or my squad of Raspberry Pis) I had all the time and access I needed to either debug it or come up with a workaround. Not this time.</p>

<p>If someone pays us $15, receives the login link via email, tries to open it on a cheap 2014 laptop and it can’t load without crashing, that’s a refund. We weren’t just messing around with advanced web features, we needed to deploy them in the most battle-hardened and resilient way possible, while also capturing just enough data and logs to pinpoint who was having problems and ideally solve them before the show started.</p>

<p>This meant going beyond the kinds of code you see in introductory tutorials and really digging into how these APIs deal with memory management, how they respond to connection issues, how they can fail, and how to tweak things at runtime to ensure that framerates stay high and dropped packets are few. I learned a lot about productizing these features, and I’d like to share as much of that as I can, but first let’s talk basics.</p>

<h2 id="basic-platform-overview">Basic Platform Overview</h2>

<p><img src="https://chrisuehlinger.com/images/shattered/screenshots/ship-in-flight.png">
<strong>A group of attendees interacting with a character in the show</strong></p>

<p>Attendees of Shattered Space are broken up into 6 groups of 5. Each group is assigned to a “ship” that flies around the system, and they interact with the characters in the show as a group. Attendees have the options to mute their microphone and turn off their camera if they wish (there is a text chat on the side they can use to communicate) although we encourage people to keep them on if they feel comfortable.</p>

<p>The Shattered Space platform consists of:</p>

<ul>
  <li>An ExpressJS service that keeps track of the overall state of the show.</li>
  <li>7 Janus WebRTC media servers. One for each ship and a extra for broadcasting a livestream of the ending scene.</li>
  <li>The Admin App, a React/Redux webapp that handles scheduling shows, keeping track of which actor is talking to which ship, and has real-time dashboards with logs of client-side errors and connectivity issues.</li>
  <li>The Actor App, a React/Redux webapp used by actors to interact with the audience via audio, video, text, and the giving/taking of items from a ship’s inventory.</li>
  <li>The Attendee App, a React/Redux webapp where attendees view the show and interact with the actors and each other via audio, video and text.</li>
  <li>The Host App, used by me to perform the motion-captured ending scene.</li>
</ul>

<p>When I say that the Show Service “keeps track of the overall state of the show”, I mean <em>all</em> of the state. Most of the Redux actions (across all 3 apps) don’t mutate the state of the reducers, but instead hit an endpoint on the Show Service that changes the state kept in the database, then fetches <em>all</em> of the state from the database and sends it to <em>all</em> of the users as a WebSocket message which then overwrites most of the reducers’ state. This way, no client can end up with “orphan state” as a result of optimistically updating their reducer before their API call returns, and fetching the updated state for <em>all</em> users can be done with a single database call (this refresh-all-state-for-everyone method is debounced and implements a queueing mechanism to ensure we don’t have too many database calls at once).</p>

<p><img src="https://chrisuehlinger.com/images/shattered/redux-oops.jpg">
<strong>I basically took Dan Abramov’s simple and elegant system and did this to it. <br> Sorry Dan.</strong></p>

<p>(I’d note that this architecture emerged sort of organicly and there are probably cleaner or more optimal ways of achieving this “Redux-but-the-server-is-the-reducer” architecture. I’m open to feedback on whether something like Relay or Meteor would be a better fit for a V2)</p>

<p><img src="https://chrisuehlinger.com/images/shattered/screenshots/admin-show-online.png"></p>

<p><img src="https://chrisuehlinger.com/images/shattered/screenshots/actor-screen.png">
<strong>The Admin app allows us to see who’s logged on and what’s happening in the show</strong></p>

<p>Of the 3 React/Redux apps, the Admin App uses the least of these shiny web technologies, and is pretty much just a dashboard for displaying what’s in the database. As admins, we can see which actors and attendees have logged on, which ships are currently visiting which actors, we can move attendees between ships if need be, and we can see a list of errors the actors and attendees have encountered (more on this later).</p>

<p><img src="https://chrisuehlinger.com/images/shattered/screenshots/actor-app-normal.png">
<strong>The actor app allows performers to engage with the audience and view information about the ship they’re talking to</strong></p>

<p>The Actor App is more sophisticated, since it needs to handle WebRTC and media device concerns. It also has 3 modes: Normal, Mobile (used automatically if the window has a dimension less than 500px) and Headless (used if the querystring variable <code>headless</code> is set to <code>true</code>. The Normal mode is used by about half of the actors, and has the ability for them to see themselves, configure their audio/video devices, change any info about their user, character or planet, and view information about the ships they’re talking to (their chat, inventory, history of previous places, etc.).</p>

<p><img src="https://chrisuehlinger.com/images/shattered/screenshots/actor-app-mobile.jpg">
<img src="https://chrisuehlinger.com/images/shattered/screenshots/actor-app-headless.png">
<strong>The mobile and headless modes of the actor app give our actors flexibility to use whatever devices they have available</strong></p>

<p>The Mobile mode uses a tab-based layout to try and accomplish all the same goals, but since only one tab can be on the screen at a time, it’s a bit of a pain to use on its own. We’ve got Headless mode, which doesn’t do any of the audio/video streaming, but shows all the information about the current ship and can run on any laptop. Many actors have opted for using the Mobile mode (since their phone has a good camera) but keeping Headless mode open on an old laptop to make it easier to use the other features.</p>

<p><img src="https://chrisuehlinger.com/images/shattered/screenshots/ship-in-flight.png">
<strong>A group of attendees interacting with a character in the show</strong></p>

<p>The Attendee app is about as complex as the actor app, but doesn’t have a Headless mode (which is really just a power-user feature for actors). This app has multiple screens corresponding to the different phases of the show:</p>

<ul>
  <li>Preshow - A lobby screen where attendees can meet the shipmates they’ll be flying with</li>
  <li>Intro - A tutorial video</li>
  <li>Freeplay - The bulk of the show, where attendees alternate between interacting with characters and choosing their next destination from the Navigation Screen</li>
  <li>Ending - A livestreamed 3D ending scene</li>
  <li>Ended - This just redirects attendees out of the app to <a href="https://shatteredspace.live/program.html" target="_blank">a static page with our casts’ bios</a>.</li>
</ul>

<p><img src="https://chrisuehlinger.com/images/shattered/screenshots/host-app.jpg">
<strong>My setup for performing the motion capture at the end of the show</strong></p>

<p>At the end of the show, I perform a scene as Colonel Panic, the AI commander of the Star Jockeys. In this scene I go around to each ship and review the items they’ve managed to collect. Then a “resolution” happens that I won’t spoil here.</p>

<p>This performance is rendered on my desktop PC (Intel 8700K + RTX 2080TI) with a special version of the Actor app that I’ve built just for this purpose. The three.js scene here involves at least 7 huge models with MeshPhysicalMaterials and a dozen moving PointLights, so rather than rendering on attendees’ computers, I render it on mine and stream it to them using an <a href="https://www.elgato.com/en/gaming/cam-link-4k" target="_blank">Elgato Camlink 4K</a>, ffmpeg and the Janus (explained below) <a href="https://janus.conf.meetecho.com/docs/streaming.html" target="_blank">Streaming plugin</a>.</p>

<p>The motion capture work is done by taking a modified version of Apple’s <a href="https://developer.apple.com/documentation/arkit/tracking_and_visualizing_faces" target="_blank">TrackingAndVisualizingFaces</a> example from the ARKit docs and having it send each frame of mocap data over WebSockets to the server, which then forwards them to the Host app. It’s amazing that this works with sub-100ms latency, but it does.</p>

<p>I’m planning on open-sourcing all of this when the show is done, but I’d want to purge the git history in case there are any secrets lying around, and I’d warn any interested spelunkers that it will be more of an …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://chrisuehlinger.com/blog/2020/06/16/unshattering-the-audience-building-theatre-on-the-web-in-2020/">https://chrisuehlinger.com/blog/2020/06/16/unshattering-the-audience-building-theatre-on-the-web-in-2020/</a></em></p>]]>
            </description>
            <link>https://chrisuehlinger.com/blog/2020/06/16/unshattering-the-audience-building-theatre-on-the-web-in-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23651117</guid>
            <pubDate>Fri, 26 Jun 2020 12:17:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Working on iPad]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 96 (<a href="https://news.ycombinator.com/item?id=23650763">thread link</a>) | @tosh
<br/>
June 26, 2020 | https://www.notion.so/vercel/Working-on-iPad-ccefea4f9e06455da169c97b3fe054c1 | <a href="https://web.archive.org/web/*/https://www.notion.so/vercel/Working-on-iPad-ccefea4f9e06455da169c97b3fe054c1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/vercel/Working-on-iPad-ccefea4f9e06455da169c97b3fe054c1</link>
            <guid isPermaLink="false">hacker-news-small-sites-23650763</guid>
            <pubDate>Fri, 26 Jun 2020 11:21:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Numerical Linear Algebra for Programmers]]>
            </title>
            <description>
<![CDATA[
Score 211 | Comments 74 (<a href="https://news.ycombinator.com/item?id=23650640">thread link</a>) | @dragandj
<br/>
June 26, 2020 | https://aiprobook.com/numerical-linear-algebra-for-programmers?release=0.9.0 | <a href="https://web.archive.org/web/*/https://aiprobook.com/numerical-linear-algebra-for-programmers?release=0.9.0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="lafp-why">
        
        
        
        <p>
          <h4>basically…</h4>



<h4>interactive &amp; dynamic</h4>
<h4>a direct link from theory to implementation</h4>
<h4>incredible performance</h4>
<h4>Intel &amp; AMD CPUs (MKL)</h4>
<h4>Nvidia GPUs (CUDA and cuBLAS)</h4>
<h4>AMD GPUs (yes, OpenCL too!)</h4>
<h4>Clojure (it’s magic!)</h4>
<h4>Java Virtual Machine (without Java boilerplate!)</h4>
<h4>complete source code</h4>
<h4>beautiful typesetting (see the sample chapters below)</h4>

        </p>
      </div><div id="lafp-interactive">
        
        
        
        <p>
          

<h4>see the result of executing each line</h4>
<h4>experiment in a live environment</h4>

<h4>no C++ build hell</h4>

<h3>no C++ syntax hell!</h3>

<h4>Java Virtual Machine, but without Java boilerplate</h4>

<h4>Clojure, the nicest language on earth :-)</h4>



        </p>
      </div><div id="lafp-fast">
        
        
        
        <p>
          

<h3>yet, high-level (you don’t touch C++)</h3>

<h2>CPUs</h2>

<h4>learn Intel MKL</h4>

<h2>GPUs</h2>

<h4>learn CUDA &amp; cuBLAS</h4>
<h4>learn OpenCL</h4>
<h4>all hardware: Nvidia, AMD, Intel</h4>

<h3>you don’t touch C++!!!</h3>

        </p>
      </div><div id="lafp-contents">
        
        
        
        <div>
          <h2>Table of Contents</h2>

<h3>Part 1: Getting Started (SOON)</h3>

<h4>Hello world (SOON)</h4>

<h4>Vectors, matrices, and linear algebra API (SOON)</h4>

<h4>Polymorphic acceleration (SOON)</h4>

<h3>Part 2: Linear algebra refresher (<a href="https://www.patreon.com/linear_algebra?ref=20">AVAILABLE</a>)</h3>

<h4>Vector spaces (<a href="https://www.patreon.com/linear_algebra?ref=21">AVAILABLE</a>)</h4>

<h4>Eigenvalues and eigenvectors (<a href="https://www.patreon.com/linear_algebra?ref=22">AVAILABLE</a>)</h4>

<h4>Matrix transformations (<a href="https://www.patreon.com/linear_algebra?ref=23">AVAILABLE</a>)</h4>

<h4>Linear transformations (<a href="https://www.patreon.com/linear_algebra?ref=24">AVAILABLE</a>)</h4>

<h3>Part 3: High performance matrix computations (<a href="https://www.patreon.com/linear_algebra?ref=40">AVAILABLE</a>)</h3>

<h4>Using matrices efficiently (<a href="https://www.patreon.com/linear_algebra?ref=41">AVAILABLE</a>)</h4>

<h4>Linear systems and factorization (<a href="https://www.patreon.com/linear_algebra?ref=42">AVAILABLE</a>)</h4>

<h4>Singular value decomposition (SVD) (<a href="https://www.patreon.com/linear_algebra?ref=43">AVAILABLE</a>)</h4>

<h4>Orthogonalization and least squares (<a href="https://www.patreon.com/linear_algebra?ref=44">AVAILABLE</a>)</h4>

<h3>Part 4: GPU acceleration</h3>

<h4>GPU computing crash course</h4>

<h4>CUDA and cuBLAS on Nvidia GPUs</h4>

<h4>OpenCL and CLBlast on AMD GPUs</h4>

<h3>Part 5: In practice (<a href="https://www.patreon.com/linear_algebra?ref=50">IN PROGRESS</a>)</h3>

<h4>Generating random matrices (<a href="https://www.patreon.com/linear_algebra?ref=51">AVAILABLE</a>)</h4>

<h4>Broadcasting (<a href="https://www.patreon.com/linear_algebra?ref=52">AVAILABLE</a>)</h4>

<h4>Mean, variance, and correlation (<a href="https://www.patreon.com/linear_algebra?ref=53">AVAILABLE</a>)</h4>

<h4>Principal component analysis (PCA) (<a href="https://www.patreon.com/linear_algebra?ref=54">AVAILABLE</a>)</h4>

<h3>Appendix</h3>

<h4>Setting up the environment and the JVM</h4>

        </div>
      </div></div>]]>
            </description>
            <link>https://aiprobook.com/numerical-linear-algebra-for-programmers?release=0.9.0</link>
            <guid isPermaLink="false">hacker-news-small-sites-23650640</guid>
            <pubDate>Fri, 26 Jun 2020 11:00:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Big Sur on Unsupported Macs]]>
            </title>
            <description>
<![CDATA[
Score 139 | Comments 115 (<a href="https://news.ycombinator.com/item?id=23650031">thread link</a>) | @todsacerdoti
<br/>
June 26, 2020 | https://parrotgeek.com/bigsur/ | <a href="https://web.archive.org/web/*/https://parrotgeek.com/bigsur/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span face="Helvetica, Arial, sans-serif"><b><u>Compatibility
            status</u></b> <br>
        Note: these instructions only support computers<b> </b>that
        have a Metal-capable GPU <i>and</i> native APFS boot support.<br>
      </span></p><div>
      <tbody>
        <tr>
          <td><span face="Helvetica,
              Arial, sans-serif"><b>Model Identifier</b><br>
            </span></td>
          <td><span face="Helvetica,
              Arial, sans-serif"><b>Human-Readable Name</b><br>
            </span></td>
          <td><span face="Helvetica,
              Arial, sans-serif"><b>Status</b><br>
            </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">MacBookAir5,1<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">MacBook









              Air (11-inch, Mid 2012)<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif"><span face="Helvetica, Arial, sans-serif">Everything except
                Wi-Fi works</span> </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">MacBookAir5,2<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">MacBook









              Air (13-inch, Mid 2012)<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif"><span face="Helvetica, Arial, sans-serif">Everything except
                Wi-Fi works</span> </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">MacBookPro9,1<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">MacBook









              Pro (15-inch, Mid 2012)<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif"><span face="Helvetica, Arial, sans-serif">Everything except
                Wi-Fi works</span> </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">MacBookPro9,2<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">MacBook









              Pro (13-inch, Mid 2012)<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif"><span face="Helvetica, Arial, sans-serif">Everything except
                Wi-Fi works</span> </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">MacBookPro10,1<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">MacBook









              Pro (Retina, 15-inch, Mid 2012)<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif"><span face="Helvetica, Arial, sans-serif">Everything except
                Wi-Fi works</span> </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">MacBookPro10,2<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">MacBook









              Pro (Retina, 13-inch, Early 2013)<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif"><span face="Helvetica, Arial, sans-serif">Everything except
                Wi-Fi works</span> </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">Macmini6,1<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">Mac
              mini (Late 2012)<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">Everything









              except Wi-Fi works<br>
            </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">Macmini6,2<br>
            </span></td>
          <td>
            <meta charset="utf-8">
            <span face="Helvetica, Arial, sans-serif">Mac mini (Late
              2012) quad-core<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif"><span face="Helvetica, Arial, sans-serif">Everything except
                Wi-Fi works</span> </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">iMac13,1<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">iMac









              (21.5-inch, Late 2012)<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif"><span face="Helvetica, Arial, sans-serif">Everything except
                Wi-Fi works</span> </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">iMac13,2<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">iMac









              (27-inch, Late 2012)<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif"><span face="Helvetica, Arial, sans-serif">Everything except
                Wi-Fi works</span> </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">iMac14,1<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">iMac









              (21.5-inch, Late 2013) integrated GPU<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">Everything






              works<br>
            </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">iMac14,2<br>
            </span></td>
          <td>
            <meta charset="utf-8">
            <span face="Helvetica, Arial, sans-serif">iMac (27-inch,
              Late 2013)<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">Everything






              works<br>
            </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">iMac14,3<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">iMac









              (21.5-inch, Late 2013) discrete GPU</span><br>
          </td>
          <td><span face="Helvetica, Arial, sans-serif">Everything






              works<br>
            </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">MacPro5,1<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">Mac
              Pro (Mid 2010/Mid 2012)<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">WiFi


              does not work; sleep issues<br>
            </span></td>
        </tr>
      </tbody>
    </div><p><span face="Helvetica, Arial, sans-serif">Special thanks to
        ASentientBot for the method of removing the installer
        compatibility check ("hax.dylib").</span><br>
    </p></div>]]>
            </description>
            <link>https://parrotgeek.com/bigsur/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23650031</guid>
            <pubDate>Fri, 26 Jun 2020 08:56:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A multiplayer board game in Rust and WebAssembly]]>
            </title>
            <description>
<![CDATA[
Score 121 | Comments 31 (<a href="https://news.ycombinator.com/item?id=23649369">thread link</a>) | @lukastyrychtr
<br/>
June 25, 2020 | http://www.mattkeeter.com/projects/pont/ | <a href="https://web.archive.org/web/*/http://www.mattkeeter.com/projects/pont/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<!-- End header -->


<h2>A multiplayer board game in Rust and WebAssembly</h2>
<p><a href="https://pont.mattkeeter.com/">
<img src="http://www.mattkeeter.com/projects/pont/screenshot.png">
</a></p><p>
<a href="https://pont.mattkeeter.com/">Click to play!</a>
</p>
<p><em>Pont</em> is an online implementation of
<a href="https://en.wikipedia.org/wiki/Qwirkle">Qwirkle, a board game by Mindware Games</a>.
It was written for my parents,
so they could play with friends and family during the COVID-19 stay-at-home era.</p>
<p>Play is split into <strong>rooms</strong>,
which are identified by a three-word code
(<code>size moody shape</code> in the image above).
Within each room,
the game distributes pieces,
enforces the game rules,
and provides a local chat window.</p>
<p>Unusually, it's a web-based multiplayer game <strong>without any Javascript</strong>:
both the client and server are written in <a href="https://www.rust-lang.org/">Rust</a>,
which is compiled into <a href="https://webassembly.org/">WebAssembly</a> to run on the browser.
(There's a Javascript shim to load the WebAssembly module, but I didn't have to write it myself)</p>
<h2>Architecture</h2>
<p>Keep in mind, I'm <em>not a web developer</em>,
so this is probably a weird <a href="https://en.wikipedia.org/wiki/Outsider_art">outsider architecture</a>
for web applications.
Here's what the system looks like:</p>
<p><img src="http://www.mattkeeter.com/projects/pont/diagram.svg" alt="Diagram"></p>
<p>The system uses <a href="https://letsencrypt.org/">Let's Encrypt</a> for certificates:
both static assets and WebSocket communication are encrypted
between the client and the server.
The game server does not communicate securely with the NGINX proxy,
but if anyone is on the server watching,
I've got bigger problems.</p>
<p>The <code>wasm</code> bundle and <code>pont-server</code> executable are both
written in Rust and managed in the <a href="https://github.com/mkeeter/pont"><code>pont</code> repository</a>.
They both depend on <a href="https://github.com/mkeeter/pont/blob/master/pont-common/src/lib.rs"><code>pont-common</code></a>,
which defines basic types and logic for gameplay
(e.g. so that both the client and server can check whether a move is legal).</p>
<p>The client and server communicate via <a href="https://developer.mozilla.org/en-US/docs/Web/API/WebSockets_API">WebSockets</a>.
Messages are strongly typed as an <a href="https://github.com/mkeeter/pont/blob/master/pont-common/src/lib.rs#L7-L48"><code>enum</code> in <code>pont-common</code></a>,
serialized using <a href="https://serde.rs/">Serde</a>,
and packed into <a href="https://github.com/servo/bincode">bincode</a>
to be sent as binary WebSocket messages.</p>
<h2>Server</h2>
<p>The game server using async Rust,
which was... exciting:</p>
<ul>
<li>There's a <a href="https://www.reddit.com/r/rust/comments/ej649l/a_summary_of_the_current_state_of_async_rust/fcw16a9/">"very polite cold war"</a>
going on between the two major (incompatible?) runtimes,
with packages that only work in one or the other</li>
<li>An <a href="https://docs.rs/futures/0.3.5/futures/channel/mpsc/index.html">infinite</a>
<a href="https://docs.rs/tokio/0.2.21/tokio/sync/mpsc/fn.channel.html">supply</a>
<a href="https://docs.rs/crossbeam-channel/0.4.2/crossbeam_channel/">of</a>
<a href="https://docs.rs/futures/0.3.5/futures/channel/oneshot/fn.channel.html">options</a>
<a href="https://docs.rs/futures-channel-preview/0.3.0-alpha.19/futures_channel/index.html">for</a>
<a href="https://doc.rust-lang.org/std/sync/mpsc/index.html">channels</a></li>
<li>General confusion between <a href="https://docs.rs/futures/0.3.5/futures/"><code>futures</code></a>,
<a href="https://doc.rust-lang.org/std/future/index.html"><code>std::Future</code></a>, and
<a href="https://docs.rs/futures-util/0.3.5/futures_util/"><code>futures_util</code></a>
(exacerbated by the fact that Googling for things will land you
into a random version of the docs)</li>
<li>Error messages that rival C++ in incomprehensibility</li>
</ul>
<p>To be fair, the Rust <code>async</code> ecosystem is relatively new,
so most of this can be ascribed to growing pains;
I'm sure that the ergonomics and library situation
will improve over time.</p>
<p>I ended up using the <a href="https://github.com/stjepang/smol"><code>smol</code> runtime</a>
because it's got relatively few dependencies,
and I appreciated that it wasn't trying to own the entire async universe
(unlike Tokio and <code>async-std</code>).</p>
<p>After getting over those hurdles,
the server architecture is relatively straightforward.
A bunch of independent tasks run asynchronously,
communicating to the outside world via WebSockets
and internally via <a href="https://docs.rs/futures/0.3.5/futures/channel/mpsc/fn.unbounded.html">unbounded MPSC queues</a>.</p>
<p>Here's an example of the server running one game (with two players),
plus one new client who has just connected.  Each rectangle
represents an async task:</p>
<p><img src="http://www.mattkeeter.com/projects/pont/server.svg" alt="Server"></p>
<p>The system has <code>2 + n_players + n_games</code> async tasks running at one time:</p>
<ul>
<li>A top-level task which accepts incoming connections.</li>
<li>A top-level task which logs the number of active rooms, once per minute</li>
<li>One async task per client connection, which passes messages between the WebSocket connection
and the application's internal queues.</li>
<li>One async task per room, which handles game state</li>
</ul>
<p>These tasks each map to a <a href="https://docs.rs/smol/0.1.10/smol/struct.Task.html"><code>smol::Task</code></a>.
(As a small optimization,
the first player's <code>Task</code> handles both the player communication
and running the room, which is why they're both blue in the diagram above)</p>
<p>The server compiles down to a 5 MB static binary.
The whole system is hosted on the smallest VM offered by
<a href="https://www.digitalocean.com/">Digital Ocean</a>,
which is a $5/month machine.
I'm looking forward to the inevitable <a href="https://news.ycombinator.com/">Hacker News</a>
<a href="https://en.wikipedia.org/wiki/Slashdot_effect">DDOS</a>,
where I can see how well it scales!</p>
<h2>Client</h2>
<p>The client is <a href="https://github.com/mkeeter/pont/blob/master/pont-client/src/lib.rs">2000 lines of framework-less excitement</a>.
It uses a
<a href="https://en.wikipedia.org/wiki/Finite-state_machine">state machine pattern</a>
to represent the flow of the game,
accepting messages from the server
and updating the state accordingly:
for example, top-level state flows from
<code>Connecting</code> to <code>CreateOrJoin</code> to <code>Playing</code>.</p>
<p>The game board is represented as an SVG;
everything else is standard HTML elements.
In fact, the whole UI is pre-constructed in
<a href="https://github.com/mkeeter/pont/blob/master/pont-client/deploy/index.html"><code>index.html</code></a>
and revealed on demand.</p>
<p>The client has a bit of polish:
Pieces are animated as they move around the board,
and there's an optional color-blind mode,
which adds corner markings to indicate color.</p>
<p><img src="http://www.mattkeeter.com/projects/pont/cb.png" alt="Color-blind mode"></p>
<p>I use direct DOM manipulation
(from the <a href="https://rustwasm.github.io/wasm-bindgen/api/web_sys/"><code>web-sys</code></a> crate)
to control the system.
This exercise has left me appreciating the usefulness of virtual DOMs,
but I didn't want to bring in the complexity of a framework.
(Is there a Rust + <code>wasm</code> version of <a href="https://svelte.dev/">Svelte</a> yet?)</p>
<p>For deployment,
I'm using <a href="https://rustwasm.github.io/wasm-pack/"><code>wasm-pack</code></a>
and serving the resulting <code>wasm</code> blob from the same server as the other static assets.</p>
<p>The main challenges on the client side were
(of course) dealing with cross-browser compatibility:
Safari, in particular, supports fewer features
and has funky handling of touch events.</p>
<h2>Conclusions</h2>
<p>After a bit of a learning curve,
this all worked surprisingly well!</p>
<p>The client side is still a bit messy,
with animations, UI inputs,
and server events all fighting to break the system's invariants.
For example,
there was a nasty bug where dragging the board while
an animation was running could drop the system into an invalid state.</p>
<p>This isn't surprising:
stateful UIs are hard,
which explains the popularity of declarative approaches.
At this point, the client is feature-complete
and hasn't quite collapsed under its own weight,
so I'm not inclined to do any dramatic refactorings.</p>
<p>Rust as a language continues to be great,
despite minor complaints.
I already discussed the async ecosystem above,
and won't dwell on that any further.
On the client side,
there are often impedance mismatches with WebAssembly:
for example, using Rust closures as callbacks
requires
<a href="https://github.com/mkeeter/pont/blob/master/pont-client/src/lib.rs#L1189-L1211">cryptic boilerplate</a>.</p>
<p>Still, with all of the pieces in place,
making changes is pleasantly fast,
and I trust the compiler to check that I haven't broken anything.</p>
<p>I'm particularly happy with the combination of WebSockets, Serde, and bincode:
having both the client and server process a strongly-typed stream of events
makes things easy to reason about.</p>
<h2>Links</h2>
<p><a href="https://pont.mattkeeter.com/">Play the game here</a>, or check out
<a href="https://github.com/mkeeter/pont">the source on Github</a></p>
<p><a href="https://news.ycombinator.com/item?id=23649369">Discussion on Hacker News</a></p>
<p>Questions?  Comments?  <a href="mailto:matt.j.keeter@gmail.com">Send me an email!</a></p>

<!-- Begin footer -->
</div></div>]]>
            </description>
            <link>http://www.mattkeeter.com/projects/pont/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23649369</guid>
            <pubDate>Fri, 26 Jun 2020 06:44:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Re-Stacking the GUI Stack]]>
            </title>
            <description>
<![CDATA[
Score 61 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23649215">thread link</a>) | @todsacerdoti
<br/>
June 25, 2020 | https://genodians.org/nfeske/2020-06-23-gui-stack | <a href="https://web.archive.org/web/*/https://genodians.org/nfeske/2020-06-23-gui-stack">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post">
        <div id="posting">
          <p><a href="https://genodians.org/nfeske/index">
            <img src="https://genodians.org/nfeske/author.png" alt="Norman Feske avatar">
           </a>
          </p>
          
          <p><span>June 23 2020 by
           <a href="https://genodians.org/nfeske/index">Norman Feske</a></span></p>
 <p>
  As I am currently right in the middle of a far-reaching rework of Genode's
  low-level GUI stack, I'd like to share a bit of background behind this work:
  the Why, the What, and the How.
 </p>
 <h4>
 <a name="Current_state"></a>
 Current state</h4>
  <p>
   The current incarnation of Genode's low-level GUI-related interfaces is almost
   identical to the very first version that we originally created in 2006.
   Genode has a very strong asymmetric notion of the
   <a href="https://genode.org/documentation/genode-foundations/20.05/architecture/Recursive_system_structure.html#Client-server_relationship">relationship</a>
   between client and server components. In this relationship, the client depends
   on the server but the server does not depend on the client.
  </p>
  <p>
   At the lowest level, the framebuffer driver and input driver(s) were
   envisioned as servers that provide the <i>Framebuffer</i> and <i>Input</i> session
   interfaces to higher-level GUI components. From our former academic view, this
   felt natural because those drivers <i>provide</i> <i>resources</i> to other components.
   Provide... serve... server! The nitpicker GUI server uses those low-level
   services to implement a higher level service that ultimately allows for the
   multiplexing of graphics and input.
   <a href="https://genode.org/documentation/genode-foundations/20.05/components/Common_session_interfaces.html#Nitpicker_GUI">Nitpicker</a>
   virtualizes the low-level framebuffer and input interfaces while supplementing
   the notions of visible views and input focus. Such a system looks as follows:
  </p>
  <p>
    <img src="https://genodians.org/nfeske/nitpicker_orig.png">
  </p>
  <p>
   The drivers and the nitpicker GUI server are displayed in red because they are
   servers. The GUI applications at the right are nitpicker clients. Nitpicker,
   in turn, is a client of the framebuffer and input drivers.
  </p>
  <p>
   The client interface of the nitpicker GUI server is success story. A few
   <a href="https://genode.org/documentation/release-notes/15.11#GUI_stack">evolutionary tweaks</a>
   notwithstanding, the original design scales up to the windowed working
   environment of Sculpt OS while retaining the tiny complexity of the nitpicker
   GUI server.
  </p>
  <p>
   However, the approach of modelling the framebuffer and input drivers as
   servers is a dead end, for the following reasons.
  </p>
  <ul>
   <li>
    <p>
     Drivers are sometimes extremely complex. When looking at the complexity of
     the Intel framebuffer driver (ported from the Linux kernel) for example, it
     feels foolish to trust that it won't fail. Because the nitpicker GUI server
     depends on the liveliness of the driver, however, the well-being of the
     driver is on the critical path for the entire GUI stack and all GUI
     applications.
    </p>
   </li>
   <li>
    <p>
     It is impossible to transparently restart or replace the driver at runtime
     without also restarting the GUI stack and - transitively - all GUI
     applications. This is because the nitpicker GUI server is connected as a
     client to the drivers. The connections are like a life supply for the GUI
     server. Cutting those would ultimately kill the GUI server.
    </p>
   </li>
   <li>
    <p>
     Adding secondary displays is rather difficult because this would require
     nitpicker to know what framebuffer servers are out there and to request
     multiple framebuffer connections. Adding such a protocol would inflate
     the complexity of nitpicker.
    </p>
   </li>
  </ul>
 <h4>
 <a name="Inverting_interfaces"></a>
 Inverting interfaces</h4>
  <p>
   To overcome these limitations, we must break the dependency of the GUI
   server from the drivers, like illustrated here:
  </p>
  <p>
    <img src="https://genodians.org/nfeske/nitpicker_next.png">
  </p>
  <p>
   In this scenario, the GUI server no longer <i>uses</i> the drivers, but the drivers
   use the GUI server. The relationship is reversed. Only the nitpicker GUI
   server remains red. Of course, the drivers cannot talk to nitpicker GUI
   server via nitpicker's regular client interface. Instead, two new interfaces
   enter the picture:
  </p>
  <div><dl>
   <dt>The <i>Capture</i> session interface</dt>
   <dd>
    <p>
     is like the inverse of the original
     <i>Framebuffer</i> session interface. It allows a client to obtain pixel data
     from the server. From the GUI server's perspective, a framebuffer driver
     is like a frame capturing device - which it is.
    </p>
   </dd>
   <dt>The <i>Event</i> session interface</dt>
   <dd>
    <p>
     is like the inverse of the original
     <i>Input</i> session interface. In contrast to a input session, which allows
     a client to obtain input events, an event session allows a client to
     induce input events. Nitpicker is an event server that consumes the input
     events from the driver(s).
    </p>
   </dd>
  </dl></div>
  <p>
   The benefits of this approach are manifold:
  </p>
  <ul>
   <li>
    <p>
     The low-complexity GUI server remains as the only component that must never
     fail, which makes the GUI stack much more resilient compared to today.
    </p>
   </li>
   <li>
    <p>
     Since the nitpicker GUI server no longer depends on the drivers, it can be
     started before the drivers are running, speeding up the boot time of
     graphical scenarios. In scenarios with rigid power management, we can remove
     the graphics driver - and switch off the graphics device - all while the GUI
     server and all GUI applications stay intact.
    </p>
   </li>
   <li>
    <p>
     Drivers can be restarted anytime. From the perspective of the nitpicker
     GUI server, this looks like a client disconnect and connect. Drivers
     can also be replaced at runtime, e.g., swapping out the VESA and Intel
     drivers.
    </p>
   </li>
   <li>
    <p>
     Connecting more than one driver to the nitpicker GUI server becomes
     conceptually simple. This clears the path towards multi-head support.
    </p>
   </li>
   <li>
    <p>
     The new capture session interface of the nitpicker GUI server would be
     the right hook for implementing screenshot/screencast applications, or a
     remote desktop server.
    </p>
   </li>
   <li>
    <p>
     Analogously to capture devices, input devices can enter and leave the
     system at any time without disruption, which will allow for the fine-grained
     management of USB HID devices. Think of plugging a new HID device to
     your Sculpt system. A new USB device would show up.
     The user can deploy the matching HID driver with the option of routing the
     event session of the driver to the system GUI server. Isn't that wonderful?
    </p>
   </li>
  </ul>
  <p>
   What is the downside? <i>It is a lot of work!</i> This leads us the following
   section.
  </p>
 <h4>
 <a name="The_plan"></a>
 The plan</h4>
  <p>
   Turning the low-level session interfaces upside down is an invasive operation
   that must be carried out in several steps, each yielding an intermediate
   consistent state.
  </p>
  <ol>
   <li>
    <p>
     We start off with some low-risk <b>cosmetic</b> changes, namely the renaming
     of the "Nitpicker" session interface to "Gui" session. The strange
     branding of the session interface after a particular implementation is a
     relic from the early days. This
     <a href="https://github.com/genodelabs/genode/issues/3778">change</a> has already
     entered Genode's master branch.
    </p>
   </li>
   <li>
    <p>
     Consistently use <b>32-bit RGB</b> as pixel format by all drivers and
     applications. This is a long-standing feature request that eliminates
     the need for color-space conversions and generally improves the output
     quality.
     It is quite labor-intensive because it requires me testing many
     different hardware platforms covering the drivers vesa_fb_drv, fb_sdl,
     intel_fb_drv, imx53_fb_drv, imx8_fb_drv, rpi_fb_drv, boot_fb_drv,
     omap4_fb_drv, exynos5_fb_drv.
     This <a href="https://github.com/genodelabs/genode/issues/3784">change</a> has already
     progressed well.
    </p>
   </li>
   <li>
    <p>
     Introducing the new <b>Capture</b> session <b>interface</b>.
    </p>
   </li>
   <li>
    <p>
     Implementing the <b>capture service</b> in the nitpicker GUI server.
    </p>
   </li>
   <li>
    <p>
     Introduce a <b>nitpicker</b> option to choose the framebuffer <b>back end</b> between
     the use of a requested framebuffer session (as done today), the use of a
     capture client for the pixel output, or the use of another GUI server
     (for stacking multiple instance of nitpicker).
    </p>
   </li>
   <li>
    <p>
     Turn "Framebuffer" <b>drivers</b> into "Capture" clients, covering all the
     drivers mentioned above. Shoveling code. Adjusting all existing
     scenarios to use nitpicker's capture service.
    </p>
   </li>
   <li>
    <p>
     <b>Pruning</b> the remaining use of the <b>framebuffer client</b> interface.
     In fact, when done, I want to remove the <tt>Framebuffer::Connection</tt>
     completely. This will require the reworking of the terminal, MESA back end,
     several tests, and the liquid_framebuffer. In the process, I hope to largely
     eliminate the use cases of the nit_fb (now called gui_fb) component so
     that this component can be removed in the end.
    </p>
   </li>
   <li>
    <p>
     <b>Turning</b> a few other <b>framebuffer clients</b> into "Capture" servers, in
     particular test-framebuffer, fb_bench, and test-driver_manager.
    </p>
   </li>
   <li>
    <p>
     <b>Removal</b> of the "Framebuffer" <b>session interface</b>, retaining the interface
     merely as a part of the GUI session.
    </p>
   </li>
   <li>
    <p>
     Introducing the new <b>Event</b> session <b>interface</b> and adding its implementation
     to the nitpicker GUI server.
    </p>
   </li>
   <li>
    <p>
     Adding a new <b>event_filter component</b> taking the place of the input_filter.
    </p>
   </li>
   <li>
    <p>
     With the structural changes done, it would be time for optimizations.
     As a prerequisite for tear-free animations, the <b>frame buffering</b> will be
     moved from the clients into the nitpicker GUI server. At first, this will be
     transparent to most clients. The subsequent removal of client-side buffering
     is second independent step. As another optimization, I plan to go though all
     places that employed the dithering of pixels.
    </p>
   </li>
  </ol>
  <p>
   Of those topics, the rework of the framebuffer drivers is certainly the most
   elaborate one. I'm considering to drop the Exynos5 and OMAP4 drivers.
   Even though I strive for replacing the input session interface by the new
   event session interface, the scope of the task of reworking the input drivers
   is not yet completely tangible to me.
  </p>
          
        </div> <!-- posting -->
      </div></div>]]>
            </description>
            <link>https://genodians.org/nfeske/2020-06-23-gui-stack</link>
            <guid isPermaLink="false">hacker-news-small-sites-23649215</guid>
            <pubDate>Fri, 26 Jun 2020 06:15:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Hitchhiker’s Guide to PlantUML]]>
            </title>
            <description>
<![CDATA[
Score 134 | Comments 24 (<a href="https://news.ycombinator.com/item?id=23648957">thread link</a>) | @bambambazooka
<br/>
June 25, 2020 | https://crashedmind.github.io/PlantUMLHitchhikersGuide/ | <a href="https://web.archive.org/web/*/https://crashedmind.github.io/PlantUMLHitchhikersGuide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Tip</p>
<p><a href="http://www.plantuml.com/plantuml/svg/SYWkIImgAStDKU3YAYueoYn9LL39JImgoynJY3OqCgWmD37HDpIBLQZc0j1YTykjipeOWCzxDPX_7Kh2tFybRIJILB7PAtJIxvrfkfonyo1vGKpxh-ByCeVhlytNv-oC--_Wm_iG_3_oty1UsAjxN8x-7XRMkeUDvTsVmavKunxthELFOUigkoz_0dlhtjaRVVmHBEp2TS_SwT_3swvxpLLs7yDhrztpAXyVms7XkcNUTHk0jc5nOrJuZIknSBZB0BWFnpttBeTmlSquODw6_HqMOK_k9eGmGhkm51ntNOc5mz6VONLXjzL1tNtOodfHdy798Y00xy0-MdYwUx3aUC049aWRi0lntkbzsHq-I9TVNDY1nRt0RXyUvqh9Q5rXtyD2_hBJaf-AHycTh-e6FBnmBtY_PFbrq6om1FicFBpu2Upb5wbPfxmDXyzWV_WGJSd0U_0mFuTzRxRPEx0RwaTmq9y-P0Ia_OgFz2aSv6Skc8W2zoquV0vBNDS08lKjsCM_WAF09XlmaVu6zh-5VHBPmf9VmYB_5WuAVx9awdLXmcThxVmjVE_r_gF04QAe3BLMPB4tuG--5eF2YNkZMhAaL1Hw2_xWGK3XWBt3P2VDMx3Alt_MqypBSZjF2yDx-4ZlUos8BkX9aaVIl4fV52OY9gWF5Xdv7UmCV9Mbh91ogIEbJ6tQ8iW8a12Wf52844aEQaLYJaT-1_UuA5d0c4jvW47VifsEHIv9fM5AfK85WL5iQWt2E3UzXRs5PsAgY5A85-sMG-GSOynCIKwF2NZ22DIzarXuezSnPKqfuT-RDXzJJDZoNBLYVS9u7a-Oa5ZXTTAth4sRFQpnxJOrPcYexWYiO6HY1eNT6jRaYiYiRYnnOsCUaT8tZEqEDsgCc0USIiaBEZxKcc8YAdBlalTJrjURAgp8qvNm0YPYoccqkbO4nBg4WOOh90uvvU0r8UNuZxyuXUbApZjy4X8aD-2CX8qXNs6PgSJC86rEG6LeafW14OhGQzV0_GRdauWXz06xMg4nbbktMTWcjCoHYb4VyJDYpN8BSdYXZVfqqnqkPsidrpcTKa6TdnVu59GLhqA760KiQIuIWux-Kcmg9QaxKtzWUi2rSpjF0eLx1a90IA_iT6Uevc41Gid2YfmhGWx-cH1pvTQmfFX8w1Rs4pu5RfmdJ4CX9i1IgwgMdI50mZhP7xegFOj5RX9-qix2BKruVBR820EkrAIjqdj0KfRlQOrgjh3GCEcOAxMVaFR5zmKC_MGSCW_O8GyAILwuDM5NcSMyojh-MWfmipbrZDt0Q60QtD2_UXMtiHoAsdYT-O5maOKcrIvqwqkuTc6amrzP6aqypFx_M2I5xHsqASWB-W9pL1W4qHP_LHHulEW4MgRcIjpQclQ7Nz5IY8N9Fs4ckSbVohTPy1eMwldHUcnf-Q8CgMBJCB6bJ_w6yGTM1xz86jxaKDjv8Ii-fd5-o2mX45hcxeYNX3nlDPM2bZwP7l3nXCKb-9h_fGKcbE5UQwqq_v619pm3kcw97UPUEEe9N5EoKqiKCh3EuqO0zOlc2KrWlD5KKaQQHLfPw1H4zlByhCju4fgnn8IFCucL9WG3o_t8yhM8pE9EM6WJ0NCgf5112oijhdn7XoYPj3IZe5wPiMdu2UUcVNO3xeM8snE-qrXI0KGiDxYXoBFSHrALEL9IgZNhCBxpW0FLKdBi0dUep1PMsW249UUIywNLZHkNQ51n2vmoAp77LD3CGIfkmZfMD-5UvmAXy9ec0AIcUR84E62RLEN20RV6HfLn16VWeqzOPI8MU4rFQkR9nYDREEMAZVBXMM0Jmkp5NC8m90ClwVQK6sCDtZa39vd7CXXtu0lCaEtpVw01knUO1BxBXZP53C1PE0FoMKLuXNbM-meVPYSH0AaPU4dFfQXXYMwcA9nIGOIYm2jCLGPuWREu4vRa6tpljxgTizDCEALSOR31kIjCDRbR8e5xWLqbQSoQ_eRFXZb7R-0w7_cbnnRMAHWEju3vl6pQCX0tfZNzA1hIuMno8sMTpO6jKT7XhU1ssoqMe7_IaAAx9F6YhWC6As-kuSKsjIAIj9NMSd2t724iXFkR9ca1vwh2MYQwD5JYTdECh2gsCe3Gx-3_qMftEwwhEXp0xy_J1FnXSmcawwtEkszCd9OqqpLhh-tvNumgMSgle8P1XZGRBF27RiQHl5dW1bksOhAMwlHdE1EFq9-v2Na4Zi_z1bkus91LVTJVmHW5kwmgOdGiZ7TuZKnPcEMwUBV-7s3w3hPiwZ9nMUYsts6AWosgfPXCH7FdvF0ZtPz5xs-r1KVWNq-r1KMBJXa7lK_w3ekgNc4WFaFf_Zgb6tmFYS5CY5XixtQ7VKsumhp2zzpXUpOMOJ9O-sxq7Ru72IqqWjjVmcQFpAzGsknB_89q1huECURixTQFSDxly3VfhRKY8zhwXpGLaL9_b_PtT_RsWVV7v_hiQFp0PS5EHDmVxx6zcAUhQ8-7SyweK-gz-TegR17HChVmJPX_0WRfVO1C2FdjJbU6sGyf8l7m1YJJpAlfiX-DY0g6mtwwaWrENy8v0pD4mpXS631yXc5Ke4J3CDpVm7wUQEjECAoOCpxd-jrrE9iS2biolE1qWyr5-14OSC9tsGTizMno_Ej4ov3JpJKOVW3EVbpfyiZroDXSmb69XiqbN6MFknCcoC7mtDkiyjFEYpk240fdG5vWo6jMbrMsIFXuhCjENraB0DVQLRSmk1Gbm-2PV0duNxA-LPSj1S69UYl-8dc-l7MBjLjmss9Ws9ATUtsu7_5oeSxUKB5o14nfIsLVv9LEgxjRMXx5505ZJa1roEBoUzmj-sEu5RQqfH2O411DRcpmJSxkFYmLRHPYO64okpvCFkcxkvlRS1i9Wdd8281sKkJoZ9CMmCKrE0V2cORS68o-hLlkKd8uHS9JxW8BxIoMntJPt60O3QFsSDbncF5vxfBT3O95sFVJcUoSIX7Mc3lFGoLjJpXc0H6VwvIIc5neeT7SaQxvvSQirHlvN0yvInz8PNn5ZsxsueR05kGvrq-vxrK9FToQmGLURavR1Em_hulSMsMQuL9DLXYWZzOEMe9WCldSO6Qnuw9Q79O1D_75RBA1y3PWborSUwsAI3DrtWcv96u7WcAoqMO3bG7JsGjKNlT2zkbN6BofdYqeiA0KWor-IGEMR46mPK0glisq49zD1zy1keqZeR2tE2VjGN_9UOHm2VmAX4lrTWlFY66p029i1vF7zo8BXiD7vfc_Y8fFXJABnHiao1GxrIe7mDxcBENSSVlFFH_tHJDnB2ppyTwgJA2rUA6ymIWK2Iixx8zdXqNr2YSG38JB0llZzLpKNfKqkp0CiIFc2vnzUM9lB99d_iBYO5JHKjGGNqPo9lz6efwZXaW0KV1sF7OL2B9NH0XXROyJXS66CLxk6US3hdCDVoiHXi5oWnFW9pX16CnyJ6vAwudg2GjVfpfb284jeiku7EOJzjAh5hW3EU4fhx2AFaifViG6d-DAorJx8kvoJXw8W-tnpmLa1XmkzPGXUm13OPFFnmCWbtgKUg_djx8W4XF6_RYg3uoUTzLwEqfrNkfHyMXhoXe6OxMBCUquojVQ1cRkJ5alSBMsTmtzVznwxVl3Z3O--7YFj94oP4khpIhVm___tpzjd45h8p4CXU_pAyImaDlCFOImi8HDe2cba5EQWp9MR7LiETXomz0_NwVJGW-zYCTxJtpw1Mhoo7B5X0467uk1z-QCmsXJB6B-HHyJt1mhrUgSVpqMmGpjQhZdIvjmMg_-pC5wrN-wwxPf92g1fuj2l7plBQ7TmOspWocMXO7NaXMKl8T0a50TfHS1TLX7cbWiQ0GIYvOWJ5MfAvanXzewqu0b4-p0uHl9Gi76oXBgsfcTsBeVy3jxKKdgM4Quonbl8noFJlMQbtq_9CoEJ60ndULAEtSS-oUFeeVzmvPrS8v7Ilb_OKFz8-ajfl6GgxF7mR5G_jNid0OFsytpvdG2bgo4fklgfT3y9J4b-0y0"><img alt="playbutton_index" src="https://crashedmind.github.io/PlantUMLHitchhikersGuide/_images/play6.png"></a> <strong>Press play</strong></p>
<blockquote>
<div><p>Imagine being able to</p>
<ol>
<li><p>share a model or diagram between all members of the team that they can all understand and contribute to and edit</p></li>
<li><p>draw diagrams like below automatically from a text description.</p></li>
<li><p>describe a system before you build it, when you’re building it, and as you maintain it into the future - keeping the description and the system current, and in sync.</p></li>
<li><p>maintain that text version in a source code repository beside the code for the system it is describing</p></li>
</ol>
<p>Imagine having a diagramming tool that</p>
<ol>
<li><p>fits with a developer workflow, and developers are comfortable using</p></li>
<li><p>enables <strong>lightweight just-enough</strong> <a href="http://agilemodeling.com/essays/barelyGoodEnough.html">AgileModeling</a> in a way that meets <a href="https://tdan.com/best-practices-for-agile-documentation/18936">AgileModelingBP</a></p></li>
<li><p>fits with modern practices of Continuous Integration Continuous Delivery - and “everything as code” including diagrams.</p></li>
</ol>
<p>Well that’s what PlantUML gives you, and more…</p>
</div></blockquote>
</div></div>]]>
            </description>
            <link>https://crashedmind.github.io/PlantUMLHitchhikersGuide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23648957</guid>
            <pubDate>Fri, 26 Jun 2020 05:26:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The War on Upstart Fiber Internet Providers]]>
            </title>
            <description>
<![CDATA[
Score 496 | Comments 213 (<a href="https://news.ycombinator.com/item?id=23647609">thread link</a>) | @joecool1029
<br/>
June 25, 2020 | http://chrishacken.com/the-war-on-upstart-fiber-optic-internet-providers/ | <a href="https://web.archive.org/web/*/http://chrishacken.com/the-war-on-upstart-fiber-optic-internet-providers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>                                
                                    <div> 
                                        <p>As someone who grew up throughout the 90's and 00's, some of my fondest memories stem from progressive advancements in internet and computing technologies.  Upgrading from Dial-Up internet to DSL was a grand event in our house.  I remember my brother and I fighting over the computer day in and day out to play games like Wolfenstein - Enemy Territory, which was released in 2003. (I'm convinced that this will be the all-time best FPS game ever created.)  At around the same time, we upgraded to one of the best Dell computer's available at the time. It had 512MB of RAM and a Pentium 4 processor.  This was a major upgrade from our Compaq Celeron, which had something like 64MB of RAM. <br>
<img src="http://chrishacken.com/content/images/2020/03/MV5BOGFmNjMzZTktNDg2ZS00ZjllLTlkMTAtZTAzMzBkN2UyMzk2XkEyXkFqcGdeQXVyMjU3MzI1NzI@._V1_.jpg" alt="Wolfenstein - Enemy Territory"></p>

<p>Eventually, the grandeur of DSL faded as the rest of the world began to adopt Cable and Fiber internet.  It wasn't until I briefly moved to Philadelphia that I was finally able to experienced what I had been missing out on.  In college I lived in a neighborhood that was one of Verizon's first Fios builds.  I was absolutely blown away by the 25 Mbps connection.  This was in 2009. I'm amazed that over a decade later, in 2020, some households still don't have access to cable or fiber internet yet.</p>

<p>Like many of our customers do now, I could never figure out why it was so difficult to get us fiber service.  The cable is cheap, just throw it up on a pole and give me internet! Right?  Well, not so fast... <br>
<img src="http://chrishacken.com/content/images/2020/03/1849761.jpg" alt="Fiber Spaghetti"></p>

<p>A quick overview of how utility services are run and the challenges involved...</p>

<p>As most people know, there are primarily two ways to deliver utility services to a home or business.  Aerial and underground.  Water, gas, and sewer are always serviced underground for obvious reasons.  Electric, telephone, cable, and fiber have the ability to either be above or below ground.</p>

<h3 id="aerial">Aerial.</h3>

<p>As with anything else, aerial has pro's and con's.</p>

<p>The pro's are primarily upfront costs (this is debatable) and speed of deployment (this is also debatable).</p>

<p>The con's are that contrary to it being cheaper to physically deploy, the pole owners generally charge up-front make ready fee's.  These fees can range from $0 to upwards of $50,000/mile.  It's essentially pay to play.  If we want to attach to 50 poles, the pole owner might determine that 10 of those poles are old and need to be replaced before we can attach to them.  Rather than fork up the cash themselves, they'll force us to pay to replace their poles in order to approve the attachment.</p>

<p>In addition to that, there are the annual pole fee's.  Depending on your agreement, we've seen pole fee's ranging anywhere from $7/pole per year all the way up to $43/pole per year with 10% annual increases (I'm looking at you PPL.  This ridiculous rate was purely intended to keep us from attaching to their poles, IMO.  It's impossible to make money with these rates). <br>
<img src="http://chrishacken.com/content/images/2020/03/Screenshot-2020-03-10-22.04.34.png" alt="Pole Rates"></p>

<p>Another con is that even though installing the cable on poles is faster, it usually takes the pole owner around 6 months just to review applications and to determine make ready requirements and costs.  As an example, if we have fiber on a pole that's 1 pole short from being able to service your house, it would take at least 6 months just to run fiber to that one additional pole. So close, yet so far.</p>

<h3 id="underground">Underground.</h3>

<p>Like aerial, underground has its own list of pro's and con's.</p>

<p>When you install a service underground, you own it for life.  There are no annual fee's.  You pay one time to install it and you're set for life.  This sounds like a pro, but it's also a con.  When we run metro conduit, it generally costs us between $15-25/ft (not including customer drops).  For the sake of argument, let's assume we're at the high-end of our costs.  If we install 1,000ft of conduit, that's $25,000 that we need to pay out of pocket upfront.  Some blocks have upwards of 30 customers, but others have as little as 5.  Let's average it out at 20 customers per block, that's $1,250 upfront per customer, assuming we get every single customer.  Conservatively, we're initially looking at a 50% take rate.  This could grow to 100% overtime, but we never make that assumption. So that's $2,500/customer.  Imagine spending $2,500 per house/building and then have them tell you that your $69/m service is too expensive.  Generally speaking, we won't do a street unless our numbers look better than this, but this is a realistic scenario as we scale and get access to cheaper capital, etc.</p>

<p><img src="http://chrishacken.com/content/images/2020/03/enorthampton01.jpg" alt="Underground Construction">
<img src="http://chrishacken.com/content/images/2020/03/enorthampton02.jpg" alt="Underground Construction Restoration"></p>

<h3 id="politics">Politics</h3>

<p>Cost issues aside, there are a number of other hurdles one needs to get past just to begin the process of building out a network.  You'd think that risking everything you have in an effort to bring your local economy into the 21st Century would be a welcome sight.  That's what I thought too; was I wrong.  While there are plenty of supporters (I truly appreciate you all), there are just as many, if not more, critics.</p>

<p>We've been fortunate enough to have had a handful of people get behind us overtime and give us a shot.  I'm sure others haven't had it so easy.  I know this because even after we've become an established player in our city throughout the past 4 years, neighboring townships and municipalities haven't been as opened armed to welcome us into their communities as I had anticipated or would have liked.</p>

<p>I'll go into more detail on small government policies that really hamper our ability to deploy underground later below.</p>

<h3 id="toomanyopinions">Too Many Opinions</h3>

<p>I'm generally a big fan of individual citizens trying to make an impact in their communities.  However, in too many cases these contributions seem to be made in the form of unproductive complaints rather than productive feedback or action.  Far too many people have a say in things that they probably shouldn't.</p>

<p><strong><em>Case A.</em></strong></p>

<p>A new customer had recently signed an agreement with us to run fiber into their building.  This is a non-profit who's members are selflessly donating their time to restore a landmark in the community.  Upon receiving their signature, I notified the city that we would be pulling a permit to connect the building in question to our underground network.  They said okay; that was that.  Our nearest existing hand hole is approximately 90ft to the right of the new customer's property; in front of another property.  As a courtesy, I notified the manager of that establishment to let her know that we would be performing work over the weekend, from Friday into Saturday.  They're closed Saturday and Sunday so I had assumed they would appreciate the notice and possibly even sign up with us.  The project would involve removing 90ft of sidewalk, running conduit, and then restoring the sidewalk with brand spankin' new concrete.  The total timespan that this would occur, from when our shovel hit the ground to having new sidewalks in place, would be 48 hrs.  The response that I received from a member of their organization made me facepalm.</p>

<p><img src="http://chrishacken.com/content/images/2020/03/Screenshot-2020-03-10-18.53.55-copy.png" alt="Sidewalk Issues"></p>

<p>Not long after receiving this email, I became aware that they didn't even own the building in question, nevermind the sidewalk.  They lease it.  This was eventually "resolved" after a series of negotiations between the non-profit's president and the establishment in question.  Often times we aren't as lucky.</p>

<p>We initially planned to have this new customer installed within a week of them signing the contract.  Now it will end up being around 2 months from start to finish.  Long story short, I learned my lesson in trying to be courteous.</p>

<p><strong><em>Case B.</em></strong></p>

<p>Last year we were installing conduit for our fiber optic network.  There were countless instances where people would literally stop their cars, roll down their windows, and yell profanities at us.  In what world is that acceptable behavior for an adult? I can't imagine being so far off my rocker that I would feel the need to yell at a bunch of construction workers trying to build a fiber optic network (not that they had any idea what we were doing).  If these are the types of people influencing decisions, there's something wrong.</p>

<p>City workers have a tough job fielding complaints from people like this and I commend them for it.  It shouldn't affect policy though.</p>

<p><strong><em>Case C.</em></strong></p>

<p>In another incident that took place not long, maybe a day or two, after <em>Case B</em> above.  A local store owner came back to us as we're swinging pick axes in 95 degree heat telling us we need to hurry up and we should hire more workers.  "My customers keep calling saying there's no where to park."  Mind you, we're standing right next to a massive parking lot that is approximately 1/3rd full.  I made my best attempt to kindly explain that paying 3 guys to stand around a hole to watch one person hand-dig to expose a utility isn't going to make our work go any faster.  I don't think he liked my response.</p>

<h3 id="theconsequences">The Consequences</h3>

<p>In many cases, resident complaints are justified.  Utility providers need to be held accountable for shitty restoration work.  However, the way in which bad restoration work is being combated is counter productive.  There has been a huge increase in curb-to-curb restoration requirements by local governments.  Essentially what these rules state is that anytime a utility cuts asphalt beyond a predetermined length, say 100ft, they are then responsible for replacing the entire road surface from the curb on the left side of the street to the curb on the right side of the street.  I believe some municipalities are also trying to introduce these measures to offload the costs of repaving roads themselves, similar to how pole owners force you to replace their aging utility poles under their make-ready requirements.  (One municipality told me as much when I attended a local council meeting in an effort to get them to waive this ridiculous ordinance for us.)</p>

<p>These policies will ultimately do more harm than good.  For us, these are the one and only thing preventing us from providing superior fiber internet services in these areas.  Forcing curb-to-curb asphalt …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://chrishacken.com/the-war-on-upstart-fiber-optic-internet-providers/">http://chrishacken.com/the-war-on-upstart-fiber-optic-internet-providers/</a></em></p>]]>
            </description>
            <link>http://chrishacken.com/the-war-on-upstart-fiber-optic-internet-providers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23647609</guid>
            <pubDate>Fri, 26 Jun 2020 00:55:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Laura Deming, founder of the Longevity Fund, on being homeschooled]]>
            </title>
            <description>
<![CDATA[
Score 110 | Comments 197 (<a href="https://news.ycombinator.com/item?id=23644762">thread link</a>) | @mksm
<br/>
June 25, 2020 | https://blog.withprimer.com/laura-deming/ | <a href="https://web.archive.org/web/*/https://blog.withprimer.com/laura-deming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
	<article>
		<div>

			<section>
				<p>Laura Deming is a biologist and founder of The Longevity Fund, the first VC firm to focus on companies that work on extending healthy human lifespan and addressing age-related diseases through biotechnology. She grew her roots in biology as a homeschooling student in New Zealand, and moved to the US to work in a <a href="https://hillblomcenter.ucsf.edu/#:~:text=The%20mission%20of%20the%20Hillblom,diseases%20have%20similar%20molecular%20causes.">UCSF biology lab</a> at age 12. By age 14, she was a student at MIT, then became a <a href="https://thielfellowship.org/">Thiel Fellow</a>. We asked Laura to share how her education prepared her to lead and build today.</p><figure><img src="https://blog.withprimer.com/content/images/2020/06/Frame-2.png" alt="" srcset="https://blog.withprimer.com/content/images/size/w600/2020/06/Frame-2.png 600w, https://blog.withprimer.com/content/images/size/w1000/2020/06/Frame-2.png 1000w, https://blog.withprimer.com/content/images/size/w1600/2020/06/Frame-2.png 1600w, https://blog.withprimer.com/content/images/size/w1754/2020/06/Frame-2.png 1754w"><figcaption>Laura Deming. Illustration by <a href="https://www.ne-oh.com/">Annie Oh</a>.</figcaption></figure><h3 id="what-are-you-working-on-and-thinking-about-this-week">What are you working on and thinking about this week?</h3><p>How long do you have? I normally have a few key focuses at work (right now, immune aging from a bunch of different angles), and then a billion other small ideas that float in and out of my cranium. My most persistent focus is something that I can’t talk about yet because it would sound slightly insane, but right now, I’m pursuing these more coherent questions: &nbsp;<br></p><ol><li>Is there a flywheel effect with biological tools? Will biological discoveries become the tools for next-generation discovery? How might we predict progress in biology?</li><li>Why does it normally take about a year for the best proto-entrepreneurs I know to reach full conviction about starting a company? What are ways to accelerate that process?</li><li>Is there an immortal cell that doesn’t replicate anywhere on earth? (We presumably wouldn’t see it if there was.)</li></ol><p>I’m really obsessed with <a href="http://book.bionumbers.org/">Cell Biology by the Numbers</a>. I think quantitative intuitive models of biology are the best thing ever. Also <a href="https://www.cornell.edu/video/nima-arkani-hamed-morality-fundamental-physics">this Nima Arkani-Hamed</a> video is literally the best thing ever.</p><h3 id="what-was-your-education-like">What was your education like?</h3><p>I grew up homeschooled in NZ with a hilariously small amount of context for what the real world was like. In retrospect, it was totally ideal. I had two strong memes deeply implanted in my cranium early in life - <em>I love science </em>and <em>it’s my job to do something really important </em>and<em> I can do it, too. </em>I have no clue who I’d be without those memes, and I’m also not sure that the latter was actually true! My dad just always told me that I was exceptional and could work out a way whatever I wanted to do in the world and I believed him. I still do, in a funny way, despite about a decade of evidence to the contrary and realizing how actually hard it is to make drugs for complex diseases. It’s extraordinarily sad how many otherwise brilliant kids might not do things they could because they don’t have a similarly supportive environment — I’m really excited for things like <a href="https://dcgross.com/">Daniel Gross</a>’s <a href="https://pioneer.app/">Pioneer</a> for that reason. </p><figure><img src="https://blog.withprimer.com/content/images/2020/06/image.png" alt="" srcset="https://blog.withprimer.com/content/images/size/w600/2020/06/image.png 600w, https://blog.withprimer.com/content/images/size/w1000/2020/06/image.png 1000w, https://blog.withprimer.com/content/images/size/w1600/2020/06/image.png 1600w, https://blog.withprimer.com/content/images/size/w2000/2020/06/image.png 2000w"><figcaption>Laura as a child, drawing DNA on the pavement outside of her house in chalk, an anecdote from a talk that she gave for <a href="https://www.youtube.com/watch?v=YwslKJut8eM">TedxYouth@Tallinn</a>. Illustration by <a href="https://www.ne-oh.com/">Annie Oh</a>.</figcaption></figure><p>I feel like it was a lot of puzzle solving and doing obvious stuff. And then starting to think more independently in college, and to try to figure out what problems I wanted to work on. But I had this moment around that time where a friend and I were driving to a camping site, and I was trying to explain a math concept to him, and he abruptly turned to me and said “I’m feeling very frustrated right now because you honestly have absolutely no idea what you are talking about.”<em> </em></p><p>It’s really hard to explain without context how actually useful that comment was. As he explained it, I was just parroting off the definition of something. The real way to understand things is to be able to see, explore, feel the concept from a bunch of different angles, and to be able to rigorously prove things about it. I still struggle with the latter, but having an intuition for what <em>real, deep </em>understanding of a concept looks like has been a great guidepost. For example, I realized I didn’t understand what entropy was, and now kind of do, after a summer of being in near tears with frustration about it. </p><h3 id="where-and-when-did-your-mission-to-improve-longevity-originate">Where and when did your mission to improve longevity originate?</h3><p>It’s funny, because I get asked that question a lot. I think of it like this: if you were to watch a million people jump off a bridge every day and just suffer in a really extreme way throughout all of it, How would we respond as a society? An overwhelming number of people would be inspired to take action and help. When you think of it in acute, immediate terms, viscerally shocking and moving. But with longevity and other deeply existential problems, the horror of what’s happening has been tragically normalized.</p><p>I really just wanted to work on the biggest problem possible. At first I thought that was cancer, but after a variety of experiences, aging just seemed like a bigger deal.</p><p>I have a much less antagonistic relationship with death now than I did when I was a kid. I understand more that we are a species, that there’s something beyond us as individuals — but despite that, I absolutely cannot square the idea of sobbing when a relative gets cancer and then being totally fine with another debilitating degenerative disease also caused by aging that we somehow have collectively decided is natural and normal.</p><h3 id="how-has-the-way-you-learned-as-a-kid-shaped-the-way-you-learn-and-make-decisions-at-the-helm-of-the-longevity-fund">How has the way you learned as a kid shaped the way you learn and make decisions at the helm of The Longevity Fund?</h3><p>I’ve had to un-learn a bunch of stuff I learned when I first came to the professional world. As a kid, I was deeply joyous about science. I loved it directly and with a passion, and I absolutely believed I was going to grow up to be like Michael Faraday (his story about <a href="https://artsandculture.google.com/exhibit/people-of-science-michael-faraday-the-royal-society/HQLyLIo6MWpoKw?hl=en">getting an apprenticeship with Humphrey Davy</a> is amazing, by the way). When I entered the world of finance with my fund, I was totally scared to seem like I didn’t know what I was doing, and I felt like it was really important to hide who I was to seem more ‘adult’. Now, in retrospect, I think that was both understandable and a bit of a mistake.</p><p>One thing I learned as a kid that I keep on forgetting so easily is how not to care about what anyone else thinks (with a few close exceptions). It’s funny - even in Silicon Valley, hypothetically the vanguard of independent thought, I feel like that’s extremely hard to do. In part, because what other people think constrains your access to resources. So it’s an interesting balance. </p><h3 id="i-ve-heard-you-talk-about-your-dad-telling-you-at-12-years-old-to-make-sure-that-everyone-was-a-little-bit-happier-because-you-were-in-the-lab-each-day-what-role-did-your-parents-play-in-your-life-and-education">I’ve heard you talk about your dad telling you at 12 years old to make sure that everyone was a little bit happier because you were in the lab each day. What role did your parents play in your life and education?</h3><p>Oh, man. My Dad had so much good advice as a kid — I really felt like I got a cheat code to life early on. It was like being Ben Franklin’s daughter or something. I’m probably exaggerating, but it felt that way. </p><p>One thing he told me was ‘action comes before motivation’ - that’s always been an incredibly powerful thing in my life. He taught me a lot about putting your head down and working hard and not believing anyone who tells you you are great, having that come mostly from your own self-judgment. Being extremely humble around people who know more, finding any way on earth to help them. </p><p>My dad also taught me a lot about humor and how ridiculous the world was in so many different ways. Almost too much - I think I take things more seriously now. But it’s kind of the Mark Twain effect - the world and everyone in it is a hilarious, self-sabotaging, foolhardy place that is also one of the most deeply joyous and interesting things going on in the galaxy. He used to say you can either look at what’s going on in the world and cry or laugh. Why not pick the latter?</p><p>My mom taught me about kindness and empathy and wanting to help others. She’s probably the most giving person I know. </p><p>When I first met Cynthia Kenyon, who literally changed my and many other lives – she’s amazing – I had this very extreme mental conceit that I would beg her to scrub floors in her lab and somehow work my way up on the academic ladder. I was 12. She very kindly offered for me to just work in her lab as a normal intern, which was so kind in retrospect. It changed my life, to be taken seriously like that at a young age. </p><h3 id="i-love-how-you-describe-the-way-the-longevity-fund-removes-limits-on-who-can-participate-in-biomedical-entrepreneurship-how-can-we-translate-some-of-what-you-ve-learned-about-diverse-participation-in-science-to-the-way-that-kids-learn">I love how you describe the way The Longevity Fund removes limits on who can participate in biomedical entrepreneurship. How can we translate some of what you’ve learned about diverse participation in science to the way that kids learn?</h3><p>I think there’s something about being absolutely delighted when you meet someone who doesn’t know something. That feeling is the best thing in the world because <em>you get to be the first person to tell them about some incredibly cool natural phenomenon</em>. That’s pretty great. I still remember being a preteen in Cynthia’s lab when Marc McCormick described how SVMs (<a href="https://en.wikipedia.org/wiki/Support_vector_machine">Support Vector Machines</a>) worked for handwriting recognition in the postal system. He was just so good at explaining things, and that really stuck. Encourage people to own ideas, be skeptical of them, and learn to delight in poking holes in things.<br></p><p>When thinking about diverse participation, it’s funny – before I came to the Valley, I had absolutely no idea that being a girl was in any way a handicap. To me, it was an obvious advantage – in a sea of people who all looked the same way, I’d stick out like a sore thumb! If I could make it, wouldn’t I obviously be an amazing role model? Being in the valley for a while, it kind of wore off, and the more articles I read about how much it sucked to be a girl in science, the more I believed it. I’m not sure what to think about all of that, really. </p><h3 id="what-s-something-you-believe-that-most-people-don-t">What’s something you believe that most people don’t?</h3><p>I can give you a few!</p><ol><li>That we will see the first drug to measurably affect <a href="https://publichealth.wustl.edu/heatlhspan-is-more-important-than-lifespan-so-why-dont-more-people-know-about-it/">human healthspan</a> tested in the next decade, and that this is one of the biggest deals in how we thinking about disease. It’s not just hype and rhetoric.</li><li>That original thinkers are so darn much more rare to find than I thought they’d be growing up. <br></li></ol><hr><p><em>Primer is a new education company whose goal is to help kids engage in limitless learning, starting with homeschoolers. </em><strong>Homeschooled:</strong><em> is a regular series about homeschooling alumni who have gone on to do amazing things. We're just getting started, so we'd love to hear what you think!</em></p><p>Sign up for …</p></section></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.withprimer.com/laura-deming/">https://blog.withprimer.com/laura-deming/</a></em></p>]]>
            </description>
            <link>https://blog.withprimer.com/laura-deming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23644762</guid>
            <pubDate>Thu, 25 Jun 2020 19:48:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Query-Based Compiler Architectures]]>
            </title>
            <description>
<![CDATA[
Score 113 | Comments 33 (<a href="https://news.ycombinator.com/item?id=23644391">thread link</a>) | @matt_d
<br/>
June 25, 2020 | https://ollef.github.io/blog/posts/query-based-compilers.html | <a href="https://web.archive.org/web/*/https://ollef.github.io/blog/posts/query-based-compilers.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p>Note: This is an old post originally from the documentation of the <a href="https://github.com/ollef/sixten">Sixten</a> programming language, that I've touched up and fleshed out. After the time that it was written I've found out about <a href="https://github.com/salsa-rs/salsa">Salsa</a>, a Rust library with very similar goals to my Rock library, which is definitely worth checking out as well!</p>
<h2 id="background">Background</h2>
<p>Compilers are no longer just black boxes that take a bunch of source files and produce assembly code. We expect them to:</p>
<ul>
<li>Be incremental, meaning that if we recompile a project after having made a few changes we only recompile what is affected by the changes.</li>
<li>Provide editor tooling, e.g. through a <a href="https://langserver.org/">language server</a>, supporting functionality like going to definition, finding the type of the expression at a specific location, and showing error messages on the fly.</li>
</ul>
<p>This is what Anders Hejlsberg talks about in <a href="https://www.youtube.com/watch?v=wSdV1M7n4gQ">his video on modern compiler construction</a> that some of you might have seen.</p>
<p>In this post I will cover how this is achieved in <a href="https://github.com/ollef/sixten">Sixten</a> by building the compiler around a query system.</p>
<p>For those of you that don't know, Sixten is an experimental functional programming language created to give the programmer more control over memory layout and boxing than most other high-level languages do. The most recent development of Sixten is being done in the <a href="https://github.com/ollef/sixty">Sixty</a> repository, and is completely query-based. Here's a little video giving a taste of what its language server can do, showing type-based completions:</p>

<h2 id="traditional-pipeline-based-compiler-architectures">Traditional pipeline-based compiler architectures</h2>
<p>A traditional compiler pipeline might look a bit like this:</p>
<div id="cb1"><pre><code><span id="cb1-1"><a href="#cb1-1"></a>+-----------+            +-----+                +--------+               +--------+</span>
<span id="cb1-2"><a href="#cb1-2"></a>|           |            |     |                |        |               |        |</span>
<span id="cb1-3"><a href="#cb1-3"></a>|source text|---parse---&gt;| AST |---typecheck-+-&gt;|core AST|---generate---&gt;|assembly|</span>
<span id="cb1-4"><a href="#cb1-4"></a>|           |            |     |       ^        |        |               |        |</span>
<span id="cb1-5"><a href="#cb1-5"></a>+-----------+            +-----+       |        +--------+               +---------</span>
<span id="cb1-6"><a href="#cb1-6"></a>                                       |</span>
<span id="cb1-7"><a href="#cb1-7"></a>                                 read and write</span>
<span id="cb1-8"><a href="#cb1-8"></a>                                     types</span>
<span id="cb1-9"><a href="#cb1-9"></a>                                       |</span>
<span id="cb1-10"><a href="#cb1-10"></a>                                       v</span>
<span id="cb1-11"><a href="#cb1-11"></a>                                  +----------+</span>
<span id="cb1-12"><a href="#cb1-12"></a>                                  |          |</span>
<span id="cb1-13"><a href="#cb1-13"></a>                                  |type table|</span>
<span id="cb1-14"><a href="#cb1-14"></a>                                  |          |</span>
<span id="cb1-15"><a href="#cb1-15"></a>                                  +----------+</span></code></pre></div>
<p>There are many variations, and often more steps and intermediate representations than in the illustration, but the idea stays the same:</p>
<p>We push source text down a pipeline and run a fixed set of transformations until we finally output assembly code or some other target language. Along the way we often need to read and update some state. For example, we might update a type table during type checking so we can later look up the type of entities that the code refers to.</p>
<p>Traditional compiler pipelines are probably quite familiar to many of us, but how query-based compilers should be architected might not be as well-known. Here I will describe one way to do it.</p>
<h2 id="going-from-pipeline-to-queries">Going from pipeline to queries</h2>
<p>What does it take to get the type of a qualified name, such as <code>"Data.List.map"</code>? In a pipeline-based architecture we would just look it up in the type table. With queries, we have to think differently. Instead of relying on having updated some piece of state, we do it as if it was done from scratch.</p>
<p>As a first iteration, we do it <em>completely</em> from scratch. It might look a little bit like this:</p>
<div id="cb2"><pre><code><span id="cb2-1"><a href="#cb2-1"></a><span>fetchType ::</span> <span>QualifiedName</span> <span>-&gt;</span> <span>IO</span> <span>Type</span></span>
<span id="cb2-2"><a href="#cb2-2"></a>fetchType (<span>QualifiedName</span> moduleName name) <span>=</span> <span>do</span></span>
<span id="cb2-3"><a href="#cb2-3"></a>  fileName <span>&lt;-</span> moduleFileName moduleName</span>
<span id="cb2-4"><a href="#cb2-4"></a>  sourceCode <span>&lt;-</span> <span>readFile</span> fileName</span>
<span id="cb2-5"><a href="#cb2-5"></a>  parsedModule <span>&lt;-</span> parseModule sourceCode</span>
<span id="cb2-6"><a href="#cb2-6"></a>  resolvedModule <span>&lt;-</span> resolveNames parsedModule</span>
<span id="cb2-7"><a href="#cb2-7"></a>  <span>let</span> definition <span>=</span> <span>lookup</span> name resolvedModule</span>
<span id="cb2-8"><a href="#cb2-8"></a>  inferDefinitionType definition</span></code></pre></div>
<p>We first find out what file the name comes from, which might be <code>Data/List.vix</code> for <code>Data.List</code>, then read the contents of the file, parse it, perhaps we do name resolution to find out what the names in the code refer to given what is imported, and last we look up the name-resolved definition and type check it, returning its type.</p>
<p>All this for just for getting the type of an identifier? It seems ridiculous because looking up the type of a name is something we'll do loads of times during the type checking of a module. Luckily we're not done yet.</p>
<p>Let's first refactor the code into smaller functions:</p>
<div id="cb3"><pre><code><span id="cb3-1"><a href="#cb3-1"></a><span>fetchParsedModule ::</span> <span>ModuleName</span> <span>-&gt;</span> <span>IO</span> <span>ParsedModule</span></span>
<span id="cb3-2"><a href="#cb3-2"></a>fetchParsedModule moduleName <span>=</span> <span>do</span></span>
<span id="cb3-3"><a href="#cb3-3"></a>  fileName <span>&lt;-</span> moduleFileName moduleName</span>
<span id="cb3-4"><a href="#cb3-4"></a>  sourceCode <span>&lt;-</span> <span>readFile</span> fileName</span>
<span id="cb3-5"><a href="#cb3-5"></a>  parseModule moduleName</span>
<span id="cb3-6"><a href="#cb3-6"></a></span>
<span id="cb3-7"><a href="#cb3-7"></a><span>fetchResolvedModule ::</span> <span>ModuleName</span> <span>-&gt;</span> <span>IO</span> <span>ResolvedModule</span></span>
<span id="cb3-8"><a href="#cb3-8"></a>fetchResolvedModule moduleName <span>=</span> <span>do</span></span>
<span id="cb3-9"><a href="#cb3-9"></a>  parsedModule <span>&lt;-</span> fetchParsedModule moduleName</span>
<span id="cb3-10"><a href="#cb3-10"></a>  resolveNames parsedModule</span>
<span id="cb3-11"><a href="#cb3-11"></a></span>
<span id="cb3-12"><a href="#cb3-12"></a><span>fetchType ::</span> <span>QualifiedName</span> <span>-&gt;</span> <span>IO</span> <span>Type</span></span>
<span id="cb3-13"><a href="#cb3-13"></a>fetchType (<span>QualifiedName</span> moduleName name) <span>=</span> <span>do</span></span>
<span id="cb3-14"><a href="#cb3-14"></a>  resolvedModule <span>&lt;-</span> fetchResolvedModule moduleName</span>
<span id="cb3-15"><a href="#cb3-15"></a>  <span>let</span> definition <span>=</span> <span>lookup</span> name resolvedModule</span>
<span id="cb3-16"><a href="#cb3-16"></a>  inferDefinitionType definition</span></code></pre></div>
<p>Note that each of the functions do everything from scratch on their own, i.e. they're each doing a (longer and longer) prefix of the work you'd do in a pipeline. I've found this to be a common pattern in my query-based compilers.</p>
<p>One way to make this efficient would be to add a memoisation layer around each function. That way, we do some expensive work the first time we invoke a function with a specific argument, but subsequent calls are cheap as they can return the cached result.</p>
<p>This is essentially what we'll do, but we won't use a separate cache per function, but instead have a central cache, indexed by the query. This functionality is provided by <a href="https://github.com/ollef/rock">Rock</a>, a library that packages up some functionality for creating query-based compilers.</p>
<h2 id="the-rock-library">The Rock library</h2>
<p><a href="https://github.com/ollef/rock">Rock</a> is an experimental library heavily inspired by <a href="https://github.com/ndmitchell/shake">Shake</a> and the <a href="https://www.microsoft.com/en-us/research/publication/build-systems-la-carte/">Build systems à la carte paper</a>. It essentially implements a build system framework, like <code>make</code>.</p>
<p>Build systems have a lot in common with modern compilers since we want them to be incremental, i.e. to take advantage of previous build results when building anew with few changes. But there's also a difference: Most build systems don't care about the <em>types</em> of their queries since they work at the level of files and file systems.</p>
<p><em>Build systems à la carte</em> is closer to what we want. There the user writes a bunch of computations, <em>tasks</em>, choosing a suitable type for keys and a type for values. The tasks are formulated assuming they're run in an environment where there is a function <code>fetch</code> of type <code>Key -&gt; Task Value</code>, where <code>Task</code> is a type for describing build system rules, that can be used to fetch the value of a dependency with a specific key. In our above example, the key type might look like this:</p>
<div id="cb4"><pre><code><span id="cb4-1"><a href="#cb4-1"></a><span>data</span> <span>Key</span></span>
<span id="cb4-2"><a href="#cb4-2"></a>  <span>=</span> <span>ParsedModuleKey</span> <span>ModuleName</span></span>
<span id="cb4-3"><a href="#cb4-3"></a>  <span>|</span> <span>ResolvedModuleKey</span> <span>ModuleName</span></span>
<span id="cb4-4"><a href="#cb4-4"></a>  <span>|</span> <span>TypeKey</span> <span>QualifiedName</span></span></code></pre></div>
<p>The build system has control over what code runs when we do a <code>fetch</code>, so by varying that it can do fine-grained dependency tracking, memoisation, and incremental updates.</p>
<p><em>Build systems à la carte</em> is also about exploring what kind of build systems we get when we vary what <code>Task</code> is allowed to do, e.g. if it's a <code>Monad</code> or <code>Applicative</code>. In Rock, we're not exploring <em>that</em>, so our <code>Task</code> is a thin layer on top of <code>IO</code>.</p>
<p>A problem that pops up now, however, is that there's no satisfactory type for <code>Value</code>. We want <code>fetch (ParsedModuleKey "Data.List")</code> to return a <code>ParsedModule</code>, while <code>fetch (TypeKey "Data.List.map")</code> should return something of type <code>Type</code>.</p>
<h3 id="indexed-queries">Indexed queries</h3>
<p>Rock allows us to index the key type by the return type of the query. The <code>Key</code> type in our running example becomes the following <a href="https://en.wikipedia.org/wiki/Generalized_algebraic_data_type">GADT</a>:</p>
<div id="cb5"><pre><code><span id="cb5-1"><a href="#cb5-1"></a><span>data</span> <span>Key</span> a <span>where</span></span>
<span id="cb5-2"><a href="#cb5-2"></a>  <span>ParsedModuleKey</span><span> ::</span> <span>ModuleName</span> <span>-&gt;</span> <span>Key</span> <span>ParsedModule</span></span>
<span id="cb5-3"><a href="#cb5-3"></a>  <span>ResolvedModuleKey</span><span> ::</span> <span>ModuleName</span> <span>-&gt;</span> <span>Key</span> <span>ResolvedModule</span></span>
<span id="cb5-4"><a href="#cb5-4"></a>  <span>TypeKey</span><span> ::</span> <span>QualifiedName</span> <span>-&gt;</span> <span>Key</span> <span>Type</span></span></code></pre></div>
<p>The <code>fetch</code> function gets the type <code>forall a. Key a -&gt; Task a</code>, so we get a <code>ParsedModule</code> when we run <code>fetch (ParsedModuleKey "Data.List")</code>, like we wanted, because the return type depends on the key we use.</p>
<p>Now that we know what <code>fetch</code> should look like, it's also worth revealing what the <code>Task</code> type looks like in Rock, more concretely. As mentioned, it's a thin layer around <code>IO</code>, providing a way to <code>fetch</code> <code>key</code>s (like <code>Key</code> above):</p>
<div id="cb6"><pre><code><span id="cb6-1"><a href="#cb6-1"></a><span>newtype</span> <span>Task</span> key a <span>=</span> <span>Task</span> {<span> unTask ::</span> <span>ReaderT</span> (<span>Fetch</span> key) <span>IO</span> a }</span>
<span id="cb6-2"><a href="#cb6-2"></a><span>newtype</span> <span>Fetch</span> key <span>=</span> <span>Fetch</span> (<span>forall</span> a<span>.</span> key a <span>-&gt;</span> <span>IO</span> a)</span></code></pre></div>
<p>The rules of our compiler, i.e. its "Makefile", then becomes the following function, reusing the functions from above:</p>
<div id="cb7"><pre><code><span id="cb7-1"><a href="#cb7-1"></a><span>rules ::</span> <span>Key</span> a <span>-&gt;</span> <span>Task</span> a</span>
<span id="cb7-2"><a href="#cb7-2"></a>rules key <span>=</span> <span>case</span> key <span>of</span></span>
<span id="cb7-3"><a href="#cb7-3"></a>  <span>ParsedModuleKey</span> moduleName <span>-&gt;</span></span>
<span id="cb7-4"><a href="#cb7-4"></a>    fetchParsedModule moduleName</span>
<span id="cb7-5"><a href="#cb7-5"></a></span>
<span id="cb7-6"><a href="#cb7-6"></a>  <span>ResolvedModuleKey</span> moduleName <span>-&gt;</span></span>
<span id="cb7-7"><a href="#cb7-7"></a>    fetchResolvedModule moduleName</span>
<span id="cb7-8"><a href="#cb7-8"></a></span>
<span id="cb7-9"><a href="#cb7-9"></a>  <span>TypeKey</span> qualifiedName <span>-&gt;</span></span>
<span id="cb7-10"><a href="#cb7-10"></a>    fetchType qualifiedName</span></code></pre></div>
<h3 id="caching">Caching</h3>
<p>The most basic way to run a <code>Task</code> in Rock is to directly call the <code>rules</code> function when a <code>Task</code> fetches a key. This results in an inefficient build system that recomputes every query from scratch.</p>
<p>But the <code>Rock</code> library lets us layer more functionality onto our <code>rules</code> function, and one thing that we can add is memoisation. If we do that Rock caches the result of each fetched key by storing the key-value pairs of already performed fetches in a <a href="https://hackage.haskell.org/package/dependent-hashmap">dependent hashmap</a>. This way, we perform each query at most once during a single run of the compiler.</p>
<h3 id="verifying-dependencies-and-reusing-state">Verifying dependencies and reusing state</h3>
<p>Another kind of functionality that can be layered onto the <code>rules</code> function is incremental updates. When it's used, Rock keeps track of what dependencies a task used when it was executed (much like Shake) in a table, i.e. what keys it fetched and what the values were. Using this information it's able to determine when it's safe to reuse the cache <em>from a previous run of the compiler</em> even though there might be changes in other parts of the dependency graph.</p>
<p>This fine-grained dependency tracking also allows reusing the cache when a dependency of a task changes in a way that has no effect. For example, whitespace changes might trigger a re-parse, but since the AST is the same, the cache can be reused in queries that depend on the …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ollef.github.io/blog/posts/query-based-compilers.html">https://ollef.github.io/blog/posts/query-based-compilers.html</a></em></p>]]>
            </description>
            <link>https://ollef.github.io/blog/posts/query-based-compilers.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23644391</guid>
            <pubDate>Thu, 25 Jun 2020 19:17:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ASGI from scratch – Let's build an ASGI web framework]]>
            </title>
            <description>
<![CDATA[
Score 73 | Comments 11 (<a href="https://news.ycombinator.com/item?id=23644252">thread link</a>) | @lukastyrychtr
<br/>
June 25, 2020 | https://shenli.dev/2020/06/20/asgi-from-scratch.html | <a href="https://web.archive.org/web/*/https://shenli.dev/2020/06/20/asgi-from-scratch.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    
<p>The first time I used <a href="https://asgi.readthedocs.io/">ASGI</a>(<em>Asynchronous Server Gateway Interface</em>) was through <a href="https://github.com/django/channels">Channels</a> 1.0 when ASGI spec was still a draft. It was my first interview project which helped me get my current job at <a href="https://fellow.app/">Fellow</a>. It felt magical at that time how easy it is to add WebSocket functionality to my Django app and handles authentication and other Django related things for me seamlessly.</p>

<p>ASGI specification is now at version 3 at the time of writing and both ASGI and Channels became part of Django Software Foundation. Compared to the draft version, it has matured a lot with added lifecycle calls and better application format, etc. Most excitingly, a healthy and fast-growing community is forming and we are seeing more and more ASGI servers running in production environments. At my company, we are serving a few million requests per day through ASGI running on <a href="https://github.com/django/daphne">Daphne</a>, Netflix’s <a href="https://netflixtechblog.com/introducing-dispatch-da4b8a2a8072">Dispatch</a> is based on <a href="https://fastapi.tiangolo.com/">FastAPI</a>, a popular ASGI web application framework, and apparently, Microsoft is <a href="https://github.com/tiangolo/fastapi/pull/26">using it</a> too.</p>

<p>I would humbly advise anyone building web services in Python to learn about ASGI. And the best way to learn something is to built things with it, so in this blog post, I’ll walk through the steps to build a micro web application framework that speaks ASGI. I hope it can help explain how ASGI works.</p>


<p>Before writing the first line of code, we need to have a basic understanding of what ASGI is and what we are building towards.</p>
<h2 id="how-asgi-works">How ASGI works</h2>
<p>Here’s a simple diagram showing how ASGI works at a high level.</p>
<pre><code>graph TD
	A[Client] --&gt;|HTTP, WebSocket, ...| B(ASGI Server)
	B --&gt; |scope, send, receive| C(ASGI application)
</code></pre>
<p>To put it in simple words, A browser(client), establishes a connection to ASGI server with a certain type of request (HTTP or WebSocket), the ASGI server then calls ASGI  application with information about the connection, encapsulated in a python dictionary called <code>scope</code>, and two callbacks, named <code>send</code> and <code>receive</code>, that the application can use to send and receive messages between server and client.</p>

<p>Here’s an example HTTP request scope</p>
<div><div><pre><code><span>{</span>
    <span>"type"</span><span>:</span> <span>"http"</span><span>,</span>
    <span>"http_version"</span><span>:</span> <span>"1.1"</span><span>,</span>
    <span>"server"</span><span>:</span> <span>(</span><span>"127.0.0.1"</span><span>,</span> <span>8000</span><span>),</span>
    <span>"client"</span><span>:</span> <span>(</span><span>"127.0.0.1"</span><span>,</span> <span>60457</span><span>),</span>
    <span>"scheme"</span><span>:</span> <span>"http"</span><span>,</span>
    <span>"method"</span><span>:</span> <span>"GET"</span><span>,</span>
    <span>"root_path"</span><span>:</span> <span>""</span><span>,</span>
    <span>"path"</span><span>:</span> <span>"/hello/a"</span><span>,</span>
    <span>"raw_path"</span><span>:</span> <span>b"/hello/a"</span><span>,</span>
    <span>"query_string"</span><span>:</span> <span>b""</span><span>,</span>
    <span>"headers"</span><span>:</span> <span>[</span>
        <span>(</span><span>b"host"</span><span>,</span> <span>b"localhost:8000"</span><span>),</span>
        <span>(</span><span>b"connection"</span><span>,</span> <span>b"keep-alive"</span><span>),</span>
        <span>(</span>
            <span>b"user-agent"</span><span>,</span>
            <span>b"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.106 Safari/537.36"</span><span>,</span>
        <span>),</span>
        <span>(</span>
            <span>b"accept"</span><span>,</span>
            <span>b"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9"</span><span>,</span>
        <span>),</span>
        <span>(</span><span>b"accept-encoding"</span><span>,</span> <span>b"gzip, deflate, br"</span><span>),</span>
        <span>(</span><span>b"accept-language"</span><span>,</span> <span>b"en-US,en;q=0.9"</span><span>),</span>
        <span>(</span>
            <span>b"cookie"</span><span>,</span>
            <span>b'csrftoken=dDA2IAPrvgPc7hkyBSyctxDk78KmhHAzUqR0LUpjXI3Xgki0QrGEWazE3RGZuLGl'</span><span>,</span>
        <span>),</span>
    <span>],</span>
<span>}</span>
</code></pre></div></div>

<p>You might notice that <code>scope</code> is not too different from a WSGI <code>environ</code>. In fact, ASGI interface is very similar to WSGI interface, but instead of getting a <code>environ</code> and <code>start_response</code> to send headers and using the return value of WSGI application as the response body, ASGI interfaces with the connection and allows us to receive and send messages multiple times during the lifecycle of the connection <strong>asynchronously</strong> until the connection is closed.  This allows a nice interface for both WebSocket and HTTP.</p>

<p>It’s also totally possible to wrap a WSGI application inside an ASGI application, just prepare a WSGI <code>environ</code> and <code>start_response</code> based on <code>scope</code>, <code>receive</code>, and <code>send</code> then call the WSGI application and it would work. If you delegate that call into a thread pool or something similar, you just made your WSGI application asynchronous. This is roughly how Channels wraps around Django.</p>

<h2 id="define-asgi-framework">Define ASGI framework</h2>
<p>When I say ASGI framework I refer it as a framework that makes building ASGI application easier and this does not include the ASGI server part. I’m mentioning this because some of the earlier Python asynchronous web frameworks have their own server implementation that also takes over tasks such as parsing  HTTP requests, handles network connections, etc. We are not doing those in ASGI web framework. As a spiritual successor to WSGI, where web servers, such as Gunicorn and uwsgi, and web frameworks, such as Flask and Django, are separated, ASGI has this separation too.</p>

<p>So, what does an ASGI application look like?</p>

<h3 id="asgi-hello-world">ASGI Hello World</h3>
<p>A simple ASGI hello world application can be written as:</p>
<div><div><pre><code><span>async</span> <span>def</span> <span>application</span><span>(</span><span>scope</span><span>,</span> <span>receive</span><span>,</span> <span>send</span><span>):</span>
    <span>name</span> <span>=</span> <span>scope</span><span>[</span><span>"path"</span><span>].</span><span>split</span><span>(</span><span>"/"</span><span>,</span> <span>1</span><span>)[</span><span>-</span><span>1</span><span>]</span> <span>or</span> <span>"world"</span>
    <span>await</span> <span>send</span><span>(</span>
        <span>{</span>
            <span>"type"</span><span>:</span> <span>"http.response.start"</span><span>,</span>
            <span>"status"</span><span>:</span> <span>200</span><span>,</span>
            <span>"headers"</span><span>:</span> <span>[[</span><span>b"content-type"</span><span>,</span> <span>b"text/plain"</span><span>],],</span>
        <span>}</span>
    <span>)</span>
    <span>await</span> <span>send</span><span>(</span>
        <span>{</span>
            <span>"type"</span><span>:</span> <span>"http.response.body"</span><span>,</span>
            <span>"body"</span><span>:</span> <span>f"Hello, </span><span>{</span><span>name</span><span>}</span><span>!"</span><span>.</span><span>encode</span><span>(),</span>
            <span>"more_body"</span><span>:</span> <span>False</span><span>,</span>
        <span>}</span>
    <span>)</span>
</code></pre></div></div>
<p><code>http.response.start</code> starts an HTTP response sending status code and response headers. In this example, it responds with the 200 OK status code and  has <code>content-type</code> set to <code>text/plain</code> in the headers.  <code>http.response.body</code> sends the response body, the <code>more_body</code> key tells the server if the response is finished. ASGI server might use this to know if a connection should be closed or automatically decide between a <code>content-length</code> header or a chunked encoding.</p>

<p>We can run the application with <a href="https://www.uvicorn.org/">uvicorn</a>:</p>
<div><div><pre><code>uvicorn asgi-hello:application
</code></pre></div></div>
<p>And you should be able to visit <code>http://localhost:8000/</code> and get <code>Hello, world</code>.Visiting <code>http://localhost:8000/tom</code> would get you <code>Hello, tom</code>.</p>

<blockquote>
  <p>By the way, uvicorn is pretty fast, a simple benchmark with <code>wrk -d10s http://localhost:8000/hi</code> on a 2018 lowest spec MacBook Air yields <code>Requests/sec:  27857.87</code>.</p>
</blockquote>

<p>Although this approach works with a simple hello world example, it’s not exactly convenient to write a more complex application this way. For one, it doesn’t do routing, if you want to respond differently for different paths, you’ll probably end up with a huge  <code>if ... else if ... else</code> clause. Secondly, having to write the ASGI message every time in the form of a python dict is quite arduous. Third, in a complex application, it gets harder to track the status of the connection, such as is the response started, is the response ended, should I start the response here, etc.</p>

<h3 id="goal">Goal</h3>
<p>With the new framework, I hope to be able to write an ASGI application like this:</p>
<div><div><pre><code><span>import</span> <span>asyncio</span>
<span>from</span> <span>aaf</span> <span>import</span> <span>aaf</span> <span># Another ASGI framework
</span><span>from</span> <span>aaf.routing</span> <span>import</span> <span>Router</span>
<span>from</span> <span>aaf.response</span> <span>import</span> <span>HttpResponse</span>

<span>router</span> <span>=</span> <span>Router</span><span>()</span>

<span>@</span><span>router</span><span>.</span><span>route</span><span>(</span><span>'/'</span><span>)</span>
<span>@</span><span>router</span><span>.</span><span>route</span><span>(</span><span>'/&lt;name&gt;'</span><span>)</span>
<span>async</span> <span>def</span> <span>hello</span><span>(</span><span>connection</span><span>,</span> <span>name</span><span>=</span><span>'world'</span><span>):</span>
	<span>return</span> <span>HttpResponse</span><span>(</span><span>f"Hello, </span><span>{</span><span>name</span><span>}</span><span>"</span><span>)</span>


<span>@</span><span>router</span><span>.</span><span>route</span><span>(</span><span>'/count'</span><span>)</span>
<span>@</span><span>router</span><span>.</span><span>route</span><span>(</span><span>'/count/&lt;int:number&gt;'</span><span>)</span>
<span>async</span> <span>def</span> <span>count</span><span>(</span><span>connection</span><span>,</span> <span>number</span><span>=</span><span>10</span><span>):</span>
	<span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>number</span><span>):</span>
		<span>await</span> <span>connection</span><span>.</span><span>send</span><span>(</span><span>f'count </span><span>{</span><span>i</span><span>}</span><span>\n</span><span>'</span><span>,</span> <span>finish</span><span>=</span><span>False</span><span>)</span>
		<span>await</span> <span>asyncio</span><span>.</span><span>sleep</span><span>(</span><span>1</span><span>)</span>
	<span>await</span> <span>connection</span><span>.</span><span>send</span><span>(</span><span>''</span><span>,</span> <span>finish</span><span>=</span><span>True</span><span>)</span>


<span>@</span><span>router</span><span>.</span><span>route</span><span>(</span><span>'/echo'</span><span>)</span>
<span>async</span> <span>def</span> <span>echo</span><span>(</span><span>connection</span><span>):</span>
	<span>body</span> <span>=</span> <span>await</span> <span>connection</span><span>.</span><span>body</span><span>()</span>
	<span>await</span> <span>connection</span><span>.</span><span>send</span><span>(</span><span>body</span><span>,</span> <span>finish</span><span>=</span><span>True</span><span>)</span>


<span>app</span> <span>=</span> <span>aaf</span><span>([</span><span>router</span><span>])</span>
</code></pre></div></div>
<p>I hope this snippet of how I want the framework to look like is self-explanatory. But here are some of the key things I want to achieve:</p>
<ol>
  <li>It should be able to handle HTTP response declaratively and imperatively.</li>
  <li>It should support Flask style routing with parameter parsing.</li>
</ol>


<h2 id="connection-class">Connection class</h2>
<p>The <code>Connection</code> class will represent an ASGI HTTP or WebSocket connection. It’s a class that encapsulates the three basic elements in ASGI, namely <code>scope</code>, <code>send</code> and <code>receive</code>, and expose some convenient methods and properties so that users don’t need to verbosely write out all the ASGI messages and parse everything, such as cookies and headers, from <code>scope</code>. But it should allow users to access the original <code>scope</code>, <code>send</code> and <code>receive</code> when they want to, so that the composability of ASGI applications is maintained. For example, it should allow user to delegate certain <code>connection</code>s to another ASGI application by calling <code>another_asgi_app(connection.scope, connectionn.asgi_send, connection.asgi_receive)</code>.</p>

<p>Here’s a simple implementation of the <code>Connection</code> class.</p>
<div><div><pre><code><span>from</span> <span>enum</span> <span>import</span> <span>Enum</span>
<span>from</span> <span>functools</span> <span>import</span> <span>cached_property</span>
<span>from</span> <span>http.cookies</span> <span>import</span> <span>SimpleCookie</span>
<span>from</span> <span>typing</span> <span>import</span> <span>Any</span><span>,</span> <span>Awaitable</span><span>,</span> <span>Callable</span><span>,</span> <span>Optional</span><span>,</span> <span>Union</span>
<span>from</span> <span>urllib.parse</span> <span>import</span> <span>parse_qsl</span><span>,</span> <span>unquote_plus</span>

<span>from</span> <span>werkzeug.datastructures</span> <span>import</span> <span>Headers</span><span>,</span> <span>MultiDict</span>

<span>CoroutineFunction</span> <span>=</span> <span>Callable</span><span>[[</span><span>Any</span><span>],</span> <span>Awaitable</span><span>]</span>


<span>class</span> <span>ConnectionType</span><span>(</span><span>Enum</span><span>):</span>
    <span>HTTP</span> <span>=</span> <span>"HTTP"</span>
    <span>WebSocket</span> <span>=</span> <span>"WebSocket"</span>


<span>class</span> <span>Connection</span><span>:</span>
    <span>def</span> <span>__init__</span><span>(</span>
        <span>self</span><span>,</span> <span>scope</span><span>:</span> <span>dict</span><span>,</span> <span>*</span><span>,</span> <span>send</span><span>:</span> <span>CoroutineFunction</span><span>,</span> <span>receive</span><span>:</span> <span>CoroutineFunction</span>
    <span>):</span>
        <span>self</span><span>.</span><span>scope</span> <span>=</span> <span>scope</span>
        <span>self</span><span>.</span><span>asgi_send</span> <span>=</span> <span>send</span>
        <span>self</span><span>.</span><span>asgi_receive</span> <span>=</span> <span>receive</span>

        <span>self</span><span>.</span><span>started</span> <span>=</span> <span>False</span>
        <span>self</span><span>.</span><span>finished</span> <span>=</span> <span>False</span>
        <span>self</span><span>.</span><span>resp_headers</span> <span>=</span> <span>Headers</span><span>()</span>
        <span>self</span><span>.</span><span>resp_cookies</span><span>:</span> <span>SimpleCookie</span> <span>=</span> <span>SimpleCookie</span><span>()</span>
        <span>self</span><span>.</span><span>resp_status_code</span><span>:</span> <span>Optional</span><span>[</span><span>int</span><span>]</span> <span>=</span> <span>None</span>

        <span>self</span><span>.</span><span>http_body</span> <span>=</span> <span>b""</span>
        <span>self</span><span>.</span><span>http_has_more_body</span> <span>=</span> <span>True</span>
        <span>self</span><span>.</span><span>http_received_body_length</span> <span>=</span> <span>0</span>

    <span>@</span><span>cached_property</span>
    <span>def</span> <span>req_headers</span><span>(</span><span>self</span><span>)</span> <span>-&gt;</span> <span>Headers</span><span>:</span>
        <span>headers</span> <span>=</span> <span>Headers</span><span>()</span>
        <span>for</span> <span>(</span><span>k</span><span>,</span> <span>v</span><span>)</span> <span>in</span> <span>self</span><span>.</span><span>scope</span><span>[</span><span>"headers"</span><span>]:</span>
            <span>headers</span><span>.</span><span>add</span><span>(</span><span>k</span><span>.</span><span>decode</span><span>(</span><span>"ascii"</span><span>),</span> <span>v</span><span>.</span><span>decode</span><span>(</span><span>"ascii"</span><span>))</span>
        <span>return</span> <span>headers</span>

    <span>@</span><span>cached_property</span>
    <span>def</span> <span>req_cookies</span><span>(</span><span>self</span><span>)</span> <span>-&gt;</span> <span>SimpleCookie</span><span>:</span>
        <span>cookie</span> <span>=</span> <span>SimpleCookie</span><span>()</span>
        <span>cookie</span><span>.</span><span>load</span><span>(</span><span>self</span><span>.</span><span>req_headers</span><span>.</span><span>get</span><span>(</span><span>"cookie"</span><span>,</span> <span>{}))</span>
        <span>return</span> <span>cookie</span>

    <span>@</span><span>cached_property</span>
    <span>def</span> <span>type</span><span>(</span><span>self</span><span>)</span> <span>-&gt;</span> <span>ConnectionType</span><span>:</span>
        <span>return</span> <span>(</span>
            <span>ConnectionType</span><span>.</span><span>WebSocket</span>
            <span>if</span> <span>self</span><span>.</span><span>scope</span><span>.</span><span>get</span><span>(</span><span>"type"</span><span>)</span> <span>==</span> <span>"websocket"</span>
            <span>else</span> <span>ConnectionType</span><span>.</span><span>HTTP</span>
        <span>)</span>

    <span>@</span><span>cached_property</span>
    <span>def</span> <span>method</span><span>(</span><span>self</span><span>)</span> <span>-&gt;</span> <span>str</span><span>:</span>
        <span>return</span> <span>self</span><span>.</span><span>scope</span><span>[</span><span>"method"</span><span>]</span>

    <span>@</span><span>cached_property</span>
    <span>def</span> <span>path</span><span>(</span><span>self</span><span>)</span> <span>-&gt;</span> <span>str</span><span>:</span>
        <span>return</span> <span>self</span><span>.</span><span>sc…</span></code></pre></div></div></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shenli.dev/2020/06/20/asgi-from-scratch.html">https://shenli.dev/2020/06/20/asgi-from-scratch.html</a></em></p>]]>
            </description>
            <link>https://shenli.dev/2020/06/20/asgi-from-scratch.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23644252</guid>
            <pubDate>Thu, 25 Jun 2020 19:04:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ARM Mac: Why I'm Worried About Virtualization]]>
            </title>
            <description>
<![CDATA[
Score 155 | Comments 302 (<a href="https://news.ycombinator.com/item?id=23642178">thread link</a>) | @bmalehorn
<br/>
June 25, 2020 | https://bmalehorn.com/arm-mac/ | <a href="https://web.archive.org/web/*/https://bmalehorn.com/arm-mac/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>It's late 2020 and you just got a brand-new Mac with Apple's own ARM processors. Exciting! But what will development be like?</p><h2>Docker</h2><p><img src="data:image/png;base64,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" width="150"></p><p>I would <strong>expect about a 5x slowdown running Docker images.</strong></p><p>Docker on a Mac utilizes a <strong>hypervisor</strong>. Hypervisors rely on running the <strong>same architecture on the host as the guest</strong>, and are about about 1x - 2x as slow as running natively.</p><p>Since you're running ARM Mac, these hypervisors can only run ARM Linux. They can't run x86_64 Linux.</p><p>What will happen instead? These tools will fall back on <strong>emulators</strong>. Emulators can run <strong>a different architecture between the host and the guest</strong>, but simulate the guest operating system at about 5x-10x slowdown.</p><div><p><img src="https://bmalehorn.com/static/perf-267ab9cfc29b6f68078fbe19892bce23.png"></p><p>A basic performance test comparing gzip performance on amd64 (hypervisor) and arm64v8 (emulator). Note that the emulator is over 6x slower. On an ARM Mac, the amd64 image will instead be 6x slower.</p></div><p>Why can't you update the Docker image to also support ARM? You theoretically could switch your backend to run ARM Linux. However, this would take months - renting out ARM instances, re-building all repositories, and a tense switch over. What if your hosting provider doesn't offer ARM instances with the same system requirements as x86_64? What if you complete this migration and find it runs at half the speed?</p><p>Worse, it might be impossible if your images include files downloaded off the internet, as those are often only compiled for x86_64.</p><div><p><img src="https://bmalehorn.com/static/phantomjs-615e9c8bc9d2deb5ca62a4533c1299d6.png"></p><p>An example of a Docker command that will only work on x86_64. PhantomJS does not release an arm build.</p></div><p>While moving your backend to ARM is far from impossible, it's a serious migration that you shouldn't take lightly. Getting a new laptop isn't enough justification to switch your backend architecture.</p><p>Another option is to <strong>run Docker remotely</strong>. You set up an x86_64 Linux server, then allow Docker to connect to it remotely. From then on, all Docker commands instead run on the server. This is also supported in Docker, <a href="https://www.digitalocean.com/community/tutorials/how-to-use-a-remote-docker-server-to-speed-up-your-workflow">here</a> is a tutorial on setting it up. This is what heavy Docker users will want to do.</p><h2>VirtualBox</h2><p><img src="https://bmalehorn.com/static/virtualbox-c37e4cc82b13d3c1c080f7ced273ae45.png" width="150"></p><p><strong>VirtualBox won't work.</strong></p><p>VirtualBox is a <strong>hypervisor</strong>. Therefore, <strong>it won't be able to run x86 Windows or x86 Linux</strong>.</p><p>You could use VirtualBox to run ARM Windows. Windows already supports ARM, and has a similar binary translation system to Apple's, so it can run x86 binaries. However, VirtualBox only supports x86 hosts and guests and is <a href="https://forums.virtualbox.org/viewtopic.php?f=8&amp;t=98742">unlikely to be ported by ARM</a>.</p><p>VMWare Fusion similarly is a hypervisor that only support x86, but <a href="https://twitter.com/VMwareFusion/status/1275483803536908288?s=20">they're thinking about supporting ARM</a>.</p><p>Instead of VirtualBox you might use QEMU, an emulator. However, QEMU is pretty low level and not often used to emulate Windows.</p><h2>Boot Camp</h2><p><img src="https://bmalehorn.com/static/boot-camp-f05493e57b0fe815dbc1d989ada98dd0.png" width="150"></p><p><strong>Boot Camp won't work.</strong></p><p><a href="https://support.apple.com/boot-camp">Boot Camp</a> is an Apple-approved way to dual-boot Mac OS and Windows. <a href="https://www.theverge.com/2020/6/24/21302213/apple-silicon-mac-arm-windows-support-boot-camp?utm_campaign=theverge&amp;utm_content=chorus&amp;utm_medium=social&amp;utm_source=twitter">Boot Camp will definitely not be available on ARM Macs</a>. It might be added later with the ability to run ARM Windows, though Microsoft <a href="https://www.theverge.com/2020/6/24/21302213/apple-silicon-mac-arm-windows-support-boot-camp">would have to approve</a>.</p><h2>Should I get an ARM Mac?</h2><p>The point of this post isn't to say that ARM Mac is a bad idea, but to give a realistic idea of what developing on one would look like assuming nothing changes. It's possible Apple could release more virtualization tools before the ARM Mac launches.</p><p>Should you get an ARM Mac if you're a developer? If you work largely on frontend, mobile, or native apps, you'll probably be fine. But if you use virtualization often, I wouldn't recommend it. There will be a lot of problems early on, and not all of them will have solutions. My biggest concern is getting an ARM Mac and realizing I simply can't run an essential application on it.</p><p>However if you like troubleshooting these issues and are excited about ARM Mac, go for it! My plan is for those kinds of people to fix these issues.</p><p>Know something I don't? Have questions? Email me at <a href="mailto:bmalehorn@gmail.com">bmalehorn@gmail.com</a>.</p></div></div>]]>
            </description>
            <link>https://bmalehorn.com/arm-mac/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23642178</guid>
            <pubDate>Thu, 25 Jun 2020 16:01:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[BLEU Score: Bilingual Evaluation Understudy]]>
            </title>
            <description>
<![CDATA[
Score 61 | Comments 12 (<a href="https://news.ycombinator.com/item?id=23641791">thread link</a>) | @keyboardman
<br/>
June 25, 2020 | https://leimao.github.io/blog/BLEU-Score/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/BLEU-Score/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>BLEU is a standard algorithm for evaluating the machine translations against the human translations. At first I thought it should be very straightforward to use. However, it turns out that there are a lot of caveats.</p>



<p>In this blog post, I am going to show the BLEU algorithm in detail and talk about the caveats.</p>

<h3 id="english-translation-example">English Translation Example</h3>

<p>We will use the following examples to illustrate how to compute the BLEU scores.</p>

<h4 id="example-1">Example 1</h4>

<p>Chinese: 猫坐在垫子上</p>

<p>Reference 1: the cat is on the mat</p>

<p>Reference 2: there is a cat on the mat</p>

<p>Candidate: the cat the cat on the mat</p>

<h4 id="example-2">Example 2</h4>

<p>Chinese: 猫坐在垫子上</p>

<p>Reference 1: the cat is on the mat</p>

<p>Reference 2: there is a cat on the mat</p>

<p>Candidate: the the the the the the the the</p>

<h3 id="precision">Precision</h3>

<p>We count each of the ngram in the candidate sentence whether it has shown in any of the reference sentences, gather the total counts for each of the unique ngram, sum up the total counts for each of the unique ngram, and divided by the number of ngrams in the candidate sentence.</p>

<h4 id="example-1-1">Example 1</h4>

<p>We first compute the unigram precision for example 1. All the unigrams in the candidate sentences have shown in the reference sentences.</p>



<table>
  <tbody><tr>
    <th>Unigram</th>
    <th>Shown?</th>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>cat</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>cat</td>
    <td>1</td>
  </tr>
  <tr>
    <td>on</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>mat</td>
    <td>1</td>
  </tr>
</tbody></table>

<p>We then merge the unigram counts.</p>



<table>
  <tbody><tr>
    <th>Unique Unigram</th>
    <th>Count</th>
  </tr>
  <tr>
    <td>the</td>
    <td>3</td>
  </tr>
  <tr>
    <td>cat</td>
    <td>2</td>
  </tr>
  <tr>
    <td>on</td>
    <td>1</td>
  </tr>
  <tr>
    <td>mat</td>
    <td>1</td>
  </tr>
</tbody></table>

<p>The total number of counts for the unique unigrams in the candidate sentence is 7, and the total number of unigrams in the candidate sentence is 7. The unigram precision is 7/7 = 1.0 for example 1.</p>



<p>We then try to compute the bigram precision for example 1.</p>



<table>
  <tbody><tr>
    <th>Bigram</th>
    <th>Shown?</th>
  </tr>
  <tr>
    <td>the cat</td>
    <td>1</td>
  </tr>
  <tr>
    <td>cat the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>the cat</td>
    <td>1</td>
  </tr>
  <tr>
    <td>cat on</td>
    <td>1</td>
  </tr>
  <tr>
    <td>on the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the mat</td>
    <td>1</td>
  </tr>
</tbody></table>

<p>We then merge the bigram counts.</p>



<table>
  <tbody><tr>
    <th>Unique Bigram</th>
    <th>Count</th>
  </tr>
  <tr>
    <td>the cat</td>
    <td>2</td>
  </tr>
  <tr>
    <td>cat the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>cat on</td>
    <td>1</td>
  </tr>
  <tr>
    <td>on the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the mat</td>
    <td>1</td>
  </tr>
</tbody></table>

<p>The total number of counts for the unique bigrams in the candidate sentence is 5, and the total number of bigrams in the candidate sentence is 6. The bigram precision is 5/6 = 0.833 for example 1.</p>

<h4 id="example-2-1">Example 2</h4>

<p>We first compute the unigram precision for example 2. All the unigrams in the candidate sentences have shown in the reference sentences.</p>



<table>
  <tbody><tr>
    <th>Unigram</th>
    <th>Shown?</th>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
</tbody></table>

<p>We then merge the unigram counts.</p>



<table>
  <tbody><tr>
    <th>Unique Unigram</th>
    <th>Count</th>
  </tr>
  <tr>
    <td>the</td>
    <td>8</td>
  </tr>
</tbody></table>

<p>The total number of counts for the unique unigrams in the candidate sentence is 8, and the total number of unigrams in the candidate sentence is 8. The unigram precision is 8/8 = 1.0 for example 2.</p>



<p>We then try to compute the bigram precision for example 2.</p>



<table>
  <tbody><tr>
    <th>Bigram</th>
    <th>Shown?</th>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
</tbody></table>

<p>We then merge the bigram counts.</p>



<table>
  <tbody><tr>
    <th>Unique Bigram</th>
    <th>Count</th>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
</tbody></table>

<p>The total number of counts for the unique bigrams in the candidate sentence is 0, and the total number of bigrams in the candidate sentence is 7. The bigram precision is 0/7 = 0 for example 2.</p>

<h4 id="drawbacks">Drawbacks</h4>

<p>We can see from example 1 and 2 that unigram precision is very easy to be over-confident about the quality of the machine translation. To overcome this, clipped count and modified precision were proposed.</p>

<h3 id="modified-precision">Modified Precision</h3>

<p>For each unique ngram, we count its maximum frequency in each of the reference sentences. The minimum of this special count and the original count is called the clipped the count. That is to say, the clipped count is no greater than the original count. We then use this clipped count, in place of the original count, for computing the modified precision.</p>

<h4 id="example-1-2">Example 1</h4>



<table>
  <tbody><tr>
    <th>Unique Unigram</th>
    <th>Count</th>
    <th>Clipped Count</th>
  </tr>
  <tr>
    <td>the</td>
    <td>3</td>
    <td>2</td>
  </tr>
  <tr>
    <td>cat</td>
    <td>2</td>
    <td>1</td>
  </tr>
  <tr>
    <td>on</td>
    <td>1</td>
    <td>1</td>
  </tr>
  <tr>
    <td>mat</td>
    <td>1</td>
    <td>1</td>
  </tr>
</tbody></table>

<p>The total number of clipped counts for the unique unigrams in the candidate sentence is 5, and the total number of unigrams in the candidate sentence is 7. The unigram modified precision is 5/7 = 0.714 for example 1.</p>



<table>
  <tbody><tr>
    <th>Unique Bigram</th>
    <th>Count</th>
    <th>Clipped Count</th>
  </tr>
  <tr>
    <td>the cat</td>
    <td>2</td>
    <td>1</td>
  </tr>
  <tr>
    <td>cat the</td>
    <td>0</td>
    <td>0</td>
  </tr>
  <tr>
    <td>cat on</td>
    <td>1</td>
    <td>1</td>
  </tr>
  <tr>
    <td>on the</td>
    <td>1</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the mat</td>
    <td>1</td>
    <td>1</td>
  </tr>
</tbody></table>

<p>The total number of clipped counts for the unique bigrams in the candidate sentence is 4, and the total number of unigrams in the candidate sentence is 6. The bigram modified precision is 4/6 = 0.667 for example 1.</p>

<h4 id="example-2-2">Example 2</h4>



<table>
  <tbody><tr>
    <th>Unique Unigram</th>
    <th>Count</th>
    <th>Clipped Count</th>
  </tr>
  <tr>
    <td>the</td>
    <td>8</td>
    <td>2</td>
  </tr>
</tbody></table>

<p>The total number of clipped counts for the unique bigrams in the candidate sentence is 0, and the total number of unigrams in the candidate sentence is 8. The unigram modified precision is 2/8 = 0.25 for example 2.</p>



<table>
  <tbody><tr>
    <th>Unique Bigram</th>
    <th>Count</th>
    <th>Clipped Count</th>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
    <td>0</td>
  </tr>
</tbody></table>

<p>The total number of clipped counts for the unique bigrams in the candidate sentence is 0, and the total number of bigrams in the candidate sentence is 7. The bigram precision is 0/7 = 0 for example 2.</p>

<h4 id="advantages">Advantages</h4>

<p>Compared to precision, we found that modified precision is a better metric, at least for unigrams.</p>

<h3 id="bleu">BLEU</h3>

<h4 id="algorithm">Algorithm</h4>

<p>BLEU is computed using a couple of ngram modified precisions. Specifically,</p>



<p>where $p_n$ is the modified precision for $n$gram, the base of $\log$ is the natural base $e$, $w_n$ is weight between 0 and 1 for $\log p_n$ and $\sum_{n=1}^{N} w_n = 1$, and BP is the brevity penalty to penalize short machine translations.</p>



<p>where $c$ is the number of unigrams (length) in all the candidate sentences, and $r$ is the best match lengths for each candidate sentence in the corpus. Here the best match length is the closest reference sentence length to the candidate sentences. For example, if there are three references with lengths 12, 14, and 17 words and the candidate translation is a terse 13 words, ideally the best match length could be either 12 or 14, but we arbitrary choose the shorter one which is 12.</p>



<p>Usually, the BLEU is evaluated on corpus where there are many candidate sentences translated from different source texts and each of them has several reference sentences. Then $c$ is the total number of unigrams (length) in all the candidate sentences, and $r$ is the sum of the best match lengths for each candidate sentence in the corpus.</p>



<p>It is not hard to find that BLEU is always a value between 0 and 1. It is because BP, $w_n$, and $p_n$ are always between 0 and 1, and</p>



<p>Usually, BLEU uses $N = 4$ and $w_n = \frac{1}{N}$.</p>

<h4 id="example-1-3">Example 1</h4>

<p>We have computed the modified precision for some of the ngrams. It is not hard to compute the others. Concretely, we have</p>





<p>Because the corpus only has one translation set and thus $c = 7$ and $r = 7$</p>



<p>We plugin these values to the BLEU equation, the BLEU is</p>



<p>We further compare the BLEU to the BLEU computed using <a href="https://www.nltk.org/">NLTK</a>.</p>

<div><div><pre><code><span>&gt;&gt;&gt;</span> <span>import</span> <span>nltk</span>
<span>&gt;&gt;&gt;</span> <span>reference_1</span> <span>=</span> <span>"the cat is on the mat"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>reference_2</span> <span>=</span> <span>"there is a cat on the mat"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>candidate</span> <span>=</span> <span>"the cat the cat on the mat"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>bleu</span> <span>=</span> <span>nltk</span><span>.</span><span>translate</span><span>.</span><span>bleu_score</span><span>.</span><span>sentence_bleu</span><span>(</span><span>references</span><span>=</span><span>[</span><span>reference_1</span><span>,</span> <span>reference_2</span><span>],</span> <span>hypothesis</span><span>=</span><span>candidate</span><span>,</span> <span>weights</span><span>=</span><span>(</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>))</span>
<span>&gt;&gt;&gt;</span> <span>print</span><span>(</span><span>bleu</span><span>)</span>
<span>0.4671379777282001</span>
</code></pre></div></div>

<p>The value of <code>bleu</code> is 0.467 which is exactly matching to the BLEU we computed manually.</p>

<h4 id="example-2-3">Example 2</h4>

<p>Similarly,</p>





<p>Because the corpus only has one translation set and thus $c = 8$ and $r = 7$</p>



<p>When we plugin these values to the BLEU equation, actually we would need to compute $\log 0$ which is not mathematically defined. We use a small number $10^{-100}$ instead of $0$ for $p_2$, $p_3$ and $p_4$. The BLEU is</p>



<p>We further also compare the BLEU to the BLEU computed using <a href="https://www.nltk.org/">NLTK</a>.</p>

<div><div><pre><code><span>&gt;&gt;&gt;</span> <span>import</span> <span>nltk</span>
<span>&gt;&gt;&gt;</span> <span>reference_1</span> <span>=</span> <span>"the cat is on the mat"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>reference_2</span> <span>=</span> <span>"there is a cat on the mat"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>candidate</span> <span>=</span> <span>"the the the the the the the the"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>bleu</span> <span>=</span> <span>nltk</span><span>.</span><span>translate</span><span>.</span><span>bleu_score</span><span>.</span><span>sentence_bleu</span><span>(</span><span>references</span><span>=</span><span>[</span><span>reference_1</span><span>,</span> <span>reference_2</span><span>],</span> <span>hypothesis</span><span>=</span><span>candidate</span><span>,</span> <span>weights</span><span>=</span><span>(</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>))</span>
<span>&gt;&gt;&gt;</span> <span>print</span><span>(</span><span>bleu</span><span>)</span>
<span>1.2882297539194154e-231</span>
</code></pre></div></div>

<p>The value of <code>bleu</code> is 0 which is exactly matching to the BLEU we computed manually.</p>

<p>Note that in the above two examples, due to the candidate sentence is long and we only have one translation in the corpus, thus $\text{BP} = 1$. In practice, there could be scenarios where $\text{BP} &lt; 1$.</p>

<h3 id="caveats">Caveats</h3>

<p>In some scenarios, BLEU does not score the translation very well, especially for those short translations with few reference sentences. For example,</p>



<p>Chinese: 你准备好了吗？</p>

<p>Reference 1: are you ready ?</p>

<p>Candidate: you are ready ?</p>

<div><div><pre><code><span>&gt;&gt;&gt;</span> <span>import</span> <span>nltk</span>
<span>&gt;&gt;&gt;</span> <span>reference_1</span> <span>=</span> <span>"are you ready ?"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>candidate</span> <span>=</span> <span>"you are ready ?"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>bleu</span> <span>=</span> <span>nltk</span><span>.</span><span>translate</span><span>.</span><span>bleu_score</span><span>.</span><span>sentence_bleu</span><span>(</span><span>references</span><span>=</span><span>[</span><span>reference_1</span><span>],</span> <span>hypothesis</span><span>=</span><span>candidate</span><span>,</span> <span>weights</span><span>=</span><span>[</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>])</span>
<span>&gt;&gt;&gt;</span> <span>print</span><span>(</span><span>bleu</span><span>)</span>
<span>1.133422688662942e-154</span>
</code></pre></div></div>

<p>This is actually a very good machine translation to me. However, the BLEU score is 0, which means that the machine translation is totally wrong.</p>



<p>In NLTK, you are allowed to provide <a href="https://www.nltk.org/api/nltk.translate.html#nltk.translate.bleu_score.SmoothingFunction">smoothing functions</a>. For example,</p>

<div><div><pre><code><span>&gt;&gt;&gt;</span> <span>import</span> <span>nltk</span>
<span>&gt;&gt;&gt;</span> <span>reference_1</span> <span>=</span> <span>"are you ready ?"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>candidate</span> <span>=</span> <span>"you are ready ?"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>bleu</span> <span>=</span> <span>nltk</span><span>.</span><span>translate</span><span>.</span><span>bleu_score</span><span>.</span><span>sentence_bleu</span><span>(</span><span>references</span><span>=</span><span>[</span><span>reference_1</span><span>],</span> <span>hypothesis</span><span>=</span><span>candidate</span><span>,</span> <span>weights</span><span>=</span><span>[</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>],</span> <span>smoothing_function</span><span>=</span><span>nltk</span><span>.</span><span>translate</span><span>.</span><span>bleu_score</span><span>.</span><span>SmoothingFunction</span><span>().</span><span>method7</span><span>)</span>
<span>&gt;&gt;&gt;</span> <span>print</span><span>(</span><span>bleu</span><span>)</span>
<span>0.4002926439114545</span>
</code></pre></div></div>

<p>This time, the value of <code>bleu</code> is 0.4, which is magically higher than the vanilla one we computed without using smoothing functions.</p>



<p>However, one should be always cautious about the smoothing function used in BLEU computation. At least we have to make sure that the BLEU scores we are comparing against are using no smoothing function or the exact same smoothing function.</p>

<h3 id="references">References</h3>

<ul>
  <li><a href="https://www.aclweb.org/anthology/P02-1040/">BLEU: a Method for Automatic Evaluation of Machine Translation</a></li>
  <li><a href="https://www.youtube.com/watch?v=DejHQYAGb7Q">BLEU - Andrew Ng</a></li>
</ul>

      <hr>
      
    </div></div>]]>
            </description>
            <link>https://leimao.github.io/blog/BLEU-Score/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23641791</guid>
            <pubDate>Thu, 25 Jun 2020 15:27:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Permacomputing]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 23 (<a href="https://news.ycombinator.com/item?id=23641719">thread link</a>) | @ibobev
<br/>
June 25, 2020 | http://viznut.fi/texts-en/permacomputing.html | <a href="https://web.archive.org/web/*/http://viznut.fi/texts-en/permacomputing.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">



<p>This is a collection of random thoughts regarding the application of
permacultural ideas to the computer world.</p>

<p>Some have tried to connect these worlds before (<a href="http://wiki.c2.com/?PermaCulture">WikiWikiWeb's Permaculture
article</a>; <a href="https://en.wikipedia.org/wiki/Kent_Beck">Kent
Beck</a>'s short-lived idea of <a href="https://www.softwarequotes.com/showquotes.aspx?id=559&amp;name=Kent%20Beck">Permaprogramming</a>),
but these have mostly concentrated on enhancing software engineering
practices with some ideas from gardening. I am more interested in the aspect
of cultural and ecological permanence. That is, how to give computers a
meaningful and sustainable place in a human civilization that has a
meaningful and sustainable place in the planetary biosphere.</p>

<h2>1. Problem</h2>

<p>Over the last few hundred years of human civilization, there has been a
dramatic increase in the consumption of artificially produced energy. In the
overarching story, this is often equated with "progress".</p>

<p>In the computer world, this phenomenon gets multiplied by itself:
"progress" facilitates ever greater densities of data storage and digital
logic, thus dramatically exploding the availability of computing resources.
However, the abundance has also caused an equivalent explosion in
wastefulness, which shows in things like mindblowingly ridiculous hardware
requirements for even quite trivial tasks.</p>

<p>At the same time, computers have been failing their <a href="https://en.wikipedia.org/wiki/Computer_Lib/Dream_Machines">utopian
expectations</a>. Instead of amplifying the users' intelligence, they rather
amplify their stupidity. Instead of making it possible to scale down the
resource requirements of the material world, they have instead become a
major part of the problem. Instead of making the world more comprehensible,
they rather add to its incomprehensibility. And they often even manage to
become slower despite becoming faster.</p>

<p>In both computing and agriculture, a major issue is that problems are too
often "solved" by increasing controllability and resource use. Permaculture
takes another way, advocating methods that "let nature do the work" and thus
minimize the dependence on artificial energy input. Localness and
decentralization are also major themes in the thought.</p>

<p>What makes permacultural philosophy particularly appealing (to me) is
that it does not advocate "going back in time" despite advocating a dramatic
decrease in use of artificial energy. Instead, it trusts in human ingenunity
in finding clever hacks for turning problems into solutions, competition
into co-operation, waste into resources. Very much the same kind of creative
thinking I appreciate in computer hacking.</p>

<p>The presence of intelligent life in an ecosystem can be justified by its
strengthening effect. Ideally, humans could make ecosystems more flexible
and more resilient because of their ability to take leaps that are difficult
or impossible for "unintelligent" natural processes. The existence of
computers in a human civilization can be justified by their ability to
augment this potential.</p>

<h2>2. Physical resources</h2>

<h3>2.1. Energy</h3>

<p>Permaculture emphasizes resource-sensitivity. Computers primarily use
electricity, so to them resource-sensitivity primarily means 1) adapting to
changes in energy conditions and 2) using the available energy wisely.
Today's computers, even mobile ones, are surprisingly bad at this. This is
partially due to their legacy as "calculation factories" that are constantly
guaranteed all the resources they "need".</p>

<p>Intense non-urgent computation (such as long machine learning batches)
would take place only when a lot of surplus energy is being produced or
there is a need for electricity-to-heat conversion. This requires that the
computer is aware of the state of the surrounding energy system.</p>

<p>At times of low energy, both hardware and software would prefer to scale
down: background processes would freeze, user interfaces would become more
rudimentary, clock frequencies would decrease, unneeded processors and
memory banks would power off. At these times, people would prefer to do
something else than interact with computers.</p>

<p>It is often wise to store energy for later use. <a href="https://en.wikipedia.org/wiki/Flywheel_energy_storage">Flywheels</a>
are a potential alternative to chemical batteries. They have similar <a href="https://en.wikipedia.org/wiki/Energy_density">energy densities</a>
(MJ/kg) but require no rare-earth materials and last for decades or
centuries instead of mere years.</p>

<h3>2.2. Silicon</h3>

<p>IC fabrication requires large amounts of energy, highly refined machinery
and poisonous substances. Because of this sacrifice, the resulting
microchips should be treasured like gems or rare exotic spices. Their active
lifespans would be maximized, and they would never be reduced to their raw
materials until they are thoroughly unusable.</p>

<p>Instead of planned obsolescence, there should be planned longevity.</p>

<p>Broken devices would be repaired. If the community needs a kind of device
that does not exist, it should preferrably be built from existing components
that have fallen out of use. Chips should be designed open and flexible, so
that they can be reappropriated even for purposes they were never intended
for.</p>

<p>Complex chips should have enough redundancy and bypass mechanisms to keep
them working even after some of their internals wear out. (In a multicore
CPU, for instance, many partially functioning cores could combine into one
fully functioning one.)</p>

<p>Chips that work but whose practical use cannot be justified can find
artistic and other psychologically meaningful use. They may also be stored
away until they are needed again (especially if the fabrication quality and
the storage conditions allow for decades or centuries of "shelf life").</p>

<p>Use what is available. Even chips that do "evil" things are worth
considering if there's a landfill full of them. Crack their DRM locks,
reverse-engineer their black boxes, deconstruct their philosophies. It might
even be possible to reappropriate something like Bitcoin-mining ASICs for
something artistically interesting or even useful.</p>

<p>Minimized on-chip feature size makes it possible to do more computation
with less energy but it often also means increased fragility and shorter
lifespans. Therefore, the densest chips should be primarily used for
purposes where more computation actually yields more. (In entertainment use,
for example, a large use of resources is nothing more than a decadent
esthetic preference.)</p>

<p><a href="https://en.wikipedia.org/wiki/Unconventional_computing">Alternatives
to semiconductors</a> should be actively researched. <a href="https://www.researchgate.net/publication/328395242_Towards_fungal_computer">Living
cells</a> might be able to replace microchips in some tasks sometime in the
future.</p>

<p>Once perfectly clean ways of producing microchip equivalents have been
taken to use, the need for "junk fetishism" will probably diminish.</p>

<h3>2.3. Miscellaneous</h3>

<p>Whenever bright external light is available, displays should be able to
use it instead of competing against it with their own backlight. (See: <a href="https://en.wikipedia.org/wiki/Transflective_liquid-crystal_display">Transflective
LCD</a>)</p>

<p>Personally-owned computers are primarily for those who dedicate
themselves to the technology and thus spend considerable amounts of time
with it. Most other people would be perfectly happy with shared hardware.
Even if the culture and society embraced computers more than anything else,
requiring everyone to own one would be an overkill.</p>

<h2>3. Observation and interaction</h2>

<p>The first item in many lists of permacultural principles is "Observe and
interact." I interpret this as primarily referring to a bidirectional and
co-operative relationship with natural systems: you should not expect your
garden to be easily top-down controllable like an army unit but accept its
quirkiness and adapt to it.</p><h3>3.1. Observation</h3>

<p>Observation is among the most important human skills computers can augment.
Things that are difficult or impossible for humans to observe can be brought
within human cognitive capacity by various computational processes. Gathered
information can be visualized, slight changes and pattern deviances
emphasized, slow processes sped up, forecasts calculated. In Bill Mollison's
words, "Information is <em>the</em> critical potential resource. It becomes
a resource only when obtained and acted upon."</p>

<p>Computer systems should also make their own inner workings as observable as
possible. If the computer produces visual output, it would use a fraction of
its resources to visualize its own intro- and extrospection. A computer that
communicates with radio waves, for example, would visualize its own view of
the surrounding radio landscape.</p>

<p>Current consumer-oriented computing systems often go to ridiculous
lengths to actually prevent the user from knowing what is going on. Even
error messages have become unfashionable; many websites and apps just
pretend everything is fine even if it isn't. This kind of extreme
unobservability is a major source of technological alienation among computer
users.</p>

<p>The visualizations intended for casual and passive observation would be
pleasant and tranquil while making it easy to see the big picture and notice
the small changes. Tapping into the inborn human tendency to observe the
natural environment may be a good idea when designing visualizers. When the
user wants to observe something more closely, however, there is no limit in
how flashy, technical and "non-natural" the presentation can be, as long as
the observer prefers it that way.</p>

<h3>3.2. Yin and yang hacking</h3>

<p>Traditional computer hacking is often very "yang". A total understanding and
control of the target system is valued. Changing a system's behavior is
often an end in itself. There are predefined goals the system is pushed
towards. Optimization tends to focus on a single measurable parameter.
Finding a system's absolute limits is more important than finding its
individual strengths or essence.</p>

<p>In contrast, "yin" hacking accepts the aspects that are beyond rational
control and comprehension. Rationality gets supported by intuition. The
relationship with the system is more bidirectional, emphasizing
experimentation and observation. The "personality" that stems from
system-specific peculiarities gets more attention than the measurable specs.
It is also increasingly important to understand when to hack and when just
to observe without hacking.</p>

<p>The difference between yin and yang hacking is similar to the difference
between permaculture and …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://viznut.fi/texts-en/permacomputing.html">http://viznut.fi/texts-en/permacomputing.html</a></em></p>]]>
            </description>
            <link>http://viznut.fi/texts-en/permacomputing.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23641719</guid>
            <pubDate>Thu, 25 Jun 2020 15:20:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Logistic regression from scratch]]>
            </title>
            <description>
<![CDATA[
Score 152 | Comments 60 (<a href="https://news.ycombinator.com/item?id=23640762">thread link</a>) | @pmuens
<br/>
June 25, 2020 | https://philippmuens.com/logistic-regression-from-scratch/ | <a href="https://web.archive.org/web/*/https://philippmuens.com/logistic-regression-from-scratch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>You can find working code examples (including this one) in my <a href="https://github.com/pmuens/lab">lab repository</a> on <a href="https://github.com/pmuens">GitHub</a>.</p><p>Sometimes it's necessary to split existing data into several classes in order to predict new, unseen data. This problem is called <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a> and one of the algorithms which can be used to learn those classes from data is called Logistic Regression.</p><p>In this article we'll take a deep dive into the Logistic Regression model to learn how it differs from other regression models such as <a href="https://en.wikipedia.org/wiki/Linear_regression">Linear-</a> or <a href="https://en.wikipedia.org/wiki/Linear_regression#Simple_and_multiple_linear_regression">Multiple Linear Regression</a>, how to think about it from an intuitive perspective and how we can translate our learnings into code while implementing it from scratch.</p><h2 id="linear-regression-vs-logistic-regression">Linear Regression vs. Logistic Regression</h2><p>If you've read the post about <a href="https://philippmuens.com/linear-and-multiple-regression-from-scratch/">Linear- and Multiple Linear Regression</a> you might remember that the main objective of our algorithm was to find a best fitting line or <a href="https://en.wikipedia.org/wiki/Hyperplane">hyperplane</a> respectively.</p><p>To recap real quick, a line can be represented via the slop-intercept form as follows:</p><p>\[ y = mx + b \]</p><p>Here, \(m\) represents the slope and \(b\) the y-intercept.</p><p>In Linear Regression we've used the existing data to find a line in slope-intercept form (a \(m\) and \(b\) combination) which "best-fitted through" such data.</p><p>Extending the slope-intercept form slightly to support multiple \(x\) values and multiple slopes (we'll use \(\beta_n\) instead of \(m_n\)) yields the following:</p><p>\[ y = &nbsp;\beta_1x_1 + ... + \beta_nx_n + b \]</p><p>This "scaled-up" slope-intercept formula was used in the <a href="https://en.wikipedia.org/wiki/Linear_regression#Simple_and_multiple_linear_regression">Multiple Linear Regression</a> model to find the \(\beta\) and \(b\) values for the <a href="https://en.wikipedia.org/wiki/Hyperplane">hyperplane</a> which "best-fitted" the data. Once found we were able to use it for predictions by plugging in \(x\) values to get respective \(y\) values.</p><p>Linear Regression models always map a set of \(x\) values to a resulting \(y\) value on a <a href="https://en.wikipedia.org/wiki/Continuous_function">continuous</a> scale. This means that the \(y\) value can e.g. be \(0\), \(42\) or \(5.023.212\). How would we use such a Regression model if our \(y\) value is categorical such as a binary value which is either \(0\) or \(1\)? Is there a way to define a threshold so that a value such as \(42\) is assigned to the category \(1\) while a small value such as \(0.002\) gets assigned to the category \(0\)?</p><p>That's where Logistic Regression comes into play. With Logistic Regression we can map any resulting \(y\) value, no matter its magnitude to a value between \(0\) and \(1\).</p><p>Let's take a closer look into the modifications we need to make to turn a Linear Regression model into a Logistic Regression model.</p><h2 id="sigmoid-functions">Sigmoid functions</h2><p>At the very heart of Logistic Regression is the so-called <a href="https://en.wikipedia.org/wiki/Sigmoid_function">Sigmoid function</a>. A Sigmoid function is a class of functions which follows an S-shape when plotted.</p><p>The most prominent Sigmoid function is the so-called <a href="https://en.wikipedia.org/wiki/Logistic_function">Logistic function</a> which was developed by <a href="https://en.wikipedia.org/wiki/Pierre_Fran%C3%A7ois_Verhulst">Pierre Francois Verhulst</a> to model <a href="https://en.wikipedia.org/wiki/Population_growth">population grown</a>. It's mathematically described via this formula:</p><p>\[ f(x) = \frac{1}{1+e^{-x}} \]</p><p>Don't be intimidated by the math! Right now all you need to know is that this function takes any \(x\) value and maps it to a \(y\) value which ranges from \(0\) to \(1\).</p><p>Plotting the function for a range of \(x\) values proofs this claim and results in the aforementioned S-shape curve:</p><figure><img src="https://philippmuens.com/content/images/2020/06/zsigmoid_result.png"></figure><p>Note that the function gets closer and closer to the \(y\) value \(0\) or \(1\) as the \(x\) values get smaller or larger respectively. Also note that the \(x\) value \(0\) results in the \(y\) value \(0.5\).</p><p>This is exactly what we need. with this function we're able to "squish" any number, no matter its magnitude into a value ranging from \(0\) to \(1\). This makes the function outcome predictable which is useful when we later on define threshold values to associate function outputs with classes.</p><p>Let's turn the function into code:</p><pre><code>def sigmoid(x: float) -&gt; float:
    return 1 / (1 + exp(-x))

assert sigmoid(0) == 0.5</code></pre><p><strong><u>Note</u></strong>: Although there are many <a href="https://en.wikipedia.org/wiki/Sigmoid_function#Examples">different Sigmoid functions</a> to choose from, a lot of people use the name "Sigmoid function" when talking about the Logistic function. We'll adhere to this convention and use the term "Sigmoid function" as a synonym for Logistic function.</p><h2 id="from-linear-regression-to-logistic-regression">From Linear Regression to Logistic Regression</h2><p>Now that we've learned about the "mapping" capabilities of the Sigmoid function we should be able to "wrap" a Linear Regression model such as <a href="https://en.wikipedia.org/wiki/Linear_regression#Simple_and_multiple_linear_regression">Multiple Linear Regression</a> inside of it to turn the regressions raw output into a value ranging from \(0\) to \(1\).</p><p>Let's translate this idea into Math. Recall that our Multiple Linear Regression model looks like this:</p><p>\[ y = &nbsp;\beta_1x_1 + ... + \beta_nx_n + b \]</p><p>"Wrapping" this in the Sigmoid function (we use \(\sigma\) to represent the Sigmoid function) results in the following:</p><p>\[ y = \sigma(\beta_1x_1 + ... + \beta_nx_n + b) \]</p><p>Easy enough! Let's turn that into code.</p><p>The first thing we need to do is to implement the underlying Multiple Linear Regression model. Looking at the Math it seems to be possible to use the <a href="https://en.wikipedia.org/wiki/Dot_product">dot-product</a> to calculate the \(\beta\) and \(x\) part to which we then add the single \(b\) value.</p><p>To make everything easier to calculate and implement we'll use a small trick. Multyping a value by the identify \(1\) yields the value so we prepend \(1\) to the \(x\) values and \(b\) to the \(\beta\) values. This way we can solely use the dot-product calculation without the necessity to add \(b\) separately later on. Here's the mathematical formulation of that trick:</p><p>\[ \vec{x} = \begin{pmatrix} 1 \\ x_1 \\ ... \\ x_n \end{pmatrix} \vec{\beta} = \begin{pmatrix} b \\ \beta_1 \\ ... \\ \beta_n \end{pmatrix} \]</p><p>\[ y = \vec{x} \cdot \vec{m} = \sum_{i=1}^n x_i \beta_i = x_1 \times \beta_1 + ... + x_n \times \beta_n \]</p><p>Once we've calculated the dot-product we need to pass it into the Sigmoid function such that its result is translated ("squished") into a value between \(0\) and \(1\).</p><p>Here's the implementation for the <code>dot</code> function which calculates the <a href="https://en.wikipedia.org/wiki/Dot_product">dot-product</a>:</p><pre><code>def dot(a: List[float], b: List[float]) -&gt; float:
    assert len(a) == len(b)
    return sum([a_i * b_i for a_i, b_i in zip(a, b)])

assert dot([1, 2, 3, 4], [5, 6, 7, 8]) == 70</code></pre><p>And here's the <code>squish</code> function which takes as parameters the \(x\) and \(\beta\) values (remember that we've prepended a \(1\) to the \(x\) values and the \(b\) to the \(\beta\) values), uses the <code>dot</code> function to calculate the dot-product of \(x\) and \(\beta\) and then passes this result into the Sigmoid function to map it to a value between \(0\) and \(1\):</p><pre><code>def squish(beta: List[float], x: List[float]) -&gt; float:
    assert len(beta) == len(x)
    # Calculate the dot product
    dot_result: float = dot(beta, x)
    # Use sigmoid to get a result between 0 and 1
    return sigmoid(dot_result)

assert squish([1, 2, 3, 4], [5, 6, 7, 8]) == 1.0</code></pre><h2 id="the-intuition-behind-the-0-1-range">The intuition behind the 0-1 range</h2><p>We've talked quite a lot about how the Sigmoid function is our solution to make the function outcome predictable as all values are mapped to a \(0\) - \(1\) range. But what does a value in that range represent? Let's take a look at an example.</p><p>The following is a data set which describes how long students have studied for an exam and whether they've passed the exam given the hours they've studied.</p><!--kg-card-begin: html--><table>
    <thead>
        <tr>
            <th>Hours studied</th>
            <th>Exam Passed</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>0,5</td>
            <td>0</td>
        </tr>
        <tr>
            <td>1,0</td>
            <td>0</td>
        </tr>
        <tr>
            <td>1,5</td>
            <td>0</td>
        </tr>
        <tr>
            <td>2,0</td>
            <td>0</td>
        </tr>
        <tr>
            <td>2,5</td>
            <td>1</td>
        </tr>
        <tr>
            <td>3,0</td>
            <td>0</td>
        </tr>
        <tr>
            <td>3,5</td>
            <td>1</td>
        </tr>
        <tr>
            <td>4,0</td>
            <td>1</td>
        </tr>
        <tr>
            <td>4,5</td>
            <td>0</td>
        </tr>
        <tr>
            <td>5,0</td>
            <td>1</td>
        </tr>
        <tr>
            <td>5,5</td>
            <td>1</td>
        </tr>
        <tr>
            <td>6,0</td>
            <td>1</td>
        </tr>
    </tbody>
</table><!--kg-card-end: html--><p>Taking a glance at the data it seems to be that the more hours the students studied, the more likely they were to pass the exam. Intuitively that makes sense.</p><p>Let's plot the data to ensure that our intuition is correct:</p><figure><img src="https://philippmuens.com/content/images/2020/06/zmock_student_data.png"></figure><p>Looking at the plotted data we can immediately see that the values seem to "stick" to either the bottom or top of the graph. Given that it seems to be infeasible to use a Linear Regression model to find a line which best describes the data. How would this line be fitted through the data if the values we'd expect this line should produce are either \(o\) or \(1\)?</p><p>Let's try a thought experiment. What would happen if we've somehow found some coefficients \(\beta\) for the Linear Regression model which "best" describe the data and pass the result it computes through the Sigmoid function? Here's the graph from above with the Sigmoid function added to it:</p><figure><img src="https://philippmuens.com/content/images/2020/06/zmock_student_data_w_sigmoid.png"></figure><p>Looking at the plotting above we can see that the Sigmoid function ensures that the result from the "underlying" Linear Regression model is mapped onto a scale between \(0\) and \(1\), which in turn makes it possible to e.g. define a threshold at \(0.5\) to say that a value which is greater than \(0.5\) might be a predictor for a student passing the exam while a value less than \(0.5\) might mean that she'll fail the exam.</p><p>Note that the wording in the last sentence isn't a coincidence. The value the Signoid function produces can be interpreted as a probability where \(0\) means \(0%\) probability and \(1\) means a \(100%\) probability.</p><h2 id="the-probability-density-function">The Probability Density Function</h2><p>As it turns out we can translate our findings from the previous section into a function called <a href="https://en.wikipedia.org/wiki/Probability_density_function">Probability density function</a> or (PDF for short).</p><p>In particular we can define a <a href="https://en.wikipedia.org/wiki/Conditional_probability">conditional probability</a> which states that given some \(\beta\) and \(x_i\), each corresponding \(y_i\) should equal \(1\) with probability \(\sigma(\beta x_i)\) and \(0\) with probability \(1-\sigma(\beta x_i)\):</p><p>\[ P(y_i \mid \beta x_i) = \sigma(\beta x_i)^{y_i} \times (1-\sigma(\beta x_i))^{1-y_i} \]</p><p>Looking at the formula above it might be a mystery how we deduced it from our verbal description from above. Here's something I want you to try: Please apply the formula by setting \(y_i\) to \(0\) and after that to \(1\) and see what happens. What you'll notice is that depending on what value you set \(y_i\) to, only one part of the formula stays the same while the other is canceled out.</p><p>Here's what we'll end up with if we set \(y_i\) to \(0\) and \(1\):</p><p>\[ 1-\sigma(\beta x_i) \quad \textrm{if} &nbsp;y_i = 0 \]</p><p>\[ \sigma(\beta x_i) \quad \textrm{if} &nbsp;y_i = 1 \]</p><p>And that's exactly the desired behavior we described above.</p><h2 id="deriving-a-loss-function">Deriving a Loss function</h2><p>With Logistic Regression our main objective is to find the models \(\beta\) parameters which maximize the likelihood that for a pair of \(x\) values the \(y\) value …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://philippmuens.com/logistic-regression-from-scratch/">https://philippmuens.com/logistic-regression-from-scratch/</a></em></p>]]>
            </description>
            <link>https://philippmuens.com/logistic-regression-from-scratch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23640762</guid>
            <pubDate>Thu, 25 Jun 2020 13:54:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What vertical farming and ag startups don't understand about agriculture, part 2]]>
            </title>
            <description>
<![CDATA[
Score 121 | Comments 119 (<a href="https://news.ycombinator.com/item?id=23640011">thread link</a>) | @kickout
<br/>
June 25, 2020 | http://thinkingagriculture.io/what-sv-doesnt-understand-about-agriculture-part-ii/ | <a href="https://web.archive.org/web/*/http://thinkingagriculture.io/what-sv-doesnt-understand-about-agriculture-part-ii/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-20">
		
	
	<div>
		
<p>Some commenters (/u/coderintherye chain notably) on the <a href="https://news.ycombinator.com/item?id=23630201">HN post</a> of the <a href="https://thinkingagriculture.io/what-silicon-valley-doesnt-understand-about-agriculture/">original article</a> brought up good points that I wanted to expand on and provide some additional context. Also for clarification: although farming is truly global, most ‘farming’ I refer to pertains to the United States (<a href="https://en.wikipedia.org/wiki/Agriculture_in_the_United_States">which is an agriculture juggernaut</a>), but in my experience should reasonably translate across agriculture zones (pending equivalent laws and climatic factors).</p>



<p><strong><em>There is ample VC money for Ag startups</em></strong></p>



<p>The original intention of the article wasn’t to bemoan the lack of capital available for <a href="https://agiowa.com/portfolio/">founders focused on agriculture</a> (there is actually plenty of capital–check out <a href="https://agfundernews.com/">AgFunderNews</a> for examples of successful raises). Instead, it is a recommendation for anyone entering the space to understand the industry and its history to harness existing synergies rather than try and swim upstream. Watching capital go to ‘solved’ problems is painful, because there are many opportunities for a unicorn ag startup if aimed in the correct space. Vertical farming for non-vegetables (or fruits) is likely dead-on-pitch. Yes, vertical farming <em>is</em> and <em>could be</em> successful, but those markets are very specific and probably 10x smaller than people think. Nice businesses no doubt, but not market shaping behemoths VCs are after. Agriculture is rightfully a commodity and the market will brutalize ideas/companies that can’t turn a profit. One bad year (droughts in 2011 and 2012 in the US Midwest) from external forces can absolutely put farmers out of business. Indoor farming has all of the risks of outdoor ag–and more! Indoor farming requires water (whose source can dry up and get shut off unexpectedly, just like a drought), has pests, and requires artificial lighting (power outage for 5 days? Uh oh). Herbicides (and sometimes pesticides) are actually an example of innovation pre-SV. Alternate technologies (i.e mechanical) didn’t work or were uneconomical for the time period; thus, chemical solutions seemed to thrive (glyphosate/glufosinate resistant corn/soy/wheat/cotton/sugar beets &amp; <a href="https://agrilife.org/lubbock/files/2020/02/BtTraitTable_FEB_2020.pdf">BT resistance for insects</a>). I predict in next 5-20 years we see that flip, where chemical and biological solutions fall out in favor of mechanized solutions (who wouldn’t want a semi-autonomous robot pulling weeds in fields in favor of a chemical solution that is <a href="https://www.nbcnews.com/news/us-news/bayer-reaches-10-5-billion-settlement-roundup-cancer-lawsuits-n1232026">open to litigation</a>)? We just have too little understanding of 2nd and 3rd order effects of disrupting nature at this scale (<a href="https://www.nature.com/articles/s41598-019-49660-6">gene drives included</a>, as promising as they appear) using these incredibly effective chemicals.</p>



<p><strong><em>Financing in the Heartland</em></strong></p>



<p>I won’t speak of financing agricultural operations in a municipality not located in the United States, as even understanding the US situation takes time and effort. Let’s be clear though: Most farmers <em>need</em> to borrow capital just to operate for a given year (hence, there is a note called an ‘operating loan’) and financing agriculture operations is more and more important as the size of farms increases. They buy seed, fertilizer, feed, chemicals, etc. to be able to produce an output to then (hopefully) sell at a profit–all to rinse and repeat. Buying big expensive new tractors ($300k+ USD), buildings to store the machines, grain storage, fencing, animal houses–all generally require a loan. Because of the huge cost to purchase these necessities, financing institutions generally need to have a <em>very</em> thorough understanding of the operation (Only farm 160 acres of corn,soy,or wheat? Good luck buying equipment). So bankers have become very good (not perfect) at evaluating and swaying farming practices to ensure maximum likelihood of repayment. Seriously, check of the used auction prices of ag machinery sometime–<a href="https://www.bigiron.com/Lots/2011JohnDeere8335RMFWDTractor-3">this tractor</a> is 10 years old and commands the price of a new Tesla. Is ag financing a place that needs disruption? Likely no because ag lending has evolved hand-in-hand in rural communities where agricultural production is the predominant industry. Because they evolved with ag, they likely have already captured the +EV that startups tend to seek because their very existence depends on it. So where <em>are</em> the value proposition? I know nothing of their founding, but the previous auction link is from <a href="https://www.bigiron.com/">Big Iron Auctions</a> and those founders likely understood ag (“hey, there is a robust secondary market for farm machinery”) and created on-line version of it–with what appears to be great success. I’d imagine these on-line secondary markets exist in Brazil and Eastern Europe given there agriculture exposure. </p>



<p><strong><em>Success Stories</em></strong></p>



<p>There are some truly incredible examples of engineering and innovation in agriculture that focus on the mechanization and scale <em>that already exists</em>. Transplanting vegetables in the Central Valley (CA) used to be labor intensive–<a href="https://www.planttape.com/">this brilliant solution solved that</a>. Auto-steer <a href="https://www.fieldbee.com/blog/fieldbee-tractor-autosteer-versus-other-systems/">systems</a> that leverage machinery that already exists. Sometimes the innovation is statistical/computation (<a href="https://www.annualreviews.org/doi/full/10.1146/annurev-animal-021815-111422">genomic prediction has revolutionized dairy cattle</a>) Starting businesses is hard and agriculture is no different.</p>



<p>Stay away from vertical farming–unless you plan on growing saffron or figure out a way to cultivate morel mushrooms!</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article></div>]]>
            </description>
            <link>http://thinkingagriculture.io/what-sv-doesnt-understand-about-agriculture-part-ii/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23640011</guid>
            <pubDate>Thu, 25 Jun 2020 12:44:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Faster Integer Parsing]]>
            </title>
            <description>
<![CDATA[
Score 162 | Comments 41 (<a href="https://news.ycombinator.com/item?id=23639486">thread link</a>) | @fanf2
<br/>
June 25, 2020 | https://kholdstare.github.io/technical/2020/05/26/faster-integer-parsing.html | <a href="https://web.archive.org/web/*/https://kholdstare.github.io/technical/2020/05/26/faster-integer-parsing.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
        <p>Back with a post after 6 years of silence. If you had to parse a microsecond-resolution epoch timestamp as quickly as possible, how would you do it?  We’ll take a look at using compiler intrinsics to do it in log(n) time.</p>


        <h3 id="the-problem">The problem</h3>

<p>Let’s say, theoretically, you have some text-based protocol, or file that
contains microsecond timestamps. You need to parse these timestamps as quickly
as possible. Maybe it’s json, maybe it’s a csv file, maybe something else
bespoke. It’s 16 characters long, and this could also apply to credit card
numbers.</p>

<figure><pre><code data-lang="csv">timestamp,event_id
1585201087123567,a
1585201087123585,b
1585201087123621,c</code></pre></figure>

<p>In the end you have to implement a function similar to this:</p>

<figure><pre><code data-lang="cpp"><span>std</span><span>::</span><span>uint64_t</span> <span>parse_timestamp</span><span>(</span><span>std</span><span>::</span><span>string_view</span> <span>s</span><span>)</span>
<span>{</span>
  <span>// ???</span>
<span>}</span></code></pre></figure>

<hr>

<h3 id="the-native-solution">The native solution</h3>

<p>Let’s start with what’s available, and compare. We have
<a href="https://en.cppreference.com/w/cpp/string/byte/atoi"><code>std::atoll</code></a> , a function
inherited from C,
<a href="https://en.cppreference.com/w/cpp/io/basic_stringstream"><code>std::stringstream</code></a>
, the newer C++17
<a href="https://en.cppreference.com/w/cpp/header/charconv"><code>&lt;charconv&gt;</code></a> header, and
by request
<a href="https://www.boost.org/doc/libs/1_73_0/libs/spirit/doc/html/spirit/qi/reference/basics.html"><code>boost::spirit::qi</code></a>.
I’ll be using <a href="https://github.com/google/benchmark">Google Benchmark</a> to
measure the performance, and to have a baseline let’s compare against loading
the final result into a register - i.e. no actual parsing involved.</p>

<p>Let’s run the benchmarks! The code is not important here, it just shows what is being benchmarked.</p>

<figure><pre><code data-lang="cpp"><span>static</span> <span>void</span> <span>BM_mov</span><span>(</span><span>benchmark</span><span>::</span><span>State</span><span>&amp;</span> <span>state</span><span>)</span> <span>{</span>
  <span>for</span> <span>(</span><span>auto</span> <span>_</span> <span>:</span> <span>state</span><span>)</span> <span>{</span>
    <span>benchmark</span><span>::</span><span>DoNotOptimize</span><span>(</span><span>1585201087123789</span><span>);</span>
  <span>}</span>
<span>}</span>

<span>static</span> <span>void</span> <span>BM_atoll</span><span>(</span><span>benchmark</span><span>::</span><span>State</span><span>&amp;</span> <span>state</span><span>)</span> <span>{</span>
  <span>for</span> <span>(</span><span>auto</span> <span>_</span> <span>:</span> <span>state</span><span>)</span> <span>{</span>
    <span>benchmark</span><span>::</span><span>DoNotOptimize</span><span>(</span><span>std</span><span>::</span><span>atoll</span><span>(</span><span>example_timestamp</span><span>));</span>
  <span>}</span>
<span>}</span>

<span>static</span> <span>void</span> <span>BM_sstream</span><span>(</span><span>benchmark</span><span>::</span><span>State</span><span>&amp;</span> <span>state</span><span>)</span> <span>{</span>
  <span>std</span><span>::</span><span>stringstream</span> <span>s</span><span>(</span><span>example_timestamp</span><span>);</span>
  <span>for</span> <span>(</span><span>auto</span> <span>_</span> <span>:</span> <span>state</span><span>)</span> <span>{</span>
    <span>s</span><span>.</span><span>seekg</span><span>(</span><span>0</span><span>);</span>
    <span>std</span><span>::</span><span>uint64_t</span> <span>i</span> <span>=</span> <span>0</span><span>;</span>
    <span>s</span> <span>&gt;&gt;</span> <span>i</span><span>;</span>
    <span>benchmark</span><span>::</span><span>DoNotOptimize</span><span>(</span><span>i</span><span>);</span>
  <span>}</span>
<span>}</span>
<span>static</span> <span>void</span> <span>BM_charconv</span><span>(</span><span>benchmark</span><span>::</span><span>State</span><span>&amp;</span> <span>state</span><span>)</span> <span>{</span>
  <span>auto</span> <span>s</span> <span>=</span> <span>example_timestamp</span><span>;</span>
  <span>for</span> <span>(</span><span>auto</span> <span>_</span> <span>:</span> <span>state</span><span>)</span> <span>{</span>
    <span>std</span><span>::</span><span>uint64_t</span> <span>result</span> <span>=</span> <span>0</span><span>;</span>
    <span>std</span><span>::</span><span>from_chars</span><span>(</span><span>s</span><span>.</span><span>data</span><span>(),</span> <span>s</span><span>.</span><span>data</span><span>()</span> <span>+</span> <span>s</span><span>.</span><span>size</span><span>(),</span> <span>result</span><span>);</span>
    <span>benchmark</span><span>::</span><span>DoNotOptimize</span><span>(</span><span>result</span><span>);</span>
  <span>}</span>
<span>}</span>

<span>static</span> <span>void</span> <span>BM_boost_spirit</span><span>(</span><span>benchmark</span><span>::</span><span>State</span><span>&amp;</span> <span>state</span><span>)</span> <span>{</span>
  <span>using</span> <span>boost</span><span>::</span><span>spirit</span><span>::</span><span>qi</span><span>::</span><span>parse</span><span>;</span>
  <span>for</span> <span>(</span><span>auto</span> <span>_</span> <span>:</span> <span>state</span><span>)</span> <span>{</span>
    <span>std</span><span>::</span><span>uint64_t</span> <span>result</span> <span>=</span> <span>0</span><span>;</span>
    <span>parse</span><span>(</span><span>s</span><span>.</span><span>data</span><span>(),</span> <span>s</span><span>.</span><span>data</span><span>()</span> <span>+</span> <span>s</span><span>.</span><span>size</span><span>(),</span> <span>result</span><span>);</span>
    <span>benchmark</span><span>::</span><span>DoNotOptimize</span><span>(</span><span>result</span><span>);</span>
  <span>}</span>
<span>}</span></code></pre></figure>

<figure>
    <canvas id="benchmark-canvas-native">
    </canvas>

</figure>

<p>Wow, <code>stringstream</code> is pretty bad. Not that it’s a fair comparison but parsing
a single integer using <code>stringstream</code> is 391 times slower than just loading our
integer into a register.  <code>&lt;charconv&gt;</code> and <code>boost::spirit</code> do a lot better by
comparison.</p>

<p>Since we know our string contains the number we’re trying to parse, and we
don’t need to do any whitespace skipping, can we be faster?  Just how much time
is spent in validation?</p>

<hr>

<h3 id="the-naive-solution">The naive solution</h3>

<p>Let’s write a good old for loop. Read the string character by character, and
build up the result.</p>

<figure><pre><code data-lang="cpp"><span>inline</span> <span>std</span><span>::</span><span>uint64_t</span> <span>parse_naive</span><span>(</span><span>std</span><span>::</span><span>string_view</span> <span>s</span><span>)</span> <span>noexcept</span>
<span>{</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>result</span> <span>=</span> <span>0</span><span>;</span>
  <span>for</span><span>(</span><span>char</span> <span>digit</span> <span>:</span> <span>s</span><span>)</span>
  <span>{</span>
    <span>result</span> <span>*=</span> <span>10</span><span>;</span>
    <span>result</span> <span>+=</span> <span>digit</span> <span>-</span> <span>'0'</span><span>;</span>
  <span>}</span>
  <span>return</span> <span>result</span><span>;</span>
<span>}</span></code></pre></figure>

<figure>
    <canvas id="benchmark-canvas-naive">
    </canvas>

</figure>

<p>That’s actually not bad for a simple for loop. If such a simple solution is
able to beat a standard-library implementation, it means there’s quite a lot of
effort that goes into input validation. As a sidenote - if you know your input,
or can do simpler validation you can get some significant speedups.</p>

<p>For further solutions and benchmarks, let’s ignore the standard library
functions. We should be able to go much faster than this.</p>

<hr>

<h3 id="the-brute-force-solution">The brute force solution</h3>

<p>If we know it’s 16 bytes, why even have a forloop? Let’s unroll it!</p>

<figure><pre><code data-lang="cpp"><span>inline</span> <span>std</span><span>::</span><span>uint64_t</span> <span>parse_unrolled</span><span>(</span><span>std</span><span>::</span><span>string_view</span> <span>s</span><span>)</span> <span>noexcept</span>
<span>{</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>result</span> <span>=</span> <span>0</span><span>;</span>

  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>0</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>1000000000000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>1</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>100000000000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>2</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>10000000000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>3</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>1000000000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>4</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>100000000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>5</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>10000000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>6</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>1000000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>7</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>100000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>8</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>10000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>9</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>1000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>10</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>100000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>11</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>10000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>12</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>1000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>13</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>100ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>14</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>10ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>15</span><span>]</span> <span>-</span> <span>'0'</span><span>);</span>

  <span>return</span> <span>result</span><span>;</span>
<span>}</span></code></pre></figure>

<figure>
    <canvas id="benchmark-canvas-brute-force">
    </canvas>

</figure>

<p>Ok, that’s slightly better again, but we’re still processing a character at a time.</p>

<hr>

<h3 id="the-byteswap-insight">The byteswap insight</h3>

<p>Let’s draw out the operations in the unrolled solution as a tree, on a
simplified example of parsing ‘1234’ into a 32-bit integer:</p>

<figure>
    <img width="100%" height="100%" src="https://kholdstare.github.io/diagrams/parse-unrolled.png">

<figcaption><p>Unrolled solution graph of operations for ‘1234’</p>
</figcaption>

</figure>

<p>We can see that the amount of multiplications and additions is linear with the
amount of characters. It’s hard to see how to improve this, because every
multiplication is by a different factor (so we can’t multiply “in one go”), and at
the end of the day we need to add up all the intermediate results.</p>

<p>However, it’s still very regular. For one thing, the first character in the
string is multiplied by the largest factor, because it is the most significant
digit.</p>

<blockquote>
  <p>On a little-endian machine (like x86), an integer’s first byte contains the
least significant digits, while the first byte in a string contains the most
significant digit.</p>
</blockquote>

<figure>
    <img width="100%" height="100%" src="https://kholdstare.github.io/diagrams/parse-byteswap-insight.png">

<figcaption><p>Looking at the string as an integer we can get closer to
the final parsed state in fewer operations - see how the hex representation is
<strong>almost</strong> what we want</p>
</figcaption>

</figure>

<p>Now to reinterpret the bytes of a string as an integer we have to use
<code>std::memcpy</code> (<a href="https://blog.regehr.org/archives/1307">to avoid strict-aliasing
violations</a>), and we have compiler
instrinsic <code>__builtin_bswap64</code> to swap the bytes in one instruction. The
<code>std::memcpy</code> will get optimized out, so this is a win so far.</p>

<figure><pre><code data-lang="cpp"><span>template</span> <span>&lt;</span><span>typename</span> <span>T</span><span>&gt;</span>
<span>inline</span> <span>T</span> <span>get_zeros_string</span><span>()</span> <span>noexcept</span><span>;</span>

<span>template</span> <span>&lt;</span><span>&gt;</span>
<span>inline</span> <span>std</span><span>::</span><span>uint64_t</span> <span>get_zeros_string</span><span>&lt;</span><span>std</span><span>::</span><span>uint64_t</span><span>&gt;</span><span>()</span> <span>noexcept</span>
<span>{</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>result</span> <span>=</span> <span>0</span><span>;</span>
  <span>constexpr</span> <span>char</span> <span>zeros</span><span>[]</span> <span>=</span> <span>"00000000"</span><span>;</span>
  <span>std</span><span>::</span><span>memcpy</span><span>(</span><span>&amp;</span><span>result</span><span>,</span> <span>zeros</span><span>,</span> <span>sizeof</span><span>(</span><span>result</span><span>));</span>
  <span>return</span> <span>result</span><span>;</span>
<span>}</span>

<span>inline</span> <span>std</span><span>::</span><span>uint64_t</span> <span>parse_8_chars</span><span>(</span><span>const</span> <span>char</span><span>*</span> <span>string</span><span>)</span> <span>noexcept</span>
<span>{</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>chunk</span> <span>=</span> <span>0</span><span>;</span>
  <span>std</span><span>::</span><span>memcpy</span><span>(</span><span>&amp;</span><span>chunk</span><span>,</span> <span>string</span><span>,</span> <span>sizeof</span><span>(</span><span>chunk</span><span>));</span>
  <span>chunk</span> <span>=</span> <span>__builtin_bswap64</span><span>(</span><span>chunk</span> <span>-</span> <span>get_zeros_string</span><span>&lt;</span><span>std</span><span>::</span><span>uint64_t</span><span>&gt;</span><span>());</span>

  <span>// ...</span>
<span>}</span></code></pre></figure>

<p>But now that we have an integer that kind of, sort of looks like what we want,
how do we get it across the finish line without too much work?</p>

<hr>

<h3 id="the-divide-and-conquer-insight">The divide and conquer insight</h3>

<p>From the previous step, we end up with an integer whose bit representation 
has each digit placed in a separate byte. I.e. even though one byte can
represent up to 256 values, we have values 0-9 in each byte of the integer.
They are also in the right little endian order. Now we just need to “smash”
them together somehow.</p>

<p>We know that doing it linearly would be too slow, what’s the next possibility?
<strong>O(log(n))</strong>! We need to combine every adjacent digit into a pair in one step,
and then each pair of digits into a group of four, and so on, until we have the
entire integer.</p>

<p>After I posted the first version of this article, <a href="https://www.reddit.com/r/cpp/comments/gr18ig/faster_integer_parsing/frx9agb">Sopel97 on
reddit</a>
pointed out that the byteswap is not necessary. Combining adjacent digits works
either way - their order doesn’t matter.  I realized that it helped me with the
next insight, but could be omitted for the final code.</p>

<blockquote>
  <p>The key is working on adjacent digits simultaneously. This allows a tree of
operations, running in O(log(n)) time.</p>
</blockquote>

<p>This involves multiplying the even-index digits by a power of 10 and leaving the
odd-index digits alone. This can be done with bitmasks to selectively apply
operations</p>

<figure>
    <img width="100%" height="100%" src="https://kholdstare.github.io/diagrams/parse-mask-insight.png">

<figcaption><p>By using bitmasking, we can apply operations to more than one digit at a time, to combine them into a larger group</p>
</figcaption>

</figure>

<p>Let’s finish the <code>parse_8_chars</code> function we started earlier by employing this
masking trick. As a neat side-effect of the masking, we don’t need to subtract
<code>'0'</code>, since it will be masked away.</p>

<figure><pre><code data-lang="cpp"><span>inline</span> <span>std</span><span>::</span><span>uint64_t</span> <span>parse_8_chars</span><span>(</span><span>const</span> <span>char</span><span>*</span> <span>string</span><span>)</span> <span>noexcept</span>
<span>{</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>chunk</span> <span>=</span> <span>0</span><span>;</span>
  <span>std</span><span>::</span><span>memcpy</span><span>(</span><span>&amp;</span><span>chunk</span><span>,</span> <span>string</span><span>,</span> <span>sizeof</span><span>(</span><span>chunk</span><span>));</span>

  <span>// 1-byte mask trick (works on 4 pairs of single digits)</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>lower_digits</span> <span>=</span> <span>(</span><span>chunk</span> <span>&amp;</span> <span>0x0f000f000f000f00</span><span>)</span> <span>&gt;&gt;</span> <span>8</span><span>;</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>upper_digits</span> <span>=</span> <span>(</span><span>chunk</span> <span>&amp;</span> <span>0x000f000f000f000f</span><span>)</span> <span>*</span> <span>10</span><span>;</span>
  <span>chunk</span> <span>=</span> <span>lower_digits</span> <span>+</span> <span>upper_digits</span><span>;</span>

  <span>// 2-byte mask trick (works on 2 pairs of two digits)</span>
  <span>lower_digits</span> <span>=</span> <span>(</span><span>chunk</span> <span>&amp;</span> <span>0x00ff000000ff0000</span><span>)</span> <span>&gt;&gt;</span> <span>16</span><span>;</span>
  <span>upper_digits</span> <span>=</span> <span>(</span><span>chunk</span> <span>&amp;</span> <span>0x000000ff000000ff</span><span>)</span> <span>*</span> <span>100</span><span>;</span>
  <span>chunk</span> <span>=</span> <span>lower_digits</span> <span>+</span> <span>upper_digits</span><span>;</span>

  <span>// 4-byte mask trick (works on pair of four digits)</span>
  <span>lower_digits</span> <span>=</span> <span>(</span><span>chunk</span> <span>&amp;</span> <span>0x0000ffff00000000</span><span>)</span> <span>&gt;&gt;</span> <span>32</span><span>;</span>
  <span>upper_digits</span> <span>=</span> <span>(</span><span>chunk</span> <span>&amp;</span> <span>0x000000000000ffff</span><span>)</span> <span>*</span> <span>10000</span><span>;</span>
  <span>chunk</span> <span>=</span> <span>lower_digits</span> <span>+</span> <span>upper_digits</span><span>;</span>

  <span>return</span> <span>chunk</span><span>;</span>
<span>}</span></code></pre></figure>

<hr>

<h3 id="the-trick">The trick</h3>

<p>Putting it all together, to parse our 16-digit integer, we break it up into two
chunks of 8 bytes, run <code>parse_8_chars</code> that we have just written, and benchmark it!</p>

<figure><pre><code data-lang="cpp"><span>inline</span> <span>std</span><span>::</span><span>uint64_t</span> <span>parse_trick</span><span>(</span><span>std</span><span>::</span><span>string_view</span> <span>s</span><span>)</span> <span>noexcept</span>
<span>{</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>upper_digits</span> <span>=</span> <span>parse_8_chars</span><span>(</span><span>s</span><span>.</span><span>data</span><span>());</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>lower_digits</span> <span>=</span> <span>parse_8_chars</span><span>(</span><span>s</span><span>.</span><span>data</span><span>()</span> <span>+</span> <span>8</span><span>);</span>
  <span>return</span> <span>upper_digits</span> <span>*</span> <span>100000000</span> <span>+</span> <span>lower_digits</span><span>;</span>
<span>}</span>

<span>static</span> <span>void</span> <span>BM_trick</span><span>(</span><span>benchmark</span><span>::</span><span>State</span><span>&amp;</span> <span>state</span><span>)</span> <span>{</span>
  <span>for</span> <span>(</span><span>auto</span> <span>_</span> <span>:</span> <span>state</span><span>)</span> <span>{</span>
    <span>benchmark</span><span>::</span><span>DoNotOptimize</span><span>(</span><span>parse_trick</span><span>(</span><span>example_stringview</span><span>));</span>
  <span>}</span>
<span>}</span></code></pre></figure>

<figure>
    <canvas id="benchmark-canvas-trick">
    </canvas>

</figure>

<p>Not too shabby, we shaved almost 56% off of the unrolled loop benchmark! Still,
it feels like we are manually doing a bunch of masking and elementwise
operations. Maybe we can just let the CPU do all the hard work?</p>

<hr>

<h3 id="the-simd-trick">The SIMD trick</h3>

<p>We have the main insight:</p>

<ul>
  <li>Combine groups of digits simultaneously to achieve O(log(n)) time</li>
</ul>

<p>We also have a 16-character, or 128-bit string to parse - can we use SIMD? Of
course we can! <a href="https://en.wikipedia.org/wiki/SIMD">SIMD stands for Single Instruction Multiple
Data</a>, and is exactly what we are looking
for. SSE and AVX instructions are supported on both Intel and AMD CPUs, and
 they typically work with wider registers.</p>

<p>I used the <a href="https://software.intel.com/sites/landingpage/IntrinsicsGuide/">Intel Intrinsics
Guide</a> to find
the right compiler intrinsics for the right SIMD CPU instructions.</p>

<p>Let’s set up the digits in each of the 16 bytes first:</p>

<figure><pre><code data-lang="cpp"><span>inline</span> <span>std</span><span>::</span><span>uint64_t</span> <span>parse_1…</span></code></pre></figure></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kholdstare.github.io/technical/2020/05/26/faster-integer-parsing.html">https://kholdstare.github.io/technical/2020/05/26/faster-integer-parsing.html</a></em></p>]]>
            </description>
            <link>https://kholdstare.github.io/technical/2020/05/26/faster-integer-parsing.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23639486</guid>
            <pubDate>Thu, 25 Jun 2020 11:43:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gopherspace in the Year 2020]]>
            </title>
            <description>
<![CDATA[
Score 58 | Comments 6 (<a href="https://news.ycombinator.com/item?id=23639411">thread link</a>) | @sT370ma2
<br/>
June 25, 2020 | https://cheapskatesguide.org/articles/gopherspace.html | <a href="https://web.archive.org/web/*/https://cheapskatesguide.org/articles/gopherspace.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

   <!-- Title -->
   
   <p><img src="https://cheapskatesguide.org/pics/gopher-240.jpg" alt="Gopher">
      I first had access to the early Internet--what there was of 
      it--through the university I attended.  I remember how different 
      the Internet was back in the mid-to-late 1980's.  We had 
      electronic mail, but almost no one used it.  We logged onto 
      remote computers with telnet and transferred files with FTP.  
      All this was done at the command line.  If I remember correctly, 
      very few graphical user interfaces existed then.  Those that 
      did were composed of ASCII characters.  The first web browser was 
      not released until 1991.  Remembering causes me some sadness, 
      though in some ways the Internet is better now.  It certainly 
      has many more users, and that is a good thing.  I just wish it had 
      more Internet-savvy users.</p>

   <p>I remember that many of the early computer networks and websites on 
      the Internet were run by imaginative people with great senses of 
      humor.  For example, the computer network that I used at the second 
      engineering company for which I worked in the late 1980's had seven 
      sun workstations named after the seven dwarves.  As you may imagine, 
      that provided us with no end of entertainment.  "Dopey is down, 
      AGAIN!"  "Grumpy is acting up."  "Sneezy died yesterday.  When is 
      the funeral?"</p>

   <p>Back then, computers were something special.  They were wondrous.  
      Individuals who owned them were mavericks in a sense.  Buying a 
      personal computer then was the same as painting the word "nerd" in big 
      red letters across your forehead, and being known as a nerd back then was 
      not something you wanted.  One of my highschool friends built a 
      Heathkit computer.  The only display it had was in the form of 
      one-inch, red LED digits on the front.</p>

   <p>Now, that computers permeate our society, no one bothers giving them 
      interesting names.  They've nearly become fungible commodities that we 
      use up and then throw away when they have outlived their usefulness.  
      Nearly everyone uses the Internet at least occassionally.  And, 
      strangely enough, being called a nerd is seen as a good thing.</p>
   <h2>Gopherspace</h2>
   <p>The Gopher protocol was released by the University of Minnesota in 
      1991.  Gopher servers provided users with access to various types 
      of files, including text, binary, image, sound, and GIF.  But the 
      milieu of gopherspace was text.   Text was mostly what Gopher users 
      saw.  Users could also access FTP, telnet, and 
      Usenet servers.  Back in the 1990's, Veronica search engines
      tied together the network of Gopher servers in a similar way as 
      modern search engines do today with the webservers of the
      modern Internet.  In the 1990's, Jughead search engines were designed 
      to search individual Gopher servers.  And, Archie was an FTP search 
      engine.  Archie, Veronica, and Jughead search engines were named 
      after characters in the Archie comics that first appeared in print in
      1941.  Back in the 1980's and early 1990's, when people who loved 
      computers still ran much of the Internet, it reflected their 
      personalities.  Now, the Internet is more a beige and gray  
      reflection of the corporate world.</p> 
  
   <p>Today the Gopher protocol has been supplanted almost completely 
      by the HTTP protocol upon which the World Wide Web is based.
      Though the Internet has changed considerably, Gopher servers are 
      still around.  Text is still mostly what users see 
      in gopherspace, and it can still be navigated with 
      gopher-capable Internet browsers.  Sadly, only one Veronica search 
      engine appears to operate today.  Now, When a user navigates through
      gopherspace with the Veronica search engine, by following links, or
      by entering URL's into his browser, he has an experience in many 
      ways similar to surfing the modern Internet.</p>
   
   <p>Though about <a href="https://en.wikipedia.org/wiki/Gopher_(protocol)"> 
      two dozen Internet browsers</a> can still access gopherspace, either 
      natively or with plugins, I will only talk about one.  I'll focus on the 
      Lynx browser, because it is readily available, easy to use, and 
      powerful.  The Lynx browser also runs on all the major 
      operating systems.  I'll show readers how to use the Lynx browser 
      to get into gopherspace and have a look around.</p>
   <h2>Installing and Using the Lynx Browser</h2>
   <p>The Lynx browser is a text-only Internet browser that has native 
      support for gopherspace.  Lynx allows a user to seamlessly navigate 
      around the Internet and gopherspace using only the keys on his computer's 
      keyboard.  Lynx does not use a mouse or touchpad.  Windows computer 
      users can download the Lynx browser from the 
      <a href="https://lynx.browser.org/">Lynx website</a>.</p>
 
   <div><p>Most Linux users can install Lynx simply by opening a Linux 
      terminal window and typing:
   </p></div><div>
<pre>sudo apt-get install lynx
</pre>
   </div>
   <p>

   Then, type "lynx" (without the quotes) at the command line to start 
   the Lynx browser.</p>

   <p>To go to a Gopher address using the Lynx browser, hit the "g" 
      key on your keyboard.  Near the bottom of the Lynx window, the 
      prompt "URL to open:" will appear.  Now, begin typing the Gopher 
      address.  Gopher URL's can also be copied and pasted from other 
      applications.  First, copy the URL from the other application, 
      then select the Lynx window, hit the right mouse button, and 
      select "paste".  Try going to this Gopher address for practice: 
      gopher://infinitelyremote.com/0/books/Internet_Gopher_Users_Guide.txt.  
      After you hit the "Enter" key, the text file entitled "Internet 
      Gopher Users Guide" should be visible in your Lynx window.</p>

   <p>Lynx has three user modes.  At this point, you are in the novice 
      user mode, so at the bottom of the page, the following instructions 
      should be visible: "-- press space for next page --  Arrow keys: 
      Up and Down to move.  Right to follow a link; Left to go back.  
      H)elp O)ptions P)rint G)o M)ain screen Q)uit /=search 
      [delete]=history list".</p>

   <p>At a basic level, Lynx is very easy to use, so a user does not 
      have to know much to navigate around gopherspace and read text 
      files.  I will go over the basic commands, and leave it to you 
      to learn more later.  To navigate around inside a text file that 
      contains no hyperlinks, press the space bar or the down arrow on 
      your keyboard to move down one page and the up arrow to move back 
      up one page.  The left arrow is like the back button in a modern 
      Internet browser; it takes you to the previous text file that you 
      visited.  In a text file with hyperlinks, pressing the up or down 
      arrow moves the cursor to the hyperlink above or below the 
      cursor's present position.  When the cursor is on a hyperlink, 
      pressing the "Enter" key or the right arrow takes you to the 
      document pointed to by the hyperlink.</p>

   <p>Some Gopher pages contain forms similar to HTML forms.  For 
      example, links to search engines may appear as a search line.  Use 
      the left or right arrow to move the cursor to the search line.  
      Then, type the key words you want to search for and hit the 
      "Enter" key.  This will take you to a search results page.</p>

   <p>To display the Gopher URL of the file you are currently reading, 
      hit the "=" key.  Then, hit the left arrow key to get back to the 
      file you were just reading.</p>

   <p>Exit from Lynx by hitting the "q" key.  By the way, most 
      command-line Linux programs that take control of a terminal 
      window can be exited by hitting either the "q" key or by typing 
      ":q".</p>

   <p>This is all the information you need to know to navigate around 
      in gopherspace (or on the rest of the Internet) using the Lynx 
      browser.  For additional instructions on the use of Lynx, bring 
      up Lynx and hit the "h" key.</p>
   <h2>Exploring Gopherspace</h2>
   <p>Now the fun begins.  Perhaps the best place to enter gopherspace 
      is gopher://gopher.floodgap.com/1/world.  There you will find 
      links to dozens of Gopher servers.  Floodgap claims that it 
      hosts the last Veronica search engine in existence.  So, from 
      Floodgap you can use the Veronica search engine to search 
      gopherspace by key words, or you can go to individual Gopher 
      user sites by following links to the Gopher servers that host them.</p>

   <p>One of the largest collections of Gopher user sites can be found 
      by following the Link on Floodgap labeled "'Greatest hits': most 
      recently verified Gopher servers".  From there, follow the link 
      labeled "sdf.org:70" to the Super-Dimensional Fortress (URL: 
      gopher://sdf.org/1).  There you will find many interesting phlogs 
      and files.  Gopher blogs are called phlogs.  One interesting 
      phlogger is Tomasino (gopher://sdf.org/1/users/tomasino/).  
      Another is solderpunk (gopher://sdf.org/1/users/solderpunk/).  
      There are also may others.  So, have fun and explore!</p>

   <p>For more interesting reading in gopherspace, try these:</p>
   <br>
   <ul>
      <li>gopher://gopher.floodgap.com/0/gopher/relevance.txt</li>
      <li>gopher://sdf.org/1/users/d1337/1990s-life</li>
      <li>gopher://gopherpedia.com/1/</li>
      <li>gopher://gopherddit.com/1/</li>
      <li>gopher://sdf.org/0/users/developer/PHLOG/earlydays.txt</li>
      <li>gopher://tilde.team/1/~ubergeek/news/</li>
      <li>gopher://hngopher.com/1</li>
      <li>gopher://sdf.org/1/users/sysdharma/phlog</li>
      <li>gopher://sdf.org/0/users/dbucklin/posts/2017-12-31-plain-text.txt</li>
      <li>gopher://sdf.org/0/users/dbucklin/posts/2016-03-11-mechanical-keyboards.txt</li>
      <li>gopher://tilde.town/</li>
      <li>gopher://1436.ninja/1/Port70News</li>
      <li>gopher://codevoid.de/1/cnn</li>
      <li>gopher://gopher.floodgap.com/1/feeds/today</li>
      <li>gopher://vger.cloud/1/pubnix</li>
      <li>gopher://sdfeu.org/1/</li>
      <li>gopher://zaibatsu.circumlunar.space/1/%7etfurrows/phlog</li>
      <li>gopher://1436.ninja/1/Phlog</li>
      <li>gopher://baud.baby</li>
      <li>gopher://sdf.org/1/users/xmanmonk/</li>
      <li>gopher://sdf.org/1/users/tokyogringo/</li>
      <li>gopher:/…</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cheapskatesguide.org/articles/gopherspace.html">https://cheapskatesguide.org/articles/gopherspace.html</a></em></p>]]>
            </description>
            <link>https://cheapskatesguide.org/articles/gopherspace.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23639411</guid>
            <pubDate>Thu, 25 Jun 2020 11:33:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Zoom works [slides]]]>
            </title>
            <description>
<![CDATA[
Score 186 | Comments 145 (<a href="https://news.ycombinator.com/item?id=23638116">thread link</a>) | @Spidery
<br/>
June 25, 2020 | https://builtformars.co.uk/how-zoom-works/ | <a href="https://web.archive.org/web/*/https://builtformars.co.uk/how-zoom-works/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-elementor-type="single" data-elementor-id="2530" data-elementor-settings="[]">
		<div>
			<div>
						<section data-id="c26fc93" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="28a6896" data-element_type="column">
			<div>
					<div>
				
				<div data-id="b04b2c1" data-element_type="widget" data-widget_type="theme-post-excerpt.default">
				<p>
			Zoom is a significant challenger in the video conferencing space, but is their UX any better than Skype or Cisco?		</p>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="052a335" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="4224d77" data-element_type="column">
			<div>
					<div>
				<div data-id="5ad8739" data-element_type="widget" data-widget_type="theme-post-featured-image.default">
				<div>
					<p><img width="720" height="410" src="https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom.png" alt="Zoom UX case study" srcset="https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom.png 1018w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-300x171.png 300w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-768x438.png 768w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-100x57.png 100w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-700x399.png 700w" sizes="(max-width: 720px) 100vw, 720px">											</p>
				</div>
				</div>
						</div>
			</div>
		</div>
				<div data-id="a001539" data-element_type="column">
			<div>
					<div>
				
				<div data-id="724633a" data-element_type="widget" data-widget_type="post-info.default">
				<div>
					<ul>
					<li itemprop="datePublished">
										<span>
															</span>
									<span>
							<span>📅 Added on</span>
										April 15, 2020					</span>
								</li>
				</ul>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="2643ed8" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="a995590" data-element_type="column">
			<div>
					<div>
				<div data-id="c9f06a8" data-element_type="widget" data-widget_type="theme-post-featured-image.default">
				<div>
					<p><img width="720" height="410" src="https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom.png" alt="Zoom UX case study" srcset="https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom.png 1018w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-300x171.png 300w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-768x438.png 768w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-100x57.png 100w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-700x399.png 700w" sizes="(max-width: 720px) 100vw, 720px">											</p>
				</div>
				</div>
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
				<section data-id="ca3ca43" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
							
							<div>
				<div>
				<div data-id="ec20c55" data-element_type="column">
			<div>
					<div>
				<div data-id="682e138" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
					<div data-elementor-type="wp-post" data-elementor-id="3204" data-elementor-settings="[]">
			<div>
				<div>
							<section data-id="7b73c3c" data-element_type="section">
						<div>
				<div>
				<div data-id="d0a7d7b" data-element_type="column">
			<div>
					<div>
				<div data-id="cd0bf0c" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><div><div role="region" aria-label="Slider"><p><img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxMjAwIiBoZWlnaHQ9IjkwMCIgPjwvc3ZnPg==" alt="Slider"></p></div></div></div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="375357f" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="353f855" data-element_type="column">
			<div>
					<div>
				<div data-id="891920c" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>💡<strong>Tip:</strong> Try using the ⬅️ <span>➡️arrows on your keyboard to navigate the slides.</span></p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="9ffc41b" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="5f2393c" data-element_type="column">
			<div>
					<div>
				<div data-id="b2a958e" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p><strong>Mobile tip:</strong> Try swiping ⬅️<span>👆➡️ left and right to navigate the slides.</span></p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="5094e89" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="4d0fdca" data-element_type="column">
			<div>
					<div>
				
				<div data-id="560b6f9" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>New case studies—packed with UX lessons—are published every <strong>14 days</strong>.</p>
				</div>
				</div>
				<div data-id="c135888" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p><span>📮 No spam, ever.&nbsp; &nbsp;</span><span>📅 1 email a week.&nbsp; &nbsp;</span><span>👋 Unsubscribe anytime.</span></p>
				</div>
				</div>
				
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="3daa393" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="4876312" data-element_type="column">
			<div>
					<div>
				<section data-id="05a68ee" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="09ef108" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
			<div>
							
					<div>
				<div data-id="31901c7" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Subscribe and get a new case study like this every <strong>14 days</strong>!</p>
				</div>
				</div>
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="94d99dd" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="3a870f9" data-element_type="column">
			<div>
					<div>
				<div data-id="91f57f2" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>There’s always more to learn</p>
				</div>
				</div>
				<div data-id="2f5c033" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Dive into other case studies. They’re typically a <strong>5 minute read</strong>.</p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="c62cabd" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						
		</section>
					</div>
		</div>
		</div></div>]]>
            </description>
            <link>https://builtformars.co.uk/how-zoom-works/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23638116</guid>
            <pubDate>Thu, 25 Jun 2020 08:13:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Liberty (1859) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 166 | Comments 102 (<a href="https://news.ycombinator.com/item?id=23636407">thread link</a>) | @mrfusion
<br/>
June 24, 2020 | https://socialsciences.mcmaster.ca/econ/ugcm/3ll3/mill/liberty.pdf | <a href="https://web.archive.org/web/*/https://socialsciences.mcmaster.ca/econ/ugcm/3ll3/mill/liberty.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div p="">&gt; 
endobj
379 0 obj
&lt;&lt; /S 964 /O 1045 /Filter /FlateDecode /Length 380 0 R &gt;&gt; 
stream
ì+ªýc„-ÌéEÎØµ«°L½÷Ëÿé;ÄÛxÃ¼to•F$ˆ¡)•ãz§%u­ÌP¬5,‚|)äìº„H”˜Ïk‚Æ&nbsp;s˜Z‡}8kxgF¼�Ew�‰	ÕìC¸‡2÷¨ÿ&gt;JùwãÏ@ãù«z‰7s¹vëëœEªœ:Øy±cˆ[°ÅÄ§ÁôCEb´.&gt;øõ½ó¶B�š:DØ´×¸æ¢¬aqäÁ"Õ&gt;(¿ìøzF|ñlçJ´W‘~|‹§	|hÓwÎ�&gt;|³¹Žö™&amp;¬frË�/^@¦Šà°GM4mejD›ê²õ`X–Þrm¯ð²ÝUdñØ"LjÝÁ{um]4tÈj»­)6qbÕ<v%aÁ£œps1�l`Ôbä2[›;� qhu'…„+~€úmÿÓ‚Ámïx="£ËÝfÊÙÁš¨Ìâ|â3É5¸æ£gøÕû‘jªãt" Øl4ï="ù2Jd·”õ" ŠÖö*uxi«Áx4ãõ€�´�+otx‰³ö÷ö,¼Þ1¢fçÐ¾›ûødÝ^h¸ÚdÎÌ4bÅs×Çê†~k%’î¦—¦¨éå6xª+§qÔÒ„†hÐ[s¹="ˆžµ—QäyÀ½fî¤u*�su$ØÐwrg" endstream="" endobj="" 380="" 0="" obj="" 488="" 352="" <<="" type="" page="" parent="" 336="" r="" resources="" 366="" contents="" 371="" mediabox="" [="" 432="" 648="" ]="" cropbox="" rotate="">&gt; 
endobj
353 0 obj
&lt;&lt; 
/Count 1 
/First 354 0 R 
/Last 354 0 R 
&gt;&gt; 
endobj
354 0 obj
&lt;&lt; 
/Title (T¬Þô¯ø1n)
/Dest [ 4 0 R /Fit ] 
/Parent 353 0 R 
/First 355 0 R 
/Last 356 0 R 
/Count -11 
&gt;&gt; 
endobj
355 0 obj
&lt;&lt; 
/Title (š[ÌBe°†à0úg)
/Dest [ 20 0 R /Fit ] 
/Parent 354 0 R 
/Next 365 0 R 
&gt;&gt; 
endobj
356 0 obj
&lt;&lt; 
/Title (‘'G`iŸ)
/Dest [ 320 0 R /Fit ] 
/Parent 354 0 R 
/Prev 357 0 R 
&gt;&gt; 
endobj
357 0 obj
&lt;&lt; 
/Title (°DÞ—9³Ùí+ Šk¹)
/Dest [ 260 0 R /Fit ] 
/Parent 354 0 R 
/Prev 358 0 R 
/Next 356 0 R 
&gt;&gt; 
endobj
358 0 obj
&lt;&lt; 
/Title (ø“€·+Š*—ÜI)
/Dest [ 260 0 R /Fit ] 
/Parent 354 0 R 
/Prev 359 0 R 
/Next 357 0 R 
&gt;&gt; 
endobj
359 0 obj
&lt;&lt; 
/Title (*I“KP8iÃ]3¨ŒÎÙÝÊÜ®%zÙ3k&gt;g’Bn~|‹Û°.¦7Z#Ð\(Ü²ÄÃhÿ"SÀv7�K/J\()
/Dest [ 209 0 R /Fit ] 
/Parent 354 0 R 
/Prev 360 0 R 
/Next 358 0 R 
&gt;&gt; 
endobj
360 0 obj
&lt;&lt; 
/Title (D7A­­*!P])
/Dest [ 209 0 R /Fit ] 
/Parent 354 0 R 
/Prev 361 0 R 
/Next 359 0 R 
&gt;&gt; 
endobj
361 0 obj
&lt;&lt; 
/Title (õËÃª5tT±ZOJR¨�»[¿5&lt;¿j+æN*œ§h4èÉÄo	É»W'±WßK¥ÞZ_š¦&amp;-M)
/Dest [ 158 0 R /Fit ] 
/Parent 354 0 R 
/Prev 362 0 R 
/Next 360 0 R 
&gt;&gt; 
endobj
362 0 obj
&lt;&lt; 
/Title (’›­öëQ“uö)
/Dest [ 158 0 R /Fit ] 
/Parent 354 0 R 
/Prev 363 0 R 
/Next 361 0 R 
&gt;&gt; 
endobj
363 0 obj
&lt;&lt; 
/Title (-hs~FD»M„íM±VleÁŸï!Å¤Ÿpnt­ô6qñ‡-Œí*üKª©)
/Dest [ 56 0 R /Fit ] 
/Parent 354 0 R 
/Prev 364 0 R 
/Next 362 0 R 
&gt;&gt; 
endobj
364 0 obj
&lt;&lt; 
/Title (:Gû¹ÀS ˜&nbsp;2)
/Dest [ 56 0 R /Fit ] 
/Parent 354 0 R 
/Prev 365 0 R 
/Next 363 0 R 
&gt;&gt; 
endobj
365 0 obj
&lt;&lt; 
/Title (²ú"0P“ºSf÷–wn&lt;)
/Dest [ 20 0 R /Fit ] 
/Parent 354 0 R 
/Prev 355 0 R 
/Next 364 0 R 
&gt;&gt; 
endobj
366 0 obj
&lt;&lt; 
/ProcSet [ /PDF /Text ] 
/Font &lt;&lt; /F5 368 0 R /F6 372 0 R /F7 375 0 R &gt;&gt; 
/ExtGState &lt;&lt; /GS1 378 0 R /GS2 377 0 R &gt;&gt; 
&gt;&gt; 
endobj
367 0 obj
&lt;&lt; 
/Type /FontDescriptor 
/Ascent 0 
/CapHeight 0 
/Descent 0 
/Flags 4 
/FontBBox [ -146 -274 1207 909 ] 
/FontName /HDDGLC+MSTT31c6b7 
/ItalicAngle 0 
/StemV 0 
/CharSet (ì»µ”±ßhZ\)0UŠ	wå*‹*Àá&nbsp;|B¬=ŠÉš¬b_Øö1ÈÖ2a¼-Sè�bœ”¿r«áÞ„’nòj"<tøþ˜Ì\ ¬ØtrùÇ;f[û<="" {²h[r)="" fontfile="" 369="" 0="" r="">&gt; 
endobj
368 0 obj
&lt;&lt; 
/Type /Font 
/Subtype /Type1 
/Name /F5 
/FirstChar 31 
/LastChar 255 
/Widths [ 750 260 320 380 520 520 900 740 220 440 440 500 520 260 333 260 580 
556 556 556 556 556 556 556 556 556 556 260 260 520 520 520 400 
820 660 640 680 740 620 540 740 820 360 340 660 620 880 760 820 
580 800 660 520 660 780 640 900 740 520 600 440 260 440 520 500 
360 556 556 556 611 500 444 611 667 333 333 556 500 722 611 611 
500 611 556 444 556 611 556 778 611 556 500 280 260 280 520 750 
750 750 300 520 400 1000 500 500 420 1300 520 320 1000 750 750 750 
750 300 300 400 400 460 556 1000 420 980 444 320 833 880 750 520 
750 320 520 520 611 520 260 500 380 740 340 480 520 750 740 400 
400 520 312 312 360 580 600 320 300 312 360 480 780 780 780 400 
660 660 660 660 660 660 880 680 620 620 620 620 360 360 390 370 
740 760 820 820 820 820 820 520 820 780 780 780 780 520 580 888 
556 556 556 556 556 556 722 556 500 500 500 500 347 347 377 357 
611 611 611 611 611 611 611 520 611 611 611 611 611 556 500 556 
] 
/Encoding 370 0 R 
/BaseFont /HDDGLC+MSTT31c6b7 
/FontDescriptor 367 0 R 
&gt;&gt; 
endobj
369 0 obj
&lt;&lt; /Length 10526 /Length1 4144 /Length2 6380 /Length3 0 &gt;&gt; 
stream
zv¥gjQkÜuùxúõüó½�ÕñQÇ9;Õê¡ƒÀÉd¾Ñ®ôQÛçFeœ5íNRAžW!evÔ=Ë½ý™îžÍ8g(XmØpJe*åº0bÝæÆ¡]ó�úqÐÁÊ©OíiÂåt/x�Ò¿ÖUÑS3P¸43G`œŽZŽBª„zïùÖ§¶«X™Åe3?»¹ÏébÃè¦sQŒ–«;îWßê¾ý„ÆaçXOˆn&amp;7¸}ÃŠÈ�Æ³ed½‚$/´ñ?þ2ÿÓ#øKˆÖl%Ù“—0ñ‡ €Eê„†4áN-.‚ÑJHÊr	Ž×+«2¦wDqV/{±gp“™|Mú:4µ$�”yC¿¹
•ÞžœN:sâ-Ú¹(}4,O™�Ù€¡í½MMùcƒÂ–¯­.N¥UwîÈ#G‹©šÕÜ­Š�)~D<a€â-ÑÔší³’È¯=¬Éky÷Ãßm~•‚ 7µl¥”÷á’dï*§yc="" $="">�»‰NHÞVý×ÙpW{5 ÞCžYìg6´Ì�9BUÐñ1Ë^t^8ûªøo#žÞv“–†mEK["ˆ03IBè3F÷Éº ŒB°È:ô•\ˆ÷Gñx?½(Å’=c×ø†Ÿ$h‡ò0KÄqÛÍ°·Ú‘<a}×¨¦’mÑ2uýúsþã¶µf”�[g` dØhhœmí×¹Ä”Žýçfç’Ž’“g›‹%†�ËiÓí="" f{¹õûâð*¾o¶¡e�u©o‚‰Ïß="" %hÌ8ìr1³1<ÁÑ_?dqï½×°˜âÞ%»bb="" œll4beb="A§#Æ‘ìŠá°Fr×i1€" l‰²[r½$ï¨ð*lîn(0vq„Ý="" Ý�="" 5ºð²¢¤m}_‡pü&8r¡äÿu©)›r“boÏ%¶tÀpkÇr$e!óp¾éj”��.\˜þÏÎÌdå$«båý+��'b…wvÎØ.ºõ b£jt3mñ»-}ø¹¤é–Ývoàéƒg¡ìiõ*h0-n¬býá*cÀÍá›®á\="">ÔÅ¨
‚°ôæ‰Ä¦Š¬‡ìäóËp¯;tPÿúÿ$	ÿrëK[Õeœ15X&nbsp;Ñ—åûê	‘3º(uÕ•ÙÛ¯.W6¤Å3r®êÞí´&nbsp;MQtêã}ñ|µ²ÔSùòP^°êéËuÿi•”‚ï¼�Ë‘Ý[Í_Ký@¾Onj³ûö
Ç	âƒ
`IRùÁY…µlt‰¼õ;�(QAr­èz¹LÇœµ.:Ô�#@+‰71.�pU¤ØÄy
D|ÕˆÝ)ÛŸ¸ýáv»ƒo´{œs^áœ,:ïË£óéqžËJ4t¯Dp³ÐzzÑ8þ›+Vpó‘lºÓ±#Q¾Ø¬ªC©ºƒÉ«€{³¶&nbsp;c\tÇ6�OÍ¸A�ÇbXöÃ&amp;4¢­3)³1Ëì\hçÃ|£:’G?£¡¬:zrL{µ¹zÕ÷|b}Oƒ`(uš7êø0s!Ñø ¼Ne�8Ìütr|LYtc”ü†‡}Ñÿ$'Í?XÓœ&nbsp;f/¨•39
PÃál²®sY”0—�2xøZ*úÝÏêt°S?ê2•=¦bAPMóïtØÀªÁìµ¼™à}ZyÙ@	ÕD°—ÚhÄ©Í÷µÇ&gt;9²”0¼çáãB»Ûzû�‹L¾&amp;ãæjÂ¥L–1»#²=çsv)érÁb8A(jóO�o1L‹*Ì*âÃ
¨Ñý—ô”õq7™Ã�Q‰Â`“6Ù-óû/w¯-meèL�´\]
‹c’"øGÇw[®†#úr¯7 ŸFÂ·§°ŸCÀç´§
X¢+F£ŒKôxœŒcye�æÖÖÛ€õ&nbsp;Ã–˜š®[ø
}¿
N5åù?wúmÔ&amp;UZvfc¼“d¼š´ÖÁÕyÝ¥#b¥ôhÑéöÖš]�&amp;QóÞ¸tÄ�*Vù\ÿ~#BÿÛñeóÙuˆ/gÃØ2báwP¿,mÙ¦¥«õ)ã™‰™}°YWó¨ÞP`rÝN½¡ÎVè¸c}'œUà­&gt;?2G�±HÎh¸º¬x’6»î9ÏºÉÐØÓê=ø=ØR'ý‚7¨°}s;mÀ:ÿïp°6…!¬np‰·»Â¼7_ê»-ær?]«tí%I¡8òWÇðf¯?Zö++vÇo#Ò2¼±3Ùú×UP_XkÊGæ¨]8„ÈÞDTœý&amp;˜ðï³{Ô[_²�”‰Å%Z4Y†òvÛØãWááá„¿Œ‡kß(–×\�&nbsp;Ó&lt;¢c.æUp	YíÄª4æ¤g»¥�º%ö?UžÖ´Iõ§7²ø«{xÓóõˆxQ8L†™ÝÑìˆF~•TbÈÚf¥TGKoc	1Q$¯¾iÄFXÏ½¡øiÆÃZMÊ™õõh`3‰Ã}~}&nbsp;)â‡Žáåg¿ƒ«“ÁËÏÊŸ,«“–Ô&nbsp;5$Øe„w‚)î©'Íq‡WÌœìæLÒÅ8Î…6±¾¥6{f¾C&amp;l€@'´%LºJëº&lt;Ç8{;ÏÌ¶à5�\„_öotÝœNxí9NŒTNøÓ‚YVqN¥‰Â³'÷‹‘	€f¸Cù­¸‰Î{)À­ªã^vO/=0”º÷Å£VòŒÜ½þÇv4µÒO9Ôž„Qaœ%0t|'³]±Ý¥
åîSÛÞ9W^ì|�KwAKôpZ—ÚŽÒç.Ÿ@®[;œªc{e]`·h;ïý(¼ËTpÏí¾”éÉ.ïlŒšÖî3%@ö¥n¡Niƒ¦rg\¿°&lt;¥&gt;\î‚RðÆ?ÒO’×ôm“Å‚Þ»ûxæFX·áÛþ0ØË¬ûu5îîlPÁp:�ÖòsŽ#€¹žgv»ÞR—â¯”{È�	ÿ„O˜òþñŒ+i“Ú&nbsp;aJÙ¢aæ@¯ì-zØ ¬”`Úû˜Ã»§vñª¼ ;p9ý”¾!æ¡«Þ”9²&gt;&lt;Nž²Dc^Ìç7òÒý B€³§'×Ýš¬±�5Ã}I©ö¸gWªe´ÀÔââBùˆôç•o¾‘¸åw,TJlY¶�ŠS†×§ÄS/çÇµ-»PÏó¬T¥ÜäåÐÚômüçd›}_öû`$N;_l;Í�€ COH(WÃˆÙ»
¯ºzÒö/¦ç¦P®ð"z#oÈÅŒuà-K—AøXÁ�¿®SàB˜YÅDmŒþƒCÅ/‹Áp¶vø€qã¹ÔPsš3(‹Pïñ+LÒv7W¦&lt;Ô!¶²á+Áw{ml°Pç®r@nsuuTg°ÅHì0ÞG¸¬E/:|Ì�ûÀgGEl=²ìÑQÇF5_ô`Ct˜L&amp;r×ŠàÛãN¨çßIôÙ¯ÎÑÔrDì·³ütr6H›W³©á5Py†¸)´ FFdúøµê¤ö¿¼Ís&amp;XAÖÖ±\Ì6æ¬Ub:iÈ_1œ·´mb;½Šq•ñîË¯Í»8Í9ÊfKÅ³×[u&amp;âÛnª¦&amp;Ë"é¢õB·�˜ïuŸø©EîŸaà8qëÊ	ãíø*¿&lt;Ï *‹´fS15÷î¨©:â©Å¦-3öÈù´�ñEãÓ�A½}šd
Î™Òü= RGW?ÖUì˜U¿»²áŠÊNÇ…�(á­}b¢/WnT	Ï_DgòÝûnÌ¡”/EŒaç¢êÆV`�rø„BšOî|ŠÚ­TàìšÜyá‰»PPáûË £?T’Í¡CÊðs¡µì5x†y×�ñæáÜÏ_'§L´Ãx-(§�U&nbsp;bû[ír&gt;Co™»†j²	Býúç†íO,ô×‰²¬Œ•‰È�—T&nbsp;SæÂÖý²'‘|ã[0}&gt;vE&nbsp;âÐÚa†7LÉtàù0ÒÄH6nx×”ŒÚ¦E…è„žßÍC�³ˆ#”lÇ4ç&nbsp;}ÏG=x=í'´æ#árýÕtƒ,‚ÔÃŸp;¹ïÚrf¶Å[Î¡ÕH?”‚-ê'Ì¦ÜX¶Á-é‡dìõžIV
[�±	ƒ5Úñ¾d&lt;ÆŽž·L/î9þSGæOŒq;«T^�…œå�@¶x•ââñäïŸxœ0ë³­'ƒXòOaÐð‰³´+š“
®ˆ[ˆø;igV`Ôz}á±„n&gt;Éõ&gt;â¬@‚ù‡ç(ÏNwSF~›¨H¶;P’ñˆî´Õç)b½øG–�—ÂU–ÀQ/§Ð^Û¼d„vÚË–N?7½ùj¤‰Îï¼Y
kG–ˆ½À“ÊBÆç€EC`ÙîŸ?.„þù5âêEÉé&lt;¦Hªþ^øÔ!µÎÛe19ü,âlÝœITw sPÇFí�=µœÍ?Rn'Ds‡vK‹7m^„Ù¿p–ŒÑX
ÉÎb§R&nbsp;%ì))åðà gF©_¿Ðþ9ÌCÖúWGÂ@¹!~Ýã}rÂK÷¢Öµs5e[þIBn-É3ú*AUIž­±Š]�#l81nfŸc)ôLß¡g�
ˆ¼£¯FŠ\¸Ç^ïÒ¬�wÌ—0;öÑêä§GEóÓ"Ë³fó
øX*`‰{ˆÌB«3ÝŠmX¨&amp;ñþ·mÕŠ²©š]ºì�Ëó üˆqXi’“çñ(†aÜ
@0ö�.Díz«+êŒœ'µqX]&gt;�8óšª¤r(¤�ßW(¢eã‹‡‚YA,±õ/É–�hizjGž�,m.×Üˆ¯.Y+„nÈT‚7þp¯:|Goª‡­
‹X°¨‡Zø6&amp;L²×ú#Ÿ­Ÿí §sØ&nbsp;žä½×ùÃ
ÕJW$ç
8aY&nbsp;”†êkÿ²X=­ïIrd¯€ÃËÊ¤ž˜.•ÿä¶‹g™$Š^«&lt;Þø¥Ÿ•*ˆÐxEødèriR5YÖÏi‘+âÔ«x‰¶\®ÓÅ{
ŸîVå?B‡�&lt;ë] ëËî:Xå$÷SBáKN[F�¬ê¬è=C…‚³NƒO(ÞåÐPW&amp;ƒÃâ}Ã8wž¸3éJI”×9G#8NmW„ª±iI‰ûœÏ¤$ÍïNgr11§8‘É
îÐ–ÿ¹lžG­ƒÚËÔ3\x—HSâx˜ð"S…�á4@Wâ’•Ì@Õ(jE„ª
dã{8·2œŒþVŒÍð9q¬�ÏOtÅfyš%ÜpL\Öb±Õ„¥Ú™Žzåmí~þí¡Ö78R�âªË‹ÐÉúýÊ¨%&gt;L²È¶Õ™Žl–ý~ö
Ž\Å“#SöläQáù@z9ÒvÃ°�FZÕâU†“ç†c%†=þEdµ;¨£ÚCó•¥sf7OŒC�‹Û€€¾rqÁ([ü±‡X\•[Z›õmUõŸæîwk4³†	]?ÿY_áŠÀéj&amp;¬UáÃ(dW‡f¿%V†G"{ÏÛUdÑ×„W¿À„¡c&lt;•ˆUW.ùÂ<wemj%º‹Ü#‡øÚ\þf�Ïbàn…Ìçzq.hÚaŠš¸Ž+‚¦«Ú%¯ˆ¿’�i*‘¸ïžÇßrß†í£Ê²¦>#OZy?ªD½qÝfK¼cŸlÔ'åGÑºýõ‚Å-x²´ÎZGr—ôé‚÷óÄé+?XÝ#_[¤ì½	Å„6üsl5
ð‰Œ÷±ÌÑ~ù»ñàvÂ3ûÕï�HT¹OöMùˆƒ¹eL¤Âl™Y«(ê‘3mðbBO)Ï˜ø
æÍYb–&lt;î~óÖ¿x¡°S�ƒ
2âQÛTM±áÂæð¸¢Õÿ_:nºðÜ9ÒVŽA¨6¸&gt;ó½�h�H6¹™Ô±A²7NÕ¥žäæ|�Ìû.€rlêMsÐ•�läÛ(f0Û0Œ^€ªö·�¥áûsnÁ\._àñløÈ.�Qò¬à=e‘i¯Ä$Û½ÞN‘wIKÛ³”“ä›|iŽ1?ÆØÂ!n…øú¬ƒÁ(Iè ¶IÞ�'ÓîýêàCãþÜY€VÔ(œ,JV°ý�ÙYšWbÅé§»3?!äà”Òè5…ÕÍ…z?ï,GÀ°]úä±®+¨gùFÙ¿€qÝÐg¯Xç`ñý‘H|žZóëNGòŒ@×nù�ë!(Bå‚{XÊ(!‡ŽXó§ï$c[P$ßb¨Û/!lyîH�âi€1˜´NAbËåt;êN‘§éÐö`ô
Îj•ÓŽŠ¬SüËÜŸŽur!!«�)Sß£¹y¢¾i±iŽG³ŸÐwW×CµˆSc¬;ð–7íB-™“¢^ÂÈ ‚«O
{wã½„J§×üøŒó¤9�ZæÉb8£\‡Ï±™—¼^kO;YU,‚/ª°Xå¼ÌD‰+¼˜Àý¥&amp;q™&lt;1V&nbsp;Bhû3Ê… EùI®¨�±’gÐxeÚƒxK‡Ž^�«Cé¸q9WËñ§X["(ÓbQ·bÐs€4ûZ…º±Þžì»ëûU%*�nºi½&lt;Á®†·Gô»W†öõP‹³^¡9È¤K¯œ˜FCÒÏgó*s²ÁFç+ÒÍ°Pôe#÷a8›1òêOöë=ÕZÂ›Žw?¿Ò"™´f¤¼¿ƒÙ&nbsp;…â&gt;¾–Ly¨›¥˜Úýœ§sh¨?’9Þ×¤ƒ(ÕúfB�¬S×ùÉÏÍÞ„‚$Á�)Ø:&amp;…‰1oÛXÑÖ±òÜÂÇNï
œ±�þµðaØŽ`öâôãLò›Ñ�i„täj?Â�RBUF7+à%žÕ	î@š­ÌãBºšæ‚&amp;"À‹f&amp;ýµlÀ²MÓd-)nÐÅïWèùf[¨Ëä¤„…K!ê›Î =›s(æäæ¢ŽhZ?°àê,ˆOè]Ìé_YÝùäÙÉôÏ«X#«=Ãig‘Â8U³Èg~¸Y’þ•hx1Q6P!§}âj³)ÿÀzÐwÒÛG
&gt;\oÔ$
S�€´¾^ÔMmPÍjqË|QoÄ°áÒp£¡ÑVqAÑ—Ü)

˜eù)­€5¯£€�zè\^…ìýš3ãì*Á¹îí!]Oó„3Š9Ó^àø55È„È“—×¶t™R@„¯Ä®¦uŒéÖwÈV4,ª£Éœlïá)U[J¤Ù;aÑn�H‰Ž
y&lt;£«¹rÜû2ø�k4z®‚¢+¶¿&nbsp;èØñX×žÏ—Kÿe“zvIU­›»ÓaÕ&lt;Ô3®ÜÞæŸ|ÏvE€e&nbsp;]Ö1ú¨HÆÄ^êÄÐ\¥v™E=üPM&lt;Æé’ÉÅi¯„êœ1Ù,t‘rê0iìIø}âsI¦¤N|÷2˜è]€T½3;Ùã`{amPcÞád€ÏT˜N%&amp;Ô×G	¿ýHÍU~=@‚vœ0”9qØ@ˆ}ÆÐ­H°õfÞ—º‰ç½µúIiKØf�mOW¿“�ãì,lÁ¦¡S.C"bx*ú¥j}º–å›Vj¶´Ô§G@–]˜•5â£,³ü&nbsp;ºPÖ�GÉè"Ê�Àxó¯_d`�Á�Vtý¶&lt;ÛYýø,µ80ÖÔ§yœÓE5“v©4Œˆ_©—Œž¬ü¨÷l±2&lt;‡˜ÛÔ•Á„�&amp;�àÏ²‡u'ÖÍ\ü¥Ü.?àðšñ}ølá©¼#�·S‹enê2õo­Û«ïå`é—‡°,ËMµ�
¢T�ŽS“Ä9œæ¥£ôÐÎ–ÂMøèßb�6üú”fr3Á ÓYc�d£b¥•à±LŽ$«Æ†ˆ7ôQ³à�OU–uÕó7Neÿ*ókâØÅÿ`×©¿‘öÇxñtøpfã+Ýv'“^¥œ�èµìF
»~È9Þguq`ø™ü9î-BÉè³qâ¡Ì%h-Ûn…JF_¦[£Èw¥`&lt;\U.lÞZ´!(‡€âÙ²ÛDZ0®´*§ë›&nbsp;ÞÚ–še¡Õ"ÁÐy¥§~§TÒÅlÇ0SüxÄsG�8®�SS*5çó;†2JT»Ø‘UB&amp;f|î<púß¶¿93žg”tÏö|nº•×4|¨zx+vÖ]‰´)c‘¼ât¬› ðuÒ¥ãlà×‡j<¤îh="" ·^káqµt€èb}+lÑ©_="" ÍÃÈx‚¥þ£2üo0¦hc0«Ëô·z£="" e3©nt±”ÀÄlsq ¾l3§›š6k^Ü:ƒûìi…É"ü6ù×'¯c×Í®<p4Žêxspez1@¼¿²ÑÓ‚°âdàØiÐe¾À«»ˆlå†)–~ÛhgËf›@ºÏ°fãp†f="" %Ä2µk5aùÔi9nÀ"~ŸÄ­9}gqçz]%Çô±!15zvŸô-ezr)Æóiè:•còñ¾j3Ô%h="" ã�\à8îv¼›¦©“v§òñ‘“•~="" Ê6Ð="" mtft03="" i:¡‹ÿh¬akêt*& ="" {�ÕªÚôùù="" ·£Æ(ìÖ9üük#ðïŠwobi±l�(Ðœ?ñêˆ—Ôsq¡-r˜xÃ‹px%÷‰v}¼5‹•¡‹ùû„¸Ûho-¤ï„¢ÿŒÙuáe©øþ‰¤a`,a€m7ªi–rÛ÷�fez¬Ð…k.}sñÁ’¥8²�Óo'é?]?,¥-áºaÕ´vòfj�¼žÆÆ6_Ãé(u!ù3guùåólücr)3žzø59à�°6$øâ’ïÕ©§4ñÆhsñ‰�oµ»noÆ2="�ŒiêR‡#ÆµYª+hQJwCçBy/A´H&nbsp;Â" q¥u"„‹øé:c�ÆÑwòqx1p°?Ð+©™æx²�b|Üf="ŽªÄ²,q`”Õba}n•ñ|yŸYó;íÆÔEB­¿á�é¶L§’’8HÑÜÑµò‘jÎ�g­µLŒ&nbsp;¾`™Mºªhw™õò•·šÅæwT—†³Î�»R]3ºî�²Îúè/|‰°ˆ§vr1û£6ÎB¸´<<™»°ãLˆöˆ�×çS1·6ø!¼ñ—›" šv="">Í€½±1¨T5w¤Ò4öªV¶-_;­_÷üÀ¢càCò9V8äÈ‹Éw�àµ¦u1ÐCÒÍªþ3N†Üoˆ@#�ÙÈªÖ%ÎO¥ˆ¹
c?ÿOl2t¨»(–˜°1#*«QqÈ&gt;ä«ÇJø¸ƒJ¦SÝþùcåpÿ–Ãà�•ÓÎ-ÀŽ¢Ê”ÓF¥0Båò0¬ì&nbsp;/‡U�d"žŸéPebFX)ÞXx&amp;¢¤Ñh›ç&gt;PÌƒž³))ŒÚ÷`R&gt;†j=çtQå~Â;b£Ò{îyÊUÆ­+:mLbzi8…‘°AÙ~‰“OñËÿV½ooB•cQ­¾ÆRÞöÊ°/tI�­ü¹¹³ü
ç:Â;)û§{¡€RsÙ÷aß"Õ+¹I¼O#…Eº&nbsp;¯€*¦rudêdI/ÁÿØ†¿ößuÏ�!w†U2×Ì—`§ëgúÑv¿]¢&lt;+ÑrCË}É{‹	&gt;‚ýT¾I)¦E9Å®Tvý�ëÙ‰øÃó§¸@Yþù!¨Ø:n~H~ÜÖ3-£ýOL.-‡@}f„* ¹b2J6HyŠGHOª}É½«±à¬œ¤8RB°"úâ6zµNÖiu%eœM×uGŒåÅôµ‹p=£j²ö»_È°/_Œé oGªßFo_–HÑR1Ò€yNlê÷•[úûk€‡KÓdÏèvuSÉØïâ^®À‰Akü‰"y£9ÃJ+ÚLùòóË.ú»ÐMèŸvŒû¾Ëö7zOKvròF½Š#PF:ñ[k"ˆ°_/¡ÅîÇßþþ-ò+u�®�F•sMa•	òVëØ¨úúB+WÛFšÙ;(Ô&amp;4"Hë4'uÃ4C&amp;hfqÎ½&gt;k†ŒÕ"áÃ^†W_o	—·Äñ.OÓ&amp;ƒáº–g-éHvs8CÖñfµB$�âÛ:H=OþãJ¹¦Éú,Òœ?=™SëélË†;ðFÁ’ªàì†µ 5(hN„;™™;;³Û•SJN”þêd²kõM[Dq=p‹Æ©Á‚�
,Nò�ùœÝ!m|´y}QƒLX¼V 
#Aµ½)7•&gt;˜Ý+xÀó:4&gt;ªìÜçå=Mãt~LIÓJ‡´’„M|›’¤*0±	ñCË»–†éFç4ÕˆPüâ¤(…7Õ›Ð«qäá~ìA‹“´÷8ƒôUê`P&gt;</púß¶¿93žg”tïö|nº•×4|¨zx+vö]‰´)c‘¼ât¬›></wemj%º‹ü#‡øú\þf�ïbàn…ìçzq.húašš¸ž+‚¦«ú%¯ˆ¿’�i*‘¸ïžçßrß†í£ê²¦></a}×¨¦’mñ2uýúsþã¶µf”�[g`></a€â-ñôší³’è¯=¬éky÷ãßm~•‚></tøþ˜ì\></v%aá£œps1�l`ôbä2[›;�></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://socialsciences.mcmaster.ca/econ/ugcm/3ll3/mill/liberty.pdf">https://socialsciences.mcmaster.ca/econ/ugcm/3ll3/mill/liberty.pdf</a></em></p>]]>
            </description>
            <link>https://socialsciences.mcmaster.ca/econ/ugcm/3ll3/mill/liberty.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23636407</guid>
            <pubDate>Thu, 25 Jun 2020 02:54:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to write PureScript react components to replace JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 99 | Comments 72 (<a href="https://news.ycombinator.com/item?id=23636336">thread link</a>) | @JacksonGariety
<br/>
June 24, 2020 | https://thomashoneyman.com/articles/replace-react-components-with-purescript/ | <a href="https://web.archive.org/web/*/https://thomashoneyman.com/articles/replace-react-components-with-purescript/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  

  

<p>I have twice migrated large JavaScript apps to PureScript. At CitizenNet we replaced Angular with Halogen, and at Awake Security we’ve replaced most of a React application with PureScript React. Both companies have seen a dramatic drop in bugs in production.</p>

<p>It’s relatively easy to replace React due to PureScript’s <code>react</code> and <code>react-basic</code> libraries. The React mental model fits well with a strongly-typed, pure functional language like PureScript (or Reason), and using the same underlying library means that components can be shared between languages with little modification.</p>

<p>At Awake Security we share internationalization, a Redux store and middleware, and much more in an code base where PureScript regularly imports JavaScript and JavaScript regularly imports PureScript.</p>

<p>The best way to rewrite a significant app from one language to another is incrementally, while it runs. At first the new language can take over logically isolated parts of the app: the management dashboard, or the chat window, or a form. But eventually you must mix components from both languages together – for example, to support shared global state.</p>

<p>At this point you can’t just let the new language take over a DOM node. You need to support simple, clear features for intermixing the languages. Fortunately, you can transform the interface of idiomatic PureScript code into idiomatic JavaScript (and vice versa). With <code>react</code> and <code>react-basic</code> you can write business logic in PureScript but easily interoperating with the larger React ecosystem and your existing code.</p>

<p>In this article I will demonstrate how to replace part of a React application with simple components written in PureScript. Along the way, I’ll share best practices for making this interop convenient and dependable. The examples will be simple, but the same techniques also apply to complex components.</p>

<h4 id="sections">Sections</h4>

<ol>
<li><a href="#let-s-write-a-react-app-in-javascript">Write a tiny React application in JavaScript</a></li>
<li><a href="#setting-up-a-shared-purescript-javascript-project">Update the application to support PureScript</a></li>
<li><a href="#replacing-a-react-component-with-purescript-react">Replace a React component with PureScript React, with the same interface and behavior as the original</a></li>
<li><a href="#replacing-a-react-component-with-purescript-react-basic">Replace the component again with React Basic</a></li>
</ol>

<p>I encourage you to code along with this article; no code is omitted and dependencies are pinned to help ensure the examples are reproducible. This code uses Node <code>v11.1.0</code>, Yarn <code>v1.12.0</code>, and NPX <code>v6.5.0</code> installed globally, and PureScript tooling installed locally.</p>

<p>Peter Murphy has <a href="https://github.com/ptrfrncsmrph/purescript-react-tutorial">implemented the ideas in this article using React Hooks</a> if you’d like to see this in action.</p>




<h2 id="let-s-write-a-react-app-in-javascript">Let’s write a React app in JavaScript</h2>

<p>We are going to write a tiny React application which shows a few counters, and then we’re going to replace its components with PureScript. The resulting JavaScript code will be indistinguishable, aside from imports, from the original, and yet it will all be PureScript under the hood.</p>

<p>Let’s follow the official React docs in using <code>create-react-app</code> to initialize the project and then trim our source code to the bare minimum.</p>
<div><pre><code data-lang="sh"><span># Create the app</span>
npx create-react-app my-app <span>&amp;&amp;</span> <span>cd</span> my-app</code></pre></div>
<p>At the time of writing, <code>create-react-app</code> produces these React dependencies:</p>
<div><pre><code data-lang="json"><span>"dependencies"</span><span>:</span> <span>{</span>
    <span>"react"</span><span>:</span> <span>"^16.8.6"</span><span>,</span>
    <span>"react-dom"</span><span>:</span> <span>"^16.8.6"</span><span>,</span>
    <span>"react-scripts"</span><span>:</span> <span>"3.0.1"</span>
  <span>}</span></code></pre></div>
<p>We have a handful of source files under <code>src</code>, but our application will need just two of them: <code>index.js</code>, the entrypoint for Webpack, and <code>App.js</code>, the root component of our application. We can delete the rest:</p>
<div><pre><code data-lang="sh"><span># Delete all the source files except for the entrypoint and</span>
<span># root app component</span>
find src -type f -not <span>\(</span> -name <span>'index.js'</span> -or -name <span>'App.js'</span> <span>\)</span> -delete</code></pre></div>
<p>Finally, let’s replace the contents of those two files with the bare minimum we’ll need for this article. From here on out I’ll supply diffs that you can supply to <code>git apply</code> to apply the same changes I did.</p>

<p>First, our entrypoint:</p>
<div><pre><code data-lang="jsx"><span>// src/index.js
</span><span></span><span>import</span> <span>React</span> <span>from</span> <span>"react"</span><span>;</span>
<span>import</span> <span>ReactDOM</span> <span>from</span> <span>"react-dom"</span><span>;</span>
<span>import</span> <span>App</span> <span>from</span> <span>"./App"</span><span>;</span>

<span>ReactDOM</span><span>.</span><span>render</span><span>(&lt;</span><span>App</span> <span>/&gt;,</span> <span>document</span><span>.</span><span>getElementById</span><span>(</span><span>"root"</span><span>));</span></code></pre></div>
<p>Then our main app component:</p>
<div><pre><code data-lang="jsx"><span>// src/App.js
</span><span></span><span>import</span> <span>React</span> <span>from</span> <span>"react"</span><span>;</span>

<span>function</span> <span>App</span><span>()</span> <span>{</span>
  <span>return</span> <span>(</span>
    <span>&lt;</span><span>div</span><span>&gt;</span>
      <span>&lt;</span><span>h1</span><span>&gt;</span><span>My</span> <span>App</span><span>&lt;/</span><span>h1</span><span>&gt;</span>
    <span>&lt;/</span><span>div</span><span>&gt;</span>
  <span>);</span>
<span>}</span>

<span>export</span> <span>default</span> <span>App</span><span>;</span></code></pre></div>
<h3 id="writing-a-react-component">Writing a React component</h3>

<p>Let’s write our first React component: a counter. This is likely the first example of a React component you ever encountered; it’s the first example in the PureScript React libraries as well. It’s also small and simple enough to be replaced twice over the course of this article.</p>

<p>The counter will be a button which maintains the number of times it has been clicked. It will accept, as its only prop, a label to display on the button.</p>
<div><pre><code data-lang="jsx"><span>// src/Counter.js
</span><span></span><span>import</span> <span>React</span> <span>from</span> <span>"react"</span><span>;</span>

<span>class</span> <span>Counter</span> <span>extends</span> <span>React</span><span>.</span><span>Component</span> <span>{</span>
  <span>constructor</span><span>(</span><span>props</span><span>)</span> <span>{</span>
    <span>super</span><span>(</span><span>props</span><span>);</span>
    <span>this</span><span>.</span><span>state</span> <span>=</span> <span>{</span>
      <span>count</span><span>:</span> <span>0</span>
    <span>};</span>
  <span>}</span>

  <span>render</span><span>()</span> <span>{</span>
    <span>return</span> <span>(</span>
      <span>&lt;</span><span>button</span> <span>onClick</span><span>=</span><span>{()</span> <span>=</span><span>&gt;</span> <span>this</span><span>.</span><span>setState</span><span>({</span> <span>count</span><span>:</span> <span>this</span><span>.</span><span>state</span><span>.</span><span>count</span> <span>+</span> <span>1</span> <span>})}</span><span>&gt;</span>
        <span>{</span><span>this</span><span>.</span><span>props</span><span>.</span><span>label</span><span>}</span><span>:</span> <span>{</span><span>this</span><span>.</span><span>state</span><span>.</span><span>count</span><span>}</span>
      <span>&lt;/</span><span>button</span><span>&gt;</span>
    <span>);</span>
  <span>}</span>
<span>}</span>

<span>export</span> <span>default</span> <span>Counter</span><span>;</span></code></pre></div>
<p>Then, we’ll import our new counters into our main application:</p>
<div><pre><code data-lang="diff"><span>--- a/src/App.js
</span><span></span><span>+++ b/src/App.js
</span><span></span><span>@@ -1,9 +1,13 @@
</span><span></span> import React from "react";
<span>+import Counter from "./Counter";
</span><span></span>
 function App() {
   return (
     &lt;div&gt;
       &lt;h1&gt;My App&lt;/h1&gt;
<span>+      &lt;Counter label="Count" /&gt;
</span><span>+      &lt;Counter label="Clicks" /&gt;
</span><span>+      &lt;Counter label="Interactions" /&gt;
</span><span></span>     &lt;/div&gt;
   );
 }
</code></pre></div>
<p>With <code>yarn start</code> we can run the dev server and see our app in action.</p>

<p><img src="https://thomashoneyman.com/images/2019/running-app.gif" alt="running app"></p>



<p>We’ve written entirely too much JavaScript. Let’s support PureScript in this project as well. Our goal is to write code in either language and freely import in either direction without friction. To accomplish that, we will install PureScript tooling, create a separate PureScript source directory, and rely on the compiler to generate JavaScript code.</p>

<h3 id="1-install-the-compiler-and-package-manager">1. Install the compiler and package manager</h3>

<p>First we must install PureScript tooling. I recommend installing versions of the compiler and Spago (a package manager and build tool) which match those used in this article. I’ll use NPX to ensure all commands are run using local copies.</p>
<div><pre><code data-lang="sh"><span># Install the compiler and the Spago package manager however you prefer;</span>
<span># since we're already in a React project I'll use Yarn</span>
yarn add -D purescript@0.13.2 spago@0.8.4</code></pre></div>
<h3 id="2-initialize-the-project-and-package-set">2. Initialize the project and package set</h3>

<p>We can create a new PureScript project with <code>spago init</code>. As of version 0.8.4, Spago always initializes with the same package set, which means you should have identical package versions to those used to write this article. I’m using the <code>psc-0.13.0-20190607</code> package set.</p>
<div><pre><code data-lang="sh"><span># npx ensures we're using our local copy of Spago installed in node_modules.</span>
npx spago init</code></pre></div>
<p>Spago has created a <code>packages.dhall</code> file which points at the set of packages which can be installed and a <code>spago.dhall</code> file which lists the packages we’ve actually installed. We can now install any dependencies we need and we’ll know for sure the versions are all compatible.</p>

<p>Before installing anything, let’s update the existing <code>.gitignore</code> file to cover PureScript. For a Spago-based project this will work:</p>
<div><pre><code data-lang="sh"><span>echo</span> -e <span>"\noutput\n.psc*\n.purs*\.spago"</span> &gt;&gt; .gitignore</code></pre></div>
<h3 id="3-adjust-the-directory-structure">3. Adjust the directory structure</h3>

<p>Finally, let’s organize our source code. It’s typical to separate JavaScript source from PureScript source except when writing an FFI file for PureScript. Since we aren’t doing that in this project, our source files will be entirely separated. Let’s move all JavaScript code into a <code>javascript</code> subdirectory and create a new <code>purescript</code> folder next to it.</p>
<div><pre><code data-lang="sh">mkdir src/javascript src/purescript
mv src/App.js src/Counter.js src/javascript</code></pre></div>
<p>Next, we’ll adjust <code>index.js</code> to the new location of our root component:</p>
<div><pre><code data-lang="diff"><span>--- a/src/index.js
</span><span></span><span>+++ b/src/index.js
</span><span></span><span>@@ -1,5 +1,5 @@
</span><span></span> import React from "react";
 import ReactDOM from "react-dom";
<span>-import App from "./App";
</span><span></span><span>+import App from "./javascript/App";
</span><span></span>
 ReactDOM.render(&lt;App /&gt;, document.getElementById("root"));
</code></pre></div>
<p>We’ve just one task left. The PureScript compiler generates JavaScript into a directory named <code>output</code> in the root of the project. But <code>create-react-app</code> disables importing anything outside the <code>src</code> directory. While there are fancier solutions, for this project we’ll get around the restriction by symlinking the <code>output</code> directory into the <code>src</code> directory.</p>
<div><pre><code data-lang="sh"><span># we can now import compiled PureScript from src/output/...</span>
ln -s <span>$PWD</span>/output <span>$PWD</span>/src</code></pre></div>
<p>Your <code>src</code> directory should now look like this:</p>
<div><pre><code data-lang="sh">src
├── index.js
├── javascript
│ ├── App.js
│ └── Counter.js
├── output -&gt; ../output
└── purescript</code></pre></div>
<h2 id="replacing-a-react-component-with-purescript-react">Replacing a React component with PureScript React</h2>

<p>I like to follow four simple steps when replacing a JavaScript React component with a PureScript one:</p>

<ol>
<li>Write the component in idiomatic PureScript.</li>
<li>Write a separate interop module for the component. This module provides the JavaScript interface and conversion functions between PureScript and JavaScript types and idioms.</li>
<li>Use the PureScript compiler to generate JavaScript</li>
<li>Import the resulting code as if it were a regular JavaScript React component.</li>
</ol>

<p>We’ll start with the <code>react</code> library, which we use at Awake Security. It’s similar to <code>react-basic</code> but maps more directly to the underlying React code and is less opinionated. Later, we’ll switch to <code>react-basic</code>, which will demonstrate some differences between them.</p>

<p>As we take each step in this process I’ll explain more about why it’s necessary and some best practices to keep in mind. Let’s start: install the <code>react</code> library and prepare to write our component:</p>
<div><pre><code data-lang="sh"><span># install the purescript-react library</span>
npx spago install react

<span># build the project so editors can pick up the `output` directory</span>
npx spago build

<span># create the component source file</span>
touch src/purescript/Counter.purs</code></pre></div>
<h3 id="1-write-the-react-component-in-idiomatic-purescript">1. Write the React component in idiomatic PureScript</h3>

<p>Even though we are writing a component to be used from JavaScript, we should still write ordinary PureScript. As we’ll soon see, it’s possible to adjust only the interface of the component for JavaScript but leave the internals untouched. This is especially important if this component is meant to be used by both PureScript and …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thomashoneyman.com/articles/replace-react-components-with-purescript/">https://thomashoneyman.com/articles/replace-react-components-with-purescript/</a></em></p>]]>
            </description>
            <link>https://thomashoneyman.com/articles/replace-react-components-with-purescript/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23636336</guid>
            <pubDate>Thu, 25 Jun 2020 02:40:29 GMT</pubDate>
        </item>
    </channel>
</rss>
