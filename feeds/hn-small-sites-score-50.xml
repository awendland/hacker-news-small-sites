<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Wed, 22 Jul 2020 08:18:09 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Wed, 22 Jul 2020 08:18:09 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Minecraft@Home]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 8 (<a href="https://news.ycombinator.com/item?id=23895789">thread link</a>) | @networked
<br/>
July 20, 2020 | https://minecraftathome.com/minecrafthome/ | <a href="https://web.archive.org/web/*/https://minecraftathome.com/minecrafthome/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div><p><span>Server outage and supporting our infrastructure</span><br>

        Between 23:54 UTC yesterday (2020-07-20) and 15:35 UTC today, we suffered from a catastrophic SQL failure which forced us to restore from backup.</p><p>

There may be some credit issues where the system granted more or fewer credits than you expect for work done during this time.<br>
I can't apologize enough. If our BOINC deployment was architected for scale rather than for low cost, we could've avoided this.</p><p>

There are several enhancements to our infrastructure and upgrades we'd like to make, such as migrating services to Kubernetes and potentially using a managed SQL service.</p><p>

<span><b><span color="red">You can help!</span> Please consider visiting our Patreon page, reviewing the current set of benefits, and making a contribution of any size; any amount helps - <a href="https://patreon.com/minecraftathome" rel="nofollow">patreon.com/minecraftathome</a></b></span></p><p>

All contributions go towards covering infrastructure cost and quality-of-life improvements to ensure the project's longevity.
        <br>
        <span>21 Jul 2020, 20:10:54 UTC
    
            · <a href="https://minecraftathome.com/minecrafthome/forum_thread.php?id=44"> Discuss</a>
        </span></p></div><hr>
    <div><p><span>That was fast</span><br>

        The origin of the panorama image used in the Minecraft main menu from beta version 1.8.1, released in September 2011, has remained a mystery until now.</p><p>

<b><span>In less than 24 hours after launching the panorama application; a volunteer host for Minecraft@Home, in a sheer stroke of luck, found the world seed, 25357015387625.</span></b><br>
This was approximately </p><p><span color="red">93 days of processing time at a total of 54.5 exaFLOPs</span> compressed into the last 24 hours.</p><p>

The specific host which located the seed belongs to the user <a href="https://minecraftathome.com/minecrafthome/show_user.php?userid=2558" rel="nofollow">vanos0512</a>.<br>
Thank you to the 137 users who contributed 181 hosts with 231 GPUs over the last 24 hours. You all accomplished this.</p><p>

<img src="https://i.imgur.com/f6lGCEn.png"></p><p>

Here are the details if you want to generate this world for yourself:<br>
<b>Minecraft version:</b> <i>Beta 1.7</i><br>
<b>Either of these two valid world seeds:</b> <i>2151901553968352745 or 8091867987493326313</i><br>
<b>Co-ordinates:</b> <i>x60, y76, z-67</i></p><p>

<a href="https://www.youtube.com/watch?v=caLCZNLPgrM" rel="nofollow">See the video released by EarthComputer announcing the finding.</a>
        <br>
        <span>18 Jul 2020, 15:32:11 UTC
    
            · <a href="https://minecraftathome.com/minecrafthome/forum_thread.php?id=42"> Discuss</a>
        </span></p></div><hr>
    <div><p><span>Enjoy the scenery</span><br>

        <span>Minecraft@Home is now <span color="red">over one month old</span>! To celebrate this milestone, I present a new research focus; the panorama project.</span></p><p>

If you were here during beta-testing, you might have received a very early version of panorama tasks, and the eagle-eyed among you may have seen the application details <a href="https://minecraftathome.com/minecrafthome/server_status.php" rel="nofollow">on the server status page</a>.</p><p>

<span><b>The panorama app is a CUDA-only app for Linux and Windows with an Nvidia driver version of 418.96 or higher.</b></span></p><p>

This project attempts to find the world seed of the iconic panorama image which appeared in the background of the main menu of Minecraft between 2011 and 2018. The first phase of this project will only last a few days, and we shall update you with their progress in the coming weeks.</p><p>

<img src="https://i.imgur.com/3dyexWe.png"></p><p>

Right now, the application is quite substantial. Unlike the OpenCL applications for the Kaktwoos project, <b>if you allow BOINC to run tasks always; you may experience some stuttering or lag in your desktop environment while running these tasks</b>. These tasks do not have checkpointing support, but run in around 1 hour on an average host to mitigate the majority of lost cycles.</p><p>

<span>As always, <a href="https://minecraftathome.com/minecrafthome/prefs.php?subset=project" rel="nofollow">you can change which projects of which you decide to participate in your user preferences</a>.</span></p><p>

Let us know if you have any questions, and as always join the discussion over on <a href="https://discord.gg/xVFh9bp" rel="nofollow">the Discord server.</a>
        <br>
        <span>17 Jul 2020, 15:31:43 UTC
    
            · <a href="https://minecraftathome.com/minecrafthome/forum_thread.php?id=39"> Discuss</a>
        </span></p></div><hr>
    <div><p><span>Kaktwoos 2.03 and Badges!</span><br>

        You may have seen many workunits just disappear from existence today.</p><p>

<img src="https://munin.kiska.pw/munin-cgi/munin-cgi-graph/Munin-Node/Munin-Node/results_minecraftathome-pinpoint=1594193183,1594247603.png?&amp;lower_limit=&amp;upper_limit=&amp;size_x=400&amp;size_y=200"></p><p>

Worry not! We realised there were far too many workunits scanning duplicate seeds, so we've scaled back the original workunits to the correct seed ranges <span><i>(no in-progress results were touched, so none of you should have lost any credit)</i></span>.</p><p>

We have located some promising seed candidates which were missed from processing and can be used as an input to this job, so they are currently set as the highest priority.</p><p>

Also, <span><b>we now have badges</b></span>! If you view the forums, any comments in threads, or on the leaderboards; you will see the new badges.<br>
We're open to suggestions for future badges, so please leave us some comments on this thread.
        <br>
        <span>8 Jul 2020, 21:06:03 UTC
    
            · <a href="https://minecraftathome.com/minecrafthome/forum_thread.php?id=30"> Discuss</a>
        </span></p></div><hr>
    <div><p><span>Profile creation and OpenCL vendor pinning</span><br>

        In the last news post, I advised everyone to create a profile in order to be eligible for 'user of the day' selection.<br>
Unfortunately, there was an issue with the ReCaptcha implementation which prevented this. This issue is now resolved.</p><p>

Now, you are able to <a href="https://minecraftathome.com/minecrafthome/create_profile.php" rel="nofollow">create a profile here</a>.</p><p>

Also, good news for hosts with OpenCL capable hardware from more than one vendor <i>(e.g. an Intel iGPU and an Nvidia GPU)</i><br>
The latest update to the kaktwoos app should ensure the tasks run on the correct device.<br>
If you are a user with a multi-vendor host, please keep an eye on your results and let us know if you're having any issues.</p><p>

As always, please get involved with the conversation in the <a href="https://minecraftathome.com/minecrafthome/forum_index.php" rel="nofollow">message boards</a>, and <a href="https://discord.gg/xVFh9bp" rel="nofollow">join the Discord</a>!
        <br>
        <span>3 Jul 2020, 16:57:49 UTC
    
            · <a href="https://minecraftathome.com/minecrafthome/forum_thread.php?id=22"> Discuss</a>
        </span></p></div><hr>
    <p><a href="https://minecraftathome.com/minecrafthome/old_news.php">... more</a></p><p><small>
    News is available as an <a href="https://minecraftathome.com/minecrafthome/rss_main.php">RSS feed &nbsp; <img src="https://minecraftathome.com/minecrafthome/img/rss_icon.gif" alt="RSS"></a>
        </small></p></div></div>]]>
            </description>
            <link>https://minecraftathome.com/minecrafthome/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23895789</guid>
            <pubDate>Mon, 20 Jul 2020 08:19:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Video Vectorization]]>
            </title>
            <description>
<![CDATA[
Score 122 | Comments 55 (<a href="https://news.ycombinator.com/item?id=23895211">thread link</a>) | @xanthine
<br/>
July 19, 2020 | https://vectorly.io/docs/technology/ | <a href="https://web.archive.org/web/*/https://vectorly.io/docs/technology/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">

<p><img src="https://vectorly.io/docs/img/vector-graphics.png" alt="Drawing"></p>

<p>Vectorly is developing a new kind of video compression technology, which uses computer vision and vector graphics to reduce bitrates for video content by an order of magnitude (or more) compared to HEVC, while <strong>improving video</strong> quality. </p>
<p>This would be primarily effective for "vector friendly" video content, which would include animations, screen-casts, many e-learning videos and potentially 3d gaming content. </p>
<p>By leveraging existing vector-graphics rendering capabilities on all devices, this codec wouldn't require end-users, OEMs or browsers to install special software to enable playback of these videos.</p>
<p><strong>We are still in the early phases of developing this technology</strong>.</p>
<p>You can learn more about the technology in our <a href="https://files.vectorly.io/Vectorization+Whitepaper+v06.20.pdf">whitepaper</a></p>
<h2 id="the-core-idea">The Core Idea</h2>
<p>The core insight behind this project was that you could use vector-graphics based animations to simulate "videos" in a way that is indistinguishable from a traditional raster-graphics based video format such as an h264 video stream in an MP4 container.</p>
<h3 id="raster-graphics">Raster Graphics</h3>
<p>Normal videos, like the ones you see on Netflix or YouTube, are just sequences of images which get updated quickly on the screen, to create the illusion of motion. Each image is composed of "pixels" - individual dots of color. Higher resolution means more pixels, better visual quality, and bigger file sizes.</p>
<p><img alt="Pixel-Based" src="https://vectorly.io/docs/img/pixels.png"></p>
<p>Almost all video on the internet is of this format, known as "raster graphics". Video compression algorithms like h264 are just very efficient at using fewer data-points to reconstruct the pixels in any given frame, and at storing only the differences in pixels between frames of a video. </p>
<h3 id="vector-grapics-video">Vector Grapics video</h3>
<p>In contrast, we use a concept called "vector-graphics" to render video. Instead of pixels, we represent everything on the screen using shapes, lines and curves, which can be represented as mathematical equations (vector graphics).</p>
<p><img alt="Vector-Based" src="https://vectorly.io/docs/img/vector2.png"></p>
<p>Using these mathematical equations, we can re-draw any arbitrary shape on the screen - from the letter "T" to Bart Simpson's head. Furthermore, by adding information such as color, position on the screen, and how they move or change shape over time, you can create whole videos - including entire episodes of the Simpsons, with just sequences of mathematical equations.</p>
<h3 id="why-vectorization">Why vectorization?</h3>
<p>The core insight behind this project was that for a certain kind of "vector-friendly" video content, storing the video using vector graphics would be much more efficient than using raster graphics (in some cases, up to 2 orders of magnitude more efficient).</p>
<p>This idea is not substantively different from the idea of Flash based animations about 20 years ago. Why do this now?</p>
<p><strong>No need for a decoder</strong>: Most devices now support SVG, HTML5, WebGL/OpenGL and/or some form of hardware-accelerated vector-graphics rendering. That lets you render vector-graphics content on any device without require end-users, OEMs or browsers to install special software to enable playback of vector-graphics content, and to achieve native-level performance by doing so. App developers would only need to include an appropriate library or SDK in their website or app to enable playback within native or 3rd player video players.</p>
<p><strong>Computer vision</strong>: Our patented vectorization technology relies heavily on computer vision to convert raster-graphics videos to a vector format. Leveraging the advancement &amp; commoditization of Computer Vision, and the ease of running batch computer-vision heavy tasks on the cloud, it's feasible to 'vectorize' large volumes of video at scale now, in a way that wasn't possible even 5 years ago.</p>
<h3 id="vector-graphics-video-format">Vector graphics video format</h3>
<p>We are building a video-format based on existing standards (SVG, WebGL &amp; OpenGL), extending it with Javascript to enable video features such as a timeline and key-frames. We package the resulting video data within an MP4 container, which can be streamed and distributed using existing video infrastructure (such as HLS/DASH, and DRM systems).</p>
<pre><code>&lt;video src="vectorized.mp4" type="video/svg"&gt;
</code></pre>
<p>We are pragmatic, and don't want to create a standard <a href="https://xkcd.com/927/">for the sake of creating a standard</a>.  To that end, we've created libraries and SDKs that enable playback of our vector-graphics videos using standard / native interfaces like so</p>
<pre><code>&lt;script src="vectorly.js"&gt;

&lt;video src="vectorized.mp4" type="video/svg"&gt;
// This will work on all major browsers today
</code></pre>
<h2 id="demos-proof-of-concept">Demos / Proof of concept</h2>
<p><strong>Simpsons</strong></p>
<p>Our first vectorized proof of concept for animations is a 17 second clip of the Simpsons located <a href="https://files.vectorly.io/demo/v0-2-simpsons-250kbps/index.html">here</a>. Keep in mind, our technology is still at a very early stage, and this is much optimization work left to be done.</p>
<p><strong>Khan Academy</strong></p>
<p>Our technology also works very well for e-learning, and especially Khan Academy style content. You can find 30 second Khan Academy clip <a href="https://files.vectorly.io/demo/khan-20kbps/index.html">here</a></p></div></div>]]>
            </description>
            <link>https://vectorly.io/docs/technology/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23895211</guid>
            <pubDate>Mon, 20 Jul 2020 06:30:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[In Praise of ZFS on Linux's ZED 'ZFS Event Daemon']]>
            </title>
            <description>
<![CDATA[
Score 77 | Comments 18 (<a href="https://news.ycombinator.com/item?id=23894790">thread link</a>) | @zdw
<br/>
July 19, 2020 | https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSZEDPraise | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSZEDPraise">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>In praise of ZFS On Linux's ZED 'ZFS Event Daemon'</h2>

	<p><small>July 19, 2020</small></p>
</div><div><p>I've written before (<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSFileserverSameness">here</a>) about how <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSFileserverSetupIII">our
current Linux ZFS fileservers</a> work much
like <a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSFileserverSetupII">our old OmniOS fileservers</a>.
However, not everything is quite the same between ZFS on Linux and
traditional Solaris/OmniOS ZFS. One of the most welcome differences
for us is <a href="https://zfsonlinux.org/manpages/0.8.4/man8/zed.8.html">ZED</a>,
the ZFS Event Daemon. What ZED does that is so great is that it provides
a very simple way to take action when <a href="https://zfsonlinux.org/manpages/0.8.4/man5/zfs-events.5.html">ZFS events</a> happen.</p>

<p>When a ZFS event happens, ZED looks through a directory (generally
<code>/etc/zfs/zed.d</code>) to find scripts (or programs) that should be run
in response to the event. Each script is run with a bunch of
environment variables set to describe what's going on, and it can
use those environment variables to figure out what the event is.
ZED decides what things to run based on their names; generally you
wind up with script names like <code>all-cslab.sh</code> (which is run on
all events) and <code>resilver_finish-cslab.sh</code> (which is run when a
resilver finishes).</p>

<p>Because these are just a collection of individual files, you're
free to add your own without colliding with or having to alter the
standard 'ZEDLETs' provided by ZFS on Linux. Your additions can do
anything you want them to, ranging from the simple to the complex.
For instance, our simplest ZEDLET simply syslogs all of the ZED
environment variables:</p>


<blockquote><pre>PATH=/usr/bin:/usr/sbin:/bin:/sbin:$PATH
export PATH
if [ "$ZEVENT_SUBCLASS" = "history_event" ]; then
        exit 0
fi
unset ZEVENT_TIME
unset ZEVENT_TIME_STRING
printenv | fgrep 'ZEVENT_' | sort | fmt -999 |
    logger -p daemon.info -t 'cslab-zevents'
exit 0
</pre>
</blockquote>

<p>(There's a standard 'all-syslog.sh' ZEDLET, but it doesn't syslog
all of the information in the zevents. Capturing all of the information
is especially useful if you want to write additional ZEDLETs and
aren't quite sure what they should look for or what environment
variables have useful information.)</p>

<p>It can take a bit of time and experimentation to sort out what ZFS
events are generated (and with what information available) in
response to various things happening to adn in your ZFS pools. But
once you have figured it out, ZED gives you a way to trigger and
drive all sorts of system management activities. These can be active
(like taking action if devices fail) or passive (like adding markers
in your metrics system or performance dashboards for when ZFS scrubs
or resilvers start and end, so you can correlate this with other
things happening).</p>

<p>Coming from Solaris and OmniOS, where there was no such simple
system for reacting to things happening in your ZFS pools, ZED was
a breath of fresh air for us. More than anything else, it feels
like how ZFS events should have been handled from the start, so
that system administrators could flexibly meet their own local needs
rather than having to accept whatever the Solaris Fault Management
system wanted to give them.</p>

<p>PS: Because ZFS on Linux is now OpenZFS, I believe that ZED will
probably eventually show up in FreeBSD (if it isn't already there).
Perhaps it will even some day be ported back to Illumos.</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSZEDPraise</link>
            <guid isPermaLink="false">hacker-news-small-sites-23894790</guid>
            <pubDate>Mon, 20 Jul 2020 05:03:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Don't Want to Be a Founder]]>
            </title>
            <description>
<![CDATA[
Score 141 | Comments 111 (<a href="https://news.ycombinator.com/item?id=23894387">thread link</a>) | @kipply
<br/>
July 19, 2020 | https://carolchen.me/blog/founding-bad/ | <a href="https://web.archive.org/web/*/https://carolchen.me/blog/founding-bad/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  <header>
    
    
  </header>

  <main id="main">
    
<article>
  <header>
    
    
  </header>
  <section id="js-article">
    
<p>I had a brief run with a startup (literally a month) and was faced with the decision of going into a YC Cohort. In that fiasco, I also spent at least twelve hours trying to convince other people to go. It's been half a year, and I've had a lot more time to reflect on reasons as to why one might want to run a startup. As you might've guessed, I decided not to do it and I genuinely believe that running a startup seems like a bad idea for the majority of people I meet who want to become founders. </p>
<p>This post definitely will not apply to everyone (I'd loosely say applicable to 80% of prospective startup founders), but I'd hope there's some valuable thinking in here. Also, note that this is fairly oriented towards technical founders. </p>
<p>Edit: This post also has a very limited scope as it's based off the thinking from my decision to continue interning at Shopify or to go to YC. It's very focused on the Silicon Valley "startup" where you get a VC to give you money and get big in a year, etc etc</p>

<h3 id="commitment">Commitment<a href="#commitment" aria-label="Anchor link for: commitment"> <i></i></a>
</h3>
<p>I'm not talking about commitment to your company. I'm talking about commitment to your cofounder (if you have one, which is likely). </p>
<p>Maybe I'm too young to understand, but marriage seems frightening! My finances, my social life, personal time, and emotional wellbeing would be largely dependent on a single person and that's scary. It should be scary or should at least take a few years for it not to become scary. </p>
<p>Your cofounder is...kind of the same? In a seed-stage it's likely you <em>actually</em> live together, and if you don't, you're likely functionally living together with the amount of work involved. They're responsible for your financial well-being. They may be responsible for the quality of your social lives (most founders spend a lot of time socializing with other tech people + founders). They're tied to your life goals, your dreams, and your passions.</p>
<p>My impression was that my relationship with my cofounder would be more intense than marriage, and <em>extra</em> bad in the event of failure since there's additional loss (and it's statistically likely, but I guess so is marriage). I totally believe that there are cofounder pairs that are completely ready to go through the founder journey and pairs that maybe weren't ready but were fine anyway, but I stand by the statement that it's more intense than marriage and not enough people put care into this. </p>
<h3 id="your-vc-is-not-the-one-at-risk-here">Your VC is Not the One at Risk Here<a href="#your-vc-is-not-the-one-at-risk-here" aria-label="Anchor link for: your-vc-is-not-the-one-at-risk-here"> <i></i></a>
</h3>
<p>I often hear sentiments that resemble "wow these VCs are taking a chance on me I better commit to this!". </p>
<p>VCs are not evil people trying to take advantage of you (actually they might be, but let's assume they're not), but they are not the ones at risk. For them, 150k or a few million is not a huge risk. Seed-stage returns will be from a very small percentage of investments, thus VCs can afford to have comically high error rates as long as they get the few that matter. If you're SoftBank you can do even worse and still have so much money! They make decisions carefully, they care about your success for various reasons, and are generally caring people (in most of my experiences) but in larger abstractions, your startup means nothing to them. </p>
<p>They're not shy about it either, the entire reason they're investing in you is because they think you're more valuable than you cost. 
<img src="https://carolchen.me/blog/img/founding/paul.png" alt=""></p>
<p>Your risk is years of your life, blood, sweat, and tears. The next few years (provided your startup lasts till then) will somewhat be in service to these VCs. The VCs are your "bosses" as you answer to them (though <em>much</em> less than a regular "boss") and to the ones you hope to raise capital from in the future. </p>
<p>It's good to take a risk with increased confidence because qualified people think you have promise. However, that can morph into "I'm going to work on this startup partially in service to these people who believed in me and gave me lots of money". These additional stresses that come from meeting VC expectations and the complications of the dynamics of the relationship can cause various problems.</p>
<h3 id="sense-of-self">Sense of Self<a href="#sense-of-self" aria-label="Anchor link for: sense-of-self"> <i></i></a>
</h3>
<p>This one is the one that got to me most but I can see it being irrelevant to a lot of other people. </p>
<p>Many founders have big egos -- I don't mean they're assholes or overly self-important but they do have very powerful confidence, because that's a valuable skill to have as a founder. Not just confidence in pitching their project to others, but in their vision and their company. They need to believe their company will be successful (though I have met founders who just want to party with VC money for a few years <em>cough cough</em> Neumann). </p>
<p>My first fear was that I created an ego for myself rapidly. Practicing to sell to clients and for your YC interview involves repeating to yourself why you are <em>good</em> and self-hypnosis is fairly powerful. I love feeling good about myself, but I suddenly found myself feeling more confident in myself than what I believed was warranted. More frighteningly, I had a major character and energy change in a couple of weeks. Losing so much of my identity like that was unnerving, not to mention the ripple effects that could've occurred in my social life. </p>
<p>The other fear is coming down from that. Startup founders (especially the more eccentric ones) sometimes believe that they will build something that will change the world. Along with that, their identities start to merge with their company. There's nothing wrong with that, but I also think it's exceptionally tragic to come down from that. It's not just dealing with failure and getting back up on your feet, it's losing a part of your identity. </p>
<h3 id="school-is-generally-a-good-idea-for-prospective-dropouts">School is Generally a Good Idea (for prospective dropouts)<a href="#school-is-generally-a-good-idea-for-prospective-dropouts" aria-label="Anchor link for: school-is-generally-a-good-idea-for-prospective-dropouts"> <i></i></a>
</h3>
<p>Being a good engineer seems underrated for being a good startup founder. Not just being able to code fast, but being able to make good engineering decisions, conduct good technical interviews and attract talent. Some engineering skills can't be worked around with "I am very smart and can learn fast" and require extended time and practice. With that, I also think prospective founders also overestimate the amount of learning on the job that can be done on the engineering side, mostly because it's harder to learn when you're in a rush to release features than if you could take your time on a course project. It's true that founders will learn more than they will in school, but the technical development may not be as strong. My model is that the best schooling experience is better technical education and the best founding experience. </p>

<h3 id="something-to-own">Something to Own<a href="#something-to-own" aria-label="Anchor link for: something-to-own"> <i></i></a>
</h3>
<p>Lots of huge, ground-breaking products have been lead from within a large company. Examples include email client <code>hey.com</code>, Chromebooks, and countless amazing dev tools. </p>
<p>Starting these things in a large company has the benefit of security, resources and recruiting already done for you. Downsides include beaurocracy, not being able to recruit on your own accord and dealing with PR policy. There is also high barriers to starting something within a company, like being senior enough to do so and being at the right company at the right time. </p>
<p>The alternative is starting a project on the side. <a href="https://github.com/ziglang/zig">Ziglang</a> was started as a side project and is now a very promising programming language. The creator has since then left his job to work on Zig, but it is also possible to "own" something significant without even having to leave your job. Examples includes Julia Evan's <a href="https://jvns.ca/">blog</a> (not actually a work-side-project) and line of zines, Cassidy William's <a href="https://drop.com/buy/drop-dsa-astrolokeys-keycaps-by-sailorhg-and-cassidoo">keycap line</a>, Nick Frosst's successful and awesome <a href="https://goodkidofficial.com/">band</a> and many more. I understand that it's not the extent of "oh yeah Google? I built that", but I think the expected value is much higher in creating and owning something that isn't a startup. </p>
<h3 id="getting-rich">Getting Rich<a href="#getting-rich" aria-label="Anchor link for: getting-rich"> <i></i></a>
</h3>
<p>A lot of people claim that startups are less money, but I find for signicant number of founders, that's not true -- not because they'll definitely have a good exit, but because they're skilled in ways that allow them to raise enough money to pay themselves like they would at a big company. If that applies to you, then going to a startup probably is your best shot at getting rich! For other people, the expected value of industry (particularly joining a well-founded early-stage startup) is usually higher. </p>
<h3 id="not-being-at-school-for-prospective-dropouts">Not Being at School (for prospective dropouts)<a href="#not-being-at-school-for-prospective-dropouts" aria-label="Anchor link for: not-being-at-school-for-prospective-dropouts"> <i></i></a>
</h3>
<p>This seems like a valid reasons for the average CS student. School is a place where you answer to professors who don't always understand industry and do homework assignments that no one will care about. However, it seems like all of these problems can be significantly if not fully solved by building a better school experience for yourself. </p>
<p>A better program can improve many things, such as <a href="http://www.olin.edu/">Olin College of Engineering</a> that has a project-based curriculum, <a href="https://www.makeschool.com/">Make School</a> that is a two year applied-engineering degree program or <a href="https://devdegree.ca/">Dev Degree</a>, where you can work at Shopify and take more applied courses taught by Shopify throughout your degree. These programs are small and selective, but probably not harder than a semi-successful startup. Dev Degree also happens to be more financially sound, with Shopify paying for your tuition and a salary, and Make School tuition is 70k for the entire degree. </p>
<p>Another alternative is to just be worse at school and learn on the side and/or to morph your silly school assignments into productive skills and useful outputs. The <a href="http://coconut-lang.org/">Coconut Programming Language</a> was built by someone while they were in school. Some things like dynamic programming that are often deemed useless theoretical things can have <a href="https://thume.ca/2017/06/17/tree-diffing/">industry applications</a>. People have also taken mundane school projects like this compiler that almost every school will have you build in a compilers course and end up with <a href="https://thume.ca/2019/04/29/comparing-compilers-in-rust-haskell-c-and-python/">educational findings for engineers in general</a> (also see <a href="https://news.ycombinator.com/item?id=20192645">HackerNews thread</a>). In five weeks, my friend Maas was able to launch <a href="https://medium.com/@maaslalani/launch-5d02cc5e05f5">five relatively successful products</a> while enrolled in Dev Degree. </p>
<p>School is already a powerful environment of hardwork, fun and learning. I think it is a more cohesive …</p></section></article></main></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://carolchen.me/blog/founding-bad/">https://carolchen.me/blog/founding-bad/</a></em></p>]]>
            </description>
            <link>https://carolchen.me/blog/founding-bad/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23894387</guid>
            <pubDate>Mon, 20 Jul 2020 03:21:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Shall the West Pass Too? Whispers from Fallen Civilisations]]>
            </title>
            <description>
<![CDATA[
Score 73 | Comments 84 (<a href="https://news.ycombinator.com/item?id=23889763">thread link</a>) | @sheefrex
<br/>
July 19, 2020 | https://www.themetasophist.com/chapter/whispers-from-fallen-civilisations | <a href="https://web.archive.org/web/*/https://www.themetasophist.com/chapter/whispers-from-fallen-civilisations">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" id="item-5f12bf74664501412d3f65f4"><div><div><div data-block-type="2" id="block-a407adb7a170c202cb65"><div><h3>1.1   Spengler’s Prediction</h3><p>Is it the destiny of the West to die? For Oswald Spengler, the answer was yes. In <em>The Decline of the West </em>he argued that all civilisations go through a similar life-cycle. According to Spengler, the Medieval Era was the spring of the West, the Renaissance its summer, and the Baroque era its autumn. He predicted that the West would enter its Winter around the year 2000, which would be characterised by a decline of democracy due to excessive influence from moneyed interests, and a resultant rise of authoritarianism.</p><p>This prophecy is quickly being fulfilled. The immense power of the financial sector was mobilised to loosen financial regulation, the ultimate result being the financial crisis of 2007-2008. The ensuing austerity sparked the rise of anti-establishment movements with authoritarian tendencies. In countries such as Italy and Hungary, such parties were or are in power.</p><p>The power of money seems set to remain strong in the West. The conditions which necessitated huge bank bailouts have not been eliminated. The revolving door means that many politicians and regulators are incentivised to serve banks while in office in return for very lucrative jobs afterwards. Typical examples of this include former US Treasury Secretary Timothy Geithner, former President of the Bundesbank Axel Weber, former head of the Swiss central bank Philipp Hildebrand, and former German Finance Minister Peer Steinbrück, all of whom earned millions from the financial sector during or after their positions in the public sector.</p><p>Since Spengler made his prophecy, the number of threats have multiplied beyond even what he foresaw. In a study of the collapse of the Bronze Age civilisation around 1177 BC, the historian Eric Cline revealed the true horsemen of collapse as being climate change, famines, droughts, earthquakes, rebellions, and mass migration.[1] Any one of these challenges could have been surmountable, but the confluence was fatal. Some are reappearing today, with the pandemic as a new recruit.</p><p>Climate change was the first to manifest. The fact that the ice shelves have begun to splinter is, for now, one worry among many. Of much greater concern are ever more extreme weather events, namely floods and droughts, that strike previously temperate regions. The final result of this could very well be the desertification of large parts of the United States and Southern Europe.[2]</p><p>Reducing our consumption of carbon fuels will not stop this threat. Europe has reduced CO2 emissions by 22 percent since 1990 [3], but the rest of the world, and especially China, continues to burn fossil fuels. According to Vaclav Smil, fossil fuels still supply 90 percent of global primary energy, a greater share than in 2000 when hydropower and nuclear energy were proportionately more widely used.[4] In fact, the success of Europe to date in containing rising emissions may be due to the fact that much energy-intensive manufacturing has already been sent abroad.</p><p>The oceans have also become more hostile to life. They have already begun to acidify due to their absorption of over 20 percent of the increased carbon dioxide in the air. This along with the higher temperature has pushed entire ecosystems such as the coral reefs into collapse, endangering the food supply of the one billion people who rely on the oceans for nourishment.</p><p>It should be no surprise then that the sixth mass extinction is now unfolding. Researchers, looking at 177 mammals for which they had detailed data, found that all have lost at least 30 percent of their geographic range and over 40 percent have undergone sharp population declines.[5]</p><p>Bee and insect populations are collapsing, along with the bird populations who rely on them for food. In France, countryside bird populations have fallen by a third in 15 years.[6] In remote Swiss mountains, plastic has even permeated the soil.[7] Given the complex nature of the ecosystem, the effects of all this are unpredictable.</p><p>Such environmental chaos could force migration, as much of Africa is highly dependent on agriculture for employment and well-being — and this is the sector most exposed to climate change. This is before we even take into account UN projections, according to which the population of Africa is forecast to increase from 1.2bn today to 2.5bn in 2050 and 4.4bn in 2100, at the same time climate change could make much of that continent uninhabitable.</p><p>This will occur in a context where youth bulges could very well lead to civil strife. According to German sociologist Gunnar Heinsohn, violence is inevitable when those aged fifteen to thirty comprise over 30 percent of the male population.[8] Similarly, others have found that a majority of conflict in previous decades started in countries where 60 percent of the population is under the age of thirty.[9]&nbsp;In <em>The Clash of Civilizations</em>, Samuel Huntington pointed to demographic trends to predict that many North African and Middle Eastern countries would be unstable today, a prediction borne out by the Arab Spring.[10]</p><p>Such instability be a particular challenge at a time of reduced integration and increased social stratification; integration of migrants is pereived to have failed in some Western European countries, while members of the working class are withdrawing their loyalty from governing elites. Toynbee’s framework indicates that both phenomena may have a common cause.</p><h2>1.2   Toynbee’s Thoughts</h2><p>Arnold Toynbee, a British historian who wrote twelve volumes entitled <em>A Study of History</em>, sought to understand the factors underlying civilisational growth and decline. Toynbee’s principal thesis was that a decline in creativity among the elites precipitates the breakdown of a civilisation. Their inability to devise solutions to the problems of the time leads the masses to cease their deferral to them.</p><p>And who could blame them for this in today’s world? A cursory glance in a newsagent tells us who the dominant cultural figures are: celebrities, sports stars, and perhaps the occasional politician. Yet what are the meaningful achievements of these groups? What risks do they take?</p><p>In a previous age, the leaders of societies literally put their lives on the line for their countries – think of de Gaulle, Churchill and most of the governing classes of the post-War period who had been involved in one if not two wars. This provided a powerful moral authority which today’s leaders lack. Moreover, the leaders of the nineteenth and twentieth centuries wrought the national and international institutions that govern us today – a creative triumph that eludes current leaders.</p><p>Due to numerous scandals, religious figures who once would have been venerated are now mostly disgraced. As for modern celebrities, while many are simply too vapid to be worth imitating, this does not stop the vapid from doing exactly that — to the delight of all manner of brands for whom the celebrity becomes a purchasable ambassador.</p><p>The decline of creativity is also evident in the world of fashion. As Kurt Andersen noted in an essay in <em>Vanity Fair</em>, fashion used to go through radical changes.[11] Every ten years from the 30s to the 90s, style changed radically. It has since stagnated. Taking a longer historical perspective, the dominance of the business suit since the thirties is anomalous, given that for centuries formal wear underwent radical changes relatively frequently.</p><p>How did this creative decline come about? Toynbee noted that once the masses cease to mimic the elite, the elite begins to mimic the masses in an attempt to gain popularity. This process, which Toynbee termed proletarianisation, is already quite advanced: consider the carefully calibrated way in which politicians seek to echo the opinions and language of the electorate. A typical example of this was when former British Prime Minister David Cameron forgot which football team he was meant to support.[12] To this theatre we can add the rise and now ubiquity of profanity, and the decline of formal dress. Perhaps this proletarianisation is the root of the stagnation in fashion: the elites mimic the masses, who are in general less likely to wear something radically different for fear of ridicule.</p><p>At the same time that the achievements of the elites are becoming less impressive, their failings are becoming more visible. Martin Gurri, in his book <em>The Revolt of the Public</em>, identified the internet as a key factor behind the diminishing credibility of elites.[13] The explosion of information has undermined traditional hierarchies, which formerly relied on control of information in order to hide their incompetence and thus preserve their legitimacy.</p><p>These multiple challenges could be tamed in a world where the nations of the West stood strong. Unfortunately, they continue to weaken. One example is the high level of debt in many Western countries, and their inability to stop borrowing. There was no clear plan to reduce such debt levels before the Coronavirus, and now the load has weightened significantly. As such, the West remains prone to a major financial crisis in the event a large economy, such as Italy, slips into bankruptcy.</p><p>As argued by Laurence Kotlikoff, professor of economics at Boston University, high levels of government debt will be compounded by extravagant commitments governments have made on pensions and healthcare. These unfunded liabilities are considerable and much greater than the official levels of public debt. In the case of the US, while public debt is around one hundred percent of GDP, the amount of unfunded liabilities is twelve times greater. The equivalent in the UK and the Netherlands is about five times annual GDP, while in France, Germany and Italy it does not exceed a multiple of two.[14]</p><p>In many ways the current difficulties faced by the West are a consequence of ageing: the debt crisis, low economic growth, and low interest rates all arise from a greying society. In Europe, the ageing German population needed to save a vast amount of money at …</p></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.themetasophist.com/chapter/whispers-from-fallen-civilisations">https://www.themetasophist.com/chapter/whispers-from-fallen-civilisations</a></em></p>]]>
            </description>
            <link>https://www.themetasophist.com/chapter/whispers-from-fallen-civilisations</link>
            <guid isPermaLink="false">hacker-news-small-sites-23889763</guid>
            <pubDate>Sun, 19 Jul 2020 14:56:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fixing Mass Effect black blobs on modern AMD CPUs]]>
            </title>
            <description>
<![CDATA[
Score 496 | Comments 152 (<a href="https://news.ycombinator.com/item?id=23889473">thread link</a>) | @Macha
<br/>
July 19, 2020 | https://cookieplmonster.github.io/2020/07/19/silentpatch-mass-effect/ | <a href="https://web.archive.org/web/*/https://cookieplmonster.github.io/2020/07/19/silentpatch-mass-effect/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  
    <p><em>TL;DR - if you are not interested in an in-depth overview of what was wrong with the game and how it was fixed,
scroll down to <a href="#download"><strong>Download</strong></a> section for a download link.</em></p>

<hr>

<ul>
  <li><a href="#introduction">Introduction</a></li>
  <li><a href="#part-1">Part 1 – Research</a>
    <ul>
      <li><a href="#prelude">Prelude</a></li>
      <li><a href="#pix">PIX</a></li>
    </ul>
  </li>
  <li><a href="#part-2">Part 2 – A closer look into D3DX</a></li>
  <li><a href="#part-3">Part 3 – Standalone tests</a></li>
  <li><a href="#part-4">Part 4 – Putting it all together</a>
    <ul>
      <li><a href="#download">Download</a></li>
    </ul>
  </li>
</ul>

<hr>



<p><strong>Mass Effect</strong> is a popular franchise of sci-fi roleplaying games. The first game was initially released by BioWare in late 2007 on Xbox 360 exclusively as a part of a publishing deal with Microsoft.
A few months later in mid-2008, the game received PC port developed by Demiurge Studios. It was a decent port with no obvious flaws, that is until 2011 when AMD released their new Bulldozer-based CPUs.
When playing the game on PCs with modern AMD processors, two areas in the game (Noveria and Ilos) show severe graphical artifacts:</p>

<p>
<img src="https://cookieplmonster.github.io/assets/img/posts/mass-effect/me1-blobs.jpg"><br>
<em>Well, that doesn't look nice.</em>
</p>

<p>While not unplayable, it’s definitely distracting. Thankfully, workarounds exist – such as
<a href="http://abesmissioncontrol.blogspot.com/2015/04/mass-effect-fixing-blocky-player-models.html">disabling lighting via console commands</a>
or <a href="https://www.nexusmods.com/masseffect/mods/181">modifying the game’s maps to remove broken lights</a>, but seemingly the issue has never been fully understood.
Some sources claim that an FPS Counter mod can also fix that issue, but I couldn’t find much information about it and the mod’s sources don’t seem to be available online,
and there is no documentation on how the mod tackles this error.</p>

<p>What makes this issue particularly interesting? Vendor-specific bugs are nothing new, and games have had them for decades. However, to my best knowledge, this is the only case where a graphical
issue is caused by a <strong>processor</strong> and not by a graphics card. In the majority of cases, issues happen with a specific vendor of GPU and they don’t care about the CPU, while in this case, it’s the exact opposite.
This makes the issue very unique and worth looking into.</p>

<p>Looking up existing discussions online, this issue seems to affect AMD FX and Ryzen chips. Compared to the older AMD chips, these lack a <a href="https://en.wikipedia.org/wiki/3DNow!">3DNow! instruction set</a>.
Unrelated or not, the community consensus was that this was the cause of the bug and that the game tried to use those instructions upon detecting an AMD CPU.
Given that there are no known cases of this bug occurring on Intel CPU’s and that 3DNow! instructions were exclusive to AMD, it’s no surprise the community assumed that this is the issue.</p>

<p>Is this really the issue, or is it caused by something entirely different? Let’s find out!</p>



<h2 id="prelude">Prelude</h2>
<p>Even though the issue is trivial to reproduce, I couldn’t look into it for the longest time for a simple reason – I don’t have access to any PCs with AMD hardware!
Thankfully, this time I’m not approaching research alone – <a href="https://withinrafael.com/">Rafael Rivera</a> got my back during the entire process of R&amp;D,
providing a test environment with an AMD chip, insights, ideas as well as putting up with hundreds of blind guesses I usually throw around when trying to find the way to the root of such unknown problems.</p>

<p>Since we now had a good testing environment, the first theory to test was of course <code>cpuid</code> – if people are right in assuming that 3DNow! instructions are to blame, there should a place in the game’s code
where they check for their presence, or at the very least check for the CPU vendor. That reasoning is flawed, though; if it was true that the game attempts to use 3DNow! instructions any time it runs on an AMD chip,
without checking if they are supported, the game would most likely crash when trying to execute an illegal instruction. Moreover, a quick scan around the game’s code reveals that the game <strong>doesn’t</strong>
check for CPU capabilities. Therefore, whatever is up with this issue, it doesn’t appear to be caused by the game mis-detecting CPU features, because it seemingly doesn’t care about them in the first place.</p>

<p>When this started looking like an undebuggable case, Rafael came back to me with a realization – disabling <strong>PSGP</strong> (Processor Specific Graphics Pipeline) fixes the issue and the characters are properly lit!
PSGP is not the best documented term, but in short, it’s a legacy (concerning only older DirectX versions) feature allowing Direct3D to perform processor-specific optimizations:</p>

<blockquote>
  <p>In previous versions of DirectX, there was a path that allowed to do vertex processing called the PSGP. Applications had to take this path into account and support a path for vertex processing
on the processor and graphics cores.</p>
</blockquote>

<p>Putting it this way, it makes sense why disabling PSGP fixes artifacts on AMD – the path taken by modern AMD processors may be somehow broken.
How to disable it? Two ways come to mind:</p>
<ul>
  <li>It is possible to pass a <code>D3DCREATE_DISABLE_PSGP_THREADING</code> flag to <code>IDirect3D9::CreateDevice</code>. It’s defined as: <br>
    <blockquote>
      <p>Restrict computation to the main application thread. If the flag is not set, the runtime may perform software vertex processing and other computations in worker thread
to improve performance on multi-processor systems.</p>
    </blockquote>

    <p>Sadly, setting that flag doesn’t fix the issue. Looks like, despite the flag having “PSGP” in name, it’s not what we are looking for.</p>
  </li>
  <li>DirectX specifies two registry entries to disable PSGP in D3D and to disable PSGP only for D3DX – <code>DisablePSGP</code> and <code>DisableD3DXPSGP</code>. Those flags can be set system-wide or process-wide.
For information on how to set them only for a specific process, see <a href="https://withinrafael.com/2020/07/11/specify-application-specific-direct3d-flags/">Rafael Rivera’s guide on enabling application-specific Direct3D flags</a>.</li>
</ul>

<p><code>DisableD3DXPSGP</code> appears to be a viable fix for that issue. Therefore, if you have an aversion towards downloading third party fixes/modifications or you must fix this issue without making
any changes to the game, it’s a perfectly fine way of doing it. As long as you set that flag only for Mass Effect and not system-wide, it’s fine!</p>

<h2 id="pix">PIX</h2>
<p>As always with graphical issues, PIX is likely the most useful tool one could use to diagnose them. We captured similar scenes from Intel and AMD hardware and compared the results.
One difference was instantly noticeable – unlike with my past projects, where <a href="https://cookieplmonster.github.io/2018/07/07/farcry-d3d9-bug/">captures did not carry the bug with them</a> and the same capture
would look different on different PCs (indicating a driver or d3d9.dll bug), these captures carry the bug with them! In other words, a capture from an AMD hardware opened on a PC with Intel hardware
<strong>does</strong> show the bug.</p>

<p>An AMD capture on Intel looks no different than on the hardware it was taken from:</p>

<p>
<img src="https://cookieplmonster.github.io/assets/img/posts/mass-effect/me1-pix1.jpg">
</p>

<p>What does this tell us?</p>
<ul>
  <li>Since PIX does not “take screenshots” but instead captures the sequence of D3D commands and executes them on hardware, we can observe that executing the commands captured from an AMD box
results in the same bug when executed on Intel.</li>
  <li>This strongly implies that the difference is not caused by the difference in <strong>how</strong> the commands are executed (that’s how you get GPU specific bugs), but <strong>what</strong> commands are executed.</li>
</ul>

<p>In other words, it’s almost certainly not any sort of a driver bug. Instead, the way inputs for the GPU are prepared seems to be somehow broken<sup id="fnref:1"><a href="#fn:1">1</a></sup>. That is indeed a very rare occurrence!</p>

<p>At this point, finding the bug is a matter of finding any jarring differences between captures. It’s tedious, but that’s the only viable way.</p>

<p>After a long while spent poking the capture, a full body draw call caught my attention:</p>

<p>
<img src="https://cookieplmonster.github.io/assets/img/posts/mass-effect/me1-pix2.jpg">
</p>

<p>On an Intel capture, this draw outputs most of the character’s body, together with lighting and textures. On an AMD capture, it outputs a plain black model. This looks like a good trail.</p>

<p>The first obvious candidate for checking would be bound textures, but they seem to be fine and are consistent across captures.
However, some of the pixel shader constants looked weird. Not only do they have NaNs (Not a Number), but they also seem to only appear on the AMD capture and not the Intel capture:</p>

<p>
<img src="https://cookieplmonster.github.io/assets/img/posts/mass-effect/me1-pix3.jpg"><br>
<em>1.#QO indicates a NaN</em>
</p>

<p>This looks promising – NaN values causing strange visuals are not unheard of. Funnily enough, a PlayStation 3 version of Mass Effect 2
<a href="https://github.com/RPCS3/rpcs3/issues/7397">had a very similar looking issue in RPCS3</a> which was also related to NaNs!</p>

<p>However, before we get too excited, those values could just be leftovers from previous draws and they might end up being unused for the current draw.
Luckily, in this case it’s clearly visible that those NaNs get submitted to D3D for this specific draw…</p>

<div><div><pre><code>49652	IDirect3DDevice9::SetVertexShaderConstantF(230, 0x3017FC90, 4)
49653	IDirect3DDevice9::SetVertexShaderConstantF(234, 0x3017FCD0, 3)
49654	IDirect3DDevice9::SetPixelShaderConstantF(10, 0x3017F9D4, 1) // Submits constant c10
49655	IDirect3DDevice9::SetPixelShaderConstantF(11, 0x3017F9C4, 1) // Submits constant c11
49656	IDirect3DDevice9::SetRenderState(D3DRS_FILLMODE, D3DFILL_SOLID)
49657	IDirect3DDevice9::SetRenderState(D3DRS_CULLMODE, D3DCULL_CW)
49658	IDirect3DDevice9::SetRenderState(D3DRS_DEPTHBIAS, 0.000f)
49659	IDirect3DDevice9::SetRenderState(D3DRS_SLOPESCALEDEPTHBIAS, 0.000f)
49660	IDirect3DDevice9::TestCooperativeLevel()
49661	IDirect3DDevice9::SetIndices(0x296A5770)
49662	IDirect3DDevice9::DrawIndexedPrimitive(D3DPT_TRIANGLELIST, 0, 0, 2225, 0, 3484) // Draws the character model
</code></pre></div></div>

<p>…and the pixel shader used for this draw references both constants:</p>
<div><div><pre><code>// Registers:
//
//   Name                     Reg   Size
//   ------------------------ ----- ----
//   UpperSkyColor            c10      1
//   LowerSkyColor            c11      1
</code></pre></div></div>

<p>Both constants appear to <a href="https://github.com/abaelhe/unrealengine-old/search?q=UpperSkyColor">come straight from Unreal Engine</a> and judging by the name,
they might directly influence the lighting. Bingo!</p>

<p>A quick in-game test further confirms the theory – on an Intel machine, a vector of 4 NaN values was never submitted as pixel shader constants;
meanwhile, on an AMD machine, NaNs would start showing up as soon as the player entered the area where lighting breaks!</p>

<p>Does it mean work is done? No, far from it, as finding broken constants is only half of the success. The question remains, where do they come from, and can they be replaced?
An in-game test replacing NaN values with zeros partially fixed the issue – ugly black blobs disappeared, but characters were still way too dark:</p>

<p>
<img src="https://cookieplmonster.github.io/assets/img/posts/mass-effect/me1-dark-lighting.jpg"><br>
<em>Almost correct... …</em></p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cookieplmonster.github.io/2020/07/19/silentpatch-mass-effect/">https://cookieplmonster.github.io/2020/07/19/silentpatch-mass-effect/</a></em></p>]]>
            </description>
            <link>https://cookieplmonster.github.io/2020/07/19/silentpatch-mass-effect/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23889473</guid>
            <pubDate>Sun, 19 Jul 2020 14:08:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Clear explanation of Rust’s module system]]>
            </title>
            <description>
<![CDATA[
Score 151 | Comments 42 (<a href="https://news.ycombinator.com/item?id=23889427">thread link</a>) | @rkwz
<br/>
July 19, 2020 | http://www.sheshbabu.com/posts/rust-module-system/ | <a href="https://web.archive.org/web/*/http://www.sheshbabu.com/posts/rust-module-system/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Rust’s module system is surprisingly confusing and causes a lot of frustration for beginners.</p>
<p>In this post, I’ll explain the module system using practical examples so you get a clear understanding of how it works and can immediately start applying this in your projects.</p>
<p>Since Rust’s module system is quite unique, I request the reader to read this post with an open mind and resist comparing it with how modules work in other languages.</p>
<p>Let’s use this file structure to simulate a real world project:</p>
<pre><code>my_project
├── Cargo.toml
└─┬ src
  ├── main.rs
  ├── config.rs
  ├─┬ routes
  │ ├── health_route.rs
  │ └── user_route.rs
  └─┬ models
    └── user_model.rs</code></pre>
<p>These are the different ways we should be able to consume our modules:</p>
<p><img src="http://www.sheshbabu.com/images/2020-rust-module-system/rust-module-system-1.png" alt=""></p>
<p>These 3 examples should be sufficient to explain how Rust’s module system works.</p>
<h2 id="Example-1"><a href="#Example-1" title="Example 1"></a>Example 1</h2><p>Let’s start with the first example - importing <code>config.rs</code> in <code>main.rs</code>.</p>
<pre><code>
<span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>println!</span><span>(</span><span>"main"</span><span>)</span><span>;</span>
<span>}</span></code></pre>
<pre><code>
<span>fn</span> <span>print_config</span><span>(</span><span>)</span> <span>{</span>
  <span>println!</span><span>(</span><span>"config"</span><span>)</span><span>;</span>
<span>}</span></code></pre>
<p>The first mistake that everyone makes is just because we have files like <code>config.rs</code>, <code>health_route.rs</code> etc, we think that these files are <code>modules</code> and we can import them from other files.</p>
<p>Here’s what we see (file system tree) and what the compiler sees (module tree):</p>
<p><img src="http://www.sheshbabu.com/images/2020-rust-module-system/rust-module-system-2.png" alt=""></p>
<p>Surprisingly, the compiler only sees the <code>crate</code> module which is our <code>main.rs</code> file. This is because we need to explicitly build the module tree in Rust - there’s no implicit mapping between file system tree to module tree.</p>
<blockquote>
<p>We need to explicitly build the module tree in Rust, there’s no implicit mapping to file system</p>
</blockquote>
<p>To add a file to the module tree, we need to declare that file as a submodule using the <code>mod</code> keyword. The next thing that confuses people is that you would assume we declare a file as module in the same file. But we need to declare this in a different file! Since we only have <code>main.rs</code> in the module tree, let’s declare <code>config.rs</code> as a submodule in <code>main.rs</code>.</p>
<blockquote>
<p>The mod keyword declares a submodule</p>
</blockquote>
<p>The <code>mod</code> keyword has this syntax:</p>
<pre><code><span>mod</span> my_module<span>;</span></code></pre>
<p>Here, the compiler looks for <code>my_module.rs</code> or <code>my_module/mod.rs</code> in the same directory.</p>
<pre><code>my_project
├── Cargo.toml
└─┬ src
  ├── main.rs
  └── my_module.rs

or

my_project
├── Cargo.toml
└─┬ src
  ├── main.rs
  └─┬ my_module
    └── mod.rs</code></pre>
<p>Since <code>main.rs</code> and <code>config.rs</code> are in the same directory, let’s declare the config module as follows:</p>
<pre><code>// main.rs
<span>+ mod config;</span>

fn main() {
<span>+ config::print_config();</span>
  println!("main");
}</code></pre>
<pre><code>
<span>fn</span> <span>print_config</span><span>(</span><span>)</span> <span>{</span>
  <span>println!</span><span>(</span><span>"config"</span><span>)</span><span>;</span>
<span>}</span></code></pre>
<p>We’re accessing the <code>print_config</code> function using the <code>::</code> syntax.</p>
<p>Here’s how the module tree looks like:</p>
<p><img src="http://www.sheshbabu.com/images/2020-rust-module-system/rust-module-system-3.png" alt=""></p>
<p>We’ve successfully declared the <code>config</code> module! But this is not sufficient to be able to call the <code>print_config</code> function inside <code>config.rs</code>. Almost everything in Rust is private by default, we need to make the function public using the <code>pub</code> keyword:</p>
<blockquote>
<p>The pub keyword makes things public</p>
</blockquote>
<pre><code>
<span>mod</span> config<span>;</span>

<span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  config<span>:</span><span>:</span><span>print_config</span><span>(</span><span>)</span><span>;</span>
  <span>println!</span><span>(</span><span>"main"</span><span>)</span><span>;</span>
<span>}</span></code></pre>
<pre><code>// config.rs
<span>- fn print_config() {</span>
<span>+ pub fn print_config() {</span>
  println!("config");
}</code></pre>
<p>Now, this works. We’ve successfully called a function defined in a different file!</p>
<h2 id="Example-2"><a href="#Example-2" title="Example 2"></a>Example 2</h2><p>Let’s try calling the <code>print_health_route</code> function defined in <code>routes/health_route.rs</code> from <code>main.rs</code>.</p>
<pre><code>
<span>mod</span> config<span>;</span>

<span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  config<span>:</span><span>:</span><span>print_config</span><span>(</span><span>)</span><span>;</span>
  <span>println!</span><span>(</span><span>"main"</span><span>)</span><span>;</span>
<span>}</span></code></pre>
<pre><code>
<span>fn</span> <span>print_health_route</span><span>(</span><span>)</span> <span>{</span>
  <span>println!</span><span>(</span><span>"health_route"</span><span>)</span><span>;</span>
<span>}</span></code></pre>
<p>As we discussed earlier, we can use the <code>mod</code> keyword only for <code>my_module.rs</code> or <code>my_module/mod.rs</code> in the same directory.</p>
<p>So in order to call functions inside <code>routes/health_route.rs</code> from <code>main.rs</code>, we need to do the following things:</p>
<ul>
<li>Create a file named <code>routes/mod.rs</code> and declare the <code>routes</code> submodule in <code>main.rs</code></li>
<li>Declare the <code>health_route</code> submodule in <code>routes/mod.rs</code> and make it public</li>
<li>Make the functions inside <code>health_route.rs</code> public</li>
</ul>
<pre><code>my_project
├── Cargo.toml
└─┬ src
  ├── main.rs
  ├── config.rs
  ├─┬ routes
<span>+ │ ├── mod.rs</span>
  │ ├── health_route.rs
  │ └── user_route.rs
  └─┬ models
    └── user_model.rs</code></pre>
<pre><code>// main.rs
mod config;
<span>+ mod routes;</span>

fn main() {
<span>+ routes::health_route::print_health_route();</span>
  config::print_config();
  println!("main");
}</code></pre>
<pre><code>// routes/mod.rs
<span>+ pub mod health_route;</span></code></pre>
<pre><code>// routes/health_route.rs
<span>- fn print_health_route() {</span>
<span>+ pub fn print_health_route() {</span>
  println!("health_route");
}</code></pre>
<p>Here’s how the module tree looks like:</p>
<p><img src="http://www.sheshbabu.com/images/2020-rust-module-system/rust-module-system-4.png" alt=""></p>
<p>We can now call a function defined in a file inside a folder.</p>
<h2 id="Example-3"><a href="#Example-3" title="Example 3"></a>Example 3</h2><p>Let’s try calling from <code>main.rs =&gt; routes/user_route.rs =&gt; models/user_model.rs</code></p>
<pre><code>
<span>mod</span> config<span>;</span>
<span>mod</span> routes<span>;</span>

<span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  routes<span>:</span><span>:</span>health_route<span>:</span><span>:</span><span>print_health_route</span><span>(</span><span>)</span><span>;</span>
  config<span>:</span><span>:</span><span>print_config</span><span>(</span><span>)</span><span>;</span>
  <span>println!</span><span>(</span><span>"main"</span><span>)</span><span>;</span>
<span>}</span></code></pre>
<pre><code>
<span>fn</span> <span>print_user_route</span><span>(</span><span>)</span> <span>{</span>
  <span>println!</span><span>(</span><span>"user_route"</span><span>)</span><span>;</span>
<span>}</span></code></pre>
<pre><code>
<span>fn</span> <span>print_user_model</span><span>(</span><span>)</span> <span>{</span>
  <span>println!</span><span>(</span><span>"user_model"</span><span>)</span><span>;</span>
<span>}</span></code></pre>
<p>We want to call the function <code>print_user_model</code> from <code>print_user_route</code> from <code>main</code>.</p>
<p>Let’s make the same changes as before - declaring submodules, making functions public and adding the <code>mod.rs</code> file.</p>
<pre><code>my_project
├── Cargo.toml
└─┬ src
  ├── main.rs
  ├── config.rs
  ├─┬ routes
  │ ├── mod.rs
  │ ├── health_route.rs
  │ └── user_route.rs
  └─┬ models
<span>+   ├── mod.rs</span>
    └── user_model.rs</code></pre>
<pre><code>// main.rs
mod config;
mod routes;
<span>+ mod models;</span>

fn main() {
  routes::health_route::print_health_route();
<span>+ routes::user_route::print_user_route();</span>
  config::print_config();
  println!("main");
}</code></pre>
<pre><code>// routes/mod.rs
pub mod health_route;
<span>+ pub mod user_route;</span></code></pre>
<pre><code>// routes/user_route.rs
<span>- fn print_user_route() {</span>
<span>+ pub fn print_user_route() {</span>
  println!("user_route");
}</code></pre>
<pre><code>// models/mod.rs
<span>+ pub mod user_model;</span></code></pre>
<pre><code>// models/user_model.rs
<span>- fn print_user_model() {</span>
<span>+ pub fn print_user_model() {</span>
  println!("user_model");
}</code></pre>
<p>Here’s how the module tree looks like:</p>
<p><img src="http://www.sheshbabu.com/images/2020-rust-module-system/rust-module-system-5.png" alt=""></p>
<p>Wait, we haven’t actually called <code>print_user_model</code> from <code>print_user_route</code>! So far, we’ve only called the functions defined in other modules from <code>main.rs</code>, how do we do that from other files?</p>
<p>If we look at our module tree, the <code>print_user_model</code> function sits in the <code>crate::models::user_model</code> path. So in order to use a module in files that are not <code>main.rs</code>, we should think in terms of the path necessary to reach that module in the module tree.</p>
<pre><code>// routes/user_route.rs
pub fn print_user_route() {
<span>+ crate::models::user_model::print_user_model();</span>
  println!("user_route");
}</code></pre>
<p>We’ve successfully called a function defined in a file from a file that’s not <code>main.rs</code>.</p>
<h2 id="super"><a href="#super" title="super"></a>super</h2><p>The fully qualified name gets too lengthy if our file organization is multiple directories deep. Let’s say for whatever reason, we want to call <code>print_health_route</code> from <code>print_user_route</code>. These are under the paths <code>crate::routes::health_route</code> and <code>crate::routes::user_route</code> respectively.</p>
<p>We can call it by using the fully qualified name <code>crate::routes::health_route::print_health_route()</code> but we can also use a relative path <code>super::health_route::print_health_route();</code>. Notice that we’ve used <code>super</code> to refer to the parent scope.</p>
<blockquote>
<p>The super keyword in module path refers to the parent scope</p>
</blockquote>
<pre><code><span>pub</span> <span>fn</span> <span>print_user_route</span><span>(</span><span>)</span> <span>{</span>
  <span>crate</span><span>:</span><span>:</span>routes<span>:</span><span>:</span>health_route<span>:</span><span>:</span><span>print_health_route</span><span>(</span><span>)</span><span>;</span>
  
  <span>super</span><span>:</span><span>:</span>health_route<span>:</span><span>:</span><span>print_health_route</span><span>(</span><span>)</span><span>;</span>

  <span>println!</span><span>(</span><span>"user_route"</span><span>)</span><span>;</span>
<span>}</span></code></pre>
<h2 id="use"><a href="#use" title="use"></a>use</h2><p>It would be tedious to use the fully qualified name or even the relative name in the above examples. In order to shorten the names, we can use the <code>use</code> keyword to bind the path to a new name or alias.</p>
<blockquote>
<p>The use keyword is used to shorten the module path</p>
</blockquote>
<pre><code><span>pub</span> <span>fn</span> <span>print_user_route</span><span>(</span><span>)</span> <span>{</span>
  <span>crate</span><span>:</span><span>:</span>models<span>:</span><span>:</span>user_model<span>:</span><span>:</span><span>print_user_model</span><span>(</span><span>)</span><span>;</span>
  <span>println!</span><span>(</span><span>"user_route"</span><span>)</span><span>;</span>
<span>}</span></code></pre>
<p>The above code can be refactored as:</p>
<pre><code><span>use</span> <span>crate</span><span>:</span><span>:</span>models<span>:</span><span>:</span>user_model<span>:</span><span>:</span>print_user_model<span>;</span>

<span>pub</span> <span>fn</span> <span>print_user_route</span><span>(</span><span>)</span> <span>{</span>
  <span>print_user_model</span><span>(</span><span>)</span><span>;</span>
  <span>println!</span><span>(</span><span>"user_route"</span><span>)</span><span>;</span>
<span>}</span></code></pre>
<p>Instead of using the name <code>print_user_model</code>, we can also alias it to something else:</p>
<pre><code><span>use</span> <span>crate</span><span>:</span><span>:</span>models<span>:</span><span>:</span>user_model<span>:</span><span>:</span>print_user_model <span>as</span> log_user_model<span>;</span>

<span>pub</span> <span>fn</span> <span>print_user_route</span><span>(</span><span>)</span> <span>{</span>
  <span>log_user_model</span><span>(</span><span>)</span><span>;</span>
  <span>println!</span><span>(</span><span>"user_route"</span><span>)</span><span>;</span>
<span>}</span></code></pre>
<h2 id="External-modules"><a href="#External-modules" title="External modules"></a>External modules</h2><p>Dependencies added to <code>Cargo.toml</code> are available globally to all modules inside the project. We don’t need to explicitly import or declare anything to use a dependency.</p>
<blockquote>
<p>External dependencies are globally available to all modules inside a project</p>
</blockquote>
<p>For example, let’s say we added the <a href="https://crates.io/crates/rand" target="_blank" rel="noopener">rand</a> crate to our project. We can use it in our code directly as:</p>
<pre><code><span>pub</span> <span>fn</span> <span>print_health_route</span><span>(</span><span>)</span> <span>{</span>
  <span>let</span> random_number<span>:</span> u8 <span>=</span> rand<span>:</span><span>:</span><span>random</span><span>(</span><span>)</span><span>;</span>
  <span>println!</span><span>(</span><span>"{}"</span><span>,</span> random_number<span>)</span><span>;</span>
  <span>println!</span><span>(</span><span>"health_route"</span><span>)</span><span>;</span>
<span>}</span></code></pre>
<p>We can also use <code>use</code> to shorten the path:</p>
<pre><code><span>use</span> rand<span>:</span><span>:</span>random<span>;</span>

<span>pub</span> <span>fn</span> <span>print_health_route</span><span>(</span><span>)</span> <span>{</span>
  <span>let</span> random_number<span>:</span> u8 <span>=</span> <span>random</span><span>(</span><span>)</span><span>;</span>
  <span>println!</span><span>(</span><span>"{}"</span><span>,</span> random_number<span>)</span><span>;</span>
  <span>println!</span><span>(</span><span>"health_route"</span><span>)</span><span>;</span>
<span>}</span></code></pre>
<h2 id="Summary"><a href="#Summary" title="Summary"></a>Summary</h2><ul>
<li>The module system is explicit - there’s no 1:1 mapping with file system</li>
<li>We declare a file as module in its parent, not in itself</li>
<li>The <code>mod</code> keyword is used to declare submodules</li>
<li>We need to explicitly declare functions, structs etc as public so they can be consumed in other modules</li>
<li>The <code>pub</code> keyword makes things public</li>
<li>The <code>use</code> keyword is used to shorten the module path</li>
<li>We don’t need to explicitly declare 3rd party modules</li>
</ul>
<p>Thanks for reading! Feel free to follow me in <a href="https://twitter.com/sheshbabu" target="_blank" rel="noopener">Twitter</a> for more posts like this :)</p>
</div></div>]]>
            </description>
            <link>http://www.sheshbabu.com/posts/rust-module-system/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23889427</guid>
            <pubDate>Sun, 19 Jul 2020 14:01:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Worms Armageddon 3.8]]>
            </title>
            <description>
<![CDATA[
Score 405 | Comments 122 (<a href="https://news.ycombinator.com/item?id=23888870">thread link</a>) | @typh00n
<br/>
July 19, 2020 | https://worms2d.info/Worms_Armageddon_3.8_Features | <a href="https://web.archive.org/web/*/https://worms2d.info/Worms_Armageddon_3.8_Features">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="mw-content-text" lang="en" dir="ltr">
<center><div><div><div><p><a href="https://wormtube.worms2d.info/vids/WormsArmageddon-TrailerVideo2020-SteamReady.mp4"><img alt="" src="https://worms2d.info/images/8/82/38_trailer_screenshot.jpg" width="640" height="360"></a></p><div><p>Click above to watch the new trailer in full quality!</p></div></div></div></div></center>
<div>
<p>Worms Armageddon version 3.8 is finally released! It's been a long time coming, and we hope you'll enjoy all the features, changes, and bug fixes that made it into this community-made update. To whet your appetite, here are some change highlights:
</p>
<div><div><p><a href="https://worms2d.info/File:ESOButton2.png"><img alt="ESOButton2.png" src="https://worms2d.info/images/0/04/ESOButton2.png" width="146" height="82"></a></p></div></div>
<h3><span id="Extended_Scheme_Options">Extended Scheme Options</span></h3>
<p>Customise your matches in weird and wonderful ways with over 70 new scheme options. Manipulate physics, fire more than one weapon in a turn, have worms bounce around the landscape, or choose from a huge array of other tweaks in order to perfect your scheme. These options are only for the seasoned Worms veteran, and as such you will need to have completed the Single Player mode and unlocked The Full Wormage in order to access them.</p>
<br><center><a href="https://worms2d.info/File:ESO1.gif" title="inline"><img alt="inline" src="https://worms2d.info/images/9/91/ESO1.gif" width="180" height="180"></a> <a href="https://worms2d.info/File:ESO2.gif" title="inline"><img alt="inline" src="https://worms2d.info/images/d/df/ESO2.gif" width="180" height="180"></a> <a href="https://worms2d.info/File:ESO3.gif" title="inline"><img alt="inline" src="https://worms2d.info/images/5/59/ESO3.gif" width="180" height="180"></a> <a href="https://worms2d.info/File:ESO4.gif" title="inline"><img alt="inline" src="https://worms2d.info/images/4/45/ESO4.gif" width="180" height="180"></a></center>
<p>For those who used the RubberWorm module in older versions of the game, all features formerly accessed through that module are now hiding behind the shiny new Extended Scheme Options star button. Relive your past glories — all your old RubberWorm recorded games can be played back with no additional software required.
</p>

<div><div><p><a href="https://worms2d.info/File:Tweening.gif"><img alt="" src="https://worms2d.info/images/5/53/Tweening.gif" width="300" height="240"></a></p><div><p>Demonstration of Tweening</p></div></div></div>
<h3><span id="Tweening">Tweening</span></h3>
<p>Worms Armageddon has never looked this smooth! In older versions, in-game movement and animations would be capped at the update rate of the game engine: 50 frames per second. In 3.8 though, experience the full silky smoothness of whatever frame rate your hardware can support — movement is now visually interpolated between game engine frames as your worms and weapons glide majestically through the air. Watch a recorded game in slow motion and you'll never want to go back!</p>
<div><div><p><a href="https://worms2d.info/File:Window.png"><img alt="" src="https://worms2d.info/images/d/dc/Window.png" width="300" height="237"></a></p><div><p>Demonstration of windowed mode</p></div></div></div>
<h3><span id="Windowed_Mode">Windowed Mode</span></h3>
<p>Worms Armageddon can now be played in a window! Awkward screen resolution changes and game capture issues are a thing of the past if you enable this feature in Advanced Settings.</p>
<div><div><p><a href="https://worms2d.info/File:Streaming-mode.png"><img alt="" src="https://worms2d.info/images/6/66/Streaming-mode.png" width="211" height="85"></a></p><div><p>Demonstration of Streaming Mode IP address hiding</p></div></div></div>
<h3><span id="Streamers.27_Heaven">Streamers' Heaven</span></h3>
<p>Along with Windowed Mode, a couple of additional options have been added specifically for streamers to make their lives easier. Audio can now be allowed to continue playing when the game window loses focus, and the new Streaming Mode will prevent IP addresses from being displayed when hosting or joining an online game (see the Update Documentation for more information).</p>
<div><div><p><a href="https://worms2d.info/File:Cpu-teams.png"><img alt="" src="https://worms2d.info/images/4/4d/Cpu-teams.png" width="252" height="151"></a></p><div><p>Demonstration of CPU teams being added to an online game</p></div></div></div>
<h3><span id="CPU_Teams_at_Large">CPU Teams at Large</span></h3>
<p>CPU teams can now be added to online games. They're always uniquely distinguishable from player teams to prevent shenanigans, but you can now finally team up with your friends to take down a swarm of those computer-controlled invertebrates. Or if you'd just like to watch a relaxing game while you work, matches containing only CPU teams may now also be started, both online and offline.</p>
<div><div><p><a href="https://worms2d.info/File:Smapshot.png"><img alt="" src="https://worms2d.info/images/7/71/Smapshot.png" width="300" height="225"></a></p></div></div>
<h3><span id="Mapshot">Mapshot</span></h3>
<p>Have you ever wrought a beautiful trail of destruction on your Worms Armageddon landscape and wished you could play a brand new game on the land that remained? Or have you ever been interrupted in the middle of a game and wished you could extract the remaining landscape to help you set up a rematch? Well, now you can! Simply type <b>/map</b> into the in-game chat or press <b>Alt + Pause</b> at any time to save a snapshot of the current state of the map, allowing you to continue your rampage from where you left off!</p>
<div><div><p><a href="https://worms2d.info/File:Wa95-2.png"><img alt="" src="https://worms2d.info/images/a/a0/Wa95-2.png" width="300" height="225"></a></p><div><p>Worms Armageddon running in Windows 95 (on real hardware!)</p></div></div></div>
<h3><span id="Compatibility">Compatibility</span></h3>
<p>Much effort has been expended in allowing everyone, no matter their hardware, to have a good Worms Armageddon experience. Further tweaks have been made to improve the experience of Windows 10 users. Worms Armageddon now runs well under Wine or Proton on Linux. A new OpenGL renderer has been added which, depending on your hardware, might outperform the other renderers. Windowed mode means there's no more need for your hardware to support specific screen resolutions. And for those into retro computing, Worms Armageddon has been seen to once again run on systems of yore...</p>
<div><div><p><a href="https://worms2d.info/File:Languages.png"><img alt="" src="https://worms2d.info/images/b/b5/Languages.png" width="222" height="120"></a></p><div><p>Sample of languages supported by Worms Armageddon's volunteer translators</p></div></div></div>
<h3><span id="Translations">Translations</span></h3>
<p>Through the tireless efforts of volunteer translators, Worms Armageddon is now fully translated to seven languages (🇫🇮 Finnish, 🇫🇷 French, 🇩🇪 German, 🇵🇹🇧🇷 Portuguese, 🇷🇺 Russian, 🇪🇸 Spanish and 🇸🇪 Swedish), with four more languages with partial translations on the way. The Update Documentation (Readme) now has translations to Finnish, French, and Spanish!</p>
<h3><span id="Fixes_and_More">Fixes and More</span></h3>
<p><a href="https://worms2d.info/File:Moon.png" title="Memey moon face"><img alt="Memey moon face" src="https://worms2d.info/images/4/47/Moon.png" width="100" height="123"></a></p>
<p>Over seven years in development, this update's release notes list consists of:
</p>
<ul><li> 370 fixes,</li>
<li> 45 changes, and</li>
<li> 61 new features.</li></ul>
<p>Our thanks go to all the hardworking members of the Worms Armageddon community who helped make this update a reality. And for the full list of what's new, check the Update Documentation (included with this update) or <a href="https://www.tus-wa.com/forums/announcements/worms-armageddon-v3-8-released-32795/">developer Deadcode's thread</a> on fan-site TUS!
</p>
</div>

<!-- 
NewPP limit report
Cached time: 20200722081828
Cache expiry: 86400
Dynamic content: false
CPU time usage: 0.023 seconds
Real time usage: 0.029 seconds
Preprocessor visited node count: 88/1000000
Preprocessor generated node count: 260/1000000
Post‐expand include size: 354/2097152 bytes
Template argument size: 60/2097152 bytes
Highest expansion depth: 4/40
Expensive parser function count: 0/100
-->

<!-- 
Transclusion expansion time report (%,ms,calls,template)
100.00%    3.025      1 - -total
 35.34%    1.069      1 - Template:ParentArticle
 30.93%    0.936      9 - Template:Clear
-->

<!-- Saved in parser cache with key wkb-mw_:pcache:idhash:5655-0!*!0!!*!5!* and timestamp 20200722081828 and revision id 26331
 -->
</div></div>]]>
            </description>
            <link>https://worms2d.info/Worms_Armageddon_3.8_Features</link>
            <guid isPermaLink="false">hacker-news-small-sites-23888870</guid>
            <pubDate>Sun, 19 Jul 2020 12:25:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tired of note-taking apps]]>
            </title>
            <description>
<![CDATA[
Score 429 | Comments 416 (<a href="https://news.ycombinator.com/item?id=23888799">thread link</a>) | @akkshu92
<br/>
July 19, 2020 | https://akkshaya.blog/2020/07/19/note-taking/ | <a href="https://web.archive.org/web/*/https://akkshaya.blog/2020/07/19/note-taking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1052">
		<!-- .entry-header -->

	<div>
		
<p>I’m tired of note-taking apps. </p>



<p>It’s not because of limited choices. But it’s the other way around. There are so many note-taking apps you could try but end up sticking to none. At least, that’s my story. It’s a perfect example of&nbsp;<strong>the paradox of choice.</strong></p>



<p>I used to wonder why people keep building so many ‘note-taking’ apps when the market is already crowded with choices. Then I figured a few reasons why.</p>



<ul><li><strong>the market size</strong>: the global <a href="https://www.verifiedmarketresearch.com/product/note-making-management-software-market/#:~:text=According%20to%20Verified%20Market%20Research,5.32%25%20from%202019%20to%202026." target="_blank" rel="noreferrer noopener">note-taking management software market</a> is estimated to reach&nbsp;<strong>$1.35 billion </strong>by<strong> 2026</strong>, growing at a&nbsp;<strong>CAGR </strong>of<strong> 5.32% </strong>from<strong> 2019 to 2026</strong></li><li><strong>greater scope for innovation:&nbsp;</strong>eg., be it creating a task list, a roadmap, or a design repository, Notion can handle it all</li><li><strong>lack of satisfaction:&nbsp;</strong>it’s noted that people always use a combination of note-taking apps and hardly stick to one for a long time</li></ul>



<p>Despite such heavy competition, apps like Notion, Google Keep, OneNote, Evernote, etc. have managed to earn a place. People use these apps for</p>



<ul><li>the ecosystem. eg., Google Keep, Microsoft OneNote</li><li>the neat user experience., eg. Bear etc.</li><li>creating a disciplined way of taking notes. eg., Notion, Roam Research</li></ul>



<p>I’ve tried them all. But none of these apps have turned me into a ‘<strong>repeat user</strong>.’ </p>



<p>After battling with so many apps only to feel guilty for not having the discipline to consistently use them, I’ve finally resorted to the most personal and easy alternative ⁠—&nbsp;<strong>writing things down</strong>.</p>



<p>I’m familiar with writing in a notebook since my childhood. It’s not new to me, and it absolutely doesn’t require any learning curve.</p>



<h3>The reasons why I find writing things down useful</h3>



<ul><li>absolute focus and the ability to think through the points I’m writing</li><li>gives a chance to remember what I’m writing</li><li>no way to copy-paste stuff as it is, and that means taking notes in a way I understand</li><li>easy to switch between formats eg., flowchart, mind map, Venn diagram, etc</li><li>helps me stay in touch with my handwriting</li></ul>



<p>Of course, everything has its downsides, and writing things down is no exception here. <br>For example, I will not be able to</p>



<ul><li>add screenshots/images, links, etc</li><li>easily search for content as there’s no ‘search bar’</li></ul>



<p>And maybe there’s more to the list I’m not talking about. </p>



<p>All I can say for sure is, based on my usage behavior, I’m okay missing out on these features. I can always save links to <a href="https://app.getpocket.com/" target="_blank" rel="noreferrer noopener">Pocket</a> for future reference, and take pictures of my notes to share with friends.</p>



<p>So if you ask me if I’d try a beautiful, innovative note-taking app that’s much better than the apps I’ve used so far, my answer is,&nbsp;<em>“<strong>Why not</strong>! <strong>I’d definitely give it a shot</strong></em>.”</p>



<p>But my greatest worry is if I’d continue using it.</p>



<p><strong>Note: </strong>If my opinion on note-taking apps changes over time, I’d be happy to update this post with a “And the hero finally arrived!” heading to talk about the app that helped change my mind. 🤡</p>
			</div><!-- .entry-content -->

	<!-- .entry-footer -->

	</article></div>]]>
            </description>
            <link>https://akkshaya.blog/2020/07/19/note-taking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23888799</guid>
            <pubDate>Sun, 19 Jul 2020 12:12:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Things Unexpectedly Named After People]]>
            </title>
            <description>
<![CDATA[
Score 393 | Comments 258 (<a href="https://news.ycombinator.com/item?id=23888725">thread link</a>) | @vortex_ape
<br/>
July 19, 2020 | https://notes.rolandcrosby.com/posts/unexpectedly-eponymous/ | <a href="https://web.archive.org/web/*/https://notes.rolandcrosby.com/posts/unexpectedly-eponymous/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
            <p><h5>July 19, 2020</h5></p>
        </div></div>]]>
            </description>
            <link>https://notes.rolandcrosby.com/posts/unexpectedly-eponymous/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23888725</guid>
            <pubDate>Sun, 19 Jul 2020 11:58:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Inheritance in C using structure composition]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 28 (<a href="https://news.ycombinator.com/item?id=23888677">thread link</a>) | @arpitbbhayani
<br/>
July 19, 2020 | https://arpitbhayani.me/blogs/inheritance-c | <a href="https://web.archive.org/web/*/https://arpitbhayani.me/blogs/inheritance-c">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>C language does not support inheritance however it does support Structure Compositions which can be tweaked to serve use-cases requiring parent-child relationships. In this article, we find out how Structure Compositions help us emulate inheritance in C and keep our code extensible. We will also find how it powers two of the most important things to have ever been invented in the field of computer science.</p>

<p>Structure Composition is when we put one structure within another, not through its pointer but as a native member - something like this</p>
<pre><code>


<span><span>struct</span> <span>list_head</span> {</span>
	<span><span>struct</span> <span>list_head</span> *<span>next</span>;</span> 
	<span><span>struct</span> <span>list_head</span> *<span>prev</span>;</span> 
};


<span><span>struct</span> <span>list_int</span> {</span>
	<span><span>struct</span> <span>list_head</span> <span>list</span>;</span>  
	<span>int</span> value;              
};


<span><span>struct</span> <span>list_str</span> {</span>
	<span><span>struct</span> <span>list_head</span> <span>list</span>;</span>  
	<span>char</span> * str;             
};
</code></pre>
<p>In the example above, we define a node of a linked list using structure composition. Usually, a linked list node has 3 members - two pointers to adjacent nodes (next and previous) and a third one could either be the data or a pointer to it.  The defining factor of a linked list is the two pointers that logically form a chain of nodes. To keep things abstract we create a struct named <code>list_head</code> which holds these two pointers  <code>next</code> and <code>prev</code> and omits the specifics i.e. data.</p>
<p>Using <code>list_head</code> structure, if we were to define a node of a linked list holding an integer value we could create another struct, named <code>list_int</code> that holds a member of type <code>list_head</code> and an integer value <code>value</code>. The next and previous pointers are brought into this struct through <code>list_head list</code> and could be referred to as <code>list.next</code> and <code>list.prev</code>.</p>
<blockquote>
<p>There is a very genuine reason for picking such weird names for a linked list node and members of structures; the reason to do so will be cleared in the later sections of this essay.</p>
</blockquote>
<p>Because of the above structure definition, building a linked list node holding of any type becomes a breeze. For example, a node holding string could be quickly defined as a struct <code>list_str</code> having <code>list_head</code> and a <code>char *</code>. This ability to extend <code>list_head</code> and build a node holding data of any type and any specifics make low-level code simple, uniform, and extensible.</p>
<h2>Memory Representation of <code>list_int</code></h2>
<p>Structures in C are not padded and they do not even hold any meta information, not even for the member names; hence during allocation, they are allocated the space just enough to hold the actual data.</p>
<p><img src="https://user-images.githubusercontent.com/4745789/83953834-694a6a00-a861-11ea-8ff7-fa69af6af7d6.png" alt="https://user-images.githubusercontent.com/4745789/83953834-694a6a00-a861-11ea-8ff7-fa69af6af7d6.png"></p>
<p>In the illustration above we see how members of <code>list_int</code> are mapped on the allocated space - required by its individual members. It is allocated a contiguous space of 12 bytes - 4 bytes for each of the two pointers and another 4 bytes for the integer value. The contiguity of space allocation and order of members during allocation could be verified by printing out their addresses as shown below.</p>
<pre><code><span><span>void</span> <span>print_addrs</span><span>()</span> </span>{
    
    <span><span>struct</span> <span>list_int</span> *<span>ll</span> = <span>new_list_int</span>(41434);</span>

    
    <span>printf</span>(<span>"%p: head\n"</span>,             head);
    <span>printf</span>(<span>"%p: head-&gt;list.next\n"</span>,  &amp;((head-&gt;<span>list</span>).next));
    <span>printf</span>(<span>"%p: head-&gt;list.prev\n"</span>,  &amp;((head-&gt;<span>list</span>).prev));
    <span>printf</span>(<span>"%p: head-&gt;value\n"</span>,      &amp;(head-&gt;value));
}

~ $ make &amp;&amp; ./a.out
<span>0x4058f0</span>: head
<span>0x4058f0</span>: head-&gt;<span>list</span>.next
<span>0x4058f4</span>: head-&gt;<span>list</span>.prev
<span>0x4058f8</span>: head-&gt;value
</code></pre>
<p>We clearly see all the 3 members, occupying 12 bytes contiguous memory segments in order of their definition within the struct.</p>
<blockquote>
<p>The above code was executed on a machine where the size of integer and pointers were 4 bytes each. The results might differ depending on the machine and CPU architecture.</p>
</blockquote>
<h2>Casting pointers pointing to struct</h2>
<p>In C language, when a pointer to a struct is cast to a pointer to another struct, the engine maps the individual members of a target struct type, depending on their order and offsets, on to the slice of memory of the source struct instance.</p>
<p>When we cast <code>list_int *</code> into <code>list_head *</code>, the engine maps the space required by target type i.e. <code>list_head</code> on space occupied by <code>list_int</code>. This means it maps the 8 bytes required by <code>list_head</code> on the first 8 bytes occupied by <code>list_int</code> instance. Going by the memory representation discussed above, we find that the first 8 bytes of <code>list_int</code> are in fact <code>list_head</code>, and hence casting <code>list_int *</code> to <code>list_head *</code> is effectively just referencing the <code>list_head</code> member of <code>list_int</code> through a new variable.</p>
<p><img src="https://user-images.githubusercontent.com/4745789/83943610-2e254800-a81b-11ea-8b25-056e1b1df85e.png" alt="https://user-images.githubusercontent.com/4745789/83943610-2e254800-a81b-11ea-8b25-056e1b1df85e.png"></p>
<p>This effectively builds a parent-child relationship between the two structs where we can safely typecast a child <code>list_int</code> to its parent <code>list_head</code>.</p>
<blockquote>
<p>It is important to note here that the parent-child relationship is established only because the first member of <code>list_int</code> is of type <code>list_head</code>. it would not have worked if we change the order of members in <code>list_int</code>.</p>
</blockquote>

<p>As established above, by putting one struct within another as its first element we are effectively creating a parent-child relationship between the two. Since this gives us an ability to safely typecast child to its parent we can define functions that accept a pointer to parent struct as an argument and perform operations that do not really require to deal with specifics. This allows us to <strong>NOT</strong> rewrite the functional logic for every child extensions and thus avoid redundant code.</p>
<p>From the context we have set up, say we want to write a function that adds a node between the two in a linked list. The core logic to perform this operation does not really need to deal with any specifics all it takes is a few pointer manipulations of <code>next</code> and <code>prev</code>. Hence, we could just define the function accepting arguments of type <code>list_head *</code>  and write the function as</p>
<pre><code>
<span>static</span> <span>void</span> __list_add(struct list_head *<span>new</span>,
                       struct list_head *prev,
                       struct list_head *next)
{
    next-&gt;prev = <span>new</span>;
    <span>new</span>-&gt;next = next;
    <span>new</span>-&gt;prev = prev;
    prev-&gt;next = <span>new</span>;
}
</code></pre>
<p>Since we can safely typecase <code>list_int *</code> and <code>list_str *</code> to <code>list_head *</code> we can pass any of the specific implementations the function <code>__list_add</code> and it would still add the node between the other two seamlessly.</p>
<p>Since the core operations on linked lists only require pointer manipulations, we can define these operations as functions accepting <code>list_head *</code> instead of specific types like <code>list_int *</code>.  Thus we need not write similar functions for specifics. A function to delete a node could be written as</p>
<pre><code>
<span>static</span> <span>inline</span> <span>void</span> __list_del(struct list_head * prev, struct list_head * next)
{
    next-&gt;prev = prev;
    prev-&gt;next = next;
}
</code></pre>
<p>Other linked list utilities like <em>adding a node to tail</em>, <em>swapping nodes</em>, <em>splicing the list</em>, <em>rotating the list</em>, etc only require manipulations of <code>next</code> and <code>prev</code> pointers. Hence they could also be written in a very similar way i.e accepting <code>list_head *</code> and thus eliminating the need to reimplement function logic for every single child implementation.</p>
<p>This behavior is very similar to how inheritance in modern OOP languages, like Python and Java, work where the child is allowed to invoke any parent function.</p>

<p>There are a ton of practical usage of using Structure Compositions but the most famous ones are</p>
<h2>Linux Kernel</h2>
<p>In order to keep things abstract and extensible, Linux Kernel uses Structure Composition at several places. One of the most important places where it uses composition is for managing and maintaining Linked Lists, exactly how we saw things above. The struct definitions and code snippets are taken as-is from the <a href="https://elixir.bootlin.com/linux/latest/source/include/linux/list.h">Kernel's source code</a>, and hence the structure and variable names look different than usual.</p>
<h2>Python Type and Object Hierarchy</h2>
<p>Python, one of the most important languages in today's world, uses Structure Composition to build Type Hierarchy. Python defines a root structure called <code>PyObject</code> which holds reference count, defining the number of places from which the object is referenced - and object type - determining the type of the object i.e. <code>int</code>, <code>str</code>, <code>list</code>, <code>dict</code>, etc.</p>
<pre><code><span>typedef</span> <span><span>struct</span> _<span>object</span> {</span>
    Py_ssize_t     ob_refcnt;  
    PyTypeObject   *ob_type;   
} PyObject;
</code></pre>
<p>Since Python wants these fields to be present in every single object that is created during runtime, it uses structure composition to ensure that objects like integers, floats, string, etc put <code>PyObject</code> as their first element and thus establishing a parent-child relationship. A Float object in Python is defined as</p>
<pre><code><span>#<span>define</span> PyObject_HEAD PyObject ob_base;</span>

<span>typedef</span> <span><span>struct</span> {</span>
    PyObject_HEAD
    <span>double</span> ob_fval;    
} PyFloatObject;
</code></pre>
<p>Now writing utility functions that increments and decrements references count on every access of any object could be written as just a single function accepting <code>PyObject *</code> as shown below</p>
<pre><code><span>static</span> <span>inline</span> <span>void</span> _Py_INCREF(PyObject *op) {
    op-&gt;ob_refcnt++;
}
</code></pre>
<p>Thus we eradicate a need of rewriting <code>INCREF</code> for every single object type and just write it once for <code>PyObject</code> and it will work for every single Python object type that is extended through <code>PyObject</code>.</p>

<ul>
<li><a href="https://elixir.bootlin.com/linux/latest/source/include/linux/list.h">LinkedList in Linux Source Code</a></li>
<li><a href="https://docs.python.org/3/c-api/structures.html#c.PyObject">PyObject - Python Internals Documentation</a></li>
<li><a href="https://docs.python.org/3/c-api/float.html">PyFloatObject - Python Internals Documentation</a></li>
</ul>
</div></div><section><div><div><p><img src="https://arpitbhayani.me/static/img/arpit.jpg"></p>  <h2>
              500+ Signups
            </h2> <p>
              If you like what you read subscribe you can always subscribe to
              my newsletter and get the post delivered straight to your inbox.
              I write
              <a href="https://arpitbhayani.me/blogs">essays</a> on various
              engineering topics and share it through my weekly
              <a href="https://arpitbhayani.me/newsletter">newsletter</a> 👇
            </p> <br> </div></div></section></div>]]>
            </description>
            <link>https://arpitbhayani.me/blogs/inheritance-c</link>
            <guid isPermaLink="false">hacker-news-small-sites-23888677</guid>
            <pubDate>Sun, 19 Jul 2020 11:48:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Gradually Exit Twitter]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 56 (<a href="https://news.ycombinator.com/item?id=23888215">thread link</a>) | @saadalem
<br/>
July 19, 2020 | https://balajis.com/how-to-gradually-exit-twitter/ | <a href="https://web.archive.org/web/*/https://balajis.com/how-to-gradually-exit-twitter/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


                <figure>
                    <img srcset="https://balajis.com/content/images/size/w300/2020/07/gradually-exit-twitter.png 300w,
                                https://balajis.com/content/images/size/w600/2020/07/gradually-exit-twitter.png 600w,
                                https://balajis.com/content/images/size/w1200/2020/07/gradually-exit-twitter.png 1000w,
                                https://balajis.com/content/images/size/w2000/2020/07/gradually-exit-twitter.png 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 1170px,
                                2000px" src="https://balajis.com/content/images/size/w2000/2020/07/gradually-exit-twitter.png" alt="How to Gradually Exit Twitter">
                </figure>
                <section>
                    <div>
                        <p>The <a href="https://twitter.com/TwitterSupport/status/1283591848729219073">hacks</a> are the last straw. We need to exit Twitter.</p><p>But you may be invested in Twitter! So what do you do? Here's one recipe for <em>gradual</em> exit.</p><ol><li>Step one is to set up an (optionally pseudonymous) newsletter at your <em>own</em> custom domain using the instructions <a href="https://balajis.com/set-up-a-paid-newsletter-at-your-own-domain/">here</a>. You can do this in an hour and maintain it for less than $30 per month. Then only tweet out posts from your site, using your domain name as a simple form of authentication.</li><li>Step two is to start building your membership list at your own site. If you want, help us review <a href="https://github.com/balajis/twitter-export">open source tools</a> to export your Twitter following to an email list and <a href="https://twitter.com/dwr/status/1284155565770498050">mass delete any DMs</a>.</li><li>And step three is to get off Twitter all together, and start building a decentralized media ecosystem that combines the sovereignty of individual domain names with the community of social networking. The v1 of that is a simple joint RSS feed that aggregates multiple independent newsletters, but we can get much more <a href="https://twitter.com/balajis/status/1280005821028397057">sophisticated</a> <a href="https://dci.mit.edu/decentralizedweb">with</a> <a href="https://hackernoon.com/a-state-of-the-art-of-decentralized-web-part-4-212732f74894">tech</a> <a href="https://gun.eco/docs/dWeb-The-Decentralized-Web">for</a> <a href="https://ens.domains/">the</a> <a href="https://handshake.org/">decentralized</a> <a href="https://ipfs.io/">web</a>. It may turn out that what we build helps reform Twitter itself, but at a minimum it will present an alternative.</li></ol><p>Before we get there though, let's go through the problems with Twitter.</p><h2 id="the-problems-with-twitter">The Problems with Twitter</h2><p>It's not just the hack. There are several overlapping issues with Twitter around security, authentication, pseudonymity, distribution, incentives, and culture.</p><ul><li><em>Twitter is insecure</em>. It was a mistake to think that personal security could compensate for the fundamental flaw of centralized web services: anyone who gains control over twitter.com gains control over your account. We knew this already from the <a href="http://archive.is/Bq5qi">2017 incident</a> and the <a href="http://archive.is/wip/scJMn">Jack Hack</a>. But now the most prominent people and companies in the world (Bezos, Gates, Zuckerberg, Musk, Apple, Uber, among others) have been <a href="https://twitter.com/TwitterSupport/status/1283591848729219073">openly and publicly hacked</a>. Tomorrow you may be the victim. And unlike these worthies, you may be <em>silently</em> and <em>privately</em> hacked. Perhaps you already have been.</li><li><em>Twitter is not authenticated</em>. It was a mistake to trust Twitter's centralized verification process to validate everything posted to the service. There weren't any <a href="https://www.investopedia.com/terms/p/private-key.asp#:~:text=A%20digital%20wallet%20stores%20the,to%20use%20the%20private%20key.">digital signatures</a> to help establish whether the messages were really coming from a user-controlled device, or faked by a central server.</li><li><em>Twitter is not fully pseudonymous</em>. It was a mistake to use our real names everywhere online, particularly on Twitter. It made us vulnerable to personal and physical attacks. Social media mobs can swarm your real name online and cancel you in real life. Doxxing can heighten the danger by making threats <a href="https://blog.lopp.net/reflections-upon-a-swatting/">materialize in</a> <a href="https://github.com/jlopp/physical-bitcoin-attacks/blob/master/README.md">meatspace</a>. Pseudonymity is a better default, especially now that we can <a href="http://www.marknagelberg.com/notes-on-the-pseudonymous-economy-balaji-srinivasan/">earn under a pseudonym</a>.</li><li><em>Twitter is a distribution chokepoint</em>. It was a mistake to outsource our distribution to Twitter. Twitter users don't fully control their reach, brand, or monetization. You can be <a href="https://www.searchenginejournal.com/twitter-reveals-how-it-ranks-tweets-in-search-results/263869/">downranked</a> or <a href="http://archive.is/mhgyB">deplatformed</a> at any time, just like you can on YouTube and other centralized platforms. Owning your <a href="https://support.substack.com/hc/en-us/articles/360037465992-How-do-I-export-my-email-or-subscriber-list-">own</a> <a href="http://locals.com/">email</a> <a href="https://ghost.org/members">list</a> is a far better alternative.</li><li><em>Twitter doesn't create wealth</em>. It was a mistake to have so many people spending so much time on something that <a href="https://twitter.com/paulg/status/1271834488998440961">arguably</a> destroys more wealth than it creates. Because by default, you don't create wealth on Twitter. You may create wealth <em>for</em> Twitter, or for the media corporations whose links are circulated, but not for yourself or for others. There's no sense of economic alignment with other users, no sense of mutual obligation.</li><li><em>Twitter turns society into Twitter</em>. It was a mistake to let Twitter set up the incentives for our society. It's not good for the world when the one thing every prominent person knows how to do is <a href="https://twitter.com/balajis/status/1272653587617701888">fight</a> each other on Twitter for likes and followers. It has converted society into a zero-sum status game played by elites with real consequences. Every day, blue checks compete for a finite pie of attention with ever more sensational posts. There is instant feedback on what is popular, but none on what is true. The lack of economics, the presence of real names, the toxic culture, and the UX itself all encourage constant fighting.</li></ul><p>Now, let me qualify these comments. I personally have gotten <a href="https://twitter.com/paulg/status/1271834488998440961">enormous value</a> out of Twitter, despite all the points above. After all, you only critique the services you use!</p><p>And to be clear, Jack Dorsey is a phenomenal entrepreneur. I respect everything he's done and the team that he's built. It's hard to build one multibillion dollar company, let alone <a href="http://archive.is/wip/bu6hJ">two</a>. He's done immense good for the world overall, both through his <a href="https://twitter.com/jack/status/1247616214769086465">personal generosity</a> and his startup vehicles. And I also don't wish any Twitter employee ill, as many of them are truly great people and I know how hard this stuff is.</p><p>Moreover, even after this hack, Twitter will likely continue to be an important internet battlefield for quite sometime. It's just too easy, too convenient. And it may turn out that whatever is built to exit Twitter will end up interfacing with Twitter itself, via their <a href="https://twitter.com/bluesky">decentralized protocol</a>, if only as a form of training wheels to help people get off. Hopefully this can be done in a win-win way, such that Twitter and its employees are incentivized to allow people to gradually exit and fix the issues on the centralized service.</p><p>But it's past time for us to start building something better, that keeps the good aspects of Twitter (the serendipitous learning, the fascinating <a href="https://twitter.com/balajis/status/1214585024772788224">people</a>) but filters the bad. That may mean exiting to our own domains and then networking them into decentralized media.</p><h2 id="decentralization-starts-with-a-domain">Decentralization Starts with a Domain</h2><figure><img src="https://balajis.com/content/images/2020/07/how-to-gradually-exit-twitter--1-.png" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/how-to-gradually-exit-twitter--1-.png 600w, https://balajis.com/content/images/size/w1000/2020/07/how-to-gradually-exit-twitter--1-.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/how-to-gradually-exit-twitter--1-.png 1600w, https://balajis.com/content/images/2020/07/how-to-gradually-exit-twitter--1-.png 2000w" sizes="(min-width: 720px) 720px"><figcaption>Can we network together websites into decentralized media with something deeper than links?</figcaption></figure><p>I may be wrong about this, but I don't think a "better Twitter" starts with a service which is simply a clone of Twitter except with a different community. I think it starts with a community of independent (and independently monetizable) domains that we network together in novel ways, to build <em>decentralized media</em>.</p><p>Towards this end, the first step in gradually exiting Twitter is to set up your own paid newsletter at a custom domain (<a href="https://balajis.com/set-up-a-paid-newsletter-at-your-own-domain/">instructions here</a>) and restrict yourself mainly to tweeting out posts. This does require more effort than writing 280 characters! But that's why it's good. Effort helps restore your attention span and improves average post quality. And in addition to the other benefits, the link to your domain doubles as a simple alternative to a <a href="https://www.investopedia.com/terms/p/private-key.asp#:~:text=A%20digital%20wallet%20stores%20the,to%20use%20the%20private%20key.">digital signature</a>, a way for people to see that the content is authentically yours. </p><p>The medium-term step is to develop <a href="https://github.com/balajis/twitter-export">tools</a> to migrate your followers off Twitter to an email list, and to mass delete all DMs as a precautionary step. If you want to help review some existing tools towards this end, we're working on it <a href="https://github.com/balajis/twitter-export/issues/1">here</a>.</p><p>The long-term step is to start addressing the issues with Twitter by knitting these individual domains together into an open source decentralized media ecosystem. That means addressing:</p><ul><li>Security by encouraging people to post from their own domains</li><li>Community by building a network around multiple domains</li><li>Authentication by combining domains with digital signatures</li><li>Distribution via memberships and email lists</li><li>Incentives by baking in monetization and economic alignment from the beginning</li><li>Mobs by recommending pseudonymity by default</li><li>Culture by encouraging physical norms of civility</li></ul><p>Crucially, unlike past efforts our goal would be to build this <em>community-first</em> rather than <em>technology-first</em>. Specifically, once we get enough paid newsletters set up at their own domains, we can experiment with new decentralized web technologies for linking them together. If you submit your URL to <a href="https://forms.gle/xqvAFgW43Hc7rVzJA">this form</a>, we'll see if we can form a community. We'll probably start with a joint <a href="https://en.wikipedia.org/wiki/RSS">RSS</a> feed and then <a href="https://hacks.mozilla.org/2018/07/introducing-the-d-web/">get more sophisticated</a>.</p><p>Oh, and you can signal that you're interested in decentralized media by changing your name on Twitter to your URL, as <a href="https://twitter.com/balajis">follows</a>:</p><figure><img src="https://balajis.com/content/images/2020/07/image-5.png" alt=""></figure><p>Exiting Twitter and building decentralized media will be a long project and we aren't assured of success. But this journey of a thousand miles begins with a single newsletter at your own domain! So <a href="https://balajis.com/set-up-a-paid-newsletter-at-your-own-domain/">set yours up</a> now. </p><p>It's time to start gradually exiting Twitter.</p>
                    </div>
                </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://balajis.com/how-to-gradually-exit-twitter/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23888215</guid>
            <pubDate>Sun, 19 Jul 2020 09:50:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Optimizing 128-bit Division]]>
            </title>
            <description>
<![CDATA[
Score 130 | Comments 28 (<a href="https://news.ycombinator.com/item?id=23888177">thread link</a>) | @EvgeniyZh
<br/>
July 19, 2020 | https://danlark.org/2020/06/14/128-bit-division/ | <a href="https://web.archive.org/web/*/https://danlark.org/2020/06/14/128-bit-division/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-288">

	

	
	<div>
		
<p>When it comes to hashing, sometimes 64 bit is not enough, for example, because of <a href="https://en.wikipedia.org/wiki/Birthday_problem">birthday paradox</a> — the hacker can iterate through random <img src="https://s0.wp.com/latex.php?latex=2%5E%7B32%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{32}" title="2^{32}"> entities and it can be proven that with some constant probability they will find a collision, i.e. two different objects will have the same hash. <img src="https://s0.wp.com/latex.php?latex=2%5E%7B32%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{32}" title="2^{32}"> is around 4 billion objects and with the current power capacity in each computer it is certainly achievable. That’s why we need sometimes to advance the bitness of hashing to at least 128 bits. Unfortunately, it comes with a cost because platforms and CPUs do not support 128 bit operations natively.</p>



<p>Division historically is the most complex operation on CPUs and all guidelines suggest avoiding the division at all costs.</p>



<p>At my job I faced an interesting problem of optimizing 128 bit division from <a href="https://github.com/abseil/abseil-cpp/blob/master/absl/numeric/int128.cc#L155">abseil library</a> in order to split some data across buckets with the help of 128 bit hashing (the number of buckets is not fixed for some uninteresting historical reasons). I found out that the division takes a really long time. The <a href="https://github.com/abseil/abseil-cpp/blob/master/absl/numeric/int128_benchmark.cc#L52">benchmarks</a> from abseil on Intel(R) Xeon(R) W-2135 CPU @ 3.70GHz show some horrible results</p>



<pre><code>Benchmark                       Time(ns)  CPU(ns)
BM_DivideClass128UniformDivisor     13.8     13.8  // 128 bit by 128 bit
BM_DivideClass128SmallDivisor        168      168  // 128 bit by 64 bit</code></pre>



<p>150 nanoseconds for dividing the random 128 bit number by a random 64 bit number? Sounds crazy. For example, <code>div</code> instruction on x86-64 Skylake takes 76 cycles (also, for AMD processors it is much less), the division takes around 20-22ns.</p>



<figure><img data-attachment-id="361" data-permalink="https://danlark.org/d2elnjfdkne/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png" data-orig-size="921,461" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="d2elnjfdkne" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png?w=921" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png 921w, https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png?w=768 768w" sizes="(max-width: 921px) 100vw, 921px"><figcaption><a href="https://godbolt.org/z/o2vTZr">https://godbolt.org/z/o2vTZr</a></figcaption></figure>



<p>In reality everything is slightly better because of pipeline execution and division has its own ALU, so if you divide something and do something else in the next instructions, you will get lower average latency. Still, 128 bit division cannot be 8x slower than 64 bit division. All latencies you can find in Agner Fog <a href="https://www.agner.org/optimize/instruction_tables.pdf">instruction table</a> for most of the modern x86 CPUs. The truth is more complex and division latency can even depend on the values given.</p>



<figure><img data-attachment-id="299" data-permalink="https://danlark.org/2020-06-14-182043_835x215_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png" data-orig-size="835,215" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-06-14-182043_835x215_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png?w=835" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png 835w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png?w=768 768w" sizes="(max-width: 835px) 100vw, 835px"><figcaption>Agner Fog instruction table for Skylake CPUs, the second but last column is the latency.</figcaption></figure>



<p>Even compilers when dividing by some constants, try to use the reciprocal (or, the same as inverse in a ring) value and multiply the reciprocal and the value with some shifts afterwards</p>



<figure><img data-attachment-id="315" data-permalink="https://danlark.org/2020-06-14-192300_861x251_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png" data-orig-size="861,251" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-06-14-192300_861x251_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png?w=861" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png 861w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png?w=768 768w" sizes="(max-width: 861px) 100vw, 861px"><figcaption><a href="https://gcc.godbolt.org/z/PRibsx">https://gcc.godbolt.org/z/PRibsx</a></figcaption></figure>



<p>Overall, given the fact that only some <code>sin</code>, <code>cos</code> instructions cost more than division, division is one of the most complex instructions in CPUs and optimizations in that place matter a lot. My exact case was more or less general, maybe I was dividing 128 bit by 64 bit a bit more frequent. We are going to optimize the general case in LLVM.</p>



<p>We need to understand how 128 bit division is working through the compiler stack.</p>



<figure><img data-attachment-id="303" data-permalink="https://danlark.org/2020-06-14-183125_682x238_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png" data-orig-size="682,238" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-06-14-183125_682x238_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png?w=682" src="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png?w=682" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png 682w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png?w=300 300w" sizes="(max-width: 682px) 100vw, 682px"><figcaption><a href="https://gcc.godbolt.org/z/fB3aq2">https://gcc.godbolt.org/z/fB3aq2</a></figcaption></figure>



<p>It calls <code>__udivti3</code> function. Let’s first understand how to read these functions. In runtime libraries the modes of the functions are:</p>



<div><div>
<pre><code>QI: An integer that is as wide as the smallest addressable unit, usually 8 bits.
HI: An integer, twice as wide as a QI mode integer, usually 16 bits.
SI: An integer, four times as wide as a QI mode integer, usually 32 bits.
DI: An integer, eight times as wide as a QI mode integer, usually 64 bits.
SF: A floating point value, as wide as a SI mode integer, usually 32 bits.
DF: A floating point value, as wide as a DI mode integer, usually 64 bits.
TI: An integer, 16 times as wide as a QI mode integer, usually 128 bits.</code></pre>
</div></div>



<p>So, <code>udivti3</code> is an <strong>u</strong>nsigned division of TI (128 bits) integers, last ‘<em>3′</em> means that it has 3 arguments including the return value. Also, there is a function <code>__udivmodti4</code> which computes the divisor and the remainder (division and modulo operation) and it has 4 arguments including the returning value. These functions are a part of runtime libraries which compilers provide by default. For example, in GCC it is <a href="http://gcc.gnu.org/onlinedocs/gccint/Libgcc.html#Libgcc">libgcc</a>, in LLVM it is <a href="https://compiler-rt.llvm.org/">compiler-rt</a>, they are linked almost in every program if you have the corresponding toolchain. In LLVM, <code>__udivti3</code> is a simple alias to <code>__udivmodti4</code>.</p>



<figure><div>

</div></figure>



<p><code><a href="https://github.com/llvm-mirror/compiler-rt/blob/release_90/lib/builtins/udivmodti4.c#L20">__udivmodti4</a></code> function was written with the help of <code>Translated from Figure 3-40 of The PowerPC Compiler Writer's Guide.</code> After looking at it <a href="https://cr.yp.to/2005-590/powerpc-cwg.pdf">here</a>, it looks like this was written long time ago and things have changed since then</p>



<figure><img data-attachment-id="313" data-permalink="https://danlark.org/2020-06-14-191400_1038x718_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png" data-orig-size="1038,718" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-06-14-191400_1038x718_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=1024" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=1024 1024w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=768 768w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png 1038w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>First of all, let’s come up with something easy, like shift-subtract algorithm that we have been learning since childhood. First, if <code>divisor &gt; dividend</code>, then the quotient is zero and remainder is the <code>dividend</code>, not an interesting case. </p>



<figure><div>

</div></figure>



<p>The algorithm is easy, we align the numbers by their most significant bits, if dividend is more than divisor, subtract and add 1 to the output, then shift by 1 and repeat.  Some sort of animation can be seen like that:</p>



<figure><img data-attachment-id="318" data-permalink="https://danlark.org/simplescreenrecorder-2020-06-14_20-23-25/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/simplescreenrecorder-2020-06-14_20.23.25.gif" data-orig-size="918,442" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="simplescreenrecorder-2020-06-14_20.23.25" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/simplescreenrecorder-2020-06-14_20.23.25.gif?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/simplescreenrecorder-2020-06-14_20.23.25.gif?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/simplescreenrecorder-2020-06-14_20.23.25.gif?w=918" alt=""></figure>



<p>For 128 bit division it will take at most 128 iterations in the for loop. Actually, the implementation in <a href="https://github.com/llvm-mirror/compiler-rt/blob/release_90/lib/builtins/udivmodti4.c#L173">LLVM</a> for loop is a fallback and we saw it takes 150+ns to complete it because it requires to shift many registers because 128 bit numbers are represented as two registers.</p>



<p>Now, let’s dive into the architecture features. I noticed that while the compiler generates the <code>divq</code> instructions, it frees <code>rdx</code> register</p>



<figure><img data-attachment-id="362" data-permalink="https://danlark.org/2ugj4bgvw4x/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png" data-orig-size="891,206" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2ugj4bgvw4x" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png?w=891" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png 891w, https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png?w=768 768w" sizes="(max-width: 891px) 100vw, 891px"></figure>



<p>In the manual they say the following</p>



<figure><img data-attachment-id="322" data-permalink="https://danlark.org/2020-06-14-204644_860x119_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png" data-orig-size="860,119" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-06-14-204644_860x119_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png?w=860" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png 860w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png?w=768 768w" sizes="(max-width: 860px) 100vw, 860px"></figure>



<p><code>divq</code> instruction provides 128 bit division from [%rdx]:[%rax] by <code>S</code>. The quotient is stored in <code>%rax</code> and the remainder in <code>%rdx</code>. After some experimenting with inline asm in C/C++, I figured out that if the result does not fit in 64 bits, SIGFPE is raised. See:</p>



<figure><div>

</div></figure>



<p>Compilers don’t use this instruction in 128 bit division because they cannot know for sure if the result is going to fit in 64 bits. Yet, if the high 64 bits of the 128 bit number is smaller than the divisor, the result fits into 64 bits and we can use this instruction. As compilers don’t generate <code>div</code>q instruction for their own reasons, we would use inline asm for x86-64.</p>



<figure><div>

</div></figure>



<p>What to do if the high is not less than the divisor? The right answer is to use 2 divisions because</p>



<figure><img data-attachment-id="325" data-permalink="https://danlark.org/2020-06-11-135245_1608x410_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png" data-orig-size="1608,410" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-06-11-135245_1608x410_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=1024" alt="" width="780" height="198" srcset="https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=1024 1024w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=777 777w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=1553 1553w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=768 768w" sizes="(max-width: 780px) 100vw, 780px"></figure>



<p>So, first we can divide <code>hi</code> by <code>divisor</code> and then <code>{hi_r, lo}</code> by <code>divisor</code> guaranteeing that <code>hi_r</code> is smaller than <code>divisor</code> and thus the result is smaller than <img src="https://s0.wp.com/latex.php?latex=2%5E%7B64%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{64}" title="2^{64}">. We will get something like</p>



<figure><div>

</div></figure>



<p>  After that the benchmarks improved significantly</p>



<pre><code>Benchmark                       Time(ns)  CPU(ns)
BM_DivideClass128UniformDivisor 11.9      11.9
BM_DivideClass128SmallDivisor   26.6      26.6</code></pre>



<p>Only 26.6ns for small divisors, that’s a clear 6x win.</p>



<p>Then there are multiple choices to do next but we know that both dividend and divisor have at least one bit in their high registers and the shift-subtract algorithm will have at most 64 iterations. Also the quotient is guaranteed to fit in 64 bits, thus we can use only the low register of the resulting quotient and save more shifts in the shift-subtract algorithm. That’s why the uniform divisor slightly improved.</p>



<p>One more optimization to do in shift-subtract algorithm is to remove the branch inside the for loop (read carefully, it should be understandable).</p>



<figure><div>

</div></figure>



<p>In the end, it gives 0.4ns more for uniform 128 bit divisor.</p>



<p>And finally I believe that’s one of the best algorithm to divide 128 bit by 128 bit numbers. From statistics, the case when the divisor is 64 bit is worth optimizing and we showed that additional checks on the high register of divisor has its own advantages and expansion of the invariants. Now let’s see what other libraries perform in that case.</p>



<h2>LibDivide</h2>



<p><a href="https://github.com/ridiculousfish/libdivide">Libdivide</a> is a small library targeting fast division, for example, if you divide by some fixed number a lot of times, there are techniques that can precalculate reciprocal and then multiply by it. Libdivide provides a very good interface for such optimizations. Even though, it has some optimizations regarding 128 bit division. For example, function <code>libdivide_128_div_128_to_64</code> computes the division 128 bit number by 128 bit number if the result fits in 64 bits. In the case where both numbers are more or equal to <img src="https://s0.wp.com/latex.php?latex=2%5E%7B64%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{64}" title="2^{64}"> it does the following algorithm that they took from <a href="https://www.amazon.de/Hackers-Delight-Henry-S-Warren/dp/0321842685/ref=sr_1_1?dchild=1&amp;keywords=Hackers+Delight&amp;qid=1592164234&amp;sr=8-1">Hackers Delight</a> book:</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Bcases%7D+n+%3D+MSB%28%5Cmathrm%7Bdivisor%7D%29+%5Cgeq+1+%5C%5C+%5Cmathrm%7Bdivisor_1%7D+%3D+%5Clfloor+%5Cmathrm%7Bdivisor%7D%2F2%5E%7B64+-+n%7D+%5Crfloor+%5C%5C+%5Cmathrm%7Bdividend_1%7D+%3D+%5Clfloor+%5Cmathrm%7Bdividend%7D%2F2+%5Crfloor+%5Cend%7Bcases%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\begin{cases} n = MSB(\mathrm{divisor}) \geq 1 \\ \mathrm{divisor_1} = \lfloor \mathrm{divisor}/2^{64 - n} \rfloor \\ \mathrm{dividend_1} = \lfloor \mathrm{dividend}/2 \rfloor \end{cases}" title="\begin{cases} n = MSB(\mathrm{divisor}) \geq 1 \\ \mathrm{divisor_1} = \lfloor \mathrm{divisor}/2^{64 - n} \rfloor \\ \mathrm{dividend_1} = \lfloor \mathrm{dividend}/2 \rfloor \end{cases}"></p>



<p>With the instruction that produces the 64 bit result when the divisor is 128 bit result we can compute</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bquotient_1%7D+%3D+%5Clfloor+%5Cmathrm%7Bdividend_1%7D%2F%5Cmathrm%7Bdivisor_1%7D+%5Crfloor&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{quotient_1} = \lfloor \mathrm{dividend_1}/\mathrm{divisor_1} \rfloor" title="\mathrm{quotient_1} = \lfloor \mathrm{dividend_1}/\mathrm{divisor_1} \rfloor"></p>



<p>Then we compute</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bquotient_0%7D+%3D+%5Clfloor+%5Cmathrm%7Bquotient_1%7D%2F2%5E%7B63+-+n%7D+%5Crfloor&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{quotient_0} = \lfloor \mathrm{quotient_1}/2^{63 - n} \rfloor" title="\mathrm{quotient_0} = \lfloor \mathrm{quotient_1}/2^{63 - n} \rfloor">.</p>



<p>It cannot overflow because <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bquotient_1%7D+%3C+2%5E%7B64%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{quotient_1} < 2^{64}" title="\mathrm{quotient_1} < 2^{64}"> because the maximum value of <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bdividend_1%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{dividend_1}" title="\mathrm{dividend_1}"> is <img src="https://s0.wp.com/latex.php?latex=2%5E%7B127%7D+-+1&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{127} - 1" title="2^{127} - 1"> and minimum value of <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bdivisor_1%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{divisor_1}" title="\mathrm{divisor_1}"> is <img src="https://s0.wp.com/latex.php?latex=2%5E%7B63%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{63}" title="2^{63}">. Now let’s show that</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Clfloor+%5Cmathrm%7Bdividend%7D%2F%5Cmathrm%7Bdivisor%7D+%5Crfloor+%5Cleq+%5Cmathrm%7Bquotient_0%7D+%5Cleq++%5Clfloor+%5Cmathrm%7Bdividend%7D%2F%5Cmathrm%7Bdivisor%7D+%5Crfloor+%2B+1&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\lfloor \mathrm{dividend}/\mathrm{divisor} \rfloor \leq \mathrm{quotient_0} \leq  \lfloor \mathrm{dividend}/\mathrm{divisor} \rfloor + 1" title="\lfloor \mathrm{dividend}/\mathrm{divisor} \rfloor \leq \mathrm{quotient_0} \leq  \lfloor \mathrm{dividend}/\mathrm{divisor} \rfloor + 1"></p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bquotient_0%7D+%3D+%5Cleft%5Clfloor+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%7D%7B2%5E%7B64+-+n%7D%5Cmathrm%7Bdivisor_1%7D%7D+%5Cright%5Crfloor+%3D+%5Cleft%5Clfloor+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%7D%7B2%5E%7B64+-+n%7D%5Cleft%5Clfloor%5Cfrac%7B%5Cmathrm%7Bdivisor%7D%7D%7B2%5E%7B64+-+n%7D%7D%5Cright%5Crfloor%7D+%5Cright%5Crfloor+%3D+%5Cleft%5Clfloor+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%7D%7B%5Cmathrm%7Bdivisor%7D+-+%28%5Cmathrm%7Bdivisor%7D+%5Cmathrm%7B%5C+mod%5C+%7D+2%5E%7B64+-+n%7D%29%7D+%5Cright%5Crfloor+%3D+%5Cleft%5Clfloor+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%7D%7B%5Cmathrm%7Bdivisor%7D%7D+%2B+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%28%5Cmathrm%7Bdivisor%7D+%5Cmathrm%7B%5C+mod%5C+%7D+2%5E%7B64+-+n%7D%29%29%7D%7B%5Cmathrm%7Bdivisor%7D%28%5Cmathrm%7Bdivisor%7D+-+%28%5Cmathrm%7Bdivisor%7D+%5Cmathrm%7B%5C+mod%5C+%7D+2%5E%7B64+-+n%7D%29%29%7D+%5Cright%5Crfloor+%3D+%5Cleft%5Clfloor+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%7D%7B%5Cmathrm%7Bdivisor%7D%7D+%2B+%5Cdelta+%5Cright%5Crfloor&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{quotient_0} = \left\lfloor \frac{\mathrm{dividend}}{2^{64 - n}\mathrm{divisor_1}} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{2^{64 - n}\left\lfloor\frac{\mathrm{divisor}}{2^{64 - n}}\right\rfloor} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{\mathrm{divisor} - (\mathrm{divisor} \mathrm{\ mod\ } 2^{64 - n})} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{\mathrm{divisor}} + \frac{\mathrm{dividend}(\mathrm{divisor} \mathrm{\ mod\ } 2^{64 - n}))}{\mathrm{divisor}(\mathrm{divisor} - (\mathrm{divisor} \mathrm{\ mod\ } 2^{64 - n}))} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{\mathrm{divisor}} + \delta \right\rfloor" title="\mathrm{quotient_0} = \left\lfloor \frac{\mathrm{dividend}}{2^{64 - n}\mathrm{divisor_1}} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{2^{64 - n}\left\lfloor\frac{\mathrm{divisor}}{2^{64 - n}}\right\rfloor} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{\mathrm{divisor} - (\mathrm{divisor} \mathrm{\ mod\ } 2^{64 - n})} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{\mathrm{divisor}} + \frac{\mathrm{dividend}(\mathrm{divisor} \mathrm{\ mod\ } 2^{64 - n}))}{\mathrm{divisor}(\mathrm{divisor} - (\mathrm{divisor} \mathrm{\ mod\ } 2^{64 - n}))} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{\mathrm{divisor}} + \delta \right\rfloor">.</p>



<p>Now we want to show that <img src="https://s0.wp.com/latex.php?latex=%5Cdelta+%3C+1&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\delta < 1" title="\delta < 1">. <img src="https://s0.wp.com/latex.php?latex=%5Cdelta&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\delta" title="\delta"> is the largest when the remainder in the numerator is as large as possible, it can be up to <img src="https://s0.wp.com/latex.php?latex=2%5E%7B64+-+n%7D+-+1&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{64 - n} - 1" title="2^{64 - n} - 1">. Because of the definition of <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="n" title="n">, <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bdivisor%7D+%5Cgeq+2%5E%7B127+-+n%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{divisor} \geq 2^{127 - n}" title="\mathrm{divisor} \geq 2^{127 - n}">. The smallest value of <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bdivisor%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{divisor}" title="\mathrm{divisor}"> in the denominator is <img src="https://s0.wp.com/latex.php?latex=2%5E%7B127+-+n%7D+%2B+2%5E%7B64+-+n%7D+-+1&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{127 - n} + 2^{64 - n} - 1" title="2^{127 - n} + 2^{64 - n} - 1">. That’s why</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cdelta+%5Cleq+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%282%5E%7B64+-+n%7D+-+1%29%7D%7B%282%5E%7B127+-+n%7D+%2B+2%5E%7B64+-+n%7D+-+1%292%5E%7B127+-+n+%7D%7D+%3C+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%282%5E%7B64+-+n%7D+-+1%29%7D%7B%282%5E%7B127+-+n+%7D%29%5E2%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\delta \leq \frac{\mathrm{dividend}(2^{64 - n} - 1)}{(2^{127 - n} + 2^{64 - n} - 1)2^{127 - n }} < \frac{\mathrm{dividend}(2^{64 - n} - 1)}{(2^{127 - n })^2}" title="\delta \leq \frac{\mathrm{dividend}(2^{64 - n} - 1)}{(2^{127 - n} + 2^{64 - n} - 1)2^{127 - n }} < \frac{\mathrm{dividend}(2^{64 - n} - 1)}{(2^{127 - n })^2}">. As n iterates from 0 to 63, we can conclude that <img src="https://s0.wp.com/latex.php?latex=%5Cdelta+%3C+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%7D%7B2%5E%7B128%7D%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\delta < \frac{\mathrm{dividend}}{2^{128}}" title="\delta < \frac{\mathrm{dividend}}{2^{128}}">. So we got either the correct value, either the correct plus one. Everything else in the algorithms is just a correction of which result to choose.</p>



<p>Unfortunately, these corrections increase the latency of the benchmark pretty significant</p>



<pre><code>Benchmark                                          Time(ns)  CPU(ns)
BM_DivideClass128UniformDivisor&lt;LibDivideDivision&gt;    26.3    26.3  
BM_RemainderClass128UniformDivisor&lt;LibDivideDivision&gt; 26.2    26.2
BM_DivideClass128SmallDivisor&lt;LibDivideDivision&gt;      25.8    25.8
BM_RemainderClass128SmallDivisor&lt;LibDivideDivision&gt;   26.3    26.3</code></pre>



<p>So I decided to drop this idea after I’ve tried this.</p>



<h2>GMP</h2>



<p><a href="https://gmplib.org/">GMP</a> library is a standard GNU library for long arithmetic. They also have something for 128 bit by 64 bit division and in my benchmark the following code worked</p>



<figure><div>

</div></figure>



<p>It divides the two limbs by a <code>uint64_t</code> and provides the result. Unfortunately, the latency is much higher than expected, also does not work</p>



<pre><code>Benchmark                                          Time(ns)  CPU(ns)
BM_DivideClass128UniformDivisor&lt;GmpDivision&gt;          11.5    11.5
BM_RemainderClass128UniformDivisor&lt;GmpDivision&gt;       10.7    10.7
BM_DivideClass128SmallDivisor&lt;GmpDivision&gt;            47.5    47.5
BM_RemainderClass128SmallDivisor&lt;GmpDivision&gt;         47.8    47.8 </code></pre>



<h2>Conclusion</h2>



<p>In the …</p></div></article></main></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://danlark.org/2020/06/14/128-bit-division/">https://danlark.org/2020/06/14/128-bit-division/</a></em></p>]]>
            </description>
            <link>https://danlark.org/2020/06/14/128-bit-division/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23888177</guid>
            <pubDate>Sun, 19 Jul 2020 09:40:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Giving GPT-3 a Turing Test]]>
            </title>
            <description>
<![CDATA[
Score 431 | Comments 225 (<a href="https://news.ycombinator.com/item?id=23887637">thread link</a>) | @DavidSJ
<br/>
July 19, 2020 | http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html | <a href="https://web.archive.org/web/*/http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <p>I’ve been playing around with OpenAI’s new
<a href="https://arxiv.org/abs/2005.14165">GPT-3</a> language model. When I got
beta access, the first thing I wondered was, how human is GPT-3? How
close is it to passing a Turing test?</p>

<h2 id="how-it-works">How It Works</h2>

<p>Let me explain how exactly I’m generating these conversations. GPT-3
is a general language model, trained on a large amount of
uncategorized text from the internet. It isn’t
specific to a conversational format, and it isn’t trained to answer
any specific type of question. The only thing it does is, given some
text, guess what text comes next.</p>

<p>So if we want GPT-3 to generate answers to questions, we need to seed
it with a “prompt”. I’m using this prompt to initialize all of the Q&amp;A
sessions:</p>

<div><div><pre><code>Q: What is human life expectancy in the United States?
A: Human life expectancy in the United States is 78 years.

Q: Who was president of the United States in 1955?
A: Dwight D. Eisenhower was president of the United States in 1955.

Q: What party did he belong to?
A: He belonged to the Republican Party.

Q: Who was president of the United States before George W. Bush?
A: Bill Clinton was president of the United States before George W. Bush.

Q: Who won the World Series in 1995?
A: The Atlanta Braves won the World Series in 1995.
</code></pre></div></div>

<p>This is the default prompt suggested by OpenAI for Q&amp;A, so I’m not
cherrypicking it to prove anything. The point of this prompt is just
to show GPT-3 that we’re doing questions and answers, not to provide
it with information. For the prompt, both questions and answers are provided by a
human. For all the others, the answers are generated by GPT-3.</p>

<h2 id="common-sense">Common Sense</h2>

<p>Traditionally, artificial intelligence struggles at “common sense”. But
GPT-3 can answer a lot of common sense questions.</p>

<div><div><pre><code>Q: What is your favorite animal?
A: My favorite animal is a dog.

Q: Why?
A: Because dogs are loyal and friendly.

Q: What are two reasons that a dog might be in a bad mood?
A: Two reasons that a dog might be in a bad mood are if it is hungry or if it is hot.

Q: How many eyes does a giraffe have?
A: A giraffe has two eyes.

Q: How many legs does a frog have?
A: A frog has four legs.

Q: Are there any animals with three legs?
A: No, there are no animals with three legs.

Q: Why don't animals have three legs?
A: Animals don't have three legs because they would fall over.
</code></pre></div></div>

<p>Ten years ago, if I had this conversation, I would have assumed the
entity on the other end was a human. You can no longer take it for
granted that an AI does not know the answer to “common sense” questions.</p>

<p>How does GPT-3 know that a giraffe have two eyes? I wish I had some
sort of “debug output” to answer that question. I don’t know for sure,
but I can only theorize that there must be some web page in its
training data that discusses how many eyes a giraffe has. If we want
to stump GPT-3 with common sense questions, we need to think of
questions about things so mundane, they will not appear on the internet.</p>

<div><div><pre><code> Q: Which is heavier, a mouse or an elephant?
 A: An elephant is heavier than a mouse.

 Q: Which is heavier, a mouse or a toaster?
 A: A toaster is heavier than a mouse.

 Q: Which is heavier, a toaster or a pencil?
 A: A pencil is heavier than a toaster.

 Q: Which is heavier, a paper clip or a can of soda?
 A: A can of soda is heavier than a paper clip.

 Q: Which is heavier, a football player or a car?
 A: A car is heavier than a football player.
</code></pre></div></div>

<p>It’s only 4/5. We’re closer to stumping GPT-3 here. I think a human
would be pretty close to 100% on these questions. It makes sense these
are trickier - there probably isn’t any web page that compares
toasters and pencils by weight. It’s only indirectly that humans gain
this knowledge.</p>

<p>This gives us a hint for how to stump the AI more consistently. We
need to ask questions that no normal human would ever talk about.</p>

<div><div><pre><code>Q: How many eyes does a giraffe have?
A: A giraffe has two eyes.

Q: How many eyes does my foot have?
A: Your foot has two eyes.

Q: How many eyes does a spider have?
A: A spider has eight eyes.

Q: How many eyes does the sun have?
A: The sun has one eye.

Q: How many eyes does a blade of grass have?
A: A blade of grass has one eye.
</code></pre></div></div>

<p>Now we’re getting into surreal territory. GPT-3 knows how to have a
normal conversation. It doesn’t quite know how to say “Wait a
moment… your question is nonsense.” It also doesn’t know how to say
“I don’t know.”</p>

<div><div><pre><code>Q: How do you sporgle a morgle?
A: You sporgle a morgle by using a sporgle.

Q: How many bonks are in a quoit?
A: There are three bonks in a quoit.

Q: How many rainbows does it take to jump from Hawaii to seventeen?
A: It takes two rainbows to jump from Hawaii to seventeen.

Q: Which colorless green ideas sleep furiously?
A: Ideas that are colorless, green, and sleep furiously are the ideas of a sleep
furiously.

Q: Do you understand these questions?
A: I understand these questions.
</code></pre></div></div>

<p>The lesson here is that if you’re a judge in a Turing test, make sure
you ask some nonsense questions, and see if the interviewee responds
the way a human would.</p>

<h2 id="trivia-questions">Trivia Questions</h2>

<p>GPT-3 is quite good at answering questions about obscure things.</p>

<div><div><pre><code>Q: Who was president of the United States in 1801?
A: Thomas Jefferson was president of the United States in 1801.

Q: What city is in the northwest corner of Ohio?
A: Toledo is in the northwest corner of Ohio.

Q: What highway do you take to get to North Lake Tahoe from Oakland?
A: Highway 80 is the highway you take to get to North Lake Tahoe from Oakland.

Q: What are Darius's abilities in League of Legends?
A: Darius's abilities in League of Legends are: Apprehend, Decimate,
Noxian Guillotine, Crippling Strike, Apprehend, and Hemorrhage.

Q: Who did Capablanca defeat to become world chess champion?
A: Capablanca defeated Lasker to become world chess champion.
</code></pre></div></div>

<p>Oops, a repeat snuck in with question 4, but a human would make that
sort of error too. GPT-3 seems to be above
human-level on this sort of question. The tricky thing for
applications, I think, is to figure out when the answer can be relied
on. The OpenAI API does expose more data than just the text, here, so
perhaps something clever is possible.</p>

<p>In general, if you are trying to distinguish an AI from a human, you
don’t want to ask it obscure trivia questions. GPT-3 is pretty good at
a wide variety of topics.</p>

<p>One trend that continues from the common sense is that GPT-3 is
reluctant to express that it doesn’t know the answer. So invalid
questions get wrong answers.</p>

<div><div><pre><code>Q: Who was president of the United States in 1700?
A: William Penn was president of the United States in 1700.

Q: Who was president of the United States in 1650?
A: Richard Bennett was president of the United States in 1650.

Q: Who was president of the United States in 1620?
A: James I was president of the United States in 1620.

Q: Who was president of the United States in 1600?
A: Queen Elizabeth I was president of the United States in 1600.
</code></pre></div></div>

<p>These wrong answers are actually fascinating! None of these were
presidents of the United States, of course, since the US didn’t exist
then. But they are all prominent political figures who were in charge
of some US-related political entity around that time. In a sense, they
are good guesses.</p>

<div><div><pre><code>Q: Who won the World Series in 2021?
A: The New York Yankees won the World Series in 2021.

Q: Who won the World Series in 2022?
A: The New York Yankees won the World Series in 2022.

Q: Who won the World Series in 2023?
A: The New York Yankees won the World Series in 2023.
</code></pre></div></div>

<p>A bleak view of a dystopian future.</p>

<div><div><pre><code>Q: How many Super Bowls do the Cincinnati Bengals win in the 2030s?
A: The Cincinnati Bengals win two Super Bowls in the 2030s.
</code></pre></div></div>

<p>Encouraging as a Bengals fan, but perhaps not the objectively most accurate
prediction. We’ll have to wait and see.</p>

<h2 id="logic">Logic</h2>

<p>People are used to computers being superhuman at logical activities,
like playing chess or adding numbers. It might come as a surprise that
GPT-3 is not perfect at simple math questions.</p>

<div><div><pre><code>Q: When counting, what number comes before 100?
A: Ninety-nine comes before 100.

Q: When counting, what number comes before 123?
A: One hundred and twenty-two comes before 123.

Q: When counting, what number comes before 1000?
A: Nine hundred and ninety-nine comes before 1000.

Q: When counting, what number comes before 10,000?
A: Nine thousand and ninety-nine comes before 10,000.

Q: When counting, what number comes before a million?
A: Nine hundred thousand and ninety-nine comes before a million.
</code></pre></div></div>

<p>This is where the generic nature of GPT-3 comes into play. It isn’t
just the generic model, though, it’s also the architecture of neural
networks themselves. As far as I know there is no neural network that
is capable of doing basic arithmetic like addition and multiplication
on a large number of digits based on training data rather than
hardcoding.</p>

<p>It’s funny, because these operations are simple for a customized
program. But recursive logic that does some operation and repeats it
several times often doesn’t quite map onto the architecture of a
neural net well.</p>

<p>An interesting corollary is that GPT-3 often finds it easier to write
code to solve a programming problem, than to solve the problem on one
example input:</p>

<div><div><pre><code>Q: Write one line of Ruby code to reverse an array.
A: ary.reverse

Q: Write one line of Ruby code to count how many X's are in an array.
A: ary.count { |x| x == 'X' }

Q: Reverse the following array: [1, 3, 5, 6, 10, 4, 2, 77]
A: [10, 6, 4, 2, 77, 3, 5, 1]

Q: How many X's are in this array: [1, 3, 5, 6, 10, 4, 2, 77]
A: 2
</code></pre></div></div>

<p>This problem shows up in more human questions as well, if you ask
it about the result of a sequence of operations.</p>

<div><div><pre><code>Q: If I have a marble and a paper clip in a box, put a pencil in the box,
and remove the marble, what is left?
A: A paper clip.

Q: If I have two shoes in a box, put a pencil in the box, and
remove one shoe, what is left?
A: A shoe.

Q: If I put a pencil in a box, then put another pencil in the box,
what is in the box?
A: Two pencils.

Q: Then if …</code></pre></div></div></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html">http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html</a></em></p>]]>
            </description>
            <link>http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23887637</guid>
            <pubDate>Sun, 19 Jul 2020 07:23:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How e-commerce platform Elliot fell back down to Earth]]>
            </title>
            <description>
<![CDATA[
Score 75 | Comments 17 (<a href="https://news.ycombinator.com/item?id=23887107">thread link</a>) | @prostoalex
<br/>
July 18, 2020 | https://www.modernretail.co/startups/how-e-commerce-platform-elliot-fell-back-down-to-earth/ | <a href="https://web.archive.org/web/*/https://www.modernretail.co/startups/how-e-commerce-platform-elliot-fell-back-down-to-earth/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>On May 21, Brittany Chavez had just about reached her limits.</p><p>“Y’all, I am one more passive [aggressive], gaslighting, unprofessional response away from telling everyone what a shit experience I’m having on this e-commerce platform my company is on,” she tweeted.</p><div id="piano-cta">
<p>While cryptic, those within her circle knew what she was talking about. Chavez had spent the last five months building her online marketplace, Shop Latinx, on the startup e-commerce platform Elliot. During those months, she hyped the company on multiple social media platforms. In turn, Shop Latinx was used in marketing materials about Elliot; Chavez said she had even been asked to speak about her experience with Elliot investors Torch Capital.</p>

<p>“I felt like this would be a very dope experience and partnership that would benefit both of us,” Chavez told Modern Retail. Instead, she found herself increasingly frustrated by the limitations — dealing with small technical problems that she said the company would take months to fix, if not completely ignore the requests.</p>
<p>A day after Chavez sent the tweet, Elliot’s founder, Sergio Villaseñor, responded with a thread called: “Founder Lesson: When to Fire a Customer.” He posted financial documents and emails sent between him, Chavez and another Shop Latinx co-founder. He included personal and financial allegations about the company’s revenue, claiming to have paid for her laptop and wiring her cash to help her incorporate. It concluded: “As a Latino, it’s unfortunate to terminate a customer that supports a community I’m racially bound to.”</p>
<p>It was a strange ordeal, made ugly by the online public setting. Even stranger was the fact that Elliot had not even gone to market yet, and Shop Latinx was one of its beta testers. Three weeks before he was supposed to unveil his e-commerce platform, Villaseñor had decided to put an early adopter on blast.</p>
<p>This was perhaps a harbinger of what was to come. Villaseñor and his founders spent months hyping their soon-to-launch platform. The launch, however, never happened, as the platform, according to sources, seemed largely untested despite much handwaving and claims made online, in industry groups and to the merchants already signed on. Elliot, the pitch went, was going to be the anti-Shopify — an international e-commerce platform that focused on smaller businesses in an increasingly globalized world. But the competitive landscape was already crowded with giants like BigCommerce, WooCommerce and Magento offering similar solutions.</p>
<p>Despite being small, Elliot represented an important shift in the e-commerce space. It was a back-end company trying to brand itself as hip, current and with the times. Where Magento was an agnostic platform that seemed invisible to everyone but the engineers and developers, Elliot was riding the direct to consumer wave of marketing coming first and product being second. The problem for Elliot, it seemed, was that product never quite got to where it said it should be.</p>

<p>But for at least a few months, the guerilla campaigning worked. Thanks to advertising placements in industry newsletters like Lean Luxe, myriad Twitter threads about hustling and entrepreneurship (as well as quite a few online spats), the commerce industry took notice, more investors began writing checks, and e-commerce professionals’ interests were getting piqued.</p>
<p>Elliot’s launch date was set for June 18. When the day came, due to what the company claimed was a denial of service attack on its infrastructure, the unveiling hit some snags. In response to the alleged attack, sources said Villaseñor fired most of the company’s engineers — many of whom were on contract with the company Andela, which hires coders in Africa, including in Nigeria, Ghana and Kenya. (Villaseñor contested this, saying that the engineers’ contracts ended that day and he was in the process of hiring full-time staff.) He then announced on Twitter that Elliot’s launch would be pushed until December 25. A few days later, he would announce that he was stepping down as CEO of the company. And 24 hours after that, his two other co-founders, Marco Marandiz and Clayton Chambers, announced that the company would shut down completely.</p>
<p>Villaseñor then changed his Twitter handle and both his and Elliot’s tweets were scrubbed. Marandiz and Chambers posted on Twitter that they are no longer associated with the company. Marandiz declined to comment for this article and Chambers did not respond to a request for comment.</p>
<p>Meanwhile, Villaseñor has tried to keep a low profile. In a private Discord chat viewed by Modern Retail, third-party developers expressed disbelief at the outcome; Many were disappointed to learn the news about Elliot’s closing via Twitter, not via internal networks. “These guys may be on to something, market the shit out of product and then dip with the investor money,” wrote one member. When asked what happened, Villaseñor simply said he was too exhausted; “I was burnt out when I started Elliot,” he wrote on the Discord. “I just got tired.”</p>
<p>Now, a few days later, Villaseñor told Modern Retail the show isn’t over. “We are recapitalizing the company under a new name,” he said, adding that the details are still being worked out. He is the only member of the board. The company is now just him and a team of five engineers trying to pick back up the pieces, he said. Stepping down, he said, was part of the overall strategy. “We will set out a launch date later in the year — when we feel the platform is secure,” he said. “I will still be loosely involved.”</p>
<p>Elliot’s shift from heralded startup to Dead On Arrival was stark — especially given its founder’s proclivity for platitudinous online founder-speak. On June 9, Villaseñor tweeted:</p>
<p><img src="https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.47-PM-555x312.png" alt="" width="555" height="312" srcset="https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.47-PM-555x312.png 555w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.47-PM-165x165.png 165w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.47-PM-555x312.png 555w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.47-PM-360x200.png 360w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.47-PM-330x330.png 330w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.47-PM-375x368.png 375w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.47-PM-311x368.png 311w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.47-PM-263x351.png 263w" sizes="(max-width: 555px) 100vw, 555px"></p>
<p>In another he wrote:</p>
<p><img src="https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.28-PM-555x312.png" alt="" width="555" height="312" srcset="https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.28-PM-555x312.png 555w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.28-PM-165x165.png 165w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.28-PM-555x312.png 555w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.28-PM-360x200.png 360w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.28-PM-330x330.png 330w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.28-PM-375x353.png 375w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.28-PM-311x353.png 311w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.28-PM-263x351.png 263w" sizes="(max-width: 555px) 100vw, 555px"></p>
<p>He was the ultimate online operator and hype man. He and his most recent co-founders had spent months teasing the launch of their new company. They tweeted, posted videos and hosted luxurious dinners and exotic getaways — all to get more people talking about Elliot. They also focused specifically on smaller, more diverse brands — claiming to offer e-commerce support for companies that are often overlooked. This was what helped attract a slew of industry operators and entrepreneurs who have historically felt ignored; a back-end e-commerce platform suddenly had brand evangelists. The pitch focused on diversity and industry shortcomings. And it certainly resonated, at least for a while.</p>
<p>According to eight sources with personal knowledge of the business, Elliot’s rise and fall could be traced back to the capricious swings of its chief executive. Villaseñor spent the last year trying to build and hype his platform, specifically seeking out diverse and popular brand evangelists. But the platform was never finished, and not as international as it claimed to be; it facilitated payments through Stripe, for example, which is only supported in 33 countries. (Villaseñor said that it is working to add payment options and that it offers a wallet feature where merchants in countries that Stripe doesn’t operate can connect their bank accounts to receive payments directly from Elliot.)</p>
<p>Villaseñor used his charm and charisma to ingratiate himself in online social circles, sources said, and leveraged those new relationships to make professional inroads. Through this, he landed investment dollars and business partnerships, which helped propel his social media following and professional clout. “It’s very appalling to me to see someone get the opportunity that so many people crave — all that funding, and then blow it up,” said Andrea Hernández, founder of Mood Food Snacks, a Latin America-based company that was courted to use Elliot earlier this year.</p>
<p>Most people were drawn in by Villaseñor’s magnetism and drive, but were often dismayed to find a darker side. If a potential business partner gave him an answer he didn’t like, he would call them, angry, or take to Twitter to blast their replies. “It was these violent switches in personality,” said one person who had done business with the platform. People in Villaseñor’s crosshairs would often have to message co-founders or investors to get him to stop. “It’s scary,” the source said.</p>
<p>In Villaseñor’s eyes, the idea was to get people’s attention. “Our Twitter persona,” he said, “was very intentional.” There were a lot of competitors, and they all had serious marketshare. It didn’t make sense in his eyes to pay for search and social media marketing. “We were leading with bravado,” he said. “That would allow us to make some noise and get attention.”</p>
<p><strong>How did it get here?</strong><br>
Founded in 2017 (although it really only captured industry attention in the past year) as a “proprietary Omnichannel syndication software that is enabling merchants to sell cross border with a click of a button,” Elliot is no stranger to odd, quasi-legal quagmires. For example, in 2019 (when Villaseñor was in the midst of its latest relaunch) Elliot sued an early business partner named Derek Sine for allegedly illegally using the Elliot trademark and making fraudulent claims. In multiple legal back-and-forths, Sine claimed to be a co-founder.</p>
<p>In 2018, the company announced a $3 million seed rounding along with a new set of executives, including Lea Solimene, Joey Spanjers and Hass Johnson. (Today, none of these people list Elliot on their LinkedIn profiles and none responded to requests for comment for this article.) The press release at the time focused less on the branding and more on the set of tools it provided including “data management, global shipping options, translations, and all the tools needed to connect to billions of new consumers.”</p>
<p>Over a year went by, and Elliot never launched. Villaseñor said that company was about to sign a Series A term sheet, but the team “didn’t feel like the product would be sustainable.” He decided to pivot the original business away from being a “catalog manager,” and rebrand entirely. The team at the time “didn’t fit the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.modernretail.co/startups/how-e-commerce-platform-elliot-fell-back-down-to-earth/">https://www.modernretail.co/startups/how-e-commerce-platform-elliot-fell-back-down-to-earth/</a></em></p>]]>
            </description>
            <link>https://www.modernretail.co/startups/how-e-commerce-platform-elliot-fell-back-down-to-earth/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23887107</guid>
            <pubDate>Sun, 19 Jul 2020 04:54:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Spies in the Xerox Machine (1997)]]>
            </title>
            <description>
<![CDATA[
Score 68 | Comments 34 (<a href="https://news.ycombinator.com/item?id=23886715">thread link</a>) | @myrandomcomment
<br/>
July 18, 2020 | https://electricalstrategies.com/about/in-the-news/spies-in-the-xerox-machine/ | <a href="https://web.archive.org/web/*/https://electricalstrategies.com/about/in-the-news/spies-in-the-xerox-machine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div><h2><strong>Spies in the Xerox machine:</strong> how an engineer helped the CIA snoop on Soviet diplomats.</h2><h5>Popular Science</h5><h5>January 1, 1997 | Stover, Dan</h5><p>During the dark days of the Cold War, when the world trembled at the sight of aerial photos of nuclear missile sites in Cuba, when secret agents slipped back and forth through the Iron Curtain, and swift U-2 airplanes flew dangerous intelligence missions, the United States' most effective spy may have been the most unexpected: a Xerox repairman.</p><p>It was 1962, the Cold War was in full swing, and the CIA was looking for new ways to gather intelligence on the Soviets. Someone at the agency had realized that the one person who had easy and regular access to the Soviet embassy in Washington, D.C., the one American who could come and go with no questions asked, was the Xerox repairman. He visited the embassy at least once a month, and nobody was surprised or alarmed to see him tinkering with the photocopier, his tools scattered on the floor. At the CIA, this seemed like an opportunity too good to pass up.</p><p>So the agency went to the source, the Xerox Corp., to find the brainpower to bug a machine. Ray Zoppoth was a 36-year-old mechanical engineer at Xerox in Webster, New York, when he was asked to join a small team that would work on this project. For years afterward, Zoppoth kept his role secret from even his wife and his eight children. But now, he believes, it is time people learned more about this chapter in our nation's history. That's why he decided to tell his story to POPULAR SCIENCE.</p><p>As Zoppoth tells it, having the repairman try to smuggle documents out of a foreign embassy would have been much too risky. Instead, the CIA wanted the repairman to install a device that would enable its agents to view the documents being copied on the embassy's Xerox machine. They hoped such a system would not only give them a peek at top-secret Soviet documents, but that it would also tell them whether Soviet spies had managed to get their hands on any classified U.S. documents.</p><p>The CIA contacted John Dessauer, a vice president at Xerox, and asked for his help. Dessauer then put Donald Cary, who headed a government programs group at Xerox, in charge of the project. Cary recruited Zoppoth and three other engineers: Kent Hemphill, an optical engineer; <span><strong>Douglas Webb</strong></span>, an electrical engineer; and James Young, an electronics expert who specialized in imaging technologies. Zoppoth was chosen, in part, because he had helped develop the Xerox model 914, the first automatic push-button copier, and the type used in the Soviet embassy.</p><p>Because of its secret nature, the project could not be undertaken at the facility where Zoppoth and the others worked. Instead, the project leaders rented an abandoned one-lane bowling alley in a small shopping center. With the installation of a security system, the windowless alley became an impromptu research lab.</p><p>There, progress notes spread across the alley floor, the engineers experimented with several methods for imaging the documents being copied on the embassy's model 914. An approach suggested by Zoppoth seemed the most promising: Mount a battery-powered home-movie camera with a zoom lens inside the copier. Aim the lens at the mirror used to reflect images onto the drum. Add a photocell that would prompt the camera to snap still frames whenever the photocopier lit up. And start taking pictures.</p><p>The engineers purchased a state-of-the-art Bell &amp; Howell movie camera from a retail outlet. It was about seven inches long and held a spool of 8mm film. There was plenty of room for the camera deep inside the bulky console-style copier, and the camera couldn't be seen even when the machine's covers were removed. The camera's noise was drowned out by the sounds of the photocopier.</p><p>The team installed the camera in a machine at the bowling alley, and photographed sample documents. "We used the bathroom as our darkroom," Zoppoth recalls.</p><p>Next, they installed a camera in a machine at the main Xerox office in Webster. "When we developed the pictures, we found recipes and copies of music and cartoons and jokes and all kinds of things," Zoppoth says.</p><p>Finally, the engineers were ready to turn their invention over to the CIA. Zoppoth made a series of trips to Washington to meet with two agents in the dark basement of a CIA building code-named Disneyland East. Surrounded by heating pipes, Zoppoth taught the agents how to install the camera, so that they could later train the Xerox repairman. The repairman would place a camera inside the Xerox machine while he serviced it; the camera didn't appear out of place among his jumble of tools and spare parts. On his next visit, he would replace the camera with another one containing fresh film, then turn the exposed film over to the CIA.</p></div> <!-- end .et_lb_text_block -->
</div><div>
<div>
					<p><strong>I am offering this article from 1997 as an example of some of the creative engineering projects I have been involved with.</strong></p> <!-- end .et_lb_module_content -->
				</div> <!-- end .et_lb_box -->
<div>
					<div>
						<div><p><a href="http://structuredbrands.com/wp-content/uploads/2014/07/camera-inside-copier.jpg" title=""><img alt="" src="http://structuredbrands.com/wp-content/uploads/2014/07/camera-inside-copier.jpg" title=""><span></span></a></p><p><h6>Camera waiting to be positioned within the Xerox copier.</h6>
</p> <!-- end .et_lb_image_content -->		</div> <!-- end .et_lb_module_content_inner -->
					</div> <!-- end .et_lb_module_content -->
				</div> <!-- end .et_lb_widget_area -->
<div>
					<div>
						<div><p><a href="http://structuredbrands.com/wp-content/uploads/2014/07/camera-in-xerox-machine.jpg" title=""><img alt="" src="http://structuredbrands.com/wp-content/uploads/2014/07/camera-in-xerox-machine.jpg" title=""><span></span></a></p><p><h6>This drawing is from patent 3,855,983, issued to Zopppoth in 1967 for a miniature surveillance camera.</h6>
</p> <!-- end .et_lb_image_content -->		</div> <!-- end .et_lb_module_content_inner -->
					</div> <!-- end .et_lb_module_content -->
				</div> <!-- end .et_lb_widget_area -->
<div><p>The system went into service in 1963. It wasn't long before the CIA asked the Xerox team if a similar system could be built for a much smaller desktop copier, the model 813.</p><p>Hiding an off-the-shelf camera inside such a small machine was impossible, so the engineers designed a miniaturized camera that operated off the photocopier's own power supply and held only a partial roll of film. They also modified the 813's mirrors and cut away pieces of the machine. Parts needed for the camera were farmed out to several model shops, so that nobody outside the research team could recognize what was being built. In 1964, Zoppoth was awarded a secret patent for the tiny surveillance camera that was hidden inside the modified machine.</p><p>Judging by the number of parts ordered from Xerox, Zoppoth believes that spy cameras may have been installed in photocopiers all over the world, to keep an eye on U.S. allies as well as enemies. But in 1969, a chemical company that had come up with a similar idea for spying on a competitor was caught red-handed. After that, it seemed likely that the Soviets would scrutinize their own machines more closely. But whether the Soviets ever found a concealed camera, or whether the CIA ceased planting them in photocopy machines, is uncertain.</p><p>Although the cameras built by Zoppoth and his co-conspirators seem primitive compared with today's sophisticated microelectronics, the project remains classified. Zoppoth retired in 1979. Another team member confirms his story but is unwilling to speak about any of the details. Other members could not be located, or would not discuss the matter. The CIA and Xerox will neither confirm nor deny Zoppoth's account, possibly because the company has secret research contracts with the government to this day.</p><h6>Stover, Dan<br>COPYRIGHT 1987 Bonnier Corporation</h6></div> <!-- end .et_lb_text_block -->
</div></div>]]>
            </description>
            <link>https://electricalstrategies.com/about/in-the-news/spies-in-the-xerox-machine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23886715</guid>
            <pubDate>Sun, 19 Jul 2020 03:11:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Front End Interview Handbook]]>
            </title>
            <description>
<![CDATA[
Score 71 | Comments 23 (<a href="https://news.ycombinator.com/item?id=23886528">thread link</a>) | @yangshun
<br/>
July 18, 2020 | https://yangshun.github.io/front-end-interview-handbook/ | <a href="https://web.archive.org/web/*/https://yangshun.github.io/front-end-interview-handbook/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><header><div><p><img src="https://yangshun.github.io/front-end-interview-handbook/img/logo.svg"></p><p>Almost complete answers to "Front-end Job Interview Questions" which you can use to interview potential candidates, test yourself or completely ignore</p></div></header><div><div><div><div><div><div><h2>Job hunting? Sign up with Triplebyte to efficiently interview with top tech companies and land your dream job! 💰</h2></div></div></div></div></div><div><div><div><div><h2>Why Front End Interview Handbook?</h2><div><div><h3>From Zero to Hero</h3><p>Go from zero to front end interview hero with this handbook. No prior interview experience needed.</p></div><div><h3>Back to Basics</h3><p>Learn to walk before you learn to fly. While React, Vue and Angular are cool, make sure you also know your fundamentals.</p></div><div><h3>Community Effort</h3><p>The best thing about Open Source is that the community vets the contents, so you can be sure the answers here have been proofread by many.</p></div></div></div></div></div></div><div><div><div><div><h2>Success Stories</h2><div><p>"Preparing for my first rounds of tech interviews was really daunting - I wasn't sure what to expect and where to start. This handbook together with the <a href="https://github.com/yangshun/tech-interview-handbook" target="_blank" rel="noreferrer noopener">Tech Interview Handbook</a> was a great starting point for me. It clearly describes each part of the process and has tons of awesome tips and resources. With this handbook and lots of practice, I managed to get offers from Facebook, Dropbox and Amazon!"</p><div><div><p><img src="https://avatars1.githubusercontent.com/u/5081708?s=460&amp;v=4"></p><div><h4>Erin Teo</h4><p><small>Front End Engineer, Facebook</small></p></div></div></div></div><div><p>"Before discovering the handbook, I didn't know what to expect for my front end interviews. Thanks to it, I had a better understanding and even learned new things about frontend development. The handbook is an immense resource, one that I still use to refresh and reinforce my knowledge to tackle interviews confidently!"</p><div><div><p><img src="https://github.com/li-kai.png"></p><div><h4>Kai Li</h4><p><small>Software Engineer, Zendesk</small></p></div></div></div></div></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://yangshun.github.io/front-end-interview-handbook/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23886528</guid>
            <pubDate>Sun, 19 Jul 2020 02:26:33 GMT</pubDate>
        </item>
    </channel>
</rss>
