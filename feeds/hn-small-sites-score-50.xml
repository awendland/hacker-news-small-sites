<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Mon, 14 Sep 2020 16:24:26 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Mon, 14 Sep 2020 16:24:26 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[I Want to Fix Goodreads]]>
            </title>
            <description>
<![CDATA[
Score 322 | Comments 164 (<a href="https://news.ycombinator.com/item?id=24454221">thread link</a>) | @prepend
<br/>
September 12, 2020 | http://prepend.com/culture/2020/09/fixing_goodreads.html | <a href="https://web.archive.org/web/*/http://prepend.com/culture/2020/09/fixing_goodreads.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post">
  

  <article>
    <p>I use <a href="https://goodreads.com/">goodreads</a> a lot because I like to read books and want to find more books to read. This morning I was reading a <a href="https://news.ycombinator.com/item?id=24451428">thread on hackernews</a> on <a href="https://www.newstatesman.com/science-tech/social-media/2020/08/better-goodreads-possible-bad-for-books-storygraph-amazon">Sarah Manavis’s NewStatesman article</a> and it reminds me of how much I want, I yearn, for useful book recommendations. I think about this pretty much every time I open the goodreads page or app and hope that maybe this is the day they finally fix recommendations, so I figure I would capture some ideas I have for fixing their recommendations.</p>

<h2 id="i-love-goodreads">I Love Goodreads</h2>

<p>First, I love Goodreads. My <a href="https://www.goodreads.com/user/show/9499790-brian">profile</a> says I joined May 2012. But I think that’s just whenever I started this profile and I have multiple, old profiles that I can’t find. My memory says I started using them soon after launch, but maybe I’m misremembering. But I’ve used them for a long time because I like to read books. I love browsing bookstores and libraries looking for new books. I experience joy finding a 50 or 100 year old book that I didn’t know about. One of my favorite things is reading a book so good that I can’t go to bed, or want to walk an extra mile. But that’s pretty rare for me, I’m lucky if I get one of those a year.</p>

<p>I have goodreads on my <a href="http://prepend.com/stack.xml">link stack</a> with the tag <a href="https://www.prepend.com/future/technology/2020/01/purdah.html">“purdah”</a> that I think means it is part of the stuff I do that uniquely identifies me.</p>

<p>Any time I get a recommendation from a friend or article or wherever, I add it to my “to read” shelf on goodreads. That helps me when I’m trying to buy a new book. So at least I can read through the 245 books that at least a past me wanted to read. This works well and is better than a vanilla list.</p>

<p>I also like seeing what my friends read and especially what they like or dislike. My friends have different tastes so it’s not as simple as just reading everything they read, but it helps a little. It’s one of the few places that I think facebook helps because at least I get to find out facebook friends who also are on goodreads. Every once in a while I find a new book through this feed, maybe once every 2 years. This might be because I don’t have many friends on goodreads (only 42), but I think it’s also because different people have different tastes in books.</p>

<p>I also like that goodreads will tell me when an author I’ve read releases a new book, or is having a book chat or something. Although I wish they would tell me when they come to a local book signing.</p>

<h2 id="the-problem-as-i-see-it">The Problem As I See It</h2>

<p>This gets me to what I think is wrong and want to fix. I have read and rated 802 books with my average rating of 3.97. This makes sense as I’m probably only going to read books I think I’ll like, but I think this is the average goodreads rating, not the average of my ratings. Looking at what I rated, I’ve only given out 3 one stars, 42 two stars and tons of five stars. I keep scrolling on and on.</p>

<p>The user interface for goodreads is pretty bad- information is hard to find, layout is wasted, search doesn’t work well, hard to tell ads from user content- but that’s not what I’m talking about here. The main problem is in finding books that I will like. Maybe a UX overhaul from a great designer would help, but not that much. A craigslist interface would be great if they could just solve this one problem…</p>

<blockquote>
  <p><strong>What is the single book that I will love most in all the world?</strong></p>
</blockquote>

<p>I want to find the next amazing experience. Books are great because they are cheap and portable. It’s not like wine where the best is more than I’ll ever pay. Or travel where a first class flight can cost $20k. If I can find a book, I can read it. And maybe someone I know can read it too.</p>

<p>If I can mix in more wonderful books, my life will be better. My family’s life will be better. Etc etc. Maybe this is the answer to world enlightenment. Probably not, but it will be great, I think.</p>

<p>When I click on <a href="https://www.goodreads.com/recommendations">recommendations</a>, goodreads shows me five books that I don’t want to read. And it’s weirdly bad. Some of it makes since why it’s bad. They recommend different versions of books I’ve read. They recommend two different versions of <em>Lord of the Rings</em> (one of my favorite books), but I guess they don’t know these are the same book. That’s just a waste of time and it’s weird that amazon isn’t smart enough to avoid duplicative books.</p>

<p><img src="http://prepend.com/assets/images/goodreads_recommendations.png" alt="Screenshot of goodreads recommendations page"></p>

<p>But then they recommend stuff like Stephen King’s <em>The Long Walk</em>. This is perplexing because I only have one book that goodreads knows I’ve read from King and I rated it two stars. I don’t have any of his books in my “to read” list. Why would they recommend this book? Two of my friends rated it four stars and one even wrote a recommendation. So maybe that’s why. I’m aware of this book and don’t want to read it. But other books like <em>Shoe Dog</em> by Phil Knight has no relationship to me. Why would they recommend this? I also know about this book and don’t want to read it. I wish there was some way to note books that I don’t want to read. Then at least they would stop showing me the same book over and over.</p>

<p>So it seems like goodreads is making pretty basic, rules-based recommendations. And they don’t help me pick new books.</p>

<h2 id="my-perfect-wish">My Perfect Wish</h2>

<p>My idea for an 11-star experience <sup id="fnref:brian_chesky" role="doc-noteref"><a href="#fn:brian_chesky">1</a></sup> in finding new books is that Goodreads knows me even better than I know myself and constantly recommends the perfect book. They recommend books that teach me, that spark enlightenment, that I hate but teach me to appreciate other books, books for when I want to be happy, and books for when I need to be sad. I want something like Jane from Ender’s Game who experiences everything I know but is fixated on finding me a good book. So the output of a book sommelier whose passion is seeing me sit there and love a book.</p>

<p>That’s what I would like.</p>

<h2 id="a-little-story-about-jeff-bezos">A Little Story About Jeff Bezos</h2>

<p>Once I was lucky enough to go to TED. It was great on so many levels, I highly recommend it and 2/3 of the cost was tax deductible. It was full of great stuff. I got to wait in the registration line in front of Neil Gaiman and Amanda Palmer, that was neat.</p>

<p>Anyway, one night Neil Gaiman was doing in a midnight ghost story reading in some neat four story townhouse type building <sup id="fnref:vancouver_club" role="doc-noteref"><a href="#fn:vancouver_club">2</a></sup> that was totally empty and spooky and a great place for the event. The reading was on the top floor and there was a huge crowd waiting for the single elevator in this place. The lights were off and there weren’t any staff around so it was maybe 100 people waiting to go up three at a time. So I looked around the corner and took the stairs. About 2 or 3 other people had the same idea so we started racing up the stairs to get to the top and avoid the crowds.</p>

<p><img src="http://prepend.com/assets/images/vancouver_club.jpg" alt="Vancouver Club street view">
<em>photo by <a href="https://fineartamerica.com/profiles/2-joe-fox">Joe Fox</a></em></p>

<p>This building was awesome. It seemed 100 years old, rare in Vancouver, and as we went up the stairs we saw each floor. The stairwell opened up to a big room that could probably seat a 50 person wedding dinner. The lights were off, and someone had opened a few windows and the white, wispy curtains were blowing with a little breeze. Even though it didn’t feel like a breeze. I said “cool, haunted house” and stopped climbing the stairs to look around. The person next to me said “yeah, cool” and we started quickly running around checking out the empty room. We did this on the third floor too and me and this random person did quick 60 second explorations of this spooky house.</p>

<p>It all happened quickly. Maybe 3 minutes to go up the stairs, run around each floor, and get to the top. About halfway through I realized this random dude was Jeff Bezos. I thought that was neat. I’ve bought books from Amazon since 1995 and I’m pretty sure I telnetted into it to order some books (although maybe that was cdnow before they bought them), so it was cool to think that Jeff Bezos likes haunted houses and still likes exploring empty buildings.</p>

<p>We got to the top and went into the venue and were maybe the first 10 people. Comically got there maybe after two or three elevators full of people. We went to the front where Gaiman was setting up at the podium. I got a comfy chair right in the front about five feet in front of Gaiman. Jeff Bezos sat in the chair to my left. The chair on my right had Neil’s wife, Amanda Palmer, who was carrying a ukelele case. I didn’t know it was a ukulele case until she told me. She also said she might play, but she didn’t.</p>

<p>Gaiman finished setting up and came up to talk to Bezos. Bezos asked if Gaiman got the books he sent. Gaiman said he did and they were really great and he enjoyed reading them. It seemed like this was the most recent in a series of book shipments.</p>

<p>Aside from nerd joy from getting to witness this small talk of people who interest me, I thought, at the time and many times since,</p>

<blockquote>
  <p>How cool is it that Neil-freaking Gaiman is still finding new books that are great, and how cool would it be to get book recommendations from Jeff Bezos. I bet he has access to the best book recommendations in the world.</p>
</blockquote>

<p>Also, TED has something called the “TED book club” where they mail you this box of books a month before the conference. This was the closest I’ve come to my dream. They maybe sent 10 and 5 are still on my bookshelf. But not the shelf behind me, so I don’t remember them specifically. I’ll look them up one day.</p>

<p>That’s probably better than Jane making recommendations. Amazon had just bought goodreads a year earlier and I was hopeful that any day, goodreads would roll out a wonderful recommendation engine any day now.</p>

<h2 id="what-i-want-to-do-to-fix">What I Want to Do to Fix</h2>

<p>What I would like to do is to just get a data dump of mine and everyone on goodreads recommendations. I don’t need to know the identities, just to know what recommendations go with what individual. It would be neat to protect privacy and find individuals to potentially follow them on goodreads, but I think for the analysis I want to do, I don’t need to know the actual identities.</p>

<p>I think if I have this data, I could try to find people who rate a few hundred books like I have, then look at what books they’ve read the most, or books that they’ve rated highest. I think that would be a good signal that I might like it.</p>

<p>It would also be cool to see …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://prepend.com/culture/2020/09/fixing_goodreads.html">http://prepend.com/culture/2020/09/fixing_goodreads.html</a></em></p>]]>
            </description>
            <link>http://prepend.com/culture/2020/09/fixing_goodreads.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24454221</guid>
            <pubDate>Sat, 12 Sep 2020 18:06:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[From Rust to TypeScript]]>
            </title>
            <description>
<![CDATA[
Score 206 | Comments 137 (<a href="https://news.ycombinator.com/item?id=24453007">thread link</a>) | @valand
<br/>
September 12, 2020 | https://valand.dev/blog/post/from-rust-to-typescript | <a href="https://web.archive.org/web/*/https://valand.dev/blog/post/from-rust-to-typescript">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>Edits:</em></p>
<ul>
<li><em>HN discussion here: <a href="https://news.ycombinator.com/item?id=24453007#24454277">https://news.ycombinator.com/item?id=24453007#24454277</a>. Thank you HN folks for the corrections, kind responses, and insightful discussion.</em></li>
<li>*fixes in Getting Rid of Exceptions snippet 1.</li>
</ul>
<p>I was introduced to Rust in 2018 and has been enamored since. Rust is a system programming language, much like C++. Unlike C++ though, being relatively new, its language design is more modern and sophisticated. Writing with can feel more like writing TypeScript or Haskell. Not surprising since, despite being a language with a very minimum runtime and no GC, it derives many principles of functional programming such as immutability, type inference, higher-order functions, pattern-matching, etc. Over the course of tinkering things with Rust, I realized that writing Rust code makes me a better coder in other languages. This article will describe how my attempt to push the best in Rust's language design into TypeScript, my main language, without altering the language itself.</p>
<h2>Getting Rid of Exceptions</h2>
<p>The first thing that strikes me the first time I learnt Rust is that there are no straightforward to write exception-like code in Rust. For someone used to exceptions after using many languages like C++, Java, JavaScript and TypeScript, this seems like an incomplete language. But Rust's lack of straightforward exception-like is actually thought out in advance.</p>
<p>Exceptions feel neat the first time you understand it. A thrown exception skips code execution into the <code>catch</code> block. By doing that you can ignore the rest of code in the function. The rest of the code in the function represents positive case, which may seem irrelevant when an error happens. Here's a piece of code:</p>

    <div data-language="text/typescript">
      <pre><code><span>function</span><span> </span><span>foo</span><span>(</span><span>someNumber</span><span>:</span><span> </span><span>number</span><span>)</span><span> </span><span>{
</span><span>  </span><span>if</span><span> </span><span>(</span><span>someNumber</span><span> </span><span>===</span><span> </span><span>0</span><span>)</span><span> </span><span>{
</span><span>    </span><span>throw</span><span> </span><span>new</span><span> </span><span>Error</span><span>(</span><span>"Error: foo"</span><span>);
</span><span>  </span><span>}
</span><span>  </span><span>return</span><span> </span><span>someNumber</span><span> </span><span>+</span><span> </span><span>1</span><span>;
}
</span><span>function</span><span> </span><span>bar</span><span>(</span><span>someNumber</span><span>:</span><span> </span><span>number</span><span>)</span><span> </span><span>{
</span><span>  </span><span>return</span><span> </span><span>foo</span><span>(</span><span>someNumber</span><span>)</span><span> </span><span>+</span><span> </span><span>1</span><span>;
}
</span><span>function</span><span> </span><span>baz</span><span>(</span><span>someNumber</span><span>:</span><span> </span><span>number</span><span>)</span><span> </span><span>{
</span><span>  </span><span>return</span><span> </span><span>bar</span><span>(</span><span>someNumber</span><span>)</span><span> </span><span>+</span><span> </span><span>1</span><span>;
}
</span><span>baz</span><span>(</span><span>0</span><span>);</span></code></pre>
    </div>
<p>When <code>baz</code> is called it will throw an uncaught exception. By reading the code you know that <code>foo</code> throws an Error. Debugging this snippet is a piece of cake, right?</p>
<p>Now let's see another snippet. In the snippet below you are importing a function that can throw exception.</p>

    <div data-language="text/typescript">
      <pre><code><span>import</span><span> </span><span>{</span><span> </span><span>callMe</span><span> </span><span>}</span><span> </span><span>from</span><span> </span><span>"somePackage"</span><span>;

</span><span>try</span><span> </span><span>{
</span><span>  </span><span>
</span><span>  </span><span>callMe</span><span>();
}</span><span> </span><span>catch</span><span> </span><span>(</span><span>exception</span><span>)</span><span> </span><span>{
</span><span>  </span><span>
</span><span>  </span><span>
</span><span>  </span><span>
</span><span>  </span><span>console</span><span>.</span><span>error</span><span>(</span><span>exception</span><span>.</span><span>message</span><span>);
}</span></code></pre>
    </div>
<p>Compared to the first snippet, this one is harder to debug. It seems so because 1.) You don't know that <code>callMe</code> will throw an error or not. 2.) If it throws an exception you will not know what is the type of the exception. The more modular your code is, the harder it is to debug exceptions.</p>
<p>Why is that? If you noticed, in the first snippet, you know which function is throwing what because the <code>throw</code> and the caller are in one file. You don't need to switch files or even scroll that far to see what's wrong. Furthermore, unlike in other language like java, TypeScript exceptions are not typed. Because of that, unlike return values, the compiler could not deduce if a function will throw an exception or not, and that's bad. Combined with the fact that an exception propagates up until they are caught. That means exception can be n-level deep. The deeper it is from, the harder it is to debug it.</p>
<p>If you're familiar with statically-typed language, deferring what's supposed to be done in compile-time to run-time is bad. It hands over problems from the compiler to the user.</p>
<p>There are best practices for writing <code>try/throw/catch</code>, such as developers should throw <code>Error</code> objects instead of nullish values. But pushing everyone to apply best practice is not enough. You cannot assert control toward what is being written in external dependencies. There are not many points introducing law when enforcers are nowhere to be found.</p>
<p>Only when you have dealt with complex codebase you will understand why <a href="https://wiki.c2.com/?DontUseExceptionsForFlowControl">we should not use exception for flow control</a>.</p>
<p>So how Rust does this? Rust encourages us to return errors instead of throwing it by providing a data type called <code>Result</code>. It is a tagged union which can either be <code>Ok(IdealData)</code> or <code>Err(NonIdealData)</code>. With this, a function can communicate the situation of a a call to its caller. For example:</p>

    <div data-language="rust">
      <pre><code><span>fn</span><span> </span><span>main</span><span> () {</span><span>
</span><span>    </span><span>let</span><span> </span><span>number</span><span>: </span><span>Result</span><span>&lt;</span><span>u8</span><span>, </span><span>_</span><span>&gt;</span><span> </span><span>=</span><span> </span><span>"1"</span><span>.</span><span>parse</span><span>();</span><span>
</span><span>    </span><span>let</span><span> </span><span>non_number</span><span>: </span><span>Result</span><span>&lt;</span><span>u8</span><span>, </span><span>_</span><span>&gt;</span><span> </span><span>=</span><span> </span><span>"a"</span><span>.</span><span>parse</span><span>();</span><span>
</span><span>    </span><span>println!</span><span>(</span><span>"{:?}"</span><span>, &amp;</span><span>number</span><span>);      </span><span>
</span><span>    </span><span>println!</span><span>(</span><span>"{:?}"</span><span>, &amp;</span><span>non_number</span><span>);  </span><span>
</span><span>}</span></code></pre>
    </div>
<p>The function <code>.parse()</code> converts a <code>string</code> into <code>u8</code>. There are scenarios where parsing a <code>string</code> into a <code>u8</code> can result in failure, one is if the parsed string is not a numeric string. Because <code>.parse()</code> has a negative case, it returns <code>Result&lt;u8, _&gt;</code>.</p>
<p>In Rust, <code>Err</code> does not jump like exceptions. Regardless the result is <code>Ok</code> or <code>Err</code>, the program will simply execute the next line. To handle the error the programmer has to check the return value is <code>Ok</code> or <code>Err</code>. Early return is encouraged instead of throw. Rust has the <code>?</code> syntax which help making early returns more concise to write and read.</p>
<p>To adopt this feature to TypeScript, these are the important things:</p>
<ol>
<li>Errors are returned instead of thrown</li>
<li>Errors types are known</li>
</ol>
<p>To simulate this behavior I am going to use tagged union too. I found this helpful library, <a href="https://github.com/gcanti/io-ts">fp-ts</a>. It covers a great deal of functional programming experience by leveraging TypeScript's type system, but I will only use a small portion of it.</p>
<p><code>fp-ts</code> has <code>Either&lt;Left, Right&gt;</code> data type. It is like Rust's <code>Result</code> but more flexible. <code>Either</code> is a tagged union value container. <code>Either</code> is <code>Left</code> or <code>Right</code>, usually <code>Right</code> represents the ideal case and <code>Left</code> represents the non-ideal case but both can be used with any types. Below is the type definition of <code>Either</code>.</p>

    <div data-language="text/typescript">
      <pre><code><span>type</span><span> </span><span>Either</span><span>&lt;</span><span>L</span><span>,</span><span> </span><span>R</span><span>&gt;</span><span> </span><span>=</span><span> </span><span>Left</span><span>&lt;</span><span>L</span><span>&gt;</span><span> </span><span>|</span><span> </span><span>Right</span><span>&lt;</span><span>R</span><span>&gt;</span><span>;
</span><span>type</span><span> </span><span>Left</span><span>&lt;</span><span>L</span><span>&gt;</span><span> </span><span>=</span><span> </span><span>{</span><span> </span><span>_tag</span><span>:</span><span> </span><span>"left"</span><span>;</span><span> </span><span>left</span><span>:</span><span> </span><span>L</span><span> </span><span>};
</span><span>type</span><span> </span><span>Right</span><span>&lt;</span><span>R</span><span>&gt;</span><span> </span><span>=</span><span> </span><span>{</span><span> </span><span>_tag</span><span>:</span><span> </span><span>"right"</span><span>;</span><span> </span><span>right</span><span>:</span><span> </span><span>R</span><span> </span><span>};</span></code></pre>
    </div>
<p>What's cool about <code>Either</code> is that TypeScript actually supports deducing tagged union from its tag. For example inside this block <code>if (someEither._tag === "left") { }</code> TypeScript knows that <code>someEither</code> is a <code>Left</code>. If there's a <code>return</code> in that block, TypeScript will deduce that for the rest of the function block, <code>someEither</code> data type is <code>Right</code> and not <code>Either</code> anymore.</p>
<p>Let's make a called <code>tryCatch</code>. It is used to wrap a function into Either. <code>fp-ts</code> actually provides this function, but let's write it so that we know what's under the hood.</p>

    <div data-language="text/typescript">
      <pre><code><span>const</span><span> </span><span>tryCatch</span><span> </span><span>=</span><span> </span><span>&lt;</span><span>T</span><span>,</span><span> </span><span>E</span><span>&gt;</span><span>(</span><span>fn</span><span>:</span><span> </span><span>()</span><span> </span><span>=&gt;</span><span> </span><span>T</span><span>,</span><span> </span><span>onError</span><span>:</span><span> </span><span>(</span><span>error</span><span>:</span><span> </span><span>unknown</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>E</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{
</span><span>  </span><span>try</span><span> </span><span>{
</span><span>    </span><span>
</span><span>    </span><span>return</span><span> </span><span>right</span><span>(</span><span>fn</span><span>());
</span><span>  </span><span>}</span><span> </span><span>catch</span><span> </span><span>(</span><span>error</span><span>)</span><span> </span><span>{
</span><span>    </span><span>
</span><span>    </span><span>return</span><span> </span><span>left</span><span>(</span><span>onError</span><span>(</span><span>error</span><span>));
</span><span>  </span><span>}
};</span></code></pre>
    </div>
<p>With our newly created <code>tryCatch</code>, creating a URL from string for example can be done like this.</p>

    <div data-language="text/typescript">
      <pre><code><span>export</span><span> </span><span>class</span><span> </span><span>InvalidURLError</span><span> </span><span>extends</span><span> </span><span>Error</span><span> </span><span>{}
</span><span>const</span><span> </span><span>makeURLFromString</span><span> </span><span>=</span><span> </span><span>(</span><span>str</span><span>:</span><span> </span><span>string</span><span>)</span><span> </span><span>=&gt;</span><span>
</span><span>  </span><span>tryCatch</span><span>(
</span><span>    </span><span>()</span><span> </span><span>=&gt;</span><span> </span><span>new</span><span> </span><span>URL</span><span>(</span><span>str</span><span>),
</span><span>    </span><span>()</span><span> </span><span>=&gt;</span><span> </span><span>new</span><span> </span><span>InvalidURLError</span><span>()
</span><span>  </span><span>);</span></code></pre>
    </div>
<p>Calling the function will look like this. The following snippet receives a string called <code>maybeUrl</code>. If <code>maybeUrl</code> is not a valid URL it returns an error. If the URL is not calling "example.com" it returns an error. Otherwise, it returns a promise from the <code>fetch</code> call.</p>

    <div data-language="text/typescript">
      <pre><code><span>export</span><span> </span><span>class</span><span> </span><span>NotExampleDotComError</span><span> </span><span>extends</span><span> </span><span>Error</span><span> </span><span>{}
</span><span>const</span><span> </span><span>callThisMaybeUrlIfItIncludesExampleDotCom</span><span> </span><span>=</span><span> </span><span>(
</span><span>  </span><span>maybeUrl</span><span>:</span><span> </span><span>string</span><span>
):</span><span> </span><span>Either</span><span>&lt;</span><span>InvalidURLError</span><span> </span><span>|</span><span> </span><span>NotExampleDotComError</span><span>,</span><span> </span><span>Promise</span><span>&lt;</span><span>any</span><span>&gt;&gt;</span><span> </span><span>=&gt;</span><span> </span><span>{
</span><span>  </span><span>const</span><span> </span><span>urlResult</span><span> </span><span>=</span><span> </span><span>makeURLFromString</span><span>(</span><span>maybeUrl</span><span>);
</span><span>  </span><span>
</span><span>  </span><span>if</span><span> </span><span>(</span><span>isLeft</span><span>(</span><span>urlResult</span><span>))</span><span> </span><span>return</span><span> </span><span>urlResult</span><span>.</span><span>left</span><span>;

</span><span>  </span><span>const</span><span> </span><span>url</span><span> </span><span>=</span><span> </span><span>urlResult</span><span>.</span><span>right</span><span>;
</span><span>  </span><span>if</span><span> </span><span>(</span><span>url</span><span>.</span><span>origin</span><span> </span><span>!==</span><span> </span><span>"example.com"</span><span>)</span><span> </span><span>return</span><span> </span><span>left</span><span>(</span><span>new</span><span> </span><span>NotExampleDotComError</span><span>());

</span><span>  </span><span>return</span><span> </span><span>right</span><span>(</span><span>fetch</span><span>(</span><span>urlResult</span><span>));
};</span></code></pre>
    </div>
<p>There's a bit more line of codes here, but it is great that the TypeScript compiler now can deduce the error type and you have more control over the flow. You can even deduce if the variable <code>error</code> is <code>instanceof</code> <code>NotExampleDotComError</code> or <code>InvalidURLError</code> for cases like printing different errors.</p>
<h2>Safe TypeScript</h2>
<p>If you have played an early 2000s FPS games and tried to cheat, usually you will find the <code>noclip</code> command. It makes your avatar fly through walls and grounds. Sometimes, though, you take a shortcut and triggers the wrong script. When that happens, you can't finish your level and must restart to make it work again.</p>
<p>That's how I see Rust's <code>unsafe</code> and TypeScript's <code>any</code>.</p>
<p>These two features solve a similar problem. In Rust's case, it enables developers to temporarily unlock the power of handling raw pointer in case someone needs it. In TypeScript's case, someone might need to escape into the free-typed JavaScript world. And in both, it is the programmer's responsibility to make sure everything is fine before the program goes back to the safe system.</p>
<p>Unsafe to safe Rust is like <code>any</code> type to typed TypeScript. Unlike Rust, TypeScript's type only works until you compile it to JavaScript code. Rust has <a href="https://doc.rust-lang.org/beta/rust-by-example/conversion/try_from_try_into.html">TryInto/TryFrom</a> trait to convert raw data into a data type. But in TypeScript's case, if you inject a value that does not match TypeScript's type annotation, TypeScript can't do anything. This comes from TypeScript team's decision to make it only a thin layer on top of JavaScript. They thought it is best if for people to write TypeScript like JavaScript and the compilation result to look almost the same as the source code.</p>
<p>My approach for this would be securing all external hole of my application, which are:</p>
<ul>
<li>WebAPIs, which consist of DOM, deserializable user inputs, fetch API, etc.</li>
<li>External Dependencies which returns <code>any</code></li>
</ul>
<p>When I was trying this approach, I was lucky to find <a href="https://github.com/gcanti/io-ts">io-ts</a>, created by the same author as <code>fp-ts</code>. This library helps me create a runtime type checker, or "codec" as the library's author calls it. Instead of writing:</p>

    <div data-language="text/typescript">
      <pre><code><span>type</span><span> </span><span>User</span><span> </span><span>=</span><span> </span><span>{</span><span> </span><span>username</span><span>:</span><span> </span><span>string</span><span>;</span><span> </span><span>userId</span><span>:</span><span> </span><span>string</span><span> </span><span>};</span></code></pre>
    </div>
<p>I wrote the codec for User:</p>

    <div data-language="text/typescript">
      <pre><code><span>const</span><span> </span><span>UserCodec</span><span> </span><span>=</span><span> </span><span>ioTs</span><span>.</span><span>type</span><span>({</span><span> </span><span>username</span><span>:</span><span> </span><span>ioTs</span><span>.</span><span>string</span><span>,</span><span> </span><span>userId</span><span>:</span><span> </span><span>ioTs</span><span>.</span><span>string</span><span> </span><span>});
</span><span>type</span><span> </span><span>User</span><span> </span><span>=</span><span> </span><span>ioTs</span><span>.</span><span>TypeOf</span><span>&lt;</span><span>typeof</span><span> </span><span>UserCodec</span><span>&gt;</span><span>;</span></code></pre>
    </div>
<p>Again, this is longer, but this is very useful if we want to secure those holes.</p>

    <div data-language="text/typescript">
      <pre><code><span>export</span><span> </span><span>class</span><span> </span><span>InvalidTypeError</span><span> </span><span>extends</span><span> </span><span>Error</span><span> </span><span>{}
</span><span>export</span><span> </span><span>class</span><span> </span><span>Fet…</span></code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://valand.dev/blog/post/from-rust-to-typescript">https://valand.dev/blog/post/from-rust-to-typescript</a></em></p>]]>
            </description>
            <link>https://valand.dev/blog/post/from-rust-to-typescript</link>
            <guid isPermaLink="false">hacker-news-small-sites-24453007</guid>
            <pubDate>Sat, 12 Sep 2020 15:03:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Review of Language Learning Tactics]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 44 (<a href="https://news.ycombinator.com/item?id=24452418">thread link</a>) | @laybak
<br/>
September 12, 2020 | https://knowledgeartist.org/article/language-learning-tips | <a href="https://web.archive.org/web/*/https://knowledgeartist.org/article/language-learning-tips">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><span>In my journey learning 9 languages over the years, I tried all sorts of different methods to make my learning more effective. Here are some of the notable approaches, along with why they work (or don't work). It </span> <a href="https://knowledgeartist.org/article/how-long-does-it-take-to-learn-a-language" target="_blank"><span>will be a long learning journey</span></a> <span>, I hope this article will make yours more fun and effective. </span></p> <p><span>Let's jump right in.</span></p>  <p><h3><span>Moving to the Target Country</span></h3></p> <p><span>In my experience learning a language, immersion is powerful. Being in a country where your target language is spoken is ideal. Your learning becomes always on, even if you don't realize it. </span></p> <p><span>I moved to Tokyo and worked at an all-Japanese company a few years ago. At the beginning I knew very little Japanese. But with this sink-or-swim approach and the daily immersion, I became comfortable with basic conversations within three months.</span></p> <p><span>Now, it is not always possible to just pack up and move to a different place. Read on for other tips I tested from my own experience. </span></p>  <p><h3><span>Language Exchange Meetups</span></h3></p> <p><span>You can only get so good at speaking a language without talking to native speakers. Language exchange groups are a great way to get that conversational practice. In a typical event, you would get paired up/grouped with native speakers of your target language, who are themselves looking to level up on your native tongue. </span></p> <p><span>For half of the time, the group would converse in one language, and then switch to the other language half-way. If you live in a major city, there are usually quite a few of these groups for the common languages. </span> <a href="https://www.meetup.com/" target="_blank"><span>Meetup</span></a> <span> is a great place to look for these events. This is an effective way to practice in your home city, or when you are already in your target country. </span></p>  <p><h3><span>Online Language Exchange</span></h3></p> <p><span>If you are unable to attend in-person meetups, online language exchange can be effective as well. Though in-person conversations would always feel more organic, you still get the instant feedback and practice with online language exchange calls. </span></p> <p><span>I have made a few friends along the way, while practicing my German, French, and Japanese. I previously had a pleasant experience using </span> <a href="https://www.italki.com/" target="_blank"><span>iTalki</span></a> <span>, where I could easily find language partners and schedule 1-1 Skype calls with them. It was entirely free. But at the time of writing, it appears they may have removed the free partner option.</span></p>  <p><h3><span>Learning Entire Phrases</span></h3></p> <p><span>I found it effective to memorize entire sentences, and pull them out when I need to. There are several benefits to this. When you are communicating in realtime, having phrases already memorized can reduce your stumbling. It can make you appear fluent and keep the conversation flowing. This also makes you feel more comfortable, knowing what to say or how to respond in a given situation.</span></p> <p><span>These familiar phrases serve as important anchors as well, for learning about the structure of the language, and for easily swapping out components to adapt to new situations. For example, after memorizing the phrase "After a few months of travelling, I am happy to finally be able to work with everyone", you can substitute some of the words and use it in a new scenario.</span></p> <p><span>Phrase books can be somewhat useful for this purpose, though it can sound scripted and unnatural. What feels more natural is writing down and remembering the response of native speaker in a real-life situation or in a movie.</span></p>  <p><h3><span>Movies/Shows in Your Target Language</span></h3></p> <p><span>Movies and TV shows are a great source of natural-sounding phrases (though overly dramatic sometimes) to add to your knowledge bank. This is great for a number of reasons: </span></p> <p><li><span>You can usually figure out what the movie is about (especially if you first watch it in your native language).</span></li></p> <p><li><span>It is enjoyable, which means you will stick with it</span></li></p> <p><li><span>You get to learn about the culture behind your target language</span> <strong> </strong> <span>as well.</span></li></p> <p><span>And if you are watching it on TV, I find that even the commercials in your target language are interesting. Not only is it good practice, you get a better sense of what kinds of products local people buy and the messaging that appeals to them. With the growing selection of international shows/movies on Netflix, along with audio and/or subtitles, this is a fun and easy way to make progress.</span></p>  <p><h3><span>Interviews with Subtitles and Translations</span></h3></p> <p><span>In addition to movies/shows, interviews are the perfect content for getting exposure to natural conversations, where people use casual everyday language. </span> <a href="https://www.youtube.com/user/magauchsein" target="_blank"><span>Easy Languages</span></a> <span> on YouTube is hands down one of my favourite language resources. They interview people on the streets on a different topic each episode, and provide subtitles in the original language + English. Over the years, they have built up an amazing collection of content in many (!) languages.</span></p> <p><span>Here's a taste of their content for German learners: </span></p> <div><p><iframe src="https://www.youtube.com/embed/hLoatpfE7VM?title=0&amp;byline=0&amp;portrait=0" frameborder="0"></iframe></p></div>  <p><h3><span>Passive Background Looping</span></h3></p> <p><span>This is one of the most effective hacks I developed to maximize my time spent learning a language. As I work, I would put on a familiar track of native speakers talking (much of the time it would be Easy Languages) in the ground. This way, I can get a lot of listening practice without spending much time. By picking content that you are already familiar with, you already know what is being talked about. And the looping gets you more "reps" for each phrase. It also helps you memorize entire phrases that you can use with ease later.</span></p>  <p><h3><span>Podcasts </span></h3></p> <p><span>This one can be tricky. I have tried quite a few podcasts and many podcast formats aren't that conducive to learning a foreign language. Either I don't understand what's going on, or there is too much repeating over the often dry content. But for Japanese learners, I highly recommend </span> <a href="https://bilingualnews.libsyn.com/" target="_blank"><span>Bilingual News</span></a> <span> hosted by Michael and Mami. It features the hosts talking about interesting topics in the news, with Michael speaking only English and Mami speaking only Japanese. The conversation always moves forward and remains engaging, and you can usually easily fill in the words you missed from the context. </span></p>  <p><h3><span>Ask a Native Speaker "How do I say X?" Wherever Possible</span></h3></p> <p><span>If you have friends (or better yet, roommates) from other countries, you can definitely get some practice in as you hang out. When you are trying to say something, why not learn to say it in your target language too? Anytime is learning time! You'll remember it much better than other methods because the learning takes place in real-life expeirences. I used to worry this may come off as annoying, but in my experience most people are happy to help, and appreciate the ernest effort you make to understand their language/culture. </span></p>  <p><h3><span>Changing Your Phone's Language</span></h3></p> <p><span>One easy way to squeeze out an extra bit of language immersion is to simply change your mobile phone to your target language. Doing so should automatically update the language in all your apps as well. Since you likely already know how to navigate through most apps anyway, in most cases you can guess the meaning of new words that you don't yet know. With this, even Facebook notifications become good practice. </span></p>  <p><h3><span>Taking classes</span></h3></p> <p><span>I have never been a fan of learning a language in a classroom, having taken Russian, French and Mandarin classs. This one is a bit of a hit or miss. The classroom environment has always felt a bit too artificial for this purpose. Typically, there is also limited practice, limited individual attention (and hence </span> <em>feedback</em> <span>). And the separation between the classroom learning context and the real-life situations makes it hard to apply the knowledge.</span></p> <p><span>That said, there are some amazing teachers out there who excel at teaching and building curriculum. And for some people, the structure of learning in a group guided by a competent instructor is just what they need. For Chinese learners, </span> <a href="https://www.excelmandarin.com/" target="_blank"><span>Excel Mandarin</span></a> <span> is an example of educators who have created an effective learning system for their students. Though not from my personal experience, I have heard nothing but positive reviews about these folks. </span></p>  <p><h3><span>Duolingo</span></h3></p> <p><span>There was a time when I would have a long-running practice streak on the popular free app </span> <a href="https://www.duolingo.com/" target="_blank"><span>Duolingo</span></a> <span>. I would use the app daily, and almost completed the curriculum for Brazilian Portuguese, Spanish, and German. I felt great. I felt engaged. I felt like I was making progress. But that's the dangerous part about apps like these that try to "gamify" the language learning process. it makes you feel productive, even if it may not reflect reality. </span></p> <p><span>It is all too easy to slip into auto-pilot mode, where you just rush to the finish line of each exercise. This is similar to how one would "speed read" a book in an hour and retain nothing from it. The app also trains you to get used to the machine-generated bad pronunciation, which is counter-productive for your listening skills. On the bright side, Duolingo can be helpful for exposure to new words, and adding some structure to your learning, especially if you are not following a curriculum or textbook.</span></p>  <p><h3><span>Reading Textbooks</span></h3></p> <p><span>Reading a textbook for the purpose of language learning is perhaps the best way to learn the formal structure of a language. But it is not effective for conversational purposes. Grammar rules are clean, but conversational languages are messy. Similar to the discussion above about taking classes, textbooks tend to give a similar passive understanding of rules, as opposed to the ability to apply that knowledge in real-time. </span></p>  <p><span>The best approach is the one you actually take and follow through with. One that fits your learning objectives and learning style. The more you can align your learning with your intrinsic motivation, the more likely it is that it will stick. </span></p>         


          
            
            <p><em>Each week, I send out a newsletter where I share my learnings, new ways to see things, and new ways to feel.</em></p>
            <p><em>Enter your email below to subscribe.</em></p>

            
          
        </div></div>]]>
            </description>
            <link>https://knowledgeartist.org/article/language-learning-tips</link>
            <guid isPermaLink="false">hacker-news-small-sites-24452418</guid>
            <pubDate>Sat, 12 Sep 2020 13:54:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why do so many people want us back in the office?]]>
            </title>
            <description>
<![CDATA[
Score 351 | Comments 486 (<a href="https://news.ycombinator.com/item?id=24452280">thread link</a>) | @ingve
<br/>
September 12, 2020 | https://paulitaylor.com/2020/09/12/why-do-so-many-people-want-us-back-in-the-office/ | <a href="https://web.archive.org/web/*/https://paulitaylor.com/2020/09/12/why-do-so-many-people-want-us-back-in-the-office/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>After the sudden and miraculous shift to remote work in March – the office fightback has well and truly begun.</p>



<p>Four months ago I wrote that – surprisingly- there was no fightback from technophobe hold-outs barricading themselves into their offices. They simply packed up their laptop and went home with the rest of us. <a rel="noreferrer noopener" href="https://paulitaylor.com/2020/04/06/did-a-virus-just-bring-about-the-end-of-the-office/" target="_blank">How </a><a href="https://paulitaylor.com/2020/04/06/did-a-virus-just-bring-about-the-end-of-the-office/">premature</a><a rel="noreferrer noopener" href="https://paulitaylor.com/2020/04/06/did-a-virus-just-bring-about-the-end-of-the-office/" target="_blank"> I was</a>. </p>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>2019: millenials are wasting all their money on buying sandwiches </p><p>2020: THE ECONOMY WILL COLLAPSE IF YOU DON'T BUY MORE SANDWICHES</p></div>— Sam Grinsell (@samgrinsell) <a href="https://twitter.com/samgrinsell/status/1299288101743886336?ref_src=twsrc%5Etfw">August 28, 2020</a></blockquote></div>
</div></figure>



<p>If you thought that 2020 couldn’t get any crazier – it seems some people really are suggesting that businesses should alter their workplace strategies in order to save…sandwich shops.</p>



<p>OK, I’m exaggerating for effect. But there really has been a hand brake applied to the move to remote/hybrid working , or my favoured term,<em><a rel="noreferrer noopener" href="https://medium.com/work-futures/the-future-is-minimum-office-not-zero-office-821928abdba2" target="_blank"> minimum office</a></em> in recent weeks. </p>



<p>An <a rel="noreferrer noopener" href="https://www.telegraph.co.uk/news/2020/08/27/go-back-work-risk-losing-job-major-drive-launched-get-people/" target="_blank">article in the Daily Telegraph</a>&nbsp;suggested&nbsp;that employees who continue to work at home will be more vulnerable to redundancy, with bosses finding it far easier get rid of people they don’t physically see.</p>



<p><a rel="noreferrer noopener" href="https://twitter.com/KirstieMAllsopp/status/1290987043829489666?s=20" target="_blank">Kirstie Allsopp</a> led the anti-remote work charge on Twitter, suggesting that if your job can be done from home, it can be done from anywhere in the world. Who would have thought that a couple of months of working in shorts and a T-Shirt has made us more susceptible to being replaced by less expensive folk in India, Myanmar and China? </p>



<p>A debate that is framed around saving sandwich shops and an already dying high street isn’t helpful or progressive. Cynically I might suggest the real subtext here is about propping up commercial property investment portfolios. Realistically though, we won’t see anything like a return to the same number of offices, and although few will shed tears for commercial real estate investors many small businesses will suffer a big hit and go out of business unless they can pivot very rapidly.</p>



<p>Clearly there are two groups emerging, those who are desperate for the pandemic to be viewed as a temporary event before everything returns to ‘normal’ and those embracing the true long term disruption that is occurring.</p>



<p>Thank heavens then for more balanced thinkers like Tom Cheesewright who has an uncanny ability to pan back and take the long view. <a rel="noreferrer noopener" href="https://tomcheesewright.com/were-still-human/" target="_blank">Writing on his website</a> about the current over-confidence in the possibilities for remote working he says:</p>



<p><em>“There is something different about being there, in person, with all of your senses engaged. It’s what I called a few years ago, ‘<a href="https://tomcheesewright.com/the-unbeatable-bandwidth-of-being-there/">the unbeatable bandwidth of being there</a>‘. What gets transmitted and received through the screen and headset, mediated by a million miles of fibre optic cable, is not the full experience of meeting. Nor does it allow for all the things that happen around those meetings. <a href="https://tomcheesewright.com/aftershocks-and-opportunities/">I’ve talked at length about the need for peer support, the subtler parts of staff training, and the mutual inspiration that happens when you’re sharing a physical space</a>.”</em></p>



<p>I’m a remote working, or at least a minimum office, enthusiast. I’ve written on this site for years about the worst aspects of office life and <a rel="noreferrer noopener" href="https://paulitaylor.com/2014/07/31/why-the-death-of-the-office-cant-come-too-soon/" target="_blank">the most popular post on here applauds its impending doom</a>.  Six years on though I’d admit it’s a deeply flawed argument. The idea that constant interruptions and back to back meetings were a symptom of being in a corporate building has been well and truly busted by…Microsoft Teams. </p>



<p>In truth the problem with work is not the tools or the physical location, but <a href="https://paulitaylor.com/2020/01/03/ending-our-obsession-with-leadership/">the obsession with leadership</a> , an undue focus on work about work, an overbearing hierarchy and the lack of true digitisation of the enterprise. Deeper, more complex problems.  </p>



<p>It’s ironic that it has taken a pandemic to reveal what was good about the office. “The things that happen between meetings” that Tom writes about reveal our innate desire for human contact – the need to get <em>our senses fully engaged</em>. Wasteful? Quite often. But we dismiss this at our peril. It may seem logical that workplace chatter stifles productivity, but studies show the opposite to be true. </p>



<p>A narrow focus on efficiency in the workplace and a flawed view of what makes people productive is similarly regressive and likely to drag people back to the old normal. As Stowe Boyd writes the backlash against minimum office is in full flow , as detailed in <a href="https://www.wsj.com/articles/companies-start-to-think-remote-work-isnt-so-great-after-all-11595603397?mod=trending_now_pos1">Companies Start to Think Remote Work Isn’t So Great After All</a>, as executives want to get people back in the office:</p>



<p>“<em>An increasing number of executives now say that remote work, while necessary for safety much of this year, is not their preferred long-term solution once the coronavirus crisis passes.</em></p>



<p><em>“There’s sort of an emerging sense behind the scenes of executives saying, ‘This is not going to be sustainable,’” said Laszlo Bock, chief executive of human-resources startup Humu and the former HR chief at Google. No CEO should be surprised that the early productivity gains companies witnessed as remote work took hold have peaked and leveled off, he adds, because workers left offices in March armed with laptops and a sense of doom</em>.”</p>



<p>Perhaps it’s simply we haven’t yet matched our colleagues roles, and their specific work preferences, within our existing organisational design never mind considered a future state. Working from home (managed and supported appropriately) <strong>can</strong> be more productive than going into the office.</p>



<p><a rel="noreferrer noopener" href="https://email.mg2.substack.com/c/eJwlUMuOwyAM_JpySwQkNHDgsJf9jYiA27BNIDKmVf5-aStZHsv2-DHeEdwznvbIhVgtgHMMdtRSX1nDILTSLJb5hgC7i5slrMCOumzRO4o5vdu1Mdqw1YZJTmJYQC9SaR8kv3IlBmcmM_qgRsXeS2ZXQ4TkwcIT8MwJ2GZXoqNchp-L_G22LthnvLdIcskbcN0cQgGHfu0eKb82CHfoXhkfgKVzCN2emzswh-opPqG7Yd67Ne_Aon2P4YYPQiiteC_6M_0JzqezJnMZ-X6XfalLIecfvc87Q3u4up0kWnGhmAgwAX1K7fW54V5TpHOG5JZ2ylcV-or4eZLOA2yCV9mAGvubbFIZOWmuWNsWctMzfShljTf6B3tch00" target="_blank">A HBR study published in August</a>&nbsp;contrasted surveys of knowledge workers from 2013 and 2020, found that remote working was in fact helping address long-held frustrations about the rhythm of office work. </p>



<ol><li>Lockdown helps us focus on the work that really matters. We are spending 12% less time drawn into large meetings and 9% more time interacting with customers and external partners.</li><li>Lockdown helps us take responsibility for our own schedules. We do 50% more activities through personal choice — because we see them as important — and half as many because someone else asked us to.</li><li>During lockdown, we view our work as more worthwhile.&nbsp; We rate the things we do as valuable to our employer&nbsp;<em>and</em>&nbsp;to ourselves. The number of tasks rated as tiresome drops from 27% to 12%, and the number we could readily offload to others drops from 41% to 27%.</li></ol>



<p>The key phrase here is: <em>managed and supported appropriately</em>. Certainly managers need to reinvent themselves as mentors to this style of working and then – forgive me – get the hell out of the way. </p>



<p>The office as the default way of working is dead. But the office itself isn’t dead. With working from home, what we gain in work-life balance we might lose in innovation and creativity. There are people who could directly challenge that sentence but I suspect they will come from highly mature companies who have fully mastered the remote working learning curve. Many of us are still at the stage of doing what we did in the office , just remotely. The timorous amongst us may use the lack of productivity net gains as a reason to regress rather than push through the ‘pain barrier’ <a rel="noreferrer noopener" href="https://paulitaylor.com/2020/07/11/nirvana-or-business-as-usual-navigating-the-new-future-of-work/" target="_blank">as Matt Mullenweg describes it.</a> </p>



<p>We can do so much better, for ourselves, our customers and society if we stop being so frightened or so certain of the future. </p>



<p>We are going to have fewer offices and spend more time at home. </p>



<p>Our efforts would be a lot better spent improving the experience and outcomes of both rather than arguing about preserving a status quo whose time has truly run out. </p>



<p><em>The office versus remote work?</em> It’s not a binary choice we need to make. </p>



<p>The best thing you can do in any period of change is to bet on neither black or white. The future will be made up instead of shades of grey where few things are certain and <em>the best you can do to prepare is to be endlessly adaptable</em>. </p>



<hr>



<p><em>Photo by <a href="https://unsplash.com/@bchild311?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Benjamin Child</a> on <a href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></em></p>
			
			
				</div></div>]]>
            </description>
            <link>https://paulitaylor.com/2020/09/12/why-do-so-many-people-want-us-back-in-the-office/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24452280</guid>
            <pubDate>Sat, 12 Sep 2020 13:32:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hiring the first head of marketing at a startup]]>
            </title>
            <description>
<![CDATA[
Score 158 | Comments 67 (<a href="https://news.ycombinator.com/item?id=24448513">thread link</a>) | @tosh
<br/>
September 11, 2020 | https://helenmin.com/blog/first-head-of-marketing | <a href="https://web.archive.org/web/*/https://helenmin.com/blog/first-head-of-marketing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" id="item-5e842a035e87b661d8bf062f"><div><div><div data-block-type="2" id="block-c44372ffee113b1df651"><div><p>“Did you see that Stripe’s CMO is out?” a founder asked one day from the desk behind me.</p><p>Though I’d heard the news, the question had me curious for two reasons: First, I was two months into my own role as head of marketing of a fast-growing fintech startup and curious what my boss thought about the topic. Second, I had closely followed the woman in question and considered her a terrific marketer.</p><p>“It’s only been a year,” he continued. “She must’ve been bad.”<br>&nbsp;</p><p><strong>Revolving door</strong>&nbsp;</p><p>This exchange sticks with me years later because it’s emblematic of the mentality some technical founders hold about the role of marketing.</p><p>The thinking goes: Founders build great products that sell themselves through the power of network effects. When the need arises down the road, the company will hire a proven marketing professional to start a department from scratch while everyone’s at a full sprint. If it doesn’t work out…<em>she must’ve been bad</em>.</p><p>In fact, brief tenures and abrupt departures of CMOs have become the norm in Silicon Valley.<strong> </strong>By my count, the tenures of Robinhood’s first <em>three</em> CMOs combined add up to two years; Wealthfront’s first CMO lasted a year and half; and Intercom’s and Affirm’s first CMOs were both out in less than a year. At Dropbox, our first CMO (who I found to be a fantastic leader and marketer) stayed on for just over a year…</p><p>These marketers weren’t all “bad.” Most of them have stellar reputations, in fact. So what’s really going on?</p><p><strong>Founder mentality</strong></p><p>In Silicon Valley, marketing isn’t important—until it is.</p><p>Founders often disregard marketing for as long as possible, convincing themselves it’s “fluff.” A product manager can probably handle things like customer research, product positioning, and the external components of a product launch, and then hand them off to sales, right? After all, he has an MBA. :)</p><p>This works well enough in the early stages, but then problems emerge: Customer-facing team members struggle to stick to a consistent message in the market; information isn’t flowing between customers and product teams; taking turns managing the company Twitter account isn’t working; and the founders have to manage the press alias.</p><p>At the same time, the internal demand for marketing grows: Engineering needs better market insights; product needs successful launches; sales needs more compelling materials; executives need external comms support; HR needs help with recruiting and retention; and customer success needs to scale and automate a lot of customer comms.</p><p>Finally, something happens. The company gets ensnared in a PR crisis, needs to expand to new markets, or faces new competition. If only the company had better brand equity, visibility, or public sentiment, executives could stay focused on what’s important.</p><p>At this point, founders “give in” and kick off the search for a head of marketing to build the function.</p><p><strong>‘Without a penny spent on marketing’</strong></p><p>When recruiting for their first head of marketing, founders will sometimes declare enthusiastically, “Look how far we’ve gotten—and without a penny spent on marketing!”&nbsp;</p><p>I tell them this is analogous to walking into a dentist’s office and proclaiming, “Look how great my teeth look—and without a day of brushing! Do you want to be my first dentist?” Yuck.</p><p>If you didn’t believe in marketing for years, you probably aren’t set up for the function to succeed in the first place. Experienced marketers know this.&nbsp;</p><p>If they’ve done the job before, a candidate will know they’ll be juggling four jobs at the same time:&nbsp;</p><ul data-rte-list="default"><li><p>Job 1: Recruit and manage a team;&nbsp;</p></li><li><p>Job 2: Define what marketing means at the company and educate the rest of the team;</p></li><li><p>Job 3: Help other departments succeed and scale; and</p></li><li><p>Job 4: Define the brand and tell stories to move the brand forward.</p></li></ul><p>They also know they’ll be stepping into a mess and answering to executives who expect quick results. What’s more, with no team in place, they’ll be responsible for day-to-day activities they’ve been delegating for years (writing copy, setting up marketing dashboards, etc.)&nbsp;</p><p>Do they really want to start at the beginning, with no resources?&nbsp;</p><p><strong>First hire a ‘super IC’ (or two)</strong></p><p>Instead of following this failed playbook, I advise startups to think about marketing much earlier in the process and begin laying the foundation that a future leader can build on.</p><p>Set up a small team of one or two strong individual contributors to take on marketing duties. These should be generalists capable of handling a variety of marketing tasks (maybe consider making them <a href="https://helenmin.com/blog/product-marketing">product marketing managers</a>). Have them set up basic infrastructure like a marketing automation tool that connects to your CRM and Google Analytics for your website and blog. Connect them to other departments to begin building websites optimized for conversions, developing simple campaigns, drafting brand messaging, and so on.</p><p>This is a win for the founder, who learns the different marketing functions much earlier in the process. It’s a win for the business generalist, who can find their passion while making an impact at the company. It’s a win for the future head of marketing, because someone will have already done some trial-and-error and gotten the marketing function off the ground. And it’s a win for the recruiter, because the job’s more attractive with someone already on the team cranking.</p><p>These super ICs won’t do all the jobs of a marketing head. They won’t recruit or necessarily even lead. But you’ll have people who understand marketing, speak the language, and can run experiments.</p><p><strong>Self-fulfilling prophecy</strong></p><p>Like NFL coaches, heads of marketing experience a lot of turnover. Because marketing initiatives are often hard to measure and roles aren’t customer-facing, removing a marketing lead is a quick and easy lever for a founder to pull at the first signs of things not working out.&nbsp;</p><p>As a result, a self-fulfilling prophecy develops, where marketers <em>assume</em> they’ll only last a year and start making decisions based on that belief. Knowing time is limited, they get over-ambitious and move too fast or focus on things that will pad their resume rather than strategic priorities. After a year or two, they’re off to another company and the startup is back at square one. </p><p>This is bad for startups! Scarred by their experience dealing with a first head of marketing departure, many founders put off hiring a new lead for a while—sometimes leaving the company even worse off than before the head of marketing joined.</p><p><strong>A checklist&nbsp;</strong></p><p>To avoid this fate for your company, use the following checklist to determine if you’re ready for a marketing head:&nbsp;</p><ul data-rte-list="default"><li><p><em>Do you have budget, headcount, and recruiting bandwidth to help a new marketing leader build their team?</em></p></li><li><p><em>Do you have a clear understanding of your growth model and where marketing efforts can uniquely impact growth?&nbsp;</em></p></li><li><p><em>Do you have buy-in from engineering and design leadership to support marketing experiments and campaigns?&nbsp;</em></p></li><li><p><em>Do you have the patience to allow time for experimentation and some fails before big wins?</em></p></li></ul><p>If you answer “yes” to (most of) these questions, congratulations—you’re ready to hire your first marketing head. Good luck!</p></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://helenmin.com/blog/first-head-of-marketing</link>
            <guid isPermaLink="false">hacker-news-small-sites-24448513</guid>
            <pubDate>Fri, 11 Sep 2020 23:41:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What's wrong with social science and how to fix it]]>
            </title>
            <description>
<![CDATA[
Score 127 | Comments 89 (<a href="https://news.ycombinator.com/item?id=24447724">thread link</a>) | @michael_fine
<br/>
September 11, 2020 | https://fantasticanachronism.com/2020/09/11/whats-wrong-with-social-science-and-how-to-fix-it/ | <a href="https://web.archive.org/web/*/https://fantasticanachronism.com/2020/09/11/whats-wrong-with-social-science-and-how-to-fix-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><blockquote><p>I've seen things you people wouldn't believe.</p></blockquote><p>Over the past year, I have skimmed through 2578 social science papers, spending about 2.5 minutes on each one. This was due to my participation in <a href="https://www.replicationmarkets.com/" target="_blank" rel="noopener">Replication Markets</a>, a part of DARPA's SCORE program, whose goal is to evaluate the reliability of social science research. 3000 studies were split up into 10 rounds of ~300 studies each. Starting in August 2019, each round consisted of one week of surveys followed by two weeks of market trading. I finished in first place in 3 out 10 survey rounds and 6 out of 10 market rounds. In total, about $200,000 in prize money will be awarded.</p><p>The studies were sourced from all social sciences disciplines (economics, psychology, sociology, management, etc.) and were published between 2009 and 2018 (in other words, most of the sample came from the post-replication crisis era).</p><p>The average replication probability in the market was 54%; while the replication results are not out yet (250 of the 3000 papers will be replicated), previous experiments have shown that prediction markets work well.<span><a href="#fn19282306691" rel="footnote"><sup id="fnref19282306691">1</sup></a></span></p><p>This is what the distribution of my own predictions looks like:<span><a href="#fn19282306692" rel="footnote"><sup id="fnref19282306692">2</sup></a></span></p><p><img src="https://fantasticanachronism.com/images/skimmed_mypredsdist-67f351a8a634ca87ace22fd62155e7c5.png"></p><p>My average forecast was in line with the market. A quarter of the claims were above 76%. And a quarter of them were below 33%: we're talking hundreds upon hundreds of terrible papers, and this is just a tiny sample of the annual academic production.</p><p>Criticizing bad science from an abstract, 10000-foot view is pleasant: you hear about some stuff that doesn't replicate, some methodologies that seem a bit silly. "They should improve their methods", "p-hacking is bad", "we must change the incentives", you declare Zeuslike from your throne in the clouds, and then go on with your day.</p><p>But actually diving into the sea of trash that is social science gives you a more tangible perspective, a more visceral revulsion, and perhaps even a sense of Lovecraftian awe at the sheer magnitude of it all: a vast landfill—a great agglomeration of garbage extending as far as the eye can see, effluvious waves crashing and throwing up a foul foam of p=0.049 papers. As you walk up to the diving platform, the deformed attendant hands you a pair of flippers. Noticing your reticence, he gives a subtle nod as if to say: "come on then, jump in".</p><h2 id="They-Know-What-They-39-re-Doing"><a href="#They-Know-What-They-39-re-Doing" title="They Know What They're Doing"></a>They Know What They're Doing</h2><p>Prediction markets work well because predicting replication is easy.<span><a href="#fn19282306693" rel="footnote"><sup id="fnref19282306693">3</sup></a></span> There's no need for a deep dive into the statistical methodology or a rigorous examination of the data, no need to scrutinize esoteric theories for subtle errors—these papers have obvious, surface-level problems.</p><p>There's a popular belief that weak studies are the result of unconscious biases leading researchers down a "garden of forking paths". Given enough "researcher degrees of freedom" even the most punctilious investigator can be misled.</p><p>I find this belief impossible to accept. The brain is a credulous piece of meat<span><a href="#fn19282306694" rel="footnote"><sup id="fnref19282306694">4</sup></a></span> but there are limits to self-delusion. Most of them have to know. It's understandable to be led down the garden of forking paths while producing the research, but when the paper is done and you give it a final read-over you will surely notice that all you have is a n=23, p=0.049 three-way interaction effect (one of dozens you tested, and with no multiple testing adjustments of course). At that point it takes more than a <em>subtle unconscious bias</em> to believe you have found something real. And even if the authors really are misled by the forking paths, what are the editors and reviewers doing? Are we supposed to believe they are all gullible rubes?</p><p>People within the academy don't want to rock the boat. They still have to attend the conferences, secure the grants, publish in the journals, show up at the faculty meetings: all these things depend on their peers. When criticising bad research it's easier for everyone to blame the forking paths rather than the person walking them. No need for uncomfortable unpleasantries. The fraudster can admit, without much of a hit to their reputation, that indeed they were <em>misled</em> by that <em>dastardly garden</em>, really through no fault of their own whatsoever, at which point their colleagues on twitter will applaud and say "ah, good on you, you handled this tough situation with such exquisite virtue, this is how progress happens! hip, hip, hurrah!" What a ridiculous charade.</p><p>Even when they do accuse someone of wrongdoing they use terms like "Questionable Research Practices" (QRP). How about Questionable Euphemism Practices?</p><ul><li>When they measure a dozen things and only pick their outcome variable at the end, that's not the garden of forking paths but the greenhouse of fraud.</li><li>When they do a correlational analysis but give "policy implications" as if they were doing a causal one, they're not walking around the garden, they're doing the landscaping of forking paths.</li><li>When they take a continuous variable and arbitrarily bin it to do subgroup analysis or when they add an <em>ad hoc</em> quadratic term to their regression, they're...fertilizing the garden of forking paths? (Look, there's only so many horticultural metaphors, ok?)</li></ul><p>The bottom line is this: if a random schmuck with zero domain expertise like me can predict what will replicate, <em>then so can scientists who have spent half their lives studying this stuff</em>. But they sure don't act like it.</p><h2 id="or-Maybe-They-Don-39-t"><a href="#or-Maybe-They-Don-39-t" title="...or Maybe They Don't?"></a>...or Maybe They Don't?</h2><blockquote><p>The horror! The horror!</p></blockquote><p>Check out this crazy chart from <a href="https://www.pnas.org/content/early/2020/04/28/1909046117" target="_blank" rel="noopener">Yang et al. (2020)</a>:</p><p><img src="https://fantasticanachronism.com/images/skimmed_citations-7d4f72c6e9582a5ba8775da70eda80e1.png"></p><p>Yes, you're reading that right: studies that replicate are cited at the same rate as studies that do not. Publishing your own weak papers is one thing, but citing other people's weak papers? This seemed implausible, so I decided to do my own analysis with a sample of 250 articles from the Replication Markets project. The correlation between citations per year and (market-estimated) probability of replication was -0.05!</p><p>You might hypothesize that the citations of non-replicating papers are negative, but negative citations are extremely rare.<span><a href="#fn19282306695" rel="footnote"><sup id="fnref19282306695">5</sup></a></span> <a href="https://www.pnas.org/content/112/45/13823" target="_blank" rel="noopener">One study</a> puts the rate at 2.4%. Astonishingly, even <em>after retraction</em> the <a href="https://pubmed.ncbi.nlm.nih.gov/18974415/" target="_blank" rel="noopener">vast majority of citations are positive</a>, and those positive citations <a href="https://pubmed.ncbi.nlm.nih.gov/20136577/" target="_blank" rel="noopener">continue for decades after retraction</a>.<span><a href="#fn19282306696" rel="footnote"><sup id="fnref19282306696">6</sup></a></span></p><p>As in all affairs of man, it once again comes down to Hanlon's Razor. Either:</p><ol><li>Malice: they know which results are likely false but cite them anyway.</li><li>or, Stupidity: they can't tell which papers will replicate even though it's quite easy.</li></ol><p>Accepting the first option would require a level of cynicism that even I struggle to muster. But the alternative doesn't seem much better: <em>how can they not know?</em> I, an idiot with no relevant credentials or knowledge, can fairly accurately determine good research from bad, but all the tenured experts can not? How can they not tell <em>which papers are retracted</em>?</p><p>I think the most plausible explanation is that scientists don't read the papers they cite, which I suppose involves both malice <em>and</em> stupidity.<span><a href="#fn19282306697" rel="footnote"><sup id="fnref19282306697">7</sup></a></span> <a href="https://www.gwern.net/Scanners#citogenesis-how-often-do-researchers-not-read-the-papers-they-cite" target="_blank" rel="noopener">Gwern has an write-up on this question</a> citing some ingenious analyses based on the proliferation of misprints: "Simkin &amp; Roychowdhury venture a guess that as many as 80% of authors citing a paper have not actually read the original". Once a paper is out there nobody bothers to check it, even though they know there's a 50-50 chance it's false!</p><p>Whatever the explanation might be, the fact is that the academic system does not allocate citations to true claims.<span><a href="#fn19282306698" rel="footnote"><sup id="fnref19282306698">8</sup></a></span> This is bad not only for the direct effect of basing further research on false results, but also because it distorts the incentives scientists face. If nobody cited weak studies, we wouldn't have so many of them. Rewarding impact without regard for the truth inevitably leads to disaster.</p><h2 id="There-Are-No-Journals-With-Strict-Quality-Standards"><a href="#There-Are-No-Journals-With-Strict-Quality-Standards" title="There Are No Journals With Strict Quality Standards"></a>There Are No Journals With Strict Quality Standards</h2><p>Naïvely you might expect that the top-ranking journals would be full of studies that are highly likely to replicate, and the low-ranking journals would be full of p&lt;0.1 studies based on five undergraduates. Not so! Like citations, journal status and quality are not very well correlated: <a href="https://www.frontiersin.org/articles/10.3389/fnhum.2018.00037/full" target="_blank" rel="noopener">there is no association between statistical power and impact factor</a>, and journals with higher impact factor <a href="https://www.biorxiv.org/content/10.1101/071530v1.full.pdf" target="_blank" rel="noopener">have more papers with erroneous p-values</a>.</p><p>This pattern is repeated in the Replication Markets data. As you can see in the chart below, there's no relationship between h-index (a measure of impact) and average expected replication rates. There's also no relationship between h-index and expected replication <em>within</em> fields.</p><p><img src="https://fantasticanachronism.com/images/skimmed_journalhindex-34ca20d3877248fe6b7313c3e2d39fae.png"></p><p>Even the <em>crème de la crème</em> of economics journals barely manage a ⅔ expected replication rate. 1 in 5 articles in QJE scores below 50%, and this is a journal that accepts just 1 out of every 30 submissions. Perhaps this (partially) explains why scientists are undiscerning: journal reputation acts as a cloak for bad research. It would be fun to test this idea empirically.</p><p>Here you can see the distribution of replication estimates for every journal in the RM sample:</p><p><img src="https://fantasticanachronism.com/images/skimmed_journals-cdc1139ad4faf1819b8b42db914dbe81.png"></p><p>As far as I can tell, for most journals the question of whether the results in a paper are true is a matter of secondary importance. If we model journals as wanting to maximize "impact", then this is hardly surprising: as we saw above, citation counts are unrelated to truth. If scientists were more careful about what they cited, then journals would in turn be more careful about what they publish.</p><h2 id="Things-Are-Not-Getting-Better"><a href="#Things-Are-Not-Getting-Better" title="Things Are Not Getting Better"></a>Things Are Not Getting Better</h2><p>Before we got to see any of the actual Replication Markets studies, we voted on the expected replication rates by year. <a href="https://royalsocietypublishing.org/doi/10.1098/rsos.200566" target="_blank" rel="noopener">Gordon et al. (2020)</a> has that data: replication rates were expected to steadily increase from 43% in 2009/2010 to 55% in 2017/2018.</p><p><img src="https://fantasticanachronism.com/images/skimmed_years_pre-7012095f551422f22db31bfffda1c899.png"></p><p>This is what the average predictions looked like <em>after</em> seeing the papers: from 53.4% in 2009 to 55.8% in 2018 (difference not statistically significant; black dots are means).</p><p><img src="https://fantasticanachronism.com/images/skimmed_years-1c0573dfb59a70e36a43deb2692229bf.png"></p><p>I frequently encounter the notion that after the replication crisis hit there was some sort of great improvement in the social sciences, that people wouldn't even dream of publishing studies based on 23 undergraduates any more (I actually saw plenty of those), etc. Stuart Ritchie's new book praises …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://fantasticanachronism.com/2020/09/11/whats-wrong-with-social-science-and-how-to-fix-it/">https://fantasticanachronism.com/2020/09/11/whats-wrong-with-social-science-and-how-to-fix-it/</a></em></p>]]>
            </description>
            <link>https://fantasticanachronism.com/2020/09/11/whats-wrong-with-social-science-and-how-to-fix-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24447724</guid>
            <pubDate>Fri, 11 Sep 2020 21:51:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The technical interview is an ego trip]]>
            </title>
            <description>
<![CDATA[
Score 163 | Comments 188 (<a href="https://news.ycombinator.com/item?id=24447182">thread link</a>) | @kowsheek
<br/>
September 11, 2020 | https://blog.kowsheek.com/the-technical-interview-is-an-ego-trip/ | <a href="https://web.archive.org/web/*/https://blog.kowsheek.com/the-technical-interview-is-an-ego-trip/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <p>Early in my career, after a short initial interview at a consulting firm in Toronto, I was invited to a technical interview on the same day. Two of the senior developers from the team I would join would conduct the interview.</p><p>The interview started pleasantly with them describing the project they have been working on: a portal for university professors to communicate with their students. It was being built with ASP.NET MVC, a framework I had been working with for several years. I expressed that I was comfortable with the framework and I would be excited to work on the project. Then the technical examination began and on its conclusion I left the interview feeling humiliated.</p><p>Many years later, when I was preparing to take an interview, I looked back on this experience to realize that the line of questioning and approach had been an ego trip for those developers. I promised myself to <em>never</em> make any of my candidates feel the way I did.</p><p>What did those developers do wrong? Leaving aside their attitude towards me, their questions had no relevance to the role or the project. I did not know what a red-black tree was at the time but I definitely knew how to use ASP.NET MVC which they did not inquire about.</p><p>My golden rule for technical interviews is that, "Every step, conversation and question <em>must</em> be pertinent to the day-to-day of the role." While this may be obvious, I am sure that many hiring managers are still expecting candidates to arrive at technical interviews with Computer Science books memorized. This form of technical interviews should be made obsolete.</p><figure><blockquote><p lang="en" dir="ltr">Bigger button = more clicks on the CTA <a href="https://t.co/Ter7xJdNKM">pic.twitter.com/Ter7xJdNKM</a></p>— Vincent Déniel (@vincentdnl) <a href="https://twitter.com/vincentdnl/status/1291041278264713220?ref_src=twsrc%5Etfw">August 5, 2020</a></blockquote>

</figure><p>With my golden rule as guide, I conduct a much simpler interview process. Prior to an interview, my team and I review samples of code that the candidate shared with us (or had written on Github) to understand the quality of their code. And during the interview, I dive into three areas of discussions with the candidates: product building, process adherence and team work.</p><h3 id="product-building">Product Building</h3><p>I try to understand the candidate's interest and experience of building products by,</p><ol><li>Going through their past experience and asking about what technologies and products they built and how. I ask about previous products they have shipped from concept to market.</li><li>To understand their thought process for deriving solutions, I draw an UI and ask them to outline and explain what approaches, structures and technologies they would use to build it out.</li><li>I ask about how they keep up with technologies and how they improve their skills to gauge their passion for the work.</li></ol><h3 id="process-adherence">Process Adherence</h3><p>To better understand how the candidate does their work,</p><ol><li>I go over their experiences and ask about how they managed their product-building and what tools and processes they used.</li><li>I explain the process of working on our team and ask how they would change it and where they see inefficiencies to discuss their thinking.</li><li>Often, I will give them a scenario where the processes are failing the team to find what they would do to tackle inefficiencies and if they would be willing to speak up.</li></ol><h3 id="team-work">Team Work</h3><p>I also try to understand how a candidate works in a team,</p><ol><li>While going through their past experiences, I ask about how they collaborated and communicated with their teams.</li><li>I present a scenario where their knowledge in an area may be lacking and evaluate if and how they would leverage and collaborate with their team.</li><li>Another scenario I ask about is where they disagree with their team-members to evaluate how they manage conflict and focus on delivering results for the team.</li></ol><p>I do this within one interview to be mindful of the candidate's time and mine. I want to hire candidates for their will to learn, grow and challenge the status quo.</p><p>The technology landscape is such that anyone can acquire a set of baseline programming skills. What is needed then, is a willingness to challenge ourselves and stay open-minded because every developer will have to learn on the job almost all of the time. Given this, the technical interview is arcane, academic and as good as dead.</p><hr><h3 id="further-reading">Further Reading</h3><ol><li><a href="https://news.ncsu.edu/2020/07/tech-job-interviews-anxiety/">Tech Sector Job Interviews Assess Anxiety, Not Software Skills</a></li><li><a href="https://medium.com/helpful-com/https-medium-com-fnthawar-helpful-technical-interviews-are-garbage-dc5d9aee5acd">Technical interviews are garbage. Here’s what we do instead</a></li><li><a href="https://remotesynthesis.com/blog/whats-wrong-with-tech-interviews">What's Wrong with the Tech Interview Process?</a></li></ol>
                </div>
            </section>

                <section>
    <h3>Subscribe to blog.kowsheek</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.kowsheek.com/the-technical-interview-is-an-ego-trip/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24447182</guid>
            <pubDate>Fri, 11 Sep 2020 20:47:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The NBC Chimes Machine (1999)]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 14 (<a href="https://news.ycombinator.com/item?id=24446569">thread link</a>) | @tintinnabula
<br/>
September 11, 2020 | http://www.theradiohistorian.org/chimes.htm | <a href="https://web.archive.org/web/*/http://www.theradiohistorian.org/chimes.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">



<center>
<h3><b> <span size="6">T</span><span size="4">HE </span><span size="6">NBC C</span><span size="4">HIMES</span><span size="6">M</span><span size="4">ACHINE<br></span>
Copyright 1999, John F. Schneider </b></h3></center>
<hr><p>



The sound of the NBC chimes is the sound of radio history itself.  Probably no single sound better recalls 
the golden age of radio.  The NBC chimes – the musical notes G-E-C – were played at the end of every 
NBC radio program beginning shortly after the network's inception, and continued in daily use on NBC radio and television 
until 1971. </p><p>
&nbsp;Shortly after the formation of the National Broadcasting Company
in 1926, network executives became aware of confusion among the
affiliate stations as to the exact when a program ended, and when it
was safe to cut away for local announcements. The problem was assigned
to a committee of three: Oscar B. Hanson, NBC's Director of Engineer
and a former AT&amp;T engineer; Earnest la Prada, an NBC orchestra
leader; and Phillips Carlin, an NBC announcer. They decided that a
musical signal of some kind would be an appropriate way to indicate the
ending of all programs. At that time, it was common for radio stations
to use the sounds of chimes, gongs, sirens and other mechanical devices
as a signature sound for their station, so the choice of a chime by NBC
was not unusual or particularly innovative. There is in fact some
evidence that the chimes may have been inspired by a similar chime
sequence used at that time by NBC affiliate WSB in Atlanta. </p><p>

During 1927 and 1928, the committee experimented with several combinations of notes.  A seven-note 
sequence which was first used, G-C-F-E-G-C-E, was determined to be too complicated for the announcers to 
play correctly on a consistent basis.  It was first simplified to G-C-F-E, and finally to just G-E-C.  This familiar 
sequence was heard for the first time on November 29, 1929.</p><p>

The chimes were sounded at :29:30 and :59:30 of each hour, to indicate the start 
of the 30 second local station break. They were initially struck by hand by the 
announcer, using a set of hand-held chimes held up to the microphone.<span face="Times New Roman">
</span>
<span>
But, there were inconsistencies in the chimes' tempo, volume, and exact timing.&nbsp; </span>
<span face="Times New Roman">&nbsp;I</span>t was finally determined that the 
best way to solve these problems was for the chimes to be generated 
mechanically.</p><center>
<img alt="Chimes Machine Schematic" src="http://www.theradiohistorian.org/chimach.gif" height="480" width="430"><p>&nbsp;<img alt="Chimes Machine" src="http://www.theradiohistorian.org/chimes2b.jpg" height="480" width="640"></p>
<p>&gt;
</p></center>

The man who designed the chimes machine was 
Captain Richard H. Ranger, who was also the inventor of the electronic organ and the RCA facsimile.  
Ranger created a device resembling a music box, where fingers on a revolving drum plucked a set of reeds.  
There were three sets of eight reeds, one for each note, allowing the generation of the fundamental note 
plus several overtones.   Each reed formed one plate of a capacitor in an oscillator circuit, and the signal 
generated by all reeds was amplified by a single 6C6 pentode tube.  It was activated by a timer,
which would cut off the program two seconds before its end (whether it was finished or 
not!) and feed the chimes to the network. <p>

NBC built a limited number of chime machines. NBC in San Francisco  had two of them - the main and backup 
machines.  Others were installed ain other cities around the country where network programs were originated 
– Los Angeles, Chicago, New York, and perhaps a few others.  It is likely that not more than a dozen chimes 
machines were ever made. </p><center>
<img alt="Chimes Machine Inside View" src="http://www.theradiohistorian.org/chimes5b.jpg"><p>&nbsp;<img alt="Chimes Machine Name Tag" src="http://www.theradiohistorian.org/chimes7b.jpg" height="349" width="512"></p>
</center>

The photos on this page show one of the few chime machines still in existence, now in the hands of a private 
collector.  (NBC had the short-sighted habit of discarding large quantities of historical artifacts throughout 
its history.  It's only through the far-sightedness of a few NBC employees, who saved some of these items 
from the trash bins, that we can today experience many recorded programs, photos, and other memorabilia from 
that era.)
<p>

&nbsp;The unit shown is the chimes machine serial number 2, probably from the first group ever made.   Its mechanical 
parts, although finely crafted, appear to have been hand made.  This unit is no doubt the original chimes machine 
placed in operation at NBC's studios at 111 Sutter Street in San Francisco.  The schematic diagram, 
also shown, indicates that serial number 5 was fabricated in 1933, so this machine would have 
predated it.  The main cabinet contains the motor drive reed mechanism and amplifier, which is accessed by  
removing the front panel's four thumbscrews.  The unit operated from an external power source, no doubt the same 
battery and motor generator system that operated the audio amplifiers in the studios.   The smaller box 
contains the timer and switches that operate the chimes for both studio and "NEMO" broadcast lines.  
("NEMO" was a term used in early radio to indicate a remote broadcast.  It comes from a telephone term, 
and stands for "Not Emanating Main Office".)  The chime machine could be operated in an automatic mode by 
the clock, which was the usual method of operation, or manually by the announcer in the event of programs 
with imprecise ending times, such as sports broadcasts. 
</p><center>
<img alt="Chimes Machine Timer" src="http://www.theradiohistorian.org/chimes4b.jpg" height="458" width="640"></center>

&nbsp;<p>The NBC chimes were officially registered with the U.S. Patent Office in 1950 as a registered service mark, the first 
known case of a sound receiving trademark protection.  They were last heard regularly on NBC 
television in 1976, used to mark the 50th anniversary of the network. </p>

<hr>
<div>
  
  <p>Here is a remembrance of the NBC 
  Chimes Machine from Rick Greenhut - February 3, 2013:</p>
  
  <p>
  <span>John,</span></p></div>

<p>
<span>Just saw your 
page on the Bay Area Radio Museum dedicated to the NBC chimes machine, and I 
wanted to give you another historical fact to add. In 1969 when I went to work 
as a summer replacement engineer (board op) at NBC-owned WKYC Cleveland, there 
was still a chimes machine back in the racks. Since all the O&amp;O's originated 
programs like NOTH (New On The Hour) and Monitor inserts, they all had 2 chimes 
machines. Besides WNBC/New York, WMAQ/Chicago and KNBR/San Francisco, 
WKYC/Cleveland and WRC/Washington also had chimes machines.</span></p>

<p>
  <span>By the next 
  summer I worked there, the chimes machine was gone - whether thrown away or 
  taken home by one of the old-timers, I couldn't say.</span></p>

<p>
  <span>Last bit of 
  radio trivia: I was doing Affiliate Relations for the NBC Radio Network in 
  August of 1987, and during the NABET engineers strike those of us in 
  management with technical backgrounds were taking shifts running the board for 
  the NOTH and manning the ROD (Radio Operations Desk) in Radio Central (network 
  master control). I was the first management person on the board when the 
  engineers walked out at 6:00 AM that morning, and engineered the 6, 7, 8 and 9 
  AM NOTH (the talent was Gary Nunn, now heard on the CBS Radio Network). At 
  8:30 that morning I was told by the General Manager, Craig Simon, that the 
  network had been sold to Westwood One, and that the chimes were not part of 
  the sale, so I was forbidden to play them at the end of the newscast like we 
  usually did.</span></p>

<p>
  <span>I ignored 
  him, and "chimed out" at the end of the 9:00 AM newscast as per usual. He came 
  up to the studio a few minutes later with a funny smile on his face, and told 
  me to make sure no one else did that. I made sure by taking the chimes cart 
  and backup out of the studio. I bulked the backup, and have the last remaining 
  cart with the NBC chimes (recorded directly from the WNBC chimes machine) in 
  my collection.</span></p>

<p>
  <span>I was the 
  last person to play the chimes on the NBC Radio Network.</span></p>
<div>
  <div>
    
    <p>
    <span>Rick<span>&nbsp;</span><span>Greenhut</span></span></p>
    <p>
    <span>Director – 
    U.S. Broadcast Sales<br>
    iBiquity Digital Corporation</span></p>
    </div>
</div>
<hr> <p>

<tt><i>REFERENCES:<br>

A History of the NBC Chimes, by Bill Harris<br>
More on the NBC Chimes, by Brian Wickham<br>
A Backstage Visit to Radio City, by Fred Krock<br>
Author's inspection of a chimes machine in the hands of a private collector</i></tt></p><p>


© Copyright 1999 John F. Schneider.  All rights reserved.  
<br></p><hr>
<center>

</center>
</div>]]>
            </description>
            <link>http://www.theradiohistorian.org/chimes.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-24446569</guid>
            <pubDate>Fri, 11 Sep 2020 19:44:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Ballpoint.io]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 10 (<a href="https://news.ycombinator.com/item?id=24446548">thread link</a>) | @artursapek
<br/>
September 11, 2020 | https://ballpoint.io/files/examples/gopher | <a href="https://web.archive.org/web/*/https://ballpoint.io/files/examples/gopher">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://ballpoint.io/files/examples/gopher</link>
            <guid isPermaLink="false">hacker-news-small-sites-24446548</guid>
            <pubDate>Fri, 11 Sep 2020 19:42:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Arbol, a parametric weather risk platform built on IPFS]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24445508">thread link</a>) | @jschilling
<br/>
September 11, 2020 | https://docs.ipfs.io/concepts/case-study-arbol/ | <a href="https://web.archive.org/web/*/https://docs.ipfs.io/concepts/case-study-arbol/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-4f5abb4a=""> <div><p><strong>"When it comes to data security versus ease of access, it's usually a trade-off. The fact that IPFS doesn't compromise on either is awesome — and it feels great to ditch Amazon S3 buckets for open source."</strong></p> <p><em>— Ben Andre, CTO, Arbol</em></p></div> <h2 id="overview"><a href="#overview">#</a> Overview</h2> <p><img src="https://docs.ipfs.io/assets/img/logo-arbol.e1ca2350.svg" alt="Arbol logo" width="220"></p> <p><a href="https://www.arbolmarket.com/" target="_blank" rel="noopener noreferrer">Arbol</a> is a software platform that connects agricultural entities like farmers and other weather-dependent parties with investors and other capital providers to insure and protect against weather-related risks. Arbol's platform sells contracts for parametric weather protection agreements in a marketplace that's an innovative, data-driven approach to risk management, cutting out the usual legacy insurance claims process of making loss assessments on the ground. Instead, Arbol relies on tamper-proof data indexes to determine payouts, and doesn't require a defined loss to be indemnified. Arbol's platform combines parametric weather protection with blockchain-based smart contracts to provide cost-efficient, automated, and user-defined weather-related risk hedging. As with traditional crop insurance and similar legacy products, end users purchase assurance that they'll be financially protected in the case of adverse weather — but with Arbol, these end users are paid automatically if adverse conditions occur, as defined by the contract and measured by local meteorological observations tracked by Arbol's data sources.</p> <p>To build the data indexes that Arbol uses to handle its contracts, the team aggregates and standardizes billions of data files comprising decades of weather information from a wide range of reputable sources — all of which is stored on IPFS. IPFS is critical to Arbol's service model due to the inherent verifiability provided by its <a href="https://docs.ipfs.io/concepts/content-addressing">content-addressed architecture</a>, as well as a decentralized data delivery model that facilitates Arbol's day-to-day aggregation, synchronization, and distribution of massive amounts of data.</p> <p>While United States agribusiness has been Arbol's initial area of focus, the team has built a globally capable platform, with expansion underway to new regions and industries around the world. Arbol currently provides contracts for managing the risks of weather exposure in the energy and agriculture sectors, and features both custom and pre-designed protection agreements for clients across industries and scale. Their current end-user base ranges from small coffee farms to major agribusinesses and power producers.</p> <p>In short, Arbol's platform is a risk marketplace where end users can get competitively priced risk management solutions and capital providers can benefit from access to a lucrative, but underdeveloped, weather risk market. And because Arbol uses IPFS for its data storage and delivery needs, end users and underwriting partners can be certain that the data Arbol uses to determine price and payouts for contracts is tamper-proof and trustworthy.</p> <h3 id="arbol-by-the-numbers"><a href="#arbol-by-the-numbers">#</a> Arbol by the numbers</h3> <div><div><p>1T</p> <p>weather-related data points hosted on IPFS</p></div><div><p>1M</p> <p>hashes generated on Arbol data every day</p></div><div><p>40</p> <p>years of high-resolution climate data</p></div><div><p>200GB</p> <p>average Arbol dataset size</p></div></div> <h2 id="the-story"><a href="#the-story">#</a> The story</h2> <p>Arbol's story begins with the commodities markets, where Siddhartha Jha, the founder and CEO, worked as a quantitative analyst and portfolio manager. What Jha saw there was a problem without a solution: Massive (and growing) demand for weather risk management for supply chains, farming industries, and the energy sector, but no viable, efficient, or cost-effective weather risk market to meet that demand. Traditional crop insurance was plagued by inefficiencies and high cost ceilings, with insurance providers forced to charge high premiums that only large corporations could afford. And while more efficient parametric insurance solutions were available on the market, even these data-driven options were often saddled with high overhead and bureaucratic waste. As a result, small businesses and local farmers were often trapped without access to protection from weather-related risks.</p> <p>Arbol aims to change that by bringing fundamental transparency, efficiency, and data-driven objectivity to the weather risk market, ensuring that any business of any size can get the appropriate protection they need to manage their level of weather-related risk. The Arbol platform achieves this goal by providing a novel mechanism for weather-exposed businesses to connect with capital providers. The key to Arbol's approach is flexible financial derivatives that leverage the power of big data and machine learning to provide parametric risk protection at low cost. These parametric structures determine automatic payouts based on metrics that are strongly correlated with financial loss.</p> <p>With Arbol, an end user pays to hedge against a specific weather-related event, such as yearly deviation in rainfall amounts or temperature. After deciding on a premium and selecting a payout amount, the end user then relies on Arbol's platform to handle the rest. Because parametric structures are objective and data-driven, they can achieve a level of precision, reliability, and cost effectiveness that traditional insurance cannot. In fact, one of Arbol's key benefits over legacy weather insurance is that it allows for hyper-local protection for managing user-specific levels of risk.</p> <p>Arbol's approach also improves upon standard parametric insurance by combining parametric insurance's precision and flexibility with the security, transparency, and efficiency of blockchain. Many of Arbol's protection agreement contracts are executed as smart contracts on the Ethereum blockchain. These smart contracts automatically deliver payouts to end users as soon as a relevant adverse weather event occurs.</p> <p>Delivering weather risk management solutions through blockchain-based contracts like this eliminates costly payout delays, as well as risks associated with fraud, corruption, and bureaucratic overhead. It also brings the benefits of peer-to-peer decentralization: Arbol users don't need to rely on Arbol as a financial middleman, because funds are locked between end users and capital providers without Arbol controlling the transfer of funds.</p> <p>However, even the best smart contract is only as smart as the data it draws from. The "oracle problem" can be a foundational obstacle for smart contracts — but Arbol's use of IPFS eliminates this risk. Because a smart contract automatically and trustlessly executes based on data, it doesn't matter how secure, transparent, and publicly verifiable its use of blockchain is. Without an accurate, trustworth, and immutable data "oracle", even blockchain-based smart contracts can be easily biased, compromised, or manipulated. For Arbol, that's where IPFS is absolutely critical.</p> <p>IPFS's content-addressed architecture enables Arbol to ensure the integrity and public verifiability of its datasets, something that traditional location addressing using centralized server architecture cannot provide. Smart contracts pointing to specific, immutable IPFS CIDs, rather than to data locations that could be tampered with, can be relied upon thanks to the integrity of their oracle.</p> <div><p><strong>"IPFS is very much at the heart of everything we do at Arbol. IPFS serves as our independently verifiable data store for all of the weather data associated with the contracts we sell. It imbues our platform with the essential principles of decentralization, data security, and public verifiability."</strong></p> <p><em>— Ben Andre, CTO, Arbol</em></p></div> <p>Arbol builds its data indexes by drawing on large weather-related datasets from a variety of trusted public and private sources, including prominent U.S. government institutions such as NASA and the National Oceanic and Atmospheric Administration (NOAA). These sources track weather data including yearly rainfall amounts, temperature fluctuations, wind speeds, and more. However, while much of the data Arbol uses is publicly available, it isn't always easily usable; much of the data, particularly deeper historical records, is stored in outdated formats, and very little of it is organized into an easily readable structure. Arbol's data indexes process, correlate, and package this data so that it is readily available for use in the weather risk market. And by putting that data onto IPFS, Arbol also ensures that it has a verifiable, tamper-resistant, and decentralized home.</p> <h2 id="ipfs-benefits"><a href="#ipfs-benefits">#</a> IPFS benefits</h2> <p>Arbol's business model hinges upon the benefits afforded by IPFS — without its immutable content addressing and inherent data verifiability, the benefits Arbol provides would be impossible to achieve in a cost-effective and efficient way. As a whole, IPFS is critical to Arbol's service model by providing the following:</p> <ul><li><p><strong>Immutable addressing:</strong> Because all data stored using IPFS is referenced and accessed via unique <a href="https://docs.ipfs.io/concepts/content-addressing">content identifiers (CIDs)</a>, any change to a data item means it receives a new CID exclusive to that revision. It's impossible to change data without changing its CID.</p></li> <li><p><strong>Data verifiability:</strong> Contracts on Arbol's platform are linked to specific, verifiably unchanged, content-addressed data. Because parametric weather risk management absolutely relies on user agreement about and trust in source data, Arbol's approach offers reassurance unavailable with other offerings in the market.</p></li> <li><p><strong>Decentralized data delivery:</strong> Arbol works with massive datasets comprising billions of files and terabytes of information. IPFS accommodates Arbol's methodology for publishing and adding to large datasets while still enabling Arbol to release and synchronize these datasets via a decentralized storage network.</p></li></ul> <h2 id="how-arbol-uses-ipfs"><a href="#how-arbol-uses-ipfs">#</a> How Arbol uses IPFS</h2> <p>Arbol's end users enjoy the "it just works" benefits of parametric protection, but a lot goes on behind the scenes to enable this data-driven solution. Arbol's weather datasets range from 1GB to 1TB in size, and each one goes through a detailed ingestion process before it can be used. Once it has been decided that a dataset meets Arbol's criteria for usefulness and validity, it is time to add it to Arbol's IPFS pipeline, a multi-stage process outlined below.</p> <ol><li><p><strong>Query/release:</strong> If a …</p></li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://docs.ipfs.io/concepts/case-study-arbol/">https://docs.ipfs.io/concepts/case-study-arbol/</a></em></p>]]>
            </description>
            <link>https://docs.ipfs.io/concepts/case-study-arbol/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24445508</guid>
            <pubDate>Fri, 11 Sep 2020 18:03:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Security by obscurity is underrated]]>
            </title>
            <description>
<![CDATA[
Score 908 | Comments 505 (<a href="https://news.ycombinator.com/item?id=24444497">thread link</a>) | @pcr910303
<br/>
September 11, 2020 | https://utkusen.com/blog/security-by-obscurity-is-underrated.html | <a href="https://web.archive.org/web/*/https://utkusen.com/blog/security-by-obscurity-is-underrated.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>
08 September 2020
</p>
<p>In the information security field, we have developed lots of thoughts that can’t be discussed (or rarely discussed):</p>
<ul>
<li>
<p>Never roll your own crypto</p>
</li>
<li>
<p>Always use TLS</p>
</li>
<li>
<p>Security by obscurity is bad</p>
</li>
</ul>
<p>And goes like this. Most of them are very generally correct. However, I started to think that people are telling those because everyone is telling them. And, most of the people are actually not thinking about exceptional cases. In this post, I will raise my objection against the idea of “Security by obscurity is bad”.</p>
<h2 id="risk-defense-in-depth-and-swiss-cheese">Risk, Defense in Depth and Swiss Cheese</h2>
<p>One of the main goal of defensive security is reducing the risk for the target business. According to the OWASP’s methodology, the risk of an issue is calculated with the formula below:</p>
<p><code>Risk = Likelihood * Impact</code></p>

<p>According to this formula, a Remote Code Execution issue poses more risk than a Cross Site Scripting one since the RCE causes more impact. This is easy. But what about the likelihood metric. According to the OWASP, likelihood refers that:</p>
<div><div><pre><code>At the highest level, this is a rough measure of how likely this particular vulnerability is to be uncovered and exploited by an attacker
</code></pre></div></div>
<p>So, if we can reduce the likelihood, we can reduce the overall risk. That’s good. It’s actually very similar to a very common idea called “Defense in Depth”. It’s also referred as “Swiss Cheese Model”</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/0/07/Swiss_cheese_model.svg" alt="Swiss Cheese"></p>
<p>According to this model, you need to build your defense mechanisms in a layered model so that even the attackers pass the first one, they will get caught on the others.</p>
<h2 id="security-by-obscurity">Security by Obscurity</h2>
<p>So let’s talk about security by obscurity. It’s a bad idea to use it as a single layer of defense. If the attacker passes it, there is nothing else to protect you. But it’s actually would be good to use it as an “additional” layer of defense. Because it has a low implementation cost and it usually works well.</p>
<p>Let’s think about a couple of scenarios here:</p>
<ul>
<li>I have a server that runs the SSH with it’s default port <code>22</code> and my credentials are: <code>root:123456</code>. What is the likelihood of being compromised?</li>
</ul>
<p>It’s almost 100% since the hackers are conducting brute force attacks to the services with common credentials globally.</p>
<ul>
<li>SSH runs in port <code>22</code> and my credentials are <code>utku:123456</code>. What is the likelihood of being compromised?</li>
</ul>
<p>Well, we have eliminated the global brute forcers since we are not using a common username. The likelihood and risk are reduced. However, we still have to deal with targeted attackers. A targeted attacker can guess the username as <code>utku</code> since it’s my name.</p>
<ul>
<li>SSH runs in port <code>64323</code> and my credentials are <code>utku:123456</code>. What is the likelihood of being compromised?</li>
</ul>
<p>Now we changed the default port number. Does it help? Firstly, we’ve eliminated the global brute forcers again since they scan only the common ports. What about the others? To find this out, I did a small survey on my Twitter to find out people’s port scan behaviors.</p>
<blockquote><div lang="en" dir="ltr"><p>I'm trying to prove a point for my new article. I need your answers for the question below. (please be honest)</p><p>-When you do a port scan with nmap to find open ports on the target, are you specify a custom port range to scan all 65,535 ports? (with -p0-65535 parameter)</p></div>— Utku Şen (@utkusen) <a href="https://twitter.com/utkusen/status/1303021175556145154?ref_src=twsrc%5Etfw">September 7, 2020</a></blockquote>

<p>As you can see here, lots of people tend to scan the default/most popular ports only. So, if you switch your port from 22 to 64323, you will eliminate some of them. You will reduce the likelihood and risk.</p>
<p>The same thing goes for software vulnerabilities as well. If a vulnerability found in the Microsoft Remote Desktop Protocol, everybody will scan for the port 3389 globally. You can reduce your risk just by changing the default port.</p>
<h2 id="other-applications">Other Applications</h2>
<p>Of course, it’s possible to use the same methodology in other fields other than changing the defaults. For example, the following ideas might be a good idea for some specific cases (not always)</p>
<ul>
<li>
<p><strong>Obfuscating codes:</strong> Of course, it’s common knowledge. Hackers are people too. If you obfuscate your code well, they will need to spend more time to find issues. They may give up eventually.</p>
</li>
<li>
<p><strong>Using random variable names for a web application:</strong> Instead of using clear variable names, you can switch them with random strings. It might help just like the code obfuscation.</p>
</li>
<li>
<p><strong>Using Symmetric Encryption in the Database:</strong> When you write data to the database, use a function like <code>encryption_algorithm(data,key)</code>. Likewise, when you read data, use a function like <code>decryption_algorithm(data,key)</code>. If the attacker can read your backend code, obviously he/she can decrypt your database. But if there is an issue that allows an attacker to read data from the database, but not the backend code (like SQL Injection), the gathered data won’t be helpful for the attacker.</p>
</li>
</ul>
<h2 id="real-life-applications">Real Life Applications</h2>
<p>Security by obscurity is widely used in physical/real-life security. For example, the president goes from point A to point B with his 30 cars convoy. But he’s not sitting on his own presidential car so that the attacker won’t target him easily. He can be in any car and it reduces the risk of an attack.</p>
<p><img src="https://i.dailymail.co.uk/1s/2019/06/04/00/14330600-0-image-a-38_1559605545988.jpg" alt="President"></p>
<p>Camouflaged animals are using security by obscurity as well. Obscurity reduces the likelihood of being killed. Therefore, they gained this ability in the evolutionary process.</p>
<p><img src="https://static.boredpanda.com/blog/wp-content/uuuploads/animal-camouflage/animal-camouflage-4.jpg" alt="Animal"></p>
<h2 id="conclusion">Conclusion</h2>
<p>Security by obscurity is not enough by itself. You should always enforce the best practices. However, if you can reduce the risk with zero cost, you should do that. Obscurity is a good layer of security.</p>


</div></div>]]>
            </description>
            <link>https://utkusen.com/blog/security-by-obscurity-is-underrated.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24444497</guid>
            <pubDate>Fri, 11 Sep 2020 16:34:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How do you reason about a probabilistic distributed system?]]>
            </title>
            <description>
<![CDATA[
Score 110 | Comments 15 (<a href="https://news.ycombinator.com/item?id=24444276">thread link</a>) | @ahelwer
<br/>
September 11, 2020 | https://ahelwer.ca/post/2020-04-15-probabilistic-distsys/ | <a href="https://web.archive.org/web/*/https://ahelwer.ca/post/2020-04-15-probabilistic-distsys/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>
    <div>
      <article role="main">
        <h2 id="in-which-i-am-stunted-upon-by-coin-flips">In which I am stunted upon by coin flips</h2>
<p>Wasn’t too long ago that I felt pretty good about my knowledge of distributed systems.
All someone <em>really</em> needed in order to understand them, I thought, was a <a href="https://www.youtube.com/watch?v=JEpsBg0AO6o">thorough understanding of the paxos protocol</a> and a willingless to reshape your brain in the image of TLA+.
Maybe add a dash of conflict-free-replicated datatypes, just so you know what “eventual consistency” means.
Past that it’s just some optimizations and mashups which come easily to your TLA+-addled brain.</p>
<p>This belief proved surprisingly robust over a number of years, even surviving an aborted attempt at analyzing the <a href="https://github.com/ahelwer/tla-experiments/blob/master/Nano.tla">Nano cryptocurrency</a>.
It was only after encountering <a href="https://muratbuffalo.blogspot.com/2018/06/snowflake-to-avalanche-novel-metastable.html">the snowflake family of consensus protocols</a> that I realized my theory just wasn’t up to the challenge.
The issue was <em>probability</em>: snowflake protocols reach consensus by iteratively polling sets of other nodes at random, and the argument that consensus is eventually reached is a statistical argument deriving an upper bound on the probability of failure.</p>
<p>I didn’t <em>dislike</em> probability &amp; statistics, I just tried to keep my distance as much as possible.
All the algorithms in distributed systems I’d encountered so far involved <em>nondeterminism</em>, sure, but not probability.
I’d assumed nondeterminism was just a more flexible way of reasoning about probability.
This idea of mine would prove to be a source of great unnecessary confusion as I learned the art of reasoning about probabilistic distributed systems, so I’ll do you a favor and give you the core lesson of this entire post in one sentence:</p>
<p><strong>You cannot model probability with nondeterminism, and you cannot model nondeterminism with probability.</strong></p>
<h2 id="models-theyre-good-folks">Models: they’re good, folks!</h2>
<p>Have you ever been writing some multithreaded code, happily plugging in a mutex here, a semaphore there, or even just using some nice message-passing primitives to make your threads all get along?
Maybe you’ll be familiar, then, with what often comes next.
A scratch at the back of your mind, a thought - <em>“oh, wait…"</em> - as you realize something weird will happen if thread \(A\) manages to reach some step before thread \(B\) has finished its assigned task.
No worries! Slap on another WaitHandle, problem solved.
Except the problem wasn’t solved. Not really.
You consider it a bit more - what if thread \(C\) comes in with a message at this inopportune time?
You realize with dawning horror you’re actually tracing cracks in the foundation.
Patch them with mutexes! Semaphores! Anything!
Alas, you are beyond help. It’s around this time that your brain, catching a glimpse of the infinite plane of combinatorial state explosion, wisely ducks its head back down for the day and leaves you with a woozy, fuzzy, clenching feeling for having the gall to ask it to fix all this.</p>
<p>I’ve felt like this many times, and formal models are the only cure I’ve ever found.
Your brain isn’t built to hold massive state spaces in its working memory, so don’t even try.
Let a model checking program churn through all those states to find the bugs.
At this point I won’t even touch a multithreaded program or distributed system without whipping up a quick TLA+ spec of its desired workings.
I just specify all the possible events in the system, how those events affect the system state, what things I always want to remain true (the invariants), then let the model checker rip.
In TLA+, we model concurrency with nondeterminism; in a concurrent system, we have no idea whether thread \(A\) will execute a step before thread \(B\).
We can represent this with a nondeterministic state machine as follows:</p>
<figure>
    <img src="https://ahelwer.ca/img/probabilistic-distsys/nondeterministic.svg" width="10000"> 
</figure>

<p>So you’ll be in state \(s_3\) if thread \(A\) executes its step before thread \(B\), and state \(s_4\) if thread \(B\) executes its step before thread \(A\).
Maybe \(s_3\) and \(s_4\) are even the same state, who knows.
The model checker will explore both of these possible execution orders, and <strong>in a well-designed concurrent system we should <em>never</em> end up in a bad state just because of a certain order of execution</strong>.</p>
<p>Readers might wonder how exactly this models concurrency, where steps can happen uh, concurrently.
The short answer is you have to ensure all the steps in your model are atomic or independent: either impossible in the real world for two of your steps to happen at the exact same time (for example, by assuming use of a lower-level hardware synchronization primitive) or impossible for execution of one step to directly affect the same variables as another step (for example, if the steps are executed on different computers within a timespan less than the network latency between them).
If the steps in your model satisfy this requirement, checking all possible execution orders accurately models concurrency.
If they don’t, you need to break the steps down further so they do.
This model nicely captures &amp; exposes all that is difficult about concurrency.</p>
<p>What questions can we ask about this sort of model?
The most important questions are <em>reachability queries</em> - can we reach a <em>bad state</em> (two caches disagreeing on a value, deadlock, dogs &amp; cats living together, etc.) from the starting state?
These questions are called <em>safety properties</em>, and if they are answered in the negative then the system is safe.
Another type of query is something like “are we always guaranteed to eventually end up in a good state?”
These are called <em>liveness properties</em>.
Turns out these two types of questions can get you pretty far in concurrent &amp; distributed systems.
Definitely far enough to make a whole career out of writing rock-solid software in places others would falter.
However, these questions also have a drawback: their answers are absolute.
True or false.
No probability involved, no room for nuance.</p>
<p>What if one of the threads flips a coin, and if it’s heads it does one thing, tails another?
Entire state spaces, bifurcated by a probabilistic event.
Maybe those state spaces contain further coin flips, or other types of randomness.
In this system your questions might change from the form “is it possible to reach a bad state” to “what is the probability of reaching a bad state?”
Unfortunately these types of questions just cannot be answered within the nondeterministic model used above.
<strong>You cannot model probability with nondeterminism.</strong>
We must use a new type of model, a state machine that handles probability directly.</p>
<h2 id="leaving-the-beautiful-pure-discrete-realm">Leaving the beautiful pure discrete realm</h2>
<p>TLA+ can’t handle probability at this time, so we’d have to use a specialized modeling language like <a href="http://www.prismmodelchecker.org/">PRISM</a> which handles probabilistic state machines.
Let’s look at the standard hello-world example for probabilistic state machines: the <a href="http://www.prismmodelchecker.org/bibitem.php?key=KY76">1976 Knuth-Yao method</a> for simulating a fair six-sided die with a series of coin flips.
This is really quite a neat problem and I encourage you to ponder it for a second before seeing how they did it!
Any sequence of \(n\) coin flips will give you an event which has probability \(\frac{1}{2^n}\) of occurring.
Simulating a fair six-sided die requires generating an event with probability \(\frac{1}{6}\) of occurring.
You might then reason this problem is impossible, because you cannot evenly divide \(2^n\) by \(6\) for any \(n\) (this follows from the uniqueness of prime factorization).
Indeed, there is no way to simulate a six-sided die with a finite number of coin flips.
We have to use an algorithm which is not guaranteed to ever terminate, although vanishingly unlikely not to do so.
Here it is:</p>
<figure>
    <img src="https://ahelwer.ca/img/probabilistic-distsys/knuth-yao.svg" width="10000"> 
</figure>

<p>You can see that if you somehow only flip heads, or only flip tails, you’ll never reach one of the accepting states (here labeled with the die number they represent).
There are some fun ways to contextualize the probabilities of you only flipping heads or tails a certain number of times in a row.
For example, there are only <a href="https://www.popularmechanics.com/space/a27259/how-many-particles-are-in-the-entire-universe/">around \(2^{268}\) subatomic particles in the observable universe</a>; if you manage to flip heads 268 times in a row, that’s the same as picking the correct subatomic particle out of a universe-wide random draw.
Maybe go look at the <a href="https://en.wikipedia.org/wiki/Hubble_Ultra-Deep_Field">Hubble Ultra-Deep Field</a> as you ponder this probability.
Another way is assuming you’re between the ages of 25-34 and live in the USA, your annual all-cause mortality rate is <a href="https://www.cdc.gov/nchs/products/databriefs/db355.htm">about 129/100,000</a>.
Assuming deaths are uniformly distributed throughout the year, this means your chances of dying today are about 1 in 283,000.
This is just 18 all-heads or all-tails coin flips in a row.
What I’m saying is that you really, really shouldn’t worry about having to flip the coin very many times.</p>
<p>This probabilistic state machine model we’ve created is called a <em>Discrete-Time Markov Chain</em>, or DTMC.
In DTMCs, every transition has an associated probability and the probabilities of all out-flowing transitions must sum to one for every state (accepting states can be thought to have a loopback with probability 1).
The above rumination on termination probabilities is summed up in <em>the long run theorem</em>: in the long run, every path in a finite Markov chain ends in an absorbing state, which is a state (or group of states) from which there is an entrance but no exit.
What questions can we ask of DTMCs?
The most interesting one - the reason why we’re here - is “what is the probability of eventually reaching a certain state?”
The long run theorem tells us we have a 100% chance of eventually reaching <em>one</em> of the Knuth-Yao state machine’s accepting states.
What about the probability of ending up in a specific accepting state?
It should be \(\frac{1}{6}\). Is it?</p>
<p>Let’s try to reason this out with basic probability.
What are the chances of ending up in accepting state \(1\)?
Well, you can get there by flipping \(HHT\).
The probability of that happening is \(\frac{1}{2} \cdot \frac{1}{2} \cdot \frac{1}{2} = \frac{1}{8} \).
But you can also get there by flipping \(HHHHT\).
The probability of <em>that</em> happening is \(\frac{1}{2^5} = \frac{1}{32} \).
We have to add this to the first probability, so now our probability is \(\frac{1}{8} + \frac{1}{32} = \frac{5}{32}\).
But we can <em>also</em> get there …</p></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ahelwer.ca/post/2020-04-15-probabilistic-distsys/">https://ahelwer.ca/post/2020-04-15-probabilistic-distsys/</a></em></p>]]>
            </description>
            <link>https://ahelwer.ca/post/2020-04-15-probabilistic-distsys/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24444276</guid>
            <pubDate>Fri, 11 Sep 2020 16:10:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scaling Erlang Developer Experience at WhatsApp [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 301 | Comments 93 (<a href="https://news.ycombinator.com/item?id=24443128">thread link</a>) | @anuragsoni
<br/>
September 11, 2020 | https://codesync.global/uploads/media/activity_slides/0001/03/f2292f201aa6b04db8c4e0b9cfa191dd07c9ee14.pdf | <a href="https://web.archive.org/web/*/https://codesync.global/uploads/media/activity_slides/0001/03/f2292f201aa6b04db8c4e0b9cfa191dd07c9ee14.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://codesync.global/uploads/media/activity_slides/0001/03/f2292f201aa6b04db8c4e0b9cfa191dd07c9ee14.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24443128</guid>
            <pubDate>Fri, 11 Sep 2020 14:20:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The lack of namespaces on crates.io is a feature]]>
            </title>
            <description>
<![CDATA[
Score 108 | Comments 181 (<a href="https://news.ycombinator.com/item?id=24442731">thread link</a>) | @LinuxBender
<br/>
September 11, 2020 | https://samsieber.tech/posts/2020/09/registry-structure-influence/ | <a href="https://web.archive.org/web/*/https://samsieber.tech/posts/2020/09/registry-structure-influence/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Rust doesn’t have namespaces in its package management system. It’s often viewed as a bug. But it’s not a bug, it’s a feature! While there are negative aspects of a flat package registry, there are also real benefits. Stability, continuity, and unity (discourages forks and fragmented identity). Proposals that seek to add namespacing without addressing the positive aspects they remove probably won’t be accepted.</p><p>I have noticed the benefits of the current system seem to only get mentioned in passing as objections to proposals and never outlined anywhere. This is an attempt to fix that by summarizing points raised across the various proposals I’ve read. While I don’t represent the crates.io team (I’m not even on the team) I hope to accurately represent trade-offs being considered.</p><h2 id="aspects-of-registry-structure">Aspects of Registry Structure</h2><p>How identity works in package management has far-reaching consequences. Most of the namespace proposals I’ve seen have been motivated by trying to address squatting and/or tweaking the current system of package identity. However, the structure of the crates.io registry affects more than just those areas. But we’ll start with the basics of identity and work from there.</p><h3 id="identity">Identity</h3><p>How do you refer to a package? A crate has at least three identities I can think of:</p><ul><li>The name on crates.io - there is exactly one crate per name</li><li>The name used in Cargo.toml - there is exactly one crate per name</li><li>The default name used in code - there is can be more than one per name, which is rare in practice</li><li>The actual name used in code - this can be controlled through Cargo.toml or externs statements, but renaming isn’t required</li></ul><p>The first two are called the <code>package.name</code> in Cargo.toml of the crate being published. The third can be overridden via <code>lib.name</code> in the package being published. The last is user-controlled. Usually, all of these names match, with the caveat that dashes are underscores in code (and crates.io doesn’t allow two crates with identical crates.io names after normalizing dashes to underscores).</p><p>Arguably, self-explanatory identities have a leg up on other identities from a discoverability perspective. E.g. <code>argparse</code> probably seems more reputable at first glance than <code>clap</code> if you’re going of name alone.</p><p>A flat registry makes identity management (naming a crate) harder. You either have to pick a GUID (haha, please don’t) or some memorable (but probably mostly or completely unrelated) identity. I see this as the main driving force for proposals seeking to add namespaces or otherwise address squatting.</p><h3 id="continuity">Continuity</h3><p>Currently, identity is continuous - a crate’s identity is immutable and that has real benefits. If you want to change the identity system at all you’ve got to ensure that identities don’t change out from under you. This is a strike against any namespace system that allows namespace ownership to unexpectedly change. Discontinuous identity has a couple of issues.</p><p>First, if a crate’s name can change, that’s bad for users. They have to go figure out the new name of the package if they want to update.</p><p>Second, if an identity’s crate can change (a consequence of the previous point if identities are reusable), then you’ve introduced a security vulnerability. Updating to a new package version with different content under different ownership is a real security risk. Doubly so if you don’t ban new minor versions on the last major version after an unintentional ownership change. Should people audit their crate? Yes! But the fewer foot-guns we have the better.</p><p>In addition to preventing security issues, proposals need to encourage transitions over transactions. Gradual moves over all-or-nothing moves. This could be seen more as compatibility than continuity. This drives things like the rust editions and the need for namespace proposals to be backward compatible.</p><h3 id="stability">Stability</h3><p>A core tenet of Rust is stability. The obvious definition is that things that compile yesterday should compile today (even with a new compiler).</p><p>A less obvious definition is that adding new dependencies shouldn’t stop you from compiling already working code. This is a major motivation for the orphan rule (though the orphan rule is more nuanced than that). This is a strike against schemes that encourage multiple distinct crates to have the same default name in code. I don’t think any proposal that encourages this could be approved. It also suggests that we ought to ban new instances of a crates default code name deviating from its package/Cargo.toml name.</p><p>In addition to code stability, crates.io should be stable too. It should be able to isolate itself from outside services. It currently depends on Github, but it doesn’t have to. This is a strike against any system that weds namespace identity to any externally managed system.</p><h3 id="squatting">Squatting</h3><p>The current identity system encourages squatting. I would define squatting as reserving a crate without actually using it. This is a natural outcome in the Rust ecosystem for a couple of reasons:</p><ul><li>Crates are easy to publish, so it’s easy to reserve a crate by publishing an empty crate</li><li>We have de-facto namespaces using prefixes - <code>serde-*</code> is one example.</li><li>There can only ever be one version of a package name. There is only one <code>http</code> crate for example. So package names are a scarce resource.</li></ul><p>There’s a lot of squatting on crates.io. I don’t have any hard numbers though.</p><p>We don’t have any structured support for squatting either, which makes it hard to separate bad actors from good actors. I think separating them out would require manual intervention, and the crates.io team is small and doesn’t have a lot of time to put towards that.</p><p>So what’s a bad actor? I consider someone who squats a bunch of crates to make or point or prevent their names from being used to be a bad actor. Crates.io has a policy against using automation to claim ownership of crates, but I haven’t heard much about it being enforced. Again, time is an issue. And this would probably extend to namespace ownership as well.</p><p>I do think there are legitimate uses. Reserving a set of extension crates for a project you’re working on is one example. My other example is reserving a crate you genuinely intend to work on (this one is a little more debatable).</p><h2 id="it-s-about-the-trade-offs">It’s about the Trade-offs</h2><p>With this system in mind, it’s hard to come up with a namespace proposal that doesn’t hurt the current system in some way.</p><p>I’d say the biggest tension is in code-level identities. They become either overlapping by chopping the namespace portion off or much longer by including the namespace portion. The previous points show why overlapping is generally considered a non-starter. And for longer identities, you need to come up with some new way to reference namespaces in code that’s doesn’t break things.</p><p>More to the point though, from what I’ve seen, most people proposing identity schemes propose it so that the ecosystem can support the overlapping crate identities (e.g. multiple http crates). And that’s exactly what the current system avoids doing.</p><p>Here’s <a href="https://github.com/rust-lang/rfcs/pull/2978#issuecomment-686823633">an on-point quote from CAD97</a> summing up (hopefully fairly accurately) what namespaces mean to the parties involved:</p><blockquote><p>To the crates team, it seems to <em>primarily</em> mean that a project can put multiple packages together under an umbrella, such that you know the packages are for-sure by the project.</p><p>To the people who feel most slighted by the crates team’s approach here, namespaces <em>primarily</em> mean the ability to publish a crate with a desired name even if there’s already a package published that provides a crate with that name, by putting the package into a different namespace such that the names do not clash.</p><p>If the latter party asks about “namespaces” and means the latter, and the team answers and means the former, you can see where the miscommunication enters, especially since the crates team has now communicated here the position that <em>generally</em>, the <code>package.name == lib.name</code> falsehood should not be made more false; i.e., the latter group’s goal is an explicitly non-desired property from the crates team.</p></blockquote><h2 id="where-to-now">Where to Now?</h2><p>There have been other proposals for namespaces that are less about overlapping identity and more about curation and grouping related crates together. There are multiple proposals there, each with their trade-offs. Expect a follow-up post discussing some of those.</p><h2 id="appendix-a-highlights">Appendix A: Highlights</h2><p>There’s a nice set of a dozen or so comments I save as I reviewed past discussions:</p><p>Carol10Cents (of the crates.io team):</p><ul><li><a href="https://users.rust-lang.org/t/cargo-problems-namespacing/2085/11">https://users.rust-lang.org/t/cargo-problems-namespacing/2085/11</a></li><li><a href="https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/20">https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/20</a></li></ul><p>kornel:</p><ul><li><a href="https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/26">https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/26</a></li></ul><p>sgrif (on the crates.io team):</p><ul><li><a href="https://internals.rust-lang.org/t/namespacing-on-crates-io/8571/39">https://internals.rust-lang.org/t/namespacing-on-crates-io/8571/39</a></li><li><a href="https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/5">https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/5</a></li><li><a href="https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/7">https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/7</a></li></ul><p>CAD97:</p><ul><li><a href="https://internals.rust-lang.org/t/namespacing-on-crates-io/8571/57">https://internals.rust-lang.org/t/namespacing-on-crates-io/8571/57</a></li><li><a href="https://github.com/rust-lang/rfcs/pull/2978#issuecomment-686823633">https://github.com/rust-lang/rfcs/pull/2978#issuecomment-686823633</a></li></ul><p>withoutboats (on the crates.io team):</p><ul><li><a href="https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/10">https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/10</a></li></ul><p>ag_dubs (on the crates.io team):</p><ul><li><a href="https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/27">https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/27</a></li><li><a href="https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/28">https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628/28</a></li></ul><p>pietroalbini (on the crates.io team):</p><ul><li><a href="https://github.com/rust-lang/rfcs/pull/2978#issuecomment-683424791">https://github.com/rust-lang/rfcs/pull/2978#issuecomment-683424791</a></li></ul><p>Random meeting notes:</p><ul><li><a href="https://paper.dropbox.com/doc/All-hands-Crate-grouping-Namespacing-discussion-NEpWAaDdNuUheLpawETYT">https://paper.dropbox.com/doc/All-hands-Crate-grouping-Namespacing-discussion-NEpWAaDdNuUheLpawETYT</a></li></ul><h2 id="appendix-b-previous-discussions">Appendix B: Previous Discussions</h2><p>There have been several attempts at this:</p><ul><li><a href="https://internals.rust-lang.org/t/namespacing-on-crates-io/8571">https://internals.rust-lang.org/t/namespacing-on-crates-io/8571</a></li><li><a href="https://internals.rust-lang.org/t/pre-rfc-domains-as-namespaces/8688">https://internals.rust-lang.org/t/pre-rfc-domains-as-namespaces/8688</a></li><li><a href="https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628">https://internals.rust-lang.org/t/pre-rfc-packages-as-namespaces/8628</a></li><li><a href="https://internals.rust-lang.org/t/scoped-packages-like-in-npm/10223/3">https://internals.rust-lang.org/t/scoped-packages-like-in-npm/10223/3</a></li><li><a href="https://internals.rust-lang.org/t/pre-rfc-idea-cratespaces-crates-as-namespace-take-2-or-3/11320">https://internals.rust-lang.org/t/pre-rfc-idea-cratespaces-crates-as-namespace-take-2-or-3/11320</a> (This was mine from last year after reading through the other proposals; my …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://samsieber.tech/posts/2020/09/registry-structure-influence/">https://samsieber.tech/posts/2020/09/registry-structure-influence/</a></em></p>]]>
            </description>
            <link>https://samsieber.tech/posts/2020/09/registry-structure-influence/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24442731</guid>
            <pubDate>Fri, 11 Sep 2020 13:46:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Octo – Generate a serverless API from an SQL query]]>
            </title>
            <description>
<![CDATA[
Score 233 | Comments 58 (<a href="https://news.ycombinator.com/item?id=24442294">thread link</a>) | @khalidlafi
<br/>
September 11, 2020 | https://octoproject.github.io/octo-cli/ | <a href="https://web.archive.org/web/*/https://octoproject.github.io/octo-cli/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <a href="" title=" ">
    <img src="https://octoproject.github.io/octo-cli/assets/cover.png" alt=" ">
  </a>
  <br>
  <h4>Expose data from any database as web service.</h4>
  <p>
    Octo CLI makes the data available from any database as a web service on-demand, 
    simplifying the process of building data-driven applications.
     It can reduce costs, improve accessibility and performance.
  </p>
 

 <p><a href="" title=" ">
    <img src="https://user-images.githubusercontent.com/20528562/92949687-2b627080-f464-11ea-99e8-d3afad80922c.png" alt=" ">
  </a>
  </p>
     <div>
    <p><a href="https://github.com/octoproject/octo-cli" title="Documentation" onmousedown="ga('send', 'event', 'download', 'click', 'zip')">View on Github</a>
    <a href="https://github.com/octoproject/octo-cli#examples" title="View on GitHub" onmousedown="ga('send', 'event', 'download', 'click', 'zip')">Get started</a>
  </p></div>
</div></div>]]>
            </description>
            <link>https://octoproject.github.io/octo-cli/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24442294</guid>
            <pubDate>Fri, 11 Sep 2020 13:02:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to stream audio from your phone to your laptop with PulseAudio]]>
            </title>
            <description>
<![CDATA[
Score 203 | Comments 117 (<a href="https://news.ycombinator.com/item?id=24441112">thread link</a>) | @manjana
<br/>
September 11, 2020 | https://bash-prompt.net/guides/pulse-audio-bluetooth-streaming/ | <a href="https://web.archive.org/web/*/https://bash-prompt.net/guides/pulse-audio-bluetooth-streaming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<p>These days your primary means of listening to music if likely from an app on your phone. So how do you get the music from your phone to your laptop or desktop that has better speakers?</p>
<p>The answer is to use Bluetooth and <a href="https://www.freedesktop.org/wiki/Software/PulseAudio/">PulseAudio</a>. PulseAudio is the modern sound implementation on the Linux desktop. It runs as a sound server and takes sound inputs such a microphone or your browser playing a YouTube video and directs this sound to outputs such as your Laptop’s speakers.</p>
<p>PulseAudio can take the audio from a Bluetooth connection and route it to your laptop’s speakers and is very simple to get running.</p>
<p>First, install the PulseAudio Bluetooth modules. On ArchLinux this is called <code>pulseaudio-bluetooth</code> and on Ubuntu/Debian it is called <code>pulseaudio-module-bluetooth</code>.</p>
<p>After you have installed this package open the following file:</p>
<pre><code>/etc/pulse/system.pa
</code></pre><p>And add the following couple of lines:</p>
<pre><code>load-module module-bluetooth-policy
load-module module-bluetooth-discover
</code></pre><p>Then, as your regular user, restart PulseAudio:</p>
<pre><code>$ pulseaudio -k
$ pulseaudio --start
</code></pre><p>And you’re all set!</p>
<p>All you need to do is to pair your phone and your computer and start playing something on your phone and it will play through your computer’s speakers.</p>

		</div></div>]]>
            </description>
            <link>https://bash-prompt.net/guides/pulse-audio-bluetooth-streaming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24441112</guid>
            <pubDate>Fri, 11 Sep 2020 10:26:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Checked exceptions: Java’s biggest mistake (2014)]]>
            </title>
            <description>
<![CDATA[
Score 112 | Comments 306 (<a href="https://news.ycombinator.com/item?id=24440536">thread link</a>) | @flying_sheep
<br/>
September 11, 2020 | http://literatejava.com/exceptions/checked-exceptions-javas-biggest-mistake/ | <a href="https://web.archive.org/web/*/http://literatejava.com/exceptions/checked-exceptions-javas-biggest-mistake/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-174">
	
	<!-- .entry-header -->

		<div>
		<p>Checked exceptions have always been a controversial feature of the Java language.</p>
<p>Advocates claim they ensure checking &amp; recovery from failures. Detractors say “catch” blocks can almost never recover from an exception, and are a frequent source of mistakes.</p>
<p>Meanwhile, Java 8 and lambdas are here. Are checked exceptions becoming obsolete in the Java world?<span id="more-174"></span></p>
<h3>The Intent of Checked Exceptions</h3>
<p>In the mid 90’s, James Gosling at Sun came up with a new language.</p>
<p>At the time, C++ programming required every single function return to be checked for error. He decided there had to be a better way, and built the concept of “exceptions” into Java.</p>
<p>The intent of <strong>checked exceptions</strong> was to locally flag, and force developers to handle, possible exceptions. Checked exceptions have to be declared on a method signature, or handled.</p>
<p>This was intended to encourage software reliability &amp; resilience. There was an intent to “recover” from contingencies – predictable outcomes other than success, such as InsufficientFundsException on attempting a payment. There was less clarity, as to what “recovery” actually entailed.</p>
<p><strong>Runtime exceptions</strong>&nbsp;were also included in Java. Since null pointers, data errors, and illegal states/ accesses could occur anywhere in code, these were made subtypes of RuntimeException.</p>
<p>Runtime exceptions can be thrown anywhere, without requiring to be declared, and are much more convenient. But would it be correct to use them instead?</p>
<h3>The Drawbacks</h3>
<p>The crucial point here, is that runtime &amp; checked exceptions are functionally equivalent.&nbsp;There is no handling or recovery which checked exceptions can do, that runtime exceptions can’t.</p>
<p>The biggest argument against “checked” exceptions is that most exceptions can’t be fixed. The simple fact is, <strong>we don’t own the code/ subsystem that broke.&nbsp;</strong>We can’t see the implementation, we’re not responsible for it, and can’t fix it.</p>
<p>Particularly problematic were the areas of JDBC (SQLException) and RMI for EJB (RemoteException). Rather than identifying fixable contingencies as per the original “checked exception” concept, these forced pervasive systemic reliability issues, not actually fixable, to be widely declared.</p>
<p>For any method, the possibility of failure includes all sub-methods called by it. Potential failures accumulate up the call tree. Declaring these on method signatures no longer offers a specific &amp; local highlight for the developer to watch for – declared exceptions spread throughout the call tree.</p>
<p>Most EJB developers have experienced this – declared exceptions become&nbsp;required on methods through the tier,&nbsp;or entire codebase. Calling a method with different&nbsp;exceptions&nbsp;requires dozens of methods to be adjusted.</p>
<p>Many developers were told to catch low-level exceptions, and rethrow them again as higher (application-level) checked exceptions. This required vast numbers – 2000 per project, upwards – of non-functional “catch-throw” blocks.</p>
<p>Swallowing exceptions, concealing the cause, double logging, and returning ‘null’/ uninitialized data all became common. Most projects could count 600+ mis-coded or outright errors.</p>
<p>Eventually, developers rebelled against the vast numbers of “catch” blocks, and the source of error these had become.</p>
<h3>Checked Exceptions – incompatible with Functional Coding</h3>
<p>And then we get to Java 8, with its new <i><b>functional programming&nbsp;</b></i>features – such as lambdas, Streams, and function composition.</p>
<p>These features are built on generics – parameter &amp; return types are genericized, so that iteration &amp; stream operations ( <code>forEach</code>, <code>map</code>, <code>flatMap</code>) can be written which perform a common operation, regardless of item type.</p>
<p>Unlike data types, however, declared exceptions can’t be genericized.</p>
<p>There is no possibility in Java to provide a stream operation (like, for example, &nbsp;<code>Stream.map</code>) which takes a lambda declaring some checked exception, &amp; transparently passes that same checked exception to surrounding code.</p>
<p>This has always been a major points against checked exceptions – all intervening code, between a throw and the receiving “catch” block, is forced to be aware of exceptions.</p>
<p>The workaround, of “wrapping” it in a RuntimeException, conceals the original type of the exception – rendering the exception-specific “catch” blocks envisaged in the original concept useless.</p>
<p>Finally we can capture Java’s new philosophy in a nutshell, by noting that none of the new “functional interfaces” in Java 8 declare checked exceptions.</p>
<h3>Conclusion</h3>
<p>Exceptions in Java provided major benefits in reliability &amp; error-handling over earlier languages.&nbsp;Java enabled reliable server &amp; business software, in a way C/ C++ never could.</p>
<p>Checked exceptions were,&nbsp;in their original form, an attempt&nbsp;to handle&nbsp;<i>contingencies</i>&nbsp;rather than&nbsp;<i>failures</i>.&nbsp;The laudable goal was to highlight specific predictable points (unable to connect,&nbsp;file not found,&nbsp;etc) &amp; ensure developers handled these.</p>
<p>What was never included in the original concept, was to force a vast range of systemic &amp;&nbsp;unrecoverable failures to be declared. These <em>failures</em>&nbsp;were never correct to be&nbsp;declared as checked exceptions.</p>
<p>Failures are generally possible in code, and EJB, web &amp; Swing/AWT containers already cater for this by providing an outermost “failed request” exception-handler. The most basic correct strategy is to rollback the transaction &amp; return an error.</p>
<p>Runtime exceptions allow any exception-handling possible with checked exceptions, but avoid restrictive coding restraints. This simplifies coding &amp; makes it easier to follow best practice of&nbsp;<a href="http://wikijava.org/wiki/10_best_practices_with_Exceptions#Throw_early_catch_late" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://wikijava.org']);">throw early, catch late</a>&nbsp;where exceptions are handled at the outermost/ highest possible level.</p>
<p>Leading Java frameworks and influences have now definitively moved&nbsp;away from checked exceptions. Spring, Hibernate and modern Java frameworks/&nbsp;vendors&nbsp;use only runtime exceptions, and this convenience is a major factor in their popularity.</p>
<p>Personalities such Josh Bloch (Java&nbsp;Collections framework), Rod Johnson, Anders Hejlsberg (father of&nbsp;C#), Gavin King&nbsp;and&nbsp;Stephen Colebourn&nbsp;(JodaTime)&nbsp;have all come out against checked exceptions.</p>
<p>Now, in&nbsp;Java 8,&nbsp;lambdas are&nbsp;the&nbsp;fundamental step forward.&nbsp;These language features&nbsp;abstract the “flow of control” from functional operations within. As we’ve seen, this makes checked exceptions &amp; the requirement to “declare or handle immediately” obsolete.</p>
<p>For developers, it is always important to pay attention to reliability &amp; diagnose likely points of failure (contingencies) such as file open, database connection, etc. If we provide good error messages at this points, we will have&nbsp;created&nbsp;self-diagnosing software – a pinnacle of engineering achievement.</p>
<p>But we should do this with unchecked exceptions, and if we have to rethrow, should always use RuntimeException or an app-specific subclass.</p>
<p>As&nbsp;Stephen Colebourn says, if your projects&nbsp;are&nbsp;still using or advocating checked exceptions, your skills are 5-10 years out date.&nbsp;Java&nbsp;has moved&nbsp;on.</p>
<p><strong>How are you dealing with exceptions &amp; reliability? Add your thoughts now.</strong></p>
<p>References:<br>
– <a href="http://www.oracle.com/technetwork/articles/entarch/effective-exceptions-092345.html">Oracle: Barry Ruzek, Effective Java Exceptions<br>
</a>– <a href="http://tutorials.jenkov.com/java-exception-handling/checked-or-unchecked-exceptions.html" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://tutorials.jenkov.com']);">Jacob Jenkov: Checked or Unchecked Exceptions</a><br>
– <a href="http://googletesting.blogspot.co.nz/2009/09/checked-exceptions-i-love-you-but-you.html" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://googletesting.blogspot.co.nz']);">Google Testing blog: &nbsp;Checked exceptions, you have to go</a><br>
–&nbsp;<a href="http://www.artima.com/intv/handcuffs.html">Ander Hejlsberg on checked exceptions<br>
–</a>&nbsp;<a href="http://blog.joda.org/2010/09/checked-exceptions-bijava_9688.html" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://blog.joda.org']);">Stephen Colebourne: Remove checked exceptions from Java</a></p>
<p>Counter-argument: &nbsp;James Gosling<br>
– <a href="http://www.artima.com/intv/solid.html" onclick="javascript:_gaq.push(['_trackEvent','outbound-article','http://www.artima.com']);">James Gosling on checked exceptions</a></p>
	</div><!-- .entry-content -->
	
	</article></div>]]>
            </description>
            <link>http://literatejava.com/exceptions/checked-exceptions-javas-biggest-mistake/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24440536</guid>
            <pubDate>Fri, 11 Sep 2020 08:57:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I built an app to fix my depression]]>
            </title>
            <description>
<![CDATA[
Score 268 | Comments 176 (<a href="https://news.ycombinator.com/item?id=24439612">thread link</a>) | @zoozla
<br/>
September 10, 2020 | http://blog.elifiner.com/how-i-built-an-app-to-fix-my-depression/ | <a href="https://web.archive.org/web/*/http://blog.elifiner.com/how-i-built-an-app-to-fix-my-depression/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-174">
	<!-- .entry-header -->

	
	
	<div>
		
<p>I was first diagnosed with depression when I was working on a startup in 2007. I went to the doctor, told him I was feeling mild flu symptoms for a couple of months, he asked me a few questions, determined that I had depression, gave my some SSRIs, and sent me home.</p>



<p>It worked for a while, but then 2008 happened, our startup collapsed, the stakes got higher and the depression came back. The doc recommended I up the dosage, but I could see this would eventually lead me to a straitjacket.</p>



<p>Over the years I’ve tried different meds, various forms of therapy, studied and actively practiced life coaching, got married, had kids, moved to another country and changed everything I could think of about my life. Unfortunately the dark bouts of depression remained.</p>



<p>About four years ago I stumbled on a book called Highly Sensitive Person that absolutely blew my mind. I realized I had very intense emotions that I was culturally programmed to repress, which caused my psyche to overload and go into full apathy mode also known as clinical depression.</p>



<p>I’ve been on a path to figure out how to process my emotions without repressing them and combined my personal experience with several non-mainstream techniques to build Wuju. It’s an online app that can help you tap into your hidden emotions and release them so they no longer influence your behaviour or cause depressive symptoms.</p>



<p>I’ve used it in the last 18 months to deal with parenting two kids, surviving infidelity, losing my job, starting a business, and covid anxiety. My longest bouts of depression now last a day at most and even that doesn’t happen too often.</p>



<p>You can try it too: <a href="https://beta.wuju.app/">beta.wuju.app</a></p>




	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>http://blog.elifiner.com/how-i-built-an-app-to-fix-my-depression/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24439612</guid>
            <pubDate>Fri, 11 Sep 2020 06:02:31 GMT</pubDate>
        </item>
    </channel>
</rss>
