<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 27 Dec 2020 12:46:47 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 27 Dec 2020 12:46:47 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[The Impact of Apple Silicon Macs on Broadway]]>
            </title>
            <description>
<![CDATA[
Score 75 | Comments 68 (<a href="https://news.ycombinator.com/item?id=25534863">thread link</a>) | @da02
<br/>
December 24, 2020 | https://brianli.com/2020/12/the-impact-of-apple-silicon-macs-on-broadway/ | <a href="https://web.archive.org/web/*/https://brianli.com/2020/12/the-impact-of-apple-silicon-macs-on-broadway/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="container"><main><article role="article"><div><p>In a previous life, I was an electronic music designer working on Broadway shows in New York City. Broadway shows look glamorous and expensive on the outside, but it’s often quite the opposite on the inside –&nbsp;at least for the music department. One of the toughest parts of my job as an electronic music designer was to find the best performance-to-cost ratio for computer rigs powering keyboards, guitars, playback tracks, and more.</p><p>Over the past decade, Broadway has replaced large sections of traditional orchestras with synthesizers, playback systems, and electronic drum pads. I’m not in support of that, but that’s a story for another day. The point here is that Broadway’s reliance on computer-driven rigs has increased, while the typical budget required to build high-end stable rigs hasn’t increased at the same rate.</p><p>Some shows I’ve worked at set aside a $10,000-$12,000 budget for two keyboard rigs. That sounds like a lot of money at first, but it’s not. For live shows, it’s usually best to have a 1:1 backup in case the main rig fails. That fact alone means you have to design a rig that fits within 50% of the proposed budget. Furthermore, a high-quality keyboard controller alone is $1,500-2,000 –&nbsp;so that means there’s $3,000 left for a computer and everything else.</p><p>Due to budget constraints, many shows end up using Mac minis. Historically speaking, the Mac mini’s computing power has been a bottleneck for electronic music designers on Broadway. In a perfect world, we’d all like to use the best-sounding sample libraries for our work, but that was never feasible with the Mac mini. Thus, the compromise was always to reduce sound quality to fit within the Mac mini’s compute constraints.</p><p>Apple Silicon changes everything for Broadway electronic music designers. The new M1 Mac mini is capable of running high-end sample libraries and virtual instruments in a stable manner, and it’s only going to get better with M2, M3, and M4-series chips in the future. The performance per dollar characteristics of Apple Silicon machines are going to have a huge impact on Broadway’s sound, and I’m very excited to see, or hear, what happens.</p></div></article></main></div></div>]]>
            </description>
            <link>https://brianli.com/2020/12/the-impact-of-apple-silicon-macs-on-broadway/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25534863</guid>
            <pubDate>Fri, 25 Dec 2020 07:14:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fictional Videogame Stills]]>
            </title>
            <description>
<![CDATA[
Score 136 | Comments 30 (<a href="https://news.ycombinator.com/item?id=25530307">thread link</a>) | @doener
<br/>
December 24, 2020 | https://www.suzannetreister.net/Ampages/Amenu.html | <a href="https://web.archive.org/web/*/https://www.suzannetreister.net/Ampages/Amenu.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
      <td colspan="4"> 
        <p><span size="2" face="Verdana, Arial, Helvetica, sans-serif"><b><span size="1" color="#99CC33">Suzanne 
          Treister<br>
          </span></b><span size="1" face="Verdana, Arial, Helvetica, sans-serif" color="#99CC33">1991-1992</span><span size="1" color="#99CC33"> 
          </span></span> </p>
        <p><span size="1" face="Verdana, Arial, Helvetica, sans-serif" color="#99CC33"><i><strong>Fictional 
          Videogame Stills</strong></i> </span></p>
        <p><span size="1" face="Verdana, Arial, Helvetica, sans-serif" color="#99CC33">In 
          the late 1980s I was making paintings about computer games. In January 1991 I bought an Amiga computer and made a series of fictional 
          videogame stills using Deluxe Paint II. I photographed them straight 
          from the screen as there was no other way to output them that I knew 
          of apart from through a very primitive daisy wheel printer where they appeared as washed out dots. <p>
          
          The effect of the photographs perfectly reproduced the highly 
          pixellated, raised needlepoint effect of the Amiga screen image. Conceptually 
          this means of presentation was also appropriate in that it made it seem 
          like I had gone into a videogame arcade and photographed the games there, 
          lending authenticity to the fiction.</p></span><span color="#99cc33" face="Verdana, Arial, Helvetica, sans-serif" size="1">The first seven works on this page form a series titled, 'Q. Would you recognise a Virtual Paradise?'</span><span size="1" face="Verdana, Arial, Helvetica, sans-serif" color="#99CC33"><p>
          
          Many of these works were shown in London at the Edward Totah Gallery in March 
        1992 (<a href="https://www.suzannetreister.net/Ampics/Installations/Totah-Installation1992/EdwardTotah_1992.html" target="_self">view installation</a>) and later that year</p></span><span color="#99cc33" face="Verdana, Arial, Helvetica, sans-serif" size="1"> at the Exeter Hotel in Adelaide, Australia.<br> 
        In 1995 the 'Q. Would you recognise a Virtual Paradise?' series was shown in London at the Royal Festival Hall in the exhibition<em> It's a Pleasure</em>, curated by Leah Kharibian.</span><span size="1" face="Verdana, Arial, Helvetica, sans-serif" color="#99CC33"><br>
        Recent venues: Somerset House, London, 2018 <a href="https://www.suzannetreister.net/Ampics/Installations/SomersetHouse2018/SomersetHouse2018.html" target="_self">view installation</a> ; Akron Art Museum, Ohio, USA 2019 and tour; Moderna Museet, Stockholm, Sweden, 2019/20 <a href="https://www.suzannetreister.net/InstallationV/Moderna-Museet_2019.html" target="_self">view installation</a><p>
          
          The original Amiga floppy disks which stored the image files are  corrupt, but the  photographic art works remain.</p></span><span size="1" face="Verdana, Arial, Helvetica, sans-serif" color="#99CC33"><p>
          
          For 
          more information <a href="https://www.suzannetreister.net/Ampages/Treister_Essay.pdf">download my essay</a> 
          from '<a href="http://www.intellectbooks.co.uk/ppbooks.php?isbn=9781841501420" target="_blank">Videogames 
            and Art</a>', Ed. Andy Clarke, Grethe Mitchell, Publ. Intellect Books, 
        UK 2007</p></span></p>
<p><span color="#996633" size="1" face="Verdana, Arial, Helvetica, sans-serif"> <a href="https://www.suzannetreister.net/Videography/Videogames_Video.html" target="_self">view video version</a><p>
            
          click 
  titles below to view enlargements of photo works</p></span></p></td>
    </div></div>]]>
            </description>
            <link>https://www.suzannetreister.net/Ampages/Amenu.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25530307</guid>
            <pubDate>Thu, 24 Dec 2020 19:01:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GoDaddy employees told they were getting a holiday bonus in a phishing test]]>
            </title>
            <description>
<![CDATA[
Score 178 | Comments 234 (<a href="https://news.ycombinator.com/item?id=25529584">thread link</a>) | @arkadiyt
<br/>
December 24, 2020 | https://coppercourier.com/story/godaddy-employees-holiday-bonus-secruity-test/ | <a href="https://web.archive.org/web/*/https://coppercourier.com/story/godaddy-employees-holiday-bonus-secruity-test/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					
<h2>Roughly 500 employees failed the test, which claimed they would receive a $650 bonus.</h2>



<p>“2020 has been a record year for GoDaddy, thanks to you!” the email read.</p>



<p>Sent by Happyholiday@Godaddy.com, tucked underneath a glittering banner of a snowflake and stamped with the words “GoDaddy Holiday Party,” the Dec. 14 email to hundreds of GoDaddy employees promised some welcome financial relief during an <a href="https://coppercourier.com/story/tens-of-millions-of-americans-face-economic-ruin-unless-congress-gets-its-sht-together/">otherwise stressful year</a>.</p>



<p>“Though we cannot celebrate together during our annual Holiday Party, we want to show our appreciation and share a $650 one-time Holiday bonus!” the email read. “To ensure that you receive your one-time bonus in time for the Holidays, please select your location and fill in the details by Friday, December 18th.”</p>



<p>But, two days later, the company sent another email.</p>



<p>“You’re getting this email because you failed our recent phishing test,” the company’s chief security officer Demetrius Comes<strong> </strong>wrote. “You will need to retake the Security Awareness Social Engineering training.”</p>



<figure><picture>
	<source media="(max-width: 320px)" srcset="https://fwiw.imgix.net/wp-content/uploads/2020/12/GoDaddy-Email.png?w=284">
	<source media="(max-width: 768px)" srcset="https://fwiw.imgix.net/wp-content/uploads/2020/12/GoDaddy-Email.png?w=676">
	<source media="(max-width: 1280px)" srcset="https://fwiw.imgix.net/wp-content/uploads/2020/12/GoDaddy-Email.png?w=1400">
	<img src="https://fwiw.imgix.net/wp-content/uploads/2020/12/GoDaddy-Email.png?w=1400" width="1400" height="9999" alt="" title="">
	
	
</picture></figure>



<figure>
		<picture>
	<source media="(max-width: 320px)" srcset="https://fwiw.imgix.net/wp-content/uploads/2020/12/Use2.png?w=284">
	<source media="(max-width: 768px)" srcset="https://fwiw.imgix.net/wp-content/uploads/2020/12/Use2.png?w=676">
	<source media="(max-width: 1280px)" srcset="https://fwiw.imgix.net/wp-content/uploads/2020/12/Use2.png?w=1400">
	<img src="https://fwiw.imgix.net/wp-content/uploads/2020/12/Use2.png?w=1400" width="1400" height="9999" alt="" title="">
	
	
</picture><span>A Dec. 14 email sent to hundreds of GoDaddy employees offered a holiday bonus to employees. It turned out to be a phishing test.</span><figcaption>Screenshots of the email were sent to The Copper Courier by multiple GoDaddy employees.</figcaption>
	</figure>



<p>Phishing tests are sent by companies to gauge their employees’ susceptibility to phishing attacks, where people outside the company will attempt to disguise themselves as trusted sources to gain access to sensitive information, like usernames and passwords.</p>



<p>The follow-up email from Comes said that roughly 500 GoDaddy employees clicked on the holiday bonus email and “failed the test.”</p>



<p>Scottsdale-based GoDaddy, the world’s largest domain registrar and web-hosting company, did not respond to repeated requests for comment about the emails. The emails were forwarded to The Copper Courier by three GoDaddy employees.</p>



<p>Earlier this year, <a href="https://www.forbes.com/sites/daveywinder/2020/05/05/godaddy-confirms-data-breach-what-19-million-customers-need-to-know/?sh=235bf0a91daa">Forbes reported</a> that 28,000 GoDaddy customers were impacted after a data breach compromised their account usernames and passwords.&nbsp;</p>



<p>Despite the company <a href="https://investors.godaddy.net/newsroom/news-releases/press-release-details/2020/GoDaddy-Reports-Second-Quarter-2020-Earnings-Results/default.aspx">surpassing 20 million customers this year</a> and reporting “record customer growth,” the company <a href="https://aboutus.godaddy.net/newsroom/news-releases/press-release-details/2020/GoDaddy-Blog-Update/default.aspx">laid off or reassigned</a> hundreds of employees during the coronavirus pandemic, <a href="https://www.abc15.com/news/business/godaddy-to-lay-off-hundreds-close-texas-offices">including in Arizona</a>, Iowa, and Texas.</p>



<p>GoDaddy is not the first company this year to trick employees into falling for phishing scams by dangling the carrot of a potential bonus.</p>



<p>In September, Tribune Publishing, which owns <a href="https://www.tribpub.com/#">several major newspapers</a> around the country, sent a similar email to its employees.</p>



<p>The email, circulated by <a href="https://twitter.com/justin_fenton/status/1308851669397053440">several furious Tribune employees on Twitter</a>, said the company was giving out targeted bonuses of $5,000-$10,000, only to later reveal itself as a phishing test sent by the company.</p>



<figure><div>
<figure><blockquote data-width="500" data-dnt="true"><div lang="en" dir="ltr"><p>I've been able to confirm that this was in fact! an internal test from <a href="https://twitter.com/tribpub?ref_src=twsrc%5Etfw">@tribpub</a>. If you click the links, you get a message from the company's training contractor saying you clicked on a simulated phishing test.</p><p>The level of cruelty is actually stunning, even for this company.</p></div>— Danielle Ohl (@DTOhl) <a href="https://twitter.com/DTOhl/status/1308850196978298880?ref_src=twsrc%5Etfw">September 23, 2020</a></blockquote></figure>
</div></figure>



<p>“The level of cruelty is actually stunning,” Tribune reporter Danielle Ohl <a href="https://twitter.com/DTOhl/status/1308850196978298880?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1308850196978298880%7Ctwgr%5E%7Ctwcon%5Es1_&amp;ref_url=https%3A%2F%2Fwww.vice.com%2Fen%2Farticle%2Fy3z8g5%2Ftribune-publishing-out-evils-itself-with-phishing-email-promising-bonuses">wrote at the time</a>.</p>



<p>A Tribune spokesperson <a href="https://www.vice.com/en/article/y3z8g5/tribune-publishing-out-evils-itself-with-phishing-email-promising-bonuses">later told Vice News</a> that the exercise was part of a regular, internal test to assess phishing risks and said that it had no intention of offending its employees. “In retrospect, the topic of the email was misleading and insensitive, and the company apologizes for its use,” the statement read.</p>



<p><em>Want to talk about phishing tests you’ve received from your employer? Reach the reporter at <a href="mailto:lorraine@couriernewsroom.com">lorraine@couriernewsroom.com</a> or 480-243-4086.</em></p>
				</div><div>
	<hr>
	<div>
    <a href="https://coppercourier.com/author/lorrainelonghi/">
        <picture>
	<source media="(max-width: 90px)" srcset="https://fwiw.imgix.net/wp-content/uploads/2020/11/Lorraine-Longhi-.jpg?w=90">
	<img src="https://fwiw.imgix.net/wp-content/uploads/2020/11/Lorraine-Longhi-.jpg?w=90" width="90" height="9999" alt="Lorraine Longhi" title="Lorraine Longhi">
</picture>    </a>
    <div>
        <p>
            <a href="https://coppercourier.com/author/lorrainelonghi/">
                Lorraine Longhi            </a>
            is a reporter for The Copper Courier. She is a native of the Southwest and has lived in Phoenix since 2006. A graduate of ASU’s Walter Cronkite School of Journalism, she previously worked for The Arizona Republic, covering city government, education, and the impact of statewide decisions.        </p>
        
    </div>
</div>
</div></div>]]>
            </description>
            <link>https://coppercourier.com/story/godaddy-employees-holiday-bonus-secruity-test/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25529584</guid>
            <pubDate>Thu, 24 Dec 2020 17:42:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[In CPython, types implemented in C are part of the type tree]]>
            </title>
            <description>
<![CDATA[
Score 103 | Comments 78 (<a href="https://news.ycombinator.com/item?id=25528557">thread link</a>) | @todsacerdoti
<br/>
December 24, 2020 | https://utcc.utoronto.ca/~cks/space/blog/python/CPythonCTypesHaveTree | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/python/CPythonCTypesHaveTree">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>In CPython, types implemented in C actually are part of the type tree</h2>

	<p><small>December 24, 2020</small></p>
</div><div><p>In Python, in theory all types descend from <code>object</code> (they are
direct or indirect subclasses of it). For years, I've believed (and
written) that this was not the case at the implementation level for
types written in native C code in CPython (the standard implementation
of Python and the one you're probably using). Types written in C
might behave as if they descended from <code>object</code>, but I thought their
behavior was actually entirely stand-alone, implemented by each
type separately in C. Courtesy of <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-6-how-python-object-system-works/">Python behind the scenes #6:
how Python object system works</a>,
I've discovered that I'm wrong.</p>

<p>In CPython, C level Python types are not literally subclasses of
the C level version of <code>object</code>, because of course C doesn't have
classes and subclasses in that sense. Instead, you usually describe
your type by defining a <a href="https://docs.python.org/3/c-api/typeobj.html"><code>PyTypeObject</code></a> struct for it, with
all sorts of fields that you fill in or don't fill in as you need
them, including a <a href="https://docs.python.org/3/c-api/typeobj.html#c.PyTypeObject.tp_base"><code>tp_base</code></a> field
for your base type (if you want more than one base type, you need
to take the alternate path of a <a href="https://docs.python.org/3/c-api/typeobj.html#heap-types">heap type</a>). When
CPython needs to execute special methods or other operations on
your type, it will directly use fields on your <code>PyTypeObject</code>
structure (and as far as I know, it only uses those fields, with
no fallbacks). On the surface, this looks like the <code>tp_base</code> field
is essentially decorative and is only used to report your claimed
<code>__base__</code> if people ask.</p>

<p>However, there is a bit of CPython magic hiding behind the scenes.
In order to actually use a <code>PyTypeObject</code> as a type, you must
register it and make it ready by calling <a href="https://docs.python.org/3/c-api/type.html#c.PyType_Ready"><code>PyType_Ready</code></a>. As part
of this, <code>PyType_Ready</code> will use your type's <code>tp_base</code> to fill
in various fields of your <code>PyTypeObject</code> if you didn't already do
that, which effectively means that your C level type will inherit
those fields from its base type (and so on all the way up to
<code>object</code>). This is outlined in <a href="https://docs.python.org/3/c-api/typeobj.html#cols">a section of the C API</a>, but of course
I never read the C API myself because I never needed to use it.
The <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-6-how-python-object-system-works/">how [the] Python object system works</a>
article has more details on how this works, if you're curious, along
with details on how special methods also work (which is more
interesting than I had any idea, and I've looked at this area
before).</p>

<p>(The distinction between what is considered a 'type' and what is
considered a 'class' by <code>repr()</code> is somewhat arbitrary; see the
sidebar <a href="https://utcc.utoronto.ca/~cks/space/blog/python/ClassesAndTypes">here</a>. C level things defined with
<code>PyTypeObject</code> will probably always be considered types instead of
classes.)</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/python/CPythonCTypesHaveTree</link>
            <guid isPermaLink="false">hacker-news-small-sites-25528557</guid>
            <pubDate>Thu, 24 Dec 2020 15:54:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Oklab: A perceptual color space for image processing]]>
            </title>
            <description>
<![CDATA[
Score 222 | Comments 75 (<a href="https://news.ycombinator.com/item?id=25525726">thread link</a>) | @ingve
<br/>
December 23, 2020 | https://bottosson.github.io/posts/oklab/ | <a href="https://web.archive.org/web/*/https://bottosson.github.io/posts/oklab/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><div><p>A perceptual color space is desirable when doing many kinds of image processing. It is useful for things like:</p><ul><li>Turning an image grayscale, while keeping the perceived lightness the same</li><li>Increasing the saturation of colors, while maintaining perceived hue and lightness</li><li>Creating smooth and uniform looking transitions between colors</li></ul><p>Unfortunately, as far as I am aware, while there are color spaces that aim to be perceptually uniform, none are without significant drawbacks when used for image processing.</p><p>For this reason I have designed a new perceptual color space, designed to be simple to use, while doing a good job at predicting perceived lightness, <a href="https://en.wikipedia.org/wiki/Colorfulness">chroma</a> and hue. It is called the <strong>Oklab color space</strong>, because it is an OK Lab color space.</p><p>Before diving into the details of why a new color space is needed and how it was derived, here is the everything needed to use the color space:</p><p>A color in Oklab is represented with three coordinates, similar to how <a href="https://en.wikipedia.org/wiki/CIELAB_color_space">CIELAB</a> works, but with better perceptual properties. Oklab uses a D65 whitepoint, since this is what sRGB and other common color spaces use. The three coordinates are:</p><ul><li><span><span><math><semantics><mrow><mi>L</mi></mrow><annotation encoding="application/x-tex">L</annotation></semantics></math></span></span> – perceived lightness</li><li><span><span><math><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span></span> – how green/red the color is</li><li><span><span><math><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span></span> – how blue/yellow the color is</li></ul><p>For many operations, <span><span><math><semantics><mrow><mi>L</mi><mi>a</mi><mi>b</mi></mrow><annotation encoding="application/x-tex">Lab</annotation></semantics></math></span></span>-coordinates can be used directly, but they can also be transformed into polar form, with the coordinates lightness, chroma and hue, <span><span><math><semantics><mrow><mi>L</mi><mi>C</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">LCh</annotation></semantics></math></span></span>:</p><p><span><span><span><math><semantics><mrow><mi>C</mi><mo>=</mo><mrow><msqrt><mrow><msup><mi>a</mi><mn>2</mn></msup><mo>+</mo><msup><mi>b</mi><mn>2</mn></msup></mrow></msqrt></mrow><mo separator="true">,</mo><mspace width="2em"></mspace><msup><mi>h</mi><mrow><mo>∘</mo></mrow></msup><mo>=</mo><mtext><mi mathvariant="normal">a</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">n</mi><mn>2</mn></mtext><mo>(</mo><mi>b</mi><mo separator="true">,</mo><mi>a</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">C={\sqrt {a^2+b^2}}, \qquad h^{\circ}=\text{atan2}(b,a)</annotation></semantics></math></span></span></span></p><p>From <span><span><math><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span></span> and <span><span><math><semantics><mrow><msup><mi>h</mi><mrow><mo>∘</mo></mrow></msup></mrow><annotation encoding="application/x-tex">h^{\circ}</annotation></semantics></math></span></span>, <span><span><math><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span></span> and <span><span><math><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span></span> can be computed like this:</p><p><span><span><span><math><semantics><mrow><mi>a</mi><mo>=</mo><mi>C</mi><mi>cos</mi><mo>(</mo><msup><mi>h</mi><mrow><mo>∘</mo></mrow></msup><mo>)</mo><mo separator="true">,</mo><mspace width="2em"></mspace><mi>b</mi><mo>=</mo><mi>C</mi><mi>sin</mi><mo>(</mo><msup><mi>h</mi><mrow><mo>∘</mo></mrow></msup><mo>)</mo></mrow><annotation encoding="application/x-tex">a=C\cos(h^{\circ}),\qquad b=C\sin(h^{\circ})</annotation></semantics></math></span></span></span></p><p>Lets look at a practical example to see how Oklab performs, before looking at how the <span><span><math><semantics><mrow><mi>L</mi><mi>a</mi><mi>b</mi></mrow><annotation encoding="application/x-tex">Lab</annotation></semantics></math></span></span> coordinates are computed.</p><blockquote><h4 id="comparing-oklab-to-hsv">Comparing Oklab to HSV <a href="#comparing-oklab-to-hsv"><span><svg viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" enable-background="new 0 0 512 512" version="1.1" xml:space="preserve" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M459.654,233.373l-90.531,90.5c-49.969,50-131.031,50-181,0c-7.875-7.844-14.031-16.688-19.438-25.813  l42.063-42.063c2-2.016,4.469-3.172,6.828-4.531c2.906,9.938,7.984,19.344,15.797,27.156c24.953,24.969,65.563,24.938,90.5,0  l90.5-90.5c24.969-24.969,24.969-65.563,0-90.516c-24.938-24.953-65.531-24.953-90.5,0l-32.188,32.219  c-26.109-10.172-54.25-12.906-81.641-8.891l68.578-68.578c50-49.984,131.031-49.984,181.031,0  C509.623,102.342,509.623,183.389,459.654,233.373z M220.326,382.186l-32.203,32.219c-24.953,24.938-65.563,24.938-90.516,0  c-24.953-24.969-24.953-65.563,0-90.531l90.516-90.5c24.969-24.969,65.547-24.969,90.5,0c7.797,7.797,12.875,17.203,15.813,27.125  c2.375-1.375,4.813-2.5,6.813-4.5l42.063-42.047c-5.375-9.156-11.563-17.969-19.438-25.828c-49.969-49.984-131.031-49.984-181.016,0  l-90.5,90.5c-49.984,50-49.984,131.031,0,181.031c49.984,49.969,131.031,49.969,181.016,0l68.594-68.594  C274.561,395.092,246.42,392.342,220.326,382.186z"></path></svg><span></span></span></a></h4><p>Here’s an Oklab color gradient with varying hue and constant lightness and chroma.</p><p><img alt="Oklab varying hue plot" decoding="async" height="169" loading="lazy" src="https://bottosson.github.io/img/oklab/hue_oklab.png" width="1130"></p><p>Compare this to a similar plot of a HSV color gradient with varying hue and constant value and saturation (HSV using the sRGB color space).</p><p><img alt="HSV varying hue plot" decoding="async" height="169" loading="lazy" src="https://bottosson.github.io/img/oklab/hue_hsv.png" width="1130"></p><p>The gradient is quite uneven and there are clear differences in lightness for different hues. Yellow, magenta and cyan appear much lighter than red and blue.</p><p>Here is lightness of the HSV plot, as predicted by Oklab:</p><p><img alt="HSV varying hue plot lightness" decoding="async" height="169" loading="lazy" src="https://bottosson.github.io/img/oklab/hue_hsv_lightness.png" width="1130"></p></blockquote><h3 id="implementation">Implementation <a href="#implementation"><span><svg viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" enable-background="new 0 0 512 512" version="1.1" xml:space="preserve" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M459.654,233.373l-90.531,90.5c-49.969,50-131.031,50-181,0c-7.875-7.844-14.031-16.688-19.438-25.813  l42.063-42.063c2-2.016,4.469-3.172,6.828-4.531c2.906,9.938,7.984,19.344,15.797,27.156c24.953,24.969,65.563,24.938,90.5,0  l90.5-90.5c24.969-24.969,24.969-65.563,0-90.516c-24.938-24.953-65.531-24.953-90.5,0l-32.188,32.219  c-26.109-10.172-54.25-12.906-81.641-8.891l68.578-68.578c50-49.984,131.031-49.984,181.031,0  C509.623,102.342,509.623,183.389,459.654,233.373z M220.326,382.186l-32.203,32.219c-24.953,24.938-65.563,24.938-90.516,0  c-24.953-24.969-24.953-65.563,0-90.531l90.516-90.5c24.969-24.969,65.547-24.969,90.5,0c7.797,7.797,12.875,17.203,15.813,27.125  c2.375-1.375,4.813-2.5,6.813-4.5l42.063-42.047c-5.375-9.156-11.563-17.969-19.438-25.828c-49.969-49.984-131.031-49.984-181.016,0  l-90.5,90.5c-49.984,50-49.984,131.031,0,181.031c49.984,49.969,131.031,49.969,181.016,0l68.594-68.594  C274.561,395.092,246.42,392.342,220.326,382.186z"></path></svg><span></span></span></a></h3><h4 id="converting-from-xyz-to-oklab">Converting from XYZ to Oklab <a href="#converting-from-xyz-to-oklab"><span><svg viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" enable-background="new 0 0 512 512" version="1.1" xml:space="preserve" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M459.654,233.373l-90.531,90.5c-49.969,50-131.031,50-181,0c-7.875-7.844-14.031-16.688-19.438-25.813  l42.063-42.063c2-2.016,4.469-3.172,6.828-4.531c2.906,9.938,7.984,19.344,15.797,27.156c24.953,24.969,65.563,24.938,90.5,0  l90.5-90.5c24.969-24.969,24.969-65.563,0-90.516c-24.938-24.953-65.531-24.953-90.5,0l-32.188,32.219  c-26.109-10.172-54.25-12.906-81.641-8.891l68.578-68.578c50-49.984,131.031-49.984,181.031,0  C509.623,102.342,509.623,183.389,459.654,233.373z M220.326,382.186l-32.203,32.219c-24.953,24.938-65.563,24.938-90.516,0  c-24.953-24.969-24.953-65.563,0-90.531l90.516-90.5c24.969-24.969,65.547-24.969,90.5,0c7.797,7.797,12.875,17.203,15.813,27.125  c2.375-1.375,4.813-2.5,6.813-4.5l42.063-42.047c-5.375-9.156-11.563-17.969-19.438-25.828c-49.969-49.984-131.031-49.984-181.016,0  l-90.5,90.5c-49.984,50-49.984,131.031,0,181.031c49.984,49.969,131.031,49.969,181.016,0l68.594-68.594  C274.561,395.092,246.42,392.342,220.326,382.186z"></path></svg><span></span></span></a></h4><p>Given a color in <span><span><math><semantics><mrow><mi>X</mi><mi>Y</mi><mi>Z</mi></mrow><annotation encoding="application/x-tex">XYZ</annotation></semantics></math></span></span> coordinates, with a D65 whitepoint, Oklab coordinates can be computed like this:</p><p>First the <span><span><math><semantics><mrow><mi>X</mi><mi>Y</mi><mi>Z</mi></mrow><annotation encoding="application/x-tex">XYZ</annotation></semantics></math></span></span> coordinates are converted to an approximate cone responses:</p><p><span><span><span><math><semantics><mrow><mrow><mo fence="true">(</mo><mtable><mtr><mtd><mrow><mi>l</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>m</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>s</mi></mrow></mtd></mtr></mtable><mo fence="true">)</mo></mrow><mo>=</mo><mrow><msub><mi mathvariant="bold">M</mi><mn mathvariant="bold">1</mn></msub></mrow><mo>×</mo><mrow><mo fence="true">(</mo><mtable><mtr><mtd><mrow><mi>X</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>Y</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>Z</mi></mrow></mtd></mtr></mtable><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\begin{pmatrix} l \\ m \\ s \end{pmatrix} = \mathbf{M_1} \times \begin{pmatrix} X \\ Y \\ Z \end{pmatrix}</annotation></semantics></math></span></span></span></p><p>A non-linearity is applied:</p><p><span><span><span><math><semantics><mrow><mrow><mo fence="true">(</mo><mtable><mtr><mtd><mrow><msup><mi>l</mi><mrow><mi mathvariant="normal">′</mi></mrow></msup></mrow></mtd></mtr><mtr><mtd><mrow><msup><mi>m</mi><mrow><mi mathvariant="normal">′</mi></mrow></msup></mrow></mtd></mtr><mtr><mtd><mrow><msup><mi>s</mi><mrow><mi mathvariant="normal">′</mi></mrow></msup></mrow></mtd></mtr></mtable><mo fence="true">)</mo></mrow><mo>=</mo><mrow><mo fence="true">(</mo><mtable><mtr><mtd><mrow><msup><mi>l</mi><mrow><mfrac><mn>1</mn><mn>3</mn></mfrac></mrow></msup></mrow></mtd></mtr><mtr><mtd><mrow><msup><mi>m</mi><mrow><mfrac><mn>1</mn><mn>3</mn></mfrac></mrow></msup></mrow></mtd></mtr><mtr><mtd><mrow><msup><mi>s</mi><mrow><mfrac><mn>1</mn><mn>3</mn></mfrac></mrow></msup></mrow></mtd></mtr></mtable><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\begin{pmatrix} l' \\ m' \\ s' \end{pmatrix} = \begin{pmatrix} l^{\frac 1 3} \\ m^{\frac 1 3} \\ s^{\frac 1 3} \end{pmatrix}</annotation></semantics></math></span></span></span></p><p>Finally, this is transformed into the <span><span><math><semantics><mrow><mi>L</mi><mi>a</mi><mi>b</mi></mrow><annotation encoding="application/x-tex">Lab</annotation></semantics></math></span></span>-coordinates:</p><p><span><span><span><math><semantics><mrow><mrow><mo fence="true">(</mo><mtable><mtr><mtd><mrow><mi>L</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>a</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>b</mi></mrow></mtd></mtr></mtable><mo fence="true">)</mo></mrow><mo>=</mo><mrow><msub><mi mathvariant="bold">M</mi><mn mathvariant="bold">2</mn></msub></mrow><mo>×</mo><mrow><mo fence="true">(</mo><mtable><mtr><mtd><mrow><msup><mi>l</mi><mrow><mi mathvariant="normal">′</mi></mrow></msup></mrow></mtd></mtr><mtr><mtd><mrow><msup><mi>m</mi><mrow><mi mathvariant="normal">′</mi></mrow></msup></mrow></mtd></mtr><mtr><mtd><mrow><msup><mi>s</mi><mrow><mi mathvariant="normal">′</mi></mrow></msup></mrow></mtd></mtr></mtable><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\begin{pmatrix} L \\ a \\ b \end{pmatrix} = \mathbf{M_2} \times \begin{pmatrix} l' \\ m' \\ s' \end{pmatrix}</annotation></semantics></math></span></span></span></p><p>with the following values for <span><span><math><semantics><mrow><mrow><msub><mi mathvariant="bold">M</mi><mn mathvariant="bold">1</mn></msub></mrow></mrow><annotation encoding="application/x-tex">\mathbf{M_1}</annotation></semantics></math></span></span> and <span><span><math><semantics><mrow><mrow><msub><mi mathvariant="bold">M</mi><mn mathvariant="bold">2</mn></msub></mrow></mrow><annotation encoding="application/x-tex">\mathbf{M_2}</annotation></semantics></math></span></span>:</p><p><span><span><span><math><semantics><mrow><mrow><msub><mi mathvariant="bold">M</mi><mn mathvariant="bold">1</mn></msub></mrow><mo>=</mo><mrow><mo fence="true">(</mo><mtable><mtr><mtd><mrow><mo>+</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>8</mn><mn>1</mn><mn>8</mn><mn>9</mn><mn>3</mn><mn>3</mn><mn>0</mn><mn>1</mn><mn>0</mn><mn>1</mn></mrow></mtd><mtd><mrow><mo>+</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>3</mn><mn>6</mn><mn>1</mn><mn>8</mn><mn>6</mn><mn>6</mn><mn>7</mn><mn>4</mn><mn>2</mn><mn>4</mn></mrow></mtd><mtd><mrow><mo>−</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>1</mn><mn>2</mn><mn>8</mn><mn>8</mn><mn>5</mn><mn>9</mn><mn>7</mn><mn>1</mn><mn>3</mn><mn>7</mn></mrow></mtd></mtr><mtr><mtd><mrow><mo>+</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>0</mn><mn>3</mn><mn>2</mn><mn>9</mn><mn>8</mn><mn>4</mn><mn>5</mn><mn>4</mn><mn>3</mn><mn>6</mn></mrow></mtd><mtd><mrow><mo>+</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>9</mn><mn>2</mn><mn>9</mn><mn>3</mn><mn>1</mn><mn>1</mn><mn>8</mn><mn>7</mn><mn>1</mn><mn>5</mn></mrow></mtd><mtd><mrow><mo>+</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>0</mn><mn>3</mn><mn>6</mn><mn>1</mn><mn>4</mn><mn>5</mn><mn>6</mn><mn>3</mn><mn>8</mn><mn>7</mn></mrow></mtd></mtr><mtr><mtd><mrow><mo>+</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>0</mn><mn>4</mn><mn>8</mn><mn>2</mn><mn>0</mn><mn>0</mn><mn>3</mn><mn>0</mn><mn>1</mn><mn>8</mn></mrow></mtd><mtd><mrow><mo>+</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>2</mn><mn>6</mn><mn>4</mn><mn>3</mn><mn>6</mn><mn>6</mn><mn>2</mn><mn>6</mn><mn>9</mn><mn>1</mn></mrow></mtd><mtd><mrow><mo>+</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>6</mn><mn>3</mn><mn>3</mn><mn>8</mn><mn>5</mn><mn>1</mn><mn>7</mn><mn>0</mn><mn>7</mn><mn>0</mn></mrow></mtd></mtr></mtable><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{M_1} = \begin{pmatrix} +0.8189330101 &amp; +0.3618667424 &amp; -0.1288597137 \\ +0.0329845436 &amp; +0.9293118715 &amp; +0.0361456387 \\ +0.0482003018 &amp; +0.2643662691 &amp; +0.6338517070 \end{pmatrix}</annotation></semantics></math></span></span></span></p><p><span><span><span><math><semantics><mrow><mrow><msub><mi mathvariant="bold">M</mi><mn mathvariant="bold">2</mn></msub></mrow><mo>=</mo><mrow><mo fence="true">(</mo><mtable><mtr><mtd><mrow><mo>+</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>2</mn><mn>1</mn><mn>0</mn><mn>4</mn><mn>5</mn><mn>4</mn><mn>2</mn><mn>5</mn><mn>5</mn><mn>3</mn></mrow></mtd><mtd><mrow><mo>+</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>7</mn><mn>9</mn><mn>3</mn><mn>6</mn><mn>1</mn><mn>7</mn><mn>7</mn><mn>8</mn><mn>5</mn><mn>0</mn></mrow></mtd><mtd><mrow><mo>−</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>0</mn><mn>0</mn><mn>4</mn><mn>0</mn><mn>7</mn><mn>2</mn><mn>0</mn><mn>4</mn><mn>6</mn><mn>8</mn></mrow></mtd></mtr><mtr><mtd><mrow><mo>+</mo><mn>1</mn><mi mathvariant="normal">.</mi><mn>9</mn><mn>7</mn><mn>7</mn><mn>9</mn><mn>9</mn><mn>8</mn><mn>4</mn><mn>9</mn><mn>5</mn><mn>1</mn></mrow></mtd><mtd><mrow><mo>−</mo><mn>2</mn><mi mathvariant="normal">.</mi><mn>4</mn><mn>2</mn><mn>8</mn><mn>5</mn><mn>9</mn><mn>2</mn><mn>2</mn><mn>0</mn><mn>5</mn><mn>0</mn></mrow></mtd><mtd><mrow><mo>+</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>4</mn><mn>5</mn><mn>0</mn><mn>5</mn><mn>9</mn><mn>3</mn><mn>7</mn><mn>0</mn><mn>9</mn><mn>9</mn></mrow></mtd></mtr><mtr><mtd><mrow><mo>+</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>0</mn><mn>2</mn><mn>5</mn><mn>9</mn><mn>0</mn><mn>4</mn><mn>0</mn><mn>3</mn><mn>7</mn><mn>1</mn></mrow></mtd><mtd><mrow><mo>+</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>7</mn><mn>8</mn><mn>2</mn><mn>7</mn><mn>7</mn><mn>1</mn><mn>7</mn><mn>6</mn><mn>6</mn><mn>2</mn></mrow></mtd><mtd><mrow><mo>−</mo><mn>0</mn><mi mathvariant="normal">.</mi><mn>8</mn><mn>0</mn><mn>8</mn><mn>6</mn><mn>7</mn><mn>5</mn><mn>7</mn><mn>6</mn><mn>6</mn><mn>0</mn></mrow></mtd></mtr></mtable><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{M_2} = \begin{pmatrix} +0.2104542553 &amp; +0.7936177850 &amp; -0.0040720468 \\ +1.9779984951 &amp; -2.4285922050 &amp; +0.4505937099 \\ +0.0259040371 &amp; +0.7827717662 &amp; -0.8086757660 \end{pmatrix}</annotation></semantics></math></span></span></span></p><p>The inverse operation, going from Oklab to XYZ is done with the following steps:</p><p><span><span><span><math><semantics><mrow><mrow><mo fence="true">(</mo><mtable><mtr><mtd><mrow><msup><mi>l</mi><mrow><mi mathvariant="normal">′</mi></mrow></msup></mrow></mtd></mtr><mtr><mtd><mrow><msup><mi>m</mi><mrow><mi mathvariant="normal">′</mi></mrow></msup></mrow></mtd></mtr><mtr><mtd><mrow><msup><mi>s</mi><mrow><mi mathvariant="normal">′</mi></mrow></msup></mrow></mtd></mtr></mtable><mo fence="true">)</mo></mrow><mo>=</mo><msup><mrow><msub><mi mathvariant="bold">M</mi><mn mathvariant="bold">2</mn></msub></mrow><mrow><mo>−</mo><mn>1</mn></mrow></msup><mo>×</mo><mrow><mo fence="true">(</mo><mtable><mtr><mtd><mrow><mi>L</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>a</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>b</mi></mrow></mtd></mtr></mtable><mo fence="true">)</mo></mrow><mo separator="true">,</mo><mspace width="2em"></mspace><mrow><mo fence="true">(</mo><mtable><mtr><mtd><mrow><mi>l</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>m</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>s</mi></mrow></mtd></mtr></mtable><mo fence="true">)</mo></mrow><mo>=</mo><mrow><mo fence="true">(</mo><mtable><mtr><mtd><mrow><msup><mrow><mo>(</mo><msup><mi>l</mi><mrow><mi mathvariant="normal">′</mi></mrow></msup><mo>)</mo></mrow><mrow><mn>3</mn></mrow></msup></mrow></mtd></mtr><mtr><mtd><mrow><msup><mrow><mo>(</mo><msup><mi>m</mi><mrow><mi mathvariant="normal">′</mi></mrow></msup><mo>)</mo></mrow><mrow><mn>3</mn></mrow></msup></mrow></mtd></mtr><mtr><mtd><mrow><msup><mrow><mo>(</mo><msup><mi>s</mi><mrow><mi mathvariant="normal">′</mi></mrow></msup><mo>)</mo></mrow><mrow><mn>3</mn></mrow></msup></mrow></mtd></mtr></mtable><mo fence="true">)</mo></mrow><mo separator="true">,</mo><mspace width="2em"></mspace><mrow><mo fence="true">(</mo><mtable><mtr><mtd><mrow><mi>X</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>Y</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>Z</mi></mrow></mtd></mtr></mtable><mo fence="true">)</mo></mrow><mo>=</mo><msup><mrow><msub><mi mathvariant="bold">M</mi><mn mathvariant="bold">1</mn></msub></mrow><mrow><mo>−</mo><mn>1</mn></mrow></msup><mo>×</mo><mrow><mo fence="true">(</mo><mtable><mtr><mtd><mrow><mi>l</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>m</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>s</mi></mrow></mtd></mtr></mtable><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\begin{pmatrix} l' \\ m' \\ s' \end{pmatrix} = \mathbf{M_2}^{-1} \times \begin{pmatrix} L \\ a \\ b \end{pmatrix},\qquad \begin{pmatrix} l \\ m \\ s \end{pmatrix} = \begin{pmatrix} {(l')}^{3} \\ {(m')}^{3} \\ {(s')}^{3} \end{pmatrix},\qquad \begin{pmatrix} X \\ Y \\ Z \end{pmatrix} = \mathbf{M_1}^{-1} \times \begin{pmatrix} l \\ m \\ s \end{pmatrix}</annotation></semantics></math></span></span></span></p><h4 id="converting-from-linear-srgb-to-oklab">Converting from linear sRGB to Oklab <a href="#converting-from-linear-srgb-to-oklab"><span><svg viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" enable-background="new 0 0 512 512" version="1.1" xml:space="preserve" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M459.654,233.373l-90.531,90.5c-49.969,50-131.031,50-181,0c-7.875-7.844-14.031-16.688-19.438-25.813  l42.063-42.063c2-2.016,4.469-3.172,6.828-4.531c2.906,9.938,7.984,19.344,15.797,27.156c24.953,24.969,65.563,24.938,90.5,0  l90.5-90.5c24.969-24.969,24.969-65.563,0-90.516c-24.938-24.953-65.531-24.953-90.5,0l-32.188,32.219  c-26.109-10.172-54.25-12.906-81.641-8.891l68.578-68.578c50-49.984,131.031-49.984,181.031,0  C509.623,102.342,509.623,183.389,459.654,233.373z M220.326,382.186l-32.203,32.219c-24.953,24.938-65.563,24.938-90.516,0  c-24.953-24.969-24.953-65.563,0-90.531l90.516-90.5c24.969-24.969,65.547-24.969,90.5,0c7.797,7.797,12.875,17.203,15.813,27.125  c2.375-1.375,4.813-2.5,6.813-4.5l42.063-42.047c-5.375-9.156-11.563-17.969-19.438-25.828c-49.969-49.984-131.031-49.984-181.016,0  l-90.5,90.5c-49.984,50-49.984,131.031,0,181.031c49.984,49.969,131.031,49.969,181.016,0l68.594-68.594  C274.561,395.092,246.42,392.342,220.326,382.186z"></path></svg><span></span></span></a></h4><p>Since this will be a common use case, here is the code to convert linear sRGB values to Oklab and back. To compute linear sRGB values, see <a href="https://bottosson.github.io/posts/colorwrong/#what-can-we-do%3F">my previous post</a>.</p><p>The code is in C++, but without any fancy features so should be easy to translate. The code is available in public domain, feel free to use it any way you please.</p><pre><code>struct Lab {float L; float a; float b;};
struct RGB {float r; float g; float b;};

Lab linear_srgb_to_oklab(RGB c) 
{
    float l = 0.4121656120f * c.r + 0.5362752080f * c.g + 0.0514575653f * c.b;
    float m = 0.2118591070f * c.r + 0.6807189584f * c.g + 0.1074065790f * c.b;
    float s = 0.0883097947f * c.r + 0.2818474174f * c.g + 0.6302613616f * c.b;

    float l_ = cbrtf(l);
    float m_ = cbrtf(m);
    float s_ = cbrtf(s);

    return {
        0.2104542553f*l_ + 0.7936177850f*m_ - 0.0040720468f*s_,
        1.9779984951f*l_ - 2.4285922050f*m_ + 0.4505937099f*s_,
        0.0259040371f*l_ + 0.7827717662f*m_ - 0.8086757660f*s_,
    };
}

RGB oklab_to_linear_srgb(Lab c) 
{
    float l_ = c.L + 0.3963377774f * c.a + 0.2158037573f * c.b;
    float m_ = c.L - 0.1055613458f * c.a - 0.0638541728f * c.b;
    float s_ = c.L - 0.0894841775f * c.a - 1.2914855480f * c.b;

    float l = l_*l_*l_;
    float m = m_*m_*m_;
    float s = s_*s_*s_;

    return {
        + 4.0767245293f*l - 3.3072168827f*m + 0.2307590544f*s,
        - 1.2681437731f*l + 2.6093323231f*m - 0.3411344290f*s,
        - 0.0041119885f*l - 0.7034763098f*m + 1.7068625689f*s,
    };
}
</code></pre><p>This is everything you need to use the Oklab color space! If you need a simple perceptual color space, try it out.</p><p>The rest of the post will go into why a new color space was needed, how it has been constructed and how it compares with existing color spaces.</p><hr><p>What properties does a perceptual color space need to satisfy to be useful for image processing? The answer to this is always going to be a bit subjective, but based on my experience, these are a good set of requirements:</p><blockquote><ul><li><strong>Should be an opponent color space</strong>, similar to for example <a href="https://en.wikipedia.org/wiki/CIELAB_color_space">CIELAB</a>.</li><li><strong>Should predict lightness, chroma and hue well</strong>. <span><span><math><semantics><mrow><mi>L</mi></mrow><annotation encoding="application/x-tex">L</annotation></semantics></math></span></span>, <span><span><math><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span></span> and <span><span><math><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span></span> should be perceived as orthogonal, so one can be altered without affecting the other two. This is useful for things like turning an image black and white and increasing colorfulness without introducing hue shifts etc.</li><li><strong>Blending two colors should result in even transitions</strong>. The transition colors should appear to be in between the blended colors (e.g. passing through a warmer color than either original color is not good).</li><li><strong>Should assume a D65 whitepoint</strong>. This is what common color spaces like sRGB, rec2020 and Display P3 uses.</li><li><strong>Should behave well numerically</strong>. The model should be easy to compute, numerically stable and differentiable.</li><li><strong>Should assume normal well lit viewing conditions</strong>. The complexity of supporting different viewing conditions is not practical in most applications. Other models could be used in conjunction if this is needed in some case.</li><li><strong>If the scale/exposure of colors are changed, the perceptual coordinates should just be scaled by a factor</strong>. More complex models that depend on absolute luminance should be avoided since the viewing conditions can not be accurately controlled and incorrect behavior would be confusing.</li></ul></blockquote><h3 id="what-about-existing-models%3F">What about existing models? <a href="#what-about-existing-models%3F"><span><svg viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" enable-background="new 0 0 512 512" version="1.1" xml:space="preserve" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M459.654,233.373l-90.531,90.5c-49.969,50-131.031,50-181,0c-7.875-7.844-14.031-16.688-19.438-25.813  l42.063-42.063c2-2.016,4.469-3.172,6.828-4.531c2.906,9.938,7.984,19.344,15.797,27.156c24.953,24.969,65.563,24.938,90.5,0  l90.5-90.5c24.969-24.969,24.969-65.563,0-90.516c-24.938-24.953-65.531-24.953-90.5,0l-32.188,32.219  c-26.109-10.172-54.25-12.906-81.641-8.891l68.578-68.578c50-49.984,131.031-49.984,181.031,0  C509.623,102.342,509.623,183.389,459.654,233.373z M220.326,382.186l-32.203,32.219c-24.953,24.938-65.563,24.938-90.516,0  c-24.953-24.969-24.953-65.563,0-90.531l90.516-90.5c24.969-24.969,65.547-24.969,90.5,0c7.797,7.797,12.875,17.203,15.813,27.125  c2.375-1.375,4.813-2.5,6.813-4.5l42.063-42.047c-5.375-9.156-11.563-17.969-19.438-25.828c-49.969-49.984-131.031-49.984-181.016,0  l-90.5,90.5c-49.984,50-49.984,131.031,0,181.031c49.984,49.969,131.031,49.969,181.016,0l68.594-68.594  C274.561,395.092,246.42,392.342,220.326,382.186z"></path></svg><span></span></span></a></h3><p>Let’s look at existing models and how they stack up against these requirements. Further down there are graphs that illustrate some of these issues.</p><blockquote><ul><li><strong><a href="https://en.wikipedia.org/wiki/CIELAB_color_space">CIELAB</a> and <a href="https://en.wikipedia.org/wiki/CIELUV">CIELUV</a></strong> – Largest issue is their inability to predict hue. In particular blue hues are predicted badly. Other smaller issues exist as well</li><li><strong><a href="https://en.wikipedia.org/wiki/CIECAM02">CIECAM02-UCS</a> and the newer CAM16-UCS</strong> – Does a good job at being perceptually uniform overall, but doesn’t meet other requirements: Bad numerical behavior, it is not scale invariant and blending does not behave well because of its compression of chroma. Hue uniformity is decent, but other models predict it more accurately.</li><li><strong><a href="https://en.wikipedia.org/wiki/OSA-UCS">OSA-UCS</a></strong> – Overall does a good job. The transformation to OSA-UCS lacks an analytical inverse unfortunately which makes it impractical.</li><li><strong><a href="https://scholarworks.rit.edu/theses/2858/">IPT</a></strong> – Does a great job modelling hue uniformity. Doesn’t predict lightness and chroma well unfortunately, but meets all other requirements. Is simple computationally and does not depend on the scale/exposure.</li><li><strong><a href="https://www.osapublishing.org/oe/fulltext.cfm?uri=oe-25-13-15131&amp;id=368272">JzAzBz</a></strong> – Overall does a fairly good job. Designed to have uniform scaling of lightness for HDR data. While useful in some cases this introduces a dependence on the scale/exposure that makes it hard to use in general cases.</li><li><strong><a href="https://en.wikipedia.org/wiki/HSL_and_HSV">HSV</a> representation of sRGB</strong> – Only on this list because it is widely used. Does not meet any of the requirements except having a D65 whitepoint.</li></ul></blockquote><p>So, all in all, all these existing models have drawbacks.</p><p>Out of all of these, two models stand out: CAM16-UCS, for being the model with best properties of perceptual uniformity overall, and IPT for having a simple computational structure that meets all the requirements besides predicting lightness and chroma well.</p><p>For this reason it is reasonable to try to make a new color space, with the same computational structure as IPT, but that performs closer to CAM16-UCS in terms of predicting lightness and chroma. This exploration resulted in Oklab.</p><h3 id="how-oklab-was-derived">How Oklab was derived <a href="#how-oklab-was-derived"><span><svg viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" enable-background="new 0 0 512 512" version="1.1" xml:space="preserve" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M459.654,233.373l-90.531,90.5c-49.969,50-131.031,50-181,0c-7.875-7.844-14.031-16.688-19.438-25.813  l42.063-42.063c2-2.016,4.469-3.172,6.828-4.531c2.906,9.938,7.984,19.344,15.797,27.156c24.953,24.969,65.563,24.938,90.5,0  l90.5-90.5c24.969-24.969,24.969-65.563,0-90.516c-24.938-24.953-65.531-24.953-90.5,0l-32.188,32.219  c-26.109-10.172-54.25-12.906-81.641-8.891l68.578-68.578c50-49.984,131.031-49.984,181.031,0  C509.623,102.342,509.623,183.389,459.654,233.373z M220.326,382.186l-32.203,32.219c-24.953,24.938-65.563,24.938-90.516,0  c-24.953-24.969-24.953-65.563,0-90.531l90.516-90.5c24.969-24.969,65.547-24.969,90.5,0c7.797,7.797,12.875,17.203,15.813,27.125  c2.375-1.375,4.813-2.5,6.813-4.5l42.063-42.047c-5.375-9.156-11.563-17.969-19.438-25.828c-49.969-49.984-131.031-49.984-181.016,0  l-90.5,90.5c-49.984,50-49.984,131.031,0,181.031c49.984,49.969,131.031,49.969,181.016,0l68.594-68.594  C274.561,395.092,246.42,392.342,220.326,382.186z"></path></svg><span></span></span></a></h3><p>To derive Oklab, three datasets were used:</p><ul><li>A generated data set of pairs of colors with the same lightness but random hue and chroma, generated using CAM16 and normal viewing conditions. Colors were limited to be within Pointer’s Gamut – the set of possible surface colors.</li><li>A generated data set of pairs of colors with the same chroma but random hue and lightness, generated using CAM16 and normal viewing conditions. Colors were limited to be within Pointer’s Gamut</li><li>The <a href="https://github.com/nschloe/colorio/blob/master/colorio/data/ebner_fairchild.yaml">uniform perceived hue</a> data used to derive IPT. From this data, colors were combined into pairs of colors with equal perceived hue.</li></ul><p>These datasets can be used to test prediction of lightness, chroma and hue respectively. If a color space accurately models <span><span><math><semantics><mrow><mi>L</mi></mrow><annotation encoding="application/x-tex">L</annotation></semantics></math></span></span>, <span><span><math><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span></span> and <span><span><math><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span></span>, then all pairs in lightness dataset should have the same value for <span><span><math><semantics><mrow><mi>L</mi></mrow><annotation encoding="application/x-tex">L</annotation></semantics></math></span></span>, all pairs in the chroma dataset the same value for <span><span><math><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span></span> and all pairs in the hue dataset the same values for <span><span><math><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span></span>.</p><p>To test a color space it is not possible to simply check the distance in predictions in the tested color space however, since that will depend on the scaling of the color space. It is also not desirable to exactly predict ground truth values for <span><span><math><semantics><mrow><mi>L</mi></mrow><annotation encoding="application/x-tex">L</annotation></semantics></math></span></span>, <span><span><math><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span></span> and <span><span><math><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span></span>, since it is more important that our model has perceptually orthogonal coordinates, than that the model has the same spacing within each coordinate.</p><p>Instead the following approach was used to create an error metric independent of the color space:</p><ul><li>For each dataset all the pairs are converted to the tested color space.</li><li>Coordinates that are supposed to be the same within a pair are swapped to generate a new set of altered pairs:<ul><li>For the lightness dataset, the L coordinates are swapped between the pairs, and so on.</li><li>These altered pair would be equal to the original pair if the model predicts the datasets perfectly.</li></ul></li><li>The perceived distance between the original colors and the altered colors are are computed using <a href="https://en.wikipedia.org/wiki/Color_difference">CIEDE2000</a>.</li><li>The error for each pair is given as the minimum of the two color differences.</li><li>The error for the entire dataset is the root mean squared error of the color differences.</li></ul><p>Oklab was derived by optimizing the parameters of a color space with the same structure as IPT, to get a low error on all the datasets. For completeness, here is the structure of the color space – the parameters to optimize are the 3x3 matrices <span><span><math><semantics><mrow><mrow><msub><mi mathvariant="bold">M</mi><mn mathvariant="bold">1</mn></msub></mrow></mrow><annotation encoding="application/x-tex">\mathbf{M_1}</annotation></semantics></math></span></span> and <span><span><math><semantics><mrow><mrow><msub><mi mathvariant="bold">M</mi><mn mathvariant="bold">2</mn></msub></mrow></mrow><annotation encoding="application/x-tex">\mathbf{M_2}</annotation></semantics></math></span></span> and the positive number <span><span><math><semantics><mrow><mi>γ</mi></mrow><annotation encoding="application/x-tex">\gamma</annotation></semantics></math></span></span>.</p><p><span><span><span><math><semantics><mrow><mrow><mo fence="true">(</mo><mtable><mtr><mtd><mrow><mi>l</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>m</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>s</mi></mrow></mtd></mtr></mtable><mo fence="true">)</mo></mrow><mo>=</mo><mrow><msub><mi mathvariant="bold">M</mi><mn mathvariant="bold">1</mn></msub></mrow><mo>×</mo><mrow><mo fence="true">(</mo><mtable><mtr><mtd><mrow><mi>X</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>Y</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>Z</mi></mrow></mtd></mtr></mtable><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\begin{pmatrix} l \\ m \\ s \end{pmatrix} = \mathbf{M_1} \times \begin{pmatrix} X \\ Y \\ Z \end{pmatrix}</annotation></semantics></math></span></span></span></p><p><span><span><span><math><semantics><mrow><mrow><mo fence="true">(</mo><mtable><mtr><mtd><mrow><mi>L</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>a</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>b</mi></mrow></mtd></mtr></mtable><mo fence="true">)</mo></mrow><mo>=</mo><mrow><msub><mi mathvariant="bold">M</mi><mn mathvariant="bold">2</mn></msub></mrow><mo>×</mo><mrow><mo fence="true">(</mo><mtable><mtr><mtd><mrow><msup><mi>l</mi><mi>γ</mi></msup></mrow></mtd></mtr><mtr><mtd><mrow><msup><mi>m</mi><mi>γ</mi></msup></mrow></mtd></mtr><mtr><mtd><mrow><msup><mi>s</mi><mi>γ</mi></msup></mrow></mtd></mtr></mtable><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\begin{pmatrix} L \\ a \\ b \end{pmatrix} = \mathbf{M_2} \times \begin{pmatrix} l^\gamma \\ m^\gamma \\ s^\gamma \end{pmatrix}</annotation></semantics></math></span></span></span></p><p>A couple of extra constraints were …</p></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bottosson.github.io/posts/oklab/">https://bottosson.github.io/posts/oklab/</a></em></p>]]>
            </description>
            <link>https://bottosson.github.io/posts/oklab/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25525726</guid>
            <pubDate>Thu, 24 Dec 2020 07:34:49 GMT</pubDate>
        </item>
    </channel>
</rss>
