<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sat, 19 Sep 2020 12:29:43 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sat, 19 Sep 2020 12:29:43 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[What happened to all the non-programmers? (2015)]]>
            </title>
            <description>
<![CDATA[
Score 93 | Comments 101 (<a href="https://news.ycombinator.com/item?id=24497470">thread link</a>) | @harporoeder
<br/>
September 16, 2020 | https://www.benkuhn.net/nonprog/ | <a href="https://web.archive.org/web/*/https://www.benkuhn.net/nonprog/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>This week I found myself at yet another dinner party that mysteriously contained only two people who were not involved with the tech industry in some way.</p><p>As I looked around and realized for the hundredth time that I was surrounded by people exactly like me, something inside me snapped. I downloaded the latest <a href="http://www.census.gov/acs/www/data_documentation/public_use_microdata_sample/" target="_blank">American Community Survey microdata</a>, fired up R and started calculating feverishly.</p><p>It turns out that among people who</p><ul><li>are under 35</li><li>live in San Francisco, Berkeley or Oakland</li><li>and have at least a bachelor’s degree</li></ul><p>about 10% have a computer-related occupation. An additional 5% are employed in some other capacity by a strongly computer-related industry.</p><p>That’s not <em>nearly</em> large enough to explain how saturated with coders my social groups are. I have plenty of social circles that are (at least nominally) totally different from my work: contra dancers, people interested in effective altruism, folk musicians, friends from college, and so on. And yet I keep finding myself in the middle of a programmer monoculture. Why?</p><p>As <a href="http://xkcd.com/1480/" target="_blank">Randall Munroe recently suggested</a>, suggests, maybe taking up a sport would help expose me to a broader range of people. But which one? Obviously not football, since I’m barely 150 pounds and don’t like traumatic brain injuries. Preferably a more elegant sport that doesn’t require a bunch of awkward equipment. Maybe Ultimate or rock climbing–</p><p>Wait, crap.</p><p>Part of the problem is that my taste in hobbies is influenced by class lines and subculture in ways that I hadn’t realized before.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> It turns out that even when it’s totally up to me, most of the things I’m interested in are strongly associated with a very particular band of socioeconomic status—a much smaller band than the set of “all bachelor’s degree holders” in my ACS analysis.</p><p>This stronger selection sneaks in when I try to pick a sport based on things like “elegance,” instead of “size of community” or “what I’ve been playing since I was five years old” or whatever other things people might pick sports for. In fact, just the fact that I’m interested in doing sports for leisure is associated with class, since it’s not something that would be so easy for, say, manual laborers or shift workers.</p><p>But I don’t think socioeconomic selection explains all of it. My parents’ friends were similarly selected, but they didn’t all have <em>literally the same job</em>, and the ones that did were usually coworkers—not people they had met socially who bizarrely all happened to work on the same stuff. My friends in other occupations with similar base rates—say, school teachers—don’t wonder where all the non-teachers are at social events. And I don’t even feel like I’m from a similar subculture to many programmers. What else could be going on?</p><ul><li><p>Maybe that crackpot-sounding stuff about the “programmer’s brain” actually has something to it. Maybe programmers are all drawn to the same activities because those activities are friendly to the programmer’s innately logical, systematizing and abstract habits of thought.</p></li><li><p>Programmers could talk about programming too much, or smell bad, or something, so people from other professions are less likely to put up with them at social events.</p></li><li><p>Perhaps the various subcultures of programmers are closer together, and more distinct from other subcultures, than I perceive. Maybe “programmer culture” is less analogous to other single professions and more analogous to “academic culture” or “hippie culture,” where it would be more reasonable to have that be your entire social group.</p></li><li><p>Maybe I miscalculated from the ACS data and there are actually way more programmers than the 10% number suggests.</p></li></ul><p>Unless I’ve miscalculated pretty badly, though, it’s clear that these social bubble effects are way stronger and more tenacious than I would have expected. And this is just one of the axes where it’s <em>obvious</em> that all the variance is being selected out. I wonder what more subtle facts are being selected for this strongly in my social groups?</p><section role="doc-endnotes"><hr><ol><li id="fn:1" role="doc-endnote"><p>When I lived in Boston, the people I associated with were determined mostly by my parents or my private high school/college, which is plenty enough to explain a monoculture without getting into class effects. <a href="#fnref:1" role="doc-backlink">↩︎</a></p></li></ol></section></article></div>]]>
            </description>
            <link>https://www.benkuhn.net/nonprog/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24497470</guid>
            <pubDate>Wed, 16 Sep 2020 20:33:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I suspect many task deadlines are designed to force engineers to work for free]]>
            </title>
            <description>
<![CDATA[
Score 255 | Comments 182 (<a href="https://news.ycombinator.com/item?id=24496219">thread link</a>) | @sT370ma2
<br/>
September 16, 2020 | http://misc-stuff.terraaeon.com/articles/engineering-deadlines.html | <a href="https://web.archive.org/web/*/http://misc-stuff.terraaeon.com/articles/engineering-deadlines.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://misc-stuff.terraaeon.com/articles/engineering-deadlines.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24496219</guid>
            <pubDate>Wed, 16 Sep 2020 19:05:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[433% Keyboard]]>
            </title>
            <description>
<![CDATA[
Score 130 | Comments 116 (<a href="https://news.ycombinator.com/item?id=24495046">thread link</a>) | @_salmon
<br/>
September 16, 2020 | https://relivesight.com/projects/433/ | <a href="https://web.archive.org/web/*/https://relivesight.com/projects/433/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

            <h2>433% Keyboard</h2>
            <p>—「0X://Explanation」<br>
            IT IS FINALLY (mostly) COMPLETED. If anyone has ever heard directly from God Himself, the conception of this keyboard was definitely the message. 450 keys of solid non-mx-browness and
            433% the size of a normal full size, what more could you ask for? This keyboard fits 2 (two) full football fields on it {diagram on page 9 of your textbooks}. and um yeah thats kinda it idk can you see it there isnt much to say.

            {and yes for anyone who is new, i know the images load slow, im using some jankery just bear with it plz and ty}
            </p>
            <p><a target="_blank" href="https://www.reddit.com/r/MechanicalKeyboards/comments/it7a0p/i_present_my_433_ortho_endgame_is_only_a_lie_if/">reddit post</a> - thanks for 13.1k upvotes and 58 awards &lt;3</p>
              <p><a id="back" href="https://relivesight.com/ongoing/">back a page</a></p>
              <p><img src="https://drive.google.com/uc?export=view&amp;id=1OKPmow5-rwRyFS-_zcOYHDpGRSjjKVej" width="500px"></p><p>Specs:</p>
        <ul>
          <li>PCB: ScrabblePad</li>
          <li>Microcontrollers: Teensy2.0++(x2)</li>
          <li>Switches: Gateron Yellows</li>
          <li>Keycaps: xda 9009 from kpreublic (98), dsa dark gray blanks (90), xda light grey blanks (12), cherry relegenadble keycaps (tipro rebrand) (120), dsa "retro beige" (26), cherry beige keycaps (52), dsa black blanks (38), and stroke and structure set keycaps (14)</li>
        </ul>
            
              
             <p>i've acquired all the materials, i intend to 3d print some "feet" for this board and maybe tent it a bit, here are the pcbs:</p>
             <p><img src="https://drive.google.com/uc?export=view&amp;id=1uWil1XZH2ctQViab6xnskC4BIYivAWeG" width="500px"></p><p>this one should be pretty straight forward, i just need some free time to build it. two "scrabblepads" by donutcables btw.</p>
             
             <p>the dautning task beings, and spoiler: i finish it all in one weekend (kinda). well you know what they say, show dont tell (and my hands ache from this build) so heres some pics of the board while i soldered the 450 diodes, switches, etc:</p>
             <p><img src="https://drive.google.com/uc?export=view&amp;id=1tlF20EdGLjFh_IJowFcZ7qy07jmj-w6s" width="300px">
             <img src="https://drive.google.com/uc?export=view&amp;id=1ykB1evyrh2UrNnkfX7z3bR4keEpgLMhG" width="300px">
             <img src="https://drive.google.com/uc?export=view&amp;id=1Ws5bUOHTzRmT6kGS_D4HoMzPZvrE81Hj" width="300px">
             <img src="https://drive.google.com/uc?export=view&amp;id=1pRKCnqxWew30dc5mC4INyfA1pUxMgCOr" width="300px"></p><p>wow! what only took you a couple seconds to look at took me a couple dozen hours, astonishing. well now the simple part (i so naively thought) choosing keycaps!
               lets just skip all of my indecsision and skip to what i finally settled on. a xda 9009 set, dsa dark gray blanks, xda light grey blanks, cherry relegenadble keycaps (tipro rebrand), dsa "retro beige", cherry beige keycaps, dsa black blanks, and stroke and structure set keycaps.
            
              </p>
               <p><img src="https://drive.google.com/uc?export=view&amp;id=1CYfMDgvnOXaQEQv89GwsMRd-nMT4Tl66" width="400px">
               <img src="https://drive.google.com/uc?export=view&amp;id=1SxTfFaIz_Mv9gzYm4qFMZsB8LYYQCbD-" width="200px">
               <img src="https://drive.google.com/uc?export=view&amp;id=1jSCz7vcr3Nc26TKKhYej4uAPvN6-HPih" width="500px">
               <img src="https://drive.google.com/uc?export=view&amp;id=1h-45yK6HDq2VmC7mxl1NMAaWgQM8IGI_" width="500px">
               <img src="https://drive.google.com/uc?export=view&amp;id=1q99gN9PK-m8a6wxMlPnEBEt9rFs3SRws" width="500px"></p><p>alot of cutting and frusturating placement of the paper (relegndable caps) later and its done! here's this board next to some other favorites of mine:</p>
               <p><img src="https://drive.google.com/uc?export=view&amp;id=1iRszdMNP3aFmEIkVCuBkOScToGBlz_Gd" width="300px">
               <img src="https://drive.google.com/uc?export=view&amp;id=1tkfGJU4lo1WCN7LOQSl1MJhVLyvJe55L" width="300px"></p><p>sadly i cant officially call this project done until i add the 3d printed feet and finish the qmk, tho fun fact: i typed this whole post on the board~
                 its honestly not as hard as i thought it would be to switch, its still 123897421987 times better than any staggered non split torture. anyway thanks for reading so far! its been fun~
               </p>

            

   <p><a id="back" href="https://relivesight.com/ongoing/">back a page</a></p>
   <p>┈ ren ​♡</p>


  </div></div>]]>
            </description>
            <link>https://relivesight.com/projects/433/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24495046</guid>
            <pubDate>Wed, 16 Sep 2020 17:36:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Large-scale Abuse of Contact Discovery in Mobile Messengers [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 264 | Comments 79 (<a href="https://news.ycombinator.com/item?id=24494505">thread link</a>) | @sizzle
<br/>
September 16, 2020 | https://encrypto.de/papers/HWSDS21.pdf | <a href="https://web.archive.org/web/*/https://encrypto.de/papers/HWSDS21.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://encrypto.de/papers/HWSDS21.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24494505</guid>
            <pubDate>Wed, 16 Sep 2020 16:51:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Modern Web Applications Stability]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 27 (<a href="https://news.ycombinator.com/item?id=24493865">thread link</a>) | @blazeeboy
<br/>
September 16, 2020 | https://www.emadelsaid.com/on-modern-web-applications-stability/ | <a href="https://web.archive.org/web/*/https://www.emadelsaid.com/on-modern-web-applications-stability/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <div>
    <section dir="auto">
  


  

  <div dir="auto">
    <p>I don’t like how modern web applications are built. Many of the web applications
are too unstable, That you can’t imagine having the system running without a
team supporting it. The fact that we try to automate manual processes then the
automation needs manual intervention defies the purpose. Some companies has an
army of developers if they were to do the business by hand they would make a
better job than the programmed system. There are many reasons for this
situation. One of the reasons is the excessive use of third party dependencies.</p>

<p>Lets take a look on a basic modern web based system, There are several layers
on software running on the machine, starting from firmware to your business
logic.</p>

<p><img src="https://www.emadelsaid.com/images/IMG_20200915_212438.jpg" alt="IMG_20200915_212438.jpg"></p>

<p>I don’t think this is very helpful to understand the gravity of the situation.
There are many actors that are not considered in this picture. Layers are also
missing because they are implicit in other layers. Lets expand these hidden
layers and actors. It will help us understand better why that small Nodejs or
RubyOnRails application we wrote isn’t just one layer in this picture.</p>

<p><img src="https://www.emadelsaid.com/images/IMG_20200915_214548.jpg" alt="IMG_20200915_214548.jpg"></p>

<p>Here are the layers we added this time:</p>

<ul>
  <li>System core utilities</li>
  <li>Other processes your application depends on like “memcached, Redis, MySQL,
Postgres…etc”</li>
  <li>Third party code your application depends on an ORM, Template engine,
pagination library, a library that <a href="https://www.theregister.com/2016/03/23/npm_left_pad_chaos/">pads your string with
spaces</a> just
because.</li>
  <li>Server applications that sits in front of your code handling HTTP and response
compression…etc.</li>
</ul>

<p>For each of these layers there is <strong>at least</strong> one team responsible for
maintaining it.</p>

<p>Again, We missed other layers and people in this picture. Most of the
applications are using external SAAS providers for logs or monitoring or bug
reporting or provide parts of the system functionality that can take more time
to build by the company team. lets add them to the picture along with their
teams.</p>

<p><img src="https://www.emadelsaid.com/images/IMG_20200915_221047.jpg" alt="IMG_20200915_221047.jpg"></p>

<p>This picture is for one application, I won’t expand it to a whole system with
different services and programs that is the reality of all companies.
Lets stick to one application for the sake of simplicity.</p>

<p>So here is the first point I want to make: With every service you use you’re not
just a user, This service is now part of your application, You are held
responsible for it’s behavior and misbehaving. You will inherit bugs in their
system. When this service team is affected by COVID-19 and get reduced to the
point where they can’t fix issues you will be affected too. When They get slower
your application will get slower too. When their service is down your
application will experience malfunction too, Your system and theirs is now
connected. So add external services integration cautiously. By adding an
external system you’re putting your trust in this service team and their ability
in delivering what the service is promising now <strong>and</strong> in the future. This is not
an easy decision and it should be treated as such.</p>

<p><img src="https://www.emadelsaid.com/images/IMG_20200915_224907.jpg" alt="IMG_20200915_224907.jpg"></p>

<p>Now lets move to the direct dependencies of your application. If you’re using
any modern programming language it’ll have a way to package code into reusable
format that could be reused by other applications. one package can use code from
other packages, these packages can use other packages and so on like a tree.</p>

<p><img src="https://www.emadelsaid.com/images/IMG_20200915_231326.jpg" alt="IMG_20200915_231326.jpg"></p>

<p>With every package in this tree we depend on the code inside this package and
the team that maintains it. A freshly generated rails project depends on 74
packages for ruby and <code>Yarn list</code> that lists JavaScript dependencies output 3102
lines, that’s 3176 packages with teams maintaining them and bugs and new
versions all the time.</p>

<p>This is wrong for many reasons. I will list some of them here for the sake of
clarity.</p>

<ul>
  <li>You have put your trust in at least 3176 other developers. You have never met
them, never talked to them, there are no guarantee they will continue to
maintain this package. There are no guarantee they won’t put code in their
package to show <a href="https://www.zdnet.com/article/npm-bans-terminal-ads/">ads in your
terminal</a> or <a href="https://www.trendmicro.com/vinfo/dk/security/news/cybercrime-and-digital-threats/hacker-infects-node-js-package-to-steal-from-bitcoin-wallets">code that
steals your bitcoin wallets
</a>.</li>
  <li>You are not really using all of this code. When someone is writing an open
source package it will suffer sooner or later from <a href="https://en.wikipedia.org/wiki/Feature_creep">feature
creeping</a> You are probably using
couple features of this package and don’t need the rest, but you wanted the
banana and got the whole forest now.</li>
  <li>With every package update you’re inventing unnecessary work for yourself. New
versions of packages are released all the time. Updating your project to <strong>get
the latest bug fixes and features</strong> is usually what people do. Most of the
time because of feature creeping these versions changes are not relevant to
you at all, but you won’t know until you read the change log. If it’s relevant
to your project you’ll need to do an update. if something is deprecated or
changed you’ll need to change your code. So suddenly someone somewhere is
telling you to change your code. That’s part of the control you have over your
code handed over to someone you never talked to or knew.</li>
  <li>When your programming language has a new release you can’t update unless all of
your dependencies are up to date. For ruby 2.7.0 for example some language syntax is
now deprecated and shows warning when you run your project. So to fix that you
either fix it in the package and open a PR with the change or wait for the
maintainer to update it.</li>
  <li>When you encounter a bug in a dependency you will have to understand this
package code, fork, branch, fix rinse and repeat. That requires a some
cooperation from the library maintainer which is most of the time isn’t
possible because most of the open source projects are voluntarily maintained.</li>
  <li>Developing new features or modifying existing features are ordre of magnitude
harder. You’ll need to dig into the documentation of the dependencies looking
for support for this little feature you want to add. That is if there is any
documentation at all for that part of the code. Otherwise you’ll have to dig
in to the library code.</li>
</ul>

<p>This is the second point I want to make: Using external library implies that you
trust the maintainer and you also inherit his decisions about using other
libraries and so forth. This decision should be weighed based on the benefit of
the library and how many of it’s features you’re going to use and other factors
like the maturity and how responsive is the maintainer, please don’t use GitHub
stars as a factor in your decision it’s misleading. And if the part you use from
the library isn’t too big I recommend using the library to save some time and
effort upfront but make sure you get rid of it and implement the part you need.
An example of that is a pagination library like rails “Kaminari” if you’re using
it to save you some time then sure. But keep on your todo list a task to remove
it and implement the feature yourself. An example of libraries that’s hard to
get rid of it “OpenCV” This is something that reimplementing the part you need
probably will be a huge task so it can stay. You’ll need to use your best
judgment to decide between these 2 sides of the spectrum.</p>

<p>I like to think of what I do as building an automated system, I would like this
system to run by itself, keep itself clean and healthy, doesn’t need manual
intervention. If the whole team disappeared out of existence I would like that
system to work for a very long time without any supervision.</p>

<p>More code means more bugs for me to fix, by extension more code that I didn’t write
means more bugs that I probably can’t solve. This is dangerous and shouldn’t be
taken lightly. Extending your code with external libraries or systems can cut
down effort hence the cost of development. But when this is taken lightly it
backfires badly.</p>

<p>HN comments: <a href="https://news.ycombinator.com/item?id=24493865">https://news.ycombinator.com/item?id=24493865</a></p>

  </div>
</section>

<hr>



    </div>
  </section></div>]]>
            </description>
            <link>https://www.emadelsaid.com/on-modern-web-applications-stability/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24493865</guid>
            <pubDate>Wed, 16 Sep 2020 15:56:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Challenging LR Parsing]]>
            </title>
            <description>
<![CDATA[
Score 113 | Comments 39 (<a href="https://news.ycombinator.com/item?id=24492675">thread link</a>) | @dilap
<br/>
September 16, 2020 | https://rust-analyzer.github.io/blog/2020/09/16/challeging-LR-parsing.html | <a href="https://web.archive.org/web/*/https://rust-analyzer.github.io/blog/2020/09/16/challeging-LR-parsing.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Consider this incomplete snippet of Rust code:</p>
<div>
<div>
<pre><code data-lang="rust"><table><tbody><tr><td><pre>1
2
3
4
5
</pre></td><td><pre><span>fn</span> <span>foo</span><span>(</span>

<span>struct</span> <span>S</span> <span>{</span>
   <span>f</span><span>:</span> <span>u32</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>I want to see an LR parser which produces the following syntax tree
(from <a href="https://rust-analyzer.github.io/manual.html#show-syntax-tree"><strong>Show Syntax Tree</strong></a> rust-analyzer command, with whitespace nodes elided for clarity):</p>
<div>
<div>
<pre><code><table><tbody><tr><td><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
</pre></td><td><pre>SOURCE_FILE@0..32
  FN@0..7
    FN_KW@0..2 "fn"
    NAME@3..6
      IDENT@3..6 "foo"
    PARAM_LIST@6..7
      L_PAREN@6..7 "("
  STRUCT@9..31
    STRUCT_KW@9..15 "struct"
    NAME@16..17
      IDENT@16..17 "S"
    RECORD_FIELD_LIST@18..31
      L_CURLY@18..19 "{"
      RECORD_FIELD@23..29
        NAME@23..24
          IDENT@23..24 "f"
        COLON@24..25 ":"
        PATH_TYPE@26..29
          PATH@26..29
            PATH_SEGMENT@26..29
              NAME_REF@26..29
                IDENT@26..29 "u32"
      R_CURLY@30..31 "}"
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>The most error-resilient LR-style parser I know, <a href="https://github.com/tree-sitter/tree-sitter">tree sitter</a>, produces this instead (tree sitter is GLR, this is <strong>not</strong> the style of parsing advocated by the article):</p>
<div>
<div>
<pre><code><table><tbody><tr><td><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
</pre></td><td><pre>source_file [0, 0] - [5, 0])
  ERROR [0, 0] - [4, 1])
    identifier [0, 3] - [0, 6])
    struct_pattern [2, 0] - [4, 1])
      type: type_identifier [2, 0] - [2, 6])
      ERROR [2, 7] - [2, 8])
        identifier [2, 7] - [2, 8])
      field_pattern [3, 3] - [3, 9])
        name: field_identifier [3, 3] - [3, 4])
        pattern: identifier [3, 6] - [3, 9])
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>Note two things about the rust-analyzer’s tree:</p>
<div>
<ul>
<li>
<p>There’s an (incomplete) “function” node for <code>fn foo(</code>.
Unclosed parenthesis doesn’t preclude the parser from recognizing parameter list.</p>
</li>
<li>
<p>Incomplete function does not prevent struct definition from being recognized.</p>
</li>
</ul>
</div>
<p>These are important for IDE support.</p>
<p>For example, suppose that the cursor is just after <code>(</code>.
If we have rust-analyzer’s syntax tree, than we can figure out that we are completing a function parameter.
If we are to get fancy we might find the calls to the (not yet fully written) <code>foo</code>, run type inference to figure out the type of the first argument, and than suggest parameter name &amp; type based on that (not currently implemented — there’s soooooo much yet to be done in rust-analyzer).
And correctly recognizing <code>struct S</code> is important to not break type-inference in the code which uses <code>S</code>.</p>
<p>There’s a lot of literature about error recovery for LR parsers, how come academics haven’t figured this out already?
I have a bold claim to make: error-recovery research in academia is focusing on a problem irrelevant for IDEs.
Specifically, the research is focused on finding “minimal cost repair sequence”:</p>
<div>
<ul>
<li>
<p>a set of edit operations is defined (skip, change or insert token),</p>
</li>
<li>
<p>a “cost” metric is defined to distinguish big and small edits,</p>
</li>
<li>
<p>an algorithm is devised to find the smallest edit which makes the current text parse.</p>
</li>
</ul>
</div>
<p>This is a very academia-friendly problem — there’s a precise mathematical formulation, there’s an obvious brute force solution (try all edits), and there’s ample space for finding polynomial algorithm.</p>
<p>But IDEs don’t care about actually guessing &amp; repairing the text!
They just need to see as much of (possibly incomplete) syntax nodes in the existing text as possible.
When rust-analyzer’s parser produces</p>
<div>
<div>
<pre><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre>  PARAM_LIST@6..7
    L_PAREN@6..7 "("
STRUCT@9..31
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>it doesn’t think “Oh, I need to insert <code>)</code> here to complete the list of parameters”.
Rather, it sees <code>struct</code> and thinks “Oh wow, didn’t expect that! I guess I’ll just stop parsing parameter list right here”.</p>
<p>So, here’s</p>
<div>
<table>
<tbody><tr>
<td>
<i title="Important"></i>
</td>
<td>
<p>First Challenge</p>
Design error <em>resilient</em> (and not just error <em>recovering</em>) LR parsing algorithm.
</td>
</tr>
</tbody></table>
</div>
<p>Note that error resilience is a topic orthogonal to error reporting.
I haven’t payed much attention to error reporting (in my experience, synchronous reporting of syntax errors in the editor compensates for bad syntax error messages), but it might be the case that MCRS are a good approach to there.</p>
</div></div>]]>
            </description>
            <link>https://rust-analyzer.github.io/blog/2020/09/16/challeging-LR-parsing.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24492675</guid>
            <pubDate>Wed, 16 Sep 2020 13:48:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Direct sales for SaaS startups – our experience and tips]]>
            </title>
            <description>
<![CDATA[
Score 145 | Comments 18 (<a href="https://news.ycombinator.com/item?id=24492609">thread link</a>) | @pau_alcala
<br/>
September 16, 2020 | https://blog.palabra.io/learning-to-listen-direct-sales-tips-for-early-stage-startups | <a href="https://web.archive.org/web/*/https://blog.palabra.io/learning-to-listen-direct-sales-tips-for-early-stage-startups">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><em>By Pau Alcalá - Co-founder of Palabra</em></p><p>While finding product-market fit for <a href="https://www.palabra.io/?utm_medium=direct-sales-tips-startups&amp;utm_source=blog">Palabra</a>, our marketing strategy was exclusively organic and our first sales came from 1-1 conversations with potential users. After a month of difficult conversations and failed demos, I learned a very new and innovative approach to direct sales: actually listening to what people are saying. In this post I'll share my experience and some tips to listen to users, in the hopes of saving founders &amp; early startup teams some time and energy.</p><h2>What we mean by direct sales</h2><p>As the name suggest, direct sales means you talk directly to your prospect and try to sell them your solution via a 1-1 conversation. This conversation usually starts by reaching the prospect you think your product would work for, and sharing why you think your solution would be good for them.</p><p>Taking a direct approach is more common for B2B businesses, because the decision to purchase is strategical and the price is higher, which means you get a bigger return for each user you convert. But I think it's a good strategy to follow for any early stage SaaS, because it's an easy and direct way of learning about your users and implementing solutions that work for them.</p><p>The biggest challenges to direct sales is finding the right prospects and knowing how to show them value as quickly as possible. With direct conversations you'll probably get a higher conversion rate than self-served sales, but at a much slower rate.</p><h2>Why direct sales in a SaaS startup?</h2><p>When we launched <a href="https://www.palabra.io/?utm_medium=direct-sales-tips-startups&amp;utm_source=blog">Palabra</a> we had no audience and not enough user data to understand who we should be targeting or how to convert them into paying users. We had two possible paths to follow:</p><ol><li>Awareness-first: Experimenting with low-budget ads or organic strategies in different channels, with different messages to see which stick better. This approach is the startup playbook, feeding the top of the funnel with as many prospects as possible assuming most of them will not end up buying, and learn how to convert them better later on.</li><li>Conversion-first: Spending almost no time to feed the top of the funnel (keep a low stream of leads and prospects) but improving that funnel to have better conversions. Leads would be scarce, but we'd learn how to qualify them and provide value so they are willing to buy and stay around.</li></ol><p>The first path was the riskier for us. First, because we had little experience with paid acquisition, and wouldn't know if our misses would be due to lack of experience or just wrong channels.</p><p>Second, we wanted to engage in deep conversations with users as soon as possible. We didn't really care about general trends, we wanted to actually understand what people were struggling with in email automation, and where to take our product so that it worked for them. That's why we decided to take the second path.</p><p>Our initial strategy was to ask a bunch of questions about people's current email automation strategies and try to turn the initial conversation into a sales pitch. We'd learn fast and get a few sales in the meantime.</p><p>Sounds easy, right? Well, it was not.</p><h2>What a failed sales conversation looks like</h2><p>After my first couple of calls I knew I was doing something wrong, but didn't know what it was. Sign ups were rarely because of my "sales" 1-1s, and every conversation left me with a sour feeling.</p><p>What usually happened was that I got to a call, asked the person a couple of questions about their strategies, and at some point I'd get nervous and start talking a lot. People are usually nice and would listen to what I had to say, but I could feel they weren't really interested, and felt like I was wasting time.</p><p>So what was I doing wrong?</p><p>After talking with my co-founder and a couple of friends in the SaaS industry, I found that I wasn't really paying attention to what prospects were saying. My team would ask questions about our prospects that I didn't know how to answer.</p><p>That meant I wasn't really selling, but I also wasn't learning about our users. I found I had to learn how to listen first, and sell later.</p><h2>How to talk less and sell more</h2><p>Listening to prospects is not at easy as it sounds when you are worried about selling them your solution. Specially if you're in early stage and don't have much experience selling software, it'll be hard to keep a clear mind and letting the user take the conversation where they want to.</p><p>But here's the thing: selling isn't about convincing people to try your product, it's about identifying how your product can solve a problem for them.</p><p>In a direct sales conversation, you should have two take outs:</p><ol><li>Identifying if the person you're talking to has a problem you could solve (the more details the better)</li><li>Communicating clearly how your product is a solution to their problem.</li></ol><p>If you fail at #1, you'll end up trying to convince people who don't actually have a problem you could help them with. Those are not your users, and there's nothing you can do today to make their life easier. Even if you somehow convince them to sign up, they'll probably cancel their subscription, making your churn go up.</p><p>Failing at #2 is usually connected to #1, because the only way of communicating a solution clearly is to understand the problem perfectly. You have to <strong>listen really carefully</strong> to understand what those problems are.</p><p>Most of your conversations with prospects should be about #1. Make a lot of questions. Listen closely and follow up on what isn't clear. Make the other person feel listened to. Worst case scenario, you end up with valuable insights about what problems people have. As an early stage startup, this information is crucial to find product-market fit.</p><p>Here are some lessons I learned while taking a direct sales approach to SaaS. Most of them came from reading <a href="http://momtestbook.com/">The Mom Test</a>, talking to awesome people and experimenting on my own.</p><h2>3 direct sales tips to listen to your users</h2><h3>Writing down what you want to get from the conversation</h3><p>This list should be really short. My initial conversation guide had 15+ questions to get to understand the problem, and then a short demo. It worked kinda fine, but I usually got lost by question 5, and then started thinking about what to ask next instead of listening to the answer.</p><p>The Mom Test suggests you should "prepare your list of 3". Three things you want to get from each conversation, depending on who you'll be talking to. And that was magic.</p><p>In early Palabra demos, when I asked to have a quick chat to someone in a startup, I usually had three different scenarios:</p><ul><li>The founder talked to me directly, who had no details about the email automation strategies his/her team was using but could provide context.</li><li>I talked to a marketer in the startup, who usually had many years of experience and had tried a bunch of other email automation tools.</li><li>I talked to a technical co-founder or dev, who had a lot of questions about technical aspects of Palabra and had tried different integrations before.</li></ul><p>I prepared three different notes to look at before each conversation, one for each "buyer" persona, and wrote down my list of three.</p><p>I started asking questions that came to mind from listening to what people were saying, and spend almost no time looking at my notes. If I ever felt I was starting to get lost, I just glanced to my list of three for that particular person to check if I was missing something. Freedom.</p><h3>Having a structured set of questions</h3><p>This advice came from a great friend and the <a href="http://sofandrade.com/">best UX designer I've met</a>. She knows all about user interviews, and since I was also trying to learn from our prospects, I knew it would help. Her advice was to divide my questions into chunks or topics I wanted to know about.</p><p>Having differentiated topics gives you flexibility to follow the conversation and not worry about what to ask after each answer. If you ask a question from the first topic and your user's answer goes to a slightly different topic, you can go to that part of your guide and then come back after that's done.</p><p>As an example, this was the structure I ended up using for each guide:</p><ul><li>About them/their job/their goals</li><li>About their emails, what they were using them from</li><li>About their email automation tools, what they were using and how</li><li>About their pains, what was missing from their current tools?</li></ul><p>What usually happened is that my email questions got answers related to tools. So I just moved over to the "tools" set of questions and then looked to see if I was missing something important at the end.</p><p>A smart move was to leave questions about pains for last. By then I usually had enough information about their problem and could offer a clear solution with <a href="https://www.palabra.io/?utm_medium=direct-sales-tips-startups&amp;utm_source=blog">Palabra</a>.</p><p>If we had a solution, I'd briefly tell people why I thought this would work, and offered to show them in a demo. By focusing on their specific solution in the demo, I only showed one feature and not the whole product, which was a much better use of everyone's time.</p><h3>Doing some background research - but still ask people</h3><p>You can't go into a sales pitch without knowing who you're talking to. For B2B sales you need to know about the company and the person you're actually going to talk to. The key here is to use that information wisely.</p><p>I used to start conversations on what I'd learned from their landing page, to let people know I had done my homework. But his was actually making me start with the wrong foot -by talking too much.</p><p>Asking about their company and what they do there gives you inside information you wouldn't get from LinkedIn or a landing page. And it also helps break the ice, since it's an easy answer for anyone.</p><p>My solution was full transparency. I started each conversation by saying I had done a bit of research about them but still wanted to hear from themselves. Then I would ask what they usually do.</p><p>This was incredibly effective. Being honest took away all of my nervousness and allowed me to relax into the conversation. I felt like I had no secrets, I was just telling the truth and asking questions. And I think this works both ways: the person you're talking to will probably trust you more if you're …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.palabra.io/learning-to-listen-direct-sales-tips-for-early-stage-startups">https://blog.palabra.io/learning-to-listen-direct-sales-tips-for-early-stage-startups</a></em></p>]]>
            </description>
            <link>https://blog.palabra.io/learning-to-listen-direct-sales-tips-for-early-stage-startups</link>
            <guid isPermaLink="false">hacker-news-small-sites-24492609</guid>
            <pubDate>Wed, 16 Sep 2020 13:40:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why is Apple acting like an asshole?]]>
            </title>
            <description>
<![CDATA[
Score 543 | Comments 451 (<a href="https://news.ycombinator.com/item?id=24490326">thread link</a>) | @ig0r0
<br/>
September 16, 2020 | https://www.jessesquires.com/blog/2020/09/15/why-is-apple-acting-like-an-asshole/ | <a href="https://web.archive.org/web/*/https://www.jessesquires.com/blog/2020/09/15/why-is-apple-acting-like-an-asshole/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>Today Apple announced <a href="https://www.apple.com/apple-events/september-2020/">at their media event</a> that the final public release of iOS 14 ships tomorrow, which came as quite a shock to all third-party developers.</p>

<!--excerpt-->

<p>This unwelcome surprise comes against the backdrop of dozens of controversies around the App Store — most recently <a href="https://www.theverge.com/2020/6/16/21293419/hey-apple-rejection-ios-app-store-dhh-gangsters-antitrust">Hey.com</a> and <a href="https://daringfireball.net/linked/2020/08/28/apple-terminates-epic-games-account">Epic</a>, but more generally its <a href="https://marco.org/2020/09/11/app-review-changes">painfully confusing</a> and <a href="https://inessential.com/2020/05/10/heads_up_to_rss_reader_authors">arbitrarily applied</a> rules, its incomprehensible <a href="https://mjtsai.com/blog/tag/rejection/">app rejections</a> and their often sudden retractions, app <a href="https://www.macrumors.com/2016/03/07/flexbright-adjust-display-temperature/">approvals followed by sudden removals</a> without explanation, and the general unequal treatment of developers where <a href="https://gizmodo.com/researchers-uber-s-ios-app-had-secret-permissions-that-1819177235">big companies</a> or favorites <a href="https://mjtsai.com/blog/2019/02/27/bbedit-12-6-to-return-to-the-mac-app-store/">get special treatment</a>. It leaves me wondering, what the hell is Apple’s strategy here? This is not a flurry of bad PR for the sake of it. There are serious problems here that need to be addressed — in particular, Developer Relations.</p>

<div>
    
    <div>
        <figure>
            <img src="https://www.jessesquires.com/img/appholes.jpg" title="Appholes" alt="Appholes">
            <div>
                
            </div>
        </figure>
    </div>
    
</div>

<h4>* * *</h4>

<p>Historically, these events announce new hardware and the upcoming release of the next major version of iOS, which is typically made public a few days later or the following week. For as long as I can remember it goes something like this:</p>

<ul>
  <li>Apple hosts a media event on a Tuesday in September.</li>
  <li>Announcements include new iPhones, iPads, and Watches. Or, at least some combination of those. Maybe something about Apple TV.</li>
  <li>All of the new hardware will run the latest version of iOS (or watchOS, or tvOS).</li>
  <li>The next major release of iOS is announced to be shipping on Friday (in a few days) or sometime the following week, like the next Tuesday.</li>
</ul>

<p>But today, Apple announced that iOS 14 is shipping <strong>tomorrow</strong>. This was near the end of the event — at roughly 11:00 AM Pacific time. This means West Coast developers have half a day to put the final touches on their app updates for iOS 14 <strong>AND</strong> get their apps submitted with the just-released Xcode 12 GM <strong>AND</strong> get through App Store review. None of those tasks are trivial, and no one familiar with them would agree that this is a sufficient amount of time to complete them. If you happen to be working on the East Coast, this means you were given just a few hours before the working day was over to get your app ready and submitted. And if you live in Europe or anywhere else in the world, well, go fuck yourself and good luck tomorrow!</p>

<p>On top of this, critical bugs still exist in the latest releases of the SDKs, Xcode 12, and iOS 14. It seems they will not be addressed.</p>

<h4>* * *</h4>

<p>Given the increasingly tenuous relationship that Apple has with developers, I do not understand how it could be in their interest to act like such an asshole right now. Not to mention, it is unlikely that they will even be able to review all of these app submissions in time. We already do not feel valued due to the aforementioned issues, and this is an outright negligent response to developer relationships the company has damaged over the past few years. Announcing that iOS 14 ships tomorrow with virtually no notice to developers is yet another breach of trust, another disappointment, and quite frankly feels like a big ‘fuck you’ to developers. What purpose does it serve to place this last-minute, unnecessary stress on third-party developers?</p>

<p>Who is in charge of iOS releases at Apple that thought this was a good idea? Who is the head of Developer Relations that thought this was a good idea?</p>

<p>To whomever made these decisions: <strong>y’all fucked up. Again.</strong></p>

    </div></div>]]>
            </description>
            <link>https://www.jessesquires.com/blog/2020/09/15/why-is-apple-acting-like-an-asshole/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24490326</guid>
            <pubDate>Wed, 16 Sep 2020 07:26:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bazel For Open-Source C/C++ Libraries Distribution]]>
            </title>
            <description>
<![CDATA[
Score 64 | Comments 58 (<a href="https://news.ycombinator.com/item?id=24490089">thread link</a>) | @todsacerdoti
<br/>
September 15, 2020 | https://liuliu.me/eyes/bazel-for-libraries-distribution-an-open-source-library-author-perspective/ | <a href="https://web.archive.org/web/*/https://liuliu.me/eyes/bazel-for-libraries-distribution-an-open-source-library-author-perspective/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In the past a few days, I’ve been experimenting with Bazel as a library distribution mechanism for <a href="https://github.com/liuliu/ccv">ccv</a>.</p>

<p>I am pretty familiar with hermetic build systems at this point. My main knowledge comes from Buck dating 8 years back. At that time, it never occurred to me such a build system could eventually be a library distribution mechanism. During the same 8 years, NPM has taken over the world. New language-dependent package managers such as Go module, Cargo and Swift Package Manager popularized the concept of using the public repositories (GitHub) as the dependency references. Languages prior to this period, mainly C / C++ are moving to this direction, slowly.</p>

<p><a href="https://github.com/liuliu/ccv">ccv</a> has a simple autoconf based feature detection / configuration system. You would expect the package to work when <code>./configure &amp;&amp; make</code>. However, it never made any serious attempt to be too smart. My initial experience with monorepos at companies strongly influenced the decision to have a simple build system. I fully expect that serious consumers will vendor the library into their monorepo using their own build systems.</p>

<p>This has been true for the past a few years. But as I am finishing up <a href="https://libnnc.org/">nnc</a> and increasingly using that for other closed-source personal projects, maintaining a closed-source <em>monorepo</em> setup for my personal projects while upstreaming fixes is quite an unpleasant experience. On the other hand, <a href="https://libnnc.org/">nnc</a> from the beginning meant to be a low-level implementation. I am expected to have high-level language bindings at some point. Given that I am doing more application-related development with <a href="https://libnnc.org/">nnc</a> in closed-source format now, it feels like the right time.</p>

<p>Although there is no one-true library distribution mechanism for C / C++, there are contenders. From the good-old apt / rpm, to Conan, which has gained some mind-share in the open-source world in recent years.</p>

<p>The choice of Bazel is not accidental. I’ve been doing <a href="https://liuliu.me/eyes/migrating-ios-project-to-bazel-a-real-world-experience/">some Swift development with Bazel</a> and the experience has been positive. Moreover, the choice of high-level binding language for <a href="https://libnnc.org/">nnc</a>, I figured, would be Swift.</p>

<h2 id="configure">Configure</h2>

<p><a href="https://github.com/liuliu/ccv">ccv</a>’s build process, as much as I would rather not, is host-dependent. I use autoconf to detect system-wide libraries such as libjpeg and libpng, to configure proper compiler options. Although <a href="https://github.com/liuliu/ccv">ccv</a> can be used with zero dependency, in that configuration, it can sometimes be slow.</p>

<p>Coming from the monorepo background, Bazel doesn’t have many utilities that are as readily available as in autoconf. You can write automatic configurations in Starlark as <a href="https://docs.bazel.build/versions/master/skylark/repository_rules.html">repository rules</a>, but there is no good documentation on how to write robust ones.</p>

<p>I ended up <a href="https://github.com/liuliu/ccv/blob/unstable/WORKSPACE#L25">letting whoever use ccv to decide how they are going to enable certain features</a>. For things like CUDA, such configuration is not tenable. I ended up copying over <a href="https://github.com/liuliu/rules_cuda">TensorFlow’s CUDA rules</a>.</p>

<h2 id="dependencies">Dependencies</h2>

<p>Good old C / C++ libraries are notoriously indifferent to libraries dependencies v.s. toolchains. Autoconf detects both toolchain configurations as well as available libraries. These types of host dependencies make cross-compilation a skill in itself.</p>

<p>Bazel is excellent for in-tree dependencies. For out-tree dependencies however, there is no established mechanism. The popular way is to write a <a href="https://github.com/protocolbuffers/protobuf/blob/master/protobuf_deps.bzl#L5">repository rules to load relevant dependencies</a>.</p>

<p>This actually works well for me. It is versatile enough to handle cases that <a href="https://github.com/liuliu/ccv/blob/unstable/config/ccv.bzl#L103">have Bazel integrations</a> and <a href="https://github.com/liuliu/dflat/blob/unstable/deps.bzl#L17">have no Bazel integrations</a>.</p>

<h2 id="consume-bazel-dependencies">Consume Bazel Dependencies</h2>

<p>Consumption of the packaged Bazel dependencies then becomes as simple as adding <code>git_repository</code> to the <code>WORKSPACE</code> and call proper <code>&lt;your_library_name&gt;_deps()</code> repository rule.</p>

<p>After packaging <a href="https://libccv.org/">ccv</a> with Bazel, now <a href="https://github.com/liuliu/s4nnc/blob/main/WORKSPACE#L3">Swift for nnc can consume the packaged dependency</a>.</p>

<h2 id="semantic-versioning-challenges">Semantic Versioning Challenges</h2>

<p>While the Bazel-provided library distribution mechanism works well for my case, it is simplistic. For one, there is really no good way to do <a href="https://semver.org/">semantic versioning</a>. It is understandable. Coming from a monorepo culture, it is challenging for anyone to dive into dependency hells of library versioning. A <a href="https://donatstudios.com/Go-v2-Modules">slightly different story happened to Go</a> a while back as well.</p>

<p>It is messy if you want to pin a specific version of the library while your dependencies are not agreeing with you. This is going to be messy regardless in C / C++ world, unless you prelink these extremely carefully. Bazel’s philosophy from what I can see, seems largely on <em>keeping the trunk working</em> side. It is working so far, but one has to wonder whether this can scale if more libraries adopted Bazel as the distribution mechanism.</p>

<h2 id="closing-words">Closing Words</h2>

<p>The past a few months experience with Bazel has been delightful. While I would continue to use language specific tools (pip, Go modules, Cargo, NPM) when doing development in that particular language, Bazel is a capable choice for me when doing cross-language development. Concepts such as <code>workspace</code>, <code>git_repository</code>, <code>http_archive</code> fit well within the larger open-source ecosystem. And most surprisingly, it works for many-repo setup if you ever need to.</p>
</div></div>]]>
            </description>
            <link>https://liuliu.me/eyes/bazel-for-libraries-distribution-an-open-source-library-author-perspective/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24490089</guid>
            <pubDate>Wed, 16 Sep 2020 06:28:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Concurrency Cost Hierarchy]]>
            </title>
            <description>
<![CDATA[
Score 108 | Comments 13 (<a href="https://news.ycombinator.com/item?id=24489829">thread link</a>) | @signa11
<br/>
September 15, 2020 | https://travisdowns.github.io/blog/2020/07/06/concurrency-costs.html | <a href="https://web.archive.org/web/*/https://travisdowns.github.io/blog/2020/07/06/concurrency-costs.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    
<!-- boilerplate 
page.assets: /assets/concurrency-costs
assetpath: /assets/concurrency-costs
tablepath: /misc/tables/concurrency-costs
-->

<h2 id="introduction">Introduction</h2>

<p>Concurrency is hard to get <em>correct</em>, at least for those of us unlucky enough to be writing in languages which expose directly the guts of concurrent hardware: threads and shared memory. Getting concurrency correct <em>and</em> fast is hard, too. Your knowledge about single-threaded optimization often won’t help you: at a micro (instruction) level we can’t simply apply the usual rules of μops, dependency chains, throughput limits, and so on. The rules are different.</p>

<p>If that first paragraph got your hopes up, this second one is here to dash them: I’m not actually going to do a deep dive into the very low level aspects of concurrent performance. There are a lot of things we just don’t know about how atomic instructions and fences execute, and we’ll save that for another day.</p>

<p>Instead, I’m going to describe a higher level taxonomy that I use to think about concurrent performance. We’ll group the performance of concurrent operations into six broad <em>levels</em> running from fast to slow, with each level differing from its neighbors by roughly an order of magnitude in performance.</p>

<p>I often find myself thinking in terms of these categories when I need high performance concurrency: what is the best level I can practically achieve for the given problem? Keeping the levels in mind is useful both during initial design (sometimes a small change in requirements or high level design can allow you to achieve a better level), and also while evaluating existing systems (to better understand existing performance and evaluate the path of least resistance to improvements).</p>

<h3 id="a-real-world-example">A “Real World” Example</h3>

<p>I don’t want this to be totally abstract, so we will use a real-world-if-you-squint<sup id="fnref:realworld" role="doc-noteref"><a href="#fn:realworld">1</a></sup> running example throughout: safely incrementing an integer counter across threads. By <em>safely</em> I mean without losing increments, producing out-of-thin air values, frying your RAM or making more than a minor rip in space-time.</p>

<h3 id="source-and-results">Source and Results</h3>

<p>The source for every benchmark here is <a href="https://github.com/travisdowns/concurrency-hierarchy-bench">available</a>, so you can follow along and even reproduce the results or run the benchmarks on your own hardware. All of the results discussed here (and more) are available in the same repository, and each plot includes a <code>[data table]</code> link to the specific subset used to generate the plot.</p>

<h3 id="hardware">Hardware</h3>

<p>All of the performance results are provided for several different hardware platforms: Intel Skylake, Ice Lake, Amazon Graviton and Graviton 2. However except when I explicitly mention other hardware, the prose refers to the results on Skylake. Although the specific numbers vary, most of the qualitative relationships hold for the hardware too, but <em>not always</em>. Not only does the hardware vary, but the OS and library implementations will vary as well.</p>

<p>It’s almost inevitable that this will be used to compare across hardware (“wow, Graviton 2 sure kicks Graviton 1’s ass”), but that’s not my goal here. The benchmarks are written primarily to tease apart the characteristics of the different levels, and <em>not</em> as a hardware shootout.</p>

<p>Find below the details of the hardware used:</p>

<table>
  <thead>
    <tr>
      <th>Micro-architecture</th>
      <th>ISA</th>
      <th>Model</th>
      <th>Tested Frequency</th>
      <th>Cores</th>
      <th>OS</th>
      <th>Instance Type</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Skylake</td>
      <td>x86</td>
      <td>i7-6700HQ</td>
      <td>2.6 GHz</td>
      <td>4</td>
      <td>Ubuntu 20.04</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>Ice Lake</td>
      <td>x86</td>
      <td>i5-1035G4</td>
      <td>3.3 GHz</td>
      <td>4</td>
      <td>Ubuntu 19.10</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>Graviton</td>
      <td>AArch64</td>
      <td>Cortex-A72</td>
      <td>2.3 GHz</td>
      <td>16</td>
      <td>Ubuntu 20.04</td>
      <td>a1.4xlarge</td>
    </tr>
    <tr>
      <td>Graviton 2</td>
      <td>AArch64</td>
      <td>Neoverse N1</td>
      <td>2.5 GHz</td>
      <td>16<sup id="fnref:g2cores" role="doc-noteref"><a href="#fn:g2cores">2</a></sup></td>
      <td>Ubuntu 20.04</td>
      <td>c6g.4xlarge</td>
    </tr>
  </tbody>
</table>

<h2 id="level-2-contended-atomics">Level 2: Contended Atomics</h2>

<p>You’d probably expect this hierarchy to be introduced from fast to slow, or vice-versa, but we’re all about defying expectations here and we are going to start in the <em>middle</em> and work our way outwards. The middle (rounding down) turns out to be <em>level 2</em> and that’s where we will jump in.</p>

<p>The most elementary way to safely modify any shared object is to use a lock. It mostly <em>just works</em> for any type of object, no matter its structure or the nature of the modifications. Almost any mainstream CPU from the last thirty years has some type of locking<sup id="fnref:parisc" role="doc-noteref"><a href="#fn:parisc">3</a></sup> instruction accessible to userspace.</p>

<p>So our baseline increment implementation will use a simple mutex of type <code>T</code> to protect a plain integer variable:</p>

<div><div><pre><code><span>T</span> <span>lock</span><span>;</span>
<span>uint64_t</span> <span>counter</span><span>;</span>

<span>void</span> <span>bench</span><span>(</span><span>size_t</span> <span>iters</span><span>)</span> <span>{</span>
    <span>while</span> <span>(</span><span>iters</span><span>--</span><span>)</span> <span>{</span>
        <span>std</span><span>::</span><span>lock_guard</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>holder</span><span>(</span><span>lock</span><span>);</span>
        <span>counter</span><span>++</span><span>;</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>We’ll call this implementation <em><abbr title="Uses a std::mutex and std::lock_guard to protect a plain integer counter.">mutex add</abbr></em>, and on my 4 CPU Skylake-S i7-6700HQ machine, when I use the vanilla <code>std::mutex</code> I get the following results for 2 to 4 threads:</p>



<p>The reported value is the median of all trials, and the vertical black error lines at the top of each bar indicate the <em>interdecile range</em>, i.e., the values at the 10th and 90th percentile. Where the error bars don’t show up, it means there is no difference between the p10 and p90 values at all, at least within the limits of the reporting resolution (100 picoseconds).</p>

<p>This shows that the baseline contended cost to modify an integer protected by a lock starts at about 125 nanoseconds for two threads, and grows somewhat with increasing thread count.</p>

<p>I can already hear someone saying: <em>If you are just modifying a single 64-bit integer, skip the lock and just directly use the atomic operations that most ISAs support!</em></p>

<p>Sure, let’s add a couple of variants that do that. The <code>std::atomic&lt;T&gt;</code> template makes this easy: we can wrap any type meeting some basic requirements and then manipulate it atomically. The easiest of all is to use <code>std::atomic&lt;uint64&gt;::operator++()</code><sup id="fnref:post" role="doc-noteref"><a href="#fn:post">4</a></sup> and this gives us <em><abbr title="Uses an atomic increment on a single shared counter.">atomic add</abbr></em>:</p>

<div><div><pre><code><span>std</span><span>::</span><span>atomic</span><span>&lt;</span><span>uint64_t</span><span>&gt;</span> <span>atomic_counter</span><span>{};</span>

<span>void</span> <span>atomic_add</span><span>(</span><span>size_t</span> <span>iters</span><span>)</span> <span>{</span>
    <span>while</span> <span>(</span><span>iters</span><span>--</span><span>)</span> <span>{</span>
        <span>atomic_counter</span><span>++</span><span>;</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>The other common approach would be to use <a href="https://en.wikipedia.org/wiki/Compare-and-swap">compare and swap (<abbr title="Compare-and-swap: an atomic operation implemented on x86 and other CPUs.">CAS</abbr>)</a> to load the existing value, add one and then <abbr title="Compare-and-swap: an atomic operation implemented on x86 and other CPUs.">CAS</abbr> it back if it hasn’t changed. If it <em>has</em> changed, the increment raced with another thread and we try again.</p>

<p>Note that even if you use increment at the source level, the assembly might actually end up using <abbr title="Compare-and-swap: an atomic operation implemented on x86 and other CPUs.">CAS</abbr> if your hardware doesn’t support atomic increment<sup id="fnref:atomicsup" role="doc-noteref"><a href="#fn:atomicsup">5</a></sup>, or if your compiler or runtime just don’t take advantage of atomic operations even though they are available (e.g., see what even the newest version of <a href="https://godbolt.org/z/5h4K7y">icc does</a> for atomic increment, and what Java did for years<sup id="fnref:java" role="doc-noteref"><a href="#fn:java">6</a></sup>). This caveat doesn’t apply to any of our tested platforms, however.</p>

<p>Let’s add a counter implementation that uses <abbr title="Compare-and-swap: an atomic operation implemented on x86 and other CPUs.">CAS</abbr> as described above, and we’ll call it <em><abbr title="Uses a CAS loop to increment a single shared counter.">cas add</abbr></em>:</p>

<div><div><pre><code><span>std</span><span>::</span><span>atomic</span><span>&lt;</span><span>uint64_t</span><span>&gt;</span> <span>cas_counter</span><span>;</span>

<span>void</span> <span>cas_add</span><span>(</span><span>size_t</span> <span>iters</span><span>)</span> <span>{</span>
    <span>while</span> <span>(</span><span>iters</span><span>--</span><span>)</span> <span>{</span>
        <span>uint64_t</span> <span>v</span> <span>=</span> <span>cas_counter</span><span>.</span><span>load</span><span>();</span>
        <span>while</span> <span>(</span><span>!</span><span>cas_counter</span><span>.</span><span>compare_exchange_weak</span><span>(</span><span>v</span><span>,</span> <span>v</span> <span>+</span> <span>1</span><span>))</span>
            <span>;</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Here’s what these look like alongside our existing <code>std::mutex</code> benchmark:</p>



<p>The first takeaway is that, at least in this <em>unrealistic maximum contention</em> benchmark, using <abbr title="Uses an atomic increment on a single shared counter.">atomic add</abbr> (<a href="https://www.felixcloutier.com/x86/xadd"><code>lock xadd</code></a> at the hardware level) is significantly better than <abbr title="Compare-and-swap: an atomic operation implemented on x86 and other CPUs.">CAS</abbr>. The second would be that <code>std::mutex</code> doesn’t come out looking all that bad on Skylake. It is only slightly worse than the <abbr title="Compare-and-swap: an atomic operation implemented on x86 and other CPUs.">CAS</abbr> approach at 2 cores and beats it at 3 and 4 cores. It is slower than the atomic increment approach, but less than three times as slow and seems to be scaling in a reasonable way.</p>

<p>All of these operations are belong to <em>level 2</em> in the hierarchy. The primary characteristic of level 2 is that they make a <em>contended access</em> to a shared variable. This means that at a minimum, the line containing the data needs to move out to the caching agent that manages coherency<sup id="fnref:l3" role="doc-noteref"><a href="#fn:l3">7</a></sup>, and then back up to the core that will receive ownership next. That’s about 70 cycles minimum just for that operation<sup id="fnref:inter" role="doc-noteref"><a href="#fn:inter">8</a></sup>.</p>

<p>Can it get slower? You bet it can. <em>Way</em> slower.</p>

<h3 id="level-3-system-calls">Level 3: System Calls</h3>

<p>The next level up (“up” is not good here…) is level 3. The key characteristic of implementations at this level is that they make a <em>system call on almost every operation</em>.</p>

<p>It is easy to write concurrency primitives that make a system call <em>unconditionally</em> (e.g., a lock which always tries to wake waiters via a <code>futex(2)</code> call, even if there aren’t any), but we won’t look at those here. Rather we’ll take a look at a case where the fast path is written to avoid a system call, but the design or way it is used implies that such a call usually happens anyway.</p>

<p>Specifically, we are going to look at some <em>fair locks</em>. Fair locks allow threads into the critical section in the same order they began waiting. That is, when the critical section becomes available, the thread that has been waiting the longest is given the chance to take it.</p>

<p>Sounds like a good idea, right? Sometimes yes, but as we will see it can have significant performance implications.</p>

<p>On the menu are three different fair locks.</p>

<p>The first is a <a href="https://en.wikipedia.org/wiki/Ticket_lock">ticket lock</a> with a <code>sched_yield</code> in the spin loop. The idea of the yield is to give other threads which may hold the lock time to run. This <code>yield()</code> approach is publicly frowned upon by concurrency experts<sup id="fnref:notwhat" role="doc-noteref"><a href="#fn:notwhat">9</a></sup>, who then sometimes go right ahead and use it anyway.</p>

<p>We will call it <abbr title="A ticket lock that calls sched_yield in a spin loop while waiting for its turn.">ticket yield</abbr> and it looks like this:</p>



<div><div><pre><code><span>/**
 * A ticket lock which uses sched_yield() while waiting
 * for the ticket to be served.
 */</span>
<span>class</span> <span>ticket_yield</span> <span>{</span>
    <span>std</span><span>::</span><span>atomic</span><span>&lt;</span><span>size_t</span><span>&gt;</span> <span>dispenser</span><span>{},</span> <span>serving</span><span>{};</span>

<span>public:</span>
    <span>void</span> <span>lock</span><span>()</span> <span>{</span>
        <span>auto</span> <span>ticket</span> <span>=</span> <span>dispenser</span><span>.</span><span>fetch_add</span><span>(</span><span>1</span><span>,</span> <span>std</span><span>::</span><span>memory_order_relaxed</span><span>);</span>

        <span>while</span> <span>(</span><span>ticket</span> <span>!=</span> <span>serving</span><span>.</span><span>load</span><span>(</span><span>std</span><span>::</span><span>memory_order_acquire</span><span>))</span>
            <span>sched_yield</span><span>();</span>
    <span>}</span>

    <span>void</span> <span>unlock</span><span>()</span> <span>{</span>
        <span>serving</span><span>.</span><span>store</span><span>(</span><span>serving</span><span>.</span><span>load</span><span>()</span> <span>+</span> <span>1</span><span>,</span> <span>std</span><span>::</span><span>memory_order_release</span><span>);</span>
    <span>}</span>
<span>};</span>
</code></pre></div></div>

<p>Let’s plot the performance results for this lock alongside the existing approaches:</p>



<p>This is level 3 visualized: it is an order of magnitude slower than the level 2 approaches. The slowdown comes from the <code>sched_yield</code> call: this is a system call and these are generally on the order of 100s of nanoseconds<sup id="fnref:spectre" role="doc-noteref"><a href="#fn:spectre">10</a></sup>, and it shows in the results.</p>

<p>This lock <em>does</em> have a fast path where <code>sched_yield</code> isn’t called: if the lock is available, no spinning occurs and <code>sched_yield</code> is never called. However, the combination of being a <em>fair</em> lock and the high contention in this test means that a lock convoy quickly forms (we’ll describe this in more detail later) and so the spin loop is entered basically …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://travisdowns.github.io/blog/2020/07/06/concurrency-costs.html">https://travisdowns.github.io/blog/2020/07/06/concurrency-costs.html</a></em></p>]]>
            </description>
            <link>https://travisdowns.github.io/blog/2020/07/06/concurrency-costs.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24489829</guid>
            <pubDate>Wed, 16 Sep 2020 05:30:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Python's Innards: Introduction (2010)]]>
            </title>
            <description>
<![CDATA[
Score 144 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24489604">thread link</a>) | @johnsonjo
<br/>
September 15, 2020 | https://tech.blog.aknin.name/2010/04/02/pythons-innards-introduction/ | <a href="https://web.archive.org/web/*/https://tech.blog.aknin.name/2010/04/02/pythons-innards-introduction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<p>A friend once said to me: <q>You know, to some people, C is just a bunch of macros that expand to assembly</q>. It’s been years ago (smartasses: it was also before <tt>llvm</tt>, ok?), but the sentence stuck with me. Do <em>Kernighan and Ritchie</em> really look at a C program and see assembly code? Does <em>Tim Berners-Lee</em> surf the Web any differently than you and me? And what on earth <em>did</em> <em>Keanu Reeves</em> see when he looked at all of that funky green gibberish soup, anyway? No, seriously, what the heck <em>did</em> he see there?! Uhm, back to the program. Anyway, what does Python look like in <em>Guido van Rossum</em>‘s<sup>1</sup> eyes?</p>
<p>This post marks the beginning of what should develop to a <a href="https://tech.blog.aknin.name/tag/pythons-innards/">series</a> on Python’s internals, I’m writing it since I believe that explaining something is the best way to grok it, and I’d very much like to be able to visualize more of Python’s ‘funky green gibberish soup’ as I read Python code. On the curriculum is mainly <em>CPython</em>, mainly <em>py3k</em>, mainly <em>bytecode evaluation</em> (I’m not a big compilation fan) – but practically everything around executing Python and Python-like code (<em>Unladen Swallow</em>, <em>Jython</em>, <em>Cython</em>, etc) might turn out to be fair game in this series. For the sake of brevity and my sanity, when I say <em>Python</em>, I mean <em>CPython</em> unless noted otherwise. I also assume a POSIX-like OS or (if and where it matters) Linux, unless otherwise noted. You should read this if you want to know how Python works. You should read this if you want to contribute to CPython. You should read this to find all the mistakes I’ll make and snicker at me behind me back or write snide comments. I realize it’s just <em>your</em> particular way to show affection.</p>
<p>I gather I’ll glean pretty much everything I write about from Python’s source or, occasionally, other fine materials (documentation, especially <a href="http://docs.python.org/py3k/c-api/index.html">this</a> and <a href="http://docs.python.org/py3k/extending/index.html">that</a>, certain PyCon lectures, <a href="https://tech.blog.aknin.name/2010/05/07/searching-mailing-list-archives-offline/">searching</a> <a href="http://mail.python.org/mailman/listinfo/python-dev">python-dev</a>, etc). Everything is out there, but I do hope my efforts at putting it all in one place to which you can RSS-subscribe will make your journey easier. I assume the reader knows some C, some OS theory, a bit less than some assembly (any architecture), a bit more than some Python and has reasonable UNIX fitness (i.e., feels comfortable installing something from source). Don’t be afraid if you’re not reasonably conversant in one (or more) of these, but I can’t promise smooth sailing, either. Also, if you don’t have a working toolchain to do Python development, maybe you’d like to head over <a href="https://tech.blog.aknin.name/2010/04/08/contributing-to-python/">here</a> and do as it says on the second paragraph (and onwards, as relevant).</p>
<p>Let’s start with something which I assume you already know, but I think is important, at least to the main way I understand… well, everything that I do understand. I look at it as if I’m looking at a machine. It’s easy in Python’s case, since Python relies on a Virtual Machine to do what it does (like many other interpreted languages). Be certain you understand “<a href="http://en.wikipedia.org/wiki/Virtual_machine#Process_virtual_machines">Virtual Machine</a>” correctly in this context: think more like JVM and less like VirtualBox (very technically, they’re the same, but in the real world we usually differentiate these two kinds of VMs). I find it easiest to understand “Virtual Machine” literally – it’s a machine built from software. Your CPU is just a complex electronic machine which receives all input (machine code, data), it has a state (registers), and based on the input and its state it will output stuff (to RAM or a Bus), right? Well, CPython is a machine built from software components that has a state and processes instructions (different implementations may use rather different instructions). This software machine operates in the process hosting the Python interpreter. Keep this in mind; I like the <a href="http://en.wikipedia.org/wiki/Turing_machine">machine</a> metaphor (as I explain in minute details <a href="https://tech.blog.aknin.name/2010/07/04/pythons-innards-for-my-wife/">here</a>).</p>
<p>That said, let’s start with a bird’s eye overview of what happens when you do this: <kbd>$ python -c 'print("Hello, world!")'</kbd>. Python’s binary is executed, the standard C library initialization which pretty much any process does happens and then the main function starts executing (see its source, <kbd>./Modules/python.c: main</kbd>, which soon calls <kbd>./Modules/main.c: Py_Main</kbd>). After some mundane initialization stuff (parse arguments, see if environment variables should affect behaviour, assess the situation of the standard streams and act accordingly, etc), <a href="http://docs.python.org/c-api/init.html#Py_Initialize">./Python/pythonrun.c: Py_Initialize</a> is called. In many ways, this function is what ‘builds’ and assembles together the pieces needed to run the CPython machine and makes ‘a process’ into ‘a process with a Python interpreter in it’. Among other things, it creates two very important Python data-structures: the <strong>interpreter state</strong> and <strong>thread state</strong>. It also creates the built-in <strong>module</strong> <a href="http://docs.python.org/library/sys.html">sys</a> and the module which hosts all <a href="http://docs.python.org/library/functions.html#built-in-functions">builtins</a>. At a later post(s) we will cover all these in depth.</p>
<p>With these in place, Python will do one of several things based on how it was executed. Roughly, it will either execute a string (the <kbd>-c</kbd> option), execute a module as an executable (the <kbd>-m</kbd> option), or execute a file (passed explicitly on the commandline or passed by the kernel when used as an interpreter for a script) or run its <a href="http://en.wikipedia.org/wiki/Read-eval-print_loop">REPL</a> loop (this is more a special case of the file to execute being an interactive device). In the case we’re currently following, it will execute a single string, since we invoked it with <kbd>-c</kbd>. To execute this single string, <kbd>./Python/pythonrun.c: PyRun_SimpleStringFlags</kbd> is called. This function creates the <kbd>__main__</kbd> <strong>namespace</strong>, which is ‘where’ our string will be executed (if you run <kbd>$ python -c 'a=1; print(a)'</kbd>, where is <kbd>a</kbd> stored? in this namespace). After the namespace is created, the string is executed in it (or rather, interpreted or <em>evaluated</em> in it). To do that, you must first transform the string into something that machine can work on.</p>
<p>As I said, I’d rather not focus on the innards of Python’s parser/compiler at this time. I’m not a compilation expert, I’m not entirely interested in it, and as far as I know, Python doesn’t have significant Compiler-Fu beyond the basic CS compilation course. We’ll do a (very) fast overview of what goes on here, and may return to it later only to inspect visible CPython behaviour (see the <a href="http://docs.python.org/reference/simple_stmts.html#the-global-statement">global</a> statement, which is said to affect parsing, for instance). So, the parser/compiler stage of <kbd>PyRun_SimpleStringFlags</kbd> goes largely like this: tokenize and create a <a href="http://en.wikipedia.org/wiki/Concrete_syntax_tree">Concrete Syntax Tree</a> (CST) from the code, transorm the CST into an <a href="http://en.wikipedia.org/wiki/Abstract_syntax_tree">Abstract Syntax Tree</a> (AST) and finally compile the AST into a <strong>code object</strong> using <kbd>./Python/ast.c: PyAST_FromNode</kbd>. For now, think of the code object as a binary string of machine code that Python VM’s ‘machinary’ can operate on – so now we’re ready to do interpretation (again, <em>evaluation</em> in Python’s parlance).</p>
<p>We have an (almost) empty <kbd>__main__</kbd>, we have a code object, we want to evaluate it. Now what? Now this line: <kbd>Python/pythonrun.c: run_mod, v = PyEval_EvalCode(co, globals, locals);</kbd> does the trick. It receives a code object and a namespace for <strong>globals</strong> and for <strong>locals</strong> (in this case, both of them will be the newly created <kbd>__main__</kbd> namespace), creates a <strong>frame object</strong> from these and executes it. You remember previously that I mentioned that <kbd>Py_Initialize</kbd> creates a thread state, and that we’ll talk about it later? Well, back to that for a bit: each Python thread is represented by its own thread state, which (among other things) points to the stack of currently executing frames. After the frame object is created and placed at the top of the thread state stack, it (or rather, the byte code pointed by it) is evaluated, opcode by opcode, by means of the (rather lengthy) <kbd>./Python/ceval.c: PyEval_EvalFrameEx</kbd>.</p>
<p><kbd>PyEval_EvalFrameEx</kbd> takes the frame, extracts opcode (and operands, if any, we’ll get to that) after opcode, and executes a short piece of C code matching the opcode. Let’s take a closer look at what these “opcodes” look like by disassembling a bit of compiled Python code:</p>
<pre title="">&gt;&gt;&gt; from dis import dis # ooh! a handy disassembly function!
&gt;&gt;&gt; co = compile("spam = eggs - 1", "&lt;string&gt;", "exec")
&gt;&gt;&gt; dis(co)
  1           0 LOAD_NAME                0 (eggs)
              3 LOAD_CONST               0 (1)
              6 BINARY_SUBTRACT     
              7 STORE_NAME               1 (spam)
             10 LOAD_CONST               1 (None)
             13 RETURN_VALUE        
&gt;&gt;&gt; 
</pre>
<p>…even without knowing much about Python’s bytecode, this is reasonably readable. You “load” the name <kbd>eggs</kbd> (where do you load it from? where do you load it to? soon), and also load a constant value (<kbd>1</kbd>), then you do a “binary subtract” (what do you mean ‘binary’ in this context? between which operands?), and so on and so forth. As you might have guessed, the names are “loaded” from the <kbd>globals</kbd> and <kbd>locals</kbd> namespaces we’ve seen earlier, and they’re loaded onto an operand stack (not to be confused with the stack of running frames), which is exactly where the binary subtract will pop them from, subtract one from the other, and put the result back on that stack. “Binary subtract” just means this is a subtraction opcode that has two operands (hence it is “binary”, this is not to say the operands are binary numbers made of ‘0’s and ‘1’s).</p>
<p>You can go look at <kbd>PyEval_EvalFrameEx</kbd> at <kbd>./Python/ceval.c</kbd> yourself, it’s not a small function by any means. For practical reasons I can’t paste too much code from there in here, but I will just paste the code that runs when a <kbd>BINARY_SUBTRACT</kbd> opcode is found, I think it really illustrates things:</p>
<pre title="">        TARGET(BINARY_SUBTRACT)
            w = POP();
            v = TOP();
            x = PyNumber_Subtract(v, w);
            Py_DECREF(v);
            Py_DECREF(w);
            SET_TOP(x);
            if (x != NULL) DISPATCH();
            break;
</pre>
<p>…pop something, take the top (of the operand stack), call a C function called PyNumber_Subtract() on these things, do something we still don’t understand (but will in due time) called “Py_DECREF” on both, set the top of the stack to the result of the subtraction (overwriting the previous top) and then do something else we don’t understand if x is not null, which is to do a …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tech.blog.aknin.name/2010/04/02/pythons-innards-introduction/">https://tech.blog.aknin.name/2010/04/02/pythons-innards-introduction/</a></em></p>]]>
            </description>
            <link>https://tech.blog.aknin.name/2010/04/02/pythons-innards-introduction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24489604</guid>
            <pubDate>Wed, 16 Sep 2020 04:43:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Go’s Major Versioning Sucks – From a Fanboy]]>
            </title>
            <description>
<![CDATA[
Score 165 | Comments 160 (<a href="https://news.ycombinator.com/item?id=24488745">thread link</a>) | @lanecwagner
<br/>
September 15, 2020 | https://qvault.io/2020/09/15/gos-major-version-handling-sucks-from-a-fanboy/ | <a href="https://web.archive.org/web/*/https://qvault.io/2020/09/15/gos-major-version-handling-sucks-from-a-fanboy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			
<p>I’m normally a fan of the rigidity within the Go toolchain. In fact, we use Go on the <a href="https://app.qvault.io/dashboard/courses">front and backend at Qvault</a>. It’s wonderful to have standardized formatting, vetting, and testing across the entire language. The first real criticism I’ve had is with the way Go modules handle major versions. It’s over-the-top opinionated and slows down development in a significant number of scenarios.</p>



<h2>Refresher on “Go Mod”</h2>



<p>Go modules, and the associated commands <code>go mod</code> and <code>go get</code> can be thought of as Go’s equivalents to NPM and Yarn. The Go toolchain provides a way to manage dependencies and lock the versions that a collection of code depends on.</p>



<p>One of the most common operations is to update a dependency in an existing module. For example:</p>



<pre><code lang="bash"># update all dependencies
go get -u ./...

# add missing and remove unused dependencies
go mod tidy

# save all dependency code in the project's "vendor" folder
go mod vendor</code></pre>



<h2>Semantic Versioning</h2>



<p>Go modules use git tags and semantic versioning to keep track of the versions of dependencies that are compatible with the module in question. Semantic versioning is a way to format version numbers and it looks like this: <code>v{MAJOR}.{MINOR}.{PATCH}</code>. For example, <code>v1.2.3</code>.</p>



<p>Each number is to be incremented according to the following standards:</p>



<pre><code lang="bash">MAJOR version when you make incompatible API changes,
MINOR version when you add functionality in a backwards compatible manner, and
PATCH version when you make backwards compatible bug fixes.</code></pre>



<h2>Package-Side Problems</h2>



<p>Go has decided that all versions beyond <code>v0</code> and <code>v1</code> are required to use the major version in the module path. There are two ways to accomplish this. </p>



<p><strong>The first and recommended way</strong> is laid out in an example on the <a rel="noreferrer noopener" href="https://blog.golang.org/v2-go-modules#TOC_4." target="_blank">Go Blog</a>:</p>



<blockquote><p>To start development on&nbsp;<code>v2</code>&nbsp;of&nbsp;<code>github.com/googleapis/gax-go</code>, we’ll create a new&nbsp;<code>v2/</code>&nbsp;directory and copy our package into it.</p></blockquote>



<p>In other words, for every major version, we are encouraged to maintain a new copy of the entire codebase. This is also the only way to do it if you want pre-modules users to be able to use your package.</p>



<p><strong>The second way</strong> is to just change the name of your module in <code>go.mod</code>. Fore example, <code>module github.com/lane-c-wagner/go-tinydate</code> would become <code>module github.com/lane-c-wagner/go-tinydate/v2</code>. Besides this not working for older versions of Go, I also find it problematic because it breaks (in my mind) one of the most useful things about module names – they reflect the file path.</p>



<h2>Package-Side Solutions</h2>



<p>Allow package maintainers to specify the major version simply by updating git tags, no module name changes required. There is no need for two sources of truth.</p>



<p>We can enforce safe updating by adding warnings or prompts to the <code>go get</code> CLI. We don’t have to add unnecessary time-consuming policies.</p>



<h2>Client-Side Problems</h2>



<p>When new versions of dependencies are released we have a simple command to get the newest stuff: <code>go get -u</code>. The problem is that this command has no way to automatically update to a new major version. It will only download new minor changes and patches. There isn’t even a console message to inform you that a new major version exists!</p>



<p>That said, the reason for not auto-updating is clear, and to be fair, well-founded:</p>



<blockquote><p>If an old package and a new package have the same import path, the new package must be backwards compatible with the old package.</p><cite><a href="https://research.swtch.com/vgo-import" rel="noopener">Import compatibility rule</a></cite></blockquote>



<p>In other words, we should only increment major versions when making breaking changes, and if breaking changes are made they can’t have the same import path. While this makes sense, I think a simple console warning would have been a better solution than forcing a cumbersome updating strategy on the community.</p>



<p><strong>Another problem </strong>on the client-side is that we don’t only need to update <code>go.mod</code>, but we actually need to <code>grep</code> through our codebase and change each import statement to point to the new major version:</p>



<blockquote><p>Users who wanted to use&nbsp;<code>v2</code>&nbsp;had to change their package imports and module requirements to&nbsp;<code>github.com/googleapis/gax-go/v2</code>.</p></blockquote>



<p>Instead of a few simple CLI commands to get the latest dependencies, we’re making changes to the code itself.</p>



<h3>A Caveat – Diamond Imports</h3>



<p>Using different paths for different major versions makes more sense in situations where we may require two different versions of the same package, you know, <a aria-label="diamond imports (opens in a new tab)" href="https://research.swtch.com/vgo-import#dependency_story" target="_blank" rel="noreferrer noopener nofollow">diamond imports</a> and all that. This is the exception, not the rule, and it seems strange to tap dance around a problem that doesn’t exist in most codebases.</p>



<h2>Client-Side Solution</h2>



<p><code>go get -u</code> should have an additional command line flag to update major versions, and should default to showing a warning that there is a newer major version you don’t have yet.</p>



<p><em>Default</em> import paths should not change between major versions. If a module requires various versions, those <em>extra</em> versions could be flagged by having a different path.</p>



<h2>Why This Sucks For Me</h2>



<p>It is often the case that I want to build a package that has domain-specific logic and will only be used only in services at the small company I work for. For example, we have a repo that holds the <code>struct{}</code> definitions for common entities used across our system.</p>



<p>Occasionally we need to make backward-incompatible changes to those struct definitions. If it were an open-source library we wouldn’t make changes so often, but because it’s internal and we are aware of all the dependencies, we change the names of exported fields <em>regularly</em>. We aren’t changing names because we chose bad ones to begin with, we are usually changing names because requirements from the business change rapidly in a startup. </p>



<p>This means major version changes are a fairly regular occurrence. Some say that we should just stay on <code>v0</code>, and that’s a reasonable solution. The problem is these ARE production packages that are being used by a wide number of services. We WANT to Semver.</p>



<p>Go makes updating major versions so cumbersome that in the majority of cases, we have opted to just increment minor versions when we should increment major versions. We want to follow the proper versioning scheme, we just don’t want to add the unnecessary steps to our dev process.</p>



<h2>Hey – I Get It</h2>



<p>I understand why these decisions were made – and I even think in a lot of cases they were great decisions. For any open-source or public facing module this makes great sense. The Go toolchain is enforcing strict rules that encourage good API design.</p>



<p>In their effort to make public APIs great, they made it unnecessarily hard to have good “local” package design.</p>



<p>There is an <a href="https://github.com/golang/go/issues/40323" rel="noopener">open issue on Github</a> that would make new major versions more discoverable from the CLI. Take a look at that if you are interested.</p>



<p>Go still has the best toolchain and ecosystem. NPM and PIP can suck it.</p>



<p>If you disagree, @ me on Twitter.</p>







<h2>Related Reading</h2>



<ul><li><a href="https://qvault.io/2020/08/15/optimize-for-simplicity-first/">Optimize for Simplicity First</a></li><li><a href="https://qvault.io/2019/10/21/golang-constant-maps-slices/">Constant Maps and Slices in Go</a></li><li><a href="https://qvault.io/2020/08/07/saving-a-third-of-our-memory-by-re-ordering-go-struct-fields/">Saving Memory by Re-ordering Go Structs</a></li></ul>
		</div></div>]]>
            </description>
            <link>https://qvault.io/2020/09/15/gos-major-version-handling-sucks-from-a-fanboy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24488745</guid>
            <pubDate>Wed, 16 Sep 2020 01:42:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When you browse Instagram and find Tony Abbott's passport number]]>
            </title>
            <description>
<![CDATA[
Score 2191 | Comments 324 (<a href="https://news.ycombinator.com/item?id=24488224">thread link</a>) | @michael_fine
<br/>
September 15, 2020 | https://mango.pdf.zone/finding-former-australian-prime-minister-tony-abbotts-passport-number-on-instagram | <a href="https://web.archive.org/web/*/https://mango.pdf.zone/finding-former-australian-prime-minister-tony-abbotts-passport-number-on-instagram">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

    

    <div itemprop="articleBody">
        <hr>
        <p><img src="https://mango.pdf.zone/img/sunburnt-country/title.png" alt="title image what's up twitter-large"></p>



<p>So you know when you’re flopping about at home, minding your own business, drinking from your water bottle in a way that does not possess <em>any</em> intent to subvert the Commonwealth of Australia?</p>

<p>It’s a feeling I know all too well, and in which I was vigorously partaking when I got this message in “the group chat”<sup id="fnref:groupchat" role="doc-noteref"><a href="#fn:groupchat">1</a></sup>.</p>

<p><img src="https://mango.pdf.zone/img/sunburnt-country/groupchat.png" alt="Can you hack this man?|medium">
<em>A nice message from my friend, with a photo of a boarding pass 🙂 A good thing about messages from your friends is that they do not have any rippling consequences 🙂🙂🙂</em></p>

<p>The man in question is <a href="https://en.wikipedia.org/wiki/Tony_Abbott">Tony Abbott</a>, one of Australia’s <em>many</em> former Prime Ministers.</p>

<p><img src="https://mango.pdf.zone/img/sunburnt-country/tony_abbott_wikipedia.png" alt="if u google tony abbott u get this|small">
<em>That’s him, officer</em></p>

<p>For security reasons, we try to change our Prime Minister every six months, and to never use the same Prime Minister on multiple websites.<sup id="fnref:kevin07" role="doc-noteref"><a href="#fn:kevin07">2</a></sup></p>

<h4 id="the-boarding-pass-photo">The boarding pass photo</h4>
<p>This particular former PM had just posted a picture of his boarding pass on Instagram (Instagram, in case you don’t know it, is an app you can open up on your phone any time to look at ads).</p>

<p><img src="https://mango.pdf.zone/img/sunburnt-country/instagrampost.PNG" alt="Instagram post showing boarding pass|large">
<em>The since-deleted Instagram post showing the boarding pass and baggage receipt. The caption reads “coming back home from japan 😍😍  looking forward to seeing everyone! climate change isn’t real 😌 ok byeee”</em></p>

<h4 id="can-you-hack-this-man">“Can you hack this man?”</h4>
<p>My friend<sup id="fnref:hoggemoade" role="doc-noteref"><a href="#fn:hoggemoade">3</a></sup> (who we will refer to by their group chat name, 𝖍𝖔𝖌𝖌𝖊 𝖒𝖔𝖆𝖉𝖊) is asking<sup id="fnref:onbehalf" role="doc-noteref"><a href="#fn:onbehalf">4</a></sup> whether I can “hack this man” not because I am the kind of person who regularly commits 𝒄𝒚𝒃𝒆𝒓 𝒕𝒓𝒆𝒂𝒔𝒐𝒏 on a whim, but because we’d recently been talking about boarding passes.</p>

<p>I’d said that people post pictures of their boarding passes all the time, not knowing that it can sometimes be used to get their passport number and stuff. They just post it being like “omg going on holidayyyy 😍😍😍”, unaware that they’re posting cringe.</p>

<p><img src="https://mango.pdf.zone/img/sunburnt-country/instagramboardingpasses.png" alt="screenshot of #boardingpass on instagram|medium">
<em>People post their boarding passes all the time, because it’s not clear that they’re meant to be secret</em></p>

<p>Meanwhile, some hacker is rubbing their hands together, being all “yumyum identity fraud 👀” in their dark web Discord, because this happens a <em>lot</em>.</p>

<p><img src="https://mango.pdf.zone/img/sunburnt-country/boardingpassposts.png" alt="screenshot of #boardingpass on instagram"></p>

<hr>

<p>So there I was, making intense and meaningful eye contact with this chat bubble, asking me if I could “hack this man”.</p>

<h3 id="surely-you-wouldnt">Surely you wouldn’t</h3>
<p>Of course, my friend wasn’t <em>actually</em> asking me to hack the former Prime Minister.</p>



<p>However.</p>



<p>You <em>gotta</em>.</p>

<p>I mean… what are you gonna do, <em>not</em> click it? Are you gonna let a <em>link</em> that’s like 50% advertising tracking ID tell you what to do? Wouldn’t you be <em>curious</em>?</p>

<p>The former Prime Minister had just posted his boarding pass. Was that <em>bad</em>? Was someone in danger? I didn’t know.</p>

<p>What I did know was: the <em>least</em> I could do<sup id="fnref:nocrime" role="doc-noteref"><a href="#fn:nocrime">5</a></sup> for my country would be to have a casual browse 👀</p>

<h2 id="investigating-the-boarding-pass-photo">Investigating the boarding pass photo</h2>
<h3 id="step-1-hubris">Step 1: Hubris</h3>

<p>So I had a bit of a casual browse, and got the picture of the boarding pass, and then…. I didn’t know what was supposed to happen after that.</p>

<p>Well, I’d heard that it’s bad to post your boarding pass online, because if you do, a bored 17 year-old Russian boy called “Katie-senpai” might somehow use it to commit identity fraud. But I don’t know anyone like that, so I just clumsily googled some stuff.</p>

<h4 id="googling-how-2-hakc-boarding-pass">Googling how 2 hakc boarding pass</h4>
<p><img src="https://mango.pdf.zone/img/sunburnt-country/uhhboardingpasshacking.png" alt="uhhh|small"></p>

<p>Eventually I found <a href="https://null-byte.wonderhowto.com/how-to/hackers-use-hidden-data-airline-boarding-passes-hack-flights-0180728/">a blog post</a> explaining that yes, pictures of boarding passes can indeed be used for Crimes. The part you wanna be looking at for all your criming needs is the barcode, because it’s got the “Booking Reference” (e.g. <code>H8JA2A</code>) in it.</p>

<p>Why do you want the booking reference? It’s one of the two things you need to log in to the airline website to manage your flight.</p>

<p>The second one is your… last name. I was really hoping the second one would be like a password or something. But, no, it’s the booking reference the airline emails you and prints on your boarding pass. And it also lets you log in to the airline website?</p>

<p>That sounds suspiciously like a password to me, but like I’m still fine to pretend it’s not if you are.</p>

<h3 id="step-2-scan-the-barcode">Step 2: Scan the barcode</h3>
<p>I’ve been practicing every morning at sunrise, but still can’t scan barcodes with my eyes. I had to settle for a barcode scanner app on my phone, but when I tried to scan the picture in the Instagram post, it didn’t work :((</p>

<p><img src="https://mango.pdf.zone/img/sunburnt-country/boardingpass.png" alt="the boarding pass photo">
<em>Maybe I shouldn’t have blurred out the barcode first</em></p>

<h3 id="step-2-scan-the-barcode-but-more">Step 2: Scan the barcode, but more</h3>

<p>Well, maybe it wasn’t scanning because the picture was too blurry.</p>

<p>I spent around 15 minutes in an “enhance, ENHANCE” montage, fiddling around with the image, increasing the contrast, and so on. Despite the montage taking up way too much of the 22 minute episode, I couldn’t even get the barcode to scan<sup id="fnref:step3" role="doc-noteref"><a href="#fn:step3">6</a></sup>.</p>

<h3 id="step-2-notice-that-the-booking-reference-is-printed-right-there-on-the-paper">Step 2: Notice that the Booking Reference is printed right there on the paper</h3>

<p>After staring at this image for 15 minutes, I noticed the Booking Reference is just… printed on the baggage receipt.</p>

<p>I graduated university.</p>

<p>But it did not prepare me for this.</p>

<p><img src="https://mango.pdf.zone/img/sunburnt-country/bookingrefhighlighted.png" alt="Boarding pass with booking reference highlighted">
<em>askdjhaflajkshdflkh</em></p>

<h3 id="step-3-visit-the-airlines-website">Step 3: Visit the airline’s website</h3>

<p><img src="https://mango.pdf.zone/img/sunburnt-country/bookinglogin2.png" alt="Manage booking login screen with empty fields-large"></p>

<p>After recovering from <em>that</em> emotional rollercoaster, I went to <a href="https://qantas.com.au/">qantas.com.au</a>, and clicked “Manage Booking”. In case you don’t know it because you live in a country with fast internet, Qantas is the main airline here in Australia.</p>

<p>(I also very conveniently started recording my screen, which is gonna pay off <em>big time</em> in just a moment.)</p>

<h3 id="step-4-type-in-the-booking-reference">Step 4: Type in the Booking Reference</h3>

<p>Well, the login form was just… <em>there</em>, and it was asking for a Booking Reference and a last name. I had just flawlessly read the Booking Reference from the boarding pass picture, and, well… I knew the last name<sup id="fnref:lastname" role="doc-noteref"><a href="#fn:lastname">7</a></sup>.</p>

<p>I did hesitate for a split-second, but… no, I had to know.</p>

<h3 id="step-5-crimes">Step 5: Crimes(?)</h3>

<video controls="" preload="auto">

    <source src="https://mango.pdf.zone/img/sunburnt-country/youngman.mp4" type="video/mp4">

<img src="https://mango.pdf.zone/img/sunburnt-country/summary.gif">
</video>
<p><em>youngman.mp4</em></p>

<p><img src="https://mango.pdf.zone/img/sunburnt-country/loggedin.png" alt="The logged in &quot;manage booking page&quot;">
<em>The “Manage Booking” page, logged in as some guy called Anthony Abbott</em></p>

<h3 id="can-i-get-a-yikes-in-the-chat">Can I get a YIKES in the chat</h3>

<p>Leave a comment if you really felt that.</p>

<p><img src="https://mango.pdf.zone/img/sunburnt-country/yikes.png" alt="yikes"></p>

<p>I guess I was now logged the heck in as Tony Abbott? And for all I know, everyone else who saw his Instagram post was right there with me. It’s kinda wholesome, to imagine us all there together. But also probably suboptimal in a governmental sense.</p>

<h5 id="was-there-anything-secret-in-here">Was there anything secret in here?</h5>

<p>I then just incredibly browsed the page, browsed it so hard.</p>

<p>I saw Tony Abbott’s name<sup id="fnref:name" role="doc-noteref"><a href="#fn:name">8</a></sup>, flight times, and Frequent Flyer number, but not really anything <em>super</em> secret-looking. Not gonna be committing any cyber treason with a Frequent Flyer number. The flight was in the past, so I couldn’t change anything, either.</p>

<p>The page said the flight had been booked by a travel agent, so I guessed some information would be missing because of that.</p>

<p>I clicked around and scrolled a considerable length, but still didn’t find any government secrets.</p>

<p>Some people might give up here. But I, the Icarus of computers, was simply too dumb to know when to stop.</p>

<h3 id="were-not-done-just-because-a-web-page-says-were-done">We’re not done just because a <em>web page</em> says we’re done</h3>

<p>I wanted to see if there were juicy things hidden <em>inside</em> the page. To do it, I had to use the <em>only</em> hacker tool I know.</p>

<p><img src="https://mango.pdf.zone/img/sunburnt-country/inspectelement.png" alt="Right click > Inspect-small">
<em>Right click &gt; Inspect Element, all you need to subvert the Commonwealth of Australia</em></p>

<p>Listen. This is the only part of the story that might be confused for highly elite computer skill. It’s not, though. Maybe later someone will show you this same thing to try and flex, acting like only <em>they</em> know how to do it. You will not go gently into that good night. You will refuse to acknowledge their flex, killing them instantly.</p>

<h5 id="how-does-inspect-element-work">How does “Inspect Element” work?</h5>
<p>“Inspect Element”, as it’s called, is a feature of Google Chrome that lets you see the computer’s internal representation (HTML) of the page you’re looking at. Kinda like opening up a clock and looking at the cool cog party inside.</p>

<p><img src="https://upload.wikimedia.org/wikipedia/commons/6/67/Pocketwatch_cutaway_drawing.jpg" alt="cog party|small">
<em>Yeahhh go little cogs, look at ‘em absolutely going off. Now imagine this but with like, JavaScript</em></p>

<p>Everything you see when you use “Inspect Element” was already downloaded to your computer, you just hadn’t asked Chrome to show it to you yet. Just like how the cogs were already in the watch, you just hadn’t opened it up to look.</p>

<p>But let us dispense with frivolous cog talk. Cheap tricks such as “Inspect Element” are used by programmers to try and understand how the website works. This is ultimately futile: Nobody can understand how websites work. Unfortunately, it kinda <em>looks</em> like hacking the first time you see it.</p>

<p>If you’d like to know more about it, I’ve prepared a short video.</p>

<blockquote><p lang="en" dir="ltr">hey youtube welcome to my hacking tutorial, today we're gonna hack.... the nsa <a href="https://t.co/2Z35GJjSZE">pic.twitter.com/2Z35GJjSZE</a></p>— “Alex” (@mangopdf) <a href="https://twitter.com/mangopdf/status/1123400764926226432?ref_src=twsrc%5Etfw">May 1, 2019</a></blockquote>


<h3 id="browsing-the-manage-booking-pages-html">Browsing the “Manage Booking” page’s HTML</h3>

<p>I scrolled around the page’s HTML, not really knowing what it meant, furiously trying to find anything that looked out of place or secret.</p>

<p>I eventually realised that manually reading HTML with my eyes was not an efficient way of defending my country, and Ctrl + F’d the HTML for “passport”.</p>

<h3 id="oh-no">oh no</h3>

<p><img src="https://mango.pdf.zone/img/sunburnt-country/passportjson.gif" alt="Blurred screenshot of close up &quot;passport&quot; number"></p>

<h3 id="oh-yes">Oh yes</h3>

<p>It’s just <em>there</em>.</p>

<p>At this point I was fairly sure I was looking at the <em>extremely</em> secret government-issued ID of the <em>28th Prime Minister of the Commonwealth of Australia, servant to her Majesty Queen Elizabeth II</em> and I was <em>kinda</em> worried that I was somehow doing something wrong, but like, not enough to stop.</p>

<h3 id="anything-else-in-this-page">….anything <em>else</em> in this page?</h3>

<p>Well damn, if Tony Abbott’s passport number is in this treasure trove of computer spaghetti, maybe there’s wayyyyy more. Perhaps this HTML contains the lost launch codes to the Sydney Opera House, or Harold Holt<sup id="fnref:holt" role="doc-noteref"><a href="#fn:holt">9</a></sup>.</p>

<p>Maybe there’s a phone number?</p>

<p>Searching for <code>phone</code> and <code>number</code> didn’t get anywhere, so I searched for <code>614</code>, the first 3 digits of an Australian phone number, using my colossal and highly celestial galaxy brain.</p>

<h5 id="weird-uppercase-letters">Weird uppercase letters</h5>
<p>A weird pile of what I could only describe as extremely uppercase letters came up. It looked like this:</p>

<div><div><pre><code>RQST QF HK1 HNDSYD/03EN|FQTV QF HK1|CTCM QF HK1 614[phone number]|CKIN QF HN1 DO NOT SEAT ROW [row number] PLS SEAT LAST ROW OF [row letter] WINDOW
</code></pre></div></div>
<p>So, there’s a lot going on here. There is indeed a phone number in here. But what the heck is all this <em>other</em> stuff?</p>

<p>I realised this was like… Qantas staff talking to eachother <em>about</em> Tony Abbott, but not <em>to</em> him?</p>

<p>In what is surely the subtweeting of the century, it has a …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mango.pdf.zone/finding-former-australian-prime-minister-tony-abbotts-passport-number-on-instagram">https://mango.pdf.zone/finding-former-australian-prime-minister-tony-abbotts-passport-number-on-instagram</a></em></p>]]>
            </description>
            <link>https://mango.pdf.zone/finding-former-australian-prime-minister-tony-abbotts-passport-number-on-instagram</link>
            <guid isPermaLink="false">hacker-news-small-sites-24488224</guid>
            <pubDate>Wed, 16 Sep 2020 00:16:13 GMT</pubDate>
        </item>
    </channel>
</rss>
