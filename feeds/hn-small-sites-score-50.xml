<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sat, 29 Aug 2020 04:16:40 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sat, 29 Aug 2020 04:16:40 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[On All That Fuckery]]>
            </title>
            <description>
<![CDATA[
Score 155 | Comments 111 (<a href="https://news.ycombinator.com/item?id=24291362">thread link</a>) | @idan
<br/>
August 27, 2020 | https://www.tinykat.cafe/on-all-that-fuckery | <a href="https://web.archive.org/web/*/https://www.tinykat.cafe/on-all-that-fuckery">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p><undefined><span role="img" aria-label="warning">‚ö†Ô∏è</span> </undefined><em>CW: racist, sexist, transphobic, hateful language and online abuse</em></p><p><span>
      <a href="https://www.tinykat.cafe/static/78121b0fe29ffe99a14ba6f375152534/b54cd/screenshot-fuckery.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="&quot;you faggots are just giving her the material for her next talk on sexism/hate threats and all that fuckery.&quot;" title="&quot;you faggots are just giving her the material for her next talk on sexism/hate threats and all that fuckery.&quot;" src="https://www.tinykat.cafe/static/78121b0fe29ffe99a14ba6f375152534/e5715/screenshot-fuckery.png" srcset="https://www.tinykat.cafe/static/78121b0fe29ffe99a14ba6f375152534/8514f/screenshot-fuckery.png 192w,https://www.tinykat.cafe/static/78121b0fe29ffe99a14ba6f375152534/804b2/screenshot-fuckery.png 384w,https://www.tinykat.cafe/static/78121b0fe29ffe99a14ba6f375152534/e5715/screenshot-fuckery.png 768w,https://www.tinykat.cafe/static/78121b0fe29ffe99a14ba6f375152534/4ad3a/screenshot-fuckery.png 1152w,https://www.tinykat.cafe/static/78121b0fe29ffe99a14ba6f375152534/71c1d/screenshot-fuckery.png 1536w,https://www.tinykat.cafe/static/78121b0fe29ffe99a14ba6f375152534/b54cd/screenshot-fuckery.png 1662w" sizes="(max-width: 768px) 100vw, 768px" loading="lazy">
  </a>
    </span></p><p>From July 14 to August 17, 2020 (at time of publish), I experienced targeted harassment on GitHub‚Äîthe company I'm employed at‚Äîvia coordination happening on several "technology" 4chan threads about me. I wanted to share this story publicly to reiterate the bullshit marginalized folks in tech have to go through in order to be successful, visible, and just <em>exist</em>.</p><p>So as the dude in the screenshot says, I have plenty of material to write a post on <em>all that fuckery</em>.</p><p><span role="img" aria-label="wavy dash">„Ä∞Ô∏è</span></p><p>The first round of trolling occurred in issues and PRs on <a href="https://github.com/katmeister/tokyo-2019">one of my repositories</a> that documents the food I ate with my friends on our spring Tokyo 2019 trip. It was only slightly concerning at first, until I realized that 40+ people were posting, commenting, and emoji reacting.</p><p><span>
      <a href="https://www.tinykat.cafe/static/b4fa0c9a46ca93a988fba3001fb34071/917ef/gh-screenshots.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="screenshots from GitHub" title="screenshots from GitHub" src="https://www.tinykat.cafe/static/b4fa0c9a46ca93a988fba3001fb34071/e5715/gh-screenshots.png" srcset="https://www.tinykat.cafe/static/b4fa0c9a46ca93a988fba3001fb34071/8514f/gh-screenshots.png 192w,https://www.tinykat.cafe/static/b4fa0c9a46ca93a988fba3001fb34071/804b2/gh-screenshots.png 384w,https://www.tinykat.cafe/static/b4fa0c9a46ca93a988fba3001fb34071/e5715/gh-screenshots.png 768w,https://www.tinykat.cafe/static/b4fa0c9a46ca93a988fba3001fb34071/4ad3a/gh-screenshots.png 1152w,https://www.tinykat.cafe/static/b4fa0c9a46ca93a988fba3001fb34071/71c1d/gh-screenshots.png 1536w,https://www.tinykat.cafe/static/b4fa0c9a46ca93a988fba3001fb34071/917ef/gh-screenshots.png 2095w" sizes="(max-width: 768px) 100vw, 768px" loading="lazy">
  </a>
    </span></p><p><undefined>Here are a few examples. The most irritating ones used tech jargon ("fixing bloat") to mask their pathetic actions. As a bystander, you might not realize until viewing the proposed changes... and seeing all content deleted. This is also the most irritating because there is no obviously hateful or violent content, and can be written off as "just a joke." <span role="img" aria-label="face with rolling eyes">üôÑ</span></undefined></p><p>This is a specific type of trolling I was experiencing, called "dogpiling":</p><blockquote><p>Dogpiling: When a group of trolls works together to overwhelm a target through a barrage of disingenuous questions, threats, slurs, insults, and other tactics meant to shame, silence, discredit, or drive a target offline. ‚Äî <a href="https://onlineharassmentfieldmanual.pen.org/defining-online-harassment-a-glossary-of-terms/">PEN America</a></p></blockquote><p>This is not a new tactic used to silence, but it was the first time I've personally experienced it. Good thing I designed a lot of our moderation tools and have talked about the <a href="https://youtu.be/5CSQYMOWOtQ?t=580">taxonomy of online abuse</a> before, and recognized this type of harassment quickly. I was able to get help from amazing coworkers, <a href="https://twitter.com/cheshire137">Sarah Vessels</a> and <a href="https://twitter.com/deniseyu21">Denise Yu</a>, to query my repo's referral data. The traffic was coming from 4chan... two 4chan threads totaling nearly 500 disturbing comments.</p><p>Seeing this shit was absolutely surreal. The GitHub content was annoying, but this made me feel sick. I still remember the feeling of being so overwhelmed and just sobbing at my desk. Reading disgusting, racist, sexist comments about me. Seeing screenshots of my face plastered across the threads. Understanding the exact moment where the dogpiling was coordinated. Realizing this was likely to keep happening (and it did).</p><p>And what still really creeps me out is that these people felt so emboldened to troll an EMPLOYEE using their actual GitHub accounts with legitimate work and contributions. <u>These harassers are everyday software engineers.</u></p><p>I'm not famous and I don't have a very large platform, so why me?</p><p>Upon reading the threads, there were some pretty clear reasons why this happened to me. I'll dig deeply into each one. <em>HUGE shoutout to my kat-ops counterpart <a href="https://twitter.com/pifafu">Kathy Zheng</a> for helping me compile screenshots!</em></p><h2>I'm a woman.</h2><p><undefined>Well, this was the most obvious reason. Women disproportionately experience online harassment, and very much so for sexual harassment. I included a few snippets but won't spend too much time on this one because it was some boring, basic bitch shit that we've all seen before <span role="img" aria-label="">ü§∑üèª‚Äç‚ôÄÔ∏è</span></undefined></p><p><span>
      <a href="https://www.tinykat.cafe/static/8c70cf424f0092c01e2bab74df31a7a1/4f046/screenshots-incels.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="sexist comments" title="sexist comments" src="https://www.tinykat.cafe/static/8c70cf424f0092c01e2bab74df31a7a1/e5715/screenshots-incels.png" srcset="https://www.tinykat.cafe/static/8c70cf424f0092c01e2bab74df31a7a1/8514f/screenshots-incels.png 192w,https://www.tinykat.cafe/static/8c70cf424f0092c01e2bab74df31a7a1/804b2/screenshots-incels.png 384w,https://www.tinykat.cafe/static/8c70cf424f0092c01e2bab74df31a7a1/e5715/screenshots-incels.png 768w,https://www.tinykat.cafe/static/8c70cf424f0092c01e2bab74df31a7a1/4ad3a/screenshots-incels.png 1152w,https://www.tinykat.cafe/static/8c70cf424f0092c01e2bab74df31a7a1/71c1d/screenshots-incels.png 1536w,https://www.tinykat.cafe/static/8c70cf424f0092c01e2bab74df31a7a1/4f046/screenshots-incels.png 3311w" sizes="(max-width: 768px) 100vw, 768px" loading="lazy">
  </a>
    </span></p><h2>I'm an Asian woman.</h2><p>I mean, I shouldn't have been surprised at this one, but here we are. I have a lot of privilege as an Asian American, but was quickly reminded how easy I can be reduced to stereotypes and slurs. And that the gross fetishization of Asian women still makes me a target:</p><p><span>
      <a href="https://www.tinykat.cafe/static/fb87155ab684bb443d4d7e156d69f4fe/91945/screenshots-asian-slurs.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="asian slurs" title="asian slurs" src="https://www.tinykat.cafe/static/fb87155ab684bb443d4d7e156d69f4fe/e5715/screenshots-asian-slurs.png" srcset="https://www.tinykat.cafe/static/fb87155ab684bb443d4d7e156d69f4fe/8514f/screenshots-asian-slurs.png 192w,https://www.tinykat.cafe/static/fb87155ab684bb443d4d7e156d69f4fe/804b2/screenshots-asian-slurs.png 384w,https://www.tinykat.cafe/static/fb87155ab684bb443d4d7e156d69f4fe/e5715/screenshots-asian-slurs.png 768w,https://www.tinykat.cafe/static/fb87155ab684bb443d4d7e156d69f4fe/4ad3a/screenshots-asian-slurs.png 1152w,https://www.tinykat.cafe/static/fb87155ab684bb443d4d7e156d69f4fe/71c1d/screenshots-asian-slurs.png 1536w,https://www.tinykat.cafe/static/fb87155ab684bb443d4d7e156d69f4fe/91945/screenshots-asian-slurs.png 2944w" sizes="(max-width: 768px) 100vw, 768px" loading="lazy">
  </a>
    </span></p><p>There was one in particular I wanted to highlight:</p><p><span>
      <a href="https://www.tinykat.cafe/static/b7462864208b987ab4889dcf7a278076/07a9c/screenshots-asian-slurs2.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="So half-human?" title="So half-human?" src="https://www.tinykat.cafe/static/b7462864208b987ab4889dcf7a278076/e5715/screenshots-asian-slurs2.png" srcset="https://www.tinykat.cafe/static/b7462864208b987ab4889dcf7a278076/8514f/screenshots-asian-slurs2.png 192w,https://www.tinykat.cafe/static/b7462864208b987ab4889dcf7a278076/804b2/screenshots-asian-slurs2.png 384w,https://www.tinykat.cafe/static/b7462864208b987ab4889dcf7a278076/e5715/screenshots-asian-slurs2.png 768w,https://www.tinykat.cafe/static/b7462864208b987ab4889dcf7a278076/4ad3a/screenshots-asian-slurs2.png 1152w,https://www.tinykat.cafe/static/b7462864208b987ab4889dcf7a278076/07a9c/screenshots-asian-slurs2.png 1440w" sizes="(max-width: 768px) 100vw, 768px" loading="lazy">
  </a>
    </span></p><p>This one in particular stood out to me because it's a very specific type of harassment I've received my whole life, usually from East Asians. This piece of trash is stating that I'm subhuman because of my Vietnamese heritage. Tbh, this hits harder than boring 'ol "chink." The colorism here makes me think this was an Asian dude. And speaking of which:  </p><p><span>
      <a href="https://www.tinykat.cafe/static/3eee0f75ebc7aeae694e1262392cf0a7/71c1d/screenshots-mrasian.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="asian slurs" title="asian slurs" src="https://www.tinykat.cafe/static/3eee0f75ebc7aeae694e1262392cf0a7/e5715/screenshots-mrasian.png" srcset="https://www.tinykat.cafe/static/3eee0f75ebc7aeae694e1262392cf0a7/8514f/screenshots-mrasian.png 192w,https://www.tinykat.cafe/static/3eee0f75ebc7aeae694e1262392cf0a7/804b2/screenshots-mrasian.png 384w,https://www.tinykat.cafe/static/3eee0f75ebc7aeae694e1262392cf0a7/e5715/screenshots-mrasian.png 768w,https://www.tinykat.cafe/static/3eee0f75ebc7aeae694e1262392cf0a7/4ad3a/screenshots-mrasian.png 1152w,https://www.tinykat.cafe/static/3eee0f75ebc7aeae694e1262392cf0a7/71c1d/screenshots-mrasian.png 1536w" sizes="(max-width: 768px) 100vw, 768px" loading="lazy">
  </a>
    </span></p><p>I also received an email from what appears to be an MRAsian... It's sadly not uncommon to see Asian men upholding white supremacy and targeting Asian women for living our damn lives.</p><h2>I have a "radical" profile README.</h2><p>My GitHub <a href="http://github.com/katmeister">profile README</a> includes my pronouns, support for #BlackLivesMatter, my values, and social links. The amount of transphobic and anti-Black racist comments because of this was sickening. Attacking allyship is yet another tactic to silence and isolate us.</p><p><span>
      <a href="https://www.tinykat.cafe/static/a7ab50905868d6c10c38a7153e01cfbe/16bd1/screenshots-readme.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="attacks on my GitHub personal README" title="attacks on my GitHub personal README" src="https://www.tinykat.cafe/static/a7ab50905868d6c10c38a7153e01cfbe/e5715/screenshots-readme.png" srcset="https://www.tinykat.cafe/static/a7ab50905868d6c10c38a7153e01cfbe/8514f/screenshots-readme.png 192w,https://www.tinykat.cafe/static/a7ab50905868d6c10c38a7153e01cfbe/804b2/screenshots-readme.png 384w,https://www.tinykat.cafe/static/a7ab50905868d6c10c38a7153e01cfbe/e5715/screenshots-readme.png 768w,https://www.tinykat.cafe/static/a7ab50905868d6c10c38a7153e01cfbe/4ad3a/screenshots-readme.png 1152w,https://www.tinykat.cafe/static/a7ab50905868d6c10c38a7153e01cfbe/71c1d/screenshots-readme.png 1536w,https://www.tinykat.cafe/static/a7ab50905868d6c10c38a7153e01cfbe/16bd1/screenshots-readme.png 2922w" sizes="(max-width: 768px) 100vw, 768px" loading="lazy">
  </a>
    </span></p><h2>I'm not a "real developer"</h2><p>Yikes, there were a <em>lot</em><undefined> of comments about this. The dismissal of my skills and claiming I can only write Markdown is an intentional tactic to tear down my value and diminish my success. Very funny, as I've been writing code to production since 2016, despite not being a skilled developer. <span role="img" aria-label="">ü§∑üèª‚Äç‚ôÄÔ∏è</span></undefined></p><p><span>
      <a href="https://www.tinykat.cafe/static/4aaf585e0e3766626332768d1b1cd811/60708/screenshots-not-developer.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="not a real developer" title="not a real developer" src="https://www.tinykat.cafe/static/4aaf585e0e3766626332768d1b1cd811/e5715/screenshots-not-developer.png" srcset="https://www.tinykat.cafe/static/4aaf585e0e3766626332768d1b1cd811/8514f/screenshots-not-developer.png 192w,https://www.tinykat.cafe/static/4aaf585e0e3766626332768d1b1cd811/804b2/screenshots-not-developer.png 384w,https://www.tinykat.cafe/static/4aaf585e0e3766626332768d1b1cd811/e5715/screenshots-not-developer.png 768w,https://www.tinykat.cafe/static/4aaf585e0e3766626332768d1b1cd811/4ad3a/screenshots-not-developer.png 1152w,https://www.tinykat.cafe/static/4aaf585e0e3766626332768d1b1cd811/71c1d/screenshots-not-developer.png 1536w,https://www.tinykat.cafe/static/4aaf585e0e3766626332768d1b1cd811/60708/screenshots-not-developer.png 2872w" sizes="(max-width: 768px) 100vw, 768px" loading="lazy">
  </a>
    </span></p><p>Also, I think this comment deserves a blockquote:</p><blockquote><p>women unironically think that's all there is to development - forking, pushing some spelling changes, etc</p><p>they literally have no concept of how involved any of it is</p><p>isn't it hilarious that these useless parasites are consuming at least 50% of employer resources? all the while shitting on actually productive geeks for political brownie points?   </p></blockquote><p><undefined>Just... let that one sit. <span role="img" aria-label="nauseated face">ü§¢</span></undefined></p><h2>I'm ruining GitHub as an employee...</h2><p>There's a recurring narrative that I'm just a diversity hire who is ruining the coding sanctity of GitHub. I don't deserve to work at this company because I do nothing, while the engineers in this thread sit in their "1 room apartments." Damn, it's not my fault you aren't talented or successful. It also appears some watched my talks‚Äîthanks for the views.</p><p><span>
      <a href="https://www.tinykat.cafe/static/23790c8be2d72cba09953ecb50c03cfc/40493/screenshots-ruining-gh.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="I'm ruining GitHub as an employee" title="I'm ruining GitHub as an employee" src="https://www.tinykat.cafe/static/23790c8be2d72cba09953ecb50c03cfc/e5715/screenshots-ruining-gh.png" srcset="https://www.tinykat.cafe/static/23790c8be2d72cba09953ecb50c03cfc/8514f/screenshots-ruining-gh.png 192w,https://www.tinykat.cafe/static/23790c8be2d72cba09953ecb50c03cfc/804b2/screenshots-ruining-gh.png 384w,https://www.tinykat.cafe/static/23790c8be2d72cba09953ecb50c03cfc/e5715/screenshots-ruining-gh.png 768w,https://www.tinykat.cafe/static/23790c8be2d72cba09953ecb50c03cfc/4ad3a/screenshots-ruining-gh.png 1152w,https://www.tinykat.cafe/static/23790c8be2d72cba09953ecb50c03cfc/71c1d/screenshots-ruining-gh.png 1536w,https://www.tinykat.cafe/static/23790c8be2d72cba09953ecb50c03cfc/40493/screenshots-ruining-gh.png 2955w" sizes="(max-width: 768px) 100vw, 768px" loading="lazy">
  </a>
    </span></p><p>I'd like to point out that the idea of avoiding "diversity hires" as to not lower the bar of quality is still a prevalent sentiment within tech. Again, these are not just nameless 4chan trolls‚Äîthey're people in our industry.</p><h2>... and should be punished.</h2><p>Yeah, these are gross. Apparently I should get fired and deserve the harassment because I'm an attention seeking whore on a programming platform! The platform I work on and create more value to developers than you ever will in your life!!</p><p><span>
      <a href="https://www.tinykat.cafe/static/e7904e47d6c1e3ff58827b2096c64f78/50e7d/screenshots-ugh.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="I should get no sympathy for abuse, should be fired, should kill myself" title="I should get no sympathy for abuse, should be fired, should kill myself" src="https://www.tinykat.cafe/static/e7904e47d6c1e3ff58827b2096c64f78/e5715/screenshots-ugh.png" srcset="https://www.tinykat.cafe/static/e7904e47d6c1e3ff58827b2096c64f78/8514f/screenshots-ugh.png 192w,https://www.tinykat.cafe/static/e7904e47d6c1e3ff58827b2096c64f78/804b2/screenshots-ugh.png 384w,https://www.tinykat.cafe/static/e7904e47d6c1e3ff58827b2096c64f78/e5715/screenshots-ugh.png 768w,https://www.tinykat.cafe/static/e7904e47d6c1e3ff58827b2096c64f78/4ad3a/screenshots-ugh.png 1152w,https://www.tinykat.cafe/static/e7904e47d6c1e3ff58827b2096c64f78/71c1d/screenshots-ugh.png 1536w,https://www.tinykat.cafe/static/e7904e47d6c1e3ff58827b2096c64f78/50e7d/screenshots-ugh.png 1738w" sizes="(max-width: 768px) 100vw, 768px" loading="lazy">
  </a>
    </span></p><p>That wasn't every screenshot from the threads, but is a good summary. The sheer volume of comments was definitely one of the more overwhelming aspects of this fuckery. Thanks for reading along this far.</p><h2>So if it wasn't clear:</h2><p><undefined>I was targeted by racist techies because of my background and visibility in order to be silenced and driven out of this industry. <span role="img" aria-label="middle finger">üñï</span></undefined></p><p>It was particularly cruel to harass me on the platform I work on everyday, where I design for open source communities. I couldn't focus at work and ended up taking two weeks off. This experience has really impacted the way I view tech and my place in it‚Äîbut I'll save that for another post. </p><p>I've already accepted that this won't be my last brush with online harassment, so long as I'm still a visible Asian woman in tech. And this is going to continue happening to me and less privileged tech workers for just existing and being successful. All we can do is protect and support each other, because it's not our job to fix this problem.</p><p>It's your move next, tech. Here are my suggestions, you can have them for free:  </p><h2>To the most privileged tech leaders:</h2><p>When these events happen to your employees, are you investing actual money to support them? Are you monitoring content, encouraging time off, creating company policies, and covering their therapy? In lucky cases like mine, where the bulk of harassment may happen on the platform the victim works on, are you actively fixing pain points your employee experienced? Make sure you have a policy and detailed playbook, and definitely don't expect your marginalized employees to fix these problems for you. Don't wait until an incident arises‚Äî<strong>it's always an "edge case" until someone's personal safety is threatened.</strong></p><p>By not having intentional protections for the most vulnerable in place, you're preventing employees from being productive at work (because they're dealing with bullshit!). And you're absolutely driving away diverse talent from joining your company. It's actually fucking up your business. Access and representation in tech isn't a pipeline or qualification problem. <strong>It's a white supremacy problem.</strong></p><blockquote><p>And what still really creeps me out is that these people felt so emboldened to troll an EMPLOYEE using their actual GitHub accounts with legitimate work and contributions. <u>These harassers are everyday software engineers.</u></p></blockquote><p>Lastly, I want to circle back to this point about users with legitimate coding work harassing me. It's easy to dismiss these trolls as incel 4channers that we shun and don't associate with. Lol no. These are your people. They work at your companies and write your code. They are harassing or doxxing your other employees. This toxic behavior is still very much a part of your tech culture, and you keep rewarding it.</p><p>Fix. This. Shit.</p></article></div>]]>
            </description>
            <link>https://www.tinykat.cafe/on-all-that-fuckery</link>
            <guid isPermaLink="false">hacker-news-small-sites-24291362</guid>
            <pubDate>Thu, 27 Aug 2020 08:38:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Talk to Your Data: One Model, Any Relational Database]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 18 (<a href="https://news.ycombinator.com/item?id=24283687">thread link</a>) | @atrudeau
<br/>
August 26, 2020 | https://blog.einstein.ai/talk-to-your-data-one-model-any-database/ | <a href="https://web.archive.org/web/*/https://blog.einstein.ai/talk-to-your-data-one-model-any-database/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  <div>
      <div>
          <p><strong>TL;DR: </strong>We introduce <a href="https://naturalsql.com/">Photon</a>, a live demo of a natural language interface to databases based on our latest research in neural semantic parsing. √∞≈∏‚Äù‚Äî <a href="https://naturalsql.com/">https://naturalsql.com/</a></p><figure><img src="https://blog.einstein.ai/content/images/2020/08/Screen-Recording-2020-07-27-at-2--1-.gif" alt=""></figure><p>Recently the field has seen a surge of interest in <a href="https://wp.sigmod.org/?p=2897">natural language based data querying approaches</a>. This is partially driven by the latest advances in <a href="http://www.phontron.com/class/nn4nlp2020/index.html">natural language processing</a> that led to the development of <a href="https://openvoicenetwork.org/post/announcing-the-open-voice-initiative/">voice- and text-based interfaces in a wide range of applications</a>. Easy and fast access of data is a continuous demand, and the <a href="https://www.researchgate.net/publication/247926251_The_Lunar_Science_Natural_Language_Information_System_Final_Report">investment in natural language information systems</a> dates back to the <a href="https://www.quickbase.com/articles/timeline-of-database-history">early days of database systems.</a> Previously, Salesforce released <a href="https://blog.einstein.ai/how-to-talk-to-your-database/">WikiSQL</a>, a large-scale benchmark dataset which enabled <a href="https://github.com/salesforce/WikiSQL">significant progress</a> in mapping natural language utterances to structured queries over open-domain tables. This article describes our <a href="https://arxiv.org/abs/2007.15280">latest research</a> in this area towards more <strong>intelligent</strong> and <strong>robust</strong> modeling, and introduces <a href="https://naturalsql.com/">Photon</a>, a live prototype of a natural language interface to complex relational databases. </p><figure><img src="https://blog.einstein.ai/content/images/2020/08/Screen-Shot-2020-08-20-at-2.33.00-AM-1.png" alt="" srcset="https://blog.einstein.ai/content/images/size/w600/2020/08/Screen-Shot-2020-08-20-at-2.33.00-AM-1.png 600w, https://blog.einstein.ai/content/images/size/w1000/2020/08/Screen-Shot-2020-08-20-at-2.33.00-AM-1.png 1000w, https://blog.einstein.ai/content/images/size/w1600/2020/08/Screen-Shot-2020-08-20-at-2.33.00-AM-1.png 1600w, https://blog.einstein.ai/content/images/size/w2400/2020/08/Screen-Shot-2020-08-20-at-2.33.00-AM-1.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Figure 1. Users from various industries access information systems everyday, everywhere.</figcaption></figure><h2 id="background">Background</h2><p><strong>Relational Databases </strong>(DBs)<strong>. </strong>The <a href="https://www.seas.upenn.edu/~zives/03f/cis550/codd.pdf">relational database</a>, introduced in 1970, remains the <a href="https://www.quora.com/Why-is-RDBMS-the-most-dominant-database-management-system-architecture">dominant</a> database architecture used across industries. It organizes data using inter-linked tables consisting of columns (also called "fields" or "attributes") and rows (also called "records" or "tuples") (Figure 2). Generally, each table represents an entity type (e.g. <em>user</em> and <em>contact)</em>; each column represents an attribute of the entity type (<em>name</em> and <em>address</em>) and each row represents an instance. Some columns are <a href="https://en.wikipedia.org/wiki/Primary_key">primary keys</a>, used for uniquely identifying a row (e.g. <em>contact.account_name</em>), and some are <a href="https://en.wikipedia.org/wiki/Foreign_key">foreign keys</a>, used to reference a primary key in a different table (e.g. <em>boat.contact</em>). </p><figure><img src="https://blog.einstein.ai/content/images/2020/08/prework_entity_diagram.jpg" alt="" srcset="https://blog.einstein.ai/content/images/size/w600/2020/08/prework_entity_diagram.jpg 600w, https://blog.einstein.ai/content/images/size/w1000/2020/08/prework_entity_diagram.jpg 1000w, https://blog.einstein.ai/content/images/2020/08/prework_entity_diagram.jpg 1004w" sizes="(min-width: 720px) 720px"><figcaption>Figure 2. Visualization of a relational database schema in Salesforce</figcaption></figure><p><strong>Structured Query Language (SQL).</strong> Most databases employ <a href="https://en.wikipedia.org/wiki/SQL#Current_Standard">SQL</a> as the language for users to query (<code>SELECT</code>) and manipulate data (<code>UPDATE</code>/ <code>INSERT</code> / <code>DELETE</code>). Industrial database management systems (DBMSs) often implement their own <a href="https://learnsql.com/blog/what-sql-dialect-to-learn/#:~:text=SQL%20Is%20the%20Language%20for%20Talking%20to%20Databases&amp;text=PostgreSQL%2C%20MySQL%2C%20Oracle%2C%20and,call%20these%20variants%20SQL%20dialects.">SQL dialects</a> (<a href="https://en.wikipedia.org/wiki/PostgreSQL">PostgreSQL</a>, <a href="https://en.wikipedia.org/wiki/SQLite">SQLite</a>, <a href="https://en.wikipedia.org/wiki/Oracle_Database">Oracle</a>, <a href="https://en.wikipedia.org/wiki/MySQL">MySQL</a> etc.) and extensions. While these dialects vary widely and are incompatible with each other, most of them support some <a href="https://en.wikipedia.org/wiki/SQL#Standardization_history">common functionalities</a>. Figure 3 shows a complex query that selects the average review scores of bow-riders by users from different departments, which requires joining three tables.</p><figure><img src="https://blog.einstein.ai/content/images/2020/08/Screen-Shot-2020-08-20-at-7.50.06-PM.png" alt="" srcset="https://blog.einstein.ai/content/images/size/w600/2020/08/Screen-Shot-2020-08-20-at-7.50.06-PM.png 600w, https://blog.einstein.ai/content/images/size/w1000/2020/08/Screen-Shot-2020-08-20-at-7.50.06-PM.png 1000w, https://blog.einstein.ai/content/images/size/w1600/2020/08/Screen-Shot-2020-08-20-at-7.50.06-PM.png 1600w, https://blog.einstein.ai/content/images/2020/08/Screen-Shot-2020-08-20-at-7.50.06-PM.png 1663w" sizes="(min-width: 720px) 720px"><figcaption>Figure 3. A SQL query that shows the average review scores of bow-riders by users from different departments</figcaption></figure><p><strong>Natural Language Interfaces to Databases (NLIDBs). </strong>While SQL was originally intended for end users, query construction is often laborious in practice and creates <a href="https://www.quora.com/How-hard-is-it-to-learn-SQL-1">steep learning curve</a>. As of today, it is common for SQL queries to be embedded into software to provide a more accessible user interface (e.g. <a href="https://www.klipfolio.com/blog/create-sql-dashboard#:~:text=A%20SQL%20dashboard%20is%20an,SQL%20(Structured%20Query%20Language).">dashboards</a>). This, however, does not eliminate the need for natural language based querying, which supports greater <a href="http://erichorvitz.com/chi99horvitz.pdf">user initiative</a> and is often less distracting. </p><h2 id="system">System</h2><blockquote>Photon is a state-of-the-art NLIDB prototype that supports most common SQL operations (including table joins and query compositions) and works across different databases. </blockquote><p>We design Photon following two core principles: <strong>intelligence </strong>and <strong>robustness</strong>. It adopts a modular architecture comprising a state-of-the-art neural semantic parser, a human-in-the-loop question corrector, a DB engine and a response generator. We expect the interface to correctly interpret a large and diverse set of natural language questions, while avoiding unreliable guesses for noisy input.</p><p><strong>Cross-Database Semantic Parsing. </strong>The core of an NLIDB is a <a href="https://en.wikipedia.org/wiki/Semantic_parsing#:~:text=Semantic%20parsing%20is%20the%20task,precise%20meaning%20of%20an%20utterance.">semantic parser</a> that maps a natural language user input to an executable SQL query. Photon adopts a cross-DB semantic parsing model that realizes this mapping for a large number of DBs, including DBs it has never been trained on. </p><!--kg-card-begin: html--><table>
    <tbody><tr>
        <td>DB
        </td>
        <td>Question
        </td>
        <td>SQL Query
        </td>
    </tr>
    <tr>
        <td>Wines		
        </td>
        <td>Title of most expensive wine		
        </td>
        <td>SELECT wines.Title FROM wines ORDER BY wines.Price DESC LIMIT 1
        </td>
    </tr>
    <tr>
        <td>Concert
        </td>
        <td>What is the top attendance for a performance?	
        </td>
        <td>SELECT MAX(show.Attendance) FROM show
        </td>
    </tr>
    <tr>
        <td>Employee	
        </td>
        <td>Bonus of Vickery	
        </td>
        <td>SELECT evaluation.Bonus FROM employee JOIN evaluation ON employee.Employee_ID = evaluation.Employee_ID WHERE employee.Name = "vickery"
        </td>
    </tr>
    </tbody><caption>Table 1. Example natural language questions and their corresponding SQL query mappings on three databases. </caption>
</table><!--kg-card-end: html--><p>Following previous work [2,4], we design an encoder-decoder model that takes a natural language question and the target DB schema as input and synthesizes a SQL query as output. We represent the input question and the DB schema jointly as a tagged sequence (Figure 4), which is first encoded with <a href="https://arxiv.org/abs/1810.04805">BERT</a> and then a <a href="https://en.wikipedia.org/wiki/Bidirectional_recurrent_neural_networks">bi-directional LSTM</a>. We use the hidden representations corresponding to special tokens <code>[T]</code> and <code>[C]</code> in this encoding as the table and column representations, and infuse them with DB metadata features. The question portion of the encoding is further encoded with another Bi-LSTM, and we use its output as the start state of the decoder.</p><figure><img src="https://blog.einstein.ai/content/images/2020/08/Screen-Shot-2020-08-20-at-11.38.02-PM.png" alt="" srcset="https://blog.einstein.ai/content/images/size/w600/2020/08/Screen-Shot-2020-08-20-at-11.38.02-PM.png 600w, https://blog.einstein.ai/content/images/size/w1000/2020/08/Screen-Shot-2020-08-20-at-11.38.02-PM.png 1000w, https://blog.einstein.ai/content/images/size/w1600/2020/08/Screen-Shot-2020-08-20-at-11.38.02-PM.png 1600w, https://blog.einstein.ai/content/images/2020/08/Screen-Shot-2020-08-20-at-11.38.02-PM.png 1733w" sizes="(min-width: 720px) 720px"><figcaption>Figure 4. Our joint question-schema encoder for cross-database semantic parsing. We represent a table as the concatenation of the table name and its column name, separated by special tokens <code>[T]</code> and <code>[C]</code>. We represent a DB as the concatenation of its table representations, and further concatenate it with the input question.&nbsp;</figcaption></figure><p>Our decoder is an LSTM-based <a href="https://arxiv.org/abs/1704.04368">pointer-generator</a> model that generates complex SQL queries as a sequence of tokens. At each decoding step, the decoder performs one of the three actions: generating a SQL keyword, copying a table/column, or copying a token from the input utterance, determined by a learned gating function.</p><p>We train the model on a popular cross-DB text-to-SQL dataset, <a href="https://yale-lily.github.io/spider">Spider</a> [4]. Combined with table value augmentation and static SQL correctness checking, our model achieves state-of-the-art structure matching accuracy on the Spider dev set. More details can be found in our <a href="https://arxiv.org/abs/2007.15280">research paper</a>. (We are continuously improving the semantic parser and updating the Photon backend.)</p><p><strong>Handling Untranslatable Utterances.</strong> While state-of-the-art cross-DB semantic parsers are able to handle a large set of common user requests, there is still ample space for improvement. Besides reducing errors made on questions that have a SQL translation, we also need to properly handle input utterances that cannot be mapped to a SQL statement, even by humans. </p><p>Practical NLIDBs are exposed to a wide range of noisy user input. Users tend to employ underspecified and incomplete NL expressions when interacting with such interfaces [6,8], and may ask for information that is not provided by the DB. For such input, learning-based semantic parsers can make unreliable guesses that may appear correct on the surface. This issue is especially severe for end-to-end neural semantic parsers when the noisy input appears similar to a valid input in the embedding space. </p><figure><img src="https://blog.einstein.ai/content/images/2020/08/Screen-Shot-2020-08-24-at-6.39.42-PM-1.png" alt="" srcset="https://blog.einstein.ai/content/images/size/w600/2020/08/Screen-Shot-2020-08-24-at-6.39.42-PM-1.png 600w, https://blog.einstein.ai/content/images/size/w1000/2020/08/Screen-Shot-2020-08-24-at-6.39.42-PM-1.png 1000w, https://blog.einstein.ai/content/images/size/w1600/2020/08/Screen-Shot-2020-08-24-at-6.39.42-PM-1.png 1600w, https://blog.einstein.ai/content/images/2020/08/Screen-Shot-2020-08-24-at-6.39.42-PM-1.png 1644w" sizes="(min-width: 720px) 720px"><figcaption>Figure 5. Types of Untranslatable Input Utterances to an NLIDB</figcaption></figure><p>Photon implements a module that automatically detects untranslatable input utterances and highlights the ambiguous spans in order to help users rephrase the utterance. To this end, we perturb the Spider dataset to automatically synthesize a large number of untranslatable utterances corresponding to the categories in Figure 5. Our perturbation method yields not only untranslatable questions but also the exact span that causes it to be untranslatable. With this new data, we train a neural translatability detector by extracting confusion spans from the input utterance. If a confusion span is detected, we deem the question untranslatable and prompt the user to rephrase. If the model detects that a confusion span likely refers to a field, we run a language model perplexity check to identify the possible target field and suggest it to the user. More details can be found in our <a href="https://arxiv.org/abs/2007.15280">research paper</a>. </p><p><strong>Dual-Input Mode. </strong>Photon accepts both natural language questions and well-formed SQL queries as input. It automatically detects the input type and executes the input immediately if it is a valid SQL query. We expect that under certain cases, forming a natural language question can be difficult and writing SQL directly may save time, especially for users proficient in SQL. </p><figure><img src="https://blog.einstein.ai/content/images/2020/08/Screen-Shot-2020-08-20-at-11.42.33-PM.png" alt="" srcset="https://blog.einstein.ai/content/images/size/w600/2020/08/Screen-Shot-2020-08-20-at-11.42.33-PM.png 600w, https://blog.einstein.ai/content/images/size/w1000/2020/08/Screen-Shot-2020-08-20-at-11.42.33-PM.png 1000w, https://blog.einstein.ai/content/images/size/w1600/2020/08/Screen-Shot-2020-08-20-at-11.42.33-PM.png 1600w, https://blog.einstein.ai/content/images/2020/08/Screen-Shot-2020-08-20-at-11.42.33-PM.png 2152w" sizes="(min-width: 720px) 720px"><figcaption>Figure 6. Photon Flow Diagram</figcaption></figure><p>Figure 6 shows the flow diagram of Photon. The confusion detection module determines the translatability of an incoming question. For translatable questions, the semantic parser attempts to parse them into executable SQL queries conditioned on the DB schema. For untranslatable questions, the confusion spans together with the context are fed into the question-correction modules to predict the user's attempted question. The response generation module handles user interaction by confirming a successful translation, soliciting feedback or asking the user to rephrase.</p><h2 id="user-feedback">User Feedback</h2><blockquote>Since its debut in July, thousands of users have interacted with the demo and we received much useful feedback. Check out these two highly engaged LinkedIn posts: <a href="https://www.linkedin.com/feed/update/urn:li:activity:6695940266932760576/?commentUrn=urn%3Ali%3Acomment%3A(activity%3A6695727069541867520%2C6695940165250248704)">link1</a>, <a href="https://www.linkedin.com/feed/update/urn:li:activity:6695343073091817472/?commentUrn=urn%3Ali%3Acomment%3A(activity%3A6695229458221293568%2C6695343012727402496)">link2</a>. </blockquote><p>Our demo users are primarily data scientists, analysts, software engineers, students and professors. √Ç&nbsp;Many liked our system and expressed strong interests in seeing future iterations. Below we summarize some suggestions and concerns, which may benefit future development of the community.</p><p><strong>Trust and Reliability. </strong>Deep learning based semantic parsers act as black boxes and their predictions lack interpretability. Moreover, it is difficult for end users to detect mistakes made by the parser when the output is executable and yields results of the same type as the correct interpretation (e.g. <em>flights arriving in SFO </em>vs. <em>flights departing from SFO</em>). Some developers have expressed reluctance to trusting the system output, highlighting the necessity of better explanation for both the generated queries and the process of deriving them. </p><p><strong>Self-control. </strong>Some users ‚Ä¶</p></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.einstein.ai/talk-to-your-data-one-model-any-database/">https://blog.einstein.ai/talk-to-your-data-one-model-any-database/</a></em></p>]]>
            </description>
            <link>https://blog.einstein.ai/talk-to-your-data-one-model-any-database/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24283687</guid>
            <pubDate>Wed, 26 Aug 2020 15:59:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SATCON1 Report on Impact of Satellite Constellations on Astronomy]]>
            </title>
            <description>
<![CDATA[
Score 86 | Comments 108 (<a href="https://news.ycombinator.com/item?id=24283229">thread link</a>) | @spenczar5
<br/>
August 26, 2020 | https://noirlab.edu/public/products/techdocs/techdoc003/ | <a href="https://web.archive.org/web/*/https://noirlab.edu/public/products/techdocs/techdoc003/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://noirlab.edu/public/products/techdocs/techdoc003/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24283229</guid>
            <pubDate>Wed, 26 Aug 2020 15:19:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scientists who never won a Nobel Prize]]>
            </title>
            <description>
<![CDATA[
Score 94 | Comments 84 (<a href="https://news.ycombinator.com/item?id=24283018">thread link</a>) | @mmhsieh
<br/>
August 26, 2020 | https://www.wondersofphysics.com/2019/01/scientists-who-never-won.html | <a href="https://web.archive.org/web/*/https://www.wondersofphysics.com/2019/01/scientists-who-never-won.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span>This is a list of scientists who have contributed greatly to our understanding of the world but who unfortunately never won the top honors. While some of the nobel snubs were the product of personal grudges or general biases particularly against women, others were matters of bad timing.</span></p><div>
<p><span><span>Her&nbsp;discovery of rotating neutron stars was recognized by the award of the 1974 Nobel Prize in Physics, but despite the fact that she was the first to observe the pulsars, Bell was excluded from the recipients of the prize.</span></span></p><table><tbody>
<tr><td><img alt="Top 10 Great Scientists Who Never Won A Nobel Prize" data-original-height="720" data-original-width="674" src="https://3.bp.blogspot.com/-5Swcbyyv0xI/XDrjsDt5kSI/AAAAAAAAINI/Eced0sYXqw42t21zFZgW6gvcdrEAXfargCLcBGAs/s1600/jocelyn%2Bbell%2Bburnell.jpg" title="Top 10 Great Scientists Who Never Won A Nobel Prize"></td></tr>
<tr><td>Irish astrophysicist</td></tr>
</tbody></table>

<p><span>As a postgraduate student, she helped in building the 16,000 m¬≤ radio telescope over two years and was the first person to notice the anomaly, sometimes reviewing as much as 29 meters of paper data per night.</span></p><h2>
<span>8. George Sudarshan</span></h2>
<br>
<table><tbody>
<tr><td><img alt="Top 10 Great Scientists Who Never Won A Nobel Prize" data-original-height="564" data-original-width="600" src="https://1.bp.blogspot.com/-qIyDtjQalxs/XDrowCq3BaI/AAAAAAAAINU/SzrsexZUv10_9tyjExZbEbj5UbDTrk_ZACLcBGAs/s1600/ECG_Sudarshan.jpg" title="Top 10 Great Scientists Who Never Won A Nobel Prize"></td></tr>
<tr><td>Indian physicist</td></tr>
</tbody></table>

<p><span>In 2005 several physicists wrote to the Swedish Academy, protesting that Sudarshan should have been awarded a share of the Prize for the <a href="https://en.wikipedia.org/wiki/Glauber%E2%80%93Sudarshan_P_representation" target="_blank">Sudarshan‚ÄìGlauber representation</a> in quantum optics, for which American physicist Roy J. Glauber won his share of the prize.</span></p><h2>
<span>7.&nbsp;Chien-Shiung Wu</span></h2>
<br>
<table><tbody>
<tr><td><img alt="Top 10 Great Scientists Who Never Won A Nobel Prize" data-original-height="829" data-original-width="802" height="400" src="https://4.bp.blogspot.com/-TfGWOsAlZ-8/XDrqnYtka6I/AAAAAAAAINg/2hLhJt-EzKwrfDB2wTC1nGLdoLxNufOtwCLcBGAs/s400/chien%2Bshiung%2Bwu.jpg" title="Top 10 Great Scientists Who Never Won A Nobel Prize" width="386"></td></tr>
<tr><td>Chinese experimental physicist</td></tr>
</tbody></table>

<p><span>She is best known for conducting the Wu experiment, which contradicted the most revered law of conservation of parity.&nbsp;This discovery resulted in her colleagues Lee and Yang winning the 1957 Nobel Prize in physics. Wu was not publicly honored until 1978.</span></p><h2>
<span>6. Lise Meitner</span></h2>
<br>
<table><tbody>
<tr><td><img alt="Top 10 Great Scientists Who Never Won A Nobel Prize" data-original-height="1024" data-original-width="842" height="400" src="https://2.bp.blogspot.com/-xWHu5gfTNVU/XDrsuGaPXuI/AAAAAAAAINs/uTQYy31ScSoPOaree7xyqtxOycxReFSfACLcBGAs/s400/lise%2Bmeitner.jpg" title="Top 10 Great Scientists Who Never Won A Nobel Prize" width="328"></td></tr>
<tr><td>Austrian-Swedish Chemist</td></tr>
</tbody></table>

<p><span>Lise Meitner along with long-time collaborator Otto Hahn led a small group of scientists who became the first to discover the nuclear fission of Uranium. The 1944 Nobel Prize in Chemistry was awarded exclusively to Otto Hahn and once again, a deserving candidate was not recognized.</span></p><p>

<span>According to <a href="https://en.wikipedia.org/wiki/Physics_Today" target="_blank">Physics Today</a>,&nbsp;</span><span>Meitner's exclusion from the chemistry award may well be summarized as a mixture of disciplinary bias, political obtuseness, ignorance, and haste. Today, nuclear fission is used to produce electricity in the nuclear power plants.</span></p><h2>
<span>5. Georges Lemaitre</span></h2>
<br>
<table><tbody>
<tr><td><img alt="Top 10 Great Scientists Who Never Won A Nobel Prize" data-original-height="502" data-original-width="422" src="https://1.bp.blogspot.com/-7HotVinnggQ/XDrwflZAoeI/AAAAAAAAIN4/04m3bE83IvEUzpbBxdFE2_7SQK2gX2eRwCLcBGAs/s1600/lemaitre.jpg" title="Top 10 Great Scientists Who Never Won A Nobel Prize"></td></tr>
<tr><td>Belgian Cosmologist</td></tr>
</tbody></table>

<p><span>Lema√É¬Ætre proposed the Big Bang theory. He was the first cosmologist ever nominated for the 1954 Nobel Prize in physics for his prediction of the expanding universe. Remarkably, he was also nominated for the 1956 Nobel prize in chemistry for his primeval-atom theory. He did not win both times.</span></p><h2>
<span>4. Henri Poincar√É¬©</span></h2>
<br>
<table><tbody>
<tr><td><img alt="Top 10 Great Scientists Who Never Won A Nobel Prize" data-original-height="500" data-original-width="371" src="https://1.bp.blogspot.com/-tnI4f37xnPI/XDrxkRZoqwI/AAAAAAAAIOE/u_k4gEMuGkEUXUZJEmMQ8cWUnS8aKSDOwCLcBGAs/s1600/Poincar%25C3%25A9.jpg" title="Top 10 Great Scientists Who Never Won A Nobel Prize"></td></tr>
<tr><td>French scientist</td></tr>
</tbody></table>

<p><span>Poincar√É¬© is considered brighter than Einstein by many a scientists. He was the first to propose gravitational waves emanating&nbsp;from a body and propagating at the speed of light as being required by the Lorentz transformations.&nbsp;</span><span>Poincar√É¬© was nominated a record 51 times for the Nobel Prize but never won.</span></p><h2>
<span>3. Nikola Tesla</span></h2>
<br>
<table><tbody>
<tr><td><img alt="Top 10 Great Scientists Who Never Won A Nobel Prize" data-original-height="698" data-original-width="900" src="https://4.bp.blogspot.com/-PT7ZBWdyrFk/XDr0BwmQbQI/AAAAAAAAIOQ/Q06M_S0l-kgGOtrOK5lBkstp27ws7OEzgCLcBGAs/s1600/tesla.jpg" title="Top 10 Great Scientists Who Never Won A Nobel Prize"></td></tr>
<tr><td>Serbian Inventor</td></tr>
</tbody></table>

<p><span>Nikola Tesla was a brilliant inventor known for his contributions to physics and engineering. He is most recognized&nbsp;for developing the alternating current electric system, which is still the predominant system used across the world today. His other inventions include Tesla coil, remote control and wireless telegraphy.</span></p><h2>
<span>2. Edwin Hubble</span></h2>

<p><span>First, he&nbsp;</span><span>revolutionized cosmology by showing that ours was not the only galaxy. The clouds of light which astronomers saw in the night sky were actually other galaxies beyond our Milky Way. He calculated distances to these galaxies.</span></p><table><tbody>
<tr><td><img alt="Top 10 Great Scientists Who Never Won A Nobel Prize" data-original-height="576" data-original-width="1024" src="https://4.bp.blogspot.com/-yqs30RtnHAc/XDr16K4xmAI/AAAAAAAAIOc/OJ7GG6YhAOo6p_fshuZtYWSN-DiWfcgDwCLcBGAs/s1600/hubble.jpg" title="Top 10 Great Scientists Who Never Won A Nobel Prize"></td></tr>
<tr><td>American Astronomer</td></tr>
</tbody></table>

<p><span>Second, he took the world by storm by proving that the galaxies were moving away from one another. The entire universe was expanding. He calculated the speeds at which the galaxies were receding.&nbsp;At the time of these two crucial discoveries, the Nobel Prize in Physics did not recognize work done in astronomy.</span></p><p>

<ins data-ad-layout="in-article" data-ad-format="fluid" data-ad-client="ca-pub-6931937217955460" data-ad-slot="2993882745"></ins>
<br>
<span>Hubble spent much of the latter part of his career attempting to have astronomy considered an area of physics.&nbsp;Shortly after his death, the Nobel Prize Committee decided that astronomical work would be eligible for the physics prize, however, the prize is not one that can be awarded posthumously.</span></p><h2>
<span>1. Satyendra Nath Bose</span></h2>
<br>
<table><tbody>
<tr><td><img alt="Top 10 Great Scientists Who Never Won A Nobel Prize" data-original-height="726" data-original-width="776" height="373" src="https://2.bp.blogspot.com/-0lbVkdIcbaU/XDr4efmSp-I/AAAAAAAAIOo/ETqszvV4GIsJbB2rjVDGjRCUrQT06c1uQCLcBGAs/s400/bose.jpg" title="Top 10 Great Scientists Who Never Won A Nobel Prize" width="400"></td></tr>
<tr><td>Indian Theoretical Physicist</td></tr>
</tbody></table>

<p><span>Bose is best known for his work on quantum mechanics in the early 1920s, providing the foundation for Bose‚ÄìEinstein statistics and the theory of the Bose‚ÄìEinstein condensate, the fifth state of matter.</span><br>
<span><br></span>
<span>Bose's work was evaluated by an expert of the Nobel Committee, Oskar Klein, who did not see his work worthy of a Nobel Prize.</span></p><p>

<span>Several Nobel Prizes were awarded related to the field initiated by him but Bose himself was never presented the coveted prize.&nbsp;</span><span>Yet <a href="https://www.wondersofphysics.com/2018/12/satyendra-nath-bose-biography.html" target="_blank">half the particles in the universe obey him</a> and that itself is a remarkable achievement.</span></p></div></div>]]>
            </description>
            <link>https://www.wondersofphysics.com/2019/01/scientists-who-never-won.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24283018</guid>
            <pubDate>Wed, 26 Aug 2020 14:55:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[First tax year with Stripe Atlas]]>
            </title>
            <description>
<![CDATA[
Score 194 | Comments 154 (<a href="https://news.ycombinator.com/item?id=24282940">thread link</a>) | @jmstfv
<br/>
August 26, 2020 | https://tryhexadecimal.com/journal/business-taxes | <a href="https://web.archive.org/web/*/https://tryhexadecimal.com/journal/business-taxes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    

    
      <section>
        <p><em>Disclaimer: this blog post doesn‚Äôt constitute accounting advice. When in doubt, talk to a lawyer/accountant and all that jazz.</em></p>

<h2 id="background">Background</h2>

<p>I incorporated a C Corp in the State of Delaware via Stripe Atlas in February 2019. It was my first time dealing with the tax system in the US, as I‚Äôve never been or operated a business there.</p>

<p>Taxes must be one of the scariest aspects precluding folks from going into a business. Below is an account of how I <del>struggled</del> dealt with my first tax season.</p>

<p>All usual disclaimers apply.</p>

<h2 id="why-a-c-corp-instead-of-an-llc">Why a C-Corp instead of an LLC?</h2>

<p>A single-member LLC (regarded as a pass-through entity by default) complicates tax situation for nonresident aliens - a term-of-art for non-US citizens &amp; residents (which is me).</p>

<p>While C Corps are more complex to run, their tax treatment is relatively straightforward: they‚Äôre only taxed on their profits. If you‚Äôre paying yourself a salary, you can expense that amount, which will lower your taxable income (assuming you‚Äôre not a US taxpayer. Otherwise, it gets complicated, fast).</p>

<p>If you‚Äôre a US citizen or a resident, LLC is more apt if you want to bootstrap your business.</p>

<p>At the time of writing, Stripe has restricted LLCs to US founders only. Presumably, some folks have shot themselves in feet too much that they decided to pull the plug.</p>

<h2 id="registered-agent">Registered agent</h2>

<p>Companies formed in the State of Delaware are required to keep a registered agent in the state. Think of it as an address state and federal agencies use to get ahold of you.</p>

<p>Somewhere around mid-January, you will receive an email from Stripe Atlas asking whether you want to renew the registered agent. If you don‚Äôt explicitly opt-out, they will automatically renew your registered agent subscription by the end of January.</p>

<p>Unfortunately, the registered agent that comes with Atlas can‚Äôt accept general mail (except for bank cards). Some virtual address providers (aka <abbr title="Commercial mail receiving agency">CMRA</abbr>) can act as your registered agent. That way, you can avoid the $100 fee for the default registered agent that comes with Atlas. To change the registered agent, you will have to complete a ‚ÄúChange of Address‚Äù form.</p>

<h2 id="delaware-franchise-tax">Delaware Franchise Tax</h2>

<p>While Delaware doesn‚Äôt have a sales tax, they do impose a <em>Franchise Tax</em> on registered businesses.</p>

<p>There are two ways to calculate the Franchise Tax: Authorized Shares Method and Assumed Par Value Capital Method. I won‚Äôt get into a <a href="https://corp.delaware.gov/frtaxcalc/">nitty-gritty</a>, but suffice it to say that you can use one that minimizes your tax liability.</p>

<p>A lot of folks running C Corps get stupendously high tax estimates amounting to tens or hundreds of thousands of dollars (causing a drama on the Stripe Atlas forum every time). It happens because the State of Delaware uses an Authorized Shares Method that results in higher tax bills. Once you switch to the Assumed Par Value Capital Method, your tax liability will (probably) drop to $450.</p>

<p>You don‚Äôt need an accountant to file an annual report, although the user interface is horrendous, to put it mildly.</p>

<p>One thing that I wish I‚Äôd known is that you can save on the Franchise Tax by authorizing 5000 shares (or less) instead of 10,000,000 shares, which is the Atlas‚Äô default. That way, your tax due will be $225 ($175 minimum tax + $50 annual report filing fee) instead of $450. LLCs in Delaware pay a flat $300 tax.</p>

<h2 id="corporate-income-taxes">Corporate income taxes</h2>

<p>You pay corporate income taxes on the profit you make during the tax year. Even if you didn‚Äôt earn a single cent from the business, you still have to file a tax report by April 15th (you can ask the <abbr title="Internal Revenue Service">IRS</abbr> to extend the deadline).</p>

<p>Nothing precludes you from filing tax reports yourself. Unless you know what you‚Äôre doing, you will probably screw it up (terribly) and waste a lot of time that you otherwise can spend on running your business (tax reporting shouldn‚Äôt be <em>that</em> complex, but that‚Äôs a topic for another day). Stripe Atlas has partnered with two accounting firms offering tax preparation services at a discount.</p>

<p>Your accountant will ask you some questions and your balance sheet and an income (P&amp;L) statement for the previous financial year, so you will have to take care of the bookkeeping before talking to the accountant.</p>

<p>Because I‚Äôm a foreigner owning more than 25% of a US corporation, I have to file Form 5472 as well (in addition to Form 1120). The inaccurate filling or failure to file it usually carries a $25,000 fine. In that light, it‚Äôs better to pay an accountant and not worry about it.</p>

<p>Make sure you have an <abbr title="Electronic Federal Tax Payment System">EFTPS</abbr> pin code before the tax season. However, judging by the number of discussions on the Stripe Atlas forum, a lot of folks outside the US don‚Äôt receive that mail. To add an insult to the injury, they don‚Äôt give you the pin code over the phone. If you‚Äôre outside of the US, get yourself a mailing address in the US, and ask the IRS to mail you the EFTPS pin code.</p>

<h2 id="just-give-me-the-numbers">Just give me the numbers</h2>

<table>
  <thead>
    <tr>
      <th>Item</th>
      <th>Cost</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Registered agent</td>
      <td>$100</td>
    </tr>
    <tr>
      <td>Delaware Franchise Tax (C Corp)</td>
      <td>$450</td>
    </tr>
    <tr>
      <td>Accounting service (discounted)</td>
      <td>$250</td>
    </tr>
  </tbody>
</table>

<p>So with the default Stripe Atlas setup for C Corps, you‚Äôre looking at $800 for yearly maintenance at a minimum (without corporate income taxes). If you opt to use a default bank account provided by Atlas (SVB), add $300 on top of that ($25 x 12), unless you maintain an average balance of $25,000 per month.</p>

<p>If you plan to incorporate towards the end of the year, wait until January. That way, you can <em>skip</em> one tax year and spend time building a business instead of doing a soul-sucking administrative busywork.</p>


        
          <section>
  
  <section>
    <p>No link tracking, no hidden pixels, no promotional emails, or other nonsense. I will only send you one email when a new article is out. Unsubscribe anytime.</p>
    <p>You can also subscribe to the <a href="https://tryhexadecimal.com/journal/feed.xml">Atom feed</a> (it's like RSS, but better).</p>
  </section>
</section>

        
      </section>

    
  </div></div>]]>
            </description>
            <link>https://tryhexadecimal.com/journal/business-taxes</link>
            <guid isPermaLink="false">hacker-news-small-sites-24282940</guid>
            <pubDate>Wed, 26 Aug 2020 14:46:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Discrete Cosine Transform in Video Compression ‚Äì Explain Like I'm Five]]>
            </title>
            <description>
<![CDATA[
Score 116 | Comments 46 (<a href="https://news.ycombinator.com/item?id=24281857">thread link</a>) | @ponderingfish
<br/>
August 26, 2020 | https://ottverse.com/discrete-cosine-transform-dct-video-compression/ | <a href="https://web.archive.org/web/*/https://ottverse.com/discrete-cosine-transform-dct-video-compression/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><b>In this article of the "Hitchhiker's Guide to Video Compression" series, let's understand what Transforms are with a simple and intuitive example. And, then let's go on to understand the role of the Discrete Cosine Transform (DCT) in Image and Video compression.</b></p><div><p>üëã This is part of a series of articles titled <b>"The Hitchhiker's Guide to Video Compression"</b> - a gentle and opinionated introduction to the fascinating world of video compression.</p><p>üîî <a href="https://ottverse.com/subscribe">Subscribe</a> to get notified of <b>"The Hitchhiker's Guide to Video Compression"</b> articles directly in your inbox, or, follow via <a href="https://twitter.com/OttVerse" target="_blank">Twitter</a> or, <a href="https://www.linkedin.com/company/66682014/admin/" target="_blank">LinkedIn</a>.</p></div><h2 id="lets-start-with-a-simple-exercise">Let‚Äôs Start With A Simple Exercise</h2><p>Before we take on the deeply mathematical subject of transforms in signal processing, let‚Äôs first get an intuitive undestanding of the ‚Äúwhy‚Äù of transforms. Why are they needed and what is their role?</p><p><strong><em>Disclaimer: video engineer here and not a photoshop expert :)</em></strong></p><p>Take a look the image below and imagine that you are looking at three spheres/balls through your window. If ask you which sphere is the biggest, you‚Äôll be able to tell me, right?</p><figure><img src="https://ottverse.com/images/front-view-3-spheres.png"><figcaption><h4>Front View of Three Spheres Through a Window</h4></figcaption></figure><p>Well, this appears easy. The sphere on the left appears to be the smallest and the one on the right is the biggest. Right?</p><h3 id="are-you-sure-though">Are You Sure Though?</h3><p>Now, If I show you aerial view of the three spheres (taken using a drone!), do you think it will change your mind?</p><p>Not sure? Let‚Äôs take a look.</p><figure><img src="https://ottverse.com/images/top-view-three-spheres.png"><figcaption><h4>Top View of The Three Spheres</h4></figcaption></figure><p>What you are looking at in this image</p><ul><li>are the three spheres from above, and</li><li>the thick blue line is the top view of the window (hence, it looks 2-dimensional)</li></ul><p>The spheres appear to be the same size as each other, right? Except, they are at different distances from the window (house).</p><p>The left-most sphere is very far from the window and hence it looks the smallest. On the other hand, the sphere on the right is close to the window and hence it looks the biggest!</p><p>Now, do you want to change your answer?</p><h2 id="your-view-of-the-data-was-transformed">Your View of the Data was Transformed</h2><p>Let‚Äôs take a minute to understand what we just did.</p><p>We took a piece of data and developed two views of the data <strong>by changing our physical position</strong>. That is, we looked at the data</p><ul><li>from front and</li><li>from above</li></ul><p>And, these two ‚Äúdifferent‚Äù views combined gave us a much better understanding of the data!</p><p>Now, let‚Äôs take a look at another example of a transform.</p><h2 id="starry-skies-and-constellations">Starry Skies and Constellations</h2><p>When you look into the starry night and locate a constellation, ask yourself this - are all the stars in that constellation on the same plane? Or are they very far away from each other?</p><p>Here is an amazing video that shows how ‚Äúcorrelated‚Äù stars in a constellation are. You‚Äôll see that the stars are in fact very, very, very far away from each other, but, they appear to lie on the same plane and in a particular shape because we are looking at the stars from Earth.</p><p><iframe src="https://www.youtube.com/embed/lD-5ZOipE48" allowfullscreen="" title="YouTube Video"></iframe></p><p>The distance between the stars became apparent when we transformed our view point which allowed us to gain more information about the data.</p><p><strong>This is exactly what a transform does.</strong></p><p>A transform is a mathematical function that <strong>transforms</strong> (changes) the input data from one <strong>domain</strong> (view) to another in order to,</p><ul><li>expose hidden characteristics of the data, or</li><li>gain a better (combined) understanding of the data, or</li><li>highlight or downplay certain characteristics of the data.</li></ul><p>I spent time explaining ‚Äútransforms‚Äù because this is typically the blocking point for most people trying to understand the discrete cosine transform or for that matter, any transform (Fourier, Z, Laplace, etc.)</p><p>With this understanding, let‚Äôs learn about the famous Discrete Cosine Transform.</p><h2 id="explain-dct-like-im-five">Explain DCT Like I‚Äôm Five</h2><p>After all the math and technical jargon, let‚Äôs try and explain the DCT to a 5 year old (it‚Äôs hard but let‚Äôs try).</p><p>Imagine you are playing ‚ÄúI Spy With My Little Eye‚Äù with a small kid. For those who don‚Äôt know, its a game where a person chooses an item in a room in his mind and the others have to guess it by asking questions (like 20 questions).</p><p>Now, let‚Äôs assume that I think of a painting of a boat hanging on the wall and ask a 5 year old to ask questions and guess what I am thinking of.</p><p>For the sake of this example, lets tweak the rules and provide 20 clues ourselves.</p><p>The best clue that we can provide is something like this ‚Äúthe item is hanging on the wall opposite the door‚Äù. This is guaranteed to lead the kid close to the prize, right?</p><p>The next best clue would be something like ‚Äúthe item is a square or box-shaped‚Äù. After that, we could say something like ‚Äúit has an ocean and a boat in it.‚Äù.</p><p>If you do this carefully, you don‚Äôt need 20 clues to guide the kid to the painting ‚Äì in all likelihood, 5 - 8 clues would suffice.</p><p>And so on.</p><p>What you‚Äôve done is,</p><ul><li>taken data (the location of a painting)</li><li>converted the location into a set of 20 clues</li><li>provided or arranged the clues in order of importance.</li><li>proved that only a few of the clues can capture the location of the painting while the rest of them add details to the puzzle.</li></ul><p>This is in essence what the DCT does. It takes data in one form, converts it to another form such that the output data is arranged in order of importance. This allows us to throw away most of the output data and still be able to get back to the original data.</p><p>Hope you understood what the DCT is trying to achieve. Because, unfortunately, the kid gloves gotta come off now!</p><h2 id="introducing-the-discrete-cosine-transform">Introducing the Discrete Cosine Transform</h2><p>The Discrete Cosine Transform or DCT is a widely used transform for image and video compression. It‚Äôs definition as per Wikipedia is as follows :-</p><blockquote><p>The Discrete Cosine Transform expresses a finite sequence of data points in terms of a sum of cosine functions oscillating at different frequencies.</p></blockquote><p>Still with me? Don‚Äôt worry about the math behind the DCT for now.</p><p>In simpler terms, the Discrete Cosine Transform takes a set of <code>N</code> correlated (similar) data-points and returns <code>N</code> de-correlated (dis-similar) data-points (coefficients) in such a way that the energy is compacted in only a few of the coefficients <code>M</code> where <code>M &lt;&lt; N</code>.</p><p>If that doesn‚Äôt make sense, try and remember this - the DCT takes input data and converts it to another domain while doing two very important things -</p><ol><li><strong>it de-correlates the data (removes any relation or similarity between the data points)</strong></li><li><strong>it compacts the energy/information into only a few of the output data points</strong></li></ol><p>To summarize, the DCT takes</p><ul><li>N data-points as its input</li><li>returns N data-points as its output</li><li>and ensures, that most of the information of the input is concentrated in only a few of the N output data-points.</li></ul><p>This is called the energy-compaction (or information compaction) property of the DCT.</p><p>Let‚Äôs understand this with an example using MATLAB.</p><p>Take an <code>8x8</code> matrix filled with the number <code>255</code> as shown below. If you need <code>8</code> bits to store each number, then you need <code>8 x 64 = 512</code> bits for storing the entire matrix. Good so far?</p><figure><img src="https://ottverse.com/images/input_255.png"></figure><p>Okay, now, let‚Äôs apply an <code>8x8</code> 2D-DCT to this matrix and get <code>8x8</code> DCT coefficients. They are shown below.</p><figure><img src="https://ottverse.com/images/coeffs_255.png"></figure><p>Looks different, doesn‚Äôt it?</p><p>If you notice carefully, the first coefficient (<code>[0, 0]</code>) element of the matrix is non-zero and the rest of the elements are zero. This greatly reduces the storage space needed for this matrix.</p><p>This is due to the de-correlating and energy compaction property of the DCT. This is usually described as follows in technical literature and can be a little difficult to understand -</p><blockquote><p><strong><em>the DCT has compacted the energy of the matrix into the first element referred to as the <code>DC</code> coefficient. The rest of the coefficients are called the <code>AC</code> coefficients.</em></strong></p></blockquote><p>What this is referring to is -</p><ul><li>the top-left corner of the output 2D DCT is called the DC coefficient. It is the most important output of the DCT and contains a lot of information about the original image.</li><li>the rest of the coefficients are called the AC coefficients. If you are transforming an image using the DCT, the AC coefficients contain finer details of the image.</li></ul><p>Now, if I take these DCT coefficients and apply an inverse-2D-DCT to it, I will get back the original coefficients.</p><p>If you want to try it out, here are the MATLAB commands to replicate the above experiment.</p><div><pre><code data-lang="matlab">inputPixels = <span>ones</span>(<span>8</span>,<span>8</span>) * <span>255</span>;
dctCoeffs = dct2(inputPixels);
reconstructedPixels = idct2(dctCoeffs);
</code></pre></div><h2 id="application-of-dct-to-image--video-compression">Application of DCT to Image &amp; Video Compression</h2><p>The de-correlation and energy compaction properties of the DCT make it extremely attractive to image and video compression. The Karhunen‚ÄìLo√®ve transform (KLT) often referred to as the <em>ideal transform</em> has much better decorrelating properties but is computationally intractable. The DCT on the other hand, is easy to program and has captured the image and video compression world.</p><p>Here is a simple MATLAB <a href="https://in.mathworks.com/help/images/ref/dct2.html">script</a> that demonstrates the power of the 2D-DCT when applied to image compression (and, in extension to video compression).</p><div><pre><code data-lang="matlab"><span>% read an image (MATLAB provides a few sample images)</span>
RGB = imread(<span>'autumn.tif'</span>);

<span>% convert to grayscale</span>
I = rgb2gray(RGB);

<span>% compute the 2D DCT</span>
J = dct2(I);

<span>% discard certain coefficients (set to zero)</span>
J(<span>abs</span>(J) &lt; T) = <span>0</span>;

<span>% recover the pixels using the inverse 2D DCT</span>
K = idct2(J);

<span>% matlab code to display the original and reconstructed image</span>
figure
imshowpair(I,K,<span>'montage'</span>)
title(<span>'Original Grayscale Image (Left) and Reconstructed Image (Right)'</span>);
</code></pre></div><p>The code is very simple -</p><ul><li>load an image (RGB) and convert it to gray-scale</li><li>compute the 2D-DCT and store it in <code>J</code></li><li><strong>set all the coefficients whose magnitude is less than a threshold <code>T</code> to <code>0</code></strong></li><li>compute the inverse 2D-DCT and recover the pixels (reconstructed)</li><li>compare the two images - original and reconstructed.</li></ul><p>Now, let‚Äôs run two experiments.</p><p><strong>Experiment 1:</strong>
Let‚Äôs set the threshold to <code>50</code> and set all the AC coefficients whose magnitude is less than <code>50</code> to <code>0</code>. And, then reconstruct the image using the inverse-DCT. Remember, we do not touch the DC coefficient in this example (whose magnitude is much, much greater than <code>50</code>).</p><p>If you take a look at the image below, you can see that it is blurred and doesn‚Äôt have all the features. But, here is the amazing part - we set a large number of coefficients to zero, we retained <strong>only 3.45% of the total <code>71070</code> coefficients.</strong> So, with just 3.45% of ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ottverse.com/discrete-cosine-transform-dct-video-compression/">https://ottverse.com/discrete-cosine-transform-dct-video-compression/</a></em></p>]]>
            </description>
            <link>https://ottverse.com/discrete-cosine-transform-dct-video-compression/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24281857</guid>
            <pubDate>Wed, 26 Aug 2020 12:41:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Vim-Like Layer for Xorg and Wayland]]>
            </title>
            <description>
<![CDATA[
Score 102 | Comments 37 (<a href="https://news.ycombinator.com/item?id=24280413">thread link</a>) | @ceda_ei
<br/>
August 26, 2020 | https://cedaei.com/posts/vim-like-layer-for-xorg-wayland/ | <a href="https://web.archive.org/web/*/https://cedaei.com/posts/vim-like-layer-for-xorg-wayland/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
        
<h2 id="insert-mode">Insert Mode<a href="#insert-mode" arialabel="Anchor">‚åó</a> </h2>
<p><img src="https://cedaei.com/images/insert_mode.jpg" alt="Insert Mode: A keyboard layout similar to normal QWERTYlayout"></p>
<h2 id="normal-mode">Normal Mode<a href="#normal-mode" arialabel="Anchor">‚åó</a> </h2>
<p><img src="https://cedaei.com/images/normal_mode.jpg" alt="Normal Mode: A keyboard layout with the alphabet keys replaced with shortcutkey"></p>
<p>Inspired by vim, I wanted to create a layer on top of my keyboard which worked
like a shortcut layer. So, to start off, I found out about XKB<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>. XKB is the
Xorg Keyboard Extension which tells Xorg on how to react to input from
keyboard.  After reading through some source code, I found out that Xorg has
support for function keys F1 - F35<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>. The general idea here was:</p>
<ul>
<li>Create an insert mode layout for text input.</li>
<li>Replace keys with relevant keys in normal mode (e.g. replace j with Down) and
for keys that require executing a command, replace then with a function key
above F12 (e.g. replace q with F13).</li>
<li>Bind all the function keys above F12 to the respective functions.</li>
</ul>
<p>To start off, I began a fresh Xorg session with nothing modifying the keys
(removed <code>xmodmap</code> from startup) and first dumped the current layout into a
file.</p>
<div><pre><code data-lang="bash">xkbcomp $DISPLAY ~/.xkb/insert.xkb
</code></pre></div><p>This was my starting point. I made changes to this file which were common to
both Insert and Normal mode. e.g. replaced <code>Caps Lock</code> with <code>Ctrl</code> and made
<code>Shift+Caps Lock</code> <code>Caps Lock</code>. Also, I unbound <code>Alt_R</code> as a modifier so that I
could use that as a switch between Normal and Insert Mode.</p>
<p>Here is a diff between the original layout and Insert mode.</p>
<pre><code>1323c1321
&lt;     key &lt;CAPS&gt; {         [       Caps_Lock ] };
---
&gt;     key &lt;CAPS&gt; {         [       Control_L,       Caps_Lock ] };
1551c1549
&lt;     modifier_map Lock { &lt;CAPS&gt; };
---
&gt;     modifier_map Control { &lt;CAPS&gt; };
1555d1552
&lt;     modifier_map Mod1 { &lt;RALT&gt; };
</code></pre><p>Next, I copied <code>~/.xkb/insert.xkb</code> to <code>~/.xkb/normal.xkb</code>. I replaced keys as
per the plan.</p>
<p>Here is a diff between Insert mode and Normal mode.</p>
<div><pre><code data-lang="diff">1200c1200
&lt;         symbols[Group1]= [               q,               Q ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F13]
1204c1204
&lt;         symbols[Group1]= [               w,               W ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F14]
1208c1208
&lt;         symbols[Group1]= [               e,               E ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F15]
1212c1212
&lt;         symbols[Group1]= [               r,               R ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F16]
1216c1216
&lt;         symbols[Group1]= [               t,               T ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F17]
1220c1220
&lt;         symbols[Group1]= [               y,               Y ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F18]
1224c1224
&lt;         symbols[Group1]= [               u,               U ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F19]
1228c1228
&lt;         symbols[Group1]= [               i,               I ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [Alt_R]
1232c1232
&lt;         symbols[Group1]= [               o,               O ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F20]
1236c1236
&lt;         symbols[Group1]= [               p,               P ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F21]
1244c1244
&lt;         symbols[Group1]= [               a,               A ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F22]
1248c1248
&lt;         symbols[Group1]= [               s,               S ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [Delete]
1252c1252
&lt;         symbols[Group1]= [               d,               D ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [BackSpace]
1256c1256
&lt;         symbols[Group1]= [               f,               F ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [Home]
1260c1260
&lt;         symbols[Group1]= [               g,               G ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [End]
1264c1264
&lt;         symbols[Group1]= [               h,               H ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [Left]
1268c1268
&lt;         symbols[Group1]= [               j,               J ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [Down]
1272c1272
&lt;         symbols[Group1]= [               k,               K ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [Up]
1276c1276
&lt;         symbols[Group1]= [               l,               L ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [Right]
1285c1285
&lt;         symbols[Group1]= [               z,               Z ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F23]
1289c1289
&lt;         symbols[Group1]= [               x,               X ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F24]
1293c1293
&lt;         symbols[Group1]= [               c,               C ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F25]
1297c1297
&lt;         symbols[Group1]= [               v,               V ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F26]
1301c1301
&lt;         symbols[Group1]= [               b,               B ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [F27]
1305c1305
&lt;         symbols[Group1]= [               n,               N ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [Next]
1309c1309
&lt;         symbols[Group1]= [               m,               M ]
<span>---
</span><span></span>&gt;         symbols[Group1]= [Prior]
</code></pre></div><p>At this point, <code>normal.xkb</code> file defines the following layout.</p>
<p><img src="https://cedaei.com/images/normal_mode_unbound.jpg" alt="Normal Mode: A keyboard "></p>
<p>Now, we need a script that switches between layouts. To load an layout in Xorg, we use</p>
<div><pre><code data-lang="bash">xkbcomp ~/.xkb/normal.xkb <span>"</span>$DISPLAY<span>"</span>
</code></pre></div><p>Sway supports this via the input command in the following form.</p>
<div><pre><code data-lang="bash">swaymsg input <span>'*'</span> xkb_file ~/.xkb/normal.xkb
</code></pre></div><p>The following script cycles through the layouts when it is called. It also
allows to add more layouts later (just add them to layouts array and it will
cycle in the order of the array).</p>
<div><pre><code data-lang="bash"><span>#!/usr/bin/env bash
</span><span></span><span># Usage: xkb_swapper.sh [layout_name]</span>

<span>function</span> set_layout<span>()</span> <span>{</span>
	echo <span>"Setting layout to </span>$1<span>"</span>
	<span>if</span> <span>[[</span> -v WAYLAND_DISPLAY <span>]]</span>; <span>then</span>
		swaymsg input <span>'*'</span> xkb_file ~/.xkb/<span>"</span>$1<span>"</span>.xkb
	<span>else</span>
		xkbcomp ~/.xkb/<span>"</span>$1<span>"</span>.xkb <span>"</span>$DISPLAY<span>"</span>
	<span>fi</span>
	echo <span>"</span>$1<span>"</span> &gt; ~/.cache/xkb-curr-<span>"</span>$DISPLAY<span>"</span>
<span>}</span>
layouts<span>=(</span>insert normal<span>)</span>
current_layout<span>=</span><span>$(</span>cat ~/.cache/xkb-curr-<span>"</span>$DISPLAY<span>"</span> <span>||</span> echo <span>""</span><span>)</span>

<span>if</span> <span>[[</span> $1 !<span>=</span> <span>""</span> <span>]]</span>; <span>then</span>
	set_layout <span>"</span>$1<span>"</span>
	exit
<span>fi</span>
<span>if</span> <span>[[</span> $current_layout <span>==</span> <span>""</span> <span>]]</span>; <span>then</span>
	echo <span>"No current layout found!"</span>
	set_layout <span>"</span><span>${</span>layouts[0]<span>}</span><span>"</span>
<span>fi</span>

i<span>=</span><span>0</span>
<span>while</span> <span>[[</span> $i -lt <span>${#</span>layouts[@]<span>}</span> <span>]]</span>; <span>do</span>
	<span>if</span> <span>[[</span> $current_layout <span>==</span> <span>"</span><span>${</span>layouts[$i]<span>}</span><span>"</span> <span>]]</span>; <span>then</span>
		new_idx<span>=</span><span>"</span><span>$((</span>i+1<span>))</span><span>"</span>
		<span>if</span> <span>[[</span> $new_idx -eq <span>${#</span>layouts[@]<span>}</span> <span>]]</span>; <span>then</span>
			set_layout <span>"</span><span>${</span>layouts[0]<span>}</span><span>"</span>
		<span>else</span>
			set_layout <span>"</span><span>${</span>layouts[$new_idx]<span>}</span><span>"</span>
		<span>fi</span>
		exit
	<span>fi</span>
	<span>((</span>i++<span>))</span>
<span>done</span>

echo <span>"Current Layout doesn't exist!"</span>
set_layout <span>"</span><span>${</span>layouts[0]<span>}</span><span>"</span>
</code></pre></div><p>The above script works with all Xorg based DE/WMs as well as Sway (wayland
compositor). I saved it as <code>xkb_swapper.sh</code> in my <code>PATH</code>. Calling the script
without any argument cycles through the layouts. If arguments are passed, the
first argument is taken as layout name and layout is changed to that.</p>
<p>The last step is binding the function keys and <code>Alt_R</code> to commands to execute.
Here are some of the parts of my i3 config that bind the function keys.</p>
<pre><code>bindsym Alt_R exec xkb_swapper.sh
bindsym 0xffca kill
bindsym 0xffcf exec volchange -5
bindsym 0xffd0 exec volchange +5
bindsym 0xffd1 exec brightness -200
bindsym 0xffd2 exec brightness +200
bindsym 0xffcb exec mpc prev
bindsym 0xffcc exec mpc toggle
bindsym 0xffcd exec mpc next
</code></pre><p><code>i3</code> doesn‚Äôt seem to accept <code>F13</code> - <code>F35</code> as keynames however it accepts the
keycodes<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>.  Here is a small list for easy access.</p>
<pre><code>0xffbe   F1
0xffbf   F2
0xffc0   F3
0xffc1   F4
0xffc2   F5
0xffc3   F6
0xffc4   F7
0xffc5   F8
0xffc6   F9
0xffc7   F10
0xffc8   F11
0xffc9   F12
0xffca   F13
0xffcb   F14
0xffcc   F15
0xffcd   F16
0xffce   F17
0xffcf   F18
0xffd0   F19
0xffd1   F20
0xffd2   F21
0xffd3   F22
0xffd4   F23
0xffd5   F24
0xffd6   F25
0xffd7   F26
0xffd8   F27
0xffd9   F28
0xffda   F29
0xffdb   F30
0xffdc   F31
0xffdd   F32
0xffde   F33
0xffdf   F34
0xffe0   F35
</code></pre>
<p>The script stores the mode in <code>~/.cache/xkb-curr-$DISPLAY</code>. <code>cat</code> that and
wrap in your bar‚Äôs config. Here is my config for
<a href="https://github.com/greshake/i3status-rust">i3status-rust</a>.</p>
<div><pre><code data-lang="toml">[[<span>block</span>]]
<span>block</span> = <span>"custom"</span>
<span>command</span> = <span>"echo -en '\\uf11c '; cat ~/.cache/xkb-curr-$DISPLAY"</span>
<span>interval</span> = <span>0.5</span>
</code></pre></div><section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>As always, the <a href="https://wiki.archlinux.org/index.php/X_keyboard_extension">Arch Wiki page on XKB</a> is a nice place to start. <a href="#fnref:1" role="doc-backlink">‚Ü©Ô∏é</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>You can find all the defined keys in <code>/usr/include/X11/keysymdef.h</code>. <a href="#fnref:2" role="doc-backlink">‚Ü©Ô∏é</a></p>
</li>
</ol>
</section>

      </div></div></div>]]>
            </description>
            <link>https://cedaei.com/posts/vim-like-layer-for-xorg-wayland/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24280413</guid>
            <pubDate>Wed, 26 Aug 2020 08:34:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[YC Software Startups: Value and Initial Programming Language Used]]>
            </title>
            <description>
<![CDATA[
Score 169 | Comments 148 (<a href="https://news.ycombinator.com/item?id=24279611">thread link</a>) | @charliereese
<br/>
August 25, 2020 | https://charliereese.ca/article/top-50-y-combinator-tech-startups | <a href="https://web.archive.org/web/*/https://charliereese.ca/article/top-50-y-combinator-tech-startups">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

			<div>

				<p>This article contains a list of the top 50 YC software startups (sourced from the October 2019 <a href="https://www.ycombinator.com/topcompanies/">YC Top Companies</a> page). It also contains aggregated statistics for valuations and back-end programming languages used.</p>
<p>Values in this article are sourced, but I cannot guarantee their accuracy.</p>
<p>Follow me on Twitter <a href="https://twitter.com/charlieinthe6">@charlieinthe6</a> for similar content. <a href="https://news.ycombinator.com/item?id=24279611">View article comments on HackerNews</a>.</p>
<p>‚òï</p>
<p><strong>Table of Contents:</strong></p>
<ol>
<li><a href="#top-50">Top 50 Software Startups</a></li>
<li><a href="#stats">Aggregated Stats</a></li>
</ol>
<h3 id="top-50">1. Top 50 Software Startups:</h3>
<table>
<thead>
<tr>
<th>Company</th>
<th>Latest val ($MM)</th>
<th>Initial back-end language(s)</th>
<th>DataSci / LowLv</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://stripe.com/">Stripe</a>: <br>Payment / economic infrastructure for internet</td>
<td>36,000 <small> <a href="https://detroit.cbslocal.com/2020/08/11/general-motors-cfo-exits-suddenly-for-silicon-valley/">source</a> </small></td>
<td>Ruby <small> <a href="https://qr.ae/pN2pJk">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://getcruise.com/">Cruise</a>: <br>Building self-driving car tech</td>
<td>19,000 <small> <a href="https://www.thedrive.com/tech/27872/gm-cruise-divisions-new-1b-investment-sets-valuation-at-staggering-19b">source</a> </small></td>
<td>C++, Python <small> <a href="https://angel.co/company/cruise-automation/jobs/757823-staff-deep-learning-optimization-engineer">source</a>, <a href="https://angel.co/company/cruise-automation/jobs/841627-staff-software-engineer-c-frameworks">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://airbnb.com/">Airbnb</a>: <br>Marketplace to rent someone‚Äôs room</td>
<td>18,000 <small> <a href="https://sanfrancisco.cbslocal.com/2020/08/11/airbnb-ipo-reportedly-close-to-filing-wsj/">source</a> </small></td>
<td>Ruby <small> <a href="https://www.forbes.com/sites/quora/2018/02/20/what-technology-stack-does-airbnb-use/#448ff4184025">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://doordash.com/">DoorDash</a>: <br>Food delivery</td>
<td>16,000 <small> <a href="https://www.cnn.com/2020/06/18/tech/doordash-funding-valuation/index.html">source</a> </small></td>
<td>Python <small> <a href="https://medium.com/@DoorDash/implementing-rest-apis-with-embedded-privacy-a2394dc4dceb">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://twitch.tv/">Twitch</a>: <br>Gaming video platform / community</td>
<td>15,000 <small> <a href="https://www.cnbc.com/2020/06/16/amazon-media-assets-worth-500-billion-almost-as-much-as-aws-needham.html#:~:text=To%20get%20to%20%24500%20billion,business%20is%20at%20%243.8%20billion.">source</a> </small></td>
<td>C++, Ruby <small> <a href="https://blog.twitch.tv/en/2015/12/18/twitch-engineering-an-introduction-and-overview-a23917b71a25/">source</a> (founded before Go)</small></td>
<td>N / Y</td>
</tr>
<tr>
<td><a href="https://instacart.com/">Instacart</a>: <br>Grocery pick-up / delivery</td>
<td>13,700 <small> <a href="https://techcrunch.com/2020/06/11/instacart-raises-225-million-at-13-7-billion-valuation/">source</a> </small></td>
<td>Ruby <small> <a href="https://stackshare.io/posts/the-tech-behind-instacarts-grocery-delivery-service">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://dropbox.com/">Dropbox</a>: <br>File hosting / syncing</td>
<td>8000 (market cap @ Aug 2020) <small> <a href="https://finance.yahoo.com/quote/DBX?p=DBX">source</a> </small></td>
<td>Python <small> <a href="https://eranki.tumblr.com/post/27076431887/scaling-lessons-learned-at-dropbox-part-1">source</a> </small></td>
<td>N / Y</td>
</tr>
<tr>
<td><a href="https://coinbase.com/">Coinbase</a>: <br>Cryptocurrency exchange</td>
<td>8,000 <small> <a href="https://www.coindesk.com/coinbase-existing-valuation-doesnt-need-ipo-lawyer-says">source</a> </small></td>
<td>Ruby <small> <a href="https://blog.coinbase.com/scaling-connections-with-ruby-and-mongodb-99204dbf8857">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://gusto.com/">Gusto</a>: <br>Employee payroll and benefits</td>
<td>3,800 <small> <a href="https://www.forbes.com/sites/donnafuscaldo/2019/07/24/gusto-amasses-3-8-billion-valuation-with-latest-fundraising-round/#50e7fa8d2820">source</a> </small></td>
<td>Ruby <small> <a href="https://boards.greenhouse.io/gusto/jobs/1337386?t=bae6d7cd1">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://rappi.com/">Rappi</a>: <br>On-demand delivery</td>
<td>3,500 <small> <a href="https://techcrunch.com/2020/04/08/ifood-merges-with-delivery-heros-domicilios-com-to-challenge-rappi-in-colombia/">source</a> </small></td>
<td>Go, Node, Python, Java <small> <a href="https://www.rappi.com/jobs/position-detail?id=b88ad33f-7ad5-4e3b-8ecb-f13a3cce3a6a&amp;lang=lang">source</a> (may have used PHP - no source)</small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://flexport.com/">Flexport</a>: <br>Freight forwarding platform</td>
<td>3,200 <small> <a href="https://www.joc.com/technology/wework-spanner-flexports-works_20191021.html">source</a> </small></td>
<td>Ruby <small> <a href="https://stackshare.io/posts/how-flexport-builds-software-to-move-over-1-billion-dollars-in-merchandise">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://reddit.com/">Reddit</a>: <br>Online network of communities</td>
<td>3,000 <small> <a href="https://techcrunch.com/2019/02/11/reddit-300-million/">source</a> </small></td>
<td>Lisp <small> <a href="http://www.aaronsw.com/weblog/rewritingreddit">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://about.gitlab.com/">GitLab</a>: <br>DevOps platform</td>
<td>2,750 <small> <a href="https://www.forbes.com/sites/alexkonrad/2019/09/17/gitlab-doubles-valuation-to-nearly-3-billion/#483591ce1794">source</a> </small></td>
<td>Ruby <small> <a href="https://about.gitlab.com/blog/2018/10/29/why-we-use-rails-to-build-gitlab/">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://brex.com/">Brex</a>: <br>Corporate credit cards</td>
<td>2,750 <small> <a href="https://techcrunch.com/2020/05/19/brex-brings-on-150m-in-new-cash-in-case-of-an-extended-recession/">source</a> </small></td>
<td>Elixir <small> <a href="https://medium.com/brexeng/why-brex-chose-elixir-fe1a4f313195">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://pagerduty.com/">PargerDuty</a>: <br>SaaS incident response platform</td>
<td>2,270 <small> <a href="https://www.google.com/search?tbm=fin&amp;q=NYSE:+PD&amp;stick=H4sIAAAAAAAAAONgecRowS3w8sc9YSn9SWtOXmPU5OIKzsgvd80rySypFJLmYoOyBKX4uXj10_UNDdOyCwszkotLeBaxcvhFBrtaKQS4AAASRGHASAAAAA&amp;sa=X&amp;ved=2ahUKEwjCtra68ZbrAhUYXc0KHdn_DoAQ3ecFMAB6BAhqEBc&amp;biw=1278&amp;bih=968#scso=_Z4c0X5TmCsjOtQbEu5zQAQ1:0">source</a> </small></td>
<td>Ruby <small> <a href="https://www.pagerduty.com/blog/elixir-at-pagerduty/">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://checkr.com/">Checkr</a>: <br>Background checks</td>
<td>2,200 <small> <a href="https://www.forbes.com/sites/bizcarson/2019/09/19/checkr-background-funding-round/#552c8c845460">source</a> </small></td>
<td>Ruby <small> <a href="https://engineering.checkr.com/yet-another-attempt-at-faster-builds-caching-db-schema-efe63d367f5">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://podium.com/">Podium</a>: <br>Interaction management platform</td>
<td>1,500 <small> <a href="https://techcrunch.com/2020/04/07/utahs-podium-raises-125m-series-c-led-by-yc-after-reaching-100m-arr/">source</a> </small></td>
<td>Ruby <small> <a href="https://devchat.tv/elixir-mix/emx-072-people-centered-solutions-with-travis-elnicky/">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://segment.com/">Segment</a>: <br>Customer data platform</td>
<td>1,500 <small> <a href="https://www.bloomberg.com/news/articles/2019-04-02/startup-segment-is-worth-1-5-billion-thanks-to-companies-troves-of-customer-data">source</a> </small></td>
<td>Go, JS <small> <a href="https://www.workatastartup.com/companies/88">source</a>, <a href="https://angel.co/company/segment/jobs/348613-senior-software-engineer">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://docker.com/">Docker</a>: <br>Build / deliver software in containers</td>
<td>1000 est. <small> <a href="https://techcrunch.com/2019/11/13/mirantis-acquires-docker-enterprise/">source</a>, <a href="https://techcrunch.com/2018/10/15/docker-has-raised-92-million-in-new-funding/">source</a> </small></td>
<td>Go <small> <a href="https://thenewstack.io/go-programming-language-helps-docker-container-ecosystem/">source</a>, <a href="https://techcrunch.com/2019/11/13/after-selling-enterprise-biz-docker-lands-35m-investment-and-new-ceo/">source</a> </small></td>
<td>N / Y</td>
</tr>
<tr>
<td><a href="https://scale.com/">Scale</a>: <br>Training / validation data for ML</td>
<td>1,000 <small> <a href="https://www.forbes.com/sites/stevenli1/2019/12/22/scale-ai-growth-story/#3360214b6f4a">source</a> </small></td>
<td>Python, JS <small> <a href="https://scale.com/careers/41e05b90-7e65-4dac-8676-50be9c1afc27">source</a>, <a href="https://scale.com/careers/37b0c485-cd77-4170-ac07-a8521b9a10fc">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://amplitude.com/">Amplitude</a>: <br>Product / customer analytics</td>
<td>1,000 <small> <a href="https://www.forbes.com/sites/davidjeans/2020/05/20/amplitude-now-valued-1-billion-backed-sequoia-benchmark/#68a1ad2041c7">source</a> </small></td>
<td>Python, Java <small> <a href="https://news.ycombinator.com/item?id=13301832&amp;p=2">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://zapier.com/">Zapier</a>: <br>Connect apps and automate workflows</td>
<td>1000 est. (20x 2018 ARR) <small> <a href="https://www.drift.com/blog/how-zapier-grew/">source</a> </small></td>
<td>Python <small> <a href="https://zapier.com/blog/zapier-tech-stack/">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://faire.com/">Faire</a>: <br>B2B wholesale marketplace</td>
<td>1,000 <small> <a href="https://www.forbes.com/sites/laurendebter/2019/10/30/faire-wholesale-marketplace-series-d-1-billion-valuation/#21c2bdfb7aa9">source</a> </small></td>
<td>Java <small> <a href="https://boards.greenhouse.io/faire/jobs/4187498002">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://plangrid.com/">PlanGrid</a>: <br>Construction software</td>
<td>875 <small> <a href="https://techcrunch.com/2018/11/20/autodesk-agrees-to-buy-plangrid-for-875-million/#:~:text=Autodesk%20announced%20plans%20to%20acquire%20PlanGrid%20for%20%24875%20million%20today.">source</a> </small></td>
<td>Python <small> <a href="https://stackoverflow.com/jobs/companies/plangrid">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://mixpanel.com/">Mixpanel</a>: <br>User analytics</td>
<td>865 <small> <a href="https://www.forbes.com/pictures/feki45efhmk/mixpanel/#71dc3892190f">source</a> </small></td>
<td>Python<small> <a href="https://boards.greenhouse.io/mixpanel/jobs/1545756?gh_jid=1545756">source</a> (founded before Go)</small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://benchling.com/">Benchling</a>: <br>Biotech research</td>
<td>850 <small> <a href="https://www.forbes.com/sites/amyfeldman/2020/05/28/biotech-rd-software-startup-benchling-started-by-mit-undergrads-scores-850-million-valuation-amid-coronavirus-pandemic/#5de0e0c61dcd">source</a> </small></td>
<td>Python <small> <a href="https://www.workatastartup.com/companies/445">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://meesho.com/">Meesho</a>: <br>Social commerce platform</td>
<td>700 <small> <a href="https://economictimes.indiatimes.com/small-biz/startups/newsbuzz/meesho-raised-125-mn-from-naspers-and-others/articleshow/70641492.cms">source</a> </small></td>
<td>Java <small> <a href="https://angel.co/company/meesho/jobs/596045-software-development-engineer-iii">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://optimizely.com/">Optimizely</a>: <br>Digital experience optimization / testing</td>
<td>600 <small> <a href="https://pitchbook.com/newsletter/optimizely-brings-in-50m#:~:text=Optimizely%2C%20which%20operates%20an%20optimization,with%20participation%20from%20Accenture%20Ventures">source</a> </small></td>
<td>Python <small> <a href="https://news.ycombinator.com/item?id=2647003">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://algolia.com/">Algolia</a>: <br>Search service</td>
<td>578 <small> <a href="https://www.bizjournals.com/sanfrancisco/news/2019/10/15/fast-growing-san-francisco-search-company-scores.html">source</a> </small></td>
<td>C++, Ruby <small> <a href="https://www.algolia.com/doc/faq/why/what-architecture-does-algolia-use-to-provide-an-high-performance-search-engine/">source</a>, <a href="https://stackshare.io/posts/how-algolia-built-their-realtime-search-as-a-service-product">source</a> </small></td>
<td>N / Y</td>
</tr>
<tr>
<td><a href="https://goat.com/">Goat</a>: <br>Sneaker marketplace</td>
<td>550 <small> <a href="https://www.forbes.com/sites/kurtbadenhausen/2019/02/07/foot-locker-invests-100-million-in-secondary-sneaker-firm-goat/#3b07b65e568d">source</a> </small></td>
<td>Ruby <small> <a href="https://www.workatastartup.com/jobs/20990">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://standard.ai/">StandardCognition</a>: <br>Autonomous checkout</td>
<td>535 <small> <a href="https://techcrunch.com/2019/07/25/standard-cognition-lands-35m-at-535m-valuation-to-battle-amazon-go/">source</a> </small></td>
<td>Python <small> <a href="https://jobs.lever.co/standard/9b874041-7cfe-4e0a-a459-fcd66451ee75">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://people.ai/">People.ai</a>: <br>Intelligent CRM</td>
<td>500 <small> <a href="https://techcrunch.com/2019/05/21/people-ai-the-predictive-sales-startup-raises-60m-at-around-500m-valuation/#:~:text=People.ai%2C%20the%20predictive%20sales,around%20%24500M%20valuation%20%7C%20TechCrunch">source</a> </small></td>
<td>Python <small> <a href="https://www.workatastartup.com/companies/1299">source</a>, <a href="https://news.ycombinator.com/item?id=16974829">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://razorpay.com/">Razorpay</a>: <br>Digital payments</td>
<td>450 <small> <a href="https://www.pymnts.com/news/investment-tracker/2019/razorpay-sequoia-india-ribbit-capital/#:~:text=With%20the%20funding%2C%20Razorpay%20is,Razorpay%20X%20neo%2Dbanking%20platform.">source</a> </small></td>
<td>PHP <small> <a href="https://news.ycombinator.com/item?id=12407955">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://equipmentshare.com/">EquipmentShare</a>: <br>Equipment rentals</td>
<td>400 est. <small> <a href="https://www.forbes.com/sites/alexkonrad/2019/11/18/softbank-looks-to-invest-equipmentshare-unicorn/#48a6b2d779b8">source</a> </small></td>
<td>Python <small> <a href="https://news.ycombinator.com/item?id=16492994&amp;p=2">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://weebly.com/">Weebly</a>: <br>Website builder</td>
<td>365 <small> <a href="https://techcrunch.com/2018/04/26/square-acquires-weebly/">source</a> </small></td>
<td>PHP <small> <a href="https://news.ycombinator.com/item?id=2839742">source</a>, <a href="https://news.ycombinator.com/item?id=5729035">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://webflow.com/">Webflow</a>: <br>Website builder</td>
<td>350 <small> <a href="https://growthhackers.com/articles/how-webflow-quietly-grew-without-vc-money?r=latest">source</a> </small></td>
<td>JS <small> <a href="https://boards.greenhouse.io/webflow/jobs/1838218">source</a>, <a href="https://www.workatastartup.com/companies/566">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://matterport.com/">Matterport</a>: <br>3D technology platform</td>
<td>325 <small> <a href="https://techcrunch.com/2019/03/05/matterport-2/#:~:text=Matterport%20had%20raised%20just%20under,DCM%2C%20Qualcomm%20Ventures%20and%20more.">source</a> </small></td>
<td>C++ <small> <a href="https://news.ycombinator.com/item?id=3300290">source</a>, <a href="https://news.ycombinator.com/item?id=5186626">source</a> </small></td>
<td>N / Y</td>
</tr>
<tr>
<td><a href="https://influxdata.com/">InfluxData</a>: <br>InfluxDB creator</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/influxdb/company_financials">source</a> </small></td>
<td>Go <small> <a href="https://github.com/influxdata/influxdb">source</a> </small></td>
<td>N / Y</td>
</tr>
<tr>
<td><a href="https://embarktrucks.com/">Embark</a>: <br>Self-driving trucks</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/embark-trucks/company_financials">source</a> </small></td>
<td>Python, C++ <small> <a href="https://jobs.lever.co/embark/25999d12-5d82-45fc-b3e4-0ebc335f6f59">source</a> </small></td>
<td>Y / Y</td>
</tr>
<tr>
<td><a href="https://sendbird.com/">SendBird</a>: <br>Chat / calls as a service</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/sendbird/company_financials">source</a> </small></td>
<td>Python <small> <a href="https://sendbird.com/careers/4317963002">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://rescale.com/">Rescale</a>: <br>Cloud simulation platform</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/rescale/company_financials">source</a> </small></td>
<td>Java, Python <small> <a href="https://news.ycombinator.com/item?id=5828217">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://gocardless.com/">GoCardless</a>: <br>Direct debit payments</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/gocardless/company_financials">source</a> </small></td>
<td>Ruby <small> <a href="https://news.ycombinator.com/item?id=14978103">source</a>, <a href="https://news.ycombinator.com/item?id=16283469">source</a>, <a href="https://news.ycombinator.com/item?id=4596703">source</a>, <a href="https://boards.greenhouse.io/gocardless/jobs/2282283">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://rigetti.com/">Rigetti Computing</a>: <br>Quantum computing</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/rigetti-computing/company_financials">source</a> </small></td>
<td>Python, Lisp, C <small> <a href="https://news.ycombinator.com/item?id=16968407">source</a> </small></td>
<td>Y / Y</td>
</tr>
<tr>
<td><a href="https://messagebird.com/">MessageBird</a>: <br>Omnichannel customer communication</td>
<td>300 <small> <a href="https://www.fool.com/investing/2020/03/13/twilio-investors-keep-tabs-on-startup-messagebird.aspx">source</a> </small></td>
<td>Go, PHP, Python, Java <small> <a href="https://careers.sh/uk/kompaniya/messagebird/robochi-mistsya/71009">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://ironcladapp.com/">Ironclad</a>: <br>Digital contracting platform</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/ironclad/company_financials">source</a> </small></td>
<td>JS, Java <small> <a href="https://jobs.lever.co/ironcladapp/2d6616e3-27b8-4138-a6fc-238e46757822">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://sift.com/">Sift</a>: <br>Digital safety and fraud detection</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/sift-science/company_financials">source</a> </small></td>
<td>Java, Ruby <small> <a href="https://news.ycombinator.com/item?id=6657091">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://mattermost.com/">Mattermost</a>: <br>Open source Slack alternative</td>
<td>250 est. <small> <a href="https://app.dealroom.co/companies/mattermost">source</a> </small></td>
<td>Go <small> <a href="https://github.com/mattermost/mattermost-server">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://xendit.co/">Xendit</a>: <br>Digital payments</td>
<td>150 est. <small> <a href="https://www.ycombinator.com/topcompanies/">source</a> </small></td>
<td>JS <small> <a href="https://www.workatastartup.com/companies/938">source</a>, <a href="https://www.xendit.co/en/careers/job-application/?gh_jid=4114942003">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://easypost.com/">EasyPost</a>: <br>Logistics software</td>
<td>150 est. <small> <a href="https://www.ycombinator.com/topcompanies/">source</a> </small></td>
<td>Ruby <small> <a href="https://news.ycombinator.com/item?id=6231587">source</a>, <a href="https://news.ycombinator.com/item?id=13542390">source</a>, <a href="https://www.linkedin.com/jobs/view/senior-software-engineer-at-easypost-1669977835/">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://newfrontinsurance.com/">Newfront</a>: <br>Insurance platform</td>
<td>150 est. <small> <a href="https://www.ycombinator.com/topcompanies/">source</a> </small></td>
<td>JS, Go <small> <a href="https://www.keyvalues.com/newfront">source</a>, <a href="https://news.ycombinator.com/item?id=21683554">source</a> </small></td>
<td>N / N</td>
</tr>
</tbody>
</table>
<p><small>
<p>Note: Ginkgo Bioworks, Boom Supersonic, Grin, Memebox, Helion Energy, North, RelativitySpace, and The Athletic were excluded from the below list; I didn't feel they were primarily software businesses. Feel free to disagree with my judgement.</p>
<p>Note: values current as of August 15, 2020.</p>
<p>Note: if one language was the primary language used to build the initial product, one language is listed above. If it was not clear which language was primary, multiple languages are listed above.</p>
<p>Note: if I couldn't find which language was used to build the startup initially, I referenced the oldest job posting I could find.</p>
<p>Note: valuations are approximate and predominantly sourced from recent articles online. Where I couldn't find an indication of value, ~$150M is assumed; startups listed above were all worth +$150M as of October 2019, as per the <a href="https://www.ycombinator.com/topcompanies/">YC Top Companies</a> page.</p>
<p>Note: "Y" and "N" values in the "DataSci / LowLv" column describe a startup's primary product (i.e. ML startups would have a "Y" for DataSci). It was included to provide additional colour on why initial back-end language(s) may have been used / selected. The values in this column are based entirely on my own judgement. Feel free to disagree with them or ignore them.</p>
<p>Note: Ruby and ruby on rails was a popular choice for YC startups around 2010 - 2012. Anecdotally, ~40% of YC startups used ruby during its peak popularity.</p>
</small></p>

<h3 id="stats">2. Aggregated Stats:</h3>

<p><strong>Startups with one (initial) primary back-end language:</strong> </p>
<table>
<thead>
<tr>
<th>Language</th>
<th>Count</th>
<th>Total Valuation ($BN)</th>
</tr>
</thead>
<tbody>
<tr>
<td>All</td>
<td>35 (70%)</td>
<td>132.1 (75%)</td>
</tr>
<tr>
<td>Ruby</td>
<td>13 (26%)</td>
<td>92.4 (52%)</td>
</tr>
<tr>
<td>Python</td>
<td>11 (22%)</td>
<td>29.9 (17%)</td>
</tr>
<tr>
<td>Lisp</td>
<td>1 (2%)</td>
<td>3.0 (2%)</td>
</tr>
<tr>
<td>Elixir</td>
<td>1 (2%)</td>
<td>2.8 (2%)</td>
</tr>
<tr>
<td>Java</td>
<td>2 (4%)</td>
<td>1.7 (1%)</td>
</tr>
<tr>
<td>Go</td>
<td>3 (6%)</td>
<td>1.6 (1%)</td>
</tr>
<tr>
<td>PHP</td>
<td>2 (4%)</td>
<td>0.8 (0%)</td>
</tr>
<tr>
<td>JS</td>
<td>2 (4%)</td>
<td>0.5 (0%)</td>
</tr>
<tr>
<td>C++</td>
<td>1 (2%)</td>
<td>0.3 (0%)</td>
</tr>
</tbody>
</table>

<p><strong>Startups with multiple (initial) primary back-end languages:</strong> </p>
<table>
<thead>
<tr>
<th>Language</th>
<th>Count</th>
<th>Total Valuation ($BN)</th>
</tr>
</thead>
<tbody>
<tr>
<td>All</td>
<td>15 (30%)</td>
<td>44.4 (25%)</td>
</tr>
<tr>
<td>C++ is one</td>
<td>4 (8%)</td>
<td>34.9 (20%)</td>
</tr>
<tr>
<td>Python is one</td>
<td>8 (16%)</td>
<td>25.7 (15%)</td>
</tr>
<tr>
<td>Ruby is one</td>
<td>3 (6%)</td>
<td>15.9 (9%)</td>
</tr>
<tr>
<td>JS is one</td>
<td>5 (10%)</td>
<td>6.5 (4%)</td>
</tr>
<tr>
<td>Java is one</td>
<td>6 (12%)</td>
<td>5.7 (3%)</td>
</tr>
<tr>
<td>Go is one</td>
<td>4 (8%)</td>
<td>5.5 (3%)</td>
</tr>
<tr>
<td>Lisp is one</td>
<td>1 (2%)</td>
<td>0.3 (0%)</td>
</tr>
<tr>
<td>C is one</td>
<td>1 (2%)</td>
<td>0.3 (0%)</td>
</tr>
<tr>
<td>PHP is one</td>
<td>1 (2%)</td>
<td>0.3 (0%)</td>
</tr>
</tbody>
</table>
<p><small>Note: "Startups with multiple (initial) primary back-end languages" table doesn't add to 100% because multiple languages were used for startups.</small></p>

<p><strong>All startups:</strong> </p>
<table>
<thead>
<tr>
<th>Language</th>
<th>Count</th>
<th>Total Valuation ($BN)</th>
</tr>
</thead>
<tbody>
<tr>
<td>All</td>
<td>50 (100%)</td>
<td>176.5 (100%)</td>
</tr>
<tr>
<td>Ruby is one</td>
<td>16 (32%)</td>
<td>108.3 (61%)</td>
</tr>
<tr>
<td>Python is one</td>
<td>19 (38%)</td>
<td>55.6 (32%)</td>
</tr>
<tr>
<td>C++ is one</td>
<td>5 (10%)</td>
<td>35.2 (20%)</td>
</tr>
<tr>
<td>Java is one</td>
<td>8 (16%)</td>
<td>7.4 (4%)</td>
</tr>
<tr>
<td>Go is one</td>
<td>7 (14%)</td>
<td>7.0 (4%)</td>
</tr>
<tr>
<td>JS is one</td>
<td>7 (14%)</td>
<td>7.0 (4%)</td>
</tr>
<tr>
<td>Lisp is one</td>
<td>2 (4%)</td>
<td>3.3 (2%)</td>
</tr>
<tr>
<td>Elixir is one</td>
<td>1 (2%)</td>
<td>2.8 (2%)</td>
</tr>
<tr>
<td>PHP is one</td>
<td>3 (6%)</td>
<td>1.1 (1%)</td>
</tr>
<tr>
<td>C is one</td>
<td>1 (2%)</td>
<td>0.3 (0%)</td>
</tr>
</tbody>
</table>
<p><small>Note: "All startups" table doesn't add to 100% because multiple languages were used for some startups.</small></p>
				
			</div>

		</article></div>]]>
            </description>
            <link>https://charliereese.ca/article/top-50-y-combinator-tech-startups</link>
            <guid isPermaLink="false">hacker-news-small-sites-24279611</guid>
            <pubDate>Wed, 26 Aug 2020 06:03:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PCI Express Retimers vs. Redrivers: An Eye-Popping Difference (2019)]]>
            </title>
            <description>
<![CDATA[
Score 120 | Comments 42 (<a href="https://news.ycombinator.com/item?id=24278760">thread link</a>) | @tragiclos
<br/>
August 25, 2020 | https://www.asteralabs.com/2019/06/26/pci-express-retimers-vs-redrivers-an-eye-popping-difference/ | <a href="https://web.archive.org/web/*/https://www.asteralabs.com/2019/06/26/pci-express-retimers-vs-redrivers-an-eye-popping-difference/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Retimers and redrivers have enabled longer physical channels in servers and storage systems since Peripheral Component Interface Express (PCIe) 3.0 was first introduced almost 10 years ago. Now that PCIe 4.0 is ramping up and PCIe 5.0 is just around the corner, how do these reach extension tools stack up in the face of new challenges in high-speed connectivity?</p>
<p>A redriver is a mostly analog reach extension device designed to boost the high-frequency portions of a signal to counteract the frequency-dependent attenuation caused by the interconnect: the central processing unit (CPU) package, system board, connectors and so on. A redriver‚Äôs data path typically includes a continuous time linear equalizer (CTLE), a wideband gain stage and a linear driver. In addition, redrivers often have input loss-of-signal threshold and output receiver (Rx) detection capability. Figure 1 illustrates a typical redriver block diagram.</p>
<p><a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/serial-bus-white-paper.pdf" target="_blank" rel="noopener noreferrer"><img src="https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block.jpg" alt="" width="731" height="419" srcset="https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block.jpg 731w, https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block-300x172.jpg 300w, https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block-260x150.jpg 260w, https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block-523x300.jpg 523w, https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block-200x115.jpg 200w, https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block-564x323.jpg 564w, https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block-600x344.jpg 600w" sizes="(max-width: 731px) 100vw, 731px"></a></p>
<p><a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/serial-bus-white-paper.pdf" target="_blank" rel="noopener noreferrer">Figure 1: Redriver block diagram [1]</a></p>
<p>A retimer is a mixed signal analog/digital device that is protocol-aware and has the ability to fully recover the data, extract the embedded clock and retransmit a fresh copy of the data using a clean clock. In addition to the CTLE and wideband gain stages also found in a redriver, retimers contain a clock and data recovery (CDR) circuit, a decision feedback equalizer (DFE) and a transmit (Tx) finite impulse response (FIR) driver. Finite state machines (FSMs) and/or a microcontroller typically manage the automatic adaptation of the CTLE, wideband gain, DFE and FIR driver, and implement the PCIe link training and status state machine (LTSSM). Figure 2 illustrates a typical retimer block diagram.</p>
<p><a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/serial-bus-white-paper.pdf" target="_blank" rel="noopener noreferrer"><img src="https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block.jpg" alt="retimer-block" width="787" height="440" srcset="https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block.jpg 787w, https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block-300x168.jpg 300w, https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block-768x429.jpg 768w, https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block-260x145.jpg 260w, https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block-537x300.jpg 537w, https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block-200x112.jpg 200w, https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block-564x315.jpg 564w, https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block-600x335.jpg 600w" sizes="(max-width: 787px) 100vw, 787px"></a></p>
<p><a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/serial-bus-white-paper.pdf" target="_blank" rel="noopener noreferrer">Figure 2: Retimer block diagram [1]</a></p>
<p>In simple terms, a redriver amplifies a signal, whereas a retimer retransmits a fresh copy of the signal. Figure 3 illustrates this and shows how an attenuated eye opening is boosted by a redriver and completely regenerated by a retimer.</p>
<p><img src="https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-1024x238.png" alt="eye-attenuated" width="1024" height="238" srcset="https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-1024x238.png 1024w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-300x70.png 300w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-768x178.png 768w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-1536x357.png 1536w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-260x60.png 260w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-800x186.png 800w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-200x46.png 200w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-564x131.png 564w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-600x139.png 600w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated.png 1658w" sizes="(max-width: 1024px) 100vw, 1024px"></p>
<p>Figure 3: Example of an eye attenuated by a channel (left), the eye after a redriver (middle) and the eye after a retimer (right)</p>
<p>The PCIe 4.0 specification took the unprecedented step of formally defining the terms ‚Äúretimer,‚Äù ‚Äúredriver‚Äù and the superset term ‚Äúrepeater,‚Äù all of which are types of extension devices or components whose purpose is to extend the physical length of a link. The definitions are:</p>
<ul>
<li><strong>Repeater</strong>: An imprecise term for an extension device [2]. (This term causes confusion ‚Ä¶ please don‚Äôt use it!)</li>
<li><strong>Redriver</strong>: A non-protocol-aware software-transparent extension device [2].</li>
<li><strong>Retimer</strong>: A physical layer protocol-aware, software-transparent extension device that forms two separate electrical link segments [2].</li>
</ul>
<h3>Use Cases for Retimers and Redrivers</h3>
<p>Reach extension devices are necessary whenever the channel ‚Äì the electrical path between the root complex (RC) and endpoint (EP) ‚Äì is longer than the PCIe specification allows. The specification defines the maximum channel length in terms of insertion loss at the Nyquist frequency (an informative specification, but easy to validate) and in terms of a reference receiver‚Äôs ability to sufficiently equalize and recover the data assuming a worst-case link partner transmitter (a normative specification, but time-consuming to validate).</p>
<p>Suffice it to say, at PCIe 4.0 speeds, reach extension devices are necessary for:</p>
<ul>
<li>Multiconnector topologies.</li>
<li>Cabled topologies.</li>
<li>Single-connector add-in card (AIC) topologies with baseboard channels longer than 9.5 inches.</li>
</ul>
<p>Figure 4 shows an example of a two-connector ‚Äúriser card‚Äù topology, which ordinarily would exceed the PCIe 4.0 loss budget of 28 dB. A redriver or retimer will enable reliable, error-free communication between the RC and EP. But how do you choose which one is the right tool for the job? Well, it helps to know more about the fundamental differences in their capabilities.</p>
<p><img src="https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-1024x391.png" alt="redriver" width="1024" height="391" srcset="https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-1024x391.png 1024w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-300x115.png 300w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-768x293.png 768w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-260x99.png 260w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-785x300.png 785w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-200x76.png 200w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-564x216.png 564w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-600x229.png 600w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver.png 1120w" sizes="(max-width: 1024px) 100vw, 1024px"><br>
Figure 4: Example of redriver (top) and retimer (bottom) used in a two-connector topology</p>
<h3>Comparing Retimer and Redriver Capabilities</h3>
<p>Not all redrivers and retimers are the same. There are many distinctions between the two, which are universally true for all PCIe reach extension devices. For example:</p>
<p><strong>Retimers actively participate in the PCIe protocol; redrivers do not.</strong> The PCIe base specification spells out how and to what extent retimers participate in the protocol during Detect, Recovery, L0 and other LTSSM states. Equalization to the L0 and L1 link states requires value-added functionality from the retimer (handshakes, timeouts, bit manipulation, etc.). Redrivers are unaware of and unparticipating in the protocol. If the link works reliably the first time, that‚Äôs great! But if the link experiences marginality of any sort, it becomes exceedingly difficult to pinpoint whether the problem is physically before the redriver or after it, since the redriver‚Äôs role in link formation is undefined and unknown to its link partners.</p>
<p><strong>Retimers reset the jitter and insertion loss budgets; redrivers do not.</strong> A retimer‚Äôs CDR fully recovers the data stream and retransmits it on a clean clock. Starting with a fresh copy of the data enables the extension of the channel to twice the original specification. Without a CDR, the best a redriver can do is attenuate (not reset) the data-dependent jitter (DDJ) caused by intersymbol interference (ISI). A redriver cannot attenuate uncorrelated or random jitter (RJ). In fact, a redriver will always add to RJ due to its own device thermal noise in a root-mean-square (RMS) manner <a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/serial-bus-white-paper.pdf" target="_blank" rel="noopener noreferrer">[1]</a>.</p>
<p><strong>Retimers have a DFE; redrivers do not.</strong> A DFE compensates for reflections in the channel response caused by impedance discontinuities in board vias, connectors and package socket-board interfaces. The nice thing about a DFE is that it is unaffected by crosstalk. The DFE equalizes just as well in the presence of crosstalk, and once the data is sampled by the retimer‚Äôs CDR, crosstalk is eliminated for good. Redrivers use a CTLE that boosts both the signal and the noise <a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/serial-bus-white-paper.pdf" target="_blank" rel="noopener noreferrer">[1]</a>. Crosstalk is not eliminated or even attenuated through a redriver; in fact, it gets amplified.</p>
<p><strong>Retimers automatically adapt their receive and transmit equalizers to match the characteristics of the channel and the link partner‚Äôs needs; redrivers do not.</strong> A retimer will examine the signal it receives and adjust the CTLE and DFE to minimize its own bit error rate (BER). Likewise, the retimer‚Äôs transmitter will adjust its de-emphasis and pre-shoot equalization to minimize the link partner‚Äôs BER according to PCIe equalization protocol. A redriver, conversely, operates with a static equalizer setting. The optimal setting (which can be different for every channel in the system) is often painstakingly selected following an exhaustive search in Input/Output Buffer Information Specification (IBIS) algorithmic modeling interface (AMI) simulations and again in lab testing ‚Äì a process fondly referred to as ‚Äútuning.‚Äù</p>
<p><strong>Retimers have built-in features to help diagnose link issues (both electrical and protocol); redrivers do not.</strong> Retimers have tools for assessing the electrical performance (internal eye monitors, pattern generators, pattern checkers) and protocol performance (link state history monitors, timeout adjustments). Redrivers cannot offer such diagnostic features because they are neither protocol-aware nor aware of the actual data passing through. Redrivers do not know what state the link is in.</p>
<p><strong>Retimers correct for lane-to-lane skew; redrivers do not.</strong> PCIe has a tight requirement on the physical skew between lanes on a board (1.6 ns for PCIe 4.0), typically caused by mismatches in channel routing length [3]. Retimers are required to compensate and reset any lane-to-lane skew, effectively doubling the specification budget. Redrivers cannot compensate for lane-to-lane skew, and what‚Äôs worse is that they may degrade the skew depending on how symmetric the redriver package is across all lanes.</p>
<p><strong>Retimers can be placed anywhere between two PCIe-compliant channels; redrivers cannot.</strong> By definition, retimers extend the total PCIe channel reach by two times the specification. A redriver‚Äôs reach extension, however, depends on where it is placed in the channel ‚Äì how much loss is before the redriver versus how much is after <a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/serial-bus-white-paper.pdf" target="_blank" rel="noopener noreferrer">[1]</a>. The specific placement of a redriver must be carefully determined by IBIS-AMI simulation and experimentation. Too close to the root complex transmitter, and the redriver‚Äôs CTLE will enter nonlinear operation and will have limited benefit. Placed too far from the transmitter, the redriver‚Äôs device noise may significantly degrade the signal-to-noise ratio (SNR) of the data signal.</p>
<p>It‚Äôs not all bad news for redrivers. They do have lower power consumption and lower input-to-output latency compared to retimers. But if the link does not form in the first place or if the BER is too high, none of that matters!</p>
<p><img src="https://www.asteralabs.com/wp-content/uploads/2020/02/comparision.png" alt="comparision" width="809" height="527" srcset="https://www.asteralabs.com/wp-content/uploads/2020/02/comparision.png 809w, https://www.asteralabs.com/wp-content/uploads/2020/02/comparision-300x195.png 300w, https://www.asteralabs.com/wp-content/uploads/2020/02/comparision-768x500.png 768w, https://www.asteralabs.com/wp-content/uploads/2020/02/comparision-230x150.png 230w, https://www.asteralabs.com/wp-content/uploads/2020/02/comparision-461x300.png 461w, https://www.asteralabs.com/wp-content/uploads/2020/02/comparision-200x130.png 200w, https://www.asteralabs.com/wp-content/uploads/2020/02/comparision-564x367.png 564w, https://www.asteralabs.com/wp-content/uploads/2020/02/comparision-600x391.png 600w" sizes="(max-width: 809px) 100vw, 809px"></p>
<p>Table 1: Comparison of retimer and redriver capabilities and usage</p>
<h3>Outlook for PCIe 4.0 Systems</h3>
<p>Looking ahead to the upcoming PCIe 4.0 systems, all signs are pointing to an increased need for reach extension devices ‚Äì and retimers in particular ‚Äì due to several trends and challenges:</p>
<ul>
<li>CPUs have more PCIe lanes per socket (&gt;100 in some cases [4]) compared to PCIe 3.0. This leads to a greater number of PCIe slots and riser cards, denser routing, and an increased use of multiconnector topologies.</li>
<li>PCIe is shifting from an I/O bus to a multipurpose system interconnect. This means that more servers will be designed to be modular, allowing an array of compute, storage and networking resources to plug in to an increasing number of PCIe slots. This type of open, ‚Äúplug anything in and it will work‚Äù server architecture requires a reach extension solution that is PCIe compliant with plug-and-play interoperability.</li>
<li>The disaggregation of resources such as modular servers, storage trays and accelerator trays is pushing endpoints physically away from CPUs, requiring cables or carrier cards to connect everything together. These longer physical topologies will increasingly need reach ‚Ä¶</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.asteralabs.com/2019/06/26/pci-express-retimers-vs-redrivers-an-eye-popping-difference/">https://www.asteralabs.com/2019/06/26/pci-express-retimers-vs-redrivers-an-eye-popping-difference/</a></em></p>]]>
            </description>
            <link>https://www.asteralabs.com/2019/06/26/pci-express-retimers-vs-redrivers-an-eye-popping-difference/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24278760</guid>
            <pubDate>Wed, 26 Aug 2020 03:20:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Want people to do the right thing? Save them the guilt trip]]>
            </title>
            <description>
<![CDATA[
Score 325 | Comments 242 (<a href="https://news.ycombinator.com/item?id=24277190">thread link</a>) | @canada_random1
<br/>
August 25, 2020 | https://psyche.co/ideas/you-want-people-to-do-the-right-thing-save-them-the-guilt-trip | <a href="https://web.archive.org/web/*/https://psyche.co/ideas/you-want-people-to-do-the-right-thing-save-them-the-guilt-trip">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><strong>Major global problems </strong>such as racial injustice or climate change often seem insurmountable. It√¢‚Ç¨‚Ñ¢s hard to believe that our individual actions can make any real difference. Yet we know that many social dilemmas are overcome only through collective action. They call for people to make behavioural changes without any direct personal benefits √¢‚Ç¨‚Äú in fact, these changes often come at a personal cost. So what might motivate people to adopt such a √¢‚Ç¨Àúprosocial√¢‚Ç¨‚Ñ¢ mindset?</p>
<p>Researchers have explored a range of answers to this puzzle. A central line of enquiry relates to emotions and self-perception. There√¢‚Ç¨‚Ñ¢s a close link between emotions and behaviour: feelings motivate us to pursue goals, seek positive reinforcement and avoid punishment. But which emotional route is the most promising √¢‚Ç¨‚Äú to make people feel bad about their shortcomings, or to encourage them to have a positive self-image because they√¢‚Ç¨‚Ñ¢ve done √¢‚Ç¨Àúthe right thing√¢‚Ç¨‚Ñ¢?</p>
<p>There are good arguments both ways. Guilt can be a powerful motivator for action; the feeling of wanting to √¢‚Ç¨Àúmake up√¢‚Ç¨‚Ñ¢ for something can lead to reparative action. On the other hand, feeling good about our actions and what they reflect about who we are can elicit positive emotions. These feelings can then provide us with the energy and mental resources to engage in difficult problems, or to √¢‚Ç¨Àúgive to others√¢‚Ç¨‚Ñ¢.</p>
<p>It√¢‚Ç¨‚Ñ¢s important to distinguish here between guilt that arises internally, and guilt that√¢‚Ç¨‚Ñ¢s externally induced. If we feel guilty about failing to recycle our plastics or adopt a vegetarian diet, we might be motivated to engage in reparative action. But if someone buttonholes us over dinner and tries to make us feel bad about our lifestyle choices, the picture might look very different; we might become defensive and try to justify our actions, which drives us further away from changing the way we behave. These scenarios then raise doubts about whether negative self-directed emotional appeals will be effective at promoting prosociality.</p>
<p>In a <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0188781">study</a> that my colleagues and I conducted at Columbia University in New York, we set out to test the consequences of positive versus negative self-directed emotions. Participants were prompted to think about either how guilty they felt about non-environmentally friendly behaviour, or how proud they might be for acting to preserve the environment. They were then asked a range of questions, such as whether they would pay increased rent to have more energy-efficient appliances, how likely they were to take public transport, and whether they√¢‚Ç¨‚Ñ¢d be willing to use reusable shopping bags and mugs. Those participants who had been thinking of how proud they would feel about themselves chose to have a higher number of energy-efficient appliances compared with those participants who had been asked to think about personal guilt. Furthermore, participants in the pride group expressed higher intentions to engage in green behaviours compared with those in the guilt group. These findings suggest that inducing people to consider positive rather than negative self-directed emotions might recruit more people to a climate-change mitigation agenda, and to prosocial behaviour more broadly.</p>
<p>This potential advantage √¢‚Ç¨‚Äú of appealing to positive emotions over negative ones √¢‚Ç¨‚Äú links up with what we know about human self-perception. Having a positive self-image about who we are and what we do is a fundamental human need. When we√¢‚Ç¨‚Ñ¢re balanced and on good terms with ourselves, we are more energetic and have greater cognitive and emotional resources. By contrast, when we feel bad about ourselves, it√¢‚Ç¨‚Ñ¢s much more difficult to be prosocial √¢‚Ç¨‚Äú especially if those feelings and actions aren√¢‚Ç¨‚Ñ¢t geared towards friends and family, but a removed, impersonal √¢‚Ç¨Àúgreater good√¢‚Ç¨‚Ñ¢. Satisfying our important internal needs as emotional creatures can help us free up prosocial resources for others.</p>
<p>Research on self-affirmation supports this picture. In one <a href="https://academiccommons.columbia.edu/doi/10.7916/D84J1XJH">study</a>, we prompted one set of participants to engage in a self-affirming exercise. This involved reflecting on the values and behaviours that were important to them, and that they appreciated in themselves. Another group completed an unrelated exercise, describing the layout of the store at which they shop most frequently. This second √¢‚Ç¨Àúcontrol√¢‚Ç¨‚Ñ¢ group allowed us to quantify the effect of the self-affirmation exercise.</p>
<p>Feeling good about ourselves can translate into acts of kindness towards others, for the benefit of society at large</p>
<p>Both groups were entered into a raffle to win a $10 bonus, and were given the option to either keep the money for themselves or to donate all or a portion to a selection of charities with varying missions and beneficiaries. The √¢‚Ç¨Àúaffirmation√¢‚Ç¨‚Ñ¢ group reported feeling more positively about themselves and more at peace with themselves √¢‚Ç¨‚Äú and what√¢‚Ç¨‚Ñ¢s more, these positive self-directed emotions translated into increased levels of charitable giving compared with those participants who had engaged in the unrelated exercise.</p>
<p><strong>My colleagues and</strong> I were curious about whether the effects of a positive self-image would extend to more challenging contexts, such as when the beneficiaries of prosociality were members of a marginalised group. In a field <a href="https://spssi.onlinelibrary.wiley.com/doi/full/10.1111/josi.12374">study</a> in Nigeria, we investigated how the public felt about enhanced social support for ex-prisoners. Like many other nations, Nigeria has high rates of recidivism. Social stigma means that those released from prison often struggle to secure jobs or have a supportive social network, which feeds into a cycle of reoffending. Interventions that reduce stigma and enhance social support can help ex-offenders to successfully reintegrate into society.</p>
<p>For the study, members of the general public in Nigeria were asked to engage in the self-affirming exercise prior to answering a range of survey questions. The results were striking. The self-affirmed participants showed more prosocial intentions and decreased discriminatory tendencies, compared with participants in the control group. They were more comfortable with having an ex-prisoner as their neighbour, for instance, and indicated stronger intentions to help an ex-prisoner whose employer was discriminating against them. They also expressed more willingness to invest personal time and effort to provide social support, such as participating in a tutoring programme for ex-prisoners.</p>
<p>Follow-up research in the United States replicated these results. Obtaining these findings in two studies and two different countries suggests that these effects can be generalised. The fact that a positive self-image can enhance prosociality doesn√¢‚Ç¨‚Ñ¢t seem to depend on a particular culture but could be an intrinsic part of human behaviour more generally. Feeling good about ourselves doesn√¢‚Ç¨‚Ñ¢t just enhance individual wellbeing by fulfilling a fundamental human psychological need; it can also translate into acts of kindness towards others, for the benefit of society at large.</p>
<p>A positive self-image can create a flywheel effect, in which the resulting prosocial behaviour sends a social signal to others. If others discriminate less, we are less likely to do so; if people in our social groups recycle more and watch their carbon footprint, we are more likely to do so. Getting a critical mass to √¢‚Ç¨Àújoin in√¢‚Ç¨‚Ñ¢ and acknowledging problems can, over time, help to shift norms √¢‚Ç¨‚Äú which are drivers, not just inhibitors, of human behaviour.</p>
<p>The potential of positive self-directed emotions has largely not been embraced by activists. The worry could be that it might make those engaging in the cause appear self-satisfied or selfish. But these studies suggest that, instead of focusing on √¢‚Ç¨Àúdoom and gloom√¢‚Ç¨‚Ñ¢ messaging that zooms in on people√¢‚Ç¨‚Ñ¢s shortcomings and risks alienating them, policymakers and strategists might find that positive messaging, speaking to people√¢‚Ç¨‚Ñ¢s positive sense of self, might be a more powerful lever of behavioural change.</p></div></div></div>]]>
            </description>
            <link>https://psyche.co/ideas/you-want-people-to-do-the-right-thing-save-them-the-guilt-trip</link>
            <guid isPermaLink="false">hacker-news-small-sites-24277190</guid>
            <pubDate>Tue, 25 Aug 2020 22:50:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to not fear your death: An Epicurean perspective]]>
            </title>
            <description>
<![CDATA[
Score 85 | Comments 148 (<a href="https://news.ycombinator.com/item?id=24275882">thread link</a>) | @diodorus
<br/>
August 25, 2020 | https://psyche.co/guides/how-to-use-philosophy-to-overcome-the-fear-of-your-own-death | <a href="https://web.archive.org/web/*/https://psyche.co/guides/how-to-use-philosophy-to-overcome-the-fear-of-your-own-death">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><h2 data-guide-section-number="1"><span>Need to know</span></h2><div><p>Your demise is inevitable. I hope that doesn√¢‚Ç¨‚Ñ¢t come as too much of a shock. I agree that the brevity of human existence is bothersome. Thankfully, for most of us, this frightful fact usually hovers somewhere beyond the margins of our consciousness: we√¢‚Ç¨‚Ñ¢re √¢‚Ç¨Àúaware√¢‚Ç¨‚Ñ¢ of our death without constantly fearing it.</p>
<p>Inevitably, though, there are moments when the reality of our eventual death strikes us in a new, chillier light. A close call demonstrates the tenuousness of life, or the death of a loved one reminds us that no one is exempt from humanity√¢‚Ç¨‚Ñ¢s ultimate destination. Even talking about death, as we are now, can be enough to bring on a ruminative contemplation of the end, and with it a shudder of fear about one√¢‚Ç¨‚Ñ¢s own extinguishment.</p>
<p>In these moments, when your pending dissipation presents itself afresh, the fact of death is <em>experienced</em> in a new way. Rather than merely being √¢‚Ç¨Àúknown√¢‚Ç¨‚Ñ¢ like one more quotidian statement about the world √¢‚Ç¨‚Äú √¢‚Ç¨ÀúThe sky is blue. I will die√¢‚Ç¨‚Ñ¢ √¢‚Ç¨‚Äú the sense of one√¢‚Ç¨‚Ñ¢s ending is felt more deeply and more immediately. In these moods, the terror of death seeps into your awareness of yourself as a person; its awesome inevitability and finality makes you feel small and powerless. This is the fear of death at an existential level, brought on by the almost unthinkable notion that there is and only ever will be one of you √¢‚Ç¨‚Äú and sooner or later it will flicker out of existence, leaving little more than memories in other soon-to-be-gone beings. The fear of death as I√¢‚Ç¨‚Ñ¢m discussing it here is not about the practical worry of who will pay off your credit card debt after you√¢‚Ç¨‚Ñ¢re gone: it√¢‚Ç¨‚Ñ¢s about the unsettling fact that the person who earned that debt in the first place is but a fleeting speck of an event in the infinite history of the Universe.</p>
<p>The fear of death is also heightened by thinking about how harmful mortality is to us √¢‚Ç¨‚Äú how there is no greater blow in life than for life to cease. As the philosopher Thomas Nagel observed, death is the great deprivation. There is always more life to be lived, and it is painful to have that taken away. The best way to get at this fear, perhaps, is to contemplate the almost unbearable thought of your future absence: one day, at family dinners, a place will no longer be set for you. The day after you die, the newspaper will still be published just as it was the day before. And the morning after your funeral, friends will make their morning coffee. You will be gone for good, though, and that certainly is a terrifying impediment.</p>
<p>So the fear of death is awful to behold √¢‚Ç¨‚Äú and therefore, naturally, something to overcome. Indeed, the striving to overcome the fear of death, I would suggest, has stimulated a great deal of thinking over the course of humanity√¢‚Ç¨‚Ñ¢s time on Earth: one could go so far as to say that working out how to thwart, or perhaps accommodate, death sits at the root of a vast number of cultural achievements. The fear of finitude is a powerful propellant.</p>
<p>So how <em>can</em> the fear of death be overcome? One popular strategy is to plan for a sequel to life, which, it√¢‚Ç¨‚Ñ¢s usually expected, will take place in another, happier realm. Resurrection, whether as a human or otherwise, has won a great many adherents. And there have been several religions, as well as philosophers, that have promulgated a view of time as cyclical: we√¢‚Ç¨‚Ñ¢ve done this before, and we√¢‚Ç¨‚Ñ¢ll do this again. Death as a mere interlude.</p>
<p>These tactics and ideas have something to recommend them, certainly. But for now, let√¢‚Ç¨‚Ñ¢s set aside all possibility of life after death so that we are left with the often horrifying thought: you exist, but one day you won√¢‚Ç¨‚Ñ¢t. Are there any good philosophical reasons not to fear that gulf √¢‚Ç¨‚Äú between being and not-being? In this Guide, I will suggest several philosophically inspired reasons not to be fearful of your own death √¢‚Ç¨‚Äú and so, in that sense, I hope that there is something helpful here to lighten the weight of the deeply unsettling existential state in which we are all lucky enough to find ourselves.</p></div></div></section><section><div><h2 data-guide-section-number="2"><span>What to do</span></h2><div><p>The life of the city-dwelling Ancient Greek philosopher Epicurus straddled the 3rd and 4th centuries BCE. His philosophy nowadays is popularly packaged as a kind of light hedonism: sensualist, joyful, a hint of luxury, a naughty second glass of wine. Though Epicurus himself was probably not quite the blinkered and unimaginative pleasure-seeker that these clich√É¬©s suggest, they do give a flavour of his outlook.</p>
<p>For him, the purpose of human life is to achieve happiness. Epicurus construed this as an absence of pain rather than a positive programme of indulging oneself by, say, keeping up a rigorous schedule of orgies or downing flasks of opium on Tuesday mornings. He recognised that whatever temporary excitement such pursuits yield in the moment will probably be well counterbalanced by a severe price to pay later on. So instead, Epicurus recommended (somewhat disappointingly) that it is <em>moderation</em> that will lead to a release from pain and suffering, which in turn will bring a respectable measure of happiness and therefore a good life. Our limitations, our meagre certainties, are at the centre of Epicurus√¢‚Ç¨‚Ñ¢ system of thought, and it is in this context of mitigating pain and accruing a gentle happiness that he believed the fear of death needs to be understood. Epicurus and his followers held that the fear of death is harmful to the enjoyment of our lives, and so showing why this fear isn√¢‚Ç¨‚Ñ¢t well-founded contributes to the overall hedonic project of living well.</p>
<p>According to this tradition, the first thing to do to overcome the fear of death is to try to articulate to yourself what it would be like to <em>be</em> dead. Imagine <em>yourself</em>, but rather than alive √¢‚Ç¨‚Äú dead. (Remember, we√¢‚Ç¨‚Ñ¢ve cast aside the afterlife.) As you√¢‚Ç¨‚Ñ¢ll swiftly appreciate, there is an intractable contradiction right at the centre of this first actionable item. You cannot imagine what it would be like to be dead, because death is an absence of existence. There is, literally, nothing to imagine √¢‚Ç¨‚Äú because nothingness itself cannot be imagined. There is no perspective, no view from nothingness, nothing to which it can be approximated. So that is the first recommendation: realise that being dead isn√¢‚Ç¨‚Ñ¢t an experience. Death itself isn√¢‚Ç¨‚Ñ¢t really a <em>thing</em> at all. In Epicurus√¢‚Ç¨‚Ñ¢ words: √¢‚Ç¨ÀúDeath is nothing to us.√¢‚Ç¨‚Ñ¢</p>
<p>To drive the point home, let√¢‚Ç¨‚Ñ¢s turn to the Roman poet Lucretius. He was a saltier and more ironic Epicurean of a later generation, the 1st century BCE, whose unexampled poem <em>On the Nature of Things</em> fell afoul of early Christians because of its crypto-atheism. In the poem, Lucretius proposes an idea, later termed the √¢‚Ç¨ÀúSymmetry Argument√¢‚Ç¨‚Ñ¢, that hints at the second thing you should do to overcome the fear of death: try to recall what it was like before you were born. Not how the world was, which is the task of historical imagination, but what it was like to <em>be</em> you √¢‚Ç¨‚Äú before you were created. You√¢‚Ç¨‚Ñ¢ll discover that prenatal existence isn√¢‚Ç¨‚Ñ¢t something that can be thought about, much less experienced. The symmetrical part of the argument, of course, is that you have the very same difficulty in imagining what it is like to be dead. Indeed, according to Lucretius, you-pre-existence is the same thing as death or post-existence: both involve the absence of you. No doubt you don√¢‚Ç¨‚Ñ¢t fear your prenatal existence and logically speaking, given their equivalence, it follows that you should fear death the exact same amount, as in not at all. (As the novelist Vladimir Nabokov put it in his memoirs: √¢‚Ç¨Àúcommon sense tells us that our existence is but a brief crack of light between two eternities of darkness.√¢‚Ç¨‚Ñ¢)</p>
<p>This brings us to the third thing to do to calm your existential angst: examine how much √¢‚Ç¨Àúnothing√¢‚Ç¨‚Ñ¢ √¢‚Ç¨‚Äú nonexistence √¢‚Ç¨‚Äú can reasonably be feared. That is, are there any good reasons for your pending death to trigger the emotion of fear? It is reasonable to be fearful of things to the extent that those things can cause you harm. It was reasonable to be jittery about nukes during the Cold War era; it is reasonable to be scared that humanity is turning the globe into a sauna; and it is reasonable for your heart to launch as from a trebuchet into your throat when your partner says to you the words √¢‚Ç¨ÀúWe need to talk.√¢‚Ç¨‚Ñ¢ These are all identifiable threats that foretell awful experiences. None of them would help us in our Epicurean goal of being happy, and so are reasonably feared.</p>
<p>But death itself √¢‚Ç¨‚Äú not the process of dying, which is something different √¢‚Ç¨‚Äú doesn√¢‚Ç¨‚Ñ¢t seem to be the sort of thing that one can reasonably be fearful of because it isn√¢‚Ç¨‚Ñ¢t anything. It√¢‚Ç¨‚Ñ¢s not uncomfortable or hurtful to <em>be</em> dead. It√¢‚Ç¨‚Ñ¢s not as if you√¢‚Ç¨‚Ñ¢re being deprived of life or of more contented years because, again, you simply aren√¢‚Ç¨‚Ñ¢t <em>there</em> to be deprived in the first place. For you, there is nowhere to locate the harm of being dead since being dead isn√¢‚Ç¨‚Ñ¢t a state of being. It√¢‚Ç¨‚Ñ¢s not something that strictly speaking happens to you and so it can√¢‚Ç¨‚Ñ¢t be harmful. (No one would say St Francis of Assisi is <em>more</em> dead than the punk rocker √¢‚Ç¨ÀúGG√¢‚Ç¨‚Ñ¢ Allin because St Francis died longer ago.) Death is the absence of an event; it√¢‚Ç¨‚Ñ¢s not a happening or a thing at all because there isn√¢‚Ç¨‚Ñ¢t such a thing as you any longer. Even something that you dreamed or imagined √¢‚Ç¨‚Äú say, a stranger standing silently by your bed as you wake √¢‚Ç¨‚Äú has a kind of existence necessary for it to be the reasonable object of a fear, even if it turns out to have been the shadow of a tree. Death itself doesn√¢‚Ç¨‚Ñ¢t have this quality. And Lucretius would add: it is just as unreasonable to fear nonexistence after life as it is to fear nonexistence before birth.</p>
<p>This is the heart of Epicurus√¢‚Ç¨‚Ñ¢ and Lucretius√¢‚Ç¨‚Ñ¢ argument for why there is no good reason to fear death. Note that their argument doesn√¢‚Ç¨‚Ñ¢t speak to the fear that others will die, which is a perfectly reasonable anxiety and one that we should ‚Ä¶</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://psyche.co/guides/how-to-use-philosophy-to-overcome-the-fear-of-your-own-death">https://psyche.co/guides/how-to-use-philosophy-to-overcome-the-fear-of-your-own-death</a></em></p>]]>
            </description>
            <link>https://psyche.co/guides/how-to-use-philosophy-to-overcome-the-fear-of-your-own-death</link>
            <guid isPermaLink="false">hacker-news-small-sites-24275882</guid>
            <pubDate>Tue, 25 Aug 2020 20:45:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Optimal Peanut Butter and Banana Sandwiches]]>
            </title>
            <description>
<![CDATA[
Score 305 | Comments 105 (<a href="https://news.ycombinator.com/item?id=24272814">thread link</a>) | @ethanahte
<br/>
August 25, 2020 | https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/ | <a href="https://web.archive.org/web/*/https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

      <section>
          <section>
              

              
              
              
              
              


              <article>
                  <div>
<video autoplay="" muted="" loop="loop">
    <source src="https://www.ethanrosenthal.com/videos/optimal-peanut-butter-and-banana/banana_small.mp4" type="video/mp4">
</video>

<p>I was personally useless for most of the Spring of 2020. There was a period of time, though, after the peak in coronavirus cases here in NYC and before the onslaught of police violence here in NYC that I managed to scrounge up the motivation to do something other than drink and maniacally refresh my Twitter feed. I set out to work on something completely meaningless. It was almost therapeutic to work on a project with no value of any kind (<em>insert PhD joke here</em>).</p>
<p>A side effect of having spent 10 years with limited income in college and grad school, 6 of those here in expensive ass NYC, is that I eat of lot of cheap sandwiches, even though I now have a nice Tech‚Ñ¢ job. While my sandwich consumption was quite formidable pre-covid, sheltering in place cemented this staple in my diet. I am particularly fond of peanut butter and banana sandwiches, having been introduced to them as a child by my maternal grandfather who ate them regularly.</p>
<p>I start a peanut butter and banana sandwich by spreading peanut butter on two slices of bread. I then slice circular slices of the banana, starting at the end of the banana, and place each slice on one of the pieces of bread until I have a single layer of banana slices. Every time I do this, the former condensed matter physicist in me starts to twitch his eye. You see, I have this urge, this desire, this <em>need</em> to maximize the <a href="https://en.wikipedia.org/wiki/Atomic_packing_factor">packing fraction</a> of the banana slices. That is, I want to maximize the coverage of the banana slices on the bread. Just as bowl-form food is perfect because you get every ingredient in every bite, each bite of my sandwich should yield the same golden ratio of bread, peanut butter, and banana.</p>
<p>If you were a machine learning model (or my wife), then you would tell me to just cut long rectangular strips along the long axis of the banana, but I‚Äôm not a sociopath. If life were simple, then the banana slices would be perfect circles of equal diameter, and we could coast along looking up optimal configurations on <a href="http://packomania.com/">packomania</a>. But alas, life is not simple. We‚Äôre in the middle of a global pandemic, and banana slices are elliptical with varying size.</p>
<p>So, how do we make optimal peanut butter and banana sandwiches? It‚Äôs really quite simple. You take a picture of your banana and bread, pass the image through a deep learning model to locate said items, do some nonlinear curve fitting to the banana, transform to polar coordinates and ‚Äúslice‚Äù the banana along the fitted curve, turn those slices into elliptical polygons, and feed the polygons and bread ‚Äúbox‚Äù into a 2D nesting algorithm.</p>
<p>You may have noticed that I supposedly started this project in the Spring, and it‚Äôs now August. Like most idiot engineers, I had no idea how complicated this stupid project was going to be, but time‚Äôs meaningless in quarantine, so here we are. And here you are! Because I made a pip installable python package <a href="https://github.com/EthanRosenthal/nannernest">nannernest</a> if you want to optimize your own sandwiches, and I‚Äôm going to spend the rest of this post describing how this whole godforsaken thing works.</p>
</div>
<div>
<h2 id="sandwich-segmentation">Sandwich Segmentation</h2>
<p>I know that deep learning has been properly commoditized when the easiest part of this project was identifying every pixel that belongs to a banana or slice of bread in an image. Seriously, this step was super easy. I used a pretrained Mask-RCNN torchvision <a href="https://pytorch.org/docs/stable/torchvision/models.html#torchvision.models.detection.maskrcnn_resnet50_fpn">model</a> with a Resnet backbone. The model was pretrained on the COCO <a href="https://cocodataset.org/">dataset</a>, and thankfully the dataset has ‚Äúbanana‚Äù as segmentation category, along with ‚Äúsandwich‚Äù and ‚Äúcake‚Äù which were close enough categories for suitable detection of most slices of bread.</p>
<p>Passing an image through the model outputs a bunch of detected objects, where each detected object has an associated <code>label</code>, <code>score</code>, <code>bounding box</code>, and <code>mask</code>, where the mask identifies the pixels that correspond to the object with a weight at each pixel corresponding to the model‚Äôs confidence in that pixel‚Äôs label.</p>
<p>Because there could be multiple bananas and slices of bread in the image, I pick out the banana and slice of bread with the highest score. Below, you can see the model is clearly able to identify the banana and bread, with the mask overlaid in a semi-transparent, radioactive green.</p>
</div>
<div>
<div>
<div><pre><code data-lang="python"><span>%</span><span>config</span> <span>InlineBackend</span><span>.</span><span>figure_format</span> <span>=</span> <span></span><span>'</span><span>retina</span><span>'</span>

<span>from</span> <span>pathlib</span> <span>import</span> <span>Path</span>
<span>import</span> <span>matplotlib.pyplot</span> <span>as</span> <span>plt</span>
<span>import</span> <span>numpy</span> <span>as</span> <span>np</span>
<span>import</span> <span>nannernest</span>

<span>_RC_PARAMS</span> <span>=</span> <span>{</span>
    <span></span><span>"</span><span>figure.figsize</span><span>"</span><span>:</span> <span>(</span><span>8</span><span>,</span> <span>4</span><span>)</span><span>,</span>
    <span></span><span>"</span><span>axes.labelsize</span><span>"</span><span>:</span> <span>16</span><span>,</span>
    <span></span><span>"</span><span>axes.titlesize</span><span>"</span><span>:</span> <span>18</span><span>,</span>
    <span></span><span>"</span><span>axes.spines.right</span><span>"</span><span>:</span> <span>False</span><span>,</span>
    <span></span><span>"</span><span>axes.spines.top</span><span>"</span><span>:</span> <span>False</span><span>,</span>
    <span></span><span>"</span><span>font.size</span><span>"</span><span>:</span> <span>14</span><span>,</span>
    <span></span><span>"</span><span>lines.linewidth</span><span>"</span><span>:</span> <span>2</span><span>,</span>
    <span></span><span>"</span><span>lines.markersize</span><span>"</span><span>:</span> <span>6</span><span>,</span>
    <span></span><span>"</span><span>legend.fontsize</span><span>"</span><span>:</span> <span>14</span><span>,</span>
<span>}</span>
<span>for</span> <span>k</span><span>,</span> <span>v</span> <span>in</span> <span>_RC_PARAMS</span><span>.</span><span>items</span><span>(</span><span>)</span><span>:</span>
    <span>plt</span><span>.</span><span>rcParams</span><span>[</span><span>k</span><span>]</span> <span>=</span> <span>v</span>

<span>DPI</span> <span>=</span> <span>160</span>
</code></pre></div></div>
</div>
<div>
<div>
<div><pre><code data-lang="python"><span>image</span><span>,</span> <span>banana</span><span>,</span> <span>bread</span> <span>=</span> <span>nannernest</span><span>.</span><span>segmentation</span><span>.</span><span>run</span><span>(</span><span>Path</span><span>(</span><span></span><span>"</span><span>pre_sandwich.jpg</span><span>"</span><span>)</span><span>)</span>
</code></pre></div></div>
</div>
<div>
<div>
<div><pre><code data-lang="python"><span>nannernest</span><span>.</span><span>viz</span><span>.</span><span>plot</span><span>(</span><span>image</span><span>,</span> <span>banana</span><span>=</span><span>banana</span><span>,</span> <span>bread</span><span>=</span><span>bread</span><span>,</span> <span>show</span><span>=</span><span>True</span><span>,</span> <span>dpi</span><span>=</span><span>DPI</span><span>)</span>
</code></pre></div></div>



<figure>
    
        <img src="https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/index_4_0.png"> </figure>

</div>
<div>
<h2 id="what-shape-does-a-banana-makehttpswwwyoutubecomwatchv3o1ad4lzygk"><a href="https://www.youtube.com/watch?v=3O1ad4lZYGk">What shape does a banana make?</a></h2>
<p>Now that we have identified the banana in the image, we need to virtually ‚Äúslice‚Äù it. This is where we are first introduced to the universal pain of computer vision:</p>
<p><em>By eye, I can see exactly what I want to do; by code, it‚Äôs so damn difficult.</em></p>
<p>I could ask you to draw lines on the banana identifying where you would slice it, and you could easily draw well-spaced, somewhat parallel slices. It‚Äôs not so easy to do this with code. However, I would also argue that this is the fun part of the problem. There are many ways to solve this, and it feels creative, as opposed to using a pre-trained deep learning model. On the other hand, ‚Äúcreatively‚Äù solving these problems likely leads to more brittle solutions compared to deep learning models trained on millions of examples. There‚Äôs a tradeoff here.</p>
<p>I tried a bunch of analytical solutions based on ellipses, but nothing seemed to work quite right. I ended up landing on a somewhat simpler solution that may not be robust to straight bananas, but who cares ‚Äì this is a silly project anyway. Using the wonderful <a href="https://scikit-image.org/">scikit-image</a> library, I first calculate the <a href="https://scikit-image.org/docs/dev/auto_examples/edges/plot_skeleton.html">skeleton</a> of the banana segmentation mask. This reduces the mask to a one pixel wide representation which effectively creates a curve that runs along the long axis of the banana.</p>
</div>
<div>
<div>
<div><pre><code data-lang="python"><span>slices</span><span>,</span> <span>banana_circle</span><span>,</span> <span>banana_centroid</span><span>,</span> <span>banana_skeleton</span> <span>=</span> <span>nannernest</span><span>.</span><span>slicing</span><span>.</span><span>run</span><span>(</span>
    <span>banana</span><span>.</span><span>mask</span>
<span>)</span>
</code></pre></div></div>
</div>
<div>
<div>
<div><pre><code data-lang="python"><span>nannernest</span><span>.</span><span>viz</span><span>.</span><span>plot</span><span>(</span><span>image</span><span>,</span> <span>banana_skeleton</span><span>=</span><span>banana_skeleton</span><span>,</span> <span>show</span><span>=</span><span>True</span><span>,</span> <span>dpi</span><span>=</span><span>DPI</span><span>)</span>
</code></pre></div></div>



<figure>
    
        <img src="https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/index_7_0.png"> </figure>

</div>
<p>I then fit a circle to the banana skeleton using a nice scipy-based least squares optimization I found <a href="https://scipy-cookbook.readthedocs.io/items/Least_Squares_Circle.html#Using-scipy.optimize.leastsq">here</a>. I actually originally tried to fit this with PyTorch and totally failed, likely due to the fact that this is actually a nonlinear optimization problem.</p>
<div>
<div>
<div><pre><code data-lang="python"><span>nannernest</span><span>.</span><span>viz</span><span>.</span><span>plot</span><span>(</span>
    <span>image</span><span>,</span>
    <span>banana_skeleton</span><span>=</span><span>banana_skeleton</span><span>,</span>
    <span>banana_circle</span><span>=</span><span>banana_circle</span><span>,</span>
    <span>show</span><span>=</span><span>True</span><span>,</span>
    <span>dpi</span><span>=</span><span>DPI</span><span>,</span>
<span>)</span>
</code></pre></div></div>



<figure>
    
        <img src="https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/index_9_0.png"> </figure>

</div>
<div>
<h2 id="rad-coordinate-transformations">Rad Coordinate Transformations</h2>
<p>With the circle fit to the banana, the goal is to now draw radial lines out from the center of the circle to the banana and have each radial line correspond to the slice of a knife. Again, while it‚Äôs easy to visualize this, it‚Äôs much harder in practice. For example, we need to start slicing at one end of the banana, but how do we find an end of the banana? Also, there are two ends, and we have to differentiate between them. Contrary to the behavior of <a href="https://www.thekitchn.com/why-you-should-peel-your-banana-like-a-monkey-206322">monkeys</a>, I start slicing my bananas at the stem end, and that‚Äôs what we‚Äôre going to do here.</p>
<p>Crucially, because we now have this circle and want to cut radial slices, we must transform from cartesian to polar coordinates and orient ourselves both radially and angularly with respect to the banana. As a start for orienting ourselves angularly, we calculate the <em>centroid</em> of the banana mask, which corresponds to the center of mass of the banana mask if the banana mask were a 2D object. The centroid is shown below as a red dot.</p>
<p>We now draw a radial line originating from the banana circle and passing through the centroid, shown as the dashed white line below. We will consider that line to mark our <em>reference</em> angle which orients us to the center of the banana.</p>
</div>
<div>
<div>
<div><pre><code data-lang="python"><span>ax</span> <span>=</span> <span>nannernest</span><span>.</span><span>viz</span><span>.</span><span>plot</span><span>(</span>
    <span>image</span><span>,</span>
    <span>banana_skeleton</span><span>=</span><span>banana_skeleton</span><span>,</span>
    <span>banana_circle</span><span>=</span><span>banana_circle</span><span>,</span>
    <span>banana_centroid</span><span>=</span><span>banana_centroid</span><span>,</span>
    <span>show</span><span>=</span><span>False</span><span>,</span>
    <span>dpi</span><span>=</span><span>DPI</span><span>,</span>
<span>)</span>

<span>dy</span> <span>=</span> <span>banana_centroid</span><span>[</span><span>0</span><span>]</span> <span>-</span> <span>banana_circle</span><span>.</span><span>yc</span>
<span>dx</span> <span>=</span> <span>banana_centroid</span><span>[</span><span>1</span><span>]</span> <span>-</span> <span>banana_circle</span><span>.</span><span>xc</span>
<span>reference_angle</span> <span>=</span> <span>np</span><span>.</span><span>arctan2</span><span>(</span><span>dy</span><span>,</span> <span>dx</span><span>)</span>
<span>radius</span> <span>=</span> <span>np</span><span>.</span><span>sqrt</span><span>(</span><span>dx</span> <span>*</span><span>*</span> <span>2</span> <span>+</span> <span>dy</span> <span>*</span><span>*</span> <span>2</span><span>)</span>

<span>radial_end_point</span> <span>=</span> <span>(</span>
    <span>banana_circle</span><span>.</span><span>xc</span> <span>+</span> <span>2</span> <span>*</span> <span>radius</span> <span>*</span> <span>np</span><span>.</span><span>cos</span><span>(</span><span>reference_angle</span><span>)</span><span>,</span>
    <span>banana_circle</span><span>.</span><span>yc</span> <span>+</span> <span>2</span> <span>*</span> <span>radius</span> <span>*</span> <span>np</span><span>.</span><span>sin</span><span>(</span><span>reference_angle</span><span>)</span><span>,</span>
<span>)</span>

<span>ax</span><span>.</span><span>plot</span><span>(</span>
    <span>(</span><span>banana_circle</span><span>.</span><span>xc</span><span>,</span> <span>radial_end_point</span><span>[</span><span>0</span><span>]</span><span>)</span><span>,</span>
    <span>(</span><span>banana_circle</span><span>.</span><span>yc</span><span>,</span> <span>radial_end_point</span><span>[</span><span>1</span><span>]</span><span>)</span><span>,</span>
    <span>color</span><span>=</span><span></span><span>"</span><span>white</span><span>"</span><span>,</span>
    <span>linestyle</span><span>=</span><span></span><span>"</span><span>--</span><span>"</span><span>,</span>
    <span>linewidth</span><span>=</span><span>1</span><span>,</span>
<span>)</span>
<span>None</span>
</code></pre></div></div>



<figure>
    
        <img src="https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/index_11_0.png"> </figure>

</div>
<p>Using <code>scikit-image</code>, we calculate the segmentation <code>mask</code> intensity along this radial line using the <code>profile_line</code> function. Because our line is passing at an angle along discrete <code>mask</code> pixels (aka matrix entries), we take an average of neighboring points along the radial line cut using the <code>linewidth</code> arguments. As you can see, the banana mask pops out a little over 100 points from the banana circle center.</p>
<div>
<div>
<div><pre><code data-lang="python"><span>from</span> <span>skimage</span> <span>import</span> <span>measure</span>

<span>profile_line</span> <span>=</span> <span>measure</span><span>.</span><span>profile_line</span><span>(</span>
    <span>banana</span><span>.</span><span>mask</span><span>.</span><span>T</span><span>,</span> <span>banana_circle</span><span>.</span><span>center</span><span>,</span> <span>radial_end_point</span><span>,</span> <span>linewidth</span><span>=</span><span>2</span><span>,</span> <span>mode</span><span>=</span><span></span><span>"</span><span>constant</span><span>"</span>
<span>)</span>
</code></pre></div></div>
</div>
<div>
<div>
<div><pre><code data-lang="python"><span>fig</span><span>,</span> <span>ax</span> <span>=</span> <span>plt</span><span>.</span><span>subplots</span><span>(</span><span>)</span>
<span>ax</span><span>.</span><span>plot</span><span>(</span><span>profile_line</span><span>)</span>
<span>ax</span><span>.</span><span>set_xlabel</span><span>(</span><span></span><span>"</span><span>Distance from banana circle center</span><span>"</span><span>)</span>
<span>ax</span><span>.</span><span>set_title</span><span>(</span><span></span><span>"</span><span>Mask Intensity</span><span>"</span><span>)</span>
<span>None</span>
</code></pre></div></div>



<figure>
    
        <img src="https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/index_14_0.png"> </figure>

</div>
<p>This profile line is what allows us to orient ourselves radially. You can clearly see where the banana starts and ends, in the radial direction. As always, just seeing it is not good enough. We need code to define the start and end of the banana in this direction. The <code>mask</code> tends to be monotonically increasing and then monotonically decreasing along the start and end, respectively. Using this information, there are a couple ways ‚Ä¶</p></article></section></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/">https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/</a></em></p>]]>
            </description>
            <link>https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24272814</guid>
            <pubDate>Tue, 25 Aug 2020 16:10:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Global Mass Surveillance ‚Äì The Fourteen Eyes]]>
            </title>
            <description>
<![CDATA[
Score 330 | Comments 149 (<a href="https://news.ycombinator.com/item?id=24272244">thread link</a>) | @latexr
<br/>
August 25, 2020 | https://www.privacytools.io/providers/#ukusa | <a href="https://web.archive.org/web/*/https://www.privacytools.io/providers/#ukusa">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <nav id="breadcrumb" aria-label="breadcrumb">
  
  <ol itemscope="" itemtype="https://schema.org/BreadcrumbList">
    <li>
      <a href="https://www.privacytools.io/"> <span>Home</span></a>
    </li>
    
    
    <li aria-current="page" itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
      
      <span itemprop="name">Providers 
      </span>
      <meta itemprop="position" content="1">
    </li>
    
    
  </ol>
</nav>


<div>
  
  <p>There's a ton of people providing services online. Discover which ones you should avoid and our recommendations for a variety of services.</p>
</div>



<p>Click on whatever service you need to view our recommendations.</p>





<img src="https://www.privacytools.io/assets/img/svg/layout/ukusa.svg" width="260" height="115" alt="UKUSA Agreement">

<p>The UKUSA Agreement is an agreement between the United Kingdom, United States, Australia, Canada, and New Zealand to cooperatively collect, analyze, and share intelligence. Members of this group, known as the <a href="https://www.giswatch.org/en/communications-surveillance/unmasking-five-eyes-global-surveillance-practices">Five Eyes</a>, focus on gathering and analyzing intelligence from different parts of the world. While Five Eyes countries have agreed to <a href="https://www.pbs.org/newshour/world/an-exclusive-club-the-five-countries-that-dont-spy-on-each-other">not spy on each other</a> as adversaries, leaks by Snowden have revealed that some Five Eyes members monitor each other's citizens and <a href="https://www.theguardian.com/uk/2013/jun/21/gchq-cables-secret-world-communications-nsa">share intelligence</a> to <a href="https://www.theguardian.com/politics/2013/jun/10/nsa-offers-intelligence-british-counterparts-blunkett">avoid breaking domestic laws</a> that prohibit them from spying on their own citizens. The Five Eyes alliance also cooperates with groups of third-party countries to share intelligence (forming the Nine Eyes and Fourteen Eyes); however, Five Eyes and third-party countries can and do spy on each other.</p>

<div>
  <div>
    <div>
        
        
        <div>
            
  <ol>
    <li>Australia </li>
    <li>Canada </li>
    <li>New Zealand </li>
    <li>United Kingdom </li>
    <li>United States of America </li>
  </ol>
  
        </div>
    </div>
</div>


  <div>
    <div>
        
        
        <div>
            
  <ol>
    <li>Denmark </li>
    <li>France </li>
    <li>Netherlands </li>
    <li>Norway </li>
  </ol>
  
        </div>
    </div>
</div>


  <div>
    <div>
        
        
        <div>
            
  <ol>
    <li>Belgium </li>
    <li>Germany </li>
    <li>Italy </li>
    <li>Spain </li>
    <li>Sweden </li>
  </ol>
  
        </div>
    </div>
</div>

</div>




<h3>Who is required to hand over the encryption keys to authorities?</h3>

<p>Mandatory <a href="https://en.wikipedia.org/wiki/Key_disclosure_law">key disclosure laws</a> require individuals to turn over encryption keys to law enforcement conducting a criminal investigation. How these laws are implemented (who may be legally compelled to assist) vary from nation to nation, but a warrant is generally required. Defenses against key disclosure laws include steganography and encrypting data in a way that provides plausible deniability.</p>  <p><a href="https://en.wikipedia.org/wiki/Steganography">Steganography</a> involves hiding sensitive information (which may be encrypted) inside of ordinary data (for example, encrypting an image file and then hiding it in an audio file). With plausible deniability, data is encrypted in a way that prevents an adversary from being able to prove that the information they are after exists (for example, one password may decrypt benign data and another password, used on the same file, could decrypt sensitive data).</p>



<p> * (people who know how to access a system may be ordered to share their knowledge, <strong>however, this doesn't apply to the suspect itself or family members.</strong>)</p>

<h3>Related Information</h3>

<ul>
  <li><a href="https://en.wikipedia.org/wiki/Key_disclosure_law">Wikipedia page on key disclosure law</a></li>
  <li><a href="https://law.stackexchange.com/questions/1523/can-a-us-citizen-be-required-to-provide-the-authentication-key-for-encrypted-dat">law.stackexchange.com question about key disclosure law in US</a></li>
  <li><a href="https://peertube.mastodon.host/videos/watch/e09915eb-5962-4830-a02f-8da5c2b59e71">DEFCON 20: Crypto and the Cops: the Law of Key Disclosure and Forced Decryption</a></li>
</ul>

<h3 id="usa">Why is it not recommended to choose a US-based service?</h3>

<img src="https://www.privacytools.io/assets/img/svg/layout/great_seal_of_the_united_states_obverse.svg" width="200" height="200" alt="USA">

<p>Services based in the United States are not recommended because of the country's surveillance programs and use of <a href="https://www.eff.org/issues/national-security-letters/faq">National Security Letters</a> (NSLs) with accompanying gag orders, which forbid the recipient from talking about the request. This combination allows the government to <a href="https://www.schneier.com/blog/archives/2013/08/more_on_the_nsa.html">secretly force</a> companies to grant complete access to customer data and transform the service into a tool of mass surveillance.</p>

<p>An example of this is <a href="https://en.wikipedia.org/wiki/Lavabit#Suspension_and_gag_order">Lavabit</a> ‚Äì a secure email service created by Ladar Levison. The FBI <a href="https://www.vice.com/en_us/article/nzz888/lavabit-founder-ladar-levison-discusses-his-federal-battle-for-privacy">requested</a> Snowden's records after finding out that he used the service. Since Lavabit did not keep logs and email content was stored encrypted, the FBI served a subpoena (with a gag order) for the service's SSL keys. Having the SSL keys would allow them to access
communications (both metadata and unencrypted content) in real time for all of Lavabit's customers, not just Snowden's.</p>

<p>Ultimately, Levison turned over the SSL keys and <a href="https://www.theguardian.com/commentisfree/2014/may/20/why-did-lavabit-shut-down-snowden-email">shut down</a> the service at the same time. The US government then <a href="https://www.cnbc.com/id/100962389">threatened Levison with arrest</a>, saying that shutting down the service was a violation of the court order.</p>

<h3>Related Information</h3>

<ul>
  <li><a href="https://www.bestvpn.com/the-ultimate-privacy-guide/#avoidus">Avoid all US and UK based services</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Surespot#History">Proof that warrant canaries work based on the surespot example.</a></li>
  <li><a href="https://en.wikipedia.org/wiki/UKUSA_Agreement">The United Kingdom ‚Äì United States of America Agreement (UKUSA)</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Lavabit#Suspension_and_gag_order">Lavabit: Suspension and gag order</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Key_disclosure_law">Key disclosure law</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Portal:Mass_surveillance">Wikipedia Portal: Mass_surveillance</a></li>
</ul>




<img src="https://www.privacytools.io/assets/img/svg/layout/warrant_canary_example.svg" width="450px" alt="Warrant Canary Example">

<p>A warrant canary is a posted document stating that an organization has not received any secret subpoenas during a specific period of time. If this document fails to be updated during the specified time then the user is to assume that the service has received such a subpoena and should stop using the service.</p>

<h4>Warrant Canary Examples:</h4>

<ol>
  <li><a href="https://proxy.sh/canary">https://proxy.sh/canary</a></li>
  <li><a href="https://www.ivpn.net/resources/canary.txt">https://www.ivpn.net/resources/canary.txt</a></li>
  <li><a href="https://www.bolehvpn.net/canary.txt">https://www.bolehvpn.net/canary.txt</a></li>
  <li><a href="https://www.ipredator.se/static/downloads/canary.txt">https://www.ipredator.se/static/downloads/canary.txt</a></li>
</ol>

<h4>Related Warrant Canary Information</h4>

<ul>
  <li><a href="https://www.eff.org/deeplinks/2014/04/warrant-canary-faq">Warrant Canary Frequently Asked Questions</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Warrant_canary#Companies_and_organizations_with_warrant_canaries">Companies and organizations with warrant canaries</a></li>
  <li><a href="https://www.schneier.com/blog/archives/2015/03/australia_outla.html">Warrant canary criticism by Bruce Schneier and an example of a law against warrant canaries.</a></li>
</ul>



  </div></div>]]>
            </description>
            <link>https://www.privacytools.io/providers/#ukusa</link>
            <guid isPermaLink="false">hacker-news-small-sites-24272244</guid>
            <pubDate>Tue, 25 Aug 2020 15:20:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Mathematical Structure of Particle Collisions Comes into View]]>
            </title>
            <description>
<![CDATA[
Score 51 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24270579">thread link</a>) | @rbanffy
<br/>
August 25, 2020 | http://abstractions.nautil.us/article/606/the-mathematical-structure-of-particle-collisions-comes-into-view | <a href="https://web.archive.org/web/*/http://abstractions.nautil.us/article/606/the-mathematical-structure-of-particle-collisions-comes-into-view">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p><span><br></span><span>W</span>hen particle physicists try to model experiments, they confront an impossible calculation‚Äîan infinitely long equation that lies beyond the reach of modern mathematics.&nbsp;<br></p>

<p>Fortunately, they can generate largely accurate predictions without seeing this arcane math all the way through. By cutting the calculation short, scientists at CERN√¢‚Ç¨‚Ñ¢s Large Hadron Collider in Europe make forecasts that match events they actually observe when they send subatomic particles barreling toward each other around a nearly 17-mile track.</p>
<p>Unfortunately, the era of agreement between forecast and observation may be ending. As measurements grow more precise, the approximation schemes theorists use to make predictions may not be able to keep up.</p>
<p>√¢‚Ç¨≈ìWe√¢‚Ç¨‚Ñ¢re getting close to exhausting what can be done,√¢‚Ç¨ÔøΩ said&nbsp;<a href="https://theory.cern/roster/duhr-claude" target="_blank">Claude Duhr</a>, a particle physicist at CERN.&nbsp;</p>
<p>But&nbsp;<a href="https://link.springer.com/article/10.1007/JHEP02(2019)139" target="_blank">three</a>&nbsp;<a href="https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.123.201602" target="_blank">papers</a>&nbsp;from a group of physicists led by&nbsp;<a href="https://amplitudesatpadova.wixsite.com/amplitudes-at-padova" target="_blank">Pierpaolo Mastrolia</a>&nbsp;of the University of Padua in Italy and&nbsp;<a href="https://www.ias.edu/scholars/sebastian-mizera" target="_blank">Sebastian Mizera</a>&nbsp;of the Institute for Advanced Study in Princeton, New Jersey, have revealed an underlying mathematical structure in the equations. The structure provides a new way of collapsing interminable terms into just dozens of essential components. Their method may help bring about new levels of predictive accuracy, which theorists desperately need if they are to move beyond the leading but incomplete model of particle physics.</p>
<p>√¢‚Ç¨≈ìThey have delivered lots of proof-of-concept results which show that this is a very promising technique,√¢‚Ç¨ÔøΩ Duhr said.</p>
<p>There could be a bigger payoff than improved predictions.&nbsp;</p>
<p>The new method skirts the traditional mathematical slog by directly computing √¢‚Ç¨≈ìintersection numbers,√¢‚Ç¨ÔøΩ which some hope could eventually lead to a more elegant description of the subatomic world.&nbsp;</p>
<p>√¢‚Ç¨≈ìThis is something that√¢‚Ç¨‚Ñ¢s not just mathematics,√¢‚Ç¨ÔøΩ said&nbsp;<a href="https://www.physics.mcgill.ca/~schuot/" target="_blank">Simon Caron-Huot</a>&nbsp;of McGill University, a quantum theorist who is studying the implications of Mastrolia and Mizera√¢‚Ç¨‚Ñ¢s work.&nbsp;√¢‚Ç¨≈ìIt√¢‚Ç¨‚Ñ¢s something that√¢‚Ç¨‚Ñ¢s deeply baked into quantum field theory.√¢‚Ç¨ÔøΩ&nbsp;</p>
<p><strong>An Infinite Loop</strong></p>
<p>When physicists model particle collisions they use a tool called a Feynman diagram, a simple schematic invented by Richard Feynman in the 1940s.</p>
<p>To get a feel for these diagrams, consider a simple particle event: Two quarks streak in, exchange a single gluon as they √¢‚Ç¨≈ìcollide,√¢‚Ç¨ÔøΩ then bounce away on their separate trajectories.</p>
<p>In a Feynman diagram the quarks√¢‚Ç¨‚Ñ¢ paths are represented by √¢‚Ç¨≈ìlegs,√¢‚Ç¨ÔøΩ which join to form √¢‚Ç¨≈ìvertices√¢‚Ç¨ÔøΩ when particles interact. Feynman developed rules for turning this cartoon into an equation which calculates the probability that the event actually takes place: You write a specific function for each leg and vertex‚Äîgenerally a fraction involving the particle√¢‚Ç¨‚Ñ¢s mass and momentum‚Äîand multiply everything together. For straightforward scenarios like this one, the calculation might fit on a cocktail napkin.&nbsp;</p>
<figure><img src="https://s3.amazonaws.com/nautilus-vertical/abstractions_5242dbae24adf53fee012a27d96504f9.jpg" alt="nautilus gluon"><figcaption><br><span>Samuel Velasco/Quanta Magazine</span></figcaption></figure>
<p>But the golden rule of quantum theory is to consider all possibilities, and exchanging a simple gluon represents just one among a vast landscape of scenarios that could unfold when two quarks collide. The exchanged gluon might momentarily split into a √¢‚Ç¨≈ìvirtual√¢‚Ç¨ÔøΩ quark pair, for instance, before reconstituting itself in a flash. Two quarks enter and two quarks leave, but a lot can happen in the middle. A full accounting, implying a perfect prediction, would demand an infinite number of diagrams. No one expects perfection, but the key to improving a calculation√¢‚Ç¨‚Ñ¢s precision is getting further along in the infinite line of events.<strong>&nbsp;</strong><br></p>
<p>And that√¢‚Ç¨‚Ñ¢s where physicists are getting stuck.&nbsp;</p>
<p>Zooming in to that hidden center involves virtual particles‚Äîquantum fluctuations that subtly influence each interaction√¢‚Ç¨‚Ñ¢s outcome. The fleeting existence of the quark pair above, like many virtual events, is represented by a Feynman diagram with a closed √¢‚Ç¨≈ìloop.√¢‚Ç¨ÔøΩ Loops confound physicists‚Äîthey√¢‚Ç¨‚Ñ¢re black boxes that introduce additional layers of infinite scenarios. To tally the possibilities implied by a loop, theorists must turn to a summing operation known as an integral. These integrals take on monstrous proportions in multi-loop Feynman diagrams, which come into play as researchers march down the line and fold in more complicated virtual interactions.&nbsp;</p>
<p>Physicists have algorithms to compute the probabilities of no-loop and one-loop scenarios, but many two-loop collisions bring computers to their knees. This imposes a ceiling on predictive precision‚Äîand on how well physicists can understand what quantum theory says.&nbsp;</p>
<center>
<iframe width="560" height="315" src="https://www.youtube.com/embed/qe7atm1x6Mg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""><span id="selection-marker-1" class="redactor-selection-marker"></span></iframe>
</center>
<p>But there is one small mercy: Physicists don√¢‚Ç¨‚Ñ¢t need to calculate every last integral in a complicated Feynman diagram because the vast majority can be lumped together.<br></p>
<p>Thousands of integrals can be reduced to just dozens of √¢‚Ç¨≈ìmaster integrals,√¢‚Ç¨ÔøΩ which are weighted and added together. But exactly which integrals can be subsumed under which master integrals is itself a hard computational question. Researchers use computers to essentially guess at millions of relationships and laboriously extract the combinations of integrals that matter.</p>
<p>But with intersection numbers, physicists may have found a way of elegantly plucking out the essential information from a sprawling calculation of Feynman integrals.</p>
<p><strong>A Geometric Fingerprint&nbsp;</strong></p>
<p>Mastrolia and Mizera√¢‚Ç¨‚Ñ¢s work is rooted in a branch of pure math called algebraic topology, which classifies shapes and spaces. Mathematicians pursue this classification with √¢‚Ç¨≈ìcohomology√¢‚Ç¨ÔøΩ theories, which allow them to extract algebraic fingerprints from complicated geometric spaces.</p>
<p>√¢‚Ç¨≈ìIt√¢‚Ç¨‚Ñ¢s kind of a summary, an algebraic gadget that incorporates the essence of the space you want to study,√¢‚Ç¨ÔøΩ said&nbsp;<a href="https://imag.umontpellier.fr/~dupont/" target="_blank">Cl√É¬©ment Dupont</a>, a mathematician at the University of Montpellier in France.</p>
<p>Feynman diagrams can be translated into geometric spaces that are amenable to analysis by cohomology. Each point within these spaces might represent one of a multitude of scenarios that could play out when two particles collide.</p>
<p>You might hope, naively, that by taking the cohomology of this space‚Äîfinding its algebraic structure‚Äîyou could calculate the weights for the master integrals that support it. But the type of geometric space that characterizes most Feynman diagrams is warped in a way that resists many cohomology calculations.</p>
<p>In 2017, Mizera was struggling to analyze how objects in string theory collide when he stumbled upon tools pioneered by Israel Gelfand and Kazuhiko Aomoto in the 1970s and 1980s as they worked with a type of cohomology called √¢‚Ç¨≈ìtwisted cohomology.√¢‚Ç¨ÔøΩ Later that year Mizera met Mastrolia, who realized that these techniques could work for Feynman diagrams too. In 2019,&nbsp;they published three papers that used this cohomology theory to streamline calculations involving simple particle collisions.</p>
<p>Their method takes a family of related physical scenarios, represents it as a geometric space, and calculates the twisted cohomology of that space. √¢‚Ç¨≈ìThis twisted cohomology has everything to say about the integrals we are interested in,√¢‚Ç¨ÔøΩ Mizera said.</p>
<p>In particular, the twisted cohomology tells them how many master integrals to expect and what their weights should be. The weights emerge as values they call √¢‚Ç¨≈ìintersection numbers.√¢‚Ç¨ÔøΩ In the end, thousands of integrals shrink to a weighted sum of dozens of master integrals.</p>
<p>The cohomology theories that produce these intersection numbers may do more than just ease a computational burden‚Äîthey could also point to the physical significance of the most important quantities in the calculation.</p>
<p>For example, when a virtual gluon splits into two virtual quarks, the quarks√¢‚Ç¨‚Ñ¢ possible lifetimes can vary. In the associated geometric space, each point can stand for a different quark lifetime. When researchers compute the weights, they see that scenarios with the longest-lasting virtual particles‚Äîthat is, cases in which the particles become essentially real‚Äîshape the outcome the most.</p>
<p>√¢‚Ç¨≈ìThat√¢‚Ç¨‚Ñ¢s the amazing thing about this method,√¢‚Ç¨ÔøΩ said Caron-Huot. √¢‚Ç¨≈ìIt reconstructs everything starting from just these rare, special events.√¢‚Ç¨ÔøΩ</p>
<p>In August 2020,&nbsp;Mizera, Mastrolia and colleagues published&nbsp;<a href="https://arxiv.org/abs/2008.04823" target="_blank">another preprint</a>&nbsp;showing that the technique has matured enough to handle real-world two-loop diagrams. A forthcoming paper by Caron-Huot will push the method further, perhaps bringing three-loop diagrams to heel.</p>
<p>If successful, the technique could help usher in the next generation of theoretical predictions. And, a few researchers suspect, it may even foreshadow a new perspective on reality.</p>

<ul><li> is a journalist covering developments in the physical sciences both on and off the planet. His work has appeared in <span>Scientific American, The Christian Science Monitor</span> and <span>LiveScience</span>, among other publications. Previously, he taught physics and English in Mozambique and Japan, and he has a bachelor√¢‚Ç¨‚Ñ¢s in physics from Brown University.</li></ul>
<p>Lead image:&nbsp;<a href="https://www.istockphoto.com/video/animation-of-particles-collision-in-hadron-collider-astrophysics-concept-gm1151477191-312085198" target="_blank" rel="noreferrer nofollow" data-is-link="https://www.istockphoto.com/video/animation-of-particles-collision-in-hadron-collider-astrophysics-concept-gm1151477191-312085198">vchal</a></p>
<p>Video: The brilliant physicist Richard Feynman devised a system of line drawings that simplified calculations of particle interactions and helped rescue the field of quantum electrodynamics.&nbsp;Directed by&nbsp;<a href="http://www.bonscifilms.com/" target="_blank">Emily Driscoll</a>&nbsp;and animated by&nbsp;<a href="http://metteilene.com/" target="_blank">Mette Ilene Holmriis&nbsp;</a>for Quanta Magazine.<br></p>





                    <p>Reprinted with permission from <a href="https://www.quantamagazine.org/">Quanta Magazine</a>'s <a href="https://www.quantamagazine.org/category/abstractions/">Abstractions blog</a>.</p>
            </article></div>]]>
            </description>
            <link>http://abstractions.nautil.us/article/606/the-mathematical-structure-of-particle-collisions-comes-into-view</link>
            <guid isPermaLink="false">hacker-news-small-sites-24270579</guid>
            <pubDate>Tue, 25 Aug 2020 12:23:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My AI Timelines Have Sped Up]]>
            </title>
            <description>
<![CDATA[
Score 95 | Comments 127 (<a href="https://news.ycombinator.com/item?id=24269316">thread link</a>) | @T-A
<br/>
August 25, 2020 | https://www.alexirpan.com/2020/08/18/ai-timelines.html | <a href="https://web.archive.org/web/*/https://www.alexirpan.com/2020/08/18/ai-timelines.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p>For this post, I‚Äôm going to take artificial general intelligence (AGI) to mean
an AI system that matches or exceeds humans at almost all (95%+)
economically valuable work. I prefer this definition because it focuses on what
causes the most societal change, rather than how we get there.</p>

<p>In 2015, I made the following forecasts about when AGI could happen.</p>

<ul>
  <li>10% chance by 2045</li>
  <li>50% chance by 2050</li>
  <li>90% chance by 2070</li>
</ul>

<p>Now that it‚Äôs 2020, I‚Äôm updating my forecast to:</p>

<ul>
  <li>10% chance by 2035</li>
  <li>50% chance by 2045</li>
  <li>90% chance by 2070</li>
</ul>

<p>I‚Äôm keeping the 90% line the same, but shifting everything else to
be faster. Now, if you‚Äôre looking for an argument of why I picked these particular
years, and why I shifted by 10 years instead of 5 or 15, you‚Äôre going to be
disappointed. Both are driven by a gut feeling.
What‚Äôs important is why parts of my thinking have changed - you can choose
your own timeline adjustment based on that.</p>

<p>Let‚Äôs start with the easy part first.</p>

<h2 id="i-should-have-been-more-uncertain">I Should Have Been More Uncertain</h2>

<p>It would be incredibly weird if I was never surprised by machine learning (ML)
research.
Historically, it‚Äôs very hard to predict the trajectory a research field will
take, and if I were never surprised, I‚Äôd take that as a personal failing to
not consider large enough ideas.</p>

<p>At the same time, when I think back on the past 5 years, I believe I was
surprised more often than average. It wasn‚Äôt all in a positive direction.
Unsupervised learning got better way faster than I expected. Deep reinforcement
learning got better
a little faster than I expected. Transfer learning has been slower than
expected. Combined, I‚Äôve decided I should widen the distribution of outcomes,
so now I‚Äôm allocating 35 years to the 10%-90% interval instead of 25 years.</p>

<p>I also noticed that my 2015 prediction placed 10% to 50% in a 5 year range,
and 50% to 90% in a 20 year range. AGI is a long-tailed event, and there‚Äôs
a real possibility it‚Äôs never viable, but a 5-20 split is absurdly skewed.
I‚Äôm adjusting accordingly.</p>

<p>Now we‚Äôre at the hard part. Why did I choose to shift the 10% and 50% lines
closer to present day?</p>



<p>Three years ago, I was talking to someone who mentioned
that <a href="https://intelligence.org/2017/10/13/fire-alarm/">there was no fire alarm for AGI</a>.
I told them I knew Eliezer Yudkowsky had written another post about AGI, and
I‚Äôd seen it shared among Facebook friends, but I hadn‚Äôt gotten around to reading it.
They summarized it as, ‚ÄúIt will never be obvious when AGI is going to occur.
Even a few years before it happens, it will be possible to argue AGI is far
away. By the time it‚Äôs common knowledge that AI safety is the most
important problem in the world, it‚Äôll be too late.‚Äù</p>

<p>And my reaction was, ‚ÄúOkay, that matches what I‚Äôve gotten from my Facebook
timeline. I already know the story of
Fermi predicting <a href="https://books.google.com/books?id=aSgFMMNQ6G4C&amp;pg=PA813&amp;lpg=PA813&amp;dq=weart+fermi&amp;source=bl&amp;ots=Jy1pBOUL10&amp;sig=c9wK_yLHbXZS_GFIv0K3bgpmE58&amp;hl=en&amp;sa=X&amp;ved=0ahUKEwjNofKsisnWAhXGlFQKHbOSB1QQ6AEIKTAA#v=onepage&amp;q=%22ten%20per%20cent%22&amp;f=false">a nuclear chain reaction was very likely
to be impossible</a>, only a few years before he worked on the
Manhattan Project. More recently, we had
<a href="https://www.wired.com/2014/05/the-world-of-computer-go/">R√©mi Coulom state that superhuman Go was about 10 years away</a>,
one year before <a href="https://arxiv.org/abs/1412.6564">the first signs it could happen</a>,
and two years before <a href="https://en.wikipedia.org/wiki/AlphaGo_versus_Lee_Sedol">AlphaGo</a> made it official.
I <em>also</em> already know the <a href="https://en.wikipedia.org/wiki/Common_knowledge_(logic)">common knowledge</a>
arguments for AI safety.‚Äù
I decided it wasn‚Äôt worth my time to read it.</p>

<p>(If you haven‚Äôt heard the common knowledge arguments, here‚Äôs the quick
version: it‚Äôs possible for the majority to believe AI safety is
worthwhile, even if no one says so publicly, because each individual could be
afraid everyone else will call them crazy if they argue for drastic action. This can happen
even if literally everyone agrees, because they don‚Äôt know that everyone agrees.)</p>

<p>I read the post several years later out of boredom, and
I now need to retroactively complain to all my Facebook friends who only
shared the historical events and common knowledge arguments. Although
that post summary is <em>correct</em>, the ideas I found useful were all
<em>outside that summary</em>. I trusted you, filter bubble! How could you let me
down like this?</p>

<p>Part of the fire alarm post proposes hypotheses for why people claim AGI is
impossible. One of the hypotheses is that researchers pay too much attention
to the difficulty of getting something working with their current tools,
extrapolate that difficulty to the future, and conclude we could never create
AGI because the available tools aren‚Äôt good enough.
This is a bad argument, because your extrapolation needs to account for
research tools also improving over time.</p>

<p>What ‚Äútool‚Äù means is a bit fuzzy. One clear example is our coding libraries.
People used to write neural nets in Caffe, MATLAB, and Theano. Now it‚Äôs mostly
TensorFlow and PyTorch. A less obvious example is
feature engineering for computer vision. When was the
last time anyone talked about <a href="https://en.wikipedia.org/wiki/Scale-invariant_feature_transform">SIFT features</a> for computer vision? Ages ago,
they‚Äôre obsolete. But feature engineering didn‚Äôt disappear, it just turned into
<a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional neural net</a> architecture tuning instead.
For a computer vision researcher, SIFT features were the old tool,
convolutional neural nets are the new tool, and computer vision is the application
that‚Äôs been supercharged by the better tool.</p>

<p>Whereas for me, I‚Äôm not a computer vision person. I think ML for control is a much
more interesting problem. However, you have to do computer vision to do control
in image-based environments, and if you want to handle the real world, image-based
inputs are the way to go. So for me, computer vision is the tool, robotics
is the application, and the improvements in computer vision have driven many
promising robot learning results.</p>

<p><img src="https://www.alexirpan.com/public/ai-timelines/filters.png" alt="AlexNet conv filters"></p>

<p>(Filters automatically learned by <a href="https://en.wikipedia.org/wiki/AlexNet">AlexNet</a>, which has
itself been obsoleted by the better tool, <a href="https://en.wikipedia.org/wiki/Residual_neural_network">ResNets</a>.)</p>

<p>I‚Äôm a big advocate for research tools. I think on average, people underestimate
their impact. So after reading the hypothesis that people don‚Äôt forecast
tool improvement properly, I thought for a bit, and decided I hadn‚Äôt properly
accounted for it either. That deserved shaving off a few years.</p>

<p>In the more empirical sides of ML, the obvious components of progress are your
ideas and computational budget, but there are less obvious ones too, like
your coding and debugging skills, and your ability to utilize your compute.
It doesn‚Äôt matter how many processors you have per machine, if your code doesn‚Äôt
use all the processors available.
There are a surprising number of ML applications where the main value-add
comes from better data management and data summarizing,
because those tools free up decision making time for everything else.</p>

<p>In general, everyone‚Äôs research tools are deficient in some way.
Research is
about doing something new, which naturally leads to discovering new problems,
and it‚Äôs highly unlikely someone‚Äôs already made the perfect tool for a problem
that didn‚Äôt exist three months ago. So, your current
research tools will <em>always</em> feel janky, and you shouldn‚Äôt be using that to
argue anything about timelines.</p>

<p>The research stack has lots of parts, improvements continually happen across that
entire stack, and most of
these improvements have multiplicative benefits. Multiplicative factors
can be very powerful.
One simple example is that to get 10x better results, you can either make one
thing 10x better with a paradigm shift, or you can make ten different
things
<a href="https://www.google.com/search?&amp;q=1.26^10">1.26x better</a>, and they‚Äôll combine
to a 10x total improvement.
The latter is just as transformative, but can be much easier,
especially if you get 10 experts with different skill sets
to work together on a common goal. This is how corporations become a thing.</p>

<p><img src="https://www.alexirpan.com/public/ai-timelines/tiny-gains-graph.jpg" alt="Tiny gains graph"></p>

<p>(From <a href="https://jamesclear.com/marginal-gains">JamesClear.com</a>)</p>

<h2 id="semi-supervised-and-unsupervised-learning-are-getting-better">Semi-Supervised and Unsupervised Learning are Getting Better</h2>

<p>Historically, unsupervised learning has been in this weird position where it is
obviously the right way to do learning, and also a complete waste of time if
you want something to work ASAP.</p>

<p>On the one hand, humans don‚Äôt have labels for most things they learn,
so ML systems shouldn‚Äôt need labels either. On the other hand, the
deep learning boom of 2015 was mostly powered by supervised learning on
large, labeled datasets.
Richard Socher made a notable tweet at the time:</p>

<div>
<blockquote><p lang="en" dir="ltr">Rather than spending a month figuring out an unsupervised machine learning problem, just label some data for a week and train a classifier.</p>‚Äî Richard Socher (@RichardSocher) <a href="https://twitter.com/RichardSocher/status/840333380130553856?ref_src=twsrc%5Etfw">March 10, 2017</a></blockquote> 
</div>

<p>I wouldn‚Äôt say unsupervised learning has always been useless. In 2010, it was
common wisdom that deep networks should go through an unsupervised pre-training
step before starting supervised learning. See <a href="https://jmlr.csail.mit.edu/papers/volume11/erhan10a/erhan10a.pdf">(Erhan et al, JMLR 2010)</a>.
In 2015, self-supervised word vectors like <a href="https://nlp.stanford.edu/projects/glove/">GloVe</a>
and <a href="https://en.wikipedia.org/wiki/Word2vec">word2vec</a> were automatically
learning interesting relationships between words.
As someone who started ML around 2015,
these unsupervised successes felt like exceptions to the rule. Most other
applications relied on labels. Pretrained ImageNet features
were the closest thing to general behavior, and those features were learned
from scratch through only supervised learning.</p>

<p>I‚Äôve long agreed that unsupervised learning is the future, and the right way
to do things, as soon as we figure out how to do so.
But man, we have spent a long time trying to do so.
That‚Äôs made me
pretty impressed with the semi-supervised and unsupervised learning papers from
the past few months.
Momentum Contrast from <a href="https://arxiv.org/abs/1911.05722">(He et al, CVPR 2020)</a>
was quite nice, SimCLR from <a href="https://arxiv.org/abs/2002.05709">(Chen et al, ICML 2020)</a> improved
on that, and Bootstrap Your Own Latent <a href="https://arxiv.org/abs/2006.07733">(Grill, Strub, Altch√©, Tallec, Richemond et al, 2020)</a>
has improved on that. And then there‚Äôs <a href="https://arxiv.org/abs/2005.14165">GPT-3</a>,
but I‚Äôll get to that later.</p>

<p>When I was thinking through what made ML hard, the trend lines were pointing to larger
models and larger labeled datasets. They‚Äôre still pointing that way now.
I concluded that future ML progress would be bottlenecked by labeling requirements.
Defining a 10x bigger model is easy. <em>Training</em> a 10x bigger model is harder, but
it doesn‚Äôt need 10x as many people to work on it. Getting 10x as many labels
does. Yes, data labeling tools are getting better, <a href="https://en.wikipedia.org/wiki/Amazon_Mechanical_Turk">Amazon Mechanical Turk</a> is very popular, and there are even
startups whose missions are to provide fast data labeling ‚Ä¶</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.alexirpan.com/2020/08/18/ai-timelines.html">https://www.alexirpan.com/2020/08/18/ai-timelines.html</a></em></p>]]>
            </description>
            <link>https://www.alexirpan.com/2020/08/18/ai-timelines.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24269316</guid>
            <pubDate>Tue, 25 Aug 2020 08:41:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DIY Single-Chip 2D Retro Game Console]]>
            </title>
            <description>
<![CDATA[
Score 128 | Comments 26 (<a href="https://news.ycombinator.com/item?id=24268585">thread link</a>) | @0xmarcin
<br/>
August 24, 2020 | http://www.voja.rs/PROJECTS/GAME_HTM/1_intro.htm | <a href="https://web.archive.org/web/*/http://www.voja.rs/PROJECTS/GAME_HTM/1_intro.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <td rowspan="4">
      <div>
			<iframe width="420" height="315" src="//www.youtube.com/embed/VbTwWFwbsE4" frameborder="0" allowfullscreen=""></iframe>
			<p>
			<img height="420" src="http://www.voja.rs/PROJECTS/GAME_HTM/console.jpg" width="600"></p>
			<p>This 
			DIY project offers the
            simple stand-alone VGA game console which is based on <b> PIC24EP512GP202</b>  microcontroller.
            As the video signal and the corresponding sync signals are generated by software, 
			the console contains a
            minimum of hardware. There is also an audio signal output with five binary tone channels, mixed by 
			a 
			passive resistor network. Two of those channels are used for sound effects,  
			similar to ones used in video games of that time (early eighties) and 
			three for background music. This output is capable of driving line 
			output for PC speakers or headphones.</p>
			<p>
			It should be noted that there is no video processing unit, PGA or 
			any special purpose chips, and that PIC microcontrollers are not 
			designed for video signal generation. Everything is achieved by a 
			series of different design tricks and some compromises.</p>
			<p>
			This is an open hardware and open software project. Video 
			and audio generators, which are the vital parts of the firmware, are 
			the parts of the operating system, which will soon be documented, and can be used 
			for any other game or application. As the timings are critical, those parts 
			are written in assembly language, but all the other parts of the 
			program (scenario for some other games or any other application) may 
			also be written in some other programming language, preferably 
			Microchip's C. In this case all parts are written in Assembler, but 
			only as a result of author's preference.</p>
			<p>
			At the moment, only the game Jumping Jack is written for the 
			platform, well known to those who played with the Spectrum personal 
			computer back in the day. However, once a new game is created, it is 
			easy to download it from the computer, via 
			the serial port. The console has a USB connector, but it is used 
			only for 5V power supply. Unfortunately, microcontrollers which are 
			packed in DIP packages (with thru-hole soldering, convenient for DIY 
			projects and workshops) do not have USB interface but only serial ports, so 
			you have to use RS 232 to download the new game instead of Jumping 
			Jack, which is deafult in this project.</p>
			<p>
			If you want to build this console, you need the PCB and components 
			which are listed <span><strong>
			<a href="http://www.voja.rs/PROJECTS/GAME_HTM/2.%20Hardware.htm#BOM">here</a></strong></span>. 
			To program the microcontroller, you should need a PIC programmer (e.g. 
			<strong>PICKIT3</strong>, avaliable <span><strong>
			<a href="http://www.microchipdirect.com/ProductSearch.aspx?Keywords=PG164130">here</a></strong></span>) and
			<strong>MPLAB X IDE</strong> software, available <span><strong>
			<a href="http://www.microchip.com/pagehandler/en-us/family/mplabx/">here</a></strong></span>. 
			But if you want to know how PIC generates video and audio signals by 
			software in real time, or even if you feel ambitious enough to 
			create your own game for this platform, please visit the
			<span>
			<strong><a href="http://www.voja.rs/PROJECTS/GAME_HTM/2.%20Hardware.htm">next page</a></strong></span></p>
          </div>
    </td>
  </div></div>]]>
            </description>
            <link>http://www.voja.rs/PROJECTS/GAME_HTM/1_intro.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-24268585</guid>
            <pubDate>Tue, 25 Aug 2020 06:23:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Animal behavior during a solar eclipse]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 37 (<a href="https://news.ycombinator.com/item?id=24268252">thread link</a>) | @everbody
<br/>
August 24, 2020 | https://readwildness.com/23/poli-eclipse | <a href="https://web.archive.org/web/*/https://readwildness.com/23/poli-eclipse">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				
				<p><span>The farm dimmed mid-afternoon</span>, dipping into dusk-light. Beside the parked tractors, we passed around a block of green glass from a welder‚Äôs helmet and took turns looking through it up at the sky. I chewed a single pebble of a snap pea in my mouth. That was the size of the sun through the glass, I thought, no bigger than a pea, a sliver missing as if chewed by a caterpillar or potato beetle.</p>
				
				<p>In a total solar eclipse, photosynthesis slows down. Plants, which turn to face the sun throughout the day, may change direction, feeling for the light. Without the sun, they become unmoored. Lost in the dark. In the 2017 eclipse, changes in light intensity were attributed to bees going temporarily still. Observers in the path of totality‚Äîthe stretch of land where the sun goes fully dark‚Äîreported fireflies emerging, crickets chirping. Night behavior bleeding into day.</p>
				
				<p>I stared through the glass. Sun the size of a blueberry. Size of a chrysanthemum bud.</p>
				
				<p>We wouldn‚Äôt get to see the total eclipse‚Äîthat dramatic upheaval of the afternoon‚Äôs forward march, an ebb when there should be flow. The path of totality was south of us, stretching from Oregon to South Carolina. Still, the light waned at our small farm. Contrast became muted, the sky and hayfields feeling duller, softer. The zinnia patch still sparked with its shocks of red, orange, pink, yellow, but the flowers seemed unsure of themselves. The shadows from the trees did strange things, cast crescent-shaped spells on the ground, reminding me of the light funneled through a dime-store kaleidoscope. Someone arrived with a pair of glasses‚Äîthe kind made from plastic and cardboard that they‚Äôd been selling at gas stations for months, running out in the final few days. We passed them around, but <span>I preferred the welding glass, the way it turned the sliver of sun goblin-green.</span></p>
				
				<p>Sun the size of a kernel of the summer‚Äôs first sweet corn; the size of a worm, coiled inside an ear from the later crop, chewing on its silky tassel.</p>
				
				<p>During a total solar eclipse, dairy cows have been known to return to their barn as the sun and sky darken. Orb-weaving spiders have been observed taking down their webs during totality, then rebuilding them <span>when the sun reappears. Some species of birds will sing out their night calls,</span> then go to their roosts, falling silent; when the sun reappears, they start their morning rituals. In this sense, the eclipse is a microcosm of night, the dark sped up, the hour hand spinning around a clock at a horse‚Äôs trot.</p>
				
				<p>Sun the size of a pepper seed. Size of a flea beetle. A ladybug resting on a windowsill. A thistle bur stuck to a coat.</p>
				
				<p>There is no evidence that an eclipse affects the behavior of horses, but nevertheless, there will be some owners who usher them into the safety of the barn before the sky goes dark. This is a form of love which happens to involve a kind of captivity.</p>
				
				<p>Sun the size of a nostril, size of a belly button, a baby‚Äôs tooth, a fingertip. Size of the chunk of flesh I‚Äôd sliced off the top of my thumb one day when I was careless with a head of cauliflower. It bled so much and so steadily that I ran to the back of the farm stand where someone sat me down on a bench to bandage the cut. I remember they held my hand so carefully, tilting it one direction then the other, saying twice, maybe three times, <i>You need to be more careful</i>.</p>
				
				<p>Once we‚Äôd passed around the glass, we scattered to our different jobs. I drove back to the snap pea patch, where I continued filling a bucket with round, ripe pods. I heard a tractor starting, the exhaust clearing its throat, then watched from where I was crouched as someone connected a hay rake to the back and pulled back onto the road, headed for one of the higher fields, leaving a cloud of dust and acres of silence behind. I realized then that the birds, which were usually a constant chorus, had gone quiet‚Äîthe small snapping of my hands plucking peas from their vines, the only noise that reached me. I stood, stretching, and looked at the sky, the familiar fields‚Äîtheir flat, muted light. I stood there looking at the farm that for years I had grown to know and care for, and I thought of scale‚Äîof how the land surrounding me had come to feel like it was my own body, a breathing, pulsing creature that could weep or swell; and, at the same time, how the land felt unthinkably large‚Äîa roaring sun‚Äîthe weight of it and of the people who worked it reaching deep into the smallest cracks and crevasses of my life like the tendrilled arms of solar flares bursting.</p>
				
				<p>I thought of all of this as I rolled another snap pea over my tongue, biting down, tasting the small eruption of green. Then I bent down, knees to dirt, to finish my work.</p>
				
				<hr>
				
				<p>Read more from <a href="https://readwildness.com/23">Issue No. 23</a> or share  on <a href="http://www.facebook.com/share.php?u=http://readwildness.com/23/poli-eclipse">Facebook</a> and <a href="https://twitter.com/share?url=http://readwildness.com/23/poli-eclipse&amp;via=platypuspress&amp;related=twitterapi%2Ctwitter&amp;hashtags=wildnessjournal&amp;text=Check%20this%20out">Twitter</a>.</p>
				
			</section></div>]]>
            </description>
            <link>https://readwildness.com/23/poli-eclipse</link>
            <guid isPermaLink="false">hacker-news-small-sites-24268252</guid>
            <pubDate>Tue, 25 Aug 2020 05:02:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[rc.d belongs in libexec, not etc]]>
            </title>
            <description>
<![CDATA[
Score 70 | Comments 66 (<a href="https://news.ycombinator.com/item?id=24267933">thread link</a>) | @Khaine
<br/>
August 24, 2020 | https://jmmv.dev/2020/08/rcd-libexec-etc.html | <a href="https://web.archive.org/web/*/https://jmmv.dev/2020/08/rcd-libexec-etc.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
              
              <article>

<p>Let‚Äôs open with the controversy: the scripts that live under <code>/etc/rc.d/</code> in FreeBSD, NetBSD, and OpenBSD are in the wrong place. They all should live in <code>/libexec/rc.d/</code> because they are code, <em>not</em> configuration.</p>

<p>This misplacement is something that has bugged me for ages but I never had the energy to open this can of worms back when I was very involved in NetBSD. I suspect it would have been a draining discussion and a very difficult thing to change.</p>

<p>But‚Ä¶ what am I talking about anyway?</p>

<p>If you have administered a BSD system, you have certainly encountered the <code>/etc/rc.d/</code> directory; and if you have administered pre-systemd Linux systems, you have dealt with <code>/etc/init.d/</code>. These directories contain startup scripts to configure the system at boot time and are immutable. Their code is parameterized to allow changing their behavior via configuration files, not via code edits. And that‚Äôs the base of my critique.</p>

<p>But before getting into why the current state is problematic and how things should look like, let‚Äôs first dig into how we got here. And, for that, we need to go back in history.</p>



<p>4.4BSD‚Äôs (1993) boot process was rather simple: the kernel started <code>init</code> which in turn ran the <code>/etc/rc</code> script before starting <code>getty</code> on each console. The <code>/etc/rc</code> monolith was in charge of configuring the machine‚Äôs file systems and processes, and delegated to two other scripts: <code>/etc/netstart</code> for network configuration and <code>/etc/rc.local</code> for locally-added services. Current BSD systems are more advanced in this area as we shall see later, but the core boot process remains the same: <code>/etc/rc</code> is the primary entry point and bootstraps a collection of shell scripts.</p>

<p>In the early days, package management and file provenance tracking, like we are used to having in popular Linux distributions, was not a thing. You were expected to tune the systems‚Äô behavior by <em>editing</em> files which might or might not have been designed to support edits. If you had to edit <code>/etc/rc</code>, which was a script shipped by the system, that was alright.</p>

<p><code>/etc/rc.local</code>, on the other hard, was <em>not</em> shipped by the system, and it was up to you to create it if you wanted to add custom startup commands without modifying <code>/etc/rc</code>. And this is where things get interesting. <code>/etc/rc.local</code> didn‚Äôt need to be supported: if you were expected and able to edit <code>/etc/rc</code> anyway, why would you deal with a separate file? The reason is, most likely, to simplify system upgrades: during an upgrade, you want to benefit from any upstream changes made to <code>/etc/rc</code> (some of which might actually be <em>necessary</em> for proper system operation). Applying updates to a manually-modified file is tricky, so putting as many of your manual overrides into <code>/etc/rc.local</code> helped minimize this problem.</p>



<p>System V 4 (SVR4, 1988) also came with its own, and very different, boot process. The key difference was that System V had the concept of runlevels. As a result, configuring the boot process was a more convoluted endeavour because it was possible to select different services per runlevel.</p>

<p>To accomplish per-runlevel tuning, the system used <a href="https://jmmv.dev/2020/08/config-files-vs-directories.html">configuration directories rather than files</a>: there was a separate <code>/etc/rcX.d/</code> directory for each runlevel (where <code>X</code> was the number of the runlevel), and these directories contained one file per action to take at startup time. To avoid duplicates, these files were just symlinks to common files under <code>/etc/init.d/</code>‚Äîand the symlinks, not their targets, were named so that their lexicographical order determined startup execution order.</p>

<p>Once again, we can already observe issues here: the symlinks under <code>/etc/rcX.d/</code> <em>are</em> configuration because their presence indicates what to start and their names determine their startup order. But the files under <code>/etc/init.d/</code> are <em>not</em>: they are shell scripts shipped with the system and should not be manually modified.</p>



<p>NetBSD <a href="http://www.mewburn.net/luke/papers/rc.d.pdf">modernized the boot process</a> in its 1.5 release (2000), and it did so in two ways: first, it introduced <code>/etc/rc.d/</code> as a directory to contain separate scripts per action and service; and, second, it introduced <a href="https://netbsd.gw.com/cgi-bin/man-cgi?rcorder+8+NetBSD-9.0-STABLE">the <code>rcorder(8)</code> tool</a> to determine the order in which these services run. <code>rcorder(8)</code> uses dependency information encoded in the scripts as comments‚Äînot lexicographical ordering as System V did. FreeBSD <a href="https://www.freebsd.org/cgi/man.cgi?query=rc&amp;apropos=0&amp;sektion=8&amp;manpath=FreeBSD+12.1-RELEASE&amp;arch=default&amp;format=html">inherited this design</a> in its 5.0 release (2003) and OpenBSD reimplemented something similar in its 4.9 release (2011).</p>

<p>With these two pieces in place, the <code>/etc/rc</code> script in NetBSD and FreeBSD changed to execute all files from <code>/etc/rc.d/</code> based on the output of <code>rcorder(8)</code>. Among these scripts is <a href="https://github.com/NetBSD/src/blob/8f8c6d6b2a8778b653d9630f3f18e057b477a012/etc/rc.d/local"><code>/etc/rc.d/local</code></a>, whose purpose is to run <code>/etc/rc.local</code> if it exists. And that‚Äôs all, really. The <code>/etc/rc</code> script thus became <a href="https://github.com/NetBSD/src/blob/8f8c6d6b2a8778b653d9630f3f18e057b477a012/etc/rc">trivial</a>.</p>

<p>The key thing to notice here is that the scripts shipped in <code>/etc/rc.d/</code> are <em>highly configurable</em> via the user-controlled <a href="https://github.com/NetBSD/src/blob/8f8c6d6b2a8778b653d9630f3f18e057b477a012/etc/rc.conf"><code>/etc/rc.conf</code></a> file. This essentially makes the scripts read-only, as it shifts local customizations to the configuration file. <em>System administrators are not supposed to edit the scripts.</em> Instead, they are supposed to: modify <code>/etc/rc.conf</code> to customize what gets run and how; add new scripts under <code>/etc/rc.d/</code> if they so choose; and edit <code>/etc/rc.local</code> to easily run arbitrary commands.</p>



<p>My main gripe is that the files under <code>/etc/rc.d/</code> are immutable scripts. They do not belong in <code>/etc/</code> and their presence there makes system upgrades harder for no good reason.</p>

<p>You see: in NetBSD and FreeBSD, system upgrades happen by unpacking new distribution sets in the root directory and then running a script to incorporate configuration updates. This script is interactive and helps highlight how new system-provided updates to configuration files conflict with previous manual edits. (This process might seem rudimentary to you, but it‚Äôs actually pretty robust and easy to understand‚Äîand you can use tooling like <a href="https://github.com/jmmv/sysupgrade/">sysupgrade</a> to make it trivial.)</p>

<p>So why is that a problem? Because you will <em>always</em> face merges like this:</p>
<div><pre><code data-lang="diff"><span>--- /etc/rc.d/npf               2019-08-09 19:09:42.800758233 -0400
</span><span></span><span>+++ /tmp/temproot/etc/rc.d/npf  2019-11-16 10:39:27.000000000 -0500
</span><span></span><span>@@ -1,6 +1,6 @@
</span><span></span> #!/bin/sh
 #
<span>-# $NetBSD: npf,v 1.3 2012/11/01 06:06:14 mrg Exp $
</span><span></span><span>+# $NetBSD: npf,v 1.4 2019/04/19 18:36:25 leot Exp $
</span><span></span> #
 # Public Domain.
 #
<span>@@ -36,7 +36,11 @@
</span><span></span>        echo "Enabling NPF."
        npf_cfg_check
        /sbin/npfctl reload
<span>-       /sbin/npfctl start
</span><span></span><span>+
</span><span>+       # The npf_boot script has enabled npf already.
</span><span>+       if [ "$autoboot" != "yes" ]; then
</span><span>+               /sbin/npfctl start
</span><span>+       fi
</span><span></span> }
 
 npf_stop()

File: /etc/rc.d/npf (modified)

Please select one of the following operations:

  d  Don't install the new file (keep your old file)
  i  Install the new file (overwrites your local modifications!)
  m  Merge the currently installed and new files
  s  Show the differences between the currently installed and new files
  su  Show differences in unified format ("diff -u")
  sc  Show differences in context format ("diff -c")
  ss  Show differences side by side ("sdiff -w187")
  scommand Show differences using the specified diff-like command
  v  Show the new file

What do you want to do? [Leave it for later]
</code></pre></div>
<p>And, really, who cares? Why are you being distracted to review a <em>code</em> change when what you are trying to do is assess <em>configuration</em> conflicts? How many times have you actually objected to these merges?</p>

<p>You might say: well, I want to know <em>exactly</em> how the boot process of my machine changes during an upgrade. Sure, that‚Äôs a fine goal, but then this procedure is flawed and completely insufficient to achieve such goal. In the example above, whatever <code>/etc/rc.d/npf</code> does can also be done from within the <code>/sbin/npfctl</code> binary it invokes‚Ä¶ and you were never asked to review changes to the latter during an upgrade, were you? And <em>of course</em> you could review the binary‚Äôs code as part of your own system build, but if you did that, then you could have reviewed the startup script as well, right?</p>



<p>Startup scripts provided by the system need to live in a location that can contain executables‚Äîbut we don‚Äôt want those executables to show up in the <code>PATH</code>. These requirements discard <code>bin</code> and <code>sbin</code>, and points us towards <code>libexec</code> on BSD systems and somewhere under <code>lib</code> on Linux.</p>

<p>Therefore, the read-only startup scripts should move from <code>/etc/rc.d/</code> to <code>/libexec/rc.d/</code> (which, by the way, also applies to <code>/etc/rc</code>, <code>/etc/rc.subr</code>, and <code>/etc/rc.shutdown</code>). And that‚Äôs it. <del><code>/etc/rc</code></del> <code>/libexec/rc</code> should continue to use <code>rcorder(8)</code> to check what‚Äôs needed to run, but it should read files from <code>/libexec/rc.d/</code>. You might even want to support a separate location for user-created services, which might still be <code>/etc/rc.d/</code> or, better yet, a more fitting location like <code>/usr/pkg/libexec/rc.d/</code> (though that quickly runs into problems if you have multiple file systems).</p>

<p>With this design, system upgrades would be much saner because the configuration merge process would focus, purely, on actual configuration changes and not on irrelevant code changes. All updates to <code>/libexec/rc.d/</code> would be applied by unpacking the new distribution sets (<code>base.txz</code> in this case) without disturbing you about how exactly they changed.</p>

<p>Does this relate to Linux distributions at all? I briefly mentioned <code>/etc/init.d/</code> at the beginning, and the problem there is similar. But it‚Äôs also an obsolete problem given that Linux distributions have moved onto systemd by now. That said, systemd still has to manage individual services and, like it or not, has gotten this right. If we look at the <a href="https://www.freedesktop.org/software/systemd/man/systemd.unit.html"><code>systemd.unit(5)</code></a> manual page, which describes where units are loaded from, the system first looks into various <code>/etc/</code> and <code>/run/</code> directories, but then also looks at <code>/usr/lib/systemd/system/</code> (a read-only location correctly controlled by the package manager)‚Äîand the vast majority of the scripts live inside the latter.</p>



<p>I currently don‚Äôt run BSD systems any more so my incentives to make this happen are low‚Ä¶ but if this all makes sense and is something you‚Äôd like to pursue, by all means please do! I‚Äôm happy to help ‚Ä¶</p></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jmmv.dev/2020/08/rcd-libexec-etc.html">https://jmmv.dev/2020/08/rcd-libexec-etc.html</a></em></p>]]>
            </description>
            <link>https://jmmv.dev/2020/08/rcd-libexec-etc.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24267933</guid>
            <pubDate>Tue, 25 Aug 2020 03:35:21 GMT</pubDate>
        </item>
    </channel>
</rss>
