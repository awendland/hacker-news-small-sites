<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 28 Jun 2020 08:16:29 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 28 Jun 2020 08:16:29 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Laura Deming, founder of the Longevity Fund, on being homeschooled]]>
            </title>
            <description>
<![CDATA[
Score 106 | Comments 183 (<a href="https://news.ycombinator.com/item?id=23644762">thread link</a>) | @mksm
<br/>
June 25, 2020 | https://blog.withprimer.com/laura-deming/ | <a href="https://web.archive.org/web/*/https://blog.withprimer.com/laura-deming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
	<article>
		<div>

			<section>
				<p>Laura Deming is a biologist and founder of The Longevity Fund, the first VC firm to focus on companies that work on extending healthy human lifespan and addressing age-related diseases through biotechnology. She grew her roots in biology as a homeschooling student in New Zealand, and moved to the US to work in a <a href="https://hillblomcenter.ucsf.edu/#:~:text=The%20mission%20of%20the%20Hillblom,diseases%20have%20similar%20molecular%20causes.">UCSF biology lab</a> at age 12. By age 14, she was a student at MIT, then became a <a href="https://thielfellowship.org/">Thiel Fellow</a>. We asked Laura to share how her education prepared her to lead and build today.</p><figure><img src="https://blog.withprimer.com/content/images/2020/06/Frame-2.png" alt="" srcset="https://blog.withprimer.com/content/images/size/w600/2020/06/Frame-2.png 600w, https://blog.withprimer.com/content/images/size/w1000/2020/06/Frame-2.png 1000w, https://blog.withprimer.com/content/images/size/w1600/2020/06/Frame-2.png 1600w, https://blog.withprimer.com/content/images/size/w1754/2020/06/Frame-2.png 1754w"><figcaption>Laura Deming. Illustration by <a href="https://www.ne-oh.com/">Annie Oh</a>.</figcaption></figure><h3 id="what-are-you-working-on-and-thinking-about-this-week">What are you working on and thinking about this week?</h3><p>How long do you have? I normally have a few key focuses at work (right now, immune aging from a bunch of different angles), and then a billion other small ideas that float in and out of my cranium. My most persistent focus is something that I can’t talk about yet because it would sound slightly insane, but right now, I’m pursuing these more coherent questions: &nbsp;<br></p><ol><li>Is there a flywheel effect with biological tools? Will biological discoveries become the tools for next-generation discovery? How might we predict progress in biology?</li><li>Why does it normally take about a year for the best proto-entrepreneurs I know to reach full conviction about starting a company? What are ways to accelerate that process?</li><li>Is there an immortal cell that doesn’t replicate anywhere on earth? (We presumably wouldn’t see it if there was.)</li></ol><p>I’m really obsessed with <a href="http://book.bionumbers.org/">Cell Biology by the Numbers</a>. I think quantitative intuitive models of biology are the best thing ever. Also <a href="https://www.cornell.edu/video/nima-arkani-hamed-morality-fundamental-physics">this Nima Arkani-Hamed</a> video is literally the best thing ever.</p><h3 id="what-was-your-education-like">What was your education like?</h3><p>I grew up homeschooled in NZ with a hilariously small amount of context for what the real world was like. In retrospect, it was totally ideal. I had two strong memes deeply implanted in my cranium early in life - <em>I love science </em>and <em>it’s my job to do something really important </em>and<em> I can do it, too. </em>I have no clue who I’d be without those memes, and I’m also not sure that the latter was actually true! My dad just always told me that I was exceptional and could work out a way whatever I wanted to do in the world and I believed him. I still do, in a funny way, despite about a decade of evidence to the contrary and realizing how actually hard it is to make drugs for complex diseases. It’s extraordinarily sad how many otherwise brilliant kids might not do things they could because they don’t have a similarly supportive environment — I’m really excited for things like <a href="https://dcgross.com/">Daniel Gross</a>’s <a href="https://pioneer.app/">Pioneer</a> for that reason. </p><figure><img src="https://blog.withprimer.com/content/images/2020/06/image.png" alt="" srcset="https://blog.withprimer.com/content/images/size/w600/2020/06/image.png 600w, https://blog.withprimer.com/content/images/size/w1000/2020/06/image.png 1000w, https://blog.withprimer.com/content/images/size/w1600/2020/06/image.png 1600w, https://blog.withprimer.com/content/images/size/w2000/2020/06/image.png 2000w"><figcaption>Laura as a child, drawing DNA on the pavement outside of her house in chalk, an anecdote from a talk that she gave for <a href="https://www.youtube.com/watch?v=YwslKJut8eM">TedxYouth@Tallinn</a>. Illustration by <a href="https://www.ne-oh.com/">Annie Oh</a>.</figcaption></figure><p>I feel like it was a lot of puzzle solving and doing obvious stuff. And then starting to think more independently in college, and to try to figure out what problems I wanted to work on. But I had this moment around that time where a friend and I were driving to a camping site, and I was trying to explain a math concept to him, and he abruptly turned to me and said “I’m feeling very frustrated right now because you honestly have absolutely no idea what you are talking about.”<em> </em></p><p>It’s really hard to explain without context how actually useful that comment was. As he explained it, I was just parroting off the definition of something. The real way to understand things is to be able to see, explore, feel the concept from a bunch of different angles, and to be able to rigorously prove things about it. I still struggle with the latter, but having an intuition for what <em>real, deep </em>understanding of a concept looks like has been a great guidepost. For example, I realized I didn’t understand what entropy was, and now kind of do, after a summer of being in near tears with frustration about it. </p><h3 id="where-and-when-did-your-mission-to-improve-longevity-originate">Where and when did your mission to improve longevity originate?</h3><p>It’s funny, because I get asked that question a lot. I think of it like this: if you were to watch a million people jump off a bridge every day and just suffer in a really extreme way throughout all of it, How would we respond as a society? An overwhelming number of people would be inspired to take action and help. When you think of it in acute, immediate terms, viscerally shocking and moving. But with longevity and other deeply existential problems, the horror of what’s happening has been tragically normalized.</p><p>I really just wanted to work on the biggest problem possible. At first I thought that was cancer, but after a variety of experiences, aging just seemed like a bigger deal.</p><p>I have a much less antagonistic relationship with death now than I did when I was a kid. I understand more that we are a species, that there’s something beyond us as individuals — but despite that, I absolutely cannot square the idea of sobbing when a relative gets cancer and then being totally fine with another debilitating degenerative disease also caused by aging that we somehow have collectively decided is natural and normal.</p><h3 id="how-has-the-way-you-learned-as-a-kid-shaped-the-way-you-learn-and-make-decisions-at-the-helm-of-the-longevity-fund">How has the way you learned as a kid shaped the way you learn and make decisions at the helm of The Longevity Fund?</h3><p>I’ve had to un-learn a bunch of stuff I learned when I first came to the professional world. As a kid, I was deeply joyous about science. I loved it directly and with a passion, and I absolutely believed I was going to grow up to be like Michael Faraday (his story about <a href="https://artsandculture.google.com/exhibit/people-of-science-michael-faraday-the-royal-society/HQLyLIo6MWpoKw?hl=en">getting an apprenticeship with Humphrey Davy</a> is amazing, by the way). When I entered the world of finance with my fund, I was totally scared to seem like I didn’t know what I was doing, and I felt like it was really important to hide who I was to seem more ‘adult’. Now, in retrospect, I think that was both understandable and a bit of a mistake.</p><p>One thing I learned as a kid that I keep on forgetting so easily is how not to care about what anyone else thinks (with a few close exceptions). It’s funny - even in Silicon Valley, hypothetically the vanguard of independent thought, I feel like that’s extremely hard to do. In part, because what other people think constrains your access to resources. So it’s an interesting balance. </p><h3 id="i-ve-heard-you-talk-about-your-dad-telling-you-at-12-years-old-to-make-sure-that-everyone-was-a-little-bit-happier-because-you-were-in-the-lab-each-day-what-role-did-your-parents-play-in-your-life-and-education">I’ve heard you talk about your dad telling you at 12 years old to make sure that everyone was a little bit happier because you were in the lab each day. What role did your parents play in your life and education?</h3><p>Oh, man. My Dad had so much good advice as a kid — I really felt like I got a cheat code to life early on. It was like being Ben Franklin’s daughter or something. I’m probably exaggerating, but it felt that way. </p><p>One thing he told me was ‘action comes before motivation’ - that’s always been an incredibly powerful thing in my life. He taught me a lot about putting your head down and working hard and not believing anyone who tells you you are great, having that come mostly from your own self-judgment. Being extremely humble around people who know more, finding any way on earth to help them. </p><p>My dad also taught me a lot about humor and how ridiculous the world was in so many different ways. Almost too much - I think I take things more seriously now. But it’s kind of the Mark Twain effect - the world and everyone in it is a hilarious, self-sabotaging, foolhardy place that is also one of the most deeply joyous and interesting things going on in the galaxy. He used to say you can either look at what’s going on in the world and cry or laugh. Why not pick the latter?</p><p>My mom taught me about kindness and empathy and wanting to help others. She’s probably the most giving person I know. </p><p>When I first met Cynthia Kenyon, who literally changed my and many other lives – she’s amazing – I had this very extreme mental conceit that I would beg her to scrub floors in her lab and somehow work my way up on the academic ladder. I was 12. She very kindly offered for me to just work in her lab as a normal intern, which was so kind in retrospect. It changed my life, to be taken seriously like that at a young age. </p><h3 id="i-love-how-you-describe-the-way-the-longevity-fund-removes-limits-on-who-can-participate-in-biomedical-entrepreneurship-how-can-we-translate-some-of-what-you-ve-learned-about-diverse-participation-in-science-to-the-way-that-kids-learn">I love how you describe the way The Longevity Fund removes limits on who can participate in biomedical entrepreneurship. How can we translate some of what you’ve learned about diverse participation in science to the way that kids learn?</h3><p>I think there’s something about being absolutely delighted when you meet someone who doesn’t know something. That feeling is the best thing in the world because <em>you get to be the first person to tell them about some incredibly cool natural phenomenon</em>. That’s pretty great. I still remember being a preteen in Cynthia’s lab when Marc McCormick described how SVMs (<a href="https://en.wikipedia.org/wiki/Support_vector_machine">Support Vector Machines</a>) worked for handwriting recognition in the postal system. He was just so good at explaining things, and that really stuck. Encourage people to own ideas, be skeptical of them, and learn to delight in poking holes in things.<br></p><p>When thinking about diverse participation, it’s funny – before I came to the Valley, I had absolutely no idea that being a girl was in any way a handicap. To me, it was an obvious advantage – in a sea of people who all looked the same way, I’d stick out like a sore thumb! If I could make it, wouldn’t I obviously be an amazing role model? Being in the valley for a while, it kind of wore off, and the more articles I read about how much it sucked to be a girl in science, the more I believed it. I’m not sure what to think about all of that, really. </p><h3 id="what-s-something-you-believe-that-most-people-don-t">What’s something you believe that most people don’t?</h3><p>I can give you a few!</p><ol><li>That we will see the first drug to measurably affect <a href="https://publichealth.wustl.edu/heatlhspan-is-more-important-than-lifespan-so-why-dont-more-people-know-about-it/">human healthspan</a> tested in the next decade, and that this is one of the biggest deals in how we thinking about disease. It’s not just hype and rhetoric.</li><li>That original thinkers are so darn much more rare to find than I thought they’d be growing up. <br></li></ol><hr><p><em>Primer is a new education company whose goal is to help kids engage in limitless learning, starting with homeschoolers. </em><strong>Homeschooled:</strong><em> is a regular series about homeschooling alumni who have gone on to do amazing things. We're just getting started, so we'd love to hear what you think!</em></p><p>Sign up for …</p></section></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.withprimer.com/laura-deming/">https://blog.withprimer.com/laura-deming/</a></em></p>]]>
            </description>
            <link>https://blog.withprimer.com/laura-deming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23644762</guid>
            <pubDate>Thu, 25 Jun 2020 19:48:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Query-Based Compiler Architectures]]>
            </title>
            <description>
<![CDATA[
Score 104 | Comments 23 (<a href="https://news.ycombinator.com/item?id=23644391">thread link</a>) | @matt_d
<br/>
June 25, 2020 | https://ollef.github.io/blog/posts/query-based-compilers.html | <a href="https://web.archive.org/web/*/https://ollef.github.io/blog/posts/query-based-compilers.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p>Note: This is an old post originally from the documentation of the <a href="https://github.com/ollef/sixten">Sixten</a> programming language, that I've touched up and fleshed out. After the time that it was written I've found out about <a href="https://github.com/salsa-rs/salsa">Salsa</a>, a Rust library with very similar goals to my Rock library, which is definitely worth checking out as well!</p>
<h2 id="background">Background</h2>
<p>Compilers are no longer just black boxes that take a bunch of source files and produce assembly code. We expect them to:</p>
<ul>
<li>Be incremental, meaning that if we recompile a project after having made a few changes we only recompile what is affected by the changes.</li>
<li>Provide editor tooling, e.g. through a <a href="https://langserver.org/">language server</a>, supporting functionality like going to definition, finding the type of the expression at a specific location, and showing error messages on the fly.</li>
</ul>
<p>This is what Anders Hejlsberg talks about in <a href="https://www.youtube.com/watch?v=wSdV1M7n4gQ">his video on modern compiler construction</a> that some of you might have seen.</p>
<p>In this post I will cover how this is achieved in <a href="https://github.com/ollef/sixten">Sixten</a> by building the compiler around a query system.</p>
<p>For those of you that don't know, Sixten is an experimental functional programming language created to give the programmer more control over memory layout and boxing than most other high-level languages do. The most recent development of Sixten is being done in the <a href="https://github.com/ollef/sixty">Sixty</a> repository, and is completely query-based. Here's a little video giving a taste of what its language server can do, showing type-based completions:</p>

<h2 id="traditional-pipeline-based-compiler-architectures">Traditional pipeline-based compiler architectures</h2>
<p>A traditional compiler pipeline might look a bit like this:</p>
<div id="cb1"><pre><code><span id="cb1-1"><a href="#cb1-1"></a>+-----------+            +-----+                +--------+               +--------+</span>
<span id="cb1-2"><a href="#cb1-2"></a>|           |            |     |                |        |               |        |</span>
<span id="cb1-3"><a href="#cb1-3"></a>|source text|---parse---&gt;| AST |---typecheck-+-&gt;|core AST|---generate---&gt;|assembly|</span>
<span id="cb1-4"><a href="#cb1-4"></a>|           |            |     |       ^        |        |               |        |</span>
<span id="cb1-5"><a href="#cb1-5"></a>+-----------+            +-----+       |        +--------+               +---------</span>
<span id="cb1-6"><a href="#cb1-6"></a>                                       |</span>
<span id="cb1-7"><a href="#cb1-7"></a>                                 read and write</span>
<span id="cb1-8"><a href="#cb1-8"></a>                                     types</span>
<span id="cb1-9"><a href="#cb1-9"></a>                                       |</span>
<span id="cb1-10"><a href="#cb1-10"></a>                                       v</span>
<span id="cb1-11"><a href="#cb1-11"></a>                                  +----------+</span>
<span id="cb1-12"><a href="#cb1-12"></a>                                  |          |</span>
<span id="cb1-13"><a href="#cb1-13"></a>                                  |type table|</span>
<span id="cb1-14"><a href="#cb1-14"></a>                                  |          |</span>
<span id="cb1-15"><a href="#cb1-15"></a>                                  +----------+</span></code></pre></div>
<p>There are many variations, and often more steps and intermediate representations than in the illustration, but the idea stays the same:</p>
<p>We push source text down a pipeline and run a fixed set of transformations until we finally output assembly code or some other target language. Along the way we often need to read and update some state. For example, we might update a type table during type checking so we can later look up the type of entities that the code refers to.</p>
<p>Traditional compiler pipelines are probably quite familiar to many of us, but how query-based compilers should be architected might not be as well-known. Here I will describe one way to do it.</p>
<h2 id="going-from-pipeline-to-queries">Going from pipeline to queries</h2>
<p>What does it take to get the type of a qualified name, such as <code>"Data.List.map"</code>? In a pipeline-based architecture we would just look it up in the type table. With queries, we have to think differently. Instead of relying on having updated some piece of state, we do it as if it was done from scratch.</p>
<p>As a first iteration, we do it <em>completely</em> from scratch. It might look a little bit like this:</p>
<div id="cb2"><pre><code><span id="cb2-1"><a href="#cb2-1"></a><span>fetchType ::</span> <span>QualifiedName</span> <span>-&gt;</span> <span>IO</span> <span>Type</span></span>
<span id="cb2-2"><a href="#cb2-2"></a>fetchType (<span>QualifiedName</span> moduleName name) <span>=</span> <span>do</span></span>
<span id="cb2-3"><a href="#cb2-3"></a>  fileName <span>&lt;-</span> moduleFileName moduleName</span>
<span id="cb2-4"><a href="#cb2-4"></a>  sourceCode <span>&lt;-</span> <span>readFile</span> fileName</span>
<span id="cb2-5"><a href="#cb2-5"></a>  parsedModule <span>&lt;-</span> parseModule sourceCode</span>
<span id="cb2-6"><a href="#cb2-6"></a>  resolvedModule <span>&lt;-</span> resolveNames parsedModule</span>
<span id="cb2-7"><a href="#cb2-7"></a>  <span>let</span> definition <span>=</span> <span>lookup</span> name resolvedModule</span>
<span id="cb2-8"><a href="#cb2-8"></a>  inferDefinitionType definition</span></code></pre></div>
<p>We first find out what file the name comes from, which might be <code>Data/List.vix</code> for <code>Data.List</code>, then read the contents of the file, parse it, perhaps we do name resolution to find out what the names in the code refer to given what is imported, and last we look up the name-resolved definition and type check it, returning its type.</p>
<p>All this for just for getting the type of an identifier? It seems ridiculous because looking up the type of a name is something we'll do loads of times during the type checking of a module. Luckily we're not done yet.</p>
<p>Let's first refactor the code into smaller functions:</p>
<div id="cb3"><pre><code><span id="cb3-1"><a href="#cb3-1"></a><span>fetchParsedModule ::</span> <span>ModuleName</span> <span>-&gt;</span> <span>IO</span> <span>ParsedModule</span></span>
<span id="cb3-2"><a href="#cb3-2"></a>fetchParsedModule moduleName <span>=</span> <span>do</span></span>
<span id="cb3-3"><a href="#cb3-3"></a>  fileName <span>&lt;-</span> moduleFileName moduleName</span>
<span id="cb3-4"><a href="#cb3-4"></a>  sourceCode <span>&lt;-</span> <span>readFile</span> fileName</span>
<span id="cb3-5"><a href="#cb3-5"></a>  parseModule moduleName</span>
<span id="cb3-6"><a href="#cb3-6"></a></span>
<span id="cb3-7"><a href="#cb3-7"></a><span>fetchResolvedModule ::</span> <span>ModuleName</span> <span>-&gt;</span> <span>IO</span> <span>ResolvedModule</span></span>
<span id="cb3-8"><a href="#cb3-8"></a>fetchResolvedModule moduleName <span>=</span> <span>do</span></span>
<span id="cb3-9"><a href="#cb3-9"></a>  parsedModule <span>&lt;-</span> fetchParsedModule moduleName</span>
<span id="cb3-10"><a href="#cb3-10"></a>  resolveNames parsedModule</span>
<span id="cb3-11"><a href="#cb3-11"></a></span>
<span id="cb3-12"><a href="#cb3-12"></a><span>fetchType ::</span> <span>QualifiedName</span> <span>-&gt;</span> <span>IO</span> <span>Type</span></span>
<span id="cb3-13"><a href="#cb3-13"></a>fetchType (<span>QualifiedName</span> moduleName name) <span>=</span> <span>do</span></span>
<span id="cb3-14"><a href="#cb3-14"></a>  resolvedModule <span>&lt;-</span> fetchResolvedModule moduleName</span>
<span id="cb3-15"><a href="#cb3-15"></a>  <span>let</span> definition <span>=</span> <span>lookup</span> name resolvedModule</span>
<span id="cb3-16"><a href="#cb3-16"></a>  inferDefinitionType definition</span></code></pre></div>
<p>Note that each of the functions do everything from scratch on their own, i.e. they're each doing a (longer and longer) prefix of the work you'd do in a pipeline. I've found this to be a common pattern in my query-based compilers.</p>
<p>One way to make this efficient would be to add a memoisation layer around each function. That way, we do some expensive work the first time we invoke a function with a specific argument, but subsequent calls are cheap as they can return the cached result.</p>
<p>This is essentially what we'll do, but we won't use a separate cache per function, but instead have a central cache, indexed by the query. This functionality is provided by <a href="https://github.com/ollef/rock">Rock</a>, a library that packages up some functionality for creating query-based compilers.</p>
<h2 id="the-rock-library">The Rock library</h2>
<p><a href="https://github.com/ollef/rock">Rock</a> is an experimental library heavily inspired by <a href="https://github.com/ndmitchell/shake">Shake</a> and the <a href="https://www.microsoft.com/en-us/research/publication/build-systems-la-carte/">Build systems à la carte paper</a>. It essentially implements a build system framework, like <code>make</code>.</p>
<p>Build systems have a lot in common with modern compilers since we want them to be incremental, i.e. to take advantage of previous build results when building anew with few changes. But there's also a difference: Most build systems don't care about the <em>types</em> of their queries since they work at the level of files and file systems.</p>
<p><em>Build systems à la carte</em> is closer to what we want. There the user writes a bunch of computations, <em>tasks</em>, choosing a suitable type for keys and a type for values. The tasks are formulated assuming they're run in an environment where there is a function <code>fetch</code> of type <code>Key -&gt; Task Value</code>, where <code>Task</code> is a type for describing build system rules, that can be used to fetch the value of a dependency with a specific key. In our above example, the key type might look like this:</p>
<div id="cb4"><pre><code><span id="cb4-1"><a href="#cb4-1"></a><span>data</span> <span>Key</span></span>
<span id="cb4-2"><a href="#cb4-2"></a>  <span>=</span> <span>ParsedModuleKey</span> <span>ModuleName</span></span>
<span id="cb4-3"><a href="#cb4-3"></a>  <span>|</span> <span>ResolvedModuleKey</span> <span>ModuleName</span></span>
<span id="cb4-4"><a href="#cb4-4"></a>  <span>|</span> <span>TypeKey</span> <span>QualifiedName</span></span></code></pre></div>
<p>The build system has control over what code runs when we do a <code>fetch</code>, so by varying that it can do fine-grained dependency tracking, memoisation, and incremental updates.</p>
<p><em>Build systems à la carte</em> is also about exploring what kind of build systems we get when we vary what <code>Task</code> is allowed to do, e.g. if it's a <code>Monad</code> or <code>Applicative</code>. In Rock, we're not exploring <em>that</em>, so our <code>Task</code> is a thin layer on top of <code>IO</code>.</p>
<p>A problem that pops up now, however, is that there's no satisfactory type for <code>Value</code>. We want <code>fetch (ParsedModuleKey "Data.List")</code> to return a <code>ParsedModule</code>, while <code>fetch (TypeKey "Data.List.map")</code> should return something of type <code>Type</code>.</p>
<h3 id="indexed-queries">Indexed queries</h3>
<p>Rock allows us to index the key type by the return type of the query. The <code>Key</code> type in our running example becomes the following <a href="https://en.wikipedia.org/wiki/Generalized_algebraic_data_type">GADT</a>:</p>
<div id="cb5"><pre><code><span id="cb5-1"><a href="#cb5-1"></a><span>data</span> <span>Key</span> a <span>where</span></span>
<span id="cb5-2"><a href="#cb5-2"></a>  <span>ParsedModuleKey</span><span> ::</span> <span>ModuleName</span> <span>-&gt;</span> <span>Key</span> <span>ParsedModule</span></span>
<span id="cb5-3"><a href="#cb5-3"></a>  <span>ResolvedModuleKey</span><span> ::</span> <span>ModuleName</span> <span>-&gt;</span> <span>Key</span> <span>ResolvedModule</span></span>
<span id="cb5-4"><a href="#cb5-4"></a>  <span>TypeKey</span><span> ::</span> <span>QualifiedName</span> <span>-&gt;</span> <span>Key</span> <span>Type</span></span></code></pre></div>
<p>The <code>fetch</code> function gets the type <code>forall a. Key a -&gt; Task a</code>, so we get a <code>ParsedModule</code> when we run <code>fetch (ParsedModuleKey "Data.List")</code>, like we wanted, because the return type depends on the key we use.</p>
<p>Now that we know what <code>fetch</code> should look like, it's also worth revealing what the <code>Task</code> type looks like in Rock, more concretely. As mentioned, it's a thin layer around <code>IO</code>, providing a way to <code>fetch</code> <code>key</code>s (like <code>Key</code> above):</p>
<div id="cb6"><pre><code><span id="cb6-1"><a href="#cb6-1"></a><span>newtype</span> <span>Task</span> key a <span>=</span> <span>Task</span> {<span> unTask ::</span> <span>ReaderT</span> (<span>Fetch</span> key) <span>IO</span> a }</span>
<span id="cb6-2"><a href="#cb6-2"></a><span>newtype</span> <span>Fetch</span> key <span>=</span> <span>Fetch</span> (<span>forall</span> a<span>.</span> key a <span>-&gt;</span> <span>IO</span> a)</span></code></pre></div>
<p>The rules of our compiler, i.e. its "Makefile", then becomes the following function, reusing the functions from above:</p>
<div id="cb7"><pre><code><span id="cb7-1"><a href="#cb7-1"></a><span>rules ::</span> <span>Key</span> a <span>-&gt;</span> <span>Task</span> a</span>
<span id="cb7-2"><a href="#cb7-2"></a>rules key <span>=</span> <span>case</span> key <span>of</span></span>
<span id="cb7-3"><a href="#cb7-3"></a>  <span>ParsedModuleKey</span> moduleName <span>-&gt;</span></span>
<span id="cb7-4"><a href="#cb7-4"></a>    fetchParsedModule moduleName</span>
<span id="cb7-5"><a href="#cb7-5"></a></span>
<span id="cb7-6"><a href="#cb7-6"></a>  <span>ResolvedModuleKey</span> moduleName <span>-&gt;</span></span>
<span id="cb7-7"><a href="#cb7-7"></a>    fetchResolvedModule moduleName</span>
<span id="cb7-8"><a href="#cb7-8"></a></span>
<span id="cb7-9"><a href="#cb7-9"></a>  <span>TypeKey</span> qualifiedName <span>-&gt;</span></span>
<span id="cb7-10"><a href="#cb7-10"></a>    fetchType qualifiedName</span></code></pre></div>
<h3 id="caching">Caching</h3>
<p>The most basic way to run a <code>Task</code> in Rock is to directly call the <code>rules</code> function when a <code>Task</code> fetches a key. This results in an inefficient build system that recomputes every query from scratch.</p>
<p>But the <code>Rock</code> library lets us layer more functionality onto our <code>rules</code> function, and one thing that we can add is memoisation. If we do that Rock caches the result of each fetched key by storing the key-value pairs of already performed fetches in a <a href="https://hackage.haskell.org/package/dependent-hashmap">dependent hashmap</a>. This way, we perform each query at most once during a single run of the compiler.</p>
<h3 id="verifying-dependencies-and-reusing-state">Verifying dependencies and reusing state</h3>
<p>Another kind of functionality that can be layered onto the <code>rules</code> function is incremental updates. When it's used, Rock keeps track of what dependencies a task used when it was executed (much like Shake) in a table, i.e. what keys it fetched and what the values were. Using this information it's able to determine when it's safe to reuse the cache <em>from a previous run of the compiler</em> even though there might be changes in other parts of the dependency graph.</p>
<p>This fine-grained dependency tracking also allows reusing the cache when a dependency of a task changes in a way that has no effect. For example, whitespace changes might trigger a re-parse, but since the AST is the same, the cache can be reused in queries that depend on the …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ollef.github.io/blog/posts/query-based-compilers.html">https://ollef.github.io/blog/posts/query-based-compilers.html</a></em></p>]]>
            </description>
            <link>https://ollef.github.io/blog/posts/query-based-compilers.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23644391</guid>
            <pubDate>Thu, 25 Jun 2020 19:17:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ASGI from scratch – Let's build an ASGI web framework]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 11 (<a href="https://news.ycombinator.com/item?id=23644252">thread link</a>) | @lukastyrychtr
<br/>
June 25, 2020 | https://shenli.dev/2020/06/20/asgi-from-scratch.html | <a href="https://web.archive.org/web/*/https://shenli.dev/2020/06/20/asgi-from-scratch.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    
<p>The first time I used <a href="https://asgi.readthedocs.io/">ASGI</a>(<em>Asynchronous Server Gateway Interface</em>) was through <a href="https://github.com/django/channels">Channels</a> 1.0 when ASGI spec was still a draft. It was my first interview project which helped me get my current job at <a href="https://fellow.app/">Fellow</a>. It felt magical at that time how easy it is to add WebSocket functionality to my Django app and handles authentication and other Django related things for me seamlessly.</p>

<p>ASGI specification is now at version 3 at the time of writing and both ASGI and Channels became part of Django Software Foundation. Compared to the draft version, it has matured a lot with added lifecycle calls and better application format, etc. Most excitingly, a healthy and fast-growing community is forming and we are seeing more and more ASGI servers running in production environments. At my company, we are serving a few million requests per day through ASGI running on <a href="https://github.com/django/daphne">Daphne</a>, Netflix’s <a href="https://netflixtechblog.com/introducing-dispatch-da4b8a2a8072">Dispatch</a> is based on <a href="https://fastapi.tiangolo.com/">FastAPI</a>, a popular ASGI web application framework, and apparently, Microsoft is <a href="https://github.com/tiangolo/fastapi/pull/26">using it</a> too.</p>

<p>I would humbly advise anyone building web services in Python to learn about ASGI. And the best way to learn something is to built things with it, so in this blog post, I’ll walk through the steps to build a micro web application framework that speaks ASGI. I hope it can help explain how ASGI works.</p>


<p>Before writing the first line of code, we need to have a basic understanding of what ASGI is and what we are building towards.</p>
<h2 id="how-asgi-works">How ASGI works</h2>
<p>Here’s a simple diagram showing how ASGI works at a high level.</p>
<pre><code>graph TD
	A[Client] --&gt;|HTTP, WebSocket, ...| B(ASGI Server)
	B --&gt; |scope, send, receive| C(ASGI application)
</code></pre>
<p>To put it in simple words, A browser(client), establishes a connection to ASGI server with a certain type of request (HTTP or WebSocket), the ASGI server then calls ASGI  application with information about the connection, encapsulated in a python dictionary called <code>scope</code>, and two callbacks, named <code>send</code> and <code>receive</code>, that the application can use to send and receive messages between server and client.</p>

<p>Here’s an example HTTP request scope</p>
<div><div><pre><code><span>{</span>
    <span>"type"</span><span>:</span> <span>"http"</span><span>,</span>
    <span>"http_version"</span><span>:</span> <span>"1.1"</span><span>,</span>
    <span>"server"</span><span>:</span> <span>(</span><span>"127.0.0.1"</span><span>,</span> <span>8000</span><span>),</span>
    <span>"client"</span><span>:</span> <span>(</span><span>"127.0.0.1"</span><span>,</span> <span>60457</span><span>),</span>
    <span>"scheme"</span><span>:</span> <span>"http"</span><span>,</span>
    <span>"method"</span><span>:</span> <span>"GET"</span><span>,</span>
    <span>"root_path"</span><span>:</span> <span>""</span><span>,</span>
    <span>"path"</span><span>:</span> <span>"/hello/a"</span><span>,</span>
    <span>"raw_path"</span><span>:</span> <span>b"/hello/a"</span><span>,</span>
    <span>"query_string"</span><span>:</span> <span>b""</span><span>,</span>
    <span>"headers"</span><span>:</span> <span>[</span>
        <span>(</span><span>b"host"</span><span>,</span> <span>b"localhost:8000"</span><span>),</span>
        <span>(</span><span>b"connection"</span><span>,</span> <span>b"keep-alive"</span><span>),</span>
        <span>(</span>
            <span>b"user-agent"</span><span>,</span>
            <span>b"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.106 Safari/537.36"</span><span>,</span>
        <span>),</span>
        <span>(</span>
            <span>b"accept"</span><span>,</span>
            <span>b"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9"</span><span>,</span>
        <span>),</span>
        <span>(</span><span>b"accept-encoding"</span><span>,</span> <span>b"gzip, deflate, br"</span><span>),</span>
        <span>(</span><span>b"accept-language"</span><span>,</span> <span>b"en-US,en;q=0.9"</span><span>),</span>
        <span>(</span>
            <span>b"cookie"</span><span>,</span>
            <span>b'csrftoken=dDA2IAPrvgPc7hkyBSyctxDk78KmhHAzUqR0LUpjXI3Xgki0QrGEWazE3RGZuLGl'</span><span>,</span>
        <span>),</span>
    <span>],</span>
<span>}</span>
</code></pre></div></div>

<p>You might notice that <code>scope</code> is not too different from a WSGI <code>environ</code>. In fact, ASGI interface is very similar to WSGI interface, but instead of getting a <code>environ</code> and <code>start_response</code> to send headers and using the return value of WSGI application as the response body, ASGI interfaces with the connection and allows us to receive and send messages multiple times during the lifecycle of the connection <strong>asynchronously</strong> until the connection is closed.  This allows a nice interface for both WebSocket and HTTP.</p>

<p>It’s also totally possible to wrap a WSGI application inside an ASGI application, just prepare a WSGI <code>environ</code> and <code>start_response</code> based on <code>scope</code>, <code>receive</code>, and <code>send</code> then call the WSGI application and it would work. If you delegate that call into a thread pool or something similar, you just made your WSGI application asynchronous. This is roughly how Channels wraps around Django.</p>

<h2 id="define-asgi-framework">Define ASGI framework</h2>
<p>When I say ASGI framework I refer it as a framework that makes building ASGI application easier and this does not include the ASGI server part. I’m mentioning this because some of the earlier Python asynchronous web frameworks have their own server implementation that also takes over tasks such as parsing  HTTP requests, handles network connections, etc. We are not doing those in ASGI web framework. As a spiritual successor to WSGI, where web servers, such as Gunicorn and uwsgi, and web frameworks, such as Flask and Django, are separated, ASGI has this separation too.</p>

<p>So, what does an ASGI application look like?</p>

<h3 id="asgi-hello-world">ASGI Hello World</h3>
<p>A simple ASGI hello world application can be written as:</p>
<div><div><pre><code><span>async</span> <span>def</span> <span>application</span><span>(</span><span>scope</span><span>,</span> <span>receive</span><span>,</span> <span>send</span><span>):</span>
    <span>name</span> <span>=</span> <span>scope</span><span>[</span><span>"path"</span><span>].</span><span>split</span><span>(</span><span>"/"</span><span>,</span> <span>1</span><span>)[</span><span>-</span><span>1</span><span>]</span> <span>or</span> <span>"world"</span>
    <span>await</span> <span>send</span><span>(</span>
        <span>{</span>
            <span>"type"</span><span>:</span> <span>"http.response.start"</span><span>,</span>
            <span>"status"</span><span>:</span> <span>200</span><span>,</span>
            <span>"headers"</span><span>:</span> <span>[[</span><span>b"content-type"</span><span>,</span> <span>b"text/plain"</span><span>],],</span>
        <span>}</span>
    <span>)</span>
    <span>await</span> <span>send</span><span>(</span>
        <span>{</span>
            <span>"type"</span><span>:</span> <span>"http.response.body"</span><span>,</span>
            <span>"body"</span><span>:</span> <span>f"Hello, </span><span>{</span><span>name</span><span>}</span><span>!"</span><span>.</span><span>encode</span><span>(),</span>
            <span>"more_body"</span><span>:</span> <span>False</span><span>,</span>
        <span>}</span>
    <span>)</span>
</code></pre></div></div>
<p><code>http.response.start</code> starts an HTTP response sending status code and response headers. In this example, it responds with the 200 OK status code and  has <code>content-type</code> set to <code>text/plain</code> in the headers.  <code>http.response.body</code> sends the response body, the <code>more_body</code> key tells the server if the response is finished. ASGI server might use this to know if a connection should be closed or automatically decide between a <code>content-length</code> header or a chunked encoding.</p>

<p>We can run the application with <a href="https://www.uvicorn.org/">uvicorn</a>:</p>
<div><div><pre><code>uvicorn asgi-hello:application
</code></pre></div></div>
<p>And you should be able to visit <code>http://localhost:8000/</code> and get <code>Hello, world</code>.Visiting <code>http://localhost:8000/tom</code> would get you <code>Hello, tom</code>.</p>

<blockquote>
  <p>By the way, uvicorn is pretty fast, a simple benchmark with <code>wrk -d10s http://localhost:8000/hi</code> on a 2018 lowest spec MacBook Air yields <code>Requests/sec:  27857.87</code>.</p>
</blockquote>

<p>Although this approach works with a simple hello world example, it’s not exactly convenient to write a more complex application this way. For one, it doesn’t do routing, if you want to respond differently for different paths, you’ll probably end up with a huge  <code>if ... else if ... else</code> clause. Secondly, having to write the ASGI message every time in the form of a python dict is quite arduous. Third, in a complex application, it gets harder to track the status of the connection, such as is the response started, is the response ended, should I start the response here, etc.</p>

<h3 id="goal">Goal</h3>
<p>With the new framework, I hope to be able to write an ASGI application like this:</p>
<div><div><pre><code><span>import</span> <span>asyncio</span>
<span>from</span> <span>aaf</span> <span>import</span> <span>aaf</span> <span># Another ASGI framework
</span><span>from</span> <span>aaf.routing</span> <span>import</span> <span>Router</span>
<span>from</span> <span>aaf.response</span> <span>import</span> <span>HttpResponse</span>

<span>router</span> <span>=</span> <span>Router</span><span>()</span>

<span>@</span><span>router</span><span>.</span><span>route</span><span>(</span><span>'/'</span><span>)</span>
<span>@</span><span>router</span><span>.</span><span>route</span><span>(</span><span>'/&lt;name&gt;'</span><span>)</span>
<span>async</span> <span>def</span> <span>hello</span><span>(</span><span>connection</span><span>,</span> <span>name</span><span>=</span><span>'world'</span><span>):</span>
	<span>return</span> <span>HttpResponse</span><span>(</span><span>f"Hello, </span><span>{</span><span>name</span><span>}</span><span>"</span><span>)</span>


<span>@</span><span>router</span><span>.</span><span>route</span><span>(</span><span>'/count'</span><span>)</span>
<span>@</span><span>router</span><span>.</span><span>route</span><span>(</span><span>'/count/&lt;int:number&gt;'</span><span>)</span>
<span>async</span> <span>def</span> <span>count</span><span>(</span><span>connection</span><span>,</span> <span>number</span><span>=</span><span>10</span><span>):</span>
	<span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>number</span><span>):</span>
		<span>await</span> <span>connection</span><span>.</span><span>send</span><span>(</span><span>f'count </span><span>{</span><span>i</span><span>}</span><span>\n</span><span>'</span><span>,</span> <span>finish</span><span>=</span><span>False</span><span>)</span>
		<span>await</span> <span>asyncio</span><span>.</span><span>sleep</span><span>(</span><span>1</span><span>)</span>
	<span>await</span> <span>connection</span><span>.</span><span>send</span><span>(</span><span>''</span><span>,</span> <span>finish</span><span>=</span><span>True</span><span>)</span>


<span>@</span><span>router</span><span>.</span><span>route</span><span>(</span><span>'/echo'</span><span>)</span>
<span>async</span> <span>def</span> <span>echo</span><span>(</span><span>connection</span><span>):</span>
	<span>body</span> <span>=</span> <span>await</span> <span>connection</span><span>.</span><span>body</span><span>()</span>
	<span>await</span> <span>connection</span><span>.</span><span>send</span><span>(</span><span>body</span><span>,</span> <span>finish</span><span>=</span><span>True</span><span>)</span>


<span>app</span> <span>=</span> <span>aaf</span><span>([</span><span>router</span><span>])</span>
</code></pre></div></div>
<p>I hope this snippet of how I want the framework to look like is self-explanatory. But here are some of the key things I want to achieve:</p>
<ol>
  <li>It should be able to handle HTTP response declaratively and imperatively.</li>
  <li>It should support Flask style routing with parameter parsing.</li>
</ol>


<h2 id="connection-class">Connection class</h2>
<p>The <code>Connection</code> class will represent an ASGI HTTP or WebSocket connection. It’s a class that encapsulates the three basic elements in ASGI, namely <code>scope</code>, <code>send</code> and <code>receive</code>, and expose some convenient methods and properties so that users don’t need to verbosely write out all the ASGI messages and parse everything, such as cookies and headers, from <code>scope</code>. But it should allow users to access the original <code>scope</code>, <code>send</code> and <code>receive</code> when they want to, so that the composability of ASGI applications is maintained. For example, it should allow user to delegate certain <code>connection</code>s to another ASGI application by calling <code>another_asgi_app(connection.scope, connectionn.asgi_send, connection.asgi_receive)</code>.</p>

<p>Here’s a simple implementation of the <code>Connection</code> class.</p>
<div><div><pre><code><span>from</span> <span>enum</span> <span>import</span> <span>Enum</span>
<span>from</span> <span>functools</span> <span>import</span> <span>cached_property</span>
<span>from</span> <span>http.cookies</span> <span>import</span> <span>SimpleCookie</span>
<span>from</span> <span>typing</span> <span>import</span> <span>Any</span><span>,</span> <span>Awaitable</span><span>,</span> <span>Callable</span><span>,</span> <span>Optional</span><span>,</span> <span>Union</span>
<span>from</span> <span>urllib.parse</span> <span>import</span> <span>parse_qsl</span><span>,</span> <span>unquote_plus</span>

<span>from</span> <span>werkzeug.datastructures</span> <span>import</span> <span>Headers</span><span>,</span> <span>MultiDict</span>

<span>CoroutineFunction</span> <span>=</span> <span>Callable</span><span>[[</span><span>Any</span><span>],</span> <span>Awaitable</span><span>]</span>


<span>class</span> <span>ConnectionType</span><span>(</span><span>Enum</span><span>):</span>
    <span>HTTP</span> <span>=</span> <span>"HTTP"</span>
    <span>WebSocket</span> <span>=</span> <span>"WebSocket"</span>


<span>class</span> <span>Connection</span><span>:</span>
    <span>def</span> <span>__init__</span><span>(</span>
        <span>self</span><span>,</span> <span>scope</span><span>:</span> <span>dict</span><span>,</span> <span>*</span><span>,</span> <span>send</span><span>:</span> <span>CoroutineFunction</span><span>,</span> <span>receive</span><span>:</span> <span>CoroutineFunction</span>
    <span>):</span>
        <span>self</span><span>.</span><span>scope</span> <span>=</span> <span>scope</span>
        <span>self</span><span>.</span><span>asgi_send</span> <span>=</span> <span>send</span>
        <span>self</span><span>.</span><span>asgi_receive</span> <span>=</span> <span>receive</span>

        <span>self</span><span>.</span><span>started</span> <span>=</span> <span>False</span>
        <span>self</span><span>.</span><span>finished</span> <span>=</span> <span>False</span>
        <span>self</span><span>.</span><span>resp_headers</span> <span>=</span> <span>Headers</span><span>()</span>
        <span>self</span><span>.</span><span>resp_cookies</span><span>:</span> <span>SimpleCookie</span> <span>=</span> <span>SimpleCookie</span><span>()</span>
        <span>self</span><span>.</span><span>resp_status_code</span><span>:</span> <span>Optional</span><span>[</span><span>int</span><span>]</span> <span>=</span> <span>None</span>

        <span>self</span><span>.</span><span>http_body</span> <span>=</span> <span>b""</span>
        <span>self</span><span>.</span><span>http_has_more_body</span> <span>=</span> <span>True</span>
        <span>self</span><span>.</span><span>http_received_body_length</span> <span>=</span> <span>0</span>

    <span>@</span><span>cached_property</span>
    <span>def</span> <span>req_headers</span><span>(</span><span>self</span><span>)</span> <span>-&gt;</span> <span>Headers</span><span>:</span>
        <span>headers</span> <span>=</span> <span>Headers</span><span>()</span>
        <span>for</span> <span>(</span><span>k</span><span>,</span> <span>v</span><span>)</span> <span>in</span> <span>self</span><span>.</span><span>scope</span><span>[</span><span>"headers"</span><span>]:</span>
            <span>headers</span><span>.</span><span>add</span><span>(</span><span>k</span><span>.</span><span>decode</span><span>(</span><span>"ascii"</span><span>),</span> <span>v</span><span>.</span><span>decode</span><span>(</span><span>"ascii"</span><span>))</span>
        <span>return</span> <span>headers</span>

    <span>@</span><span>cached_property</span>
    <span>def</span> <span>req_cookies</span><span>(</span><span>self</span><span>)</span> <span>-&gt;</span> <span>SimpleCookie</span><span>:</span>
        <span>cookie</span> <span>=</span> <span>SimpleCookie</span><span>()</span>
        <span>cookie</span><span>.</span><span>load</span><span>(</span><span>self</span><span>.</span><span>req_headers</span><span>.</span><span>get</span><span>(</span><span>"cookie"</span><span>,</span> <span>{}))</span>
        <span>return</span> <span>cookie</span>

    <span>@</span><span>cached_property</span>
    <span>def</span> <span>type</span><span>(</span><span>self</span><span>)</span> <span>-&gt;</span> <span>ConnectionType</span><span>:</span>
        <span>return</span> <span>(</span>
            <span>ConnectionType</span><span>.</span><span>WebSocket</span>
            <span>if</span> <span>self</span><span>.</span><span>scope</span><span>.</span><span>get</span><span>(</span><span>"type"</span><span>)</span> <span>==</span> <span>"websocket"</span>
            <span>else</span> <span>ConnectionType</span><span>.</span><span>HTTP</span>
        <span>)</span>

    <span>@</span><span>cached_property</span>
    <span>def</span> <span>method</span><span>(</span><span>self</span><span>)</span> <span>-&gt;</span> <span>str</span><span>:</span>
        <span>return</span> <span>self</span><span>.</span><span>scope</span><span>[</span><span>"method"</span><span>]</span>

    <span>@</span><span>cached_property</span>
    <span>def</span> <span>path</span><span>(</span><span>self</span><span>)</span> <span>-&gt;</span> <span>str</span><span>:</span>
        <span>return</span> <span>self</span><span>.</span><span>sc…</span></code></pre></div></div></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shenli.dev/2020/06/20/asgi-from-scratch.html">https://shenli.dev/2020/06/20/asgi-from-scratch.html</a></em></p>]]>
            </description>
            <link>https://shenli.dev/2020/06/20/asgi-from-scratch.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23644252</guid>
            <pubDate>Thu, 25 Jun 2020 19:04:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ARM Mac: Why I'm Worried About Virtualization]]>
            </title>
            <description>
<![CDATA[
Score 147 | Comments 283 (<a href="https://news.ycombinator.com/item?id=23642178">thread link</a>) | @bmalehorn
<br/>
June 25, 2020 | https://bmalehorn.com/arm-mac/ | <a href="https://web.archive.org/web/*/https://bmalehorn.com/arm-mac/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>It's late 2020 and you just got a brand-new Mac with Apple's own ARM processors. Exciting! But what will development be like?</p><h2>Docker</h2><p><img src="data:image/png;base64,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" width="150"></p><p>I would <strong>expect about a 5x slowdown running Docker images.</strong></p><p>Docker on a Mac utilizes a <strong>hypervisor</strong>. Hypervisors rely on running the <strong>same architecture on the host as the guest</strong>, and are about about 1x - 2x as slow as running natively.</p><p>Since you're running ARM Mac, these hypervisors can only run ARM Linux. They can't run x86_64 Linux.</p><p>What will happen instead? These tools will fall back on <strong>emulators</strong>. Emulators can run <strong>a different architecture between the host and the guest</strong>, but simulate the guest operating system at about 5x-10x slowdown.</p><div><p><img src="https://bmalehorn.com/static/perf-267ab9cfc29b6f68078fbe19892bce23.png"></p><p>A basic performance test comparing gzip performance on amd64 (hypervisor) and arm64v8 (emulator). Note that the emulator is over 6x slower. On an ARM Mac, the amd64 image will instead be 6x slower.</p></div><p>Why can't you update the Docker image to also support ARM? You theoretically could switch your backend to run ARM Linux. However, this would take months - renting out ARM instances, re-building all repositories, and a tense switch over. What if your hosting provider doesn't offer ARM instances with the same system requirements as x86_64? What if you complete this migration and find it runs at half the speed?</p><p>Worse, it might be impossible if your images include files downloaded off the internet, as those are often only compiled for x86_64.</p><div><p><img src="https://bmalehorn.com/static/phantomjs-615e9c8bc9d2deb5ca62a4533c1299d6.png"></p><p>An example of a Docker command that will only work on x86_64. PhantomJS does not release an arm build.</p></div><p>While moving your backend to ARM is far from impossible, it's a serious migration that you shouldn't take lightly. Getting a new laptop isn't enough justification to switch your backend architecture.</p><p>Another option is to <strong>run Docker remotely</strong>. You set up an x86_64 Linux server, then allow Docker to connect to it remotely. From then on, all Docker commands instead run on the server. This is also supported in Docker, <a href="https://www.digitalocean.com/community/tutorials/how-to-use-a-remote-docker-server-to-speed-up-your-workflow">here</a> is a tutorial on setting it up. This is what heavy Docker users will want to do.</p><h2>VirtualBox</h2><p><img src="https://bmalehorn.com/static/virtualbox-c37e4cc82b13d3c1c080f7ced273ae45.png" width="150"></p><p><strong>VirtualBox won't work.</strong></p><p>VirtualBox is a <strong>hypervisor</strong>. Therefore, <strong>it won't be able to run x86 Windows or x86 Linux</strong>.</p><p>You could use VirtualBox to run ARM Windows. Windows already supports ARM, and has a similar binary translation system to Apple's, so it can run x86 binaries. However, VirtualBox only supports x86 hosts and guests and is <a href="https://forums.virtualbox.org/viewtopic.php?f=8&amp;t=98742">unlikely to be ported by ARM</a>.</p><p>VMWare Fusion similarly is a hypervisor that only support x86, but <a href="https://twitter.com/VMwareFusion/status/1275483803536908288?s=20">they're thinking about supporting ARM</a>.</p><p>Instead of VirtualBox you might use QEMU, an emulator. However, QEMU is pretty low level and not often used to emulate Windows.</p><h2>Boot Camp</h2><p><img src="https://bmalehorn.com/static/boot-camp-f05493e57b0fe815dbc1d989ada98dd0.png" width="150"></p><p><strong>Boot Camp won't work.</strong></p><p><a href="https://support.apple.com/boot-camp">Boot Camp</a> is an Apple-approved way to dual-boot Mac OS and Windows. <a href="https://www.theverge.com/2020/6/24/21302213/apple-silicon-mac-arm-windows-support-boot-camp?utm_campaign=theverge&amp;utm_content=chorus&amp;utm_medium=social&amp;utm_source=twitter">Boot Camp will definitely not be available on ARM Macs</a>. It might be added later with the ability to run ARM Windows, though Microsoft <a href="https://www.theverge.com/2020/6/24/21302213/apple-silicon-mac-arm-windows-support-boot-camp">would have to approve</a>.</p><h2>Should I get an ARM Mac?</h2><p>The point of this post isn't to say that ARM Mac is a bad idea, but to give a realistic idea of what developing on one would look like assuming nothing changes. It's possible Apple could release more virtualization tools before the ARM Mac launches.</p><p>Should you get an ARM Mac if you're a developer? If you work largely on frontend, mobile, or native apps, you'll probably be fine. But if you use virtualization often, I wouldn't recommend it. There will be a lot of problems early on, and not all of them will have solutions. My biggest concern is getting an ARM Mac and realizing I simply can't run an essential application on it.</p><p>However if you like troubleshooting these issues and are excited about ARM Mac, go for it! My plan is for those kinds of people to fix these issues.</p><p>Know something I don't? Have questions? Email me at <a href="mailto:bmalehorn@gmail.com">bmalehorn@gmail.com</a>.</p></div></div>]]>
            </description>
            <link>https://bmalehorn.com/arm-mac/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23642178</guid>
            <pubDate>Thu, 25 Jun 2020 16:01:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[BLEU Score: Bilingual Evaluation Understudy]]>
            </title>
            <description>
<![CDATA[
Score 56 | Comments 12 (<a href="https://news.ycombinator.com/item?id=23641791">thread link</a>) | @keyboardman
<br/>
June 25, 2020 | https://leimao.github.io/blog/BLEU-Score/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/BLEU-Score/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>BLEU is a standard algorithm for evaluating the machine translations against the human translations. At first I thought it should be very straightforward to use. However, it turns out that there are a lot of caveats.</p>



<p>In this blog post, I am going to show the BLEU algorithm in detail and talk about the caveats.</p>

<h3 id="english-translation-example">English Translation Example</h3>

<p>We will use the following examples to illustrate how to compute the BLEU scores.</p>

<h4 id="example-1">Example 1</h4>

<p>Chinese: 猫坐在垫子上</p>

<p>Reference 1: the cat is on the mat</p>

<p>Reference 2: there is a cat on the mat</p>

<p>Candidate: the cat the cat on the mat</p>

<h4 id="example-2">Example 2</h4>

<p>Chinese: 猫坐在垫子上</p>

<p>Reference 1: the cat is on the mat</p>

<p>Reference 2: there is a cat on the mat</p>

<p>Candidate: the the the the the the the the</p>

<h3 id="precision">Precision</h3>

<p>We count each of the ngram in the candidate sentence whether it has shown in any of the reference sentences, gather the total counts for each of the unique ngram, sum up the total counts for each of the unique ngram, and divided by the number of ngrams in the candidate sentence.</p>

<h4 id="example-1-1">Example 1</h4>

<p>We first compute the unigram precision for example 1. All the unigrams in the candidate sentences have shown in the reference sentences.</p>



<table>
  <tbody><tr>
    <th>Unigram</th>
    <th>Shown?</th>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>cat</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>cat</td>
    <td>1</td>
  </tr>
  <tr>
    <td>on</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>mat</td>
    <td>1</td>
  </tr>
</tbody></table>

<p>We then merge the unigram counts.</p>



<table>
  <tbody><tr>
    <th>Unique Unigram</th>
    <th>Count</th>
  </tr>
  <tr>
    <td>the</td>
    <td>3</td>
  </tr>
  <tr>
    <td>cat</td>
    <td>2</td>
  </tr>
  <tr>
    <td>on</td>
    <td>1</td>
  </tr>
  <tr>
    <td>mat</td>
    <td>1</td>
  </tr>
</tbody></table>

<p>The total number of counts for the unique unigrams in the candidate sentence is 7, and the total number of unigrams in the candidate sentence is 7. The unigram precision is 7/7 = 1.0 for example 1.</p>



<p>We then try to compute the bigram precision for example 1.</p>



<table>
  <tbody><tr>
    <th>Bigram</th>
    <th>Shown?</th>
  </tr>
  <tr>
    <td>the cat</td>
    <td>1</td>
  </tr>
  <tr>
    <td>cat the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>the cat</td>
    <td>1</td>
  </tr>
  <tr>
    <td>cat on</td>
    <td>1</td>
  </tr>
  <tr>
    <td>on the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the mat</td>
    <td>1</td>
  </tr>
</tbody></table>

<p>We then merge the bigram counts.</p>



<table>
  <tbody><tr>
    <th>Unique Bigram</th>
    <th>Count</th>
  </tr>
  <tr>
    <td>the cat</td>
    <td>2</td>
  </tr>
  <tr>
    <td>cat the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>cat on</td>
    <td>1</td>
  </tr>
  <tr>
    <td>on the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the mat</td>
    <td>1</td>
  </tr>
</tbody></table>

<p>The total number of counts for the unique bigrams in the candidate sentence is 5, and the total number of bigrams in the candidate sentence is 6. The bigram precision is 5/6 = 0.833 for example 1.</p>

<h4 id="example-2-1">Example 2</h4>

<p>We first compute the unigram precision for example 2. All the unigrams in the candidate sentences have shown in the reference sentences.</p>



<table>
  <tbody><tr>
    <th>Unigram</th>
    <th>Shown?</th>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
</tbody></table>

<p>We then merge the unigram counts.</p>



<table>
  <tbody><tr>
    <th>Unique Unigram</th>
    <th>Count</th>
  </tr>
  <tr>
    <td>the</td>
    <td>8</td>
  </tr>
</tbody></table>

<p>The total number of counts for the unique unigrams in the candidate sentence is 8, and the total number of unigrams in the candidate sentence is 8. The unigram precision is 8/8 = 1.0 for example 2.</p>



<p>We then try to compute the bigram precision for example 2.</p>



<table>
  <tbody><tr>
    <th>Bigram</th>
    <th>Shown?</th>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
</tbody></table>

<p>We then merge the bigram counts.</p>



<table>
  <tbody><tr>
    <th>Unique Bigram</th>
    <th>Count</th>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
</tbody></table>

<p>The total number of counts for the unique bigrams in the candidate sentence is 0, and the total number of bigrams in the candidate sentence is 7. The bigram precision is 0/7 = 0 for example 2.</p>

<h4 id="drawbacks">Drawbacks</h4>

<p>We can see from example 1 and 2 that unigram precision is very easy to be over-confident about the quality of the machine translation. To overcome this, clipped count and modified precision were proposed.</p>

<h3 id="modified-precision">Modified Precision</h3>

<p>For each unique ngram, we count its maximum frequency in each of the reference sentences. The minimum of this special count and the original count is called the clipped the count. That is to say, the clipped count is no greater than the original count. We then use this clipped count, in place of the original count, for computing the modified precision.</p>

<h4 id="example-1-2">Example 1</h4>



<table>
  <tbody><tr>
    <th>Unique Unigram</th>
    <th>Count</th>
    <th>Clipped Count</th>
  </tr>
  <tr>
    <td>the</td>
    <td>3</td>
    <td>2</td>
  </tr>
  <tr>
    <td>cat</td>
    <td>2</td>
    <td>1</td>
  </tr>
  <tr>
    <td>on</td>
    <td>1</td>
    <td>1</td>
  </tr>
  <tr>
    <td>mat</td>
    <td>1</td>
    <td>1</td>
  </tr>
</tbody></table>

<p>The total number of clipped counts for the unique unigrams in the candidate sentence is 5, and the total number of unigrams in the candidate sentence is 7. The unigram modified precision is 5/7 = 0.714 for example 1.</p>



<table>
  <tbody><tr>
    <th>Unique Bigram</th>
    <th>Count</th>
    <th>Clipped Count</th>
  </tr>
  <tr>
    <td>the cat</td>
    <td>2</td>
    <td>1</td>
  </tr>
  <tr>
    <td>cat the</td>
    <td>0</td>
    <td>0</td>
  </tr>
  <tr>
    <td>cat on</td>
    <td>1</td>
    <td>1</td>
  </tr>
  <tr>
    <td>on the</td>
    <td>1</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the mat</td>
    <td>1</td>
    <td>1</td>
  </tr>
</tbody></table>

<p>The total number of clipped counts for the unique bigrams in the candidate sentence is 4, and the total number of unigrams in the candidate sentence is 6. The bigram modified precision is 4/6 = 0.667 for example 1.</p>

<h4 id="example-2-2">Example 2</h4>



<table>
  <tbody><tr>
    <th>Unique Unigram</th>
    <th>Count</th>
    <th>Clipped Count</th>
  </tr>
  <tr>
    <td>the</td>
    <td>8</td>
    <td>2</td>
  </tr>
</tbody></table>

<p>The total number of clipped counts for the unique bigrams in the candidate sentence is 0, and the total number of unigrams in the candidate sentence is 8. The unigram modified precision is 2/8 = 0.25 for example 2.</p>



<table>
  <tbody><tr>
    <th>Unique Bigram</th>
    <th>Count</th>
    <th>Clipped Count</th>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
    <td>0</td>
  </tr>
</tbody></table>

<p>The total number of clipped counts for the unique bigrams in the candidate sentence is 0, and the total number of bigrams in the candidate sentence is 7. The bigram precision is 0/7 = 0 for example 2.</p>

<h4 id="advantages">Advantages</h4>

<p>Compared to precision, we found that modified precision is a better metric, at least for unigrams.</p>

<h3 id="bleu">BLEU</h3>

<h4 id="algorithm">Algorithm</h4>

<p>BLEU is computed using a couple of ngram modified precisions. Specifically,</p>



<p>where $p_n$ is the modified precision for $n$gram, the base of $\log$ is the natural base $e$, $w_n$ is weight between 0 and 1 for $\log p_n$ and $\sum_{n=1}^{N} w_n = 1$, and BP is the brevity penalty to penalize short machine translations.</p>



<p>where $c$ is the number of unigrams (length) in all the candidate sentences, and $r$ is the best match lengths for each candidate sentence in the corpus. Here the best match length is the closest reference sentence length to the candidate sentences. For example, if there are three references with lengths 12, 14, and 17 words and the candidate translation is a terse 13 words, ideally the best match length could be either 12 or 14, but we arbitrary choose the shorter one which is 12.</p>



<p>Usually, the BLEU is evaluated on corpus where there are many candidate sentences translated from different source texts and each of them has several reference sentences. Then $c$ is the total number of unigrams (length) in all the candidate sentences, and $r$ is the sum of the best match lengths for each candidate sentence in the corpus.</p>



<p>It is not hard to find that BLEU is always a value between 0 and 1. It is because BP, $w_n$, and $p_n$ are always between 0 and 1, and</p>



<p>Usually, BLEU uses $N = 4$ and $w_n = \frac{1}{N}$.</p>

<h4 id="example-1-3">Example 1</h4>

<p>We have computed the modified precision for some of the ngrams. It is not hard to compute the others. Concretely, we have</p>





<p>Because the corpus only has one translation set and thus $c = 7$ and $r = 7$</p>



<p>We plugin these values to the BLEU equation, the BLEU is</p>



<p>We further compare the BLEU to the BLEU computed using <a href="https://www.nltk.org/">NLTK</a>.</p>

<div><div><pre><code><span>&gt;&gt;&gt;</span> <span>import</span> <span>nltk</span>
<span>&gt;&gt;&gt;</span> <span>reference_1</span> <span>=</span> <span>"the cat is on the mat"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>reference_2</span> <span>=</span> <span>"there is a cat on the mat"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>candidate</span> <span>=</span> <span>"the cat the cat on the mat"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>bleu</span> <span>=</span> <span>nltk</span><span>.</span><span>translate</span><span>.</span><span>bleu_score</span><span>.</span><span>sentence_bleu</span><span>(</span><span>references</span><span>=</span><span>[</span><span>reference_1</span><span>,</span> <span>reference_2</span><span>],</span> <span>hypothesis</span><span>=</span><span>candidate</span><span>,</span> <span>weights</span><span>=</span><span>(</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>))</span>
<span>&gt;&gt;&gt;</span> <span>print</span><span>(</span><span>bleu</span><span>)</span>
<span>0.4671379777282001</span>
</code></pre></div></div>

<p>The value of <code>bleu</code> is 0.467 which is exactly matching to the BLEU we computed manually.</p>

<h4 id="example-2-3">Example 2</h4>

<p>Similarly,</p>





<p>Because the corpus only has one translation set and thus $c = 8$ and $r = 7$</p>



<p>When we plugin these values to the BLEU equation, actually we would need to compute $\log 0$ which is not mathematically defined. We use a small number $10^{-100}$ instead of $0$ for $p_2$, $p_3$ and $p_4$. The BLEU is</p>



<p>We further also compare the BLEU to the BLEU computed using <a href="https://www.nltk.org/">NLTK</a>.</p>

<div><div><pre><code><span>&gt;&gt;&gt;</span> <span>import</span> <span>nltk</span>
<span>&gt;&gt;&gt;</span> <span>reference_1</span> <span>=</span> <span>"the cat is on the mat"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>reference_2</span> <span>=</span> <span>"there is a cat on the mat"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>candidate</span> <span>=</span> <span>"the the the the the the the the"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>bleu</span> <span>=</span> <span>nltk</span><span>.</span><span>translate</span><span>.</span><span>bleu_score</span><span>.</span><span>sentence_bleu</span><span>(</span><span>references</span><span>=</span><span>[</span><span>reference_1</span><span>,</span> <span>reference_2</span><span>],</span> <span>hypothesis</span><span>=</span><span>candidate</span><span>,</span> <span>weights</span><span>=</span><span>(</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>))</span>
<span>&gt;&gt;&gt;</span> <span>print</span><span>(</span><span>bleu</span><span>)</span>
<span>1.2882297539194154e-231</span>
</code></pre></div></div>

<p>The value of <code>bleu</code> is 0 which is exactly matching to the BLEU we computed manually.</p>

<p>Note that in the above two examples, due to the candidate sentence is long and we only have one translation in the corpus, thus $\text{BP} = 1$. In practice, there could be scenarios where $\text{BP} &lt; 1$.</p>

<h3 id="caveats">Caveats</h3>

<p>In some scenarios, BLEU does not score the translation very well, especially for those short translations with few reference sentences. For example,</p>



<p>Chinese: 你准备好了吗？</p>

<p>Reference 1: are you ready ?</p>

<p>Candidate: you are ready ?</p>

<div><div><pre><code><span>&gt;&gt;&gt;</span> <span>import</span> <span>nltk</span>
<span>&gt;&gt;&gt;</span> <span>reference_1</span> <span>=</span> <span>"are you ready ?"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>candidate</span> <span>=</span> <span>"you are ready ?"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>bleu</span> <span>=</span> <span>nltk</span><span>.</span><span>translate</span><span>.</span><span>bleu_score</span><span>.</span><span>sentence_bleu</span><span>(</span><span>references</span><span>=</span><span>[</span><span>reference_1</span><span>],</span> <span>hypothesis</span><span>=</span><span>candidate</span><span>,</span> <span>weights</span><span>=</span><span>[</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>])</span>
<span>&gt;&gt;&gt;</span> <span>print</span><span>(</span><span>bleu</span><span>)</span>
<span>1.133422688662942e-154</span>
</code></pre></div></div>

<p>This is actually a very good machine translation to me. However, the BLEU score is 0, which means that the machine translation is totally wrong.</p>



<p>In NLTK, you are allowed to provide <a href="https://www.nltk.org/api/nltk.translate.html#nltk.translate.bleu_score.SmoothingFunction">smoothing functions</a>. For example,</p>

<div><div><pre><code><span>&gt;&gt;&gt;</span> <span>import</span> <span>nltk</span>
<span>&gt;&gt;&gt;</span> <span>reference_1</span> <span>=</span> <span>"are you ready ?"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>candidate</span> <span>=</span> <span>"you are ready ?"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>bleu</span> <span>=</span> <span>nltk</span><span>.</span><span>translate</span><span>.</span><span>bleu_score</span><span>.</span><span>sentence_bleu</span><span>(</span><span>references</span><span>=</span><span>[</span><span>reference_1</span><span>],</span> <span>hypothesis</span><span>=</span><span>candidate</span><span>,</span> <span>weights</span><span>=</span><span>[</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>],</span> <span>smoothing_function</span><span>=</span><span>nltk</span><span>.</span><span>translate</span><span>.</span><span>bleu_score</span><span>.</span><span>SmoothingFunction</span><span>().</span><span>method7</span><span>)</span>
<span>&gt;&gt;&gt;</span> <span>print</span><span>(</span><span>bleu</span><span>)</span>
<span>0.4002926439114545</span>
</code></pre></div></div>

<p>This time, the value of <code>bleu</code> is 0.4, which is magically higher than the vanilla one we computed without using smoothing functions.</p>



<p>However, one should be always cautious about the smoothing function used in BLEU computation. At least we have to make sure that the BLEU scores we are comparing against are using no smoothing function or the exact same smoothing function.</p>

<h3 id="references">References</h3>

<ul>
  <li><a href="https://www.aclweb.org/anthology/P02-1040/">BLEU: a Method for Automatic Evaluation of Machine Translation</a></li>
  <li><a href="https://www.youtube.com/watch?v=DejHQYAGb7Q">BLEU - Andrew Ng</a></li>
</ul>

      <hr>
      
    </div></div>]]>
            </description>
            <link>https://leimao.github.io/blog/BLEU-Score/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23641791</guid>
            <pubDate>Thu, 25 Jun 2020 15:27:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Logistic regression from scratch]]>
            </title>
            <description>
<![CDATA[
Score 144 | Comments 52 (<a href="https://news.ycombinator.com/item?id=23640762">thread link</a>) | @pmuens
<br/>
June 25, 2020 | https://philippmuens.com/logistic-regression-from-scratch/ | <a href="https://web.archive.org/web/*/https://philippmuens.com/logistic-regression-from-scratch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>You can find working code examples (including this one) in my <a href="https://github.com/pmuens/lab">lab repository</a> on <a href="https://github.com/pmuens">GitHub</a>.</p><p>Sometimes it's necessary to split existing data into several classes in order to predict new, unseen data. This problem is called <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a> and one of the algorithms which can be used to learn those classes from data is called Logistic Regression.</p><p>In this article we'll take a deep dive into the Logistic Regression model to learn how it differs from other regression models such as <a href="https://en.wikipedia.org/wiki/Linear_regression">Linear-</a> or <a href="https://en.wikipedia.org/wiki/Linear_regression#Simple_and_multiple_linear_regression">Multiple Linear Regression</a>, how to think about it from an intuitive perspective and how we can translate our learnings into code while implementing it from scratch.</p><h2 id="linear-regression-vs-logistic-regression">Linear Regression vs. Logistic Regression</h2><p>If you've read the post about <a href="https://philippmuens.com/linear-and-multiple-regression-from-scratch/">Linear- and Multiple Linear Regression</a> you might remember that the main objective of our algorithm was to find a best fitting line or <a href="https://en.wikipedia.org/wiki/Hyperplane">hyperplane</a> respectively.</p><p>To recap real quick, a line can be represented via the slop-intercept form as follows:</p><p>\[ y = mx + b \]</p><p>Here, \(m\) represents the slope and \(b\) the y-intercept.</p><p>In Linear Regression we've used the existing data to find a line in slope-intercept form (a \(m\) and \(b\) combination) which "best-fitted through" such data.</p><p>Extending the slope-intercept form slightly to support multiple \(x\) values and multiple slopes (we'll use \(\beta_n\) instead of \(m_n\)) yields the following:</p><p>\[ y = &nbsp;\beta_1x_1 + ... + \beta_nx_n + b \]</p><p>This "scaled-up" slope-intercept formula was used in the <a href="https://en.wikipedia.org/wiki/Linear_regression#Simple_and_multiple_linear_regression">Multiple Linear Regression</a> model to find the \(\beta\) and \(b\) values for the <a href="https://en.wikipedia.org/wiki/Hyperplane">hyperplane</a> which "best-fitted" the data. Once found we were able to use it for predictions by plugging in \(x\) values to get respective \(y\) values.</p><p>Linear Regression models always map a set of \(x\) values to a resulting \(y\) value on a <a href="https://en.wikipedia.org/wiki/Continuous_function">continuous</a> scale. This means that the \(y\) value can e.g. be \(0\), \(42\) or \(5.023.212\). How would we use such a Regression model if our \(y\) value is categorical such as a binary value which is either \(0\) or \(1\)? Is there a way to define a threshold so that a value such as \(42\) is assigned to the category \(1\) while a small value such as \(0.002\) gets assigned to the category \(0\)?</p><p>That's where Logistic Regression comes into play. With Logistic Regression we can map any resulting \(y\) value, no matter its magnitude to a value between \(0\) and \(1\).</p><p>Let's take a closer look into the modifications we need to make to turn a Linear Regression model into a Logistic Regression model.</p><h2 id="sigmoid-functions">Sigmoid functions</h2><p>At the very heart of Logistic Regression is the so-called <a href="https://en.wikipedia.org/wiki/Sigmoid_function">Sigmoid function</a>. A Sigmoid function is a class of functions which follows an S-shape when plotted.</p><p>The most prominent Sigmoid function is the so-called <a href="https://en.wikipedia.org/wiki/Logistic_function">Logistic function</a> which was developed by <a href="https://en.wikipedia.org/wiki/Pierre_Fran%C3%A7ois_Verhulst">Pierre Francois Verhulst</a> to model <a href="https://en.wikipedia.org/wiki/Population_growth">population grown</a>. It's mathematically described via this formula:</p><p>\[ f(x) = \frac{1}{1+e^{-x}} \]</p><p>Don't be intimidated by the math! Right now all you need to know is that this function takes any \(x\) value and maps it to a \(y\) value which ranges from \(0\) to \(1\).</p><p>Plotting the function for a range of \(x\) values proofs this claim and results in the aforementioned S-shape curve:</p><figure><img src="https://philippmuens.com/content/images/2020/06/zsigmoid_result.png"></figure><p>Note that the function gets closer and closer to the \(y\) value \(0\) or \(1\) as the \(x\) values get smaller or larger respectively. Also note that the \(x\) value \(0\) results in the \(y\) value \(0.5\).</p><p>This is exactly what we need. with this function we're able to "squish" any number, no matter its magnitude into a value ranging from \(0\) to \(1\). This makes the function outcome predictable which is useful when we later on define threshold values to associate function outputs with classes.</p><p>Let's turn the function into code:</p><pre><code>def sigmoid(x: float) -&gt; float:
    return 1 / (1 + exp(-x))

assert sigmoid(0) == 0.5</code></pre><p><strong><u>Note</u></strong>: Although there are many <a href="https://en.wikipedia.org/wiki/Sigmoid_function#Examples">different Sigmoid functions</a> to choose from, a lot of people use the name "Sigmoid function" when talking about the Logistic function. We'll adhere to this convention and use the term "Sigmoid function" as a synonym for Logistic function.</p><h2 id="from-linear-regression-to-logistic-regression">From Linear Regression to Logistic Regression</h2><p>Now that we've learned about the "mapping" capabilities of the Sigmoid function we should be able to "wrap" a Linear Regression model such as <a href="https://en.wikipedia.org/wiki/Linear_regression#Simple_and_multiple_linear_regression">Multiple Linear Regression</a> inside of it to turn the regressions raw output into a value ranging from \(0\) to \(1\).</p><p>Let's translate this idea into Math. Recall that our Multiple Linear Regression model looks like this:</p><p>\[ y = &nbsp;\beta_1x_1 + ... + \beta_nx_n + b \]</p><p>"Wrapping" this in the Sigmoid function (we use \(\sigma\) to represent the Sigmoid function) results in the following:</p><p>\[ y = \sigma(\beta_1x_1 + ... + \beta_nx_n + b) \]</p><p>Easy enough! Let's turn that into code.</p><p>The first thing we need to do is to implement the underlying Multiple Linear Regression model. Looking at the Math it seems to be possible to use the <a href="https://en.wikipedia.org/wiki/Dot_product">dot-product</a> to calculate the \(\beta\) and \(x\) part to which we then add the single \(b\) value.</p><p>To make everything easier to calculate and implement we'll use a small trick. Multyping a value by the identify \(1\) yields the value so we prepend \(1\) to the \(x\) values and \(b\) to the \(\beta\) values. This way we can solely use the dot-product calculation without the necessity to add \(b\) separately later on. Here's the mathematical formulation of that trick:</p><p>\[ \vec{x} = \begin{pmatrix} 1 \\ x_1 \\ ... \\ x_n \end{pmatrix} \vec{\beta} = \begin{pmatrix} b \\ \beta_1 \\ ... \\ \beta_n \end{pmatrix} \]</p><p>\[ y = \vec{x} \cdot \vec{m} = \sum_{i=1}^n x_i \beta_i = x_1 \times \beta_1 + ... + x_n \times \beta_n \]</p><p>Once we've calculated the dot-product we need to pass it into the Sigmoid function such that its result is translated ("squished") into a value between \(0\) and \(1\).</p><p>Here's the implementation for the <code>dot</code> function which calculates the <a href="https://en.wikipedia.org/wiki/Dot_product">dot-product</a>:</p><pre><code>def dot(a: List[float], b: List[float]) -&gt; float:
    assert len(a) == len(b)
    return sum([a_i * b_i for a_i, b_i in zip(a, b)])

assert dot([1, 2, 3, 4], [5, 6, 7, 8]) == 70</code></pre><p>And here's the <code>squish</code> function which takes as parameters the \(x\) and \(\beta\) values (remember that we've prepended a \(1\) to the \(x\) values and the \(b\) to the \(\beta\) values), uses the <code>dot</code> function to calculate the dot-product of \(x\) and \(\beta\) and then passes this result into the Sigmoid function to map it to a value between \(0\) and \(1\):</p><pre><code>def squish(beta: List[float], x: List[float]) -&gt; float:
    assert len(beta) == len(x)
    # Calculate the dot product
    dot_result: float = dot(beta, x)
    # Use sigmoid to get a result between 0 and 1
    return sigmoid(dot_result)

assert squish([1, 2, 3, 4], [5, 6, 7, 8]) == 1.0</code></pre><h2 id="the-intuition-behind-the-0-1-range">The intuition behind the 0-1 range</h2><p>We've talked quite a lot about how the Sigmoid function is our solution to make the function outcome predictable as all values are mapped to a \(0\) - \(1\) range. But what does a value in that range represent? Let's take a look at an example.</p><p>The following is a data set which describes how long students have studied for an exam and whether they've passed the exam given the hours they've studied.</p><!--kg-card-begin: html--><table>
    <thead>
        <tr>
            <th>Hours studied</th>
            <th>Exam Passed</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>0,5</td>
            <td>0</td>
        </tr>
        <tr>
            <td>1,0</td>
            <td>0</td>
        </tr>
        <tr>
            <td>1,5</td>
            <td>0</td>
        </tr>
        <tr>
            <td>2,0</td>
            <td>0</td>
        </tr>
        <tr>
            <td>2,5</td>
            <td>1</td>
        </tr>
        <tr>
            <td>3,0</td>
            <td>0</td>
        </tr>
        <tr>
            <td>3,5</td>
            <td>1</td>
        </tr>
        <tr>
            <td>4,0</td>
            <td>1</td>
        </tr>
        <tr>
            <td>4,5</td>
            <td>0</td>
        </tr>
        <tr>
            <td>5,0</td>
            <td>1</td>
        </tr>
        <tr>
            <td>5,5</td>
            <td>1</td>
        </tr>
        <tr>
            <td>6,0</td>
            <td>1</td>
        </tr>
    </tbody>
</table><!--kg-card-end: html--><p>Taking a glance at the data it seems to be that the more hours the students studied, the more likely they were to pass the exam. Intuitively that makes sense.</p><p>Let's plot the data to ensure that our intuition is correct:</p><figure><img src="https://philippmuens.com/content/images/2020/06/zmock_student_data.png"></figure><p>Looking at the plotted data we can immediately see that the values seem to "stick" to either the bottom or top of the graph. Given that it seems to be infeasible to use a Linear Regression model to find a line which best describes the data. How would this line be fitted through the data if the values we'd expect this line should produce are either \(o\) or \(1\)?</p><p>Let's try a thought experiment. What would happen if we've somehow found some coefficients \(\beta\) for the Linear Regression model which "best" describe the data and pass the result it computes through the Sigmoid function? Here's the graph from above with the Sigmoid function added to it:</p><figure><img src="https://philippmuens.com/content/images/2020/06/zmock_student_data_w_sigmoid.png"></figure><p>Looking at the plotting above we can see that the Sigmoid function ensures that the result from the "underlying" Linear Regression model is mapped onto a scale between \(0\) and \(1\), which in turn makes it possible to e.g. define a threshold at \(0.5\) to say that a value which is greater than \(0.5\) might be a predictor for a student passing the exam while a value less than \(0.5\) might mean that she'll fail the exam.</p><p>Note that the wording in the last sentence isn't a coincidence. The value the Signoid function produces can be interpreted as a probability where \(0\) means \(0%\) probability and \(1\) means a \(100%\) probability.</p><h2 id="the-probability-density-function">The Probability Density Function</h2><p>As it turns out we can translate our findings from the previous section into a function called <a href="https://en.wikipedia.org/wiki/Probability_density_function">Probability density function</a> or (PDF for short).</p><p>In particular we can define a <a href="https://en.wikipedia.org/wiki/Conditional_probability">conditional probability</a> which states that given some \(\beta\) and \(x_i\), each corresponding \(y_i\) should equal \(1\) with probability \(\sigma(\beta x_i)\) and \(0\) with probability \(1-\sigma(\beta x_i)\):</p><p>\[ P(y_i \mid \beta x_i) = \sigma(\beta x_i)^{y_i} \times (1-\sigma(\beta x_i))^{1-y_i} \]</p><p>Looking at the formula above it might be a mystery how we deduced it from our verbal description from above. Here's something I want you to try: Please apply the formula by setting \(y_i\) to \(0\) and after that to \(1\) and see what happens. What you'll notice is that depending on what value you set \(y_i\) to, only one part of the formula stays the same while the other is canceled out.</p><p>Here's what we'll end up with if we set \(y_i\) to \(0\) and \(1\):</p><p>\[ 1-\sigma(\beta x_i) \quad \textrm{if} &nbsp;y_i = 0 \]</p><p>\[ \sigma(\beta x_i) \quad \textrm{if} &nbsp;y_i = 1 \]</p><p>And that's exactly the desired behavior we described above.</p><h2 id="deriving-a-loss-function">Deriving a Loss function</h2><p>With Logistic Regression our main objective is to find the models \(\beta\) parameters which maximize the likelihood that for a pair of \(x\) values the \(y\) value …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://philippmuens.com/logistic-regression-from-scratch/">https://philippmuens.com/logistic-regression-from-scratch/</a></em></p>]]>
            </description>
            <link>https://philippmuens.com/logistic-regression-from-scratch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23640762</guid>
            <pubDate>Thu, 25 Jun 2020 13:54:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What vertical farming and ag startups don't understand about agriculture, part 2]]>
            </title>
            <description>
<![CDATA[
Score 120 | Comments 118 (<a href="https://news.ycombinator.com/item?id=23640011">thread link</a>) | @kickout
<br/>
June 25, 2020 | http://thinkingagriculture.io/what-sv-doesnt-understand-about-agriculture-part-ii/ | <a href="https://web.archive.org/web/*/http://thinkingagriculture.io/what-sv-doesnt-understand-about-agriculture-part-ii/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-20">
		
	
	<div>
		
<p>Some commenters (/u/coderintherye chain notably) on the <a href="https://news.ycombinator.com/item?id=23630201">HN post</a> of the <a href="https://thinkingagriculture.io/what-silicon-valley-doesnt-understand-about-agriculture/">original article</a> brought up good points that I wanted to expand on and provide some additional context. Also for clarification: although farming is truly global, most ‘farming’ I refer to pertains to the United States (<a href="https://en.wikipedia.org/wiki/Agriculture_in_the_United_States">which is an agriculture juggernaut</a>), but in my experience should reasonably translate across agriculture zones (pending equivalent laws and climatic factors).</p>



<p><strong><em>There is ample VC money for Ag startups</em></strong></p>



<p>The original intention of the article wasn’t to bemoan the lack of capital available for <a href="https://agiowa.com/portfolio/">founders focused on agriculture</a> (there is actually plenty of capital–check out <a href="https://agfundernews.com/">AgFunderNews</a> for examples of successful raises). Instead, it is a recommendation for anyone entering the space to understand the industry and its history to harness existing synergies rather than try and swim upstream. Watching capital go to ‘solved’ problems is painful, because there are many opportunities for a unicorn ag startup if aimed in the correct space. Vertical farming for non-vegetables (or fruits) is likely dead-on-pitch. Yes, vertical farming <em>is</em> and <em>could be</em> successful, but those markets are very specific and probably 10x smaller than people think. Nice businesses no doubt, but not market shaping behemoths VCs are after. Agriculture is rightfully a commodity and the market will brutalize ideas/companies that can’t turn a profit. One bad year (droughts in 2011 and 2012 in the US Midwest) from external forces can absolutely put farmers out of business. Indoor farming has all of the risks of outdoor ag–and more! Indoor farming requires water (whose source can dry up and get shut off unexpectedly, just like a drought), has pests, and requires artificial lighting (power outage for 5 days? Uh oh). Herbicides (and sometimes pesticides) are actually an example of innovation pre-SV. Alternate technologies (i.e mechanical) didn’t work or were uneconomical for the time period; thus, chemical solutions seemed to thrive (glyphosate/glufosinate resistant corn/soy/wheat/cotton/sugar beets &amp; <a href="https://agrilife.org/lubbock/files/2020/02/BtTraitTable_FEB_2020.pdf">BT resistance for insects</a>). I predict in next 5-20 years we see that flip, where chemical and biological solutions fall out in favor of mechanized solutions (who wouldn’t want a semi-autonomous robot pulling weeds in fields in favor of a chemical solution that is <a href="https://www.nbcnews.com/news/us-news/bayer-reaches-10-5-billion-settlement-roundup-cancer-lawsuits-n1232026">open to litigation</a>)? We just have too little understanding of 2nd and 3rd order effects of disrupting nature at this scale (<a href="https://www.nature.com/articles/s41598-019-49660-6">gene drives included</a>, as promising as they appear) using these incredibly effective chemicals.</p>



<p><strong><em>Financing in the Heartland</em></strong></p>



<p>I won’t speak of financing agricultural operations in a municipality not located in the United States, as even understanding the US situation takes time and effort. Let’s be clear though: Most farmers <em>need</em> to borrow capital just to operate for a given year (hence, there is a note called an ‘operating loan’) and financing agriculture operations is more and more important as the size of farms increases. They buy seed, fertilizer, feed, chemicals, etc. to be able to produce an output to then (hopefully) sell at a profit–all to rinse and repeat. Buying big expensive new tractors ($300k+ USD), buildings to store the machines, grain storage, fencing, animal houses–all generally require a loan. Because of the huge cost to purchase these necessities, financing institutions generally need to have a <em>very</em> thorough understanding of the operation (Only farm 160 acres of corn,soy,or wheat? Good luck buying equipment). So bankers have become very good (not perfect) at evaluating and swaying farming practices to ensure maximum likelihood of repayment. Seriously, check of the used auction prices of ag machinery sometime–<a href="https://www.bigiron.com/Lots/2011JohnDeere8335RMFWDTractor-3">this tractor</a> is 10 years old and commands the price of a new Tesla. Is ag financing a place that needs disruption? Likely no because ag lending has evolved hand-in-hand in rural communities where agricultural production is the predominant industry. Because they evolved with ag, they likely have already captured the +EV that startups tend to seek because their very existence depends on it. So where <em>are</em> the value proposition? I know nothing of their founding, but the previous auction link is from <a href="https://www.bigiron.com/">Big Iron Auctions</a> and those founders likely understood ag (“hey, there is a robust secondary market for farm machinery”) and created on-line version of it–with what appears to be great success. I’d imagine these on-line secondary markets exist in Brazil and Eastern Europe given there agriculture exposure. </p>



<p><strong><em>Success Stories</em></strong></p>



<p>There are some truly incredible examples of engineering and innovation in agriculture that focus on the mechanization and scale <em>that already exists</em>. Transplanting vegetables in the Central Valley (CA) used to be labor intensive–<a href="https://www.planttape.com/">this brilliant solution solved that</a>. Auto-steer <a href="https://www.fieldbee.com/blog/fieldbee-tractor-autosteer-versus-other-systems/">systems</a> that leverage machinery that already exists. Sometimes the innovation is statistical/computation (<a href="https://www.annualreviews.org/doi/full/10.1146/annurev-animal-021815-111422">genomic prediction has revolutionized dairy cattle</a>) Starting businesses is hard and agriculture is no different.</p>



<p>Stay away from vertical farming–unless you plan on growing saffron or figure out a way to cultivate morel mushrooms!</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article></div>]]>
            </description>
            <link>http://thinkingagriculture.io/what-sv-doesnt-understand-about-agriculture-part-ii/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23640011</guid>
            <pubDate>Thu, 25 Jun 2020 12:44:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Faster Integer Parsing]]>
            </title>
            <description>
<![CDATA[
Score 155 | Comments 39 (<a href="https://news.ycombinator.com/item?id=23639486">thread link</a>) | @fanf2
<br/>
June 25, 2020 | https://kholdstare.github.io/technical/2020/05/26/faster-integer-parsing.html | <a href="https://web.archive.org/web/*/https://kholdstare.github.io/technical/2020/05/26/faster-integer-parsing.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
        <p>Back with a post after 6 years of silence. If you had to parse a microsecond-resolution epoch timestamp as quickly as possible, how would you do it?  We’ll take a look at using compiler intrinsics to do it in log(n) time.</p>


        <h3 id="the-problem">The problem</h3>

<p>Let’s say, theoretically, you have some text-based protocol, or file that
contains microsecond timestamps. You need to parse these timestamps as quickly
as possible. Maybe it’s json, maybe it’s a csv file, maybe something else
bespoke. It’s 16 characters long, and this could also apply to credit card
numbers.</p>

<figure><pre><code data-lang="csv">timestamp,event_id
1585201087123567,a
1585201087123585,b
1585201087123621,c</code></pre></figure>

<p>In the end you have to implement a function similar to this:</p>

<figure><pre><code data-lang="cpp"><span>std</span><span>::</span><span>uint64_t</span> <span>parse_timestamp</span><span>(</span><span>std</span><span>::</span><span>string_view</span> <span>s</span><span>)</span>
<span>{</span>
  <span>// ???</span>
<span>}</span></code></pre></figure>

<hr>

<h3 id="the-native-solution">The native solution</h3>

<p>Let’s start with what’s available, and compare. We have
<a href="https://en.cppreference.com/w/cpp/string/byte/atoi"><code>std::atoll</code></a> , a function
inherited from C,
<a href="https://en.cppreference.com/w/cpp/io/basic_stringstream"><code>std::stringstream</code></a>
, the newer C++17
<a href="https://en.cppreference.com/w/cpp/header/charconv"><code>&lt;charconv&gt;</code></a> header, and
by request
<a href="https://www.boost.org/doc/libs/1_73_0/libs/spirit/doc/html/spirit/qi/reference/basics.html"><code>boost::spirit::qi</code></a>.
I’ll be using <a href="https://github.com/google/benchmark">Google Benchmark</a> to
measure the performance, and to have a baseline let’s compare against loading
the final result into a register - i.e. no actual parsing involved.</p>

<p>Let’s run the benchmarks! The code is not important here, it just shows what is being benchmarked.</p>

<figure><pre><code data-lang="cpp"><span>static</span> <span>void</span> <span>BM_mov</span><span>(</span><span>benchmark</span><span>::</span><span>State</span><span>&amp;</span> <span>state</span><span>)</span> <span>{</span>
  <span>for</span> <span>(</span><span>auto</span> <span>_</span> <span>:</span> <span>state</span><span>)</span> <span>{</span>
    <span>benchmark</span><span>::</span><span>DoNotOptimize</span><span>(</span><span>1585201087123789</span><span>);</span>
  <span>}</span>
<span>}</span>

<span>static</span> <span>void</span> <span>BM_atoll</span><span>(</span><span>benchmark</span><span>::</span><span>State</span><span>&amp;</span> <span>state</span><span>)</span> <span>{</span>
  <span>for</span> <span>(</span><span>auto</span> <span>_</span> <span>:</span> <span>state</span><span>)</span> <span>{</span>
    <span>benchmark</span><span>::</span><span>DoNotOptimize</span><span>(</span><span>std</span><span>::</span><span>atoll</span><span>(</span><span>example_timestamp</span><span>));</span>
  <span>}</span>
<span>}</span>

<span>static</span> <span>void</span> <span>BM_sstream</span><span>(</span><span>benchmark</span><span>::</span><span>State</span><span>&amp;</span> <span>state</span><span>)</span> <span>{</span>
  <span>std</span><span>::</span><span>stringstream</span> <span>s</span><span>(</span><span>example_timestamp</span><span>);</span>
  <span>for</span> <span>(</span><span>auto</span> <span>_</span> <span>:</span> <span>state</span><span>)</span> <span>{</span>
    <span>s</span><span>.</span><span>seekg</span><span>(</span><span>0</span><span>);</span>
    <span>std</span><span>::</span><span>uint64_t</span> <span>i</span> <span>=</span> <span>0</span><span>;</span>
    <span>s</span> <span>&gt;&gt;</span> <span>i</span><span>;</span>
    <span>benchmark</span><span>::</span><span>DoNotOptimize</span><span>(</span><span>i</span><span>);</span>
  <span>}</span>
<span>}</span>
<span>static</span> <span>void</span> <span>BM_charconv</span><span>(</span><span>benchmark</span><span>::</span><span>State</span><span>&amp;</span> <span>state</span><span>)</span> <span>{</span>
  <span>auto</span> <span>s</span> <span>=</span> <span>example_timestamp</span><span>;</span>
  <span>for</span> <span>(</span><span>auto</span> <span>_</span> <span>:</span> <span>state</span><span>)</span> <span>{</span>
    <span>std</span><span>::</span><span>uint64_t</span> <span>result</span> <span>=</span> <span>0</span><span>;</span>
    <span>std</span><span>::</span><span>from_chars</span><span>(</span><span>s</span><span>.</span><span>data</span><span>(),</span> <span>s</span><span>.</span><span>data</span><span>()</span> <span>+</span> <span>s</span><span>.</span><span>size</span><span>(),</span> <span>result</span><span>);</span>
    <span>benchmark</span><span>::</span><span>DoNotOptimize</span><span>(</span><span>result</span><span>);</span>
  <span>}</span>
<span>}</span>

<span>static</span> <span>void</span> <span>BM_boost_spirit</span><span>(</span><span>benchmark</span><span>::</span><span>State</span><span>&amp;</span> <span>state</span><span>)</span> <span>{</span>
  <span>using</span> <span>boost</span><span>::</span><span>spirit</span><span>::</span><span>qi</span><span>::</span><span>parse</span><span>;</span>
  <span>for</span> <span>(</span><span>auto</span> <span>_</span> <span>:</span> <span>state</span><span>)</span> <span>{</span>
    <span>std</span><span>::</span><span>uint64_t</span> <span>result</span> <span>=</span> <span>0</span><span>;</span>
    <span>parse</span><span>(</span><span>s</span><span>.</span><span>data</span><span>(),</span> <span>s</span><span>.</span><span>data</span><span>()</span> <span>+</span> <span>s</span><span>.</span><span>size</span><span>(),</span> <span>result</span><span>);</span>
    <span>benchmark</span><span>::</span><span>DoNotOptimize</span><span>(</span><span>result</span><span>);</span>
  <span>}</span>
<span>}</span></code></pre></figure>

<figure>
    <canvas id="benchmark-canvas-native">
    </canvas>

</figure>

<p>Wow, <code>stringstream</code> is pretty bad. Not that it’s a fair comparison but parsing
a single integer using <code>stringstream</code> is 391 times slower than just loading our
integer into a register.  <code>&lt;charconv&gt;</code> and <code>boost::spirit</code> do a lot better by
comparison.</p>

<p>Since we know our string contains the number we’re trying to parse, and we
don’t need to do any whitespace skipping, can we be faster?  Just how much time
is spent in validation?</p>

<hr>

<h3 id="the-naive-solution">The naive solution</h3>

<p>Let’s write a good old for loop. Read the string character by character, and
build up the result.</p>

<figure><pre><code data-lang="cpp"><span>inline</span> <span>std</span><span>::</span><span>uint64_t</span> <span>parse_naive</span><span>(</span><span>std</span><span>::</span><span>string_view</span> <span>s</span><span>)</span> <span>noexcept</span>
<span>{</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>result</span> <span>=</span> <span>0</span><span>;</span>
  <span>for</span><span>(</span><span>char</span> <span>digit</span> <span>:</span> <span>s</span><span>)</span>
  <span>{</span>
    <span>result</span> <span>*=</span> <span>10</span><span>;</span>
    <span>result</span> <span>+=</span> <span>digit</span> <span>-</span> <span>'0'</span><span>;</span>
  <span>}</span>
  <span>return</span> <span>result</span><span>;</span>
<span>}</span></code></pre></figure>

<figure>
    <canvas id="benchmark-canvas-naive">
    </canvas>

</figure>

<p>That’s actually not bad for a simple for loop. If such a simple solution is
able to beat a standard-library implementation, it means there’s quite a lot of
effort that goes into input validation. As a sidenote - if you know your input,
or can do simpler validation you can get some significant speedups.</p>

<p>For further solutions and benchmarks, let’s ignore the standard library
functions. We should be able to go much faster than this.</p>

<hr>

<h3 id="the-brute-force-solution">The brute force solution</h3>

<p>If we know it’s 16 bytes, why even have a forloop? Let’s unroll it!</p>

<figure><pre><code data-lang="cpp"><span>inline</span> <span>std</span><span>::</span><span>uint64_t</span> <span>parse_unrolled</span><span>(</span><span>std</span><span>::</span><span>string_view</span> <span>s</span><span>)</span> <span>noexcept</span>
<span>{</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>result</span> <span>=</span> <span>0</span><span>;</span>

  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>0</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>1000000000000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>1</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>100000000000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>2</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>10000000000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>3</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>1000000000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>4</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>100000000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>5</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>10000000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>6</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>1000000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>7</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>100000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>8</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>10000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>9</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>1000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>10</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>100000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>11</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>10000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>12</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>1000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>13</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>100ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>14</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>10ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>15</span><span>]</span> <span>-</span> <span>'0'</span><span>);</span>

  <span>return</span> <span>result</span><span>;</span>
<span>}</span></code></pre></figure>

<figure>
    <canvas id="benchmark-canvas-brute-force">
    </canvas>

</figure>

<p>Ok, that’s slightly better again, but we’re still processing a character at a time.</p>

<hr>

<h3 id="the-byteswap-insight">The byteswap insight</h3>

<p>Let’s draw out the operations in the unrolled solution as a tree, on a
simplified example of parsing ‘1234’ into a 32-bit integer:</p>

<figure>
    <img width="100%" height="100%" src="https://kholdstare.github.io/diagrams/parse-unrolled.png">

<figcaption><p>Unrolled solution graph of operations for ‘1234’</p>
</figcaption>

</figure>

<p>We can see that the amount of multiplications and additions is linear with the
amount of characters. It’s hard to see how to improve this, because every
multiplication is by a different factor (so we can’t multiply “in one go”), and at
the end of the day we need to add up all the intermediate results.</p>

<p>However, it’s still very regular. For one thing, the first character in the
string is multiplied by the largest factor, because it is the most significant
digit.</p>

<blockquote>
  <p>On a little-endian machine (like x86), an integer’s first byte contains the
least significant digits, while the first byte in a string contains the most
significant digit.</p>
</blockquote>

<figure>
    <img width="100%" height="100%" src="https://kholdstare.github.io/diagrams/parse-byteswap-insight.png">

<figcaption><p>Looking at the string as an integer we can get closer to
the final parsed state in fewer operations - see how the hex representation is
<strong>almost</strong> what we want</p>
</figcaption>

</figure>

<p>Now to reinterpret the bytes of a string as an integer we have to use
<code>std::memcpy</code> (<a href="https://blog.regehr.org/archives/1307">to avoid strict-aliasing
violations</a>), and we have compiler
instrinsic <code>__builtin_bswap64</code> to swap the bytes in one instruction. The
<code>std::memcpy</code> will get optimized out, so this is a win so far.</p>

<figure><pre><code data-lang="cpp"><span>template</span> <span>&lt;</span><span>typename</span> <span>T</span><span>&gt;</span>
<span>inline</span> <span>T</span> <span>get_zeros_string</span><span>()</span> <span>noexcept</span><span>;</span>

<span>template</span> <span>&lt;</span><span>&gt;</span>
<span>inline</span> <span>std</span><span>::</span><span>uint64_t</span> <span>get_zeros_string</span><span>&lt;</span><span>std</span><span>::</span><span>uint64_t</span><span>&gt;</span><span>()</span> <span>noexcept</span>
<span>{</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>result</span> <span>=</span> <span>0</span><span>;</span>
  <span>constexpr</span> <span>char</span> <span>zeros</span><span>[]</span> <span>=</span> <span>"00000000"</span><span>;</span>
  <span>std</span><span>::</span><span>memcpy</span><span>(</span><span>&amp;</span><span>result</span><span>,</span> <span>zeros</span><span>,</span> <span>sizeof</span><span>(</span><span>result</span><span>));</span>
  <span>return</span> <span>result</span><span>;</span>
<span>}</span>

<span>inline</span> <span>std</span><span>::</span><span>uint64_t</span> <span>parse_8_chars</span><span>(</span><span>const</span> <span>char</span><span>*</span> <span>string</span><span>)</span> <span>noexcept</span>
<span>{</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>chunk</span> <span>=</span> <span>0</span><span>;</span>
  <span>std</span><span>::</span><span>memcpy</span><span>(</span><span>&amp;</span><span>chunk</span><span>,</span> <span>string</span><span>,</span> <span>sizeof</span><span>(</span><span>chunk</span><span>));</span>
  <span>chunk</span> <span>=</span> <span>__builtin_bswap64</span><span>(</span><span>chunk</span> <span>-</span> <span>get_zeros_string</span><span>&lt;</span><span>std</span><span>::</span><span>uint64_t</span><span>&gt;</span><span>());</span>

  <span>// ...</span>
<span>}</span></code></pre></figure>

<p>But now that we have an integer that kind of, sort of looks like what we want,
how do we get it across the finish line without too much work?</p>

<hr>

<h3 id="the-divide-and-conquer-insight">The divide and conquer insight</h3>

<p>From the previous step, we end up with an integer whose bit representation 
has each digit placed in a separate byte. I.e. even though one byte can
represent up to 256 values, we have values 0-9 in each byte of the integer.
They are also in the right little endian order. Now we just need to “smash”
them together somehow.</p>

<p>We know that doing it linearly would be too slow, what’s the next possibility?
<strong>O(log(n))</strong>! We need to combine every adjacent digit into a pair in one step,
and then each pair of digits into a group of four, and so on, until we have the
entire integer.</p>

<p>After I posted the first version of this article, <a href="https://www.reddit.com/r/cpp/comments/gr18ig/faster_integer_parsing/frx9agb">Sopel97 on
reddit</a>
pointed out that the byteswap is not necessary. Combining adjacent digits works
either way - their order doesn’t matter.  I realized that it helped me with the
next insight, but could be omitted for the final code.</p>

<blockquote>
  <p>The key is working on adjacent digits simultaneously. This allows a tree of
operations, running in O(log(n)) time.</p>
</blockquote>

<p>This involves multiplying the even-index digits by a power of 10 and leaving the
odd-index digits alone. This can be done with bitmasks to selectively apply
operations</p>

<figure>
    <img width="100%" height="100%" src="https://kholdstare.github.io/diagrams/parse-mask-insight.png">

<figcaption><p>By using bitmasking, we can apply operations to more than one digit at a time, to combine them into a larger group</p>
</figcaption>

</figure>

<p>Let’s finish the <code>parse_8_chars</code> function we started earlier by employing this
masking trick. As a neat side-effect of the masking, we don’t need to subtract
<code>'0'</code>, since it will be masked away.</p>

<figure><pre><code data-lang="cpp"><span>inline</span> <span>std</span><span>::</span><span>uint64_t</span> <span>parse_8_chars</span><span>(</span><span>const</span> <span>char</span><span>*</span> <span>string</span><span>)</span> <span>noexcept</span>
<span>{</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>chunk</span> <span>=</span> <span>0</span><span>;</span>
  <span>std</span><span>::</span><span>memcpy</span><span>(</span><span>&amp;</span><span>chunk</span><span>,</span> <span>string</span><span>,</span> <span>sizeof</span><span>(</span><span>chunk</span><span>));</span>

  <span>// 1-byte mask trick (works on 4 pairs of single digits)</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>lower_digits</span> <span>=</span> <span>(</span><span>chunk</span> <span>&amp;</span> <span>0x0f000f000f000f00</span><span>)</span> <span>&gt;&gt;</span> <span>8</span><span>;</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>upper_digits</span> <span>=</span> <span>(</span><span>chunk</span> <span>&amp;</span> <span>0x000f000f000f000f</span><span>)</span> <span>*</span> <span>10</span><span>;</span>
  <span>chunk</span> <span>=</span> <span>lower_digits</span> <span>+</span> <span>upper_digits</span><span>;</span>

  <span>// 2-byte mask trick (works on 2 pairs of two digits)</span>
  <span>lower_digits</span> <span>=</span> <span>(</span><span>chunk</span> <span>&amp;</span> <span>0x00ff000000ff0000</span><span>)</span> <span>&gt;&gt;</span> <span>16</span><span>;</span>
  <span>upper_digits</span> <span>=</span> <span>(</span><span>chunk</span> <span>&amp;</span> <span>0x000000ff000000ff</span><span>)</span> <span>*</span> <span>100</span><span>;</span>
  <span>chunk</span> <span>=</span> <span>lower_digits</span> <span>+</span> <span>upper_digits</span><span>;</span>

  <span>// 4-byte mask trick (works on pair of four digits)</span>
  <span>lower_digits</span> <span>=</span> <span>(</span><span>chunk</span> <span>&amp;</span> <span>0x0000ffff00000000</span><span>)</span> <span>&gt;&gt;</span> <span>32</span><span>;</span>
  <span>upper_digits</span> <span>=</span> <span>(</span><span>chunk</span> <span>&amp;</span> <span>0x000000000000ffff</span><span>)</span> <span>*</span> <span>10000</span><span>;</span>
  <span>chunk</span> <span>=</span> <span>lower_digits</span> <span>+</span> <span>upper_digits</span><span>;</span>

  <span>return</span> <span>chunk</span><span>;</span>
<span>}</span></code></pre></figure>

<hr>

<h3 id="the-trick">The trick</h3>

<p>Putting it all together, to parse our 16-digit integer, we break it up into two
chunks of 8 bytes, run <code>parse_8_chars</code> that we have just written, and benchmark it!</p>

<figure><pre><code data-lang="cpp"><span>inline</span> <span>std</span><span>::</span><span>uint64_t</span> <span>parse_trick</span><span>(</span><span>std</span><span>::</span><span>string_view</span> <span>s</span><span>)</span> <span>noexcept</span>
<span>{</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>upper_digits</span> <span>=</span> <span>parse_8_chars</span><span>(</span><span>s</span><span>.</span><span>data</span><span>());</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>lower_digits</span> <span>=</span> <span>parse_8_chars</span><span>(</span><span>s</span><span>.</span><span>data</span><span>()</span> <span>+</span> <span>8</span><span>);</span>
  <span>return</span> <span>upper_digits</span> <span>*</span> <span>100000000</span> <span>+</span> <span>lower_digits</span><span>;</span>
<span>}</span>

<span>static</span> <span>void</span> <span>BM_trick</span><span>(</span><span>benchmark</span><span>::</span><span>State</span><span>&amp;</span> <span>state</span><span>)</span> <span>{</span>
  <span>for</span> <span>(</span><span>auto</span> <span>_</span> <span>:</span> <span>state</span><span>)</span> <span>{</span>
    <span>benchmark</span><span>::</span><span>DoNotOptimize</span><span>(</span><span>parse_trick</span><span>(</span><span>example_stringview</span><span>));</span>
  <span>}</span>
<span>}</span></code></pre></figure>

<figure>
    <canvas id="benchmark-canvas-trick">
    </canvas>

</figure>

<p>Not too shabby, we shaved almost 56% off of the unrolled loop benchmark! Still,
it feels like we are manually doing a bunch of masking and elementwise
operations. Maybe we can just let the CPU do all the hard work?</p>

<hr>

<h3 id="the-simd-trick">The SIMD trick</h3>

<p>We have the main insight:</p>

<ul>
  <li>Combine groups of digits simultaneously to achieve O(log(n)) time</li>
</ul>

<p>We also have a 16-character, or 128-bit string to parse - can we use SIMD? Of
course we can! <a href="https://en.wikipedia.org/wiki/SIMD">SIMD stands for Single Instruction Multiple
Data</a>, and is exactly what we are looking
for. SSE and AVX instructions are supported on both Intel and AMD CPUs, and
 they typically work with wider registers.</p>

<p>I used the <a href="https://software.intel.com/sites/landingpage/IntrinsicsGuide/">Intel Intrinsics
Guide</a> to find
the right compiler intrinsics for the right SIMD CPU instructions.</p>

<p>Let’s set up the digits in each of the 16 bytes first:</p>

<figure><pre><code data-lang="cpp"><span>inline</span> <span>std</span><span>::</span><span>uint64_t</span> <span>parse_1…</span></code></pre></figure></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kholdstare.github.io/technical/2020/05/26/faster-integer-parsing.html">https://kholdstare.github.io/technical/2020/05/26/faster-integer-parsing.html</a></em></p>]]>
            </description>
            <link>https://kholdstare.github.io/technical/2020/05/26/faster-integer-parsing.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23639486</guid>
            <pubDate>Thu, 25 Jun 2020 11:43:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Zoom works [slides]]]>
            </title>
            <description>
<![CDATA[
Score 186 | Comments 143 (<a href="https://news.ycombinator.com/item?id=23638116">thread link</a>) | @Spidery
<br/>
June 25, 2020 | https://builtformars.co.uk/how-zoom-works/ | <a href="https://web.archive.org/web/*/https://builtformars.co.uk/how-zoom-works/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-elementor-type="single" data-elementor-id="2530" data-elementor-settings="[]">
		<div>
			<div>
						<section data-id="c26fc93" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="28a6896" data-element_type="column">
			<div>
					<div>
				
				<div data-id="b04b2c1" data-element_type="widget" data-widget_type="theme-post-excerpt.default">
				<p>
			Zoom is a significant challenger in the video conferencing space, but is their UX any better than Skype or Cisco?		</p>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="052a335" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="4224d77" data-element_type="column">
			<div>
					<div>
				<div data-id="5ad8739" data-element_type="widget" data-widget_type="theme-post-featured-image.default">
				<div>
					<p><img width="720" height="410" src="https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom.png" alt="Zoom UX case study" srcset="https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom.png 1018w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-300x171.png 300w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-768x438.png 768w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-100x57.png 100w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-700x399.png 700w" sizes="(max-width: 720px) 100vw, 720px">											</p>
				</div>
				</div>
						</div>
			</div>
		</div>
				<div data-id="a001539" data-element_type="column">
			<div>
					<div>
				
				<div data-id="724633a" data-element_type="widget" data-widget_type="post-info.default">
				<div>
					<ul>
					<li itemprop="datePublished">
										<span>
															</span>
									<span>
							<span>📅 Added on</span>
										April 15, 2020					</span>
								</li>
				</ul>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="2643ed8" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="a995590" data-element_type="column">
			<div>
					<div>
				<div data-id="c9f06a8" data-element_type="widget" data-widget_type="theme-post-featured-image.default">
				<div>
					<p><img width="720" height="410" src="https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom.png" alt="Zoom UX case study" srcset="https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom.png 1018w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-300x171.png 300w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-768x438.png 768w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-100x57.png 100w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-700x399.png 700w" sizes="(max-width: 720px) 100vw, 720px">											</p>
				</div>
				</div>
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
				<section data-id="ca3ca43" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
							
							<div>
				<div>
				<div data-id="ec20c55" data-element_type="column">
			<div>
					<div>
				<div data-id="682e138" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
					<div data-elementor-type="wp-post" data-elementor-id="3204" data-elementor-settings="[]">
			<div>
				<div>
							<section data-id="7b73c3c" data-element_type="section">
						<div>
				<div>
				<div data-id="d0a7d7b" data-element_type="column">
			<div>
					<div>
				<div data-id="cd0bf0c" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><div><div role="region" aria-label="Slider"><p><img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxMjAwIiBoZWlnaHQ9IjkwMCIgPjwvc3ZnPg==" alt="Slider"></p></div></div></div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="375357f" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="353f855" data-element_type="column">
			<div>
					<div>
				<div data-id="891920c" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>💡<strong>Tip:</strong> Try using the ⬅️ <span>➡️arrows on your keyboard to navigate the slides.</span></p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="9ffc41b" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="5f2393c" data-element_type="column">
			<div>
					<div>
				<div data-id="b2a958e" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p><strong>Mobile tip:</strong> Try swiping ⬅️<span>👆➡️ left and right to navigate the slides.</span></p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="5094e89" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="4d0fdca" data-element_type="column">
			<div>
					<div>
				
				<div data-id="560b6f9" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>New case studies—packed with UX lessons—are published every <strong>14 days</strong>.</p>
				</div>
				</div>
				<div data-id="c135888" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p><span>📮 No spam, ever.&nbsp; &nbsp;</span><span>📅 1 email a week.&nbsp; &nbsp;</span><span>👋 Unsubscribe anytime.</span></p>
				</div>
				</div>
				
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="3daa393" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="4876312" data-element_type="column">
			<div>
					<div>
				<section data-id="05a68ee" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="09ef108" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
			<div>
							
					<div>
				<div data-id="31901c7" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Subscribe and get a new case study like this every <strong>14 days</strong>!</p>
				</div>
				</div>
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="94d99dd" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="3a870f9" data-element_type="column">
			<div>
					<div>
				<div data-id="91f57f2" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>There’s always more to learn</p>
				</div>
				</div>
				<div data-id="2f5c033" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Dive into other case studies. They’re typically a <strong>5 minute read</strong>.</p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="c62cabd" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						
		</section>
					</div>
		</div>
		</div></div>]]>
            </description>
            <link>https://builtformars.co.uk/how-zoom-works/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23638116</guid>
            <pubDate>Thu, 25 Jun 2020 08:13:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Liberty (1859) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 165 | Comments 101 (<a href="https://news.ycombinator.com/item?id=23636407">thread link</a>) | @mrfusion
<br/>
June 24, 2020 | https://socialsciences.mcmaster.ca/econ/ugcm/3ll3/mill/liberty.pdf | <a href="https://web.archive.org/web/*/https://socialsciences.mcmaster.ca/econ/ugcm/3ll3/mill/liberty.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://socialsciences.mcmaster.ca/econ/ugcm/3ll3/mill/liberty.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23636407</guid>
            <pubDate>Thu, 25 Jun 2020 02:54:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to write PureScript react components to replace JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 99 | Comments 72 (<a href="https://news.ycombinator.com/item?id=23636336">thread link</a>) | @JacksonGariety
<br/>
June 24, 2020 | https://thomashoneyman.com/articles/replace-react-components-with-purescript/ | <a href="https://web.archive.org/web/*/https://thomashoneyman.com/articles/replace-react-components-with-purescript/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  

  

<p>I have twice migrated large JavaScript apps to PureScript. At CitizenNet we replaced Angular with Halogen, and at Awake Security we’ve replaced most of a React application with PureScript React. Both companies have seen a dramatic drop in bugs in production.</p>

<p>It’s relatively easy to replace React due to PureScript’s <code>react</code> and <code>react-basic</code> libraries. The React mental model fits well with a strongly-typed, pure functional language like PureScript (or Reason), and using the same underlying library means that components can be shared between languages with little modification.</p>

<p>At Awake Security we share internationalization, a Redux store and middleware, and much more in an code base where PureScript regularly imports JavaScript and JavaScript regularly imports PureScript.</p>

<p>The best way to rewrite a significant app from one language to another is incrementally, while it runs. At first the new language can take over logically isolated parts of the app: the management dashboard, or the chat window, or a form. But eventually you must mix components from both languages together – for example, to support shared global state.</p>

<p>At this point you can’t just let the new language take over a DOM node. You need to support simple, clear features for intermixing the languages. Fortunately, you can transform the interface of idiomatic PureScript code into idiomatic JavaScript (and vice versa). With <code>react</code> and <code>react-basic</code> you can write business logic in PureScript but easily interoperating with the larger React ecosystem and your existing code.</p>

<p>In this article I will demonstrate how to replace part of a React application with simple components written in PureScript. Along the way, I’ll share best practices for making this interop convenient and dependable. The examples will be simple, but the same techniques also apply to complex components.</p>

<h4 id="sections">Sections</h4>

<ol>
<li><a href="#let-s-write-a-react-app-in-javascript">Write a tiny React application in JavaScript</a></li>
<li><a href="#setting-up-a-shared-purescript-javascript-project">Update the application to support PureScript</a></li>
<li><a href="#replacing-a-react-component-with-purescript-react">Replace a React component with PureScript React, with the same interface and behavior as the original</a></li>
<li><a href="#replacing-a-react-component-with-purescript-react-basic">Replace the component again with React Basic</a></li>
</ol>

<p>I encourage you to code along with this article; no code is omitted and dependencies are pinned to help ensure the examples are reproducible. This code uses Node <code>v11.1.0</code>, Yarn <code>v1.12.0</code>, and NPX <code>v6.5.0</code> installed globally, and PureScript tooling installed locally.</p>

<p>Peter Murphy has <a href="https://github.com/ptrfrncsmrph/purescript-react-tutorial">implemented the ideas in this article using React Hooks</a> if you’d like to see this in action.</p>




<h2 id="let-s-write-a-react-app-in-javascript">Let’s write a React app in JavaScript</h2>

<p>We are going to write a tiny React application which shows a few counters, and then we’re going to replace its components with PureScript. The resulting JavaScript code will be indistinguishable, aside from imports, from the original, and yet it will all be PureScript under the hood.</p>

<p>Let’s follow the official React docs in using <code>create-react-app</code> to initialize the project and then trim our source code to the bare minimum.</p>
<div><pre><code data-lang="sh"><span># Create the app</span>
npx create-react-app my-app <span>&amp;&amp;</span> <span>cd</span> my-app</code></pre></div>
<p>At the time of writing, <code>create-react-app</code> produces these React dependencies:</p>
<div><pre><code data-lang="json"><span>"dependencies"</span><span>:</span> <span>{</span>
    <span>"react"</span><span>:</span> <span>"^16.8.6"</span><span>,</span>
    <span>"react-dom"</span><span>:</span> <span>"^16.8.6"</span><span>,</span>
    <span>"react-scripts"</span><span>:</span> <span>"3.0.1"</span>
  <span>}</span></code></pre></div>
<p>We have a handful of source files under <code>src</code>, but our application will need just two of them: <code>index.js</code>, the entrypoint for Webpack, and <code>App.js</code>, the root component of our application. We can delete the rest:</p>
<div><pre><code data-lang="sh"><span># Delete all the source files except for the entrypoint and</span>
<span># root app component</span>
find src -type f -not <span>\(</span> -name <span>'index.js'</span> -or -name <span>'App.js'</span> <span>\)</span> -delete</code></pre></div>
<p>Finally, let’s replace the contents of those two files with the bare minimum we’ll need for this article. From here on out I’ll supply diffs that you can supply to <code>git apply</code> to apply the same changes I did.</p>

<p>First, our entrypoint:</p>
<div><pre><code data-lang="jsx"><span>// src/index.js
</span><span></span><span>import</span> <span>React</span> <span>from</span> <span>"react"</span><span>;</span>
<span>import</span> <span>ReactDOM</span> <span>from</span> <span>"react-dom"</span><span>;</span>
<span>import</span> <span>App</span> <span>from</span> <span>"./App"</span><span>;</span>

<span>ReactDOM</span><span>.</span><span>render</span><span>(&lt;</span><span>App</span> <span>/&gt;,</span> <span>document</span><span>.</span><span>getElementById</span><span>(</span><span>"root"</span><span>));</span></code></pre></div>
<p>Then our main app component:</p>
<div><pre><code data-lang="jsx"><span>// src/App.js
</span><span></span><span>import</span> <span>React</span> <span>from</span> <span>"react"</span><span>;</span>

<span>function</span> <span>App</span><span>()</span> <span>{</span>
  <span>return</span> <span>(</span>
    <span>&lt;</span><span>div</span><span>&gt;</span>
      <span>&lt;</span><span>h1</span><span>&gt;</span><span>My</span> <span>App</span><span>&lt;/</span><span>h1</span><span>&gt;</span>
    <span>&lt;/</span><span>div</span><span>&gt;</span>
  <span>);</span>
<span>}</span>

<span>export</span> <span>default</span> <span>App</span><span>;</span></code></pre></div>
<h3 id="writing-a-react-component">Writing a React component</h3>

<p>Let’s write our first React component: a counter. This is likely the first example of a React component you ever encountered; it’s the first example in the PureScript React libraries as well. It’s also small and simple enough to be replaced twice over the course of this article.</p>

<p>The counter will be a button which maintains the number of times it has been clicked. It will accept, as its only prop, a label to display on the button.</p>
<div><pre><code data-lang="jsx"><span>// src/Counter.js
</span><span></span><span>import</span> <span>React</span> <span>from</span> <span>"react"</span><span>;</span>

<span>class</span> <span>Counter</span> <span>extends</span> <span>React</span><span>.</span><span>Component</span> <span>{</span>
  <span>constructor</span><span>(</span><span>props</span><span>)</span> <span>{</span>
    <span>super</span><span>(</span><span>props</span><span>);</span>
    <span>this</span><span>.</span><span>state</span> <span>=</span> <span>{</span>
      <span>count</span><span>:</span> <span>0</span>
    <span>};</span>
  <span>}</span>

  <span>render</span><span>()</span> <span>{</span>
    <span>return</span> <span>(</span>
      <span>&lt;</span><span>button</span> <span>onClick</span><span>=</span><span>{()</span> <span>=</span><span>&gt;</span> <span>this</span><span>.</span><span>setState</span><span>({</span> <span>count</span><span>:</span> <span>this</span><span>.</span><span>state</span><span>.</span><span>count</span> <span>+</span> <span>1</span> <span>})}</span><span>&gt;</span>
        <span>{</span><span>this</span><span>.</span><span>props</span><span>.</span><span>label</span><span>}</span><span>:</span> <span>{</span><span>this</span><span>.</span><span>state</span><span>.</span><span>count</span><span>}</span>
      <span>&lt;/</span><span>button</span><span>&gt;</span>
    <span>);</span>
  <span>}</span>
<span>}</span>

<span>export</span> <span>default</span> <span>Counter</span><span>;</span></code></pre></div>
<p>Then, we’ll import our new counters into our main application:</p>
<div><pre><code data-lang="diff"><span>--- a/src/App.js
</span><span></span><span>+++ b/src/App.js
</span><span></span><span>@@ -1,9 +1,13 @@
</span><span></span> import React from "react";
<span>+import Counter from "./Counter";
</span><span></span>
 function App() {
   return (
     &lt;div&gt;
       &lt;h1&gt;My App&lt;/h1&gt;
<span>+      &lt;Counter label="Count" /&gt;
</span><span>+      &lt;Counter label="Clicks" /&gt;
</span><span>+      &lt;Counter label="Interactions" /&gt;
</span><span></span>     &lt;/div&gt;
   );
 }
</code></pre></div>
<p>With <code>yarn start</code> we can run the dev server and see our app in action.</p>

<p><img src="https://thomashoneyman.com/images/2019/running-app.gif" alt="running app"></p>



<p>We’ve written entirely too much JavaScript. Let’s support PureScript in this project as well. Our goal is to write code in either language and freely import in either direction without friction. To accomplish that, we will install PureScript tooling, create a separate PureScript source directory, and rely on the compiler to generate JavaScript code.</p>

<h3 id="1-install-the-compiler-and-package-manager">1. Install the compiler and package manager</h3>

<p>First we must install PureScript tooling. I recommend installing versions of the compiler and Spago (a package manager and build tool) which match those used in this article. I’ll use NPX to ensure all commands are run using local copies.</p>
<div><pre><code data-lang="sh"><span># Install the compiler and the Spago package manager however you prefer;</span>
<span># since we're already in a React project I'll use Yarn</span>
yarn add -D purescript@0.13.2 spago@0.8.4</code></pre></div>
<h3 id="2-initialize-the-project-and-package-set">2. Initialize the project and package set</h3>

<p>We can create a new PureScript project with <code>spago init</code>. As of version 0.8.4, Spago always initializes with the same package set, which means you should have identical package versions to those used to write this article. I’m using the <code>psc-0.13.0-20190607</code> package set.</p>
<div><pre><code data-lang="sh"><span># npx ensures we're using our local copy of Spago installed in node_modules.</span>
npx spago init</code></pre></div>
<p>Spago has created a <code>packages.dhall</code> file which points at the set of packages which can be installed and a <code>spago.dhall</code> file which lists the packages we’ve actually installed. We can now install any dependencies we need and we’ll know for sure the versions are all compatible.</p>

<p>Before installing anything, let’s update the existing <code>.gitignore</code> file to cover PureScript. For a Spago-based project this will work:</p>
<div><pre><code data-lang="sh"><span>echo</span> -e <span>"\noutput\n.psc*\n.purs*\.spago"</span> &gt;&gt; .gitignore</code></pre></div>
<h3 id="3-adjust-the-directory-structure">3. Adjust the directory structure</h3>

<p>Finally, let’s organize our source code. It’s typical to separate JavaScript source from PureScript source except when writing an FFI file for PureScript. Since we aren’t doing that in this project, our source files will be entirely separated. Let’s move all JavaScript code into a <code>javascript</code> subdirectory and create a new <code>purescript</code> folder next to it.</p>
<div><pre><code data-lang="sh">mkdir src/javascript src/purescript
mv src/App.js src/Counter.js src/javascript</code></pre></div>
<p>Next, we’ll adjust <code>index.js</code> to the new location of our root component:</p>
<div><pre><code data-lang="diff"><span>--- a/src/index.js
</span><span></span><span>+++ b/src/index.js
</span><span></span><span>@@ -1,5 +1,5 @@
</span><span></span> import React from "react";
 import ReactDOM from "react-dom";
<span>-import App from "./App";
</span><span></span><span>+import App from "./javascript/App";
</span><span></span>
 ReactDOM.render(&lt;App /&gt;, document.getElementById("root"));
</code></pre></div>
<p>We’ve just one task left. The PureScript compiler generates JavaScript into a directory named <code>output</code> in the root of the project. But <code>create-react-app</code> disables importing anything outside the <code>src</code> directory. While there are fancier solutions, for this project we’ll get around the restriction by symlinking the <code>output</code> directory into the <code>src</code> directory.</p>
<div><pre><code data-lang="sh"><span># we can now import compiled PureScript from src/output/...</span>
ln -s <span>$PWD</span>/output <span>$PWD</span>/src</code></pre></div>
<p>Your <code>src</code> directory should now look like this:</p>
<div><pre><code data-lang="sh">src
├── index.js
├── javascript
│ ├── App.js
│ └── Counter.js
├── output -&gt; ../output
└── purescript</code></pre></div>
<h2 id="replacing-a-react-component-with-purescript-react">Replacing a React component with PureScript React</h2>

<p>I like to follow four simple steps when replacing a JavaScript React component with a PureScript one:</p>

<ol>
<li>Write the component in idiomatic PureScript.</li>
<li>Write a separate interop module for the component. This module provides the JavaScript interface and conversion functions between PureScript and JavaScript types and idioms.</li>
<li>Use the PureScript compiler to generate JavaScript</li>
<li>Import the resulting code as if it were a regular JavaScript React component.</li>
</ol>

<p>We’ll start with the <code>react</code> library, which we use at Awake Security. It’s similar to <code>react-basic</code> but maps more directly to the underlying React code and is less opinionated. Later, we’ll switch to <code>react-basic</code>, which will demonstrate some differences between them.</p>

<p>As we take each step in this process I’ll explain more about why it’s necessary and some best practices to keep in mind. Let’s start: install the <code>react</code> library and prepare to write our component:</p>
<div><pre><code data-lang="sh"><span># install the purescript-react library</span>
npx spago install react

<span># build the project so editors can pick up the `output` directory</span>
npx spago build

<span># create the component source file</span>
touch src/purescript/Counter.purs</code></pre></div>
<h3 id="1-write-the-react-component-in-idiomatic-purescript">1. Write the React component in idiomatic PureScript</h3>

<p>Even though we are writing a component to be used from JavaScript, we should still write ordinary PureScript. As we’ll soon see, it’s possible to adjust only the interface of the component for JavaScript but leave the internals untouched. This is especially important if this component is meant to be used by both PureScript and …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thomashoneyman.com/articles/replace-react-components-with-purescript/">https://thomashoneyman.com/articles/replace-react-components-with-purescript/</a></em></p>]]>
            </description>
            <link>https://thomashoneyman.com/articles/replace-react-components-with-purescript/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23636336</guid>
            <pubDate>Thu, 25 Jun 2020 02:40:29 GMT</pubDate>
        </item>
    </channel>
</rss>
