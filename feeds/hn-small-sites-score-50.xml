<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 20 Sep 2020 04:24:19 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 20 Sep 2020 04:24:19 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[How can we, as web professionals, help to make the web more energy efficient?]]>
            </title>
            <description>
<![CDATA[
Score 107 | Comments 223 (<a href="https://news.ycombinator.com/item?id=24513427">thread link</a>) | @giuliomagnifico
<br/>
September 17, 2020 | https://cmhb.de/web-design-and-carbon-impact | <a href="https://web.archive.org/web/*/https://cmhb.de/web-design-and-carbon-impact">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
<section>
    <div><blockquote>
<p>How can we, as web professionals, help to make the web more energy efficient?</p>
</blockquote>
<p>From data centres to transmission networks to the devices that we hold in our hands, it is all consuming electricity, and in turn producing carbon emissions. According to recent estimates, the entire network already consumes 10% of global electricity production, with data traffic doubling roughly every two years. It’s probably something very few people think about, or are even aware of as being an issue. But the fact of the matter is that the Internet consumes a huge amount of electricity. And when it comes to web design, there is a lot that can be done to make the web far more energy efficient.</p>
<hr>
<h2>Attitudes</h2>
<p>Creating a website is a lot more accessible today, made simpler by the emergence of no-code site builders. But it might be asking a lot for your typical web user or amateur creator to be aware of the environmental impact of their site. This, however, shouldn’t really be the case for any digital professional. Naturally, web developers will be more conscious of the weight of their pages, given that they are fully immersed in the code and content management that serves what you see on a web page. But even then, many developers simply look for the quickest route to completing a project, rather than the best way to produce the quickest and most efficient site. </p>
<p>So they load a website with bulky Javascript and third-party tools to meet the visual specification of the client or designer. As long as it works, right? They probably don’t care. They’re probably happy with their site that loads quickly on their 500Mbps connection. Who cares if they’re wasting expensive data on mobile connections in other countries? “But Carl, some of us don’t have the luxury of building super high-performance, lightweight, and optimised sites due to client budgets and deadlines.” Well, I think you need to work on your craft, change your attitude and your priorities, or find another profession.</p>
<p>When we talk about the energy efficiency of websites, it’s easy to assume that it’s a purely technical topic. However, efficiency can be improved before we even build a website. Design and content have a big impact on energy efficiency.</p>
<p>Therefore, some of the biggest contributors to heavy sites and large CO2 emissions, are <em>designers</em>. Large moving imagery, multiple web fonts, animation, sound, autoplaying video, and generally esoteric design is prevalent these days. We see showcase after showcase of the <em>best of the web</em>, where the only criteria is: “Does it look well-designed?” Well, look under the hood. It’s pretty terrifying. And that’s not even getting into the many accessibility concerns. If only more designers would ask themselves, “When was the last time I considered page size when designing something? When was the last time I decided that page weight was more important than aesthetics?” </p>
<p>These are questions I have put to designers before, and the response quite often is, “I’m just experimenting with technologies and trying to improve my UI skills. What harm is there in that?” Well, <em>Site of the Day</em>, the harm is your energy usage, and the likelihood that nobody—besides an echo chamber of fellow designers—give a shit about your over-design. People just want to access content quickly, without distraction, without friction, and without it using a tonne of data. That’s not to say aesthetics aren’t important—they certainly are. The visual design of a site can play a significant role in user experience, readability, and conversion, but as with most things, there is a balance to be achieved. And there is a responsibility to be shared.</p>
<hr>
<h2>Solutions</h2>
<p>Fortunately, there are a growing number of web professionals who do care about the impact sites have on the planet, and there are many solutions designers and developers alike can find to improve their sites without overly compromising their designs. Solutions that I am actively looking into to improve my own work.</p>
<p>So how can we be more energy efficient in web design? Well, the folks over at <a href="https://www.wholegraindigital.com/blog/website-energy-efficiency/">Wholegrain Digital</a> put together a comprehensive list, but here are some key considerations:</p>
<h3>Reduce Images</h3>
<p>The single largest contributors to page weight. The more images, the more data needs to be transferred and the more energy is used. A good starting point is to ask oneself:</p>
<ul>
<li>Does the image genuinely add value to the user?</li>
<li>Does it communicate useful information?</li>
<li>Could the same impact be achieved if the image was smaller?</li>
<li>Could we achieve the same effect with a vector graphic (or even CSS style) instead of a photo?</li>
</ul>
<h3>Optimise Images</h3>
<p>Some designs are focused almost entirely on imagery, in which case optimisation is vital to better performance. There are technical decisions that significantly affect the file size of images displayed on a page. These include:</p>
<ul>
<li>Load images at the correct scale instead of relying on CSS to resize them, so that you avoid loading images that are larger than the scale they will be displayed at.</li>
<li>Use image optimisation tools before you upload them to your site. I personally use <a href="https://imageoptim.com/mac">ImageOptim</a>.</li>
<li>Use the most efficient file format for each image, such as WebP instead of JPEG (although this is not supported by all browsers).</li>
<li>Use image processing tools to resize, crop, and enhance your images that are served. I use <a href="https://www.imgix.com/">imgimx</a> for this, which works well for image-heavy sites such as <a href="https://minimalissimo.com/">Minimalissimo</a>.</li>
</ul>
<h3>Reduce Video</h3>
<p>By far the most data intensive and processing intensive form of content. As with images, ask yourself if videos are really necessary. If they are, never autoplay a video. It creates a much higher load on the users CPU, resulting in vastly greater energy consumption. Plus, it’s annoying as hell. Let the user decide whether or not to play a video.</p>
<h3>Font Selection and Optimisation</h3>
<p>Web fonts can enhance the visual appeal of site designs, as well as improve readability, but they can add significant file weight to the sites on which they are used. A single font file could be as much as 250Kb, and that might only be for the standard weight. If you want bold, add another 250Kb! A couple of options worth considering:</p>
<ul>
<li>Use system fonts where possible.</li>
<li>Use fewer font variations.</li>
<li>Stick to modern web font file formats like WOFF and WOFF2.</li>
<li>Subset fonts to only include the characters needed on the site.</li>
</ul>
<h3>Write Clean Code</h3>
<p>Tidy and streamlined code is a fundamentally good thing. Keep code clean and simple, avoid duplication, and write efficient queries. The code behind the scenes should be a well oiled, lean machine. And I’ll take this opportunity to share a controversial opinion: <em>all designers should learn to code.</em> At least if they want a website. No-code site builders can be very good, but if you’re not aware of the underlying code, then you’ll be less aware of ways to optimise your site.</p>
<h3>Use Less Javascript</h3>
<p>JS impacts website efficiency in two ways: by adding file weight to the web page and by increasing the amount of processing required by the user’s device. The second of these is something that applies to JS much more than to other types of files. Look for ways to achieve front-end interactions, functionality, and animations using more efficient technologies like CSS, or at least use JS efficiently. A particular mention should be given here to tracking and advertising scripts that rarely offer any value to the user, but can add significant file weight. Don’t let advertising get in the way of craftsmanship.</p>
<h3>Use Server Caching</h3>
<p>Using caching technologies such as <a href="https://memcached.org/">Memcached</a> or <a href="https://varnish-cache.org/">Varnish</a> pre-generate static versions of each page so that the server overhead can be significantly reduced for most visitors. This significantly reduces server energy consumption and makes a big difference to page load times. </p>
<h3>SEO</h3>
<p>When optimising a site for search engines, we are helping people find the information they want quickly and easily. When SEO is successful, it results in people spending less time browsing the web looking for information, and visiting fewer pages that don’t meet their needs.</p>
<hr>
<p>No site is perfect, but appreciating that we have a responsibility to produce better digital design for the planet and for users is a good place to start. Web efficiency is an attitude and the result of a mindful approach to building for the web.</p>
<hr>
<h2>Useful Resources</h2>
<ul>
<li><a href="https://www.websitecarbon.com/">Website Carbon</a> (test your site’s carbon footprint)</li>
<li><a href="https://imageoptim.com/mac">ImageOptim</a> (image optimisation tool)</li>
<li><a href="https://www.imgix.com/">imgix</a> (image processing tool)</li>
<li><a href="https://developers.google.com/speed/pagespeed/insights/">Google PageSpeed Insights</a> (test your site’s performance)</li>
<li><a href="https://solar.lowtechmagazine.com/low-tech-solutions.html">Low-tech Solutions</a> (by Low-tech Magazine)</li>
</ul></div>
</section>
    </div></div>]]>
            </description>
            <link>https://cmhb.de/web-design-and-carbon-impact</link>
            <guid isPermaLink="false">hacker-news-small-sites-24513427</guid>
            <pubDate>Fri, 18 Sep 2020 06:02:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Introduction to Data Oriented Design with Rust]]>
            </title>
            <description>
<![CDATA[
Score 398 | Comments 134 (<a href="https://news.ycombinator.com/item?id=24506744">thread link</a>) | @headalgorithm
<br/>
September 17, 2020 | https://jamesmcm.github.io/blog/2020/07/25/intro-dod/ | <a href="https://web.archive.org/web/*/https://jamesmcm.github.io/blog/2020/07/25/intro-dod/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In the post we will investigate the main concepts of <a href="https://en.wikipedia.org/wiki/Data-oriented_design">Data-oriented
Design</a> using Rust.</p>

<p>The source code for this example is <a href="https://github.com/jamesmcm/data-oriented-example">available on Github</a>.</p>

<!--more-->

<h2 id="what-is-data-oriented-design">What is data-oriented design?</h2>

<p>Data-oriented design is an approach to optimising programs by carefully
considering the memory layout of data structures, and their implications
for auto-vectorisation and use of the CPU cache. I highly recommend
watching Mike Acton’s <a href="https://www.youtube.com/watch?v=rX0ItVEVjHc">“Data-Oriented Design and C++”</a> talk
if you haven’t seen it already.</p>

<p>In this post we will cover 4 cases, using <a href="https://docs.rs/criterion/0.3.3/criterion/">criterion</a> for
benchmarking. The cases are:</p>

<ul>
  <li>Struct of arrays vs. array of structs</li>
  <li>The cost of branching inside a hot loop</li>
  <li>Linked List vs. Vector iteration</li>
  <li>The cost of dynamic dispatch vs. monomorphisation</li>
</ul>

<h2 id="struct-of-arrays-vs-array-of-structs">Struct of Arrays vs. Array of Structs</h2>

<p>The <a href="https://en.wikipedia.org/wiki/AoS_and_SoA">Struct of Arrays vs. Array of Structs</a> 
refers to two contrasting ways of organising entity data to be operated
over.</p>

<p>For example, imagine we are writing a video game and we would like to
have a Player struct with the following fields:</p>

<div><div><pre><code><span>pub</span> <span>struct</span> <span>Player</span> <span>{</span>
    <span>name</span><span>:</span> <span>String</span><span>,</span>
    <span>health</span><span>:</span> <span>f64</span><span>,</span>
    <span>location</span><span>:</span> <span>(</span><span>f64</span><span>,</span> <span>f64</span><span>),</span>
    <span>velocity</span><span>:</span> <span>(</span><span>f64</span><span>,</span> <span>f64</span><span>),</span>
    <span>acceleration</span><span>:</span> <span>(</span><span>f64</span><span>,</span> <span>f64</span><span>),</span>
<span>}</span>
</code></pre></div></div>

<p>Then at each frame, we want to update the locations and velocities of all
Players. We could write something like:</p>

<div><div><pre><code><span>pub</span> <span>fn</span> <span>run_oop</span><span>(</span><span>players</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Vec</span><span>&lt;</span><span>Player</span><span>&gt;</span><span>)</span> <span>{</span>
    <span>for</span> <span>player</span> <span>in</span> <span>players</span><span>.iter_mut</span><span>()</span> <span>{</span>
        <span>player</span><span>.location</span> <span>=</span> <span>(</span>
            <span>player</span><span>.location</span><span>.</span><span>0</span> <span>+</span> <span>player</span><span>.velocity</span><span>.</span><span>0</span><span>,</span>
            <span>player</span><span>.location</span><span>.</span><span>1</span> <span>+</span> <span>player</span><span>.velocity</span><span>.</span><span>1</span><span>,</span>
        <span>);</span>
        <span>player</span><span>.velocity</span> <span>=</span> <span>(</span>
            <span>player</span><span>.velocity</span><span>.</span><span>0</span> <span>+</span> <span>player</span><span>.acceleration</span><span>.</span><span>0</span><span>,</span>
            <span>player</span><span>.velocity</span><span>.</span><span>1</span> <span>+</span> <span>player</span><span>.acceleration</span><span>.</span><span>1</span><span>,</span>
        <span>);</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>This would be the usual object-oriented approach to this problem. The
issue here is that in memory the structs are stored as follows (assuming
no field re-ordering i.e. <code>#[repr(C)]</code>), on a 64-bit architecture each field will be 64
bits (8 bytes, so each Player is 64 bytes):</p>

<div><div><pre><code>-- Vec&lt;Player&gt;
name  (pointer to heap)  -- Player 1
health    
location0  (tuple split for clarity) 
location1
velocity0
velocity1
acceleration0
acceleration1
name  (pointer to heap)  -- Player 2
location0    
location1
velocity0
velocity1
acceleration0
acceleration1
...
</code></pre></div></div>

<p>Note the parts we want to operate on (locations, velocities and
accelerations) are not stored contiguously across different Players.
This prevents us from using vector operations to operate on multiple
players at once (since they cannot be loaded in the same CPU cache
line, usually ~64 bytes).</p>

<p>In contrast, the data-oriented approach is to design around this
limitation and optimise for auto-vectorisation. Instead of using a
struct per Player, we now use one struct for all Players and each Player
has their values stored at their index in the separate attribute Vectors:</p>

<div><div><pre><code><span>pub</span> <span>struct</span> <span>DOPlayers</span> <span>{</span>
    <span>names</span><span>:</span> <span>Vec</span><span>&lt;</span><span>String</span><span>&gt;</span><span>,</span>
    <span>health</span><span>:</span> <span>Vec</span><span>&lt;</span><span>f64</span><span>&gt;</span><span>,</span>
    <span>locations</span><span>:</span> <span>Vec</span><span>&lt;</span><span>(</span><span>f64</span><span>,</span> <span>f64</span><span>)</span><span>&gt;</span><span>,</span>
    <span>velocities</span><span>:</span> <span>Vec</span><span>&lt;</span><span>(</span><span>f64</span><span>,</span> <span>f64</span><span>)</span><span>&gt;</span><span>,</span>
    <span>acceleration</span><span>:</span> <span>Vec</span><span>&lt;</span><span>(</span><span>f64</span><span>,</span> <span>f64</span><span>)</span><span>&gt;</span><span>,</span>
<span>}</span>
</code></pre></div></div>

<p>Now we can do the same calculation as in the OOP case as follows:</p>

<div><div><pre><code><span>pub</span> <span>fn</span> <span>run_dop</span><span>(</span><span>world</span><span>:</span> <span>&amp;</span><span>mut</span> <span>DOPlayers</span><span>)</span> <span>{</span>
    <span>for</span> <span>(</span><span>pos</span><span>,</span> <span>(</span><span>vel</span><span>,</span> <span>acc</span><span>))</span> <span>in</span> <span>world</span>
        <span>.locations</span>
        <span>.iter_mut</span><span>()</span>
        <span>.zip</span><span>(</span><span>world</span><span>.velocities</span><span>.iter_mut</span><span>()</span><span>.zip</span><span>(</span><span>world</span><span>.acceleration</span><span>.iter</span><span>()))</span>
    <span>{</span>
        <span>*</span><span>pos</span> <span>=</span> <span>(</span><span>pos</span><span>.</span><span>0</span> <span>+</span> <span>vel</span><span>.</span><span>0</span><span>,</span> <span>pos</span><span>.</span><span>1</span> <span>+</span> <span>vel</span><span>.</span><span>1</span><span>);</span>
        <span>*</span><span>vel</span> <span>=</span> <span>(</span><span>vel</span><span>.</span><span>0</span> <span>+</span> <span>acc</span><span>.</span><span>0</span><span>,</span> <span>vel</span><span>.</span><span>1</span> <span>+</span> <span>acc</span><span>.</span><span>1</span><span>);</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>In this case the memory layout is as follows:</p>
<div><div><pre><code>-- DOPlayers
name1    -- names
name2
...
health1    -- health
health2
...
location1    -- locations
location2
...
</code></pre></div></div>

<p>The relevant fields are now stored contiguously. Given that each
location tuple will be 16 bytes, we could now feasibly load 4 location
tuples on the same cache line to operate on them simultaneously with
SIMD instructions.</p>

<h3 id="benchmark">Benchmark</h3>

<p>Here are the results of the criterion benchmark for the above code (the
full code and benchmark code is available <a href="https://github.com/jamesmcm/data-oriented-example">in the Github repo</a>):</p>

<p><img src="https://jamesmcm.github.io/images/soa.svg" alt="AoS vs. SoA benchmark" title="AoS vs. SoA benchmark"></p>

<p>Overall, we see that the data-oriented approach finishes in half the
time. This would seem to be due to the data-oriented case operating on
two Players at a time - we can confirm this by reviewing the compiled
assembly.</p>

<p>Reviewing the <a href="https://godbolt.org/z/d8bjMb">output on Godbolt</a> we see the following:</p>

<pre><code>// Relevant OOP loop
.LBB0_2:
        movupd  xmm0, xmmword ptr [rax + rdx + 32]
        movupd  xmm1, xmmword ptr [rax + rdx + 48]
        movupd  xmm2, xmmword ptr [rax + rdx + 64]
        addpd   xmm0, xmm1
        movupd  xmmword ptr [rax + rdx + 32], xmm0
        addpd   xmm2, xmm1
        movupd  xmmword ptr [rax + rdx + 48], xmm2
        add     rdx, 80
        cmp     rcx, rdx
        jne     .LBB0_2

// ...
// Relevant DOP loop
.LBB1_7:
        movupd  xmm0, xmmword ptr [rcx + rdx - 16]
        movupd  xmm1, xmmword ptr [rax + rdx - 16]
        addpd   xmm1, xmm0
        movupd  xmmword ptr [rcx + rdx - 16], xmm1
        movupd  xmm0, xmmword ptr [r9 + rdx - 16]
        movupd  xmm1, xmmword ptr [rax + rdx - 16]
        addpd   xmm1, xmm0
        movupd  xmm0, xmmword ptr [rax + rdx]
        movupd  xmmword ptr [rax + rdx - 16], xmm1
        add     rdi, 2
        movupd  xmm1, xmmword ptr [rcx + rdx]
        addpd   xmm1, xmm0
        movupd  xmmword ptr [rcx + rdx], xmm1
        movupd  xmm0, xmmword ptr [rax + rdx]
        movupd  xmm1, xmmword ptr [r9 + rdx]
        addpd   xmm1, xmm0
        movupd  xmmword ptr [rax + rdx], xmm1
        add     rdx, 32
        cmp     rsi, rdi
        jne     .LBB1_7
        test    r8, r8
        je      .LBB1_5
</code></pre>

<p>We can see in the data-oriented case, the loop is unrolled to operate on
two elements at once - resulting in the 50% speed up overall!</p>

<p><strong>Addendum</strong>: As noted by <a href="https://www.reddit.com/r/rust/comments/hxqwom/an_introduction_to_data_oriented_design_with_rust/fz8lxcq/">/u/five9a2 on Reddit</a>
the above output is specifically for the default target, which is
misleading since <code>cargo bench</code> uses the native target by default (i.e.
all possible features on your CPU), so our benchmarks are not using the
above assembly code.</p>

<p>By setting the compiler flag to <code>-C target-cpu=skylake-avx512</code> to enable 
Skylake features, we get the <a href="https://godbolt.org/z/PEPdvn">following output</a>:</p>

<pre><code>// OOP loop
.LBB0_2:
        vmovupd ymm0, ymmword ptr [rax + rdx + 32]
        vaddpd  ymm0, ymm0, ymmword ptr [rax + rdx + 48]
        vmovupd ymmword ptr [rax + rdx + 32], ymm0
        add     rdx, 80
        cmp     rcx, rdx
        jne     .LBB0_2

...
// DOP loop
.LBB1_19:
        vmovupd zmm0, zmmword ptr [rsi + 4*rax - 64]
        vaddpd  zmm0, zmm0, zmmword ptr [rcx + 4*rax - 64]
        vmovupd zmmword ptr [rsi + 4*rax - 64], zmm0
        vmovupd zmm0, zmmword ptr [rcx + 4*rax - 64]
        vaddpd  zmm0, zmm0, zmmword ptr [r10 + 4*rax - 64]
        vmovupd zmmword ptr [rcx + 4*rax - 64], zmm0
        vmovupd zmm0, zmmword ptr [rsi + 4*rax]
        vaddpd  zmm0, zmm0, zmmword ptr [rcx + 4*rax]
        vmovupd zmmword ptr [rsi + 4*rax], zmm0
        vmovupd zmm0, zmmword ptr [rcx + 4*rax]
        vaddpd  zmm0, zmm0, zmmword ptr [r10 + 4*rax]
        vmovupd zmmword ptr [rcx + 4*rax], zmm0
        add     r11, 8
        add     rax, 32
        add     rdi, 2
        jne     .LBB1_19
        test    r9, r9
        je      .LBB1_22
</code></pre>

<p>Here we see the OOP loop making use of the 256-bit ymm registers for the
position tuple and velocity tuple, and another for the velocity tuple
and acceleration tuple. This is possible because they are adjacent in
memory (due to the ordering of the fields). In the DOP loop,
the 512-bit zmm register is used.</p>

<p>It seems the performance differences comes from the bandwidth between
cache levels, since the performance is identical for the small examples.
This can be demonstrated further by removing the extra fields from the
struct - in this case we see only a 25% performance difference (<a href="https://godbolt.org/z/Th91Wa">godbolt
link</a>), and this
corresponds to Player struct now being 384 bits (and so 1/4 of the
512-bit read/write is unused).</p>

<p>This emphasises how important it is to consider your deployment target,
and if deploying performance-sensitive code, to consider setting the
target-cpu explicitly to benefit from all of its features.</p>

<p>It also demonstrates how the ordering of fields can be important to
performance. By default Rust will re-order fields automatically, but you can set
<code>#[repr(C)]</code> to disable this (necessary for C interoperability for
example).</p>

<h3 id="summary">Summary</h3>

<p>This example demonstrates the importance of considering memory layout
when aiming for performant code and auto-vectorisation.</p>

<p>Note that the same logic can also apply when working with arrays of
structs - making your struct smaller will allow you to load more
elements on the same cache line and possibly lead to autovectorisation.
<a href="https://github.com/Rene-007/flake_growth/blob/master/src/helpers.rs">Here is an example</a> of
a crate (which was shared on the <a href="https://www.reddit.com/r/rust/comments/hmqjvs/growing_gold_with_rust/">Rust subreddit</a>) that achieved a 40% performance
improvement by doing just that.</p>

<p>This particular re-organisation has a direct analogue in database design. A
major difference between databases aimed at transactional (OLTP)
workloads and analytical (OLAP) workloads is that the latter tend to use
columnar-based storage. Just like the case above, this means that
operations on one column can take advantage of the contiguous storage
and use vector operations, which tends to be the main access pattern for
analytical workloads (e.g. calculate the average purchase size across all rows,
rather than updating and retrieving entire, specific rows).</p>

<p>In the case of analytical databases this is actually a double win, since it also
applies to the serialisation of the data to disk, where compression can
now be applied along the column (where the data is guaranteed to be of the
same type) leading to much better compression ratios.</p>

<p>If you are working on a problem that might benefit from the struct of
arrays approach, and want to run a quick benchmark, you might be
interested in the <a href="https://github.com/lumol-org/soa-derive">soa-derive</a>
crate that will allow you to derive the struct of arrays from your
struct.</p>

<h2 id="branching-in-a-hot-loop">Branching in a hot loop</h2>

<p>Another optimisation tactic is to avoid branching in any “hot” parts of
the code (i.e. any part that will be executed many, many times).</p>

<p>Branching can arise in subtle ways, often by trying to use one struct for many
different cases. For example, we might define some general Node type …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jamesmcm.github.io/blog/2020/07/25/intro-dod/">https://jamesmcm.github.io/blog/2020/07/25/intro-dod/</a></em></p>]]>
            </description>
            <link>https://jamesmcm.github.io/blog/2020/07/25/intro-dod/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24506744</guid>
            <pubDate>Thu, 17 Sep 2020 16:34:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thinking Clearly About Correlations and Causation (2018) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 61 | Comments 10 (<a href="https://news.ycombinator.com/item?id=24506243">thread link</a>) | @Anon84
<br/>
September 17, 2020 | https://dacemirror.sci-hub.tw/journal-article/7fe084d6885f9339910bf080b718c012/rohrer2018.pdf?download=true | <a href="https://web.archive.org/web/*/https://dacemirror.sci-hub.tw/journal-article/7fe084d6885f9339910bf080b718c012/rohrer2018.pdf?download=true">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://dacemirror.sci-hub.tw/journal-article/7fe084d6885f9339910bf080b718c012/rohrer2018.pdf?download=true</link>
            <guid isPermaLink="false">hacker-news-small-sites-24506243</guid>
            <pubDate>Thu, 17 Sep 2020 15:58:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Favorite Rust Function Signature]]>
            </title>
            <description>
<![CDATA[
Score 234 | Comments 111 (<a href="https://news.ycombinator.com/item?id=24505436">thread link</a>) | @brundolf
<br/>
September 17, 2020 | https://www.brandonsmith.ninja/blog/favorite-rust-function | <a href="https://web.archive.org/web/*/https://www.brandonsmith.ninja/blog/favorite-rust-function">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemprop="articleBody">
      

      

      

      


      <p>I've gotten really into writing parsers lately, and Rust has turned out to be
        the perfect language for that. In the course of my adventures, I came up with
        the following:</p>
      <pre><code><span>fn</span> tokenize<span>&lt;</span><span>'a</span><span>&gt;</span><span>(</span>code<span>:</span> <span>&amp;</span><span>'a</span> str<span>)</span> <span>-&gt;</span> <span>impl</span> Iterator<span>&lt;</span>Item<span>=</span><span>&amp;</span><span>'a</span> str<span>&gt;</span> <span>{</span>
  <span>...</span>
<span>}</span>
</code></pre>
      <p>and it really deepened my appreciation for Rust.</p>
      <h2 id="what-does-this-function-do%3F">What does this function do? </h2>
      <p>For those not familiar with parsing, tokenization is the first step of the
        process. It takes a raw code string, like this:</p>
      <pre><code>let a = "foo";
</code></pre>
      <p>and turns it into a linear series of meaningful tokens, like so:</p>
      <pre><code>["let", "a", "=", "\"foo\"", ";"]
</code></pre>
      <p>This phase isn't terribly complicated, but it simplifies the mental model for
        the next pass: constructing an "abstract syntax tree". It removes whitespace
        from the equation, bundles up segments like strings and numbers, and just
        generally makes the code in the next pass cleaner.</p>
      <p>The downside is that, if you perform this as a separate pass, your parser now
        has to iterate over all of the source code <em>twice</em>. This may not be the end of
        the world: tokenizing isn't the most expensive operation. But it isn't ideal,
        so some parsers combine the two passes into a single one, saving cycles at the
        expense of readability.</p>
      <h2 id="what's-going-on-in-the-rust-version%3F">What's going on in the Rust version? </h2>
      <p>I'll copy the signature here again for reference:</p>
      <pre><code><span>fn</span> tokenize<span>&lt;</span><span>'a</span><span>&gt;</span><span>(</span>code<span>:</span> <span>&amp;</span><span>'a</span> str<span>)</span> <span>-&gt;</span> <span>impl</span> Iterator<span>&lt;</span>Item<span>=</span><span>&amp;</span><span>'a</span> str<span>&gt;</span> <span>{</span>
  <span>...</span>
<span>}</span>
</code></pre>
      <p>There are several things going on here.</p>
      <p><code>&amp;str</code>, in Rust, is a "string slice". It's effectively a character pointer and a
        length. The contents of the slice are guaranteed to be in valid, alive memory.
        <code>&amp;'a str</code> is a string slice <em>with a lifetime</em>. The lifetime <code>'a</code>, to be
        exact. This lifetime describes a limited span of time in which the
        reference (and the full contents of the slice) are guaranteed to be in valid,
        alive memory. More on this later.</p>
      <p><code>Iterator&lt;Item=&amp;'a str&gt;</code> is an iterator over elements of type <code>&amp;'a str</code>. This
        is a <em>trait</em>, though, not a concrete type. Rust needs a concrete type with a
        fixed size when you're defining something like a function, but luckily we can
        say <code>impl Iterator&lt;Item=&amp;'a str&gt;</code>, which tells Rust, "fill in some type that
        implements <code>Iterator&lt;Item=&amp;'a str&gt;</code>, to be inferred at compile-time". This is
        very helpful because in Rust there are lots and lots of different concrete types
        for <code>Iterator</code>; applying something like a <code>map()</code> or a <code>filter()</code> returns a whole
        new concrete type. So this way, we don't have to worry about keeping the
        function signature up to date as we work on the logic.</p>
      <h2 id="so-what's-so-great-about-all-this%3F">So what's so great about all this? </h2>
      <p>Okay, so we have a function that takes a reference to a string slice and returns
        an iterator over string slices. Why's that special? There are two reasons.</p>
      <h3 id="iterators-let-you-treat-one-pass-like-it's-two">Iterators let you treat one pass like it's two </h3>
      <p>Remember how I said you traditionally have to pick between doing a separate
        tokenization pass, and doing a single pass with all the logic interleaved? With
        an iterator, you can have the best of both worlds.</p>
      <p>When this function completes, it hasn't yet iterated over the string. It hasn't
        allocated any kind of collection in memory. It returns a structure that's
        <em>prepared</em> to iterate over the input string slice and produce a sequence of new
        slices. When this value later gets <code>map()</code>ed into something else, or
        <code>filter()</code>ed, or any other <code>Iterator</code> transformations get applied, the stages
        of the process get interleaved, and the "loops" effectively get folded into a
        single one. By doing this, we're able to get the clean abstraction of a
        tokenizing "pass" without the runtime overhead of a second loop!</p>
      <p>But other languages have iterators. Rust's may be extra powerful and ergonomic,
        but they aren't a totally unique feature. The next part is very much unique to
        Rust.</p>
      
      <p>The <code>tokenize()</code> function doesn't allocate any new memory for a collection of
        tokens. That's great. But what may be less obvious is that it <em>also</em> doesn't
        allocate any memory for the tokens themselves! Each string slice representing a
        token is a <em>direct pointer to part of the original string</em>.</p>
      <p>You can do this in C/C++, of course, but there's a danger: if those tokens are
        ever accessed after the original code string has been freed, you'll have a
        memory error.</p>
      <p>For example: let's say you open a file and load the source code from it, and
        store the result in a local variable. Then you <code>tokenize()</code> it and send the
        tokens on to somewhere else outside of the function where the original string
        lived. Voilà, you've got a <a href="https://en.wikipedia.org/wiki/Dangling_pointer">use-after-free error</a>.</p>
      <p>One way to guard against this is by copying each string segment into a <em>new</em>
        string, allocated on the heap, which allows you to safely pass it on after the
        original string is gone. But this comes with a cost: creating, copying, and
        eventually disposing of each of those new strings takes time (and memory). Code
        down the line also has to be aware that it's responsible for de-allocating those
        strings, otherwise they'll leak.</p>
      <p>This is where the magic of lifetimes comes into play.</p>
      <p>Rust prevents the above situation entirely. Normally, though, to accomplish this
        a <code>&amp;str</code> coming into a function from elsewhere must be assumed to be <em>static</em>,
        or to be alive for the entire duration of the program's execution. This is the
        status assigned to, for example, a string literal that you've manually entered
        into your Rust code. Rust doesn't know, in the context of the function, how
        long that reference will be valid, so it must be pessimistic.</p>
      <p><strong>But.</strong> That little <code>'a</code> says: "these things all live for the same span of time". We
        can <em>assert</em> that the original source code string lives at least as long as the
        <em>tokens</em> that reference it. By doing so, Rust can reason about whether or not
        those resulting token references are valid at a given point, and therefore
        doesn't have to assume them to be static! We can do <em>whatever we want</em> with
        those tokens and the compiler will guarantee that they always point to something
        valid, even if the source code is loaded in dynamically at runtime (from a file
        or otherwise). If we find out later via a compiler error that they really do
        need to outlive the source string, then we can copy them ("take ownership") at
        that point. If the compiler doesn't force us to do so, we know we're safe,
        and we know we can continue using the most efficient possible approach,
        <em>fearlessly</em>.</p>
      <p>What we've effectively done is written the most optimistic possible function
        (in terms of memory safety), with no downsides, because the Rust compiler will
        tell us if we're misusing it and force us to then "step down" to whatever level
        of extra accommodation is needed.</p>
      <h2 id="conclusion">Conclusion </h2>
      <p>I've been using (and loving) Rust for about a year and a half now. And there are
        many things to love, but when I got this function working I immediately saw it
        as a microcosm of what really sets the language apart. This is something that
        you <strong>cannot do</strong> both a) this safely and b) this efficiently <strong>in any other
language</strong>. This is the power of Rust.</p>


    </article></div>]]>
            </description>
            <link>https://www.brandonsmith.ninja/blog/favorite-rust-function</link>
            <guid isPermaLink="false">hacker-news-small-sites-24505436</guid>
            <pubDate>Thu, 17 Sep 2020 15:00:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Shutting Down NavHere]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 31 (<a href="https://news.ycombinator.com/item?id=24505232">thread link</a>) | @jermaustin1
<br/>
September 17, 2020 | https://jeremyaboyd.com/post/shutting-down-navhere | <a href="https://web.archive.org/web/*/https://jeremyaboyd.com/post/shutting-down-navhere">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <div>
            <div>
                <div>
                    <p>So over the last few weeks and months, I have made the not-so-easy decision to shut down NavHere. It was a product both birthed and killed by a change to GoDaddy's domain forwarding service.</p>
<p>GoDaddy, for all it's faults had a really decent domain/link forwarding and masking product, and best of all it was FREE. This all changed in 2018 with a series of changes that eventually broke domain forwarding. If you forwarded your domain, you would lose your path, if you had link forwarding enabled, you couldn't forward the domain, and if you had domain masking, you would again, lose the path.</p>
<p>I had multiple domains utilizing this, and my buddy's Austin's domain stopped forwarding to his university professor page.</p>
<p>When we realized what happened, we built NavHere, a "highly available" (failover-able with floating IP, but not balanced), vanity domain and link forwarding service. </p>
<p>I built out the infrastructure on Digital Ocean </p>
<ul>
<li>1 web application server (for the domain administration)</li>
<li>2 forwarding servers (1 primary - 1 failover with floating IP - and it was imaged so spinning up a new one took 30 seconds)</li>
<li>a 3-node cluster of database servers. </li>
</ul>
<p>All together it only cost about $55/mo to host, so figuring I only need 10 signups a month to cover the cost, I went off to the GoDaddy support forums where everyone was complaining to start letting people know... and got banned ALMOST immediately. A handful of people did see those posts, though and were the first to sign up. A couple of them even PAID! I just KNEW I was on my way to a million dollars in ARR. Then silence.</p>
<p>A couple of weeks after launching, I decided to reach out to a former manager and sell them on it. I knew they were paying around $15k per month for a similar service, and secured an "SMS of Intent" from my former manager stating they would switch over to us providing we gave them an API to manage their domains and links. </p>
<p><strong>Yes! Profitability here we come!</strong></p>
<p>In the couple of weeks from that initial enthusiasm to when I finally secured and exposed the internal API, my former manager left the company. There had been a series layoffs, budget freezes, and an emphases on outsourcing. So even though NavHere would have saved them $162k/year, there was no one there who would/could approve it. Again back to square one. With only a few paying customers, and still losing around $40/mo (a tiny rounding error, no doubt, but still, a loss).</p>
<p>By the end of  2018, we had hundreds of free-trial users, and were serving 100s of thousands of forwarding requests each day. But we had only converted a few paying customers (it was in the low 10s of paying customers), and most of those sales were VERY hands on. I was having to explain DNS to small business owners who all they know is their GoDaddy stopped working. It would some times take over a week from when they first contacted to when they had finally set up their DNS records, and another week before they would set up their DNS records <strong>correctly</strong>, and all of that for only $9/year. It wasn't sustainable. </p>
<p><strong>It wasn't fun.</strong></p>
<p>And then, <strong>as quickly as they broke it</strong>, in mid 2019, GoDaddy decided they were tired of people complaining and fixed/reverted/whatever the breaking changes they made, and since then, we have not had a single new paying customer sign up (rightly so, I feel). And now, all but a couple of paying customers have left - I hope back to GoDaddy's free domain forwarding.</p>
<p>So with that, I have decided to shut down NavHere effective 2020-10-31. </p>
<p>I know I said it wasn't fun, but <strong>that is a lie</strong>. Anytime you build something that is useful to someone, it <strong>IS</strong> fun. What becomes less fun is the after-building part of running the business.</p>
<p>It <strong>was</strong> fun; it <strong>was</strong> exciting; but NavHere is <strong>no longer needed</strong>. And that <strong>is</strong> sad.</p>

                </div>
            </div>
        </div>
    </article></div>]]>
            </description>
            <link>https://jeremyaboyd.com/post/shutting-down-navhere</link>
            <guid isPermaLink="false">hacker-news-small-sites-24505232</guid>
            <pubDate>Thu, 17 Sep 2020 14:45:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[UK government’s plans to regulate the internet are a threat to free speech]]>
            </title>
            <description>
<![CDATA[
Score 225 | Comments 176 (<a href="https://news.ycombinator.com/item?id=24505074">thread link</a>) | @timthorn
<br/>
September 17, 2020 | https://freespeechunion.org/why-the-governments-plans-to-regulate-the-internet-are-a-threat-to-free-speech/ | <a href="https://web.archive.org/web/*/https://freespeechunion.org/why-the-governments-plans-to-regulate-the-internet-are-a-threat-to-free-speech/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-17831" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">

	
	
<div>

	
	<!-- .entry-header -->

	
	<div itemprop="text">

		
		
<p>Dr Radomir Tylecote</p>



<p>September 2020</p>



<p><a href="https://freespeechunion.org/fsu-briefing-online-harms/">Full Report</a><br><a href="https://www.gofundme.com/f/the-free-speech-union-fighting-fund">GoFundMe appeal</a></p>



<figure><div>
<p><iframe title="How the Government’s plans to regulate the internet are a threat to free speech" width="1200" height="675" src="https://www.youtube.com/embed/CQac6mzC444?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
</div></figure>







<h3>The Government’s proposed new internet regulator will infringe free speech</h3>



<p>The Government published the Online Harms White Paper in April 2019 and intends to put a Bill before Parliament next year. The proposals aim to make the UK “the safest place in the world to go online”, but they will seriously infringe free speech.</p>



<p>Some of the harms the White Paper identifies are real, including distributing images of child abuse and online activities by terrorists. But these would be better dealt with by simpler legislation and more resources for law enforcement.</p>



<p>However, some of the harms the White Paper describes are vague, such as “unacceptable content” and “disinformation”. These are not fixed but would be determined by a future regulator. This will lead to sweeping censorship. Online Harms does not even properly define “harm”, so the definition risks being outsourced to activists and lobby groups.</p>



<p>A proposed new regulator will even have the power to censor lawful content: the government says new regulation should prohibit material “that may directly or indirectly cause harm” even if “not necessarily illegal”. The Government also singled out “offensive material”, as if giving offence is a harm the public should be protected from by the state.</p>



<h3>The proposals move the UK towards the internet laws of China, Russia and Belarus</h3>



<p>The Government’s proposals are partly inspired by Germany’s 2017 “NetzDG” internet law, but Human Rights Watch has called for Germany to scrap the law, saying it “turns internet companies into censors”. President Lukashenko of Belarus, Vladimir Putin’s United Russia Party and the Venezuelan government have cited NetzDG as the model for their online laws.</p>



<p>Our government’s plans also bear a worrying similarity to Beijing’s internet censorship policies. Beijing censors “rumours” because they cause “social harms”. Our government’s proposals describe “disinformation” as “harmful”, and will make “content which has been disputed by reputable fact-checking services less visible to users”, forcing companies to promote “authoritative news sources”. This contradicts our government’s claim that “the regulator will not be responsible for policing truth and accuracy online”.</p>



<p>While the authors of the White Paper believe their proposals will mean more “tolerance” and less “hate”, they will likely have the opposite effect, as people respond angrily to censorship and conspiracy theorists enjoy the cachet of being banned by the state.</p>



<p>In this briefing we outline the Government’s Online Harms plans and explain why they are a danger to freedom of speech. Later this year, the Free Speech Union will propose alternative regulation to protect the vulnerable without jeopardising free speech.</p>



<p><a href="https://freespeechunion.org/fsu-briefing-online-harms/">Full Report</a><br><a href="https://www.gofundme.com/f/the-free-speech-union-fighting-fund">GoFundMe appeal</a></p>



<p><em>FSU research papers are designed to promote discussion of free speech issues. As with all FSU publications, the views expressed are those of the author(s) and not those of the FSU, its directors, Advisory Councils or other senior staff.</em></p>

		
		
			</div><!-- .entry-content .clear -->
</div>

	
</article></div>]]>
            </description>
            <link>https://freespeechunion.org/why-the-governments-plans-to-regulate-the-internet-are-a-threat-to-free-speech/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24505074</guid>
            <pubDate>Thu, 17 Sep 2020 14:31:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Data-Oriented Programming in Python]]>
            </title>
            <description>
<![CDATA[
Score 68 | Comments 14 (<a href="https://news.ycombinator.com/item?id=24504947">thread link</a>) | @jbredeche
<br/>
September 17, 2020 | https://www.moderndescartes.com/essays/data_oriented_python/ | <a href="https://web.archive.org/web/*/https://www.moderndescartes.com/essays/data_oriented_python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
	

<p> Originally posted 2020-09-13</p>
<p> Tagged: <a href="https://www.moderndescartes.com/essays/tags/optimization">optimization</a>, <a href="https://www.moderndescartes.com/essays/tags/computer_science">computer_science</a>, <a href="https://www.moderndescartes.com/essays/tags/python">python</a></p>
<p> <em>Obligatory disclaimer: all opinions are mine and not of my employer </em></p>
<hr>

<p>Many users of Python deprioritize performance in favor of soft benefits like ergonomics, business value, and simplicity. Users who prioritize performance typically end up on faster compiled languages like C++ or Java.</p>
<p>One group of users is left behind, though. The scientific computing community has lots of raw data they need to process, and would very much like performance. Yet, they struggle to move away from Python, because of network effects, and because Python’s beginner-friendliness is appealing to scientists for whom programming is not a first language. So, how can Python users achieve some fraction of the performance that their C++ and Java friends enjoy?</p>
<p>In practice, scientific computing users rely on the NumPy family of libraries e.g.&nbsp;NumPy, SciPy, TensorFlow, PyTorch, CuPy, JAX, etc.. The sheer proliferation of these libraries suggests that the NumPy model is getting something right. In this essay, I’ll talk about what makes NumPy so effective, and where the next generation of Python numerical computing libraries (e.g.&nbsp;TensorFlow, PyTorch, JAX) seems to be headed.</p>
<h2 id="data-good-pointers-bad">Data good, pointers bad</h2>
<p>A pesky fact of computing is that computers can compute far faster than we can deliver data to compute on. In particular, data transfer <em>latency</em> is the Achille’s heel of data devices (both RAM and storage). Manufacturers disguise this weakness by emphasizing improvements in data transfer <em>throughput</em>, but latency continues to stagnate. Ultimately, this means that any chained data access patterns, where one data retrieval must be completed before the next may proceed, are the worst case for computers.</p>
<p>These worst-case chained data access patterns are unfortunately quite common – so common that they have a name you may be familiar with: a pointer.</p>
<p>Pointers have always been slow. In the ’80s and ’90s, our hard drives were essentially optimized record players, with a read head riding on top of a spinning platter. These hard drives had physical limitations: The disk could only spin so fast without shattering, and the read head was also mechanical, limiting its movement speed. Disk seeks were slow, and the programs that were most severely affected were databases. Some ways that databases dealt with these physical limitations are:</p>
<ul>
<li>Instead of using binary trees (requiring <span>\(\log_2 N\)</span> disk seeks), B-trees with a much higher branching factor <span>\(k\)</span> were used, only requiring <span>\(\log_k N\)</span> disk seeks.</li>
<li>Indices were used to query data without having to read the full contents of each row.</li>
<li>Vertically-oriented databases optimized for read-heavy workloads (e.g.&nbsp;summary statistics over one field, across entire datasets), by reorganizing from <a href="https://en.wikipedia.org/wiki/AoS_and_SoA">arrays of structs to structs of arrays</a>. This maximized effective disk throughput, since no extraneous data was loaded.</li>
</ul>
<p>Today, compute speed is roughly <span>\(10^5 - 10^6\)</span> times faster than in 1990. Today, RAM is roughly <span>\(10^5\)</span> times faster than HDDs from 1990. I was amused and unsurprised to find that Raymond Hettinger’s <a href="https://www.youtube.com/watch?v=npw4s1QTmPg">excellent talk on the evolution of Python’s in-memory <code>dict</code> implementation</a> plays out like a brief history of early database design. Time, rather than healing things, has only worsened the compute-memory imbalance.</p>
<h2 id="numpys-optimizations">NumPy’s optimizations</h2>
<h3 id="boxing-costs">Boxing costs</h3>
<p>In many higher-level languages, raw data comes in boxes containing metadata and a pointer to the actual data. In Python, the PyObject box holds reference counts, so that the garbage collector can operate generically on all Python entities.</p>
<p>Boxing creates two sources of inefficiency:</p>
<ul>
<li>The metadata bloats the data, reducing the data density of our expensive memory.</li>
<li>The pointer indirection creates another round trip of memory retrieval latency.</li>
</ul>
<p>A NumPy array can hold many raw data within a single PyObject box, <em>provided that all of those data are of the same type</em> (int32, float32, etc.). By doing this, NumPy amortizes the cost of boxing over multiple data.</p>
<p>In <a href="https://www.moderndescartes.com/essays/deep_dive_mcts">my previous investigations into Monte Carlo tree search</a>, a naive UCT implementation performed poorly because it instantiated millions of UCTNode objects whose sole purpose was to hold a handful of float32 values. In the optimized UCT implementation, these nodes were replaced with NumPy arrays, reducing memory usage by a factor of 30.</p>
<h3 id="attribute-lookup-function-dispatch-costs">Attribute lookup / function dispatch costs</h3>
<p>Python’s language design forces an unusually large amount of pointer chasing. I mentioned boxing as one layer of pointer indirection, but really it’s just the tip of the iceberg.</p>
<p>Python has no problem handling the following code, even though each of these multiplications invokes a completely different implementation.</p>
<pre><code>&gt;&gt;&gt; mixed_list = [1, 1.0, 'foo', ('bar',)]
&gt;&gt;&gt; for obj in mixed_list:
...     print(obj * 2)

2
2.0
'foofoo'
('bar', 'bar')</code></pre>
<p>Python accomplishes this with a minimum of two layers of pointer indirection:</p>
<ol type="1">
<li>Look up the type of the object.</li>
<li>Look up and execute the <code>__mul__</code> function from that type’s operation registry.</li>
</ol>
<p>Additional layers of pointer indirection may be required if the <code>__mul__</code> method is defined on a superclass: the chain of superclasses must be traversed, one pointer at a time, until an implementation is found.</p>
<p>Attribute lookup is similarly fraught; <code>@property</code>, <code>__getattr__</code>, and <code>__getattribute__</code> provide users with flexibility that incurs pointer chasing overhead with something as simple as executing <code>a.b</code>. Access patterns like <code>a.b.c.d</code> create exactly the chained data access patterns that are a worst-case for data retrieval latency.</p>
<p>To top it all off, merely <em>resolving</em> the object is expensive: there’s a stack of lexical scopes (local, nonlocal, then global) that are checked in order to find the variable name. Each check requires a dictionary lookup, another source of pointer indirection.</p>
<p>As the saying goes: “We can solve any problem by introducing an extra level of indirection… except for the problem of too many levels of indirection”. The NumPy family of libraries deals with this indirection, not by removing it, but again by sharing its cost over multiple data.</p>
<pre><code>&gt;&gt;&gt; homogenous_array = np.arange(5, dtype=np.float32)
&gt;&gt;&gt; multiply_by_two = homogenous_array * 2
&gt;&gt;&gt; print(multiply_by_two)
array([ 0.,  2.,  4.,  6.,  8.], dtype=float32)</code></pre>
<p>Sharing a single box for multiple data allows NumPy to retain the expressiveness of Python while minimizing the cost of the dynamism. As before, this works because of the additional constraint that all data in a NumPy array must have identical type.</p>
<h2 id="the-frontier-jit">The Frontier: JIT</h2>
<p>So far, we’ve seen that NumPy doesn’t solve any of Python’s fundamental problems when it comes to pointer overhead. Instead, it merely puts a bandaid on the problem by sharing those costs across multiple data. It’s a pretty successful strategy – in my hands (<a href="https://www.moderndescartes.com/essays/vectorized_pagerank">1</a>, <a href="https://www.moderndescartes.com/essays/deep_dive_mcts">2</a>), I find that NumPy can typically achieve 30-60x speedups over pure Python solutions to dense numerical code. However, given that C code typically achieves <a href="https://www.moderndescartes.com/essays/data_oriented_python/(https://benchmarksgame-team.pages.debian.net/benchmarksgame/fastest/python3-gcc.html)">100-200x performance</a> over pure Python on dense numerical code (common in scientific computing), it would be nice if we could further reduce the Python overhead.</p>
<p>Tracing <a href="https://en.wikipedia.org/wiki/Just-in-time_compilation">JITs</a> promise to do exactly this. Roughly, the strategy is to trace the execution of the code and record the pointer chasing outcomes. Then, when you call the same code snippet, reuse the recorded outcomes! NumPy amortizes Python overhead over multiple data, and JIT amortizes Python overhead over multiple function calls.</p>
<p>(I should note that I’m most familiar with the tracing JITs used by TensorFlow and JAX. <a href="https://doc.pypy.org/en/latest/">PyPy</a> and <a href="https://numba.pydata.org/">Numba</a> are two alternate JIT implementations that have a longer history, but I don’t know enough about them to treat them fairly, so my apologies to readers.)</p>
<p>Tracing unlocks many wins typically reserved for compiled languages. For example, once you have the entire trace in one place, operations can be fused together (e.g., to make use of the <a href="https://en.wikipedia.org/wiki/FMA_instruction_set">fused multiply-add instructions</a> common to most modern computers), memory layouts can be optimized, and so on. TensorFlow’s <a href="https://www.tensorflow.org/guide/graph_optimization">Grappler</a> is one such implementation of this idea. Traces can also be <a href="https://en.wikipedia.org/wiki/Backpropagation">walked backwards</a> to automatically compute derivatives. Traces can be compiled for different hardware configurations, so that the same Python code executes on CPU, GPU, and TPU. JAX can <a href="https://jax.readthedocs.io/en/latest/notebooks/quickstart.html#Auto-vectorization-with-vmap">autovectorize traces</a>, adding a batch dimension to all operations. Finally, a trace can be exported in a language-agnostic manner, allowing a program defined in Python to be executed in <a href="https://www.tensorflow.org/js">Javascript</a>, <a href="https://www.tensorflow.org/tfx/guide/serving">C++</a>, or more.</p>
<p>Unsurprisingly, there’s a catch to all this. NumPy can amortize Python overhead over multiple data, but only if that data is the same type. JIT can amortize Python overhead over multiple function calls, but only if the function calls would have resulted in the same pointer chasing outcomes. Retracing the function to verify this would defeat the purpose of JIT, so instead, TensorFlow/JAX JIT uses array shape and dtype to guess at whether a trace is reusable. This heuristic is necessarily conservative, rules out otherwise legal programs, often requires unnecessarily specific shape information, and doesn’t make any guarantees against mischievous tinkering. Furthermore, data-dependent tracing is a known issue (<a href="https://pytorch.org/docs/stable/generated/torch.jit.trace.html">1</a>, <a href="https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html#python-control-flow-+-JIT">2</a>). I worked on <a href="https://blog.tensorflow.org/2018/07/autograph-converts-python-into-tensorflow-graphs.html">AutoGraph</a>, a tool to address data-dependent tracing. Still, the engineering benefits of a shared tracing infrastructure are too good to pass up. I expect to see JIT-based systems flourish in the future and iron out their user experience.</p>
<h2 id="conclusion">Conclusion</h2>
<p>The NumPy API’s specifically addresses Python’s performance problems for the kinds of programs that scientific computing users want to write. It encourages users to write code in ways that minimize pointer overhead. Coincidentally, this way of writing code is a fruitful abstraction for tracing JITs targeting vastly parallel computing architectures like GPU and TPU. (Some people argue that <a href="https://dl.acm.org/citation.cfm?id=3321441">machine learning is stuck in a rut</a> due to this NumPy monoculture.) In any case, tracing JITs built on top of …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.moderndescartes.com/essays/data_oriented_python/">https://www.moderndescartes.com/essays/data_oriented_python/</a></em></p>]]>
            </description>
            <link>https://www.moderndescartes.com/essays/data_oriented_python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24504947</guid>
            <pubDate>Thu, 17 Sep 2020 14:21:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Retro Unix Operating System]]>
            </title>
            <description>
<![CDATA[
Score 79 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24504891">thread link</a>) | @elvis70
<br/>
September 17, 2020 | https://www.singlix.com/runix | <a href="https://web.archive.org/web/*/https://www.singlix.com/runix">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div width="390">

            
<p>
<span lang="en-us"><span face="Arial" color="#003366" size="2">
Retro UNIX 8086 v1 operating system has been developed by Erdogan Tan as a 
special purposed derivation of original UNIX v1 (by Ken Thompson, 1970-1972).</span></span></p>

<p>
<span face="Arial" color="#003366" size="2"><span lang="en-us">Source code has 
been ported from PDP-11 Unix assembler syntax to Microsoft Macro Assembler 
(INTEL x86 real mode) syntax and original unix source code has been modified for 
IBM PC/AT compatibility with standard ROM BIOS functions, without 
dropping/removing original UNIX v1 multitasking (time-sharing) features.</span></span></p>

<p><span lang="en-us">
<span face="Arial" size="2" color="#003366">Retro UNIX 386 v1 is 32 bit (80386 
protected mode) version of Retro UNIX 8086 v1. Retro UNIX 386 v1 operating 
system kernel and binaries have been written in assembly language syntax of 
Netwide Assembler (NASM). </span>
</span></p>

<p>
<span face="Arial" color="#003366" size="2"><span lang="en-us">Retro UNIX is a 
predecessor to SINGLIX operating system project.<br>
&nbsp;</span></span></p>
            </div></div>]]>
            </description>
            <link>https://www.singlix.com/runix</link>
            <guid isPermaLink="false">hacker-news-small-sites-24504891</guid>
            <pubDate>Thu, 17 Sep 2020 14:16:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Toward a Technological Cage for the Masses]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 74 (<a href="https://news.ycombinator.com/item?id=24503179">thread link</a>) | @sT370ma2
<br/>
September 17, 2020 | https://cheapskatesguide.org/articles/techno-cage.html | <a href="https://web.archive.org/web/*/https://cheapskatesguide.org/articles/techno-cage.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://cheapskatesguide.org/articles/techno-cage.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24503179</guid>
            <pubDate>Thu, 17 Sep 2020 11:05:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Is 1 World Trade Center Missing from Spider-Man?]]>
            </title>
            <description>
<![CDATA[
Score 170 | Comments 114 (<a href="https://news.ycombinator.com/item?id=24502706">thread link</a>) | @tosh
<br/>
September 17, 2020 | https://www.stevenbuccini.com/why-1wtc-isnt-in-spiderman | <a href="https://web.archive.org/web/*/https://www.stevenbuccini.com/why-1wtc-isnt-in-spiderman">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Like many people across the world, I’m using my quarantine effectively: by catching up on all the video games I wasn’t able to play while traveling. The game at the top of my list? <a href="https://en.wikipedia.org/wiki/Spider-Man_(2018_video_game)">Spider-Man</a>, which was widely recognized as one of the top games of 2018. The game is features an open-world, which means you can travel around the game map as you see fit. And since Spider-Man, canonically, lives in real-life New York City, this means you’ll spend hours webbing around an incredibly detailed version of the city that never sleeps.</p>

<p>If you’ve spent any appreciable amount of time in New York, the in-game world will immediately feel familiar. The developers nailed the look and feel of the city. I found myself using real-world landmarks to orient myself as I slinged (slunged?) across Manhattan. The game leans into this realism—it even includes a challenge where you can take photos of in-game landmarks. While some are unique to the Marvel universe, like Avengers Tower and Uncle Ben’s grave, many exist in the real world and are faithfully reproduced within the game: Williamsburg/Brooklyn/Manhattan/Queensboro Bridges all make an appearance, as does Grand Central, Madison Square Garden, Saint Patrick’s Cathedral, Columbus Circle, the High Line and many more points of reference. As you’re swinging through the city, you’re treated to great views of Manhattan’s skyline, anchored by the Empire State Building, Chrysler Building, and Freedom Tower. Except, it’s <em>not</em> the Freedom Tower, despite being located in the exact same location as its real-life counterpart. Why are equally famous buildings like the Empire State Building accurately depicted, but the Freedom Tower isn’t?</p>

<p>Here’s what the “Freedom Tower” looks like in the game:
<img src="https://www.stevenbuccini.com/assets/spiderman/spiderman-1wtc.png" alt="In-Game 1WTC">
<em>(credit to Polygon because I was too lazy to get this off my PS4 myself)</em></p>

<p>Interestingly enough, the in-game design looks to be based on Libeskind’s original design for Freedom Tower (an interesting recap of the changes can be found <a href="https://www.newyorker.com/business/currency/daniel-libeskinds-world-trade-center-change-of-heart">here</a>), lending further credence to the theory that this building is supposed to be 1WTC.</p>

<p>My curiosity was further piqued when I learned that the <em>real</em> One World Trade Center was actually in the game during a demo at E3 in June of 2018, less than 4 months before the final game was set to be released to the public!</p>

<p><img src="https://www.stevenbuccini.com/assets/spiderman/1wtc_e3.png" alt="Real-life 1WTC in Spider-Man demo from E3 2018"></p>

<p>This deadline is even closer than it appears at first glance as the <a href="https://en.wikipedia.org/wiki/Software_release_life_cycle#RTM">“gold master”</a> is finalized weeks before release date so manufacturers have time to make and distribute the game to retailers. This change must have been implemented at the 11th hour.</p>

<p>And even after swapping the model out, they featured the building prominently on the home screen in the released version of the video game!
<img src="https://www.stevenbuccini.com/assets/spiderman/spiderman-start.png" alt="Start screen">
<em>(<a href="https://www.noobfeed.com/features/1119/marvel-s-spider-man-how-do-you-access-new-game-plus-and-ultimate-difficulty">credit</a>)</em></p>

<p>So <em>why</em> isn’t the real-life 1 WTC featured? At this point, we can eliminate time and budget constraints because we know the model already existed and was implemented before launch. We know that the designers thought this building was important as it’s the first thing you notice when starting the game.</p>

<p>I wish to briefly introduce <strong>Buccini’s razor</strong>—if something fun disappears unexpectedly, the cause is litigation (real or imagined).</p>

<p>It turns out that just like an author can copyright their book and a musician can copyright a song, an architect can copyright a building. Sure enough, here’s the copyright record for One World Trade Center:
<img src="https://www.stevenbuccini.com/assets/spiderman/copyright_record.png" alt="Record from [copyright.gov](https://www.copyright.gov/); can't deeplink the record but you can find it yourself by using the document record seen above"></p>

<p>At this point, I had a strong feeling copyright law was the reason for the change. The <a href="https://www.reddit.com/r/SpidermanPS4/comments/9grnr8/freedom_tower/">internet</a> <a href="https://www.reddit.com/r/SpidermanPS4/comments/9d3paw/the_real_reason_for_the_redesigned_freedom_tower/">seems</a> <a href="https://gamefaqs.gamespot.com/boards/191635-marvels-spider-man/76988485">to</a> <a href="https://www.neogaf.com/threads/one-world-trade-center-has-been-removed-from-spider-man-ps4.1465315/">agree</a>.</p>

<p>As luck<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> would have it, there was <a href="https://www.nexsenpruet.com/professionals/jeff-reichard">an expert in architectural copyright</a> right around the corner from my house here in Greensboro! Jeffrey was kind enough to spend a few minutes of his time thinking about this not-at-all-important question.</p>

<p>First, Jeffrey noted that <em>copyrights expire</em>. Just as music and books can pass into the public domain for anyone to replicate freely, you can also build an exact replica of the Empire State Building here in the United States if you so choose. Generally, any building constructed after December 1, 1990 is covered by the <a href="https://www.djc.com/news/ae/11151054.html">Architectural Works Copyright Protection Act</a>. This would explain why older structures are replicated faithfully but the Freedom Tower is not.</p>

<p>However, this doesn’t tell the full story. As Jeffrey noted, <a href="https://www.law.cornell.edu/uscode/text/17/120">17 U.S. Code § 120(a)</a> “provides an exception related to pictorial representations of of buildings that are visible from a public place. Therefore, I am not sure exactly why they changed it in the video game.”</p>

<p>The final piece of the puzzle lies at the <a href="https://www.youtube.com/watch?v=vo5A_fuDgtk&amp;feature=youtu.be&amp;t=2666">end of the credits</a>, where the creators of the game specifically thank the owners of certain famous buildings in New York, including the Empire State Building. I found this curious as the Empire State Building should be doubly safe: it was constructed long before 1990 so it is not covered under copyright law, and it is visible from a public place so it should be exempt from any potential copyrights. But look closer. You’ll see that they are acknowledging the <em>trademark</em> holders, NOT the <em>copyright</em> holders.</p>

<p><a href="https://www.photosecrets.com/buildings-copyright-and-trademarks">As this page</a> helpfully explains, applying a trademark to the building limits how the building’s image can be used in the sale of goods and services (like video games)! The credits hint that the video game creators obtained limited licenses to use the trademark, i.e. the distinctive design and appearance of the building, for certain buildings such as the Flatiron Building.<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup></p>

<p>Therefore, the most likely answer is that the distinctive shape of 1 World Trade Center is either trademarked (although I could not find it within USPTO databases) or is so recognizable that it is easily defensible via a common law trademark and the game developers were unable to secure a license to use the trademark before their deadline.</p>

<p>However, <a href="https://www.youtube.com/watch?v=gHzuHo80U2M">Sony just announced</a> an expansion to the Spider-Man video game, so perhaps the additional time and the demonstrated popularity of the first installment will help resolve this issue for the upcoming title.</p>



  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://www.stevenbuccini.com/why-1wtc-isnt-in-spiderman</link>
            <guid isPermaLink="false">hacker-news-small-sites-24502706</guid>
            <pubDate>Thu, 17 Sep 2020 09:38:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I overslept because iOS 14 disabled my alarm]]>
            </title>
            <description>
<![CDATA[
Score 474 | Comments 306 (<a href="https://news.ycombinator.com/item?id=24502697">thread link</a>) | @dewey
<br/>
September 17, 2020 | https://annoying.technology/posts/e82ff3bde8b225e6/ | <a href="https://web.archive.org/web/*/https://annoying.technology/posts/e82ff3bde8b225e6/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://d33wubrfki0l68.cloudfront.net/9261d105b12f5c6c5928c9532d1f8721b84005cd/62d1b/media/oversleeping.jpg"></p><p>I’m using the iOS <a href="https://support.apple.com/en-us/HT208655">Bedtime</a> feature for years now. With yesterday’s iOS 14 update the feature got moved from the Clock app to the Health app. Unfortunately the migration is done by disabling your existing alarm and showing a button to open the Health app to set it up again.</p><p>I woke up late and well rested today.</p></div></div>]]>
            </description>
            <link>https://annoying.technology/posts/e82ff3bde8b225e6/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24502697</guid>
            <pubDate>Thu, 17 Sep 2020 09:36:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Infosec Apocalypse]]>
            </title>
            <description>
<![CDATA[
Score 153 | Comments 97 (<a href="https://news.ycombinator.com/item?id=24501803">thread link</a>) | @chillax
<br/>
September 16, 2020 | https://blog.rickasaurus.com/2020/08/31/The-Infosec-Apocalypse.html | <a href="https://web.archive.org/web/*/https://blog.rickasaurus.com/2020/08/31/The-Infosec-Apocalypse.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>The rise of tooling for vulnerability detection combined with pressure driven by Vendor Due Diligence is causing a massive enterprise freezeout for non-mainstream technologies across the board. Of particular concern is the impact this will have on the adoption of functional programming in enterprise and small business B2B development.</p>

<p>I see now that the last 10 years were “easy mode” for the growth of new programming tools and infrastructure, with many new breakthrough technologies seeing rapid adoption. Languages like Node, Go and to some degree Scala saw breakaway success, not to mention all of the new cloud tech, NoSQL tech, containerization and data processing platforms along with their custom query DSLs. Other languages like Haskell saw success in small companies and skunkworks style teams solving very difficult problems.</p>

<h3 id="the-rise-of-vulnerability-scanning">The Rise of Vulnerability Scanning</h3>

<p>Just this past year I’ve come to see we’re in the middle of a massive change across the industry. There are new forces at play which will calcify current software stacks and make it extremely hard for existing or new entrants to see similar success without a massive coordinated push backed by big enterprise companies. This force is the rise of InfoSec and vulnerability detection tooling.</p>

<p>Tools like <a href="https://owasp.org/www-community/Source_Code_Analysis_Tools">Blackduck, WhiteSource, Checkmarx, Veracode</a> are exploding in popularity, there are too many to list and many variations on the same theme. In the wake of so many data leaks and hacking events enterprises no longer trust their developers and SREs to take care of security, and so protocols are being implemented top down. This isn’t just on the code scanning side, there is a similar set of things going on with network scanning as well which impacts programming languages less, but similarly will calcify server stacks.</p>

<p>These tools are quickly making their way into SOC2 and SDLC policies across industry, and if your language or new infrastructure tool isn’t supported by them there’s little chance you will get the previously already tenuous approval to use them. This sets the already high bar for adoption much higher. As you might expect, vendors will only implement support for languages that meet some threshold for profitability of their tools. Not only do you need to build a modern set of tools for your language to compete, now you also need support from external vendors.</p>

<h3 id="vendor-due-diligence">Vendor Due Diligence</h3>

<p>Maybe we just cede this territory to enterprise tools with big backers like Microsoft and Oracle, we never more than a few small inroads anyway. The use of these tools is arguably a good thing overall for software security. Unfortunately, the problem cannot be sidestepped so easily, and I’m afraid this is where things look very bleak. The biggest new trend is in enforcement of these tools through Vendor Due Diligence.</p>

<p>You may not be familiar with Vendor Due Diligence if you aren’t in a manager role. The basic idea is your customer will send you a long list of technical questions about your product which you must fill out to their satisfaction before they buy your product or service. In the B2B space where I work these lists are nothing new, but have been getting longer and longer over the last 10 years, now often numbering in the hundreds of questions.</p>

<p>Most recently I’ve seen more and more invasive questions being asked, some even going into how teams are organized, but important to this article is that across the board they now all ask about vulnerability scanning and now often request specific outputs for well-known vulnerability scanning tools. The implication being that if you’re not scanning with these tools they won’t buy your software, and the list of supported languages is small.</p>

<p>Any experienced technology manager sees the natural tradeoff here. When it comes down to making money versus using cool tech, cool tech will lose every time. You’re just burning money if you’re building cool things with cool tech if you know no one will buy it.</p>

<h3 id="so-what-now">So What Now?</h3>

<p>Potentially we will see a resurgence of “compile-to” functional programming with mainstream language targets to sidestep the issue. I suppose though that the extra build complexity and problems debugging will prevent this from ever being mainstream, not to mention that the vulnerability tools look for specific patterns and likely won’t behave well on generated code.</p>

<p>There is some hope in the form of projects like SonarCube which enables users to come together and <a href="https://github.com/SonarSource/sonar-custom-plugin-example">build custom plugins</a>. Will functional programming communities come together to build and maintain such boring tech? I somewhat doubt it. This kind of work is not what most programmers would choose to do in their off time. Similarly, vulnerability detection is unlikely to be a good target to be advanced a little at a time with academic papers. It would take true functional programming fanatics to build companies or tools dedicated to the cause. If you are interested in helping out, pay attention to the <a href="https://owasp.org/www-project-top-ten/">OWASP Top 10</a> as this list drives focus for many infosec teams.</p>

<p>Where does this leave us? If our communities do nothing then smaller B2B software operations focused mom and pop shops or consumer focused web applications likely won’t see any impact unless static analysis makes it into data protection law. Beyond these use cases FP will be relegated to tiny boxes on the back end where vulnerabilities are much less of a concern and the mathematical skills of functional programmers can bring extreme amounts of value.</p>

<p>I know there are many deeper facets I didn’t cover here, if you want to continue the discussion <a href="https://twitter.com/rickasaurus/status/1300487826782420995">join the thread on twitter</a>.</p>


  </div></div>]]>
            </description>
            <link>https://blog.rickasaurus.com/2020/08/31/The-Infosec-Apocalypse.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24501803</guid>
            <pubDate>Thu, 17 Sep 2020 06:34:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hacking on Bug Bounties for Four Years]]>
            </title>
            <description>
<![CDATA[
Score 64 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24500198">thread link</a>) | @infosecau
<br/>
September 16, 2020 | https://blog.assetnote.io/2020/09/15/hacking-on-bug-bounties-for-four-years/ | <a href="https://web.archive.org/web/*/https://blog.assetnote.io/2020/09/15/hacking-on-bug-bounties-for-four-years/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <ul>
  <li><a href="https://blog.assetnote.io/2020/09/15/hacking-on-bug-bounties-for-four-years/#intro">Intro &amp; Motivations</a></li>
  <li><a href="https://blog.assetnote.io/2020/09/15/hacking-on-bug-bounties-for-four-years/#findings">Findings</a></li>
  <li><a href="https://blog.assetnote.io/2020/09/15/hacking-on-bug-bounties-for-four-years/#analysis">Analysis</a></li>
  <li><a href="https://blog.assetnote.io/2020/09/15/hacking-on-bug-bounties-for-four-years/#collaboration">Collaboration</a></li>
  <li><a href="https://blog.assetnote.io/2020/09/15/hacking-on-bug-bounties-for-four-years/#methodology">Methodology</a></li>
</ul>

<hr>





<p>I value transparency a lot, especially when it comes to the bug bounty space. Bug bounty hunters all around the world are submitting a range of reports where the issues found span across multiple domains, often leveraging numerous techniques and methodologies. However, if you’re not already an active bug bounty hunter who has a good understanding of what a bounty program expects, or will pay out for, you have a major disadvantage compared to someone who does have this knowledge. I hope through this blog post, I can demystify the sort of issues bug bounty programs pay for.</p>

<p>The last blog post I did in this series was around four years ago, <a href="https://shubs.io/high-frequency-security-bug-hunting-120-days-120-bugs/">120 days, 120 bugs</a>. In the last four years, a lot has happened. I moved to Europe for six months, I moved interstate in Australia twice, I won a <a href="https://www.youtube.com/watch?v=VojwIY4GL-4">live hacking event</a>, I co-founded a company and helped build an <a href="https://assetnote.io/">attack surface management platform</a> with a team of people I consider family.</p>

<p>Unlike my previous blog post, I did not set myself a goal to find a bug a day. Instead, I participated in bug bounties whenever time allowed. There were many months where I found nothing at all, which often terrified me when it came to evaluating my self worth as a hacker. I also admitted to myself, that I might be a good hacker, but there is always going to be a better hacker out there, and I’ve made my peace with that as a hyper-competitve person.</p>

<p>If you don’t have an excellent understanding of fundamental application security <a href="http://projects.webappsec.org/w/page/13246978/Threat%20Classification">attacks and weaknesses</a> before you approach bug bounties, in my opinion, you are wasting your time. <a href="https://portswigger.net/web-security">Practice and learn more here</a>.</p>

<p>If you’re looking for a paid, more extensive resource, check out and practice with <a href="https://pentesterlab.com/">PentesterLab</a>.</p>

<p>Participating so heavily in bug bounties has given us the knowledge at Assetnote about what security teams <em>actually</em> care about. It’s the reason we can maintain high signal when we are continuously finding exposures.</p>

<p>My primary motivation for this blog post is to educate the masses on what bug bounty programs are paying out for.</p>

<p>For example, would you know that you could submit a dangling EC2 IP (subdomain pointing to an EC2 IP that is no longer owned by the company) as a bug report without reading the proof in the pudding below? I’ve been paid for this by programs, so clearly they value this sort of information.</p>

<hr>




<p>Below are all of my findings for the last four years. I’ve redacted information where necessary, but by reading the titles, it should give you a good understanding of what I was reporting to programs.</p>

<table data-order="[[ 0, &quot;desc&quot; ]]" id="bugs">
<thead><tr><th title="Field #1">Date</th>
<th title="Field #2">Bug</th>
<th title="Field #3">Payout</th>
</tr></thead>
<tbody><tr>
<td>2020-09-02 14:04:11 UTC</td>
<td>[redacted] Hosted Zone Takeover</td>
<td>$1,000.00</td>
</tr>
<tr>
<td>2020-07-16 18:39:22 UTC</td>
<td>Spring debugging endpoints exposed leading to disclosure of all secrets via heapdump on [redacted] &amp; Account takeover by Trace</td>
<td>$2,500.00</td>
</tr>
<tr>
<td>2020-06-30 22:54:07 UTC</td>
<td>Blind SSRF on [redacted] through invoicing API - access to internal hosts</td>
<td>$60.00</td>
</tr>
<tr>
<td>2020-06-10 13:53:43 UTC</td>
<td>Full Account takeover through subdomain takeover via [redacted]</td>
<td>$300.00</td>
</tr>
<tr>
<td>2020-06-10 13:24:10 UTC</td>
<td>Full Account takeover through subdomain takeover via [redacted]</td>
<td>$300.00</td>
</tr>
<tr>
<td>2020-06-10 13:21:57 UTC</td>
<td>Full Account takeover through subdomain takeover via  [redacted]</td>
<td>$300.00</td>
</tr>
<tr>
<td>2020-06-08 14:28:05 UTC</td>
<td>Amazon S3 Subdomain Hijack - [redacted]</td>
<td>$256.00</td>
</tr>
<tr>
<td>2020-06-08 05:29:58 UTC</td>
<td>Route53 Hosted Zone Takeover of [redacted]</td>
<td>$500.00</td>
</tr>
<tr>
<td>2020-06-05 16:27:42 UTC</td>
<td>Admin panel for Cisco IP Conference Station CP-7937G exposed on the internet on [redacted] IP ranges</td>
<td>$400.00</td>
</tr>
<tr>
<td>2020-06-03 21:07:51 UTC</td>
<td>Pre-auth Blind MSSQL Injection affecting [redacted]</td>
<td>$1,024.00</td>
</tr>
<tr>
<td>2020-06-03 14:18:24 UTC</td>
<td>Pre-auth MSSQL Injection affecting [redacted]</td>
<td>$1,024.00</td>
</tr>
<tr>
<td>2020-06-02 15:28:50 UTC</td>
<td>Pre-auth SQL Injection affecting [redacted]</td>
<td>$1,024.00</td>
</tr>
<tr>
<td>2020-06-02 15:26:58 UTC</td>
<td>RCE via arbitrary file write and path traversal [redacted]</td>
<td>$1,024.00</td>
</tr>
<tr>
<td>2020-06-02 15:25:08 UTC</td>
<td>RCE via arbitrary file write and path traversal [redacted]</td>
<td>$1,024.00</td>
</tr>
<tr>
<td>2020-05-18 10:12:38 UTC</td>
<td>Route53 Hosted Zone Takeover of [redacted]</td>
<td>$1,000.00</td>
</tr>
<tr>
<td>2020-05-18 10:11:58 UTC</td>
<td>Route53 Hosted Zone Takeover of [redacted]</td>
<td>$1,000.00</td>
</tr>
<tr>
<td>2020-05-18 10:06:22 UTC</td>
<td>Route53 Hosted Zone Takeover of [redacted]</td>
<td>$1,000.00</td>
</tr>
<tr>
<td>2020-05-18 10:05:20 UTC</td>
<td>Route53 Hosted Zone Takeover of [redacted]</td>
<td>$1,000.00</td>
</tr>
<tr>
<td>2020-05-11 18:47:54 UTC</td>
<td>Route53 Hosted Zone Takeover of [redacted]</td>
<td>$100.00</td>
</tr>
<tr>
<td>2020-05-11 14:59:23 UTC</td>
<td>Account takeover through Subdomain Takeover of [redacted] (Cookie Disclosure -&gt; Account Takeover)</td>
<td>$2,500.00</td>
</tr>
<tr>
<td>2020-05-11 14:31:18 UTC</td>
<td>Account takeover through Subdomain Takeover of [redacted] (Cookie Disclosure -&gt; Account Takeover)</td>
<td>$2,500.00</td>
</tr>
<tr>
<td>2020-05-07 01:47:49 UTC</td>
<td>View all metadata for any [redacted] IDOR [redacted]</td>
<td>$1,000.00</td>
</tr>
<tr>
<td>2020-04-29 22:58:57 UTC</td>
<td>IDOR view all [redacted]</td>
<td>$4,000.00</td>
</tr>
<tr>
<td>2020-04-29 22:57:55 UTC</td>
<td>IDOR view the [redacted]</td>
<td>$2,500.00</td>
</tr>
<tr>
<td>2020-04-24 18:19:23 UTC</td>
<td>Subdomain takeover of [redacted] through Heroku</td>
<td>$300.00</td>
</tr>
<tr>
<td>2020-04-24 18:18:45 UTC</td>
<td>Subdomain takeover of [redacted] through Heroku</td>
<td>$300.00</td>
</tr>
<tr>
<td>2020-04-23 19:45:04 UTC</td>
<td>Ability to horizontal bruteforce [redacted] accounts by abusing [redacted] sign up flow</td>
<td>$500.00</td>
</tr>
<tr>
<td>2020-04-22 17:44:29 UTC</td>
<td>View all metadata for any [redacted] IDOR [redacted]</td>
<td>$500.00</td>
</tr>
<tr>
<td>2020-04-22 17:42:51 UTC</td>
<td>IDOR view the [redacted] for any [redacted] for today [redacted]</td>
<td>$500.00</td>
</tr>
<tr>
<td>2020-04-22 17:42:06 UTC</td>
<td>IDOR view all [redacted] for a [redacted] [redacted]</td>
<td>$500.00</td>
</tr>
<tr>
<td>2020-04-06 19:13:19 UTC</td>
<td>Facebook - Payout For [redacted]</td>
<td>$5,000.00</td>
</tr>
<tr>
<td>2020-03-07 15:12:24 UTC</td>
<td>Accessing Querybuilder on [redacted] to gain access to secrets</td>
<td>$3,000.00</td>
</tr>
<tr>
<td>2020-02-25 15:02:20 UTC</td>
<td>Subdomain takeover of [redacted] via Amazon S3</td>
<td>$750.00</td>
</tr>
<tr>
<td>2020-02-20 23:01:58 UTC</td>
<td>HTML injection, DOS of email receipts and potentially template injection within [redacted] via "Expense Info" section</td>
<td>$500.00</td>
</tr>
<tr>
<td>2020-02-18 14:45:40 UTC</td>
<td>Admin account bruteforce via [redacted]/libs/granite/core/content/login.html</td>
<td>$500.00</td>
</tr>
<tr>
<td>2020-02-15 12:24:57 UTC</td>
<td>Blind XSS via registering on [redacted]</td>
<td>$500.00</td>
</tr>
<tr>
<td>2020-02-04 03:45:38 UTC</td>
<td>HTML Injection in email when contributing to a [redacted]</td>
<td>$700.00</td>
</tr>
<tr>
<td>2020-01-21 17:13:58 UTC</td>
<td>Ability to attach malicious attachments (of any name and of any content type) to [redacted] support staff via [redacted]</td>
<td>$2,000.00</td>
</tr>
<tr>
<td>2020-01-15 11:41:59 UTC</td>
<td>No authentication required to view and delete Terraform locks at [redacted]</td>
<td>$250.00</td>
</tr>
<tr>
<td>2019-12-12 16:25:11 UTC</td>
<td>[redacted] Webhook URL + object leaked in JavaScript on [redacted]</td>
<td>$3,000.00</td>
</tr>
<tr>
<td>2019-11-21 22:15:20 UTC</td>
<td>AWS &amp; Screenhero JWT Credentials from [redacted] not rotated, still working</td>
<td>$1,000.00</td>
</tr>
<tr>
<td>2019-10-17 13:44:23 UTC</td>
<td>RCE on [redacted] via IBM Aspera exploit leading to compromise of secure file storage </td>
<td>$1,000.00</td>
</tr>
<tr>
<td>2019-10-15 14:29:25 UTC</td>
<td>SSO bypass on [redacted] leading to access of internal documents and portals</td>
<td>$250.00</td>
</tr>
<tr>
<td>2019-10-11 18:07:51 UTC</td>
<td>Admin access to [redacted] via guessing credentials</td>
<td>$1,500.00</td>
</tr>
<tr>
<td>2019-10-11 18:06:15 UTC</td>
<td>3rd party subdomain hijack - EC2 IP of [redacted] is no longer controlled by [redacted]</td>
<td>$250.00</td>
</tr>
<tr>
<td>2019-09-30 16:56:50 UTC</td>
<td>Multiple server-side issues affecting [redacted] (SSRF, admin panels)</td>
<td>$2,660.00</td>
</tr>
<tr>
<td>2019-09-25 22:10:00 UTC</td>
<td>Read any [redacted] details using UUID - IDOR in [redacted]</td>
<td>$1,000.00</td>
</tr>
<tr>
<td>2019-09-10 16:17:59 UTC</td>
<td>SSRF in [redacted]</td>
<td>$2,000.00</td>
</tr>
<tr>
<td>2019-09-03 15:28:36 UTC</td>
<td>SSRF in [redacted]</td>
<td>$17,900.00</td>
</tr>
<tr>
<td>2019-08-29 00:43:00 UTC</td>
<td>Bypassing email whitelists for organisation signup flows on [redacted]</td>
<td>$250.00</td>
</tr>
<tr>
<td>2019-08-09 05:15:44 UTC</td>
<td>[Pre-Submission] SSRF in [redacted] (Iframely)</td>
<td>$2,970.30</td>
</tr>
<tr>
<td>2019-07-29 16:32:59 UTC</td>
<td>[Bypass] SSRF via [redacted] leads to internal network access, ability to read internal JSON responses</td>
<td>$23,000.00</td>
</tr>
<tr>
<td>2019-07-24 02:52:42 UTC</td>
<td>PHPInfo exposed at [redacted]</td>
<td>$100.00</td>
</tr>
<tr>
<td>2019-07-24 02:46:02 UTC</td>
<td>SSRF on [redacted] leading to AWS breach via security credentials</td>
<td>$5,000.00</td>
</tr>
<tr>
<td>2019-07-08 14:44:23 UTC</td>
<td>Remote command execution on production [redacted] (via tsi parameter) - CVE-2017-12611</td>
<td>$2,000.00</td>
</tr>
<tr>
<td>2019-06-12 17:42:53 UTC</td>
<td>Username/Password for Aspera and other secrets leaked in [redacted]</td>
<td>$1,500.00</td>
</tr>
<tr>
<td>2019-06-12 17:42:08 UTC</td>
<td>SSO/Authorization bypass for APIs hosted on [redacted]</td>
<td>$1,500.00</td>
</tr>
<tr>
<td>2019-06-12 14:45:09 UTC</td>
<td>Remote Code Execution (many endpoints) - [redacted]</td>
<td>$4,500.00</td>
</tr>
<tr>
<td>2019-06-10 17:29:35 UTC</td>
<td>Extract email, dob, full address, federal tax ID and other PII for all leads in [redacted]</td>
<td>$1,800.00</td>
</tr>
<tr>
<td>2019-06-10 16:53:22 UTC</td>
<td>Obtain email, mobile of customers of [redacted] by iterating through Lead IDs via the API</td>
<td>$12,600.00</td>
</tr>
<tr>
<td>2019-06-10 16:52:40 UTC</td>
<td>Ability to pull out all opportunities (IDOR) extract PII for customers of [redacted]</td>
<td>$12,600.00</td>
</tr>
<tr>
<td>2019-06-07 18:51:24 UTC</td>
<td>[redacted][IDOR] - Accessing all accounts via regression / new attack vector by abusing [redacted] (regression?)</td>
<td>$2,500.00</td>
</tr>
<tr>
<td>2019-06-07 18:17:31 UTC</td>
<td>Blind SSRF on [redacted] through RPC call to checkAvailableLivechatAgents</td>
<td>$62.50</td>
</tr>
<tr>
<td>2019-06-07 18:07:22 UTC</td>
<td>HTML injection in emails when adding a reviewer to [redacted]</td>
<td>$125.00</td>
</tr>
<tr>
<td>2019-06-07 17:42:09 UTC</td>
<td>[IDOR] Impersonating an [redacted] employee via /api/readHandler on [redacted]</td>
<td>$1,500.00</td>
</tr>
<tr>
<td>2019-06-07 15:33:31 UTC</td>
<td>Extract mobile number and [redacted] using only an email address, for any [redacted]</td>
<td>$750.00</td>
</tr>
<tr>
<td>2019-06-07 14:36:01 UTC</td>
<td>Zendesk Ticket IDOR / Ability to enumerate  IDs via [redacted]</td>
<td>$125.00</td>
</tr>
<tr>
<td>2019-06-07 14:24:15 UTC</td>
<td>Extract mobile number and [redacted] using only an email address, for any [redacted] user</td>
<td>$750.00</td>
</tr>
<tr>
<td>2019-06-07 14:11:20 UTC</td>
<td>HTML Injection in [redacted] receipts if printed from [redacted]</td>
<td>$100.00</td>
</tr>
<tr>
<td>2019-06-07 13:56:46 UTC</td>
<td>Ability to access the airwatch admin panels and APIs in [redacted]</td>
<td>$1,000.00</td>
</tr>
<tr>
<td>2019-06-07 13:21:31 UTC</td>
<td>IDOR on [redacted] allows you to access [redacted] information for any [redacted] user</td>
<td>$250.00</td>
</tr>
<tr>
<td>2019-06-07 10:13:20 UTC</td>
<td>[redacted][IDOR] - Accessing all accounts via regression / new attack vector by abusing [redacted] (regression?)</td>
<td>$15,000.00</td>
</tr>
<tr>
<td>2019-05-22 19:33:27 UTC</td>
<td>SQLi and Authentication Bypass in [redacted]</td>
<td>$4,500.00</td>
</tr>
<tr>
<td>2019-04-29 14:14:42 UTC</td>
<td>Reflected XSS in [redacted]</td>
<td>$500.00</td>
</tr>
<tr>
<td>2019-04-29 14:14:29 UTC</td>
<td>SSRF in [redacted]</td>
<td>$1,500.00</td>
</tr>
<tr>
<td>2019-04-25 07:33:22 UTC</td>
<td>Local file disclosure through Rails CVE-2019-5418 in [redacted]</td>
<td>$100.00</td>
</tr>
<tr>
<td>2019-04-19 02:28:54 UTC</td>
<td>SSRF - [redacted]</td>
<td>$4,950.00</td>
</tr>
<tr>
<td>2019-04-19 02:28:35 UTC</td>
<td>SSRF at [redacted] via the 'url' parameter</td>
<td>$4,950.00</td>
</tr>
<tr>
<td>2019-03-29 11:23:14 UTC</td>
<td>AWS S3 secrets leaked in [redacted] meeting connector …</td></tr></tbody></table></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.assetnote.io/2020/09/15/hacking-on-bug-bounties-for-four-years/">https://blog.assetnote.io/2020/09/15/hacking-on-bug-bounties-for-four-years/</a></em></p>]]>
            </description>
            <link>https://blog.assetnote.io/2020/09/15/hacking-on-bug-bounties-for-four-years/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24500198</guid>
            <pubDate>Thu, 17 Sep 2020 01:29:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What happened to all the non-programmers? (2015)]]>
            </title>
            <description>
<![CDATA[
Score 99 | Comments 118 (<a href="https://news.ycombinator.com/item?id=24497470">thread link</a>) | @harporoeder
<br/>
September 16, 2020 | https://www.benkuhn.net/nonprog/ | <a href="https://web.archive.org/web/*/https://www.benkuhn.net/nonprog/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>This week I found myself at yet another dinner party that mysteriously contained only two people who were not involved with the tech industry in some way.</p><p>As I looked around and realized for the hundredth time that I was surrounded by people exactly like me, something inside me snapped. I downloaded the latest <a href="http://www.census.gov/acs/www/data_documentation/public_use_microdata_sample/" target="_blank">American Community Survey microdata</a>, fired up R and started calculating feverishly.</p><p>It turns out that among people who</p><ul><li>are under 35</li><li>live in San Francisco, Berkeley or Oakland</li><li>and have at least a bachelor’s degree</li></ul><p>about 10% have a computer-related occupation. An additional 5% are employed in some other capacity by a strongly computer-related industry.</p><p>That’s not <em>nearly</em> large enough to explain how saturated with coders my social groups are. I have plenty of social circles that are (at least nominally) totally different from my work: contra dancers, people interested in effective altruism, folk musicians, friends from college, and so on. And yet I keep finding myself in the middle of a programmer monoculture. Why?</p><p>As <a href="http://xkcd.com/1480/" target="_blank">Randall Munroe recently suggested</a>, suggests, maybe taking up a sport would help expose me to a broader range of people. But which one? Obviously not football, since I’m barely 150 pounds and don’t like traumatic brain injuries. Preferably a more elegant sport that doesn’t require a bunch of awkward equipment. Maybe Ultimate or rock climbing–</p><p>Wait, crap.</p><p>Part of the problem is that my taste in hobbies is influenced by class lines and subculture in ways that I hadn’t realized before.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> It turns out that even when it’s totally up to me, most of the things I’m interested in are strongly associated with a very particular band of socioeconomic status—a much smaller band than the set of “all bachelor’s degree holders” in my ACS analysis.</p><p>This stronger selection sneaks in when I try to pick a sport based on things like “elegance,” instead of “size of community” or “what I’ve been playing since I was five years old” or whatever other things people might pick sports for. In fact, just the fact that I’m interested in doing sports for leisure is associated with class, since it’s not something that would be so easy for, say, manual laborers or shift workers.</p><p>But I don’t think socioeconomic selection explains all of it. My parents’ friends were similarly selected, but they didn’t all have <em>literally the same job</em>, and the ones that did were usually coworkers—not people they had met socially who bizarrely all happened to work on the same stuff. My friends in other occupations with similar base rates—say, school teachers—don’t wonder where all the non-teachers are at social events. And I don’t even feel like I’m from a similar subculture to many programmers. What else could be going on?</p><ul><li><p>Maybe that crackpot-sounding stuff about the “programmer’s brain” actually has something to it. Maybe programmers are all drawn to the same activities because those activities are friendly to the programmer’s innately logical, systematizing and abstract habits of thought.</p></li><li><p>Programmers could talk about programming too much, or smell bad, or something, so people from other professions are less likely to put up with them at social events.</p></li><li><p>Perhaps the various subcultures of programmers are closer together, and more distinct from other subcultures, than I perceive. Maybe “programmer culture” is less analogous to other single professions and more analogous to “academic culture” or “hippie culture,” where it would be more reasonable to have that be your entire social group.</p></li><li><p>Maybe I miscalculated from the ACS data and there are actually way more programmers than the 10% number suggests.</p></li></ul><p>Unless I’ve miscalculated pretty badly, though, it’s clear that these social bubble effects are way stronger and more tenacious than I would have expected. And this is just one of the axes where it’s <em>obvious</em> that all the variance is being selected out. I wonder what more subtle facts are being selected for this strongly in my social groups?</p><section role="doc-endnotes"><hr><ol><li id="fn:1" role="doc-endnote"><p>When I lived in Boston, the people I associated with were determined mostly by my parents or my private high school/college, which is plenty enough to explain a monoculture without getting into class effects. <a href="#fnref:1" role="doc-backlink">↩︎</a></p></li></ol></section></article></div>]]>
            </description>
            <link>https://www.benkuhn.net/nonprog/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24497470</guid>
            <pubDate>Wed, 16 Sep 2020 20:33:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I suspect many task deadlines are designed to force engineers to work for free]]>
            </title>
            <description>
<![CDATA[
Score 263 | Comments 186 (<a href="https://news.ycombinator.com/item?id=24496219">thread link</a>) | @sT370ma2
<br/>
September 16, 2020 | http://misc-stuff.terraaeon.com/articles/engineering-deadlines.html | <a href="https://web.archive.org/web/*/http://misc-stuff.terraaeon.com/articles/engineering-deadlines.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://misc-stuff.terraaeon.com/articles/engineering-deadlines.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24496219</guid>
            <pubDate>Wed, 16 Sep 2020 19:05:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[433% Keyboard]]>
            </title>
            <description>
<![CDATA[
Score 138 | Comments 128 (<a href="https://news.ycombinator.com/item?id=24495046">thread link</a>) | @_salmon
<br/>
September 16, 2020 | https://relivesight.com/projects/433/ | <a href="https://web.archive.org/web/*/https://relivesight.com/projects/433/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

            <h2>433% Keyboard</h2>
            <p>—「0X://Explanation」<br>
            IT IS FINALLY (mostly) COMPLETED. If anyone has ever heard directly from God Himself, the conception of this keyboard was definitely the message. 450 keys of solid non-mx-browness and
            433% the size of a normal full size, what more could you ask for? This keyboard fits 2 (two) full football fields on it {diagram on page 9 of your textbooks}. and um yeah thats kinda it idk can you see it there isnt much to say.

            {and yes for anyone who is new, i know the images load slow, im using some jankery just bear with it plz and ty}
            </p>
            <p><a target="_blank" href="https://www.reddit.com/r/MechanicalKeyboards/comments/it7a0p/i_present_my_433_ortho_endgame_is_only_a_lie_if/">reddit post</a> - thanks for 13.1k upvotes and 58 awards &lt;3</p>
              <p><a id="back" href="https://relivesight.com/ongoing/">back a page</a></p>
              <p><img src="https://drive.google.com/uc?export=view&amp;id=1OKPmow5-rwRyFS-_zcOYHDpGRSjjKVej" width="500px"></p><p>Specs:</p>
        <ul>
          <li>PCB: ScrabblePad</li>
          <li>Microcontrollers: Teensy2.0++(x2)</li>
          <li>Switches: Gateron Yellows</li>
          <li>Keycaps: xda 9009 from kpreublic (98), dsa dark gray blanks (90), xda light grey blanks (12), cherry relegenadble keycaps (tipro rebrand) (120), dsa "retro beige" (26), cherry beige keycaps (52), dsa black blanks (38), and stroke and structure set keycaps (14)</li>
        </ul>
            
              
             <p>i've acquired all the materials, i intend to 3d print some "feet" for this board and maybe tent it a bit, here are the pcbs:</p>
             <p><img src="https://drive.google.com/uc?export=view&amp;id=1uWil1XZH2ctQViab6xnskC4BIYivAWeG" width="500px"></p><p>this one should be pretty straight forward, i just need some free time to build it. two "scrabblepads" by donutcables btw.</p>
             
             <p>the dautning task beings, and spoiler: i finish it all in one weekend (kinda). well you know what they say, show dont tell (and my hands ache from this build) so heres some pics of the board while i soldered the 450 diodes, switches, etc:</p>
             <p><img src="https://drive.google.com/uc?export=view&amp;id=1tlF20EdGLjFh_IJowFcZ7qy07jmj-w6s" width="300px">
             <img src="https://drive.google.com/uc?export=view&amp;id=1ykB1evyrh2UrNnkfX7z3bR4keEpgLMhG" width="300px">
             <img src="https://drive.google.com/uc?export=view&amp;id=1Ws5bUOHTzRmT6kGS_D4HoMzPZvrE81Hj" width="300px">
             <img src="https://drive.google.com/uc?export=view&amp;id=1pRKCnqxWew30dc5mC4INyfA1pUxMgCOr" width="300px"></p><p>wow! what only took you a couple seconds to look at took me a couple dozen hours, astonishing. well now the simple part (i so naively thought) choosing keycaps!
               lets just skip all of my indecsision and skip to what i finally settled on. a xda 9009 set, dsa dark gray blanks, xda light grey blanks, cherry relegenadble keycaps (tipro rebrand), dsa "retro beige", cherry beige keycaps, dsa black blanks, and stroke and structure set keycaps.
            
              </p>
               <p><img src="https://drive.google.com/uc?export=view&amp;id=1CYfMDgvnOXaQEQv89GwsMRd-nMT4Tl66" width="400px">
               <img src="https://drive.google.com/uc?export=view&amp;id=1SxTfFaIz_Mv9gzYm4qFMZsB8LYYQCbD-" width="200px">
               <img src="https://drive.google.com/uc?export=view&amp;id=1jSCz7vcr3Nc26TKKhYej4uAPvN6-HPih" width="500px">
               <img src="https://drive.google.com/uc?export=view&amp;id=1h-45yK6HDq2VmC7mxl1NMAaWgQM8IGI_" width="500px">
               <img src="https://drive.google.com/uc?export=view&amp;id=1q99gN9PK-m8a6wxMlPnEBEt9rFs3SRws" width="500px"></p><p>alot of cutting and frusturating placement of the paper (relegndable caps) later and its done! here's this board next to some other favorites of mine:</p>
               <p><img src="https://drive.google.com/uc?export=view&amp;id=1iRszdMNP3aFmEIkVCuBkOScToGBlz_Gd" width="300px">
               <img src="https://drive.google.com/uc?export=view&amp;id=1tkfGJU4lo1WCN7LOQSl1MJhVLyvJe55L" width="300px"></p><p>sadly i cant officially call this project done until i add the 3d printed feet and finish the qmk, tho fun fact: i typed this whole post on the board~
                 its honestly not as hard as i thought it would be to switch, its still 123897421987 times better than any staggered non split torture. anyway thanks for reading so far! its been fun~
               </p>

            

   <p><a id="back" href="https://relivesight.com/ongoing/">back a page</a></p>
   <p>┈ ren ​♡</p>


  </div></div>]]>
            </description>
            <link>https://relivesight.com/projects/433/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24495046</guid>
            <pubDate>Wed, 16 Sep 2020 17:36:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Large-scale Abuse of Contact Discovery in Mobile Messengers [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 282 | Comments 84 (<a href="https://news.ycombinator.com/item?id=24494505">thread link</a>) | @sizzle
<br/>
September 16, 2020 | https://encrypto.de/papers/HWSDS21.pdf | <a href="https://web.archive.org/web/*/https://encrypto.de/papers/HWSDS21.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://encrypto.de/papers/HWSDS21.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24494505</guid>
            <pubDate>Wed, 16 Sep 2020 16:51:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Modern Web Applications Stability]]>
            </title>
            <description>
<![CDATA[
Score 61 | Comments 30 (<a href="https://news.ycombinator.com/item?id=24493865">thread link</a>) | @blazeeboy
<br/>
September 16, 2020 | https://www.emadelsaid.com/on-modern-web-applications-stability/ | <a href="https://web.archive.org/web/*/https://www.emadelsaid.com/on-modern-web-applications-stability/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <div>
    <section dir="auto">
  


  

  <div dir="auto">
    <p>I don’t like how modern web applications are built. Many of the web applications
are too unstable, That you can’t imagine having the system running without a
team supporting it. The fact that we try to automate manual processes then the
automation needs manual intervention defies the purpose. Some companies has an
army of developers if they were to do the business by hand they would make a
better job than the programmed system. There are many reasons for this
situation. One of the reasons is the excessive use of third party dependencies.</p>

<p>Lets take a look on a basic modern web based system, There are several layers
on software running on the machine, starting from firmware to your business
logic.</p>

<p><img src="https://www.emadelsaid.com/images/IMG_20200915_212438.jpg" alt="IMG_20200915_212438.jpg"></p>

<p>I don’t think this is very helpful to understand the gravity of the situation.
There are many actors that are not considered in this picture. Layers are also
missing because they are implicit in other layers. Lets expand these hidden
layers and actors. It will help us understand better why that small Nodejs or
RubyOnRails application we wrote isn’t just one layer in this picture.</p>

<p><img src="https://www.emadelsaid.com/images/IMG_20200915_214548.jpg" alt="IMG_20200915_214548.jpg"></p>

<p>Here are the layers we added this time:</p>

<ul>
  <li>System core utilities</li>
  <li>Other processes your application depends on like “memcached, Redis, MySQL,
Postgres…etc”</li>
  <li>Third party code your application depends on an ORM, Template engine,
pagination library, a library that <a href="https://www.theregister.com/2016/03/23/npm_left_pad_chaos/">pads your string with
spaces</a> just
because.</li>
  <li>Server applications that sits in front of your code handling HTTP and response
compression…etc.</li>
</ul>

<p>For each of these layers there is <strong>at least</strong> one team responsible for
maintaining it.</p>

<p>Again, We missed other layers and people in this picture. Most of the
applications are using external SAAS providers for logs or monitoring or bug
reporting or provide parts of the system functionality that can take more time
to build by the company team. lets add them to the picture along with their
teams.</p>

<p><img src="https://www.emadelsaid.com/images/IMG_20200915_221047.jpg" alt="IMG_20200915_221047.jpg"></p>

<p>This picture is for one application, I won’t expand it to a whole system with
different services and programs that is the reality of all companies.
Lets stick to one application for the sake of simplicity.</p>

<p>So here is the first point I want to make: With every service you use you’re not
just a user, This service is now part of your application, You are held
responsible for it’s behavior and misbehaving. You will inherit bugs in their
system. When this service team is affected by COVID-19 and get reduced to the
point where they can’t fix issues you will be affected too. When They get slower
your application will get slower too. When their service is down your
application will experience malfunction too, Your system and theirs is now
connected. So add external services integration cautiously. By adding an
external system you’re putting your trust in this service team and their ability
in delivering what the service is promising now <strong>and</strong> in the future. This is not
an easy decision and it should be treated as such.</p>

<p><img src="https://www.emadelsaid.com/images/IMG_20200915_224907.jpg" alt="IMG_20200915_224907.jpg"></p>

<p>Now lets move to the direct dependencies of your application. If you’re using
any modern programming language it’ll have a way to package code into reusable
format that could be reused by other applications. one package can use code from
other packages, these packages can use other packages and so on like a tree.</p>

<p><img src="https://www.emadelsaid.com/images/IMG_20200915_231326.jpg" alt="IMG_20200915_231326.jpg"></p>

<p>With every package in this tree we depend on the code inside this package and
the team that maintains it. A freshly generated rails project depends on 74
packages for ruby and <code>Yarn list</code> that lists JavaScript dependencies output 3102
lines, that’s 3176 packages with teams maintaining them and bugs and new
versions all the time.</p>

<p>This is wrong for many reasons. I will list some of them here for the sake of
clarity.</p>

<ul>
  <li>You have put your trust in at least 3176 other developers. You have never met
them, never talked to them, there are no guarantee they will continue to
maintain this package. There are no guarantee they won’t put code in their
package to show <a href="https://www.zdnet.com/article/npm-bans-terminal-ads/">ads in your
terminal</a> or <a href="https://www.trendmicro.com/vinfo/dk/security/news/cybercrime-and-digital-threats/hacker-infects-node-js-package-to-steal-from-bitcoin-wallets">code that
steals your bitcoin wallets
</a>.</li>
  <li>You are not really using all of this code. When someone is writing an open
source package it will suffer sooner or later from <a href="https://en.wikipedia.org/wiki/Feature_creep">feature
creeping</a> You are probably using
couple features of this package and don’t need the rest, but you wanted the
banana and got the whole forest now.</li>
  <li>With every package update you’re inventing unnecessary work for yourself. New
versions of packages are released all the time. Updating your project to <strong>get
the latest bug fixes and features</strong> is usually what people do. Most of the
time because of feature creeping these versions changes are not relevant to
you at all, but you won’t know until you read the change log. If it’s relevant
to your project you’ll need to do an update. if something is deprecated or
changed you’ll need to change your code. So suddenly someone somewhere is
telling you to change your code. That’s part of the control you have over your
code handed over to someone you never talked to or knew.</li>
  <li>When your programming language has a new release you can’t update unless all of
your dependencies are up to date. For ruby 2.7.0 for example some language syntax is
now deprecated and shows warning when you run your project. So to fix that you
either fix it in the package and open a PR with the change or wait for the
maintainer to update it.</li>
  <li>When you encounter a bug in a dependency you will have to understand this
package code, fork, branch, fix rinse and repeat. That requires a some
cooperation from the library maintainer which is most of the time isn’t
possible because most of the open source projects are voluntarily maintained.</li>
  <li>Developing new features or modifying existing features are ordre of magnitude
harder. You’ll need to dig into the documentation of the dependencies looking
for support for this little feature you want to add. That is if there is any
documentation at all for that part of the code. Otherwise you’ll have to dig
in to the library code.</li>
</ul>

<p>This is the second point I want to make: Using external library implies that you
trust the maintainer and you also inherit his decisions about using other
libraries and so forth. This decision should be weighed based on the benefit of
the library and how many of it’s features you’re going to use and other factors
like the maturity and how responsive is the maintainer, please don’t use GitHub
stars as a factor in your decision it’s misleading. And if the part you use from
the library isn’t too big I recommend using the library to save some time and
effort upfront but make sure you get rid of it and implement the part you need.
An example of that is a pagination library like rails “Kaminari” if you’re using
it to save you some time then sure. But keep on your todo list a task to remove
it and implement the feature yourself. An example of libraries that’s hard to
get rid of it “OpenCV” This is something that reimplementing the part you need
probably will be a huge task so it can stay. You’ll need to use your best
judgment to decide between these 2 sides of the spectrum.</p>

<p>I like to think of what I do as building an automated system, I would like this
system to run by itself, keep itself clean and healthy, doesn’t need manual
intervention. If the whole team disappeared out of existence I would like that
system to work for a very long time without any supervision.</p>

<p>More code means more bugs for me to fix, by extension more code that I didn’t write
means more bugs that I probably can’t solve. This is dangerous and shouldn’t be
taken lightly. Extending your code with external libraries or systems can cut
down effort hence the cost of development. But when this is taken lightly it
backfires badly.</p>

<p>HN comments: <a href="https://news.ycombinator.com/item?id=24493865">https://news.ycombinator.com/item?id=24493865</a></p>

  </div>
</section>

<hr>



    </div>
  </section></div>]]>
            </description>
            <link>https://www.emadelsaid.com/on-modern-web-applications-stability/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24493865</guid>
            <pubDate>Wed, 16 Sep 2020 15:56:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Challenging LR Parsing]]>
            </title>
            <description>
<![CDATA[
Score 120 | Comments 41 (<a href="https://news.ycombinator.com/item?id=24492675">thread link</a>) | @dilap
<br/>
September 16, 2020 | https://rust-analyzer.github.io/blog/2020/09/16/challeging-LR-parsing.html | <a href="https://web.archive.org/web/*/https://rust-analyzer.github.io/blog/2020/09/16/challeging-LR-parsing.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Consider this incomplete snippet of Rust code:</p>
<div>
<div>
<pre><code data-lang="rust"><table><tbody><tr><td><pre>1
2
3
4
5
</pre></td><td><pre><span>fn</span> <span>foo</span><span>(</span>

<span>struct</span> <span>S</span> <span>{</span>
   <span>f</span><span>:</span> <span>u32</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>I want to see an LR parser which produces the following syntax tree
(from <a href="https://rust-analyzer.github.io/manual.html#show-syntax-tree"><strong>Show Syntax Tree</strong></a> rust-analyzer command, with whitespace nodes elided for clarity):</p>
<div>
<div>
<pre><code><table><tbody><tr><td><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
</pre></td><td><pre>SOURCE_FILE@0..32
  FN@0..7
    FN_KW@0..2 "fn"
    NAME@3..6
      IDENT@3..6 "foo"
    PARAM_LIST@6..7
      L_PAREN@6..7 "("
  STRUCT@9..31
    STRUCT_KW@9..15 "struct"
    NAME@16..17
      IDENT@16..17 "S"
    RECORD_FIELD_LIST@18..31
      L_CURLY@18..19 "{"
      RECORD_FIELD@23..29
        NAME@23..24
          IDENT@23..24 "f"
        COLON@24..25 ":"
        PATH_TYPE@26..29
          PATH@26..29
            PATH_SEGMENT@26..29
              NAME_REF@26..29
                IDENT@26..29 "u32"
      R_CURLY@30..31 "}"
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>The most error-resilient LR-style parser I know, <a href="https://github.com/tree-sitter/tree-sitter">tree sitter</a>, produces this instead (tree sitter is GLR, this is <strong>not</strong> the style of parsing advocated by the article):</p>
<div>
<div>
<pre><code><table><tbody><tr><td><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
</pre></td><td><pre>source_file [0, 0] - [5, 0])
  ERROR [0, 0] - [4, 1])
    identifier [0, 3] - [0, 6])
    struct_pattern [2, 0] - [4, 1])
      type: type_identifier [2, 0] - [2, 6])
      ERROR [2, 7] - [2, 8])
        identifier [2, 7] - [2, 8])
      field_pattern [3, 3] - [3, 9])
        name: field_identifier [3, 3] - [3, 4])
        pattern: identifier [3, 6] - [3, 9])
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>Note two things about the rust-analyzer’s tree:</p>
<div>
<ul>
<li>
<p>There’s an (incomplete) “function” node for <code>fn foo(</code>.
Unclosed parenthesis doesn’t preclude the parser from recognizing parameter list.</p>
</li>
<li>
<p>Incomplete function does not prevent struct definition from being recognized.</p>
</li>
</ul>
</div>
<p>These are important for IDE support.</p>
<p>For example, suppose that the cursor is just after <code>(</code>.
If we have rust-analyzer’s syntax tree, than we can figure out that we are completing a function parameter.
If we are to get fancy we might find the calls to the (not yet fully written) <code>foo</code>, run type inference to figure out the type of the first argument, and than suggest parameter name &amp; type based on that (not currently implemented — there’s soooooo much yet to be done in rust-analyzer).
And correctly recognizing <code>struct S</code> is important to not break type-inference in the code which uses <code>S</code>.</p>
<p>There’s a lot of literature about error recovery for LR parsers, how come academics haven’t figured this out already?
I have a bold claim to make: error-recovery research in academia is focusing on a problem irrelevant for IDEs.
Specifically, the research is focused on finding “minimal cost repair sequence”:</p>
<div>
<ul>
<li>
<p>a set of edit operations is defined (skip, change or insert token),</p>
</li>
<li>
<p>a “cost” metric is defined to distinguish big and small edits,</p>
</li>
<li>
<p>an algorithm is devised to find the smallest edit which makes the current text parse.</p>
</li>
</ul>
</div>
<p>This is a very academia-friendly problem — there’s a precise mathematical formulation, there’s an obvious brute force solution (try all edits), and there’s ample space for finding polynomial algorithm.</p>
<p>But IDEs don’t care about actually guessing &amp; repairing the text!
They just need to see as much of (possibly incomplete) syntax nodes in the existing text as possible.
When rust-analyzer’s parser produces</p>
<div>
<div>
<pre><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre>  PARAM_LIST@6..7
    L_PAREN@6..7 "("
STRUCT@9..31
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>it doesn’t think “Oh, I need to insert <code>)</code> here to complete the list of parameters”.
Rather, it sees <code>struct</code> and thinks “Oh wow, didn’t expect that! I guess I’ll just stop parsing parameter list right here”.</p>
<p>So, here’s</p>
<div>
<table>
<tbody><tr>
<td>
<i title="Important"></i>
</td>
<td>
<p>First Challenge</p>
Design error <em>resilient</em> (and not just error <em>recovering</em>) LR parsing algorithm.
</td>
</tr>
</tbody></table>
</div>
<p>Note that error resilience is a topic orthogonal to error reporting.
I haven’t payed much attention to error reporting (in my experience, synchronous reporting of syntax errors in the editor compensates for bad syntax error messages), but it might be the case that MCRS are a good approach to there.</p>
</div></div>]]>
            </description>
            <link>https://rust-analyzer.github.io/blog/2020/09/16/challeging-LR-parsing.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24492675</guid>
            <pubDate>Wed, 16 Sep 2020 13:48:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Direct sales for SaaS startups – our experience and tips]]>
            </title>
            <description>
<![CDATA[
Score 158 | Comments 19 (<a href="https://news.ycombinator.com/item?id=24492609">thread link</a>) | @pau_alcala
<br/>
September 16, 2020 | https://blog.palabra.io/learning-to-listen-direct-sales-tips-for-early-stage-startups | <a href="https://web.archive.org/web/*/https://blog.palabra.io/learning-to-listen-direct-sales-tips-for-early-stage-startups">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><em>By Pau Alcalá - Co-founder of Palabra</em></p><p>While finding product-market fit for <a href="https://www.palabra.io/?utm_medium=direct-sales-tips-startups&amp;utm_source=blog">Palabra</a>, our marketing strategy was exclusively organic and our first sales came from 1-1 conversations with potential users. After a month of difficult conversations and failed demos, I learned a very new and innovative approach to direct sales: actually listening to what people are saying. In this post I'll share my experience and some tips to listen to users, in the hopes of saving founders &amp; early startup teams some time and energy.</p><h2>What we mean by direct sales</h2><p>As the name suggest, direct sales means you talk directly to your prospect and try to sell them your solution via a 1-1 conversation. This conversation usually starts by reaching the prospect you think your product would work for, and sharing why you think your solution would be good for them.</p><p>Taking a direct approach is more common for B2B businesses, because the decision to purchase is strategical and the price is higher, which means you get a bigger return for each user you convert. But I think it's a good strategy to follow for any early stage SaaS, because it's an easy and direct way of learning about your users and implementing solutions that work for them.</p><p>The biggest challenges to direct sales is finding the right prospects and knowing how to show them value as quickly as possible. With direct conversations you'll probably get a higher conversion rate than self-served sales, but at a much slower rate.</p><h2>Why direct sales in a SaaS startup?</h2><p>When we launched <a href="https://www.palabra.io/?utm_medium=direct-sales-tips-startups&amp;utm_source=blog">Palabra</a> we had no audience and not enough user data to understand who we should be targeting or how to convert them into paying users. We had two possible paths to follow:</p><ol><li>Awareness-first: Experimenting with low-budget ads or organic strategies in different channels, with different messages to see which stick better. This approach is the startup playbook, feeding the top of the funnel with as many prospects as possible assuming most of them will not end up buying, and learn how to convert them better later on.</li><li>Conversion-first: Spending almost no time to feed the top of the funnel (keep a low stream of leads and prospects) but improving that funnel to have better conversions. Leads would be scarce, but we'd learn how to qualify them and provide value so they are willing to buy and stay around.</li></ol><p>The first path was the riskier for us. First, because we had little experience with paid acquisition, and wouldn't know if our misses would be due to lack of experience or just wrong channels.</p><p>Second, we wanted to engage in deep conversations with users as soon as possible. We didn't really care about general trends, we wanted to actually understand what people were struggling with in email automation, and where to take our product so that it worked for them. That's why we decided to take the second path.</p><p>Our initial strategy was to ask a bunch of questions about people's current email automation strategies and try to turn the initial conversation into a sales pitch. We'd learn fast and get a few sales in the meantime.</p><p>Sounds easy, right? Well, it was not.</p><h2>What a failed sales conversation looks like</h2><p>After my first couple of calls I knew I was doing something wrong, but didn't know what it was. Sign ups were rarely because of my "sales" 1-1s, and every conversation left me with a sour feeling.</p><p>What usually happened was that I got to a call, asked the person a couple of questions about their strategies, and at some point I'd get nervous and start talking a lot. People are usually nice and would listen to what I had to say, but I could feel they weren't really interested, and felt like I was wasting time.</p><p>So what was I doing wrong?</p><p>After talking with my co-founder and a couple of friends in the SaaS industry, I found that I wasn't really paying attention to what prospects were saying. My team would ask questions about our prospects that I didn't know how to answer.</p><p>That meant I wasn't really selling, but I also wasn't learning about our users. I found I had to learn how to listen first, and sell later.</p><h2>How to talk less and sell more</h2><p>Listening to prospects is not at easy as it sounds when you are worried about selling them your solution. Specially if you're in early stage and don't have much experience selling software, it'll be hard to keep a clear mind and letting the user take the conversation where they want to.</p><p>But here's the thing: selling isn't about convincing people to try your product, it's about identifying how your product can solve a problem for them.</p><p>In a direct sales conversation, you should have two take outs:</p><ol><li>Identifying if the person you're talking to has a problem you could solve (the more details the better)</li><li>Communicating clearly how your product is a solution to their problem.</li></ol><p>If you fail at #1, you'll end up trying to convince people who don't actually have a problem you could help them with. Those are not your users, and there's nothing you can do today to make their life easier. Even if you somehow convince them to sign up, they'll probably cancel their subscription, making your churn go up.</p><p>Failing at #2 is usually connected to #1, because the only way of communicating a solution clearly is to understand the problem perfectly. You have to <strong>listen really carefully</strong> to understand what those problems are.</p><p>Most of your conversations with prospects should be about #1. Make a lot of questions. Listen closely and follow up on what isn't clear. Make the other person feel listened to. Worst case scenario, you end up with valuable insights about what problems people have. As an early stage startup, this information is crucial to find product-market fit.</p><p>Here are some lessons I learned while taking a direct sales approach to SaaS. Most of them came from reading <a href="http://momtestbook.com/">The Mom Test</a>, talking to awesome people and experimenting on my own.</p><h2>3 direct sales tips to listen to your users</h2><h3>Writing down what you want to get from the conversation</h3><p>This list should be really short. My initial conversation guide had 15+ questions to get to understand the problem, and then a short demo. It worked kinda fine, but I usually got lost by question 5, and then started thinking about what to ask next instead of listening to the answer.</p><p>The Mom Test suggests you should "prepare your list of 3". Three things you want to get from each conversation, depending on who you'll be talking to. And that was magic.</p><p>In early Palabra demos, when I asked to have a quick chat to someone in a startup, I usually had three different scenarios:</p><ul><li>The founder talked to me directly, who had no details about the email automation strategies his/her team was using but could provide context.</li><li>I talked to a marketer in the startup, who usually had many years of experience and had tried a bunch of other email automation tools.</li><li>I talked to a technical co-founder or dev, who had a lot of questions about technical aspects of Palabra and had tried different integrations before.</li></ul><p>I prepared three different notes to look at before each conversation, one for each "buyer" persona, and wrote down my list of three.</p><p>I started asking questions that came to mind from listening to what people were saying, and spend almost no time looking at my notes. If I ever felt I was starting to get lost, I just glanced to my list of three for that particular person to check if I was missing something. Freedom.</p><h3>Having a structured set of questions</h3><p>This advice came from a great friend and the <a href="http://sofandrade.com/">best UX designer I've met</a>. She knows all about user interviews, and since I was also trying to learn from our prospects, I knew it would help. Her advice was to divide my questions into chunks or topics I wanted to know about.</p><p>Having differentiated topics gives you flexibility to follow the conversation and not worry about what to ask after each answer. If you ask a question from the first topic and your user's answer goes to a slightly different topic, you can go to that part of your guide and then come back after that's done.</p><p>As an example, this was the structure I ended up using for each guide:</p><ul><li>About them/their job/their goals</li><li>About their emails, what they were using them from</li><li>About their email automation tools, what they were using and how</li><li>About their pains, what was missing from their current tools?</li></ul><p>What usually happened is that my email questions got answers related to tools. So I just moved over to the "tools" set of questions and then looked to see if I was missing something important at the end.</p><p>A smart move was to leave questions about pains for last. By then I usually had enough information about their problem and could offer a clear solution with <a href="https://www.palabra.io/?utm_medium=direct-sales-tips-startups&amp;utm_source=blog">Palabra</a>.</p><p>If we had a solution, I'd briefly tell people why I thought this would work, and offered to show them in a demo. By focusing on their specific solution in the demo, I only showed one feature and not the whole product, which was a much better use of everyone's time.</p><h3>Doing some background research - but still ask people</h3><p>You can't go into a sales pitch without knowing who you're talking to. For B2B sales you need to know about the company and the person you're actually going to talk to. The key here is to use that information wisely.</p><p>I used to start conversations on what I'd learned from their landing page, to let people know I had done my homework. But his was actually making me start with the wrong foot -by talking too much.</p><p>Asking about their company and what they do there gives you inside information you wouldn't get from LinkedIn or a landing page. And it also helps break the ice, since it's an easy answer for anyone.</p><p>My solution was full transparency. I started each conversation by saying I had done a bit of research about them but still wanted to hear from themselves. Then I would ask what they usually do.</p><p>This was incredibly effective. Being honest took away all of my nervousness and allowed me to relax into the conversation. I felt like I had no secrets, I was just telling the truth and asking questions. And I think this works both ways: the person you're talking to will probably trust you more if you're …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.palabra.io/learning-to-listen-direct-sales-tips-for-early-stage-startups">https://blog.palabra.io/learning-to-listen-direct-sales-tips-for-early-stage-startups</a></em></p>]]>
            </description>
            <link>https://blog.palabra.io/learning-to-listen-direct-sales-tips-for-early-stage-startups</link>
            <guid isPermaLink="false">hacker-news-small-sites-24492609</guid>
            <pubDate>Wed, 16 Sep 2020 13:40:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why is Apple acting like an asshole?]]>
            </title>
            <description>
<![CDATA[
Score 560 | Comments 479 (<a href="https://news.ycombinator.com/item?id=24490326">thread link</a>) | @ig0r0
<br/>
September 16, 2020 | https://www.jessesquires.com/blog/2020/09/15/why-is-apple-acting-like-an-asshole/ | <a href="https://web.archive.org/web/*/https://www.jessesquires.com/blog/2020/09/15/why-is-apple-acting-like-an-asshole/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>Today Apple announced <a href="https://www.apple.com/apple-events/september-2020/">at their media event</a> that the final public release of iOS 14 ships tomorrow, which came as quite a shock to all third-party developers.</p>

<!--excerpt-->

<p>This unwelcome surprise comes against the backdrop of dozens of controversies around the App Store — most recently <a href="https://www.theverge.com/2020/6/16/21293419/hey-apple-rejection-ios-app-store-dhh-gangsters-antitrust">Hey.com</a> and <a href="https://daringfireball.net/linked/2020/08/28/apple-terminates-epic-games-account">Epic</a>, but more generally its <a href="https://marco.org/2020/09/11/app-review-changes">painfully confusing</a> and <a href="https://inessential.com/2020/05/10/heads_up_to_rss_reader_authors">arbitrarily applied</a> rules, its incomprehensible <a href="https://mjtsai.com/blog/tag/rejection/">app rejections</a> and their often sudden retractions, app <a href="https://www.macrumors.com/2016/03/07/flexbright-adjust-display-temperature/">approvals followed by sudden removals</a> without explanation, and the general unequal treatment of developers where <a href="https://gizmodo.com/researchers-uber-s-ios-app-had-secret-permissions-that-1819177235">big companies</a> or favorites <a href="https://mjtsai.com/blog/2019/02/27/bbedit-12-6-to-return-to-the-mac-app-store/">get special treatment</a>. It leaves me wondering, what the hell is Apple’s strategy here? This is not a flurry of bad PR for the sake of it. There are serious problems here that need to be addressed — in particular, Developer Relations.</p>

<div>
    
    <div>
        <figure>
            <img src="https://www.jessesquires.com/img/appholes.jpg" title="Appholes" alt="Appholes">
            <div>
                
            </div>
        </figure>
    </div>
    
</div>

<h4>* * *</h4>

<p>Historically, these events announce new hardware and the upcoming release of the next major version of iOS, which is typically made public a few days later or the following week. For as long as I can remember it goes something like this:</p>

<ul>
  <li>Apple hosts a media event on a Tuesday in September.</li>
  <li>Announcements include new iPhones, iPads, and Watches. Or, at least some combination of those. Maybe something about Apple TV.</li>
  <li>All of the new hardware will run the latest version of iOS (or watchOS, or tvOS).</li>
  <li>The next major release of iOS is announced to be shipping on Friday (in a few days) or sometime the following week, like the next Tuesday.</li>
</ul>

<p>But today, Apple announced that iOS 14 is shipping <strong>tomorrow</strong>. This was near the end of the event — at roughly 11:00 AM Pacific time. This means West Coast developers have half a day to put the final touches on their app updates for iOS 14 <strong>AND</strong> get their apps submitted with the just-released Xcode 12 GM <strong>AND</strong> get through App Store review. None of those tasks are trivial, and no one familiar with them would agree that this is a sufficient amount of time to complete them. If you happen to be working on the East Coast, this means you were given just a few hours before the working day was over to get your app ready and submitted. And if you live in Europe or anywhere else in the world, well, go fuck yourself and good luck tomorrow!</p>

<p>On top of this, critical bugs still exist in the latest releases of the SDKs, Xcode 12, and iOS 14. It seems they will not be addressed.</p>

<h4>* * *</h4>

<p>Given the increasingly tenuous relationship that Apple has with developers, I do not understand how it could be in their interest to act like such an asshole right now. Not to mention, it is unlikely that they will even be able to review all of these app submissions in time. We already do not feel valued due to the aforementioned issues, and this is an outright negligent response to developer relationships the company has damaged over the past few years. Announcing that iOS 14 ships tomorrow with virtually no notice to developers is yet another breach of trust, another disappointment, and quite frankly feels like a big ‘fuck you’ to developers. What purpose does it serve to place this last-minute, unnecessary stress on third-party developers?</p>

<p>Who is in charge of iOS releases at Apple that thought this was a good idea? Who is the head of Developer Relations that thought this was a good idea?</p>

<p>To whomever made these decisions: <strong>y’all fucked up. Again.</strong></p>

    </div></div>]]>
            </description>
            <link>https://www.jessesquires.com/blog/2020/09/15/why-is-apple-acting-like-an-asshole/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24490326</guid>
            <pubDate>Wed, 16 Sep 2020 07:26:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bazel For Open-Source C/C++ Libraries Distribution]]>
            </title>
            <description>
<![CDATA[
Score 64 | Comments 68 (<a href="https://news.ycombinator.com/item?id=24490089">thread link</a>) | @todsacerdoti
<br/>
September 15, 2020 | https://liuliu.me/eyes/bazel-for-libraries-distribution-an-open-source-library-author-perspective/ | <a href="https://web.archive.org/web/*/https://liuliu.me/eyes/bazel-for-libraries-distribution-an-open-source-library-author-perspective/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In the past a few days, I’ve been experimenting with Bazel as a library distribution mechanism for <a href="https://github.com/liuliu/ccv">ccv</a>.</p>

<p>I am pretty familiar with hermetic build systems at this point. My main knowledge comes from Buck dating 8 years back. At that time, it never occurred to me such a build system could eventually be a library distribution mechanism. During the same 8 years, NPM has taken over the world. New language-dependent package managers such as Go module, Cargo and Swift Package Manager popularized the concept of using the public repositories (GitHub) as the dependency references. Languages prior to this period, mainly C / C++ are moving to this direction, slowly.</p>

<p><a href="https://github.com/liuliu/ccv">ccv</a> has a simple autoconf based feature detection / configuration system. You would expect the package to work when <code>./configure &amp;&amp; make</code>. However, it never made any serious attempt to be too smart. My initial experience with monorepos at companies strongly influenced the decision to have a simple build system. I fully expect that serious consumers will vendor the library into their monorepo using their own build systems.</p>

<p>This has been true for the past a few years. But as I am finishing up <a href="https://libnnc.org/">nnc</a> and increasingly using that for other closed-source personal projects, maintaining a closed-source <em>monorepo</em> setup for my personal projects while upstreaming fixes is quite an unpleasant experience. On the other hand, <a href="https://libnnc.org/">nnc</a> from the beginning meant to be a low-level implementation. I am expected to have high-level language bindings at some point. Given that I am doing more application-related development with <a href="https://libnnc.org/">nnc</a> in closed-source format now, it feels like the right time.</p>

<p>Although there is no one-true library distribution mechanism for C / C++, there are contenders. From the good-old apt / rpm, to Conan, which has gained some mind-share in the open-source world in recent years.</p>

<p>The choice of Bazel is not accidental. I’ve been doing <a href="https://liuliu.me/eyes/migrating-ios-project-to-bazel-a-real-world-experience/">some Swift development with Bazel</a> and the experience has been positive. Moreover, the choice of high-level binding language for <a href="https://libnnc.org/">nnc</a>, I figured, would be Swift.</p>

<h2 id="configure">Configure</h2>

<p><a href="https://github.com/liuliu/ccv">ccv</a>’s build process, as much as I would rather not, is host-dependent. I use autoconf to detect system-wide libraries such as libjpeg and libpng, to configure proper compiler options. Although <a href="https://github.com/liuliu/ccv">ccv</a> can be used with zero dependency, in that configuration, it can sometimes be slow.</p>

<p>Coming from the monorepo background, Bazel doesn’t have many utilities that are as readily available as in autoconf. You can write automatic configurations in Starlark as <a href="https://docs.bazel.build/versions/master/skylark/repository_rules.html">repository rules</a>, but there is no good documentation on how to write robust ones.</p>

<p>I ended up <a href="https://github.com/liuliu/ccv/blob/unstable/WORKSPACE#L25">letting whoever use ccv to decide how they are going to enable certain features</a>. For things like CUDA, such configuration is not tenable. I ended up copying over <a href="https://github.com/liuliu/rules_cuda">TensorFlow’s CUDA rules</a>.</p>

<h2 id="dependencies">Dependencies</h2>

<p>Good old C / C++ libraries are notoriously indifferent to libraries dependencies v.s. toolchains. Autoconf detects both toolchain configurations as well as available libraries. These types of host dependencies make cross-compilation a skill in itself.</p>

<p>Bazel is excellent for in-tree dependencies. For out-tree dependencies however, there is no established mechanism. The popular way is to write a <a href="https://github.com/protocolbuffers/protobuf/blob/master/protobuf_deps.bzl#L5">repository rules to load relevant dependencies</a>.</p>

<p>This actually works well for me. It is versatile enough to handle cases that <a href="https://github.com/liuliu/ccv/blob/unstable/config/ccv.bzl#L103">have Bazel integrations</a> and <a href="https://github.com/liuliu/dflat/blob/unstable/deps.bzl#L17">have no Bazel integrations</a>.</p>

<h2 id="consume-bazel-dependencies">Consume Bazel Dependencies</h2>

<p>Consumption of the packaged Bazel dependencies then becomes as simple as adding <code>git_repository</code> to the <code>WORKSPACE</code> and call proper <code>&lt;your_library_name&gt;_deps()</code> repository rule.</p>

<p>After packaging <a href="https://libccv.org/">ccv</a> with Bazel, now <a href="https://github.com/liuliu/s4nnc/blob/main/WORKSPACE#L3">Swift for nnc can consume the packaged dependency</a>.</p>

<h2 id="semantic-versioning-challenges">Semantic Versioning Challenges</h2>

<p>While the Bazel-provided library distribution mechanism works well for my case, it is simplistic. For one, there is really no good way to do <a href="https://semver.org/">semantic versioning</a>. It is understandable. Coming from a monorepo culture, it is challenging for anyone to dive into dependency hells of library versioning. A <a href="https://donatstudios.com/Go-v2-Modules">slightly different story happened to Go</a> a while back as well.</p>

<p>It is messy if you want to pin a specific version of the library while your dependencies are not agreeing with you. This is going to be messy regardless in C / C++ world, unless you prelink these extremely carefully. Bazel’s philosophy from what I can see, seems largely on <em>keeping the trunk working</em> side. It is working so far, but one has to wonder whether this can scale if more libraries adopted Bazel as the distribution mechanism.</p>

<h2 id="closing-words">Closing Words</h2>

<p>The past a few months experience with Bazel has been delightful. While I would continue to use language specific tools (pip, Go modules, Cargo, NPM) when doing development in that particular language, Bazel is a capable choice for me when doing cross-language development. Concepts such as <code>workspace</code>, <code>git_repository</code>, <code>http_archive</code> fit well within the larger open-source ecosystem. And most surprisingly, it works for many-repo setup if you ever need to.</p>
</div></div>]]>
            </description>
            <link>https://liuliu.me/eyes/bazel-for-libraries-distribution-an-open-source-library-author-perspective/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24490089</guid>
            <pubDate>Wed, 16 Sep 2020 06:28:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Concurrency Cost Hierarchy]]>
            </title>
            <description>
<![CDATA[
Score 144 | Comments 25 (<a href="https://news.ycombinator.com/item?id=24489829">thread link</a>) | @signa11
<br/>
September 15, 2020 | https://travisdowns.github.io/blog/2020/07/06/concurrency-costs.html | <a href="https://web.archive.org/web/*/https://travisdowns.github.io/blog/2020/07/06/concurrency-costs.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    
<!-- boilerplate 
page.assets: /assets/concurrency-costs
assetpath: /assets/concurrency-costs
tablepath: /misc/tables/concurrency-costs
-->

<h2 id="introduction">Introduction</h2>

<p>Concurrency is hard to get <em>correct</em>, at least for those of us unlucky enough to be writing in languages which expose directly the guts of concurrent hardware: threads and shared memory. Getting concurrency correct <em>and</em> fast is hard, too. Your knowledge about single-threaded optimization often won’t help you: at a micro (instruction) level we can’t simply apply the usual rules of μops, dependency chains, throughput limits, and so on. The rules are different.</p>

<p>If that first paragraph got your hopes up, this second one is here to dash them: I’m not actually going to do a deep dive into the very low level aspects of concurrent performance. There are a lot of things we just don’t know about how atomic instructions and fences execute, and we’ll save that for another day.</p>

<p>Instead, I’m going to describe a higher level taxonomy that I use to think about concurrent performance. We’ll group the performance of concurrent operations into six broad <em>levels</em> running from fast to slow, with each level differing from its neighbors by roughly an order of magnitude in performance.</p>

<p>I often find myself thinking in terms of these categories when I need high performance concurrency: what is the best level I can practically achieve for the given problem? Keeping the levels in mind is useful both during initial design (sometimes a small change in requirements or high level design can allow you to achieve a better level), and also while evaluating existing systems (to better understand existing performance and evaluate the path of least resistance to improvements).</p>

<h3 id="a-real-world-example">A “Real World” Example</h3>

<p>I don’t want this to be totally abstract, so we will use a real-world-if-you-squint<sup id="fnref:realworld" role="doc-noteref"><a href="#fn:realworld">1</a></sup> running example throughout: safely incrementing an integer counter across threads. By <em>safely</em> I mean without losing increments, producing out-of-thin air values, frying your RAM or making more than a minor rip in space-time.</p>

<h3 id="source-and-results">Source and Results</h3>

<p>The source for every benchmark here is <a href="https://github.com/travisdowns/concurrency-hierarchy-bench">available</a>, so you can follow along and even reproduce the results or run the benchmarks on your own hardware. All of the results discussed here (and more) are available in the same repository, and each plot includes a <code>[data table]</code> link to the specific subset used to generate the plot.</p>

<h3 id="hardware">Hardware</h3>

<p>All of the performance results are provided for several different hardware platforms: Intel Skylake, Ice Lake, Amazon Graviton and Graviton 2. However except when I explicitly mention other hardware, the prose refers to the results on Skylake. Although the specific numbers vary, most of the qualitative relationships hold for the hardware too, but <em>not always</em>. Not only does the hardware vary, but the OS and library implementations will vary as well.</p>

<p>It’s almost inevitable that this will be used to compare across hardware (“wow, Graviton 2 sure kicks Graviton 1’s ass”), but that’s not my goal here. The benchmarks are written primarily to tease apart the characteristics of the different levels, and <em>not</em> as a hardware shootout.</p>

<p>Find below the details of the hardware used:</p>

<table>
  <thead>
    <tr>
      <th>Micro-architecture</th>
      <th>ISA</th>
      <th>Model</th>
      <th>Tested Frequency</th>
      <th>Cores</th>
      <th>OS</th>
      <th>Instance Type</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Skylake</td>
      <td>x86</td>
      <td>i7-6700HQ</td>
      <td>2.6 GHz</td>
      <td>4</td>
      <td>Ubuntu 20.04</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>Ice Lake</td>
      <td>x86</td>
      <td>i5-1035G4</td>
      <td>3.3 GHz</td>
      <td>4</td>
      <td>Ubuntu 19.10</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>Graviton</td>
      <td>AArch64</td>
      <td>Cortex-A72</td>
      <td>2.3 GHz</td>
      <td>16</td>
      <td>Ubuntu 20.04</td>
      <td>a1.4xlarge</td>
    </tr>
    <tr>
      <td>Graviton 2</td>
      <td>AArch64</td>
      <td>Neoverse N1</td>
      <td>2.5 GHz</td>
      <td>16<sup id="fnref:g2cores" role="doc-noteref"><a href="#fn:g2cores">2</a></sup></td>
      <td>Ubuntu 20.04</td>
      <td>c6g.4xlarge</td>
    </tr>
  </tbody>
</table>

<h2 id="level-2-contended-atomics">Level 2: Contended Atomics</h2>

<p>You’d probably expect this hierarchy to be introduced from fast to slow, or vice-versa, but we’re all about defying expectations here and we are going to start in the <em>middle</em> and work our way outwards. The middle (rounding down) turns out to be <em>level 2</em> and that’s where we will jump in.</p>

<p>The most elementary way to safely modify any shared object is to use a lock. It mostly <em>just works</em> for any type of object, no matter its structure or the nature of the modifications. Almost any mainstream CPU from the last thirty years has some type of locking<sup id="fnref:parisc" role="doc-noteref"><a href="#fn:parisc">3</a></sup> instruction accessible to userspace.</p>

<p>So our baseline increment implementation will use a simple mutex of type <code>T</code> to protect a plain integer variable:</p>

<div><div><pre><code><span>T</span> <span>lock</span><span>;</span>
<span>uint64_t</span> <span>counter</span><span>;</span>

<span>void</span> <span>bench</span><span>(</span><span>size_t</span> <span>iters</span><span>)</span> <span>{</span>
    <span>while</span> <span>(</span><span>iters</span><span>--</span><span>)</span> <span>{</span>
        <span>std</span><span>::</span><span>lock_guard</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>holder</span><span>(</span><span>lock</span><span>);</span>
        <span>counter</span><span>++</span><span>;</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>We’ll call this implementation <em><abbr title="Uses a std::mutex and std::lock_guard to protect a plain integer counter.">mutex add</abbr></em>, and on my 4 CPU Skylake-S i7-6700HQ machine, when I use the vanilla <code>std::mutex</code> I get the following results for 2 to 4 threads:</p>



<p>The reported value is the median of all trials, and the vertical black error lines at the top of each bar indicate the <em>interdecile range</em>, i.e., the values at the 10th and 90th percentile. Where the error bars don’t show up, it means there is no difference between the p10 and p90 values at all, at least within the limits of the reporting resolution (100 picoseconds).</p>

<p>This shows that the baseline contended cost to modify an integer protected by a lock starts at about 125 nanoseconds for two threads, and grows somewhat with increasing thread count.</p>

<p>I can already hear someone saying: <em>If you are just modifying a single 64-bit integer, skip the lock and just directly use the atomic operations that most ISAs support!</em></p>

<p>Sure, let’s add a couple of variants that do that. The <code>std::atomic&lt;T&gt;</code> template makes this easy: we can wrap any type meeting some basic requirements and then manipulate it atomically. The easiest of all is to use <code>std::atomic&lt;uint64&gt;::operator++()</code><sup id="fnref:post" role="doc-noteref"><a href="#fn:post">4</a></sup> and this gives us <em><abbr title="Uses an atomic increment on a single shared counter.">atomic add</abbr></em>:</p>

<div><div><pre><code><span>std</span><span>::</span><span>atomic</span><span>&lt;</span><span>uint64_t</span><span>&gt;</span> <span>atomic_counter</span><span>{};</span>

<span>void</span> <span>atomic_add</span><span>(</span><span>size_t</span> <span>iters</span><span>)</span> <span>{</span>
    <span>while</span> <span>(</span><span>iters</span><span>--</span><span>)</span> <span>{</span>
        <span>atomic_counter</span><span>++</span><span>;</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>The other common approach would be to use <a href="https://en.wikipedia.org/wiki/Compare-and-swap">compare and swap (<abbr title="Compare-and-swap: an atomic operation implemented on x86 and other CPUs.">CAS</abbr>)</a> to load the existing value, add one and then <abbr title="Compare-and-swap: an atomic operation implemented on x86 and other CPUs.">CAS</abbr> it back if it hasn’t changed. If it <em>has</em> changed, the increment raced with another thread and we try again.</p>

<p>Note that even if you use increment at the source level, the assembly might actually end up using <abbr title="Compare-and-swap: an atomic operation implemented on x86 and other CPUs.">CAS</abbr> if your hardware doesn’t support atomic increment<sup id="fnref:atomicsup" role="doc-noteref"><a href="#fn:atomicsup">5</a></sup>, or if your compiler or runtime just don’t take advantage of atomic operations even though they are available (e.g., see what even the newest version of <a href="https://godbolt.org/z/5h4K7y">icc does</a> for atomic increment, and what Java did for years<sup id="fnref:java" role="doc-noteref"><a href="#fn:java">6</a></sup>). This caveat doesn’t apply to any of our tested platforms, however.</p>

<p>Let’s add a counter implementation that uses <abbr title="Compare-and-swap: an atomic operation implemented on x86 and other CPUs.">CAS</abbr> as described above, and we’ll call it <em><abbr title="Uses a CAS loop to increment a single shared counter.">cas add</abbr></em>:</p>

<div><div><pre><code><span>std</span><span>::</span><span>atomic</span><span>&lt;</span><span>uint64_t</span><span>&gt;</span> <span>cas_counter</span><span>;</span>

<span>void</span> <span>cas_add</span><span>(</span><span>size_t</span> <span>iters</span><span>)</span> <span>{</span>
    <span>while</span> <span>(</span><span>iters</span><span>--</span><span>)</span> <span>{</span>
        <span>uint64_t</span> <span>v</span> <span>=</span> <span>cas_counter</span><span>.</span><span>load</span><span>();</span>
        <span>while</span> <span>(</span><span>!</span><span>cas_counter</span><span>.</span><span>compare_exchange_weak</span><span>(</span><span>v</span><span>,</span> <span>v</span> <span>+</span> <span>1</span><span>))</span>
            <span>;</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Here’s what these look like alongside our existing <code>std::mutex</code> benchmark:</p>



<p>The first takeaway is that, at least in this <em>unrealistic maximum contention</em> benchmark, using <abbr title="Uses an atomic increment on a single shared counter.">atomic add</abbr> (<a href="https://www.felixcloutier.com/x86/xadd"><code>lock xadd</code></a> at the hardware level) is significantly better than <abbr title="Compare-and-swap: an atomic operation implemented on x86 and other CPUs.">CAS</abbr>. The second would be that <code>std::mutex</code> doesn’t come out looking all that bad on Skylake. It is only slightly worse than the <abbr title="Compare-and-swap: an atomic operation implemented on x86 and other CPUs.">CAS</abbr> approach at 2 cores and beats it at 3 and 4 cores. It is slower than the atomic increment approach, but less than three times as slow and seems to be scaling in a reasonable way.</p>

<p>All of these operations are belong to <em>level 2</em> in the hierarchy. The primary characteristic of level 2 is that they make a <em>contended access</em> to a shared variable. This means that at a minimum, the line containing the data needs to move out to the caching agent that manages coherency<sup id="fnref:l3" role="doc-noteref"><a href="#fn:l3">7</a></sup>, and then back up to the core that will receive ownership next. That’s about 70 cycles minimum just for that operation<sup id="fnref:inter" role="doc-noteref"><a href="#fn:inter">8</a></sup>.</p>

<p>Can it get slower? You bet it can. <em>Way</em> slower.</p>

<h3 id="level-3-system-calls">Level 3: System Calls</h3>

<p>The next level up (“up” is not good here…) is level 3. The key characteristic of implementations at this level is that they make a <em>system call on almost every operation</em>.</p>

<p>It is easy to write concurrency primitives that make a system call <em>unconditionally</em> (e.g., a lock which always tries to wake waiters via a <code>futex(2)</code> call, even if there aren’t any), but we won’t look at those here. Rather we’ll take a look at a case where the fast path is written to avoid a system call, but the design or way it is used implies that such a call usually happens anyway.</p>

<p>Specifically, we are going to look at some <em>fair locks</em>. Fair locks allow threads into the critical section in the same order they began waiting. That is, when the critical section becomes available, the thread that has been waiting the longest is given the chance to take it.</p>

<p>Sounds like a good idea, right? Sometimes yes, but as we will see it can have significant performance implications.</p>

<p>On the menu are three different fair locks.</p>

<p>The first is a <a href="https://en.wikipedia.org/wiki/Ticket_lock">ticket lock</a> with a <code>sched_yield</code> in the spin loop. The idea of the yield is to give other threads which may hold the lock time to run. This <code>yield()</code> approach is publicly frowned upon by concurrency experts<sup id="fnref:notwhat" role="doc-noteref"><a href="#fn:notwhat">9</a></sup>, who then sometimes go right ahead and use it anyway.</p>

<p>We will call it <abbr title="A ticket lock that calls sched_yield in a spin loop while waiting for its turn.">ticket yield</abbr> and it looks like this:</p>



<div><div><pre><code><span>/**
 * A ticket lock which uses sched_yield() while waiting
 * for the ticket to be served.
 */</span>
<span>class</span> <span>ticket_yield</span> <span>{</span>
    <span>std</span><span>::</span><span>atomic</span><span>&lt;</span><span>size_t</span><span>&gt;</span> <span>dispenser</span><span>{},</span> <span>serving</span><span>{};</span>

<span>public:</span>
    <span>void</span> <span>lock</span><span>()</span> <span>{</span>
        <span>auto</span> <span>ticket</span> <span>=</span> <span>dispenser</span><span>.</span><span>fetch_add</span><span>(</span><span>1</span><span>,</span> <span>std</span><span>::</span><span>memory_order_relaxed</span><span>);</span>

        <span>while</span> <span>(</span><span>ticket</span> <span>!=</span> <span>serving</span><span>.</span><span>load</span><span>(</span><span>std</span><span>::</span><span>memory_order_acquire</span><span>))</span>
            <span>sched_yield</span><span>();</span>
    <span>}</span>

    <span>void</span> <span>unlock</span><span>()</span> <span>{</span>
        <span>serving</span><span>.</span><span>store</span><span>(</span><span>serving</span><span>.</span><span>load</span><span>()</span> <span>+</span> <span>1</span><span>,</span> <span>std</span><span>::</span><span>memory_order_release</span><span>);</span>
    <span>}</span>
<span>};</span>
</code></pre></div></div>

<p>Let’s plot the performance results for this lock alongside the existing approaches:</p>



<p>This is level 3 visualized: it is an order of magnitude slower than the level 2 approaches. The slowdown comes from the <code>sched_yield</code> call: this is a system call and these are generally on the order of 100s of nanoseconds<sup id="fnref:spectre" role="doc-noteref"><a href="#fn:spectre">10</a></sup>, and it shows in the results.</p>

<p>This lock <em>does</em> have a fast path where <code>sched_yield</code> isn’t called: if the lock is available, no spinning occurs and <code>sched_yield</code> is never called. However, the combination of being a <em>fair</em> lock and the high contention in this test means that a lock convoy quickly forms (we’ll describe this in more detail later) and so the spin loop is entered basically …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://travisdowns.github.io/blog/2020/07/06/concurrency-costs.html">https://travisdowns.github.io/blog/2020/07/06/concurrency-costs.html</a></em></p>]]>
            </description>
            <link>https://travisdowns.github.io/blog/2020/07/06/concurrency-costs.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24489829</guid>
            <pubDate>Wed, 16 Sep 2020 05:30:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Python's Innards: Introduction (2010)]]>
            </title>
            <description>
<![CDATA[
Score 164 | Comments 11 (<a href="https://news.ycombinator.com/item?id=24489604">thread link</a>) | @johnsonjo
<br/>
September 15, 2020 | https://tech.blog.aknin.name/2010/04/02/pythons-innards-introduction/ | <a href="https://web.archive.org/web/*/https://tech.blog.aknin.name/2010/04/02/pythons-innards-introduction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<p>A friend once said to me: <q>You know, to some people, C is just a bunch of macros that expand to assembly</q>. It’s been years ago (smartasses: it was also before <tt>llvm</tt>, ok?), but the sentence stuck with me. Do <em>Kernighan and Ritchie</em> really look at a C program and see assembly code? Does <em>Tim Berners-Lee</em> surf the Web any differently than you and me? And what on earth <em>did</em> <em>Keanu Reeves</em> see when he looked at all of that funky green gibberish soup, anyway? No, seriously, what the heck <em>did</em> he see there?! Uhm, back to the program. Anyway, what does Python look like in <em>Guido van Rossum</em>‘s<sup>1</sup> eyes?</p>
<p>This post marks the beginning of what should develop to a <a href="https://tech.blog.aknin.name/tag/pythons-innards/">series</a> on Python’s internals, I’m writing it since I believe that explaining something is the best way to grok it, and I’d very much like to be able to visualize more of Python’s ‘funky green gibberish soup’ as I read Python code. On the curriculum is mainly <em>CPython</em>, mainly <em>py3k</em>, mainly <em>bytecode evaluation</em> (I’m not a big compilation fan) – but practically everything around executing Python and Python-like code (<em>Unladen Swallow</em>, <em>Jython</em>, <em>Cython</em>, etc) might turn out to be fair game in this series. For the sake of brevity and my sanity, when I say <em>Python</em>, I mean <em>CPython</em> unless noted otherwise. I also assume a POSIX-like OS or (if and where it matters) Linux, unless otherwise noted. You should read this if you want to know how Python works. You should read this if you want to contribute to CPython. You should read this to find all the mistakes I’ll make and snicker at me behind me back or write snide comments. I realize it’s just <em>your</em> particular way to show affection.</p>
<p>I gather I’ll glean pretty much everything I write about from Python’s source or, occasionally, other fine materials (documentation, especially <a href="http://docs.python.org/py3k/c-api/index.html">this</a> and <a href="http://docs.python.org/py3k/extending/index.html">that</a>, certain PyCon lectures, <a href="https://tech.blog.aknin.name/2010/05/07/searching-mailing-list-archives-offline/">searching</a> <a href="http://mail.python.org/mailman/listinfo/python-dev">python-dev</a>, etc). Everything is out there, but I do hope my efforts at putting it all in one place to which you can RSS-subscribe will make your journey easier. I assume the reader knows some C, some OS theory, a bit less than some assembly (any architecture), a bit more than some Python and has reasonable UNIX fitness (i.e., feels comfortable installing something from source). Don’t be afraid if you’re not reasonably conversant in one (or more) of these, but I can’t promise smooth sailing, either. Also, if you don’t have a working toolchain to do Python development, maybe you’d like to head over <a href="https://tech.blog.aknin.name/2010/04/08/contributing-to-python/">here</a> and do as it says on the second paragraph (and onwards, as relevant).</p>
<p>Let’s start with something which I assume you already know, but I think is important, at least to the main way I understand… well, everything that I do understand. I look at it as if I’m looking at a machine. It’s easy in Python’s case, since Python relies on a Virtual Machine to do what it does (like many other interpreted languages). Be certain you understand “<a href="http://en.wikipedia.org/wiki/Virtual_machine#Process_virtual_machines">Virtual Machine</a>” correctly in this context: think more like JVM and less like VirtualBox (very technically, they’re the same, but in the real world we usually differentiate these two kinds of VMs). I find it easiest to understand “Virtual Machine” literally – it’s a machine built from software. Your CPU is just a complex electronic machine which receives all input (machine code, data), it has a state (registers), and based on the input and its state it will output stuff (to RAM or a Bus), right? Well, CPython is a machine built from software components that has a state and processes instructions (different implementations may use rather different instructions). This software machine operates in the process hosting the Python interpreter. Keep this in mind; I like the <a href="http://en.wikipedia.org/wiki/Turing_machine">machine</a> metaphor (as I explain in minute details <a href="https://tech.blog.aknin.name/2010/07/04/pythons-innards-for-my-wife/">here</a>).</p>
<p>That said, let’s start with a bird’s eye overview of what happens when you do this: <kbd>$ python -c 'print("Hello, world!")'</kbd>. Python’s binary is executed, the standard C library initialization which pretty much any process does happens and then the main function starts executing (see its source, <kbd>./Modules/python.c: main</kbd>, which soon calls <kbd>./Modules/main.c: Py_Main</kbd>). After some mundane initialization stuff (parse arguments, see if environment variables should affect behaviour, assess the situation of the standard streams and act accordingly, etc), <a href="http://docs.python.org/c-api/init.html#Py_Initialize">./Python/pythonrun.c: Py_Initialize</a> is called. In many ways, this function is what ‘builds’ and assembles together the pieces needed to run the CPython machine and makes ‘a process’ into ‘a process with a Python interpreter in it’. Among other things, it creates two very important Python data-structures: the <strong>interpreter state</strong> and <strong>thread state</strong>. It also creates the built-in <strong>module</strong> <a href="http://docs.python.org/library/sys.html">sys</a> and the module which hosts all <a href="http://docs.python.org/library/functions.html#built-in-functions">builtins</a>. At a later post(s) we will cover all these in depth.</p>
<p>With these in place, Python will do one of several things based on how it was executed. Roughly, it will either execute a string (the <kbd>-c</kbd> option), execute a module as an executable (the <kbd>-m</kbd> option), or execute a file (passed explicitly on the commandline or passed by the kernel when used as an interpreter for a script) or run its <a href="http://en.wikipedia.org/wiki/Read-eval-print_loop">REPL</a> loop (this is more a special case of the file to execute being an interactive device). In the case we’re currently following, it will execute a single string, since we invoked it with <kbd>-c</kbd>. To execute this single string, <kbd>./Python/pythonrun.c: PyRun_SimpleStringFlags</kbd> is called. This function creates the <kbd>__main__</kbd> <strong>namespace</strong>, which is ‘where’ our string will be executed (if you run <kbd>$ python -c 'a=1; print(a)'</kbd>, where is <kbd>a</kbd> stored? in this namespace). After the namespace is created, the string is executed in it (or rather, interpreted or <em>evaluated</em> in it). To do that, you must first transform the string into something that machine can work on.</p>
<p>As I said, I’d rather not focus on the innards of Python’s parser/compiler at this time. I’m not a compilation expert, I’m not entirely interested in it, and as far as I know, Python doesn’t have significant Compiler-Fu beyond the basic CS compilation course. We’ll do a (very) fast overview of what goes on here, and may return to it later only to inspect visible CPython behaviour (see the <a href="http://docs.python.org/reference/simple_stmts.html#the-global-statement">global</a> statement, which is said to affect parsing, for instance). So, the parser/compiler stage of <kbd>PyRun_SimpleStringFlags</kbd> goes largely like this: tokenize and create a <a href="http://en.wikipedia.org/wiki/Concrete_syntax_tree">Concrete Syntax Tree</a> (CST) from the code, transorm the CST into an <a href="http://en.wikipedia.org/wiki/Abstract_syntax_tree">Abstract Syntax Tree</a> (AST) and finally compile the AST into a <strong>code object</strong> using <kbd>./Python/ast.c: PyAST_FromNode</kbd>. For now, think of the code object as a binary string of machine code that Python VM’s ‘machinary’ can operate on – so now we’re ready to do interpretation (again, <em>evaluation</em> in Python’s parlance).</p>
<p>We have an (almost) empty <kbd>__main__</kbd>, we have a code object, we want to evaluate it. Now what? Now this line: <kbd>Python/pythonrun.c: run_mod, v = PyEval_EvalCode(co, globals, locals);</kbd> does the trick. It receives a code object and a namespace for <strong>globals</strong> and for <strong>locals</strong> (in this case, both of them will be the newly created <kbd>__main__</kbd> namespace), creates a <strong>frame object</strong> from these and executes it. You remember previously that I mentioned that <kbd>Py_Initialize</kbd> creates a thread state, and that we’ll talk about it later? Well, back to that for a bit: each Python thread is represented by its own thread state, which (among other things) points to the stack of currently executing frames. After the frame object is created and placed at the top of the thread state stack, it (or rather, the byte code pointed by it) is evaluated, opcode by opcode, by means of the (rather lengthy) <kbd>./Python/ceval.c: PyEval_EvalFrameEx</kbd>.</p>
<p><kbd>PyEval_EvalFrameEx</kbd> takes the frame, extracts opcode (and operands, if any, we’ll get to that) after opcode, and executes a short piece of C code matching the opcode. Let’s take a closer look at what these “opcodes” look like by disassembling a bit of compiled Python code:</p>
<pre title="">&gt;&gt;&gt; from dis import dis # ooh! a handy disassembly function!
&gt;&gt;&gt; co = compile("spam = eggs - 1", "&lt;string&gt;", "exec")
&gt;&gt;&gt; dis(co)
  1           0 LOAD_NAME                0 (eggs)
              3 LOAD_CONST               0 (1)
              6 BINARY_SUBTRACT     
              7 STORE_NAME               1 (spam)
             10 LOAD_CONST               1 (None)
             13 RETURN_VALUE        
&gt;&gt;&gt; 
</pre>
<p>…even without knowing much about Python’s bytecode, this is reasonably readable. You “load” the name <kbd>eggs</kbd> (where do you load it from? where do you load it to? soon), and also load a constant value (<kbd>1</kbd>), then you do a “binary subtract” (what do you mean ‘binary’ in this context? between which operands?), and so on and so forth. As you might have guessed, the names are “loaded” from the <kbd>globals</kbd> and <kbd>locals</kbd> namespaces we’ve seen earlier, and they’re loaded onto an operand stack (not to be confused with the stack of running frames), which is exactly where the binary subtract will pop them from, subtract one from the other, and put the result back on that stack. “Binary subtract” just means this is a subtraction opcode that has two operands (hence it is “binary”, this is not to say the operands are binary numbers made of ‘0’s and ‘1’s).</p>
<p>You can go look at <kbd>PyEval_EvalFrameEx</kbd> at <kbd>./Python/ceval.c</kbd> yourself, it’s not a small function by any means. For practical reasons I can’t paste too much code from there in here, but I will just paste the code that runs when a <kbd>BINARY_SUBTRACT</kbd> opcode is found, I think it really illustrates things:</p>
<pre title="">        TARGET(BINARY_SUBTRACT)
            w = POP();
            v = TOP();
            x = PyNumber_Subtract(v, w);
            Py_DECREF(v);
            Py_DECREF(w);
            SET_TOP(x);
            if (x != NULL) DISPATCH();
            break;
</pre>
<p>…pop something, take the top (of the operand stack), call a C function called PyNumber_Subtract() on these things, do something we still don’t understand (but will in due time) called “Py_DECREF” on both, set the top of the stack to the result of the subtraction (overwriting the previous top) and then do something else we don’t understand if x is not null, which is to do a …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tech.blog.aknin.name/2010/04/02/pythons-innards-introduction/">https://tech.blog.aknin.name/2010/04/02/pythons-innards-introduction/</a></em></p>]]>
            </description>
            <link>https://tech.blog.aknin.name/2010/04/02/pythons-innards-introduction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24489604</guid>
            <pubDate>Wed, 16 Sep 2020 04:43:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[North Pacific Logbook]]>
            </title>
            <description>
<![CDATA[
Score 90 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24489257">thread link</a>) | @blast
<br/>
September 15, 2020 | https://100r.co/site/north_pacific_logbook.html | <a href="https://web.archive.org/web/*/https://100r.co/site/north_pacific_logbook.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The passage from <b>Japan</b> (Shimoda) to <b>Canada</b> (Victoria) took <b>51 days</b>, and it was the hardest thing we've ever done. We decided to keep a logbook, to better remember it and so it can help others who wish to make this trip.</p><div>
	<!--  -->
	<tbody><tr><th colspan="3" id="week1">Week 1</th></tr>
	<tr>
		<td rowspan="6">June 9th</td>
		<td>0600</td>
		<td>We woke up early today, as we had little time to prepare before leaving Japan. Why so last minute? Because we only decided to leave yesterday morning. The reason we decided so late, was because we were waiting for a SIM card for our Iridium GO satellite phone, and we received it yesterday morning. As soon as we got it, we grabbed our passports and boat papers and hurried to the Immigration Office in Shizuoka to check out (a 4-5 hour train ride away). We were eager to leave on the 9th, as there was a good weather window, with moderate winds coming from a favourable direction. Because we weren't planning to leave until late yesterday morning, there were many tasks we had no yet done, or had not had time to do.<p>We're usually more organized than this, with only a few menial tasks to do, but not this time. Last minute departures is not our style, but we also wanted to take this window. We had to find a post box to send the pocket wifi we rented and to fill our water tanks — this may not seem like much, but it was, as it piled up on top of other things we'd forgotten, like finding and installing the pot holders to the stovetop, installing the jack lines, taking out the tethers, putting key items back in the ditch bag plus a number of other last minute things that had escaped us at the time.</p></td>
	</tr>
	<!--  -->
	<tr>
		<td>0700</td>
		<td>We meet Shuhei, Thomas and Anja on the sailing vessel Robusta for coffee, turning down a cup as coffee, as it never sits right on the first day at sea. We use this opportunity to chat, meanwhile butterflies gather in my gut. I am nervous. I always am before a big trip and this time is no different, although this is our biggest passage yet, and will also likely be the most challenging. My gut has every right to twist itself into knots. We ask Shuhei to drop off our pocket wifi in a post box, he agrees ­— ah, what a kind person. He came by this with his truck to help Robusta with some last minute tasks, like getting produce, gas etc. We had done most of that ahead of time.</td>
	</tr>
	<!--  -->
	<tr>
		<td>0800</td>
		<td>We push off our spot and head over to the Shimoda Boat Services pontoon to fill our water tanks. We tied up to it and began to ferry bins back and forth to empty them in our tank. We filled as many recipients as we could carry, as we don't know how long the trip will take. Once the tanks and jerry cans were full, we left the pontoon and headed outside of the breakwater. The Shimoda coastguard ship was lifting anchor at the time, it went past us, disappearing quickly as it was going much faster. Outside of the breakwater, we saw the lighthouse on our starboard side, the one we had difficulty rounding when we arrived here a week and a half ago due to 30-knot winds off our bow. Today, the seas were tame and the skies clear and blue. <p>We saw the Kurofune, a replica of Commodore Perry's black ship, taking tourists about the harbor. It was the first time we'd seen it on the water, as there weren't many tourists before due to concerns with the coronavirus. Now that the state of emergency's been lifted, people started traveling more around the country.</p></td>
	</tr>
	<!--  -->
	<tr>
		<td>1200</td>
		<td>The current is pushing us along, fast. We passed Oshima island at a ridiculous speed of 9.5 knots! The kuroshio, or <i>black current</i>, is very strong in this area, and even stronger between the islands as the water is forced through a narrow opening. We had no problem with ships, even with many heading to Tokyo. Our speed made it easy to work our way out of the main shipping channel. We are flying! Pino is happy to be moving again, and as are we.</td>
	</tr>
	<!--  -->
	<tr>
		<td>1430</td>
		<td>We saw porpoises in the water! It's been too long! They came for a bow-riding session. We missed them. Winds are coming out of the SW, at a good speed of 12-15 knots. We're going at 8 knots. For lunch, we had inari pouches, a meal we'd purchased at MaxValue the night before. It's nice not having to cook on the first day. Neither of us are sea sick, but going below is still difficult and can easily trigger it. We stay outside instead, enjoying the good wind, weather and sun. <p>Devine is reading "The mushrooom at the end of the world", while I steer us east. We tried calling Robusta on the VHF, but got no answer, either they're too far or their radio isn't on.</p></td>
	</tr>
	<!--  -->
	<tr>
		<td>1700</td>
		<td>Wind rises to 20 knots, we put on our foul weather gear as we don't want to wet our clothes. We won't be doing laundry in this trip, so keeping clothes dry is crucial.</td>
	</tr>
	<!--  -->
	<tr>
		<td rowspan="4">June 10th</td>
		<td>0800</td>
		<td>We download the weather, it is the same as yesterday, but it looks like the wind will increase this evening. Both of us are feeling sick and grumpy. We're experiencing the early symptoms of sea sickness, which usually means a headache, reduced appetite, morose view on things etc. This happens on every trip. Neither of us have ever vomited, thankfully.<p>Yesterday we sent Robusta an email and got a reply, they are ok and are southwest of us.</p></td>
	</tr>
	<!--  -->
	<tr>
		<td>1200</td>
		<td>We napped hard, then awoke and decided that we should try and cook something. Neither of us feel like eating rice balls, we regret getting so many as we aren't sure we can eat them. We have no appetite, but try to eat anyway.<p>We ate raw snap peas as a snack, the texture was weird in our mouths. Devine made spicy ramen, which were very, very spicy. I couldn't finish my bowl. We had a grapefruit for desert, and made a mess on deck trying to pry it apart. The deck had red on it for a while afterwards.</p></td>
	</tr>
	<!--  -->
	<tr>
		<td>1700</td>
		<td>We check the weather again. We don't normally check it twice a day as it eats up data, but the weather was changing so fast...! We wanted to know what was going on. We're glad we looked, as the wind was set to increase by a lot. If we hadn't checked, we might not have set the second reef point in our main. The last thing we want in this ocean is to have too much canvas up.</td>
	</tr>
	<!--  -->
	<tr>
		<td>1800</td>
		<td> We eat chips as a snack, as we are not hungry for a full dinner. Everything tastes weird? It's like our taste buds are going crazy. The only thing that goes down easy is salty foods.</td>
	</tr>
	<!--  -->
	<tr>
		<td rowspan="6">June 11th</td>
		<td>0200</td>
		<td>Saw a tanker ahead, but it wasn't moving? We passed its stern, wondering why it was idling out here.</td>
	</tr>
	<!--  -->
	<tr>
		<td>0900</td>
		<td>We've reduced the jib, as the wind is a strong and steady 27 knots. We are sailing east, although the current has pushed us higher than we wanted. We are at 36 degrees, and it is worrisome as we knew it was safer to stay under 35. The wind above that line tends to be stronger. Robusta was at 33 degrees, upon exiting Shimoda they took a more southerly route, I wish we'd done the same. We underestimated the strength of this current. We have peanut butter toast with slices of banana on top for breakfast.<p>Devine sent a happy birthday message to his sister.</p></td>
	</tr>
	<!--  -->
	<tr>
		<td>1100</td>
		<td>The waves are getting bigger. We are worried about our fresh produce as we can't eat any of it. This has never happened to us before. The sun is warm and is hastening the rotting of some of the more sensitive vegetables, like broccoli. We had to throw away half a head overboard today. I hope we'll find our appetites again, I'd rather the food end up in our stomachs than in the ocean.</td>
	</tr>
	<!--  -->
	<tr>
		<td>1200</td>
		<td>Devine made a salad for lunch to try and use up some of our uglier produce. The wind is blowing food off of my fork as I eat, maybe not the best meal to have on a windy day. The wind is blowing 25-30 knots, generating big waves, but at least it is sunny.</td>
	</tr>
	<!--  -->
	<tr>
		<td>1300</td>
		<td>We watched seabirds pirouetting in the distance, they've no problem in this wind. Their movements are sharp and fast. We don't know what kind of bird they are, they're brown with a white stomach.<p>We've noticed the automatic bilge pump keeps going off, we think there's a leak below the waterline, if so, that is worrisome. We tried to find where it was, but found nothing. None of the thru-hulls are leaking. I also checked the hose connections, nada! I suspect it may be the rudder post that is leaking, but for now it is impossible to look as I'd have to get into the cockpit locker, which is full of water bins and other heavy gear. For now, we try and check the bilge often, pumping the water out by hand every 2h or so. We have two manual bilge pumps, one in the cockpit and another in the cabin under the sink. The automatic bilge pump doesn't empty the bilge entirely, as it sits on a little stand above the lowest point, but the manual pump tube touches the bottom and does a better job of sucking up the majority of the water. If anything, the automatic pump serves as an alarm.</p></td>
	</tr>
	<!--  -->
	<tr>
		<td>1700</td>
		<td>Made spaghetti with eggplant and green peppers for dinner. It is still hard to finish food, so we started making smaller portions as to avoid waste. Both of us are still plagued with weird tastebuds. Sweet is too sweet, veggies are bland...</td>
	</tr>
	<!--  -->
	<tr>
		<td rowspan="2">June 12th</td>
		<td>0800</td>
		<td>Rain. All day. It won't stop. We've asked it to, but <i>it won't listen</i>.</td>
	</tr>
	<!--  -->
	<tr>
		<td>1900</td>
		<td>The conditions out here are horrible. We are running with the waves and wind, we wished we'd put in the 3rd reef earlier. It is too late to do it now, as it is dark and stormy. Neither of us eat dinner, we're in sparta mode. </td>
	</tr>
	<!--  -->
	<tr>
		<td rowspan="4">June 13th</td>
		<td>0800</td>
		<td>It is still raining a lot, with winds gusting in the high 30's. This weather is demoralizing, but at least we are making good easting and getting further and further away from Japan. I never thought I'd be happy about getting away from Japan, it's my favorite place in the world...! The ocean around the country is mean, and another entity entirely, lingering here is dangerous. <i>Oh how much I wish the rain would stop</i>, everything would be more pleasant if the rain stopped.</td>
	</tr>
	<!--  -->
	<tr>
		<td>1200</td>
		<td>Devine made pasta with a mustard sauce for lunch, I ate half and left the bowl on the stove. It was delicious but I couldn't finish, I'll keep it as a snack for later. We had our usual …</td></tr></tbody></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://100r.co/site/north_pacific_logbook.html">https://100r.co/site/north_pacific_logbook.html</a></em></p>]]>
            </description>
            <link>https://100r.co/site/north_pacific_logbook.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24489257</guid>
            <pubDate>Wed, 16 Sep 2020 03:22:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Go’s Major Versioning Sucks – From a Fanboy]]>
            </title>
            <description>
<![CDATA[
Score 166 | Comments 162 (<a href="https://news.ycombinator.com/item?id=24488745">thread link</a>) | @lanecwagner
<br/>
September 15, 2020 | https://qvault.io/2020/09/15/gos-major-version-handling-sucks-from-a-fanboy/ | <a href="https://web.archive.org/web/*/https://qvault.io/2020/09/15/gos-major-version-handling-sucks-from-a-fanboy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			
<p>I’m normally a fan of the rigidity within the Go toolchain. In fact, we use Go on the <a href="https://app.qvault.io/dashboard/courses">front and backend at Qvault</a>. It’s wonderful to have standardized formatting, vetting, and testing across the entire language. The first real criticism I’ve had is with the way Go modules handle major versions. It’s over-the-top opinionated and slows down development in a significant number of scenarios.</p>



<h2>Refresher on “Go Mod”</h2>



<p>Go modules, and the associated commands <code>go mod</code> and <code>go get</code> can be thought of as Go’s equivalents to NPM and Yarn. The Go toolchain provides a way to manage dependencies and lock the versions that a collection of code depends on.</p>



<p>One of the most common operations is to update a dependency in an existing module. For example:</p>



<pre><code lang="bash"># update all dependencies
go get -u ./...

# add missing and remove unused dependencies
go mod tidy

# save all dependency code in the project's "vendor" folder
go mod vendor</code></pre>



<h2>Semantic Versioning</h2>



<p>Go modules use git tags and semantic versioning to keep track of the versions of dependencies that are compatible with the module in question. Semantic versioning is a way to format version numbers and it looks like this: <code>v{MAJOR}.{MINOR}.{PATCH}</code>. For example, <code>v1.2.3</code>.</p>



<p>Each number is to be incremented according to the following standards:</p>



<pre><code lang="bash">MAJOR version when you make incompatible API changes,
MINOR version when you add functionality in a backwards compatible manner, and
PATCH version when you make backwards compatible bug fixes.</code></pre>



<h2>Package-Side Problems</h2>



<p>Go has decided that all versions beyond <code>v0</code> and <code>v1</code> are required to use the major version in the module path. There are two ways to accomplish this. </p>



<p><strong>The first and recommended way</strong> is laid out in an example on the <a rel="noreferrer noopener" href="https://blog.golang.org/v2-go-modules#TOC_4." target="_blank">Go Blog</a>:</p>



<blockquote><p>To start development on&nbsp;<code>v2</code>&nbsp;of&nbsp;<code>github.com/googleapis/gax-go</code>, we’ll create a new&nbsp;<code>v2/</code>&nbsp;directory and copy our package into it.</p></blockquote>



<p>In other words, for every major version, we are encouraged to maintain a new copy of the entire codebase. This is also the only way to do it if you want pre-modules users to be able to use your package.</p>



<p><strong>The second way</strong> is to just change the name of your module in <code>go.mod</code>. Fore example, <code>module github.com/lane-c-wagner/go-tinydate</code> would become <code>module github.com/lane-c-wagner/go-tinydate/v2</code>. Besides this not working for older versions of Go, I also find it problematic because it breaks (in my mind) one of the most useful things about module names – they reflect the file path.</p>



<h2>Package-Side Solutions</h2>



<p>Allow package maintainers to specify the major version simply by updating git tags, no module name changes required. There is no need for two sources of truth.</p>



<p>We can enforce safe updating by adding warnings or prompts to the <code>go get</code> CLI. We don’t have to add unnecessary time-consuming policies.</p>



<h2>Client-Side Problems</h2>



<p>When new versions of dependencies are released we have a simple command to get the newest stuff: <code>go get -u</code>. The problem is that this command has no way to automatically update to a new major version. It will only download new minor changes and patches. There isn’t even a console message to inform you that a new major version exists!</p>



<p>That said, the reason for not auto-updating is clear, and to be fair, well-founded:</p>



<blockquote><p>If an old package and a new package have the same import path, the new package must be backwards compatible with the old package.</p><cite><a href="https://research.swtch.com/vgo-import" rel="noopener">Import compatibility rule</a></cite></blockquote>



<p>In other words, we should only increment major versions when making breaking changes, and if breaking changes are made they can’t have the same import path. While this makes sense, I think a simple console warning would have been a better solution than forcing a cumbersome updating strategy on the community.</p>



<p><strong>Another problem </strong>on the client-side is that we don’t only need to update <code>go.mod</code>, but we actually need to <code>grep</code> through our codebase and change each import statement to point to the new major version:</p>



<blockquote><p>Users who wanted to use&nbsp;<code>v2</code>&nbsp;had to change their package imports and module requirements to&nbsp;<code>github.com/googleapis/gax-go/v2</code>.</p></blockquote>



<p>Instead of a few simple CLI commands to get the latest dependencies, we’re making changes to the code itself.</p>



<h3>A Caveat – Diamond Imports</h3>



<p>Using different paths for different major versions makes more sense in situations where we may require two different versions of the same package, you know, <a aria-label="diamond imports (opens in a new tab)" href="https://research.swtch.com/vgo-import#dependency_story" target="_blank" rel="noreferrer noopener nofollow">diamond imports</a> and all that. This is the exception, not the rule, and it seems strange to tap dance around a problem that doesn’t exist in most codebases.</p>



<h2>Client-Side Solution</h2>



<p><code>go get -u</code> should have an additional command line flag to update major versions, and should default to showing a warning that there is a newer major version you don’t have yet.</p>



<p><em>Default</em> import paths should not change between major versions. If a module requires various versions, those <em>extra</em> versions could be flagged by having a different path.</p>



<h2>Why This Sucks For Me</h2>



<p>It is often the case that I want to build a package that has domain-specific logic and will only be used only in services at the small company I work for. For example, we have a repo that holds the <code>struct{}</code> definitions for common entities used across our system.</p>



<p>Occasionally we need to make backward-incompatible changes to those struct definitions. If it were an open-source library we wouldn’t make changes so often, but because it’s internal and we are aware of all the dependencies, we change the names of exported fields <em>regularly</em>. We aren’t changing names because we chose bad ones to begin with, we are usually changing names because requirements from the business change rapidly in a startup. </p>



<p>This means major version changes are a fairly regular occurrence. Some say that we should just stay on <code>v0</code>, and that’s a reasonable solution. The problem is these ARE production packages that are being used by a wide number of services. We WANT to Semver.</p>



<p>Go makes updating major versions so cumbersome that in the majority of cases, we have opted to just increment minor versions when we should increment major versions. We want to follow the proper versioning scheme, we just don’t want to add the unnecessary steps to our dev process.</p>



<h2>Hey – I Get It</h2>



<p>I understand why these decisions were made – and I even think in a lot of cases they were great decisions. For any open-source or public facing module this makes great sense. The Go toolchain is enforcing strict rules that encourage good API design.</p>



<p>In their effort to make public APIs great, they made it unnecessarily hard to have good “local” package design.</p>



<p>There is an <a href="https://github.com/golang/go/issues/40323" rel="noopener">open issue on Github</a> that would make new major versions more discoverable from the CLI. Take a look at that if you are interested.</p>



<p>Go still has the best toolchain and ecosystem. NPM and PIP can suck it.</p>



<p>If you disagree, @ me on Twitter.</p>







<h2>Related Reading</h2>



<ul><li><a href="https://qvault.io/2020/08/15/optimize-for-simplicity-first/">Optimize for Simplicity First</a></li><li><a href="https://qvault.io/2019/10/21/golang-constant-maps-slices/">Constant Maps and Slices in Go</a></li><li><a href="https://qvault.io/2020/08/07/saving-a-third-of-our-memory-by-re-ordering-go-struct-fields/">Saving Memory by Re-ordering Go Structs</a></li></ul>
		</div></div>]]>
            </description>
            <link>https://qvault.io/2020/09/15/gos-major-version-handling-sucks-from-a-fanboy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24488745</guid>
            <pubDate>Wed, 16 Sep 2020 01:42:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When you browse Instagram and find Tony Abbott's passport number]]>
            </title>
            <description>
<![CDATA[
Score 2287 | Comments 331 (<a href="https://news.ycombinator.com/item?id=24488224">thread link</a>) | @michael_fine
<br/>
September 15, 2020 | https://mango.pdf.zone/finding-former-australian-prime-minister-tony-abbotts-passport-number-on-instagram | <a href="https://web.archive.org/web/*/https://mango.pdf.zone/finding-former-australian-prime-minister-tony-abbotts-passport-number-on-instagram">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

    

    <div itemprop="articleBody">
        <hr>
        <p><img src="https://mango.pdf.zone/img/sunburnt-country/title.png" alt="title image what's up twitter-large"></p>



<p>So you know when you’re flopping about at home, minding your own business, drinking from your water bottle in a way that does not possess <em>any</em> intent to subvert the Commonwealth of Australia?</p>

<p>It’s a feeling I know all too well, and in which I was vigorously partaking when I got this message in “the group chat”<sup id="fnref:groupchat" role="doc-noteref"><a href="#fn:groupchat">1</a></sup>.</p>

<p><img src="https://mango.pdf.zone/img/sunburnt-country/groupchat.png" alt="Can you hack this man?|medium">
<em>A nice message from my friend, with a photo of a boarding pass 🙂 A good thing about messages from your friends is that they do not have any rippling consequences 🙂🙂🙂</em></p>

<p>The man in question is <a href="https://en.wikipedia.org/wiki/Tony_Abbott">Tony Abbott</a>, one of Australia’s <em>many</em> former Prime Ministers.</p>

<p><img src="https://mango.pdf.zone/img/sunburnt-country/tony_abbott_wikipedia.png" alt="if u google tony abbott u get this|small">
<em>That’s him, officer</em></p>

<p>For security reasons, we try to change our Prime Minister every six months, and to never use the same Prime Minister on multiple websites.<sup id="fnref:kevin07" role="doc-noteref"><a href="#fn:kevin07">2</a></sup></p>

<h4 id="the-boarding-pass-photo">The boarding pass photo</h4>
<p>This particular former PM had just posted a picture of his boarding pass on Instagram (Instagram, in case you don’t know it, is an app you can open up on your phone any time to look at ads).</p>

<p><img src="https://mango.pdf.zone/img/sunburnt-country/instagrampost.PNG" alt="Instagram post showing boarding pass|large">
<em>The since-deleted Instagram post showing the boarding pass and baggage receipt. The caption reads “coming back home from japan 😍😍  looking forward to seeing everyone! climate change isn’t real 😌 ok byeee”</em></p>

<h4 id="can-you-hack-this-man">“Can you hack this man?”</h4>
<p>My friend<sup id="fnref:hoggemoade" role="doc-noteref"><a href="#fn:hoggemoade">3</a></sup> (who we will refer to by their group chat name, 𝖍𝖔𝖌𝖌𝖊 𝖒𝖔𝖆𝖉𝖊) is asking<sup id="fnref:onbehalf" role="doc-noteref"><a href="#fn:onbehalf">4</a></sup> whether I can “hack this man” not because I am the kind of person who regularly commits 𝒄𝒚𝒃𝒆𝒓 𝒕𝒓𝒆𝒂𝒔𝒐𝒏 on a whim, but because we’d recently been talking about boarding passes.</p>

<p>I’d said that people post pictures of their boarding passes all the time, not knowing that it can sometimes be used to get their passport number and stuff. They just post it being like “omg going on holidayyyy 😍😍😍”, unaware that they’re posting cringe.</p>

<p><img src="https://mango.pdf.zone/img/sunburnt-country/instagramboardingpasses.png" alt="screenshot of #boardingpass on instagram|medium">
<em>People post their boarding passes all the time, because it’s not clear that they’re meant to be secret</em></p>

<p>Meanwhile, some hacker is rubbing their hands together, being all “yumyum identity fraud 👀” in their dark web Discord, because this happens a <em>lot</em>.</p>

<p><img src="https://mango.pdf.zone/img/sunburnt-country/boardingpassposts.png" alt="screenshot of #boardingpass on instagram"></p>

<hr>

<p>So there I was, making intense and meaningful eye contact with this chat bubble, asking me if I could “hack this man”.</p>

<h3 id="surely-you-wouldnt">Surely you wouldn’t</h3>
<p>Of course, my friend wasn’t <em>actually</em> asking me to hack the former Prime Minister.</p>



<p>However.</p>



<p>You <em>gotta</em>.</p>

<p>I mean… what are you gonna do, <em>not</em> click it? Are you gonna let a <em>link</em> that’s like 50% advertising tracking ID tell you what to do? Wouldn’t you be <em>curious</em>?</p>

<p>The former Prime Minister had just posted his boarding pass. Was that <em>bad</em>? Was someone in danger? I didn’t know.</p>

<p>What I did know was: the <em>least</em> I could do<sup id="fnref:nocrime" role="doc-noteref"><a href="#fn:nocrime">5</a></sup> for my country would be to have a casual browse 👀</p>

<h2 id="investigating-the-boarding-pass-photo">Investigating the boarding pass photo</h2>
<h3 id="step-1-hubris">Step 1: Hubris</h3>

<p>So I had a bit of a casual browse, and got the picture of the boarding pass, and then…. I didn’t know what was supposed to happen after that.</p>

<p>Well, I’d heard that it’s bad to post your boarding pass online, because if you do, a bored 17 year-old Russian boy called “Katie-senpai” might somehow use it to commit identity fraud. But I don’t know anyone like that, so I just clumsily googled some stuff.</p>

<h4 id="googling-how-2-hakc-boarding-pass">Googling how 2 hakc boarding pass</h4>
<p><img src="https://mango.pdf.zone/img/sunburnt-country/uhhboardingpasshacking.png" alt="uhhh|small"></p>

<p>Eventually I found <a href="https://null-byte.wonderhowto.com/how-to/hackers-use-hidden-data-airline-boarding-passes-hack-flights-0180728/">a blog post</a> explaining that yes, pictures of boarding passes can indeed be used for Crimes. The part you wanna be looking at for all your criming needs is the barcode, because it’s got the “Booking Reference” (e.g. <code>H8JA2A</code>) in it.</p>

<p>Why do you want the booking reference? It’s one of the two things you need to log in to the airline website to manage your flight.</p>

<p>The second one is your… last name. I was really hoping the second one would be like a password or something. But, no, it’s the booking reference the airline emails you and prints on your boarding pass. And it also lets you log in to the airline website?</p>

<p>That sounds suspiciously like a password to me, but like I’m still fine to pretend it’s not if you are.</p>

<h3 id="step-2-scan-the-barcode">Step 2: Scan the barcode</h3>
<p>I’ve been practicing every morning at sunrise, but still can’t scan barcodes with my eyes. I had to settle for a barcode scanner app on my phone, but when I tried to scan the picture in the Instagram post, it didn’t work :((</p>

<p><img src="https://mango.pdf.zone/img/sunburnt-country/boardingpass.png" alt="the boarding pass photo">
<em>Maybe I shouldn’t have blurred out the barcode first</em></p>

<h3 id="step-2-scan-the-barcode-but-more">Step 2: Scan the barcode, but more</h3>

<p>Well, maybe it wasn’t scanning because the picture was too blurry.</p>

<p>I spent around 15 minutes in an “enhance, ENHANCE” montage, fiddling around with the image, increasing the contrast, and so on. Despite the montage taking up way too much of the 22 minute episode, I couldn’t even get the barcode to scan<sup id="fnref:step3" role="doc-noteref"><a href="#fn:step3">6</a></sup>.</p>

<h3 id="step-2-notice-that-the-booking-reference-is-printed-right-there-on-the-paper">Step 2: Notice that the Booking Reference is printed right there on the paper</h3>

<p>After staring at this image for 15 minutes, I noticed the Booking Reference is just… printed on the baggage receipt.</p>

<p>I graduated university.</p>

<p>But it did not prepare me for this.</p>

<p><img src="https://mango.pdf.zone/img/sunburnt-country/bookingrefhighlighted.png" alt="Boarding pass with booking reference highlighted">
<em>askdjhaflajkshdflkh</em></p>

<h3 id="step-3-visit-the-airlines-website">Step 3: Visit the airline’s website</h3>

<p><img src="https://mango.pdf.zone/img/sunburnt-country/bookinglogin2.png" alt="Manage booking login screen with empty fields-large"></p>

<p>After recovering from <em>that</em> emotional rollercoaster, I went to <a href="https://qantas.com.au/">qantas.com.au</a>, and clicked “Manage Booking”. In case you don’t know it because you live in a country with fast internet, Qantas is the main airline here in Australia.</p>

<p>(I also very conveniently started recording my screen, which is gonna pay off <em>big time</em> in just a moment.)</p>

<h3 id="step-4-type-in-the-booking-reference">Step 4: Type in the Booking Reference</h3>

<p>Well, the login form was just… <em>there</em>, and it was asking for a Booking Reference and a last name. I had just flawlessly read the Booking Reference from the boarding pass picture, and, well… I knew the last name<sup id="fnref:lastname" role="doc-noteref"><a href="#fn:lastname">7</a></sup>.</p>

<p>I did hesitate for a split-second, but… no, I had to know.</p>

<h3 id="step-5-crimes">Step 5: Crimes(?)</h3>

<video controls="" preload="auto">

    <source src="https://mango.pdf.zone/img/sunburnt-country/youngman.mp4" type="video/mp4">

<img src="https://mango.pdf.zone/img/sunburnt-country/summary.gif">
</video>
<p><em>youngman.mp4</em></p>

<p><img src="https://mango.pdf.zone/img/sunburnt-country/loggedin.png" alt="The logged in &quot;manage booking page&quot;">
<em>The “Manage Booking” page, logged in as some guy called Anthony Abbott</em></p>

<h3 id="can-i-get-a-yikes-in-the-chat">Can I get a YIKES in the chat</h3>

<p>Leave a comment if you really felt that.</p>

<p><img src="https://mango.pdf.zone/img/sunburnt-country/yikes.png" alt="yikes"></p>

<p>I guess I was now logged the heck in as Tony Abbott? And for all I know, everyone else who saw his Instagram post was right there with me. It’s kinda wholesome, to imagine us all there together. But also probably suboptimal in a governmental sense.</p>

<h5 id="was-there-anything-secret-in-here">Was there anything secret in here?</h5>

<p>I then just incredibly browsed the page, browsed it so hard.</p>

<p>I saw Tony Abbott’s name<sup id="fnref:name" role="doc-noteref"><a href="#fn:name">8</a></sup>, flight times, and Frequent Flyer number, but not really anything <em>super</em> secret-looking. Not gonna be committing any cyber treason with a Frequent Flyer number. The flight was in the past, so I couldn’t change anything, either.</p>

<p>The page said the flight had been booked by a travel agent, so I guessed some information would be missing because of that.</p>

<p>I clicked around and scrolled a considerable length, but still didn’t find any government secrets.</p>

<p>Some people might give up here. But I, the Icarus of computers, was simply too dumb to know when to stop.</p>

<h3 id="were-not-done-just-because-a-web-page-says-were-done">We’re not done just because a <em>web page</em> says we’re done</h3>

<p>I wanted to see if there were juicy things hidden <em>inside</em> the page. To do it, I had to use the <em>only</em> hacker tool I know.</p>

<p><img src="https://mango.pdf.zone/img/sunburnt-country/inspectelement.png" alt="Right click > Inspect-small">
<em>Right click &gt; Inspect Element, all you need to subvert the Commonwealth of Australia</em></p>

<p>Listen. This is the only part of the story that might be confused for highly elite computer skill. It’s not, though. Maybe later someone will show you this same thing to try and flex, acting like only <em>they</em> know how to do it. You will not go gently into that good night. You will refuse to acknowledge their flex, killing them instantly.</p>

<h5 id="how-does-inspect-element-work">How does “Inspect Element” work?</h5>
<p>“Inspect Element”, as it’s called, is a feature of Google Chrome that lets you see the computer’s internal representation (HTML) of the page you’re looking at. Kinda like opening up a clock and looking at the cool cog party inside.</p>

<p><img src="https://upload.wikimedia.org/wikipedia/commons/6/67/Pocketwatch_cutaway_drawing.jpg" alt="cog party|small">
<em>Yeahhh go little cogs, look at ‘em absolutely going off. Now imagine this but with like, JavaScript</em></p>

<p>Everything you see when you use “Inspect Element” was already downloaded to your computer, you just hadn’t asked Chrome to show it to you yet. Just like how the cogs were already in the watch, you just hadn’t opened it up to look.</p>

<p>But let us dispense with frivolous cog talk. Cheap tricks such as “Inspect Element” are used by programmers to try and understand how the website works. This is ultimately futile: Nobody can understand how websites work. Unfortunately, it kinda <em>looks</em> like hacking the first time you see it.</p>

<p>If you’d like to know more about it, I’ve prepared a short video.</p>

<blockquote><p lang="en" dir="ltr">hey youtube welcome to my hacking tutorial, today we're gonna hack.... the nsa <a href="https://t.co/2Z35GJjSZE">pic.twitter.com/2Z35GJjSZE</a></p>— “Alex” (@mangopdf) <a href="https://twitter.com/mangopdf/status/1123400764926226432?ref_src=twsrc%5Etfw">May 1, 2019</a></blockquote>


<h3 id="browsing-the-manage-booking-pages-html">Browsing the “Manage Booking” page’s HTML</h3>

<p>I scrolled around the page’s HTML, not really knowing what it meant, furiously trying to find anything that looked out of place or secret.</p>

<p>I eventually realised that manually reading HTML with my eyes was not an efficient way of defending my country, and Ctrl + F’d the HTML for “passport”.</p>

<h3 id="oh-no">oh no</h3>

<p><img src="https://mango.pdf.zone/img/sunburnt-country/passportjson.gif" alt="Blurred screenshot of close up &quot;passport&quot; number"></p>

<h3 id="oh-yes">Oh yes</h3>

<p>It’s just <em>there</em>.</p>

<p>At this point I was fairly sure I was looking at the <em>extremely</em> secret government-issued ID of the <em>28th Prime Minister of the Commonwealth of Australia, servant to her Majesty Queen Elizabeth II</em> and I was <em>kinda</em> worried that I was somehow doing something wrong, but like, not enough to stop.</p>

<h3 id="anything-else-in-this-page">….anything <em>else</em> in this page?</h3>

<p>Well damn, if Tony Abbott’s passport number is in this treasure trove of computer spaghetti, maybe there’s wayyyyy more. Perhaps this HTML contains the lost launch codes to the Sydney Opera House, or Harold Holt<sup id="fnref:holt" role="doc-noteref"><a href="#fn:holt">9</a></sup>.</p>

<p>Maybe there’s a phone number?</p>

<p>Searching for <code>phone</code> and <code>number</code> didn’t get anywhere, so I searched for <code>614</code>, the first 3 digits of an Australian phone number, using my colossal and highly celestial galaxy brain.</p>

<h5 id="weird-uppercase-letters">Weird uppercase letters</h5>
<p>A weird pile of what I could only describe as extremely uppercase letters came up. It looked like this:</p>

<div><div><pre><code>RQST QF HK1 HNDSYD/03EN|FQTV QF HK1|CTCM QF HK1 614[phone number]|CKIN QF HN1 DO NOT SEAT ROW [row number] PLS SEAT LAST ROW OF [row letter] WINDOW
</code></pre></div></div>
<p>So, there’s a lot going on here. There is indeed a phone number in here. But what the heck is all this <em>other</em> stuff?</p>

<p>I realised this was like… Qantas staff talking to eachother <em>about</em> Tony Abbott, but not <em>to</em> him?</p>

<p>In what is surely the subtweeting of the century, it has a …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mango.pdf.zone/finding-former-australian-prime-minister-tony-abbotts-passport-number-on-instagram">https://mango.pdf.zone/finding-former-australian-prime-minister-tony-abbotts-passport-number-on-instagram</a></em></p>]]>
            </description>
            <link>https://mango.pdf.zone/finding-former-australian-prime-minister-tony-abbotts-passport-number-on-instagram</link>
            <guid isPermaLink="false">hacker-news-small-sites-24488224</guid>
            <pubDate>Wed, 16 Sep 2020 00:16:13 GMT</pubDate>
        </item>
    </channel>
</rss>
