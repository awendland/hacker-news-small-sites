<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Mon, 03 Aug 2020 12:23:27 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Mon, 03 Aug 2020 12:23:27 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[What I learned from doing over 60 technical interviews in 30 days]]>
            </title>
            <description>
<![CDATA[
Score 181 | Comments 111 (<a href="https://news.ycombinator.com/item?id=24017555">thread link</a>) | @bolajiayodeji
<br/>
July 31, 2020 | https://meekg33k.dev/what-i-learned-from-doing-60-technical-interviews-in-30-days-ckda9sn7s00iftss13b0wd0ky | <a href="https://web.archive.org/web/*/https://meekg33k.dev/what-i-learned-from-doing-60-technical-interviews-in-30-days-ckda9sn7s00iftss13b0wd0ky">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>In this article, I’ll share my motivation for doing 60+ technical interviews in 30 days. More importantly, I’ll share 13 lessons I learned from my failures and my successes.</p>
<p>I’ve grouped the lessons into three categories to match the phases of a typical recruitment process.</p>
<p>While most of the lessons apply directly to software engineers and technical professionals, the principles behind these lessons can be applied to all careers. I hope you find something useful that you can apply to your professional lives.</p>
<h2 id="how-did-i-get-started-">How did I get started?</h2>
<blockquote>
<p> “If you’re going to fail, do it fast.” — Unknown</p>
</blockquote>
<p>Like any other software engineer, I’ve had different types of technical interviews - from the dreaded whiteboard coding interview to the unreal 45-minute coding challenge on platforms like HackerRank. While some of my experiences in these interviews were great, others were bad. Really bad.</p>
<p>But I wanted to get really good at interviewing. I wanted to learn to overcome the interviewing phobia and exude confidence at interviews. Like a skilled surfer, I wanted to learn to ride the high pressure waves that came with interviews. I was also looking to change jobs at the time.</p>
<p>So from January through early March 2020, I applied to and was contacted by companies based in the US and Europe. From early-stage startups like Coda to later stage startups like Crunchbase, from mid-size companies like Affirm, to bigger companies like Amazon and even remote companies like Webflow.</p>
<p>109+ applications later, I landed myself more than 60 interviews. These comprised more than 60 introductory phone interviews, 50+ technical phone screen interviews, 18 take-home coding projects, 11 coding challenges and 8 on-site interviews including 3 virtual ones.</p>
<h2 id="what-did-i-learn-">What did I learn?</h2>
<p>For better appreciation, I have grouped the lessons into three categories to match the different phases of a typical recruitment process.</p>
<h3 id="pre-interview-phase">Pre-Interview Phase</h3>
<p>This covers everything from the initial contact with a company to the point where the first interview happens.</p>
<h4 id="1-what-i-learned-about-applications">1. What I learned about applications</h4>
<p>When I started applying to companies, I imagined that the more applications I submitted, the higher my chances of getting an interview would be. Seems logical, huh? So I set a target of 5 applications a day, aiming for 1 interview for every 5 applications.</p>
<p>But my strategy didn’t work as I hoped it would. The number of interview requests I got often fell short of my target. It was almost a 1:12 ratio - 1 interview for every 12 applications.</p>
<p>I was faced with the question: do I need to increase my daily target to, say, 10 companies? Or was there something else I needed to change?</p>
<p>With every unsuccessful application, I saw that something needed to change.</p>
<p>That change came when I took a break from meeting my daily numbers and began to think of my applications differently. I began to see each application as a sales pitch to the hiring manager or whoever was going to be reading my application, but here the product being sold was me.</p>
<p>If a company needed to fill a talent gap and I say I had the skills, I needed to find a way to convince them that I did.</p>
<p>My new task then became to find a way to effectively pitch my unique skills, experience and personality in a way that convinced the hiring manager that I was the right fit for the job.</p>
<p>Here is an example of one of such <em>pitches</em> I came up with:</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1596030331456/A8nDIn-ih.png?auto=format&amp;q=60" alt="body image.png"></p>
<p>Backed with my resume, this cover letter had a 95% success rate. The one time this didn’t work, the hiring manager still replied to let me know that the position was no longer available but he would like to connect in the future.</p>
<p>The lesson here is, be very intentional about the application you put forward – quality over quantity. Better still do both. Know your unique competencies and experience and present them in a way that matches the company’s needs without sacrificing your personality.</p>
<p>It is also important to understand the peculiarity of the company you are applying to and its specific needs. A startup or a smaller-sized company may have different needs from a bigger company, thus requiring a different skill-set.</p>
<p>Sell yourself and be sure to back your sales pitch during the interview.</p>
<h4 id="2-what-i-learned-about-recruiter-in-mails">2. What I learned about recruiter in-mails</h4>
<p>During this period, I received a number of in-mails from recruiters (mostly unsolicited) for open roles, the majority of which were roles I wasn’t interested in.</p>
<p>Granted, it was sometimes a lot given my busy schedule but I learned to be empathetic, understanding that these recruiters were only trying to do their jobs.</p>
<p>I stopped seeing these in-mails as noise in my inbox and started making the effort to reply to all recruiter in-mails, even for positions I was not interested in. By doing this, I succeeded in building a network of recruiters that have become a rich resource if I have to switch roles in the future.</p>
<p>Now I don’t expect you may want to start replying to every in-mail you receive. But it might interest you to know that some of the interview requests I got were from recruiters I had replied to before for roles I wasn’t interested in. It never hurts to reply.</p>
<h3 id="the-interview-phase">The Interview Phase</h3>
<p>This covers everything about the interview itself, cutting across the different interview types.</p>
<h4 id="3-how-to-handle-introductory-phone-calls">3. How to handle introductory phone calls</h4>
<p>Yes I get it, you’re busy and many things are competing for your time. But hey, you are also an excellent professional, and that means you never get on a phone call without knowing at least these two things:</p>
<ul>
<li>the first name of your interviewer, and</li>
<li>at least one tangible thing about the company — what they do, where they are located, any recent news, something, anything!</li>
</ul>
<p>I noticed that for interviews where I put in the effort to make these findings, I always came across as being genuinely interested in the company. That’s something recruiters typically look for in these kinds of interviews.</p>
<h4 id="4-how-to-handle-technical-phone-screens">4. How to handle technical phone screens</h4>
<p>The one thing that can almost single-handedly decide how well you do in a technical phone screen interview is your ability to communicate your thoughts clearly.</p>
<p>You may have heard stuff like this before:
“<em>The interviewers care about your thought process. Yes they can see your code but importantly, they want to know why you are doing what you’re doing</em>.”</p>
<p>The interviewer isn’t there with you and so does not have the luxury of seeing other non-verbal cues like your hand gestures or nuances. All the interviewer has is your voice as a means of understanding your thought process.</p>
<p>Now you know how you should lead this conversation, the next question is how do you become good at this? Because the truth is, while expressing your thoughts may come naturally to some people, it doesn’t to others – including me.</p>
<p>So – Practice! Practice!! Practice!!!</p>
<p>Practice doing a lot of mock interviews. Doing these mock interviews with friends made me better and more confident in explaining my thought process. But more interestingly, it helped me develop a new mindset about interviews.</p>
<p>I began to see interviews as a conversation with a friend or a team member. I visualized the interviewer on the other end as one of my friends (I sometimes gave the interviewer a name in my head). So what would have been a high-pressure interview I now saw as a friendly ‘chat’ about a technical problem.</p>
<p>This new mindset, aided by the many practice interviews, helped me grow in confidence so much so that I started enjoying interviews, sorry, technical chats.
How to get started on a problem</p>
<p>Never start solving a problem without fully understanding the problem statement. You are almost never wrong if you start by asking clarifying questions. It’s also a good sign to your interviewer when you ask those questions rather than run with your assumptions.</p>
<h4 id="5-how-to-solve-the-problem">5. How to solve the problem</h4>
<p>Good candidates know how to solve a problem (e.g. a sorting problem), but the best candidates know multiple solutions to a problem and understand the trade-offs of one solution versus the other.</p>
<p>The interviews where I performed the best (Cruise comes to mind) are the ones where I didn’t just solve the algorithmic challenge – I was also able to provide alternative solutions and discuss the trade-offs.</p>
<p>Aim to provide multiple solutions to a problem, be willing to discuss the trade-offs, and be able to implement at least one of them.</p>
<p>For technical interviews, write clean code. Most interviewers care about your code quality as well as the correctness of your solution. Aim for modular code, separate reusable logic into utility functions, name variables and methods properly, and just be a boss!</p>
<h4 id="6-what-to-do-when-you-re-stuck-on-a-problem">6. What to do when you’re stuck on a problem</h4>
<p>There will be times when you’re stuck. And this could be caused by a number of reasons: you don’t have the requisite knowledge, incorrect assumptions, missing details, and so on.</p>
<p>I used to think that at such times I was being judged by how fast I could come up with a solution. So I would be quiet, thinking, not communicating with the interviewer, just thinking.</p>
<p>And this is where a lot of us get it wrong. I get it, you need some alone time to think. But sorry to burst your bubble, that alone time is not when you’re being interviewed by a person.</p>
<p>Yes, your interviewer wants to see that you can come up with a solution, but one thing you must not forget is that they also want to see that <strong>you can collaborate with other team-mates to come up with a solution</strong>. While companies want rock-stars, they also want team-players.</p>
<p>Since your interviewer is a friend, a buddy, a team member who’s on your side and means well for you (Refer to 4), talk to them while you're figuring it out.</p>
<p>Share your thought process up till the point you got stuck and do it confidently, not like some cry for help. By doing so you just may uncover the solution, as was the case during my interview with Coda.</p>
<h4 id="7-how-to-handle-coding-challenges">7. How to handle coding challenges</h4>
<p>The lessons here apply to interviews that take the form of coding challenges on platforms like Hackerrank, Codility, and so on. Typically these are timed challenges, say 45 minutes or …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://meekg33k.dev/what-i-learned-from-doing-60-technical-interviews-in-30-days-ckda9sn7s00iftss13b0wd0ky">https://meekg33k.dev/what-i-learned-from-doing-60-technical-interviews-in-30-days-ckda9sn7s00iftss13b0wd0ky</a></em></p>]]>
            </description>
            <link>https://meekg33k.dev/what-i-learned-from-doing-60-technical-interviews-in-30-days-ckda9sn7s00iftss13b0wd0ky</link>
            <guid isPermaLink="false">hacker-news-small-sites-24017555</guid>
            <pubDate>Sat, 01 Aug 2020 04:19:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Designing a Physics Engine]]>
            </title>
            <description>
<![CDATA[
Score 74 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24016718">thread link</a>) | @todsacerdoti
<br/>
July 31, 2020 | https://blog.winter.dev/2020/designing-a-physics-engine/ | <a href="https://web.archive.org/web/*/https://blog.winter.dev/2020/designing-a-physics-engine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>By coincidence, right when <a href="https://www.youtube.com/c/TheChernoProject/videos" target="_blank" rel="noreferrer noopener">The Cherno</a> announced his game engine series I was just starting to get going on my own engine. I couldn’t wait to finally have a professional opinion on how to make one. With self-taught programming it’s hard to not doubt yourself constantly, wondering if you are doing things right or just think you are.</p>



<p>Recently, he has been posting videos about huge aspects of his engine like physics and entity systems, which were what I really wanted to learn about by making myself, but he ended up using libraries instead of going through the internals! I am not against using libraries, but to use them for the fun stuff? I felt like it defeated the point of making a <em>custom</em> engine series.</p>



<p>There is an argument to be made about saving time, but this was the first C++ project that I was making and the goal from the start was to go through all the major pillars of an engine: input, graphics, physics, entities, and audio. I wanted to learn how those things worked along with C++ and code design in general.</p>



<p>I bet that some other people are interested in the details of how these systems work, and I want to learn how to explain code better, so I am going to try and make some videos going over the internals of these systems. They end up being much simpler than at first glance.</p>



<p><strong>Let’s start with the physics engine…</strong></p>



<p>Physics engines are responsible for figuring out where each object in a scene is over time. Objects can collide with one another, then choose to respond in several ways. It’s a generic problem that the user can configure at several different levels. Do they want a collider? Do they want to respond to collisions? Do they want to simulate dynamics? They could want dynamics, but not gravity. It’s a problem that calls for good planning and robust design.</p>



<p>I looked at how <a href="https://github.com/bulletphysics/bullet3" target="_blank" rel="noreferrer noopener">bullet</a> and <a href="https://github.com/erincatto/box2d" target="_blank" rel="noreferrer noopener">box2d</a> went about sorting their engines and concluded that the way bullet went about it was solid. I boiled it down to just what was needed, and based my design around that. There are already some <a href="https://www.toptal.com/game/video-game-physics-part-i-an-introduction-to-rigid-body-dynamics" target="_blank" rel="noreferrer noopener">great articles</a> going over the hard math involved, so I am going to focus on the design aspect instead because I haven’t seen anyone do that, and it’s also a real headache.</p>



<p>At the current moment, this physics engine is not fully featured, but in future articles I plan to build it out further. This article will not cover rotation, multiple contact point collisions, or constrained simulation. I think it will work out for the best as it’s easy to get overwhelmed, and I want to ease into those topics. With that out of the way, let’s dive into the different parts of a physics engine.</p>



<p>The problem can be split into 2 or 3 pieces, dynamics, collision detection, and collision response. I’ll start with dynamics because it is by far the simplest.</p>



<p><strong>Dynamics</strong></p>



<p>Dynamics is all about calculating where the new positions of objects are based on their velocity and acceleration. In high school you learn about the four kinematic equations along with Newton's three laws which describe the motion of objects. We’ll only be using the first and third kinematic equations, the others are more useful for analysis of situations, not simulation. That leaves us with:</p>



<p><span data-katex-display="true">v = v_0+at</span>



<span data-katex-display="true">\Delta x = v_0t + \frac{1}{2}at^2</span></p><p>We can give ourselves more control by using Newtons 2<sup>nd</sup> law, subbing out acceleration giving us:</p>



<p><span data-katex-display="true">v = v_0+\frac{F}{m}t</span>



<span data-katex-display="true">x = x_0+vt</span></p><p>Each object needs to store these three properties: velocity, mass, and net force. Here we find the first decision we can make towards the design, net force could either be a list or a single vector. In school you make force diagrams and sum up the forces, implying that we should store a list. This would make it so you could set a force, but you would need to remove it later which could get annoying for the user. If we think about it further, net force is really the total force applied in a <em>single</em> frame, so we can use a vector and clear it at the end of each update. This allows the user to apply a force by adding it, but removing it is automatic. This shortens our code and gives a performance bump because there is no summation of forces, it’s a running total.</p>



<p>We’ll use this struct to store the object info for now.</p>



<pre><span>struct</span>&nbsp;<span>Object</span>&nbsp;<span>{</span>
	<span>vector3</span>&nbsp;<span>Position</span><span>;</span>&nbsp;<span>//&nbsp;struct&nbsp;with&nbsp;3&nbsp;floats&nbsp;for&nbsp;x,&nbsp;y,&nbsp;z&nbsp;or&nbsp;i&nbsp;+&nbsp;j&nbsp;+&nbsp;k</span>
	<span>vector3</span>&nbsp;<span>Velocity</span><span>;</span>
	<span>vector3</span>&nbsp;<span>Force</span><span>;</span>
	<span>float</span>&nbsp;<span>Mass</span><span>;</span>
<span>};</span>
</pre>



<p>We need a way to keep track of the objects we want to update. A classic approach is to have a <em>physics world</em> that has list of objects and a <em>step</em> function that loops over each one. Let’s see how that might look; I’ll omit header/cpp files for brevity.</p>



<pre><span>class</span>&nbsp;<span>PhysicsWorld</span>&nbsp;<span>{</span>
<span>private</span><span>:</span>
	<span>std</span><span>::</span><span>vector</span><span>&lt;</span><span>Object</span><span>*&gt;</span>&nbsp;<span>m_objects</span><span>;</span>
	<span>vector3</span>&nbsp;<span>m_gravity</span>&nbsp;<span>=</span>&nbsp;<span>vector3</span><span>(</span><span>0</span><span>,</span>&nbsp;<span>-</span><span>9.81f</span><span>,</span>&nbsp;<span>0</span><span>);</span>
 
<span>public</span><span>:</span>
	<span>void</span>&nbsp;<span>AddObject</span>&nbsp;&nbsp;&nbsp;<span>(</span><span>Object</span><span>*</span>&nbsp;<span>object</span><span>)</span>&nbsp;<span>{</span>&nbsp;<span>/*&nbsp;...&nbsp;*/</span>&nbsp;<span>}</span>
	<span>void</span>&nbsp;<span>RemoveObject</span><span>(</span><span>Object</span><span>*</span>&nbsp;<span>object</span><span>)</span>&nbsp;<span>{</span>&nbsp;<span>/*&nbsp;...&nbsp;*/</span>&nbsp;<span>}</span>
 
	<span>void</span>&nbsp;<span>Step</span><span>(</span>
		<span>float</span>&nbsp;<span>dt</span><span>)</span>
	<span>{</span>
		<span>for</span>&nbsp;<span>(</span><span>Object</span><span>*</span>&nbsp;<span>obj</span>&nbsp;<span>:</span>&nbsp;<span>m_objects</span><span>)</span>&nbsp;<span>{</span>
			<span>obj</span><span>-&gt;</span><span>Force</span>&nbsp;<span>+=</span>&nbsp;<span>obj</span><span>-&gt;</span><span>Mass</span>&nbsp;<span>*</span>&nbsp;<span>m_gravity</span><span>;</span>&nbsp;<span>//&nbsp;apply&nbsp;a&nbsp;force</span>
 
			<span>obj</span><span>-&gt;</span><span>Velocity</span>&nbsp;<span>+=</span>&nbsp;<span>obj</span><span>-&gt;</span><span>Force</span>&nbsp;<span>/</span>&nbsp;<span>obj</span><span>-&gt;</span><span>Mass</span>&nbsp;<span>*</span>&nbsp;<span>dt</span><span>;</span>
			<span>obj</span><span>-&gt;</span><span>Position</span>&nbsp;<span>+=</span>&nbsp;<span>obj</span><span>-&gt;</span><span>Velocity</span>&nbsp;<span>*</span>&nbsp;<span>dt</span><span>;</span>
 
			<span>obj</span><span>-&gt;</span><span>Force</span>&nbsp;<span>=</span>&nbsp;<span>vector3</span><span>(</span><span>0</span><span>,</span>&nbsp;<span>0</span><span>,</span>&nbsp;<span>0</span><span>);</span>&nbsp;<span>//&nbsp;reset&nbsp;net&nbsp;force&nbsp;at&nbsp;the&nbsp;end</span>
		<span>}</span>
	<span>}</span>
<span>};</span>
</pre>



<p>Note the use of pointers, this forces other systems to take care of the actual storing of objects, leaving the physics engine to worry about physics, not memory allocation.</p>



<p>With this you can simulate all sorts of stuff from objects flying through the sky to solar systems.</p>



<iframe src="https://www.youtube.com/embed/crKrkn-RIOU?rel=0" allowfullscreen=""></iframe>



<iframe src="https://www.youtube.com/embed/sHZEs-oQTI4?rel=0" allowfullscreen=""></iframe>



<p>You can do a lot with this, but it’s the easy part to be honest, and that’s not what you came for…</p>



<p><strong>Collision detection</strong></p>



<p>Collision detection is more involved, but we can lighten the load by using some clever tricks. Let’s think about what needs to be found first. If we look at some examples of objects colliding, we notice that in most cases there is a point on each shape that is furthest inside the other.</p>



<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 364.19 219.82"><defs></defs><g id="Layer_2" data-name="Layer 2"><g id="Layer_1-2" data-name="Layer 1"><path id="a7vJywMoip" d="M250.74,108.59A108.34,108.34,0,1,1,142.4.25,108.39,108.39,0,0,1,250.74,108.59Z"></path><path id="aojGvlR1o" d="M364.19,149.47H0"></path><path id="b13RQfe45N" d="M145,216.93a2.64,2.64,0,1,1-2.64-2.64A2.64,2.64,0,0,1,145,216.93Z"></path><path id="a3jwpJe9bd" d="M145,149.47a2.64,2.64,0,1,1-2.64-2.64A2.64,2.64,0,0,1,145,149.47Z"></path><g id="epQfmNKBq"><text transform="translate(147.06 211.83)">A</text></g><g id="g3JoLaPokP"><text transform="translate(147.06 143.56)">B</text></g><path id="bnhzn14P" d="M145,157.62l-2.64-3.82-2.64,3.82h1.68v54.21h1.93V157.62Z"></path><g id="a5EIiwgkw"><g id="aeJzDwQJn"><text transform="translate(269.3 140.4)">Plane B</text></g></g><g id="lWR9tvULn"><g id="giK7zCiBZ"><text transform="translate(209.6 209.41)">Sphere A</text></g></g></g></g></svg>
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 319.48 293.52"><defs></defs><g id="Layer_2" data-name="Layer 2"><g id="Layer_1-2" data-name="Layer 1"><path id="circleB" d="M216.92,108.58A108.34,108.34,0,1,1,108.58.25,108.38,108.38,0,0,1,216.92,108.58Z"></path><path id="pointA" d="M201.59,169.27a2.64,2.64,0,1,1-2.64-2.64A2.64,2.64,0,0,1,201.59,169.27Z"></path><path id="bvujLY3Pv" d="M319.23,184.93A108.34,108.34,0,1,1,210.89,76.59,108.4,108.4,0,0,1,319.23,184.93Z"></path><path id="b2sM6mmV3Y" d="M138.53,105.94a2.64,2.64,0,1,1-2.64-2.64A2.64,2.64,0,0,1,138.53,105.94Z"></path><g id="g7IjQmpjFM"><g id="a5ffFLN0Lk"><text transform="translate(206.96 169.27)">A</text></g></g><g id="f5t39XVL9"><g id="a3HVPWIRk6"><text transform="translate(125.66 100.13)">B</text></g></g><path id="a6B9Ro3d2Q" d="M145.73,112.32l-5.51-1.77,1.78,5.5,1.18-1.18,51.76,51.76,1.37-1.37L144.55,113.5Z"></path><g id="b34R6jrlf6"><g id="azoQGzEb0"><text transform="translate(254.28 162.37)">Sphere B</text></g></g><g id="c1Pseh1RfC"><g id="j1Q686eol"><text transform="translate(10.62 84.31)">Sphere A</text></g></g></g></g></svg>



<p>This turns out to be all we need to respond to a collision. From those two points we can find the normal, and how deep the objects are inside one another. This is huge because it means that we can abstract the idea of different shapes away, and only worry about the points in the response.</p>



<p>Let’s jump into the code, we’ll need some helper structs that I’ll note first.</p>



<pre><span>struct</span>&nbsp;<span>CollisionPoints</span>&nbsp;<span>{</span>
	<span>vector3</span>&nbsp;<span>A</span><span>;</span>&nbsp;<span>//&nbsp;Furthest&nbsp;point&nbsp;of&nbsp;A&nbsp;into&nbsp;B</span>
	<span>vector3</span>&nbsp;<span>B</span><span>;</span>&nbsp;<span>//&nbsp;Furthest&nbsp;point&nbsp;of&nbsp;B&nbsp;into&nbsp;A</span>
	<span>vector3</span>&nbsp;<span>Normal</span><span>;</span>&nbsp;<span>//&nbsp;B&nbsp;–&nbsp;A&nbsp;normalized</span>
	<span>float</span>&nbsp;<span>Depth</span><span>;</span>&nbsp;&nbsp;&nbsp;&nbsp;<span>//&nbsp;Length&nbsp;of&nbsp;B&nbsp;–&nbsp;A</span>
	<span>bool</span>&nbsp;<span>HasCollision</span><span>;</span>
<span>};</span>
 
<span>struct</span>&nbsp;<span>Transform</span>&nbsp;<span>{</span>&nbsp;<span>//&nbsp;Describes&nbsp;an&nbsp;objects&nbsp;location</span>
	<span>vector3</span>&nbsp;<span>Position</span><span>;</span>
	<span>vector3</span>&nbsp;<span>Scale</span><span>;</span>
	<span>quaternion</span>&nbsp;<span>Rotation</span><span>;</span>
<span>};</span>
</pre>



<p>Each shape will have a different type of collider to hold its properties and a base to allow them to be stored. Any type of collider should be able to test for a collision with any other type, so we’ll add functions in the base for each one. These functions will take <em>Transforms</em>, so the colliders can use relative coordinates. I’ll only demonstrate spheres and planes, but the code is repeatable for any number of colliders.</p>



<pre><span>struct</span>&nbsp;<span>Collider</span>&nbsp;<span>{</span>
	<span>virtual</span>&nbsp;<span>CollisionPoints</span>&nbsp;<span>TestCollision</span><span>(</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>transform</span><span>,</span>
		<span>const</span>&nbsp;<span>Collider</span><span>*</span>&nbsp;<span>collider</span><span>,</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>colliderTransform</span><span>)</span>&nbsp;<span>const</span>&nbsp;<span>=</span>&nbsp;<span>0</span><span>;</span>
 
	<span>virtual</span>&nbsp;<span>CollisionPoints</span>&nbsp;<span>TestCollision</span><span>(</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>transform</span><span>,</span>
		<span>const</span>&nbsp;<span>SphereCollider</span><span>*</span>&nbsp;<span>sphere</span><span>,</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>sphereTransform</span><span>)</span>&nbsp;<span>const</span>&nbsp;<span>=</span>&nbsp;<span>0</span><span>;</span>
 
	<span>virtual</span>&nbsp;<span>CollisionPoints</span>&nbsp;<span>TestCollision</span><span>(</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>transform</span><span>,</span>
		<span>const</span>&nbsp;<span>PlaneCollider</span><span>*</span>&nbsp;<span>plane</span><span>,</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>planeTransform</span><span>)</span>&nbsp;<span>const</span>&nbsp;<span>=</span>&nbsp;<span>0</span><span>;</span>
<span>};</span>
</pre>



<p>Let’s make both types of colliders at the same time too see how they interact. A sphere is defined as a point and a radius, and a plane is defined as a vector and a distance. We’ll override the functions from <em>Collider</em>, but won’t worry about the work for now.</p>



<p>We can choose per collider which other colliders it will detect by filling, or not filling, in these functions. In this case, we don’t want Plane v Plane collisions, so we return an empty <em>CollisionPoints</em>.</p>



<pre><span>struct</span>&nbsp;<span>SphereCollider</span>
	<span>:</span>&nbsp;<span>Collider</span>
<span>{</span>
	<span>vector3</span>&nbsp;<span>Center</span><span>;</span>
	<span>float</span>&nbsp;<span>Radius</span><span>;</span>
 
	<span>CollisionPoints</span>&nbsp;<span>TestCollision</span><span>(</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>transform</span><span>,</span>
		<span>const</span>&nbsp;<span>Collider</span><span>*</span>&nbsp;<span>collider</span><span>,</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>colliderTransform</span><span>)</span>&nbsp;<span>const</span>&nbsp;<span>override</span>
	<span>{</span>
		<span>return</span>&nbsp;<span>collider</span><span>-&gt;</span><span>TestCollision</span><span>(</span><span>colliderTransform</span><span>,</span>&nbsp;<span>this</span><span>,</span>&nbsp;<span>transform</span><span>);</span>
	<span>}</span>
 
	<span>CollisionPoints</span>&nbsp;<span>TestCollision</span><span>(</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>transform</span><span>,</span>
		<span>const</span>&nbsp;<span>SphereCollider</span><span>*</span>&nbsp;<span>sphere</span><span>,</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>sphereTransform</span><span>)</span>&nbsp;<span>const</span>&nbsp;<span>override</span>
	<span>{</span>
		<span>return</span>&nbsp;<span>algo</span><span>::</span><span>FindSphereSphereCollisionPoints</span><span>(</span>
			<span>this</span><span>,</span>&nbsp;<span>transform</span><span>,</span>&nbsp;<span>sphere</span><span>,</span>&nbsp;<span>sphereTransform</span><span>);</span>
	<span>}</span>
 
	<span>CollisionPoints</span>&nbsp;<span>TestCollision</span><span>(</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>transform</span><span>,</span>
		<span>const</span>&nbsp;<span>PlaneCollider</span><span>*</span>&nbsp;<span>plane</span><span>,</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>planeTransform</span><span>)</span>&nbsp;<span>const</span>&nbsp;<span>override</span>
	<span>{</span>
		<span>return</span>&nbsp;<span>algo</span><span>::</span><span>FindSpherePlaneCollisionPoints</span><span>(</span>
			<span>this</span><span>,</span>&nbsp;<span>transform</span><span>,</span>&nbsp;<span>plane</span><span>,</span>&nbsp;<span>planeTransform</span><span>);</span>
	<span>}</span>
<span>};</span></pre>



<p>We can add a function for testing the base and use a technique called <a href="https://en.wikipedia.org/wiki/Double_dispatch" target="_blank" rel="noreferrer noopener">double dispatch</a>. This takes advantage of the type system to determine both types of colliders for us by swapping the arguments, determining the first, then the second type through two calls of TestCollision. This saves us needing to know what type of colliders we are checking, which means we’ve fully abstracted away the notion of different shapes outside the collision detection.</p>



<pre><span>struct</span>&nbsp;<span>PlaneCollider</span>
	<span>:</span>&nbsp;<span>Collider</span>
<span>{</span>
	<span>vector3</span>&nbsp;<span>Plane</span><span>;</span>
	<span>float</span>&nbsp;<span>Distance</span><span>;</span>
 
	<span>CollisionPoints</span>&nbsp;<span>TestCollision</span><span>(</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>transform</span><span>,</span>
		<span>const</span>&nbsp;<span>Collider</span><span>*</span>&nbsp;<span>collider</span><span>,</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>colliderTransform</span><span>)</span>&nbsp;<span>const</span>&nbsp;<span>override</span>
	<span>{</span>
		<span>return</span>&nbsp;<span>collider</span><span>-&gt;</span><span>TestCollision</span><span>(</span><span>colliderTransform</span><span>,</span>&nbsp;<span>this</span><span>,</span>&nbsp;<span>transform</span><span>);</span>
	<span>}</span>
 
	<span>CollisionPoints</span>&nbsp;<span>TestCollision</span><span>(</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>transform</span><span>,</span>
		<span>const</span>&nbsp;<span>SphereCollider</span><span>*</span>&nbsp;<span>sphere</span><span>,</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>sphereTransform</span><span>)</span>&nbsp;<span>const</span>&nbsp;<span>override</span>
	<span>{</span>
		<span>//&nbsp;reuse&nbsp;sphere&nbsp;code</span>
		<span>return</span>&nbsp;<span>sphere</span><span>-&gt;</span><span>TestCollision</span><span>(</span><span>sphereTransform</span><span>,</span>&nbsp;<span>this</span><span>,</span>&nbsp;<span>transform</span><span>);</span>
	<span>}</span>
 
	<span>CollisionPoints</span>&nbsp;<span>TestCollision</span><span>(</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>transform</span><span>,</span>
		<span>const</span>&nbsp;<span>PlaneCollider</span><span>*</span>&nbsp;<span>plane</span><span>,</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>planeTransform</span><span>)</span>&nbsp;<span>const</span>&nbsp;<span>override</span>
	<span>{</span>
		<span>return</span>&nbsp;<span>{};</span>&nbsp;<span>//&nbsp;No&nbsp;plane&nbsp;v&nbsp;plane</span>
	<span>}</span>
<span>};</span>
</pre>



<p>In cases like this, where there are many classes with a web of similar functions, it can be confusing as to where the actual code is located. <em>Sphere</em> v …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.winter.dev/2020/designing-a-physics-engine/">https://blog.winter.dev/2020/designing-a-physics-engine/</a></em></p>]]>
            </description>
            <link>https://blog.winter.dev/2020/designing-a-physics-engine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24016718</guid>
            <pubDate>Sat, 01 Aug 2020 02:07:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Glucosamine Supplementation Reduces All-Cause Mortality: Study]]>
            </title>
            <description>
<![CDATA[
Score 254 | Comments 134 (<a href="https://news.ycombinator.com/item?id=24012587">thread link</a>) | @mrfusion
<br/>
July 31, 2020 | https://www.lifespan.io/news/glucosamine-supplementation-reduces-all-cause-mortality/ | <a href="https://web.archive.org/web/*/https://www.lifespan.io/news/glucosamine-supplementation-reduces-all-cause-mortality/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
																
								
								
<p>It is one of the most commonly used supplements frequently taken to address joint pain, but there might be more to this dietary supplement than first meets the eye.</p>
<p>Glucosamine was originally discovered during the 1960s in Italy by pharmacologist Professor Luigi Rovati. Glucosamine is one of the most commonly used dietary supplements and is typically taken to help with the joint pain and inflammation associated with aging.</p>
<p>Glucosamine is a polysaccharide that is found naturally in cartilaginous joint tissues, bones, skin, ligaments, and nails, and it is involved in protein and lipid synthesis. In the context of joints, synovial fluid contains glucosamine and occupies the space between joints, helping to reduce the friction of joint surfaces.</p>
<p>Despite it being frequently taken for arthritis, the evidence for its effectiveness is limited, although, there is data for it being anti-inflammatory, as suggested by the results of a randomized clinical trial in 2015 [1].</p>
<p>However, glucosamine supplementation seems to correlate with lower all-cause mortality and other mortality risks, such as cardiovascular disease (CVD), cancer, respiratory and digestive diseases. A recent <a href="https://ard.bmj.com/content/79/6/829" target="_blank" rel="noopener noreferrer">analysis</a> published in the journal BMJ showed that glucosamine supplementation conveys around a 15% reduction of all-cause mortality [2]. This is a considerable amount when compared to other lifestyle interventions as well as other supplements. The data gathered is from a large number of people, and the trend of reduced mortality is unmistakable.</p>


<blockquote>
<p>This population-based prospective cohort study included 495 077 women and men (mean (SD) age, 56.6 (8.1) years) from the UK Biobank study. Participants were recruited from 2006 to 2010 and were followed up through 2018. We evaluated all-cause mortality and mortality due to cardiovascular disease (CVD), cancer, respiratory and digestive disease. HRs and 95% CIs for all-cause and cause-specific mortality were calculated using Cox proportional hazards models with adjustment for potential confounding variables.</p>
<p>Regular glucosamine supplementation was associated with lower mortality due to all causes, cancer, CVD, respiratory and digestive diseases.</p>
</blockquote>
<p><strong>Conclusion</strong></p>
<p>The exact reasons for this correlation with the reduction of various mortality risks is as yet unknown, but given the large patient group in this and in other analyses along with the popularity of this supplement, it is impossible to deny that there is a definite trend here.</p>
<p>We are not suggesting that you take this supplement, but given that it is cheap and freely available with an excellent safety profile, it may be worth your consideration and further research to evaluate if you wish to take it or not.</p>
			
		
<p><strong>Literature</strong></p>
<p>[1] Navarro, S. L., White, E., Kantor, E. D., Zhang, Y., Rho, J., Song, X., … &amp; Lampe, J. W. (2015). Randomized trial of glucosamine and chondroitin supplementation on inflammation and oxidative stress biomarkers and plasma proteomics profiles in healthy humans. PloS one, 10(2), e0117534.</p>
<p>[2] Li, Z. H., Gao, X., Chung, V. C., Zhong, W. F., Fu, Q., Lv, Y. B., … &amp; Li, F. R. (2020). Associations of regular glucosamine use with all-cause and cause-specific mortality: a large prospective cohort study. Annals of the Rheumatic Diseases, 79(6), 829-836.</p>
																	
															</div></div>]]>
            </description>
            <link>https://www.lifespan.io/news/glucosamine-supplementation-reduces-all-cause-mortality/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24012587</guid>
            <pubDate>Fri, 31 Jul 2020 19:07:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Niklaus Wirth was right and that is a problem]]>
            </title>
            <description>
<![CDATA[
Score 185 | Comments 169 (<a href="https://news.ycombinator.com/item?id=24011573">thread link</a>) | @bowero
<br/>
July 31, 2020 | https://bowero.nl/blog/2020/07/31/niklaus-wirth-was-right-and-that-is-a-problem/ | <a href="https://web.archive.org/web/*/https://bowero.nl/blog/2020/07/31/niklaus-wirth-was-right-and-that-is-a-problem/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-226">
	

	<div>
		
<p>Wirth’s law is not really a law. Actually, none of them ever are laws. They are adages:</p>



<blockquote><p><em>a proverb or short statement expressing a general truth.</em></p><cite><a href="https://www.lexico.com/en/definition/adage">https://www.lexico.com/en/definition/adage</a></cite></blockquote>



<p>Here is another law that is not a real law:&nbsp;<em>Moore’s law is the observation that the number of transistors in a dense integrated circuit (IC) doubles about every two years.</em></p>



<p>This means that we can expect the speed and capability of computers to increase while lowering the costs. Sadly, this is where Wirth’s law comes in:</p>



<blockquote><p><em>Wirth’s law is an adage on computer performance which states that software is getting slower more rapidly than hardware is becoming faster.</em></p><cite><a href="https://en.wikipedia.org/wiki/Wirth%27s_law">https://en.wikipedia.org/wiki/Wirth%27s_law</a></cite></blockquote>



<p>And while Moore’s law has proven to be true since 1975, Wirth’s law seems to be true as well. Niklaus Wirth, the designer of Pascal, wrote an article in 1995:</p>



<blockquote><p>About 25 years ago, an interactive text editor could be designed with as little as 8,000 bytes of storage. (Modern program editors request 100 times that much!) An operating system had to manage with 8,000 bytes, and a compiler had to fit into 32 Kbytes, whereas their modern descendants require megabytes. Has all this inflated software become any faster? On the contrary. Were it not for a thousand times faster hardware, modern software would be utterly unusable.</p><cite>Niklaus Wirth – A Plea for Lean Software</cite></blockquote>



<p>The problem of modern software development is manyfold. Wirth points out one crucial aspect: time.</p>



<blockquote><p>Time pressure is probably the foremost reason behind the emergence of bulky software.</p><cite>Niklaus Wirth – A Plea for Lean Software</cite></blockquote>



<p>And while that was true back in 1995, that is no longer the most important factor. We now have to deal with a much bigger problem: abstraction. Developers never built things from scratch, and that has never been a problem, but now they have also become lazy.</p>



<p>It was Edsger W. Dijkstra who tried to improve the quality of code and coined the concept of <em>structured programming</em>. He tried to get programming out of the state of crisis it was in, and he found support in programmers like Harlan D. Mills, Richard C. Linger and Bernard I. Witt. For a short period of time, programming was seen as a real craftmanship. Programmers cared about the quality of their programs, and that included clarity and efficiency.</p>



<p>Those times have passed. With the introduction of higher-level languages such as Java, Ruby, PHP and Javascript all in 1995, the same year in which Wirth wrote his article, programming became more abstract. </p>



<p>Languages like these made programming a lot easier and took many things out of the programmer’s hands. They were object-oriented and came with things as an IDE and garbage collection.</p>



<p>This meant that programmers had fewer things to worry about, which is of course great. Sadly, everything comes with a price. Having fewer things to worry about, also means having fewer things to think about. 1995 was the year in which programmers stopped thinking about the quality of their programs.</p>



<p>It also marked the beginning of the widespread use of libraries, probably one of the bigger problems. Don’t get me wrong, I love libraries. They are the only reason I am able to get things done. However, a library never comes with the exact things that you need.</p>



<p>Because a library is not made for one specific project, it probably has a bit more functionalities than you really needed. No problem, you would say. However, things pile up pretty quickly. Even the people who like libraries, don’t want to reinvent the wheel. This results in what we call dependency hell. <a href="https://blog.appsignal.com/2020/04/09/ride-down-the-javascript-dependency-hell.html">Nikola Duza wrote a post about that issue in Javascript</a>.</p>



<p>The problem does not seem that big, but try to grasp what is happening here. In another tutorial that Nikola wrote, he built a simple todo-list. It works in your browser with HTML and Javascript. How many dependencies did he use? <a href="https://blog.appsignal.com/2020/05/14/javascript-growing-pains-from-0-to-13000-dependencies.html">13,000.</a></p>



<p>These numbers are insane, but this problem will only keep increasing. As new, very useful libraries keep being built, the number of dependencies per project will keep growing as well.</p>



<p>That means that the problem Niklaus was warning us about in 1995, only gets bigger over time. </p>



<p>And no, you don’t have to learn assembly and start writing your web application in that. A good way to start would be to split up libraries. Instead of creating one big library that does everything you could ever possibly need, just create many libraries. Your god-like library could still exist, but solely as a wrapper. </p>



<p>This way a programmer only has to select the libraries he really requires, while ignoring the functionalities he is not going to use in his application. Not only are his dependencies smaller, but they will also use less of their dependencies because the dependencies of the unused functionalities do not have to be installed.</p>



<blockquote><p><strong>Note: </strong>The proposed solution obviously is not <em>the</em> solution. It would for example require a good way of versioning software to avoid a new dependency hell.</p></blockquote>
	</div>

	
</article></div>]]>
            </description>
            <link>https://bowero.nl/blog/2020/07/31/niklaus-wirth-was-right-and-that-is-a-problem/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24011573</guid>
            <pubDate>Fri, 31 Jul 2020 18:03:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Starting a Business Around GPT-3 Is a Bad Idea]]>
            </title>
            <description>
<![CDATA[
Score 111 | Comments 65 (<a href="https://news.ycombinator.com/item?id=24007929">thread link</a>) | @paraschopra
<br/>
July 31, 2020 | https://www.allencheng.com/starting-a-business-around-gpt-3-is-a-bad-idea/ | <a href="https://web.archive.org/web/*/https://www.allencheng.com/starting-a-business-around-gpt-3-is-a-bad-idea/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>GPT-3 is an amazing technology. Within a few weeks after beta API access opened, a <a href="https://twitter.com/xuenay/status/1283312640199196673" target="_blank">host of jaw-dropping demos</a> popped up, from <a href="https://twitter.com/sharifshameem/status/1282676454690451457" target="_blank">automatic code generation</a> to <a href="https://twitter.com/nicklovescode/status/1283326066338062337" target="_blank">automated therapy bots</a> to <a href="https://www.gwern.net/GPT-3" target="_blank">writing original poetry and Navy SEAL copypasta memes</a>. It does things that would have been science fiction 10 years ago.&nbsp;GPT-3 and its successor algorithms are going to change entire industries.</p><p>Naturally, tech founders and VC investors are salivating at the possibilities of turning GPT-3 applications into businesses.</p><p>But a good technology doesn’t necessarily make for a good business. <strong>The fact that GPT-3 works so well out of the box should be terrifying to founders.</strong> Here’s why:</p><ul><li>If it’s easy to make a good-enough app out of the box, the barriers to entry are mercilessly low. Dozens of competitors for your idea will spring up literally overnight, as they already have in these Twitter demos.</li><li>It’s not just about new entrants. If GPT-3 is so easy to adopt and build products with, incumbents will do it too. Thus, in Clayton Christensen’s framework, GPT-3 looks more like a <strong>sustaining innovation</strong> than a disruptive innovation. This will strengthen existing winners more than it creates openings for new startups.</li><li>If the baseline GPT-3 performance cannot be substantially improved to create a substantial (10x) proprietary edge, the competition will shift away from technology to other dimensions of competition—particularly in marketing and distribution. This is where incumbents beat startups.</li><li>Meanwhile, the profits will accrue to the true beneficiaries: 1) the algorithm owners,&nbsp; OpenAI (and, by extension, Azure), 2) to marketing platforms, particularly Google and Facebook. Both can raise pricing to the point where companies built on each are barely profitable.</li></ul><p>Let’s dive more into these ideas.</p><h2><span id="Low_Barrier_to_Entry_Fierce_Competition"><strong>Low Barrier to Entry = Fierce Competition</strong></span></h2><div><figure><img src="https://i1.wp.com/www.allencheng.com/wp-content/uploads/2020/07/image.png?w=750&amp;ssl=1" alt="" srcset="https://i1.wp.com/www.allencheng.com/wp-content/uploads/2020/07/image.png?w=471&amp;ssl=1 471w, https://i1.wp.com/www.allencheng.com/wp-content/uploads/2020/07/image.png?resize=300%2C174&amp;ssl=1 300w" sizes="(max-width: 471px) 100vw, 471px" data-recalc-dims="1"></figure></div><p><a href="https://a16z.com/2020/05/28/moats-before-gross-margins/" target="_blank">Moats provide an enduring competitive advantage</a>. The wider and deeper the moat, the higher the barrier to entry to compete with your business, and the less capably a hotshot teenager can start a new company to compete.</p><p>If a moat is shallow, hundreds of competitors can pop up overnight and provide a good-enough competing product. If you can’t build a meaningful product advantage, then the grounds of competition shift to other dimensions of competition—namely, marketing and distribution.</p><h3><strong>The Parable of Online Mattresses</strong></h3><p>The online mattress industry had shallow moats and played out predictably. A few years ago, if you wanted to start a new mattress company, you only needed to cobble together a few components:</p><ul><li>A manufacturer</li><li>A website</li><li>A marketing campaign</li></ul><p>At the peak of the industry, there were <a href="https://www.cnbc.com/2019/08/18/there-are-now-175-online-mattress-companiesand-you-cant-tell-them-apart.html" target="_blank">175 online mattress companies</a>. None had a meaningful product advantage—many used the same mattress manufacturers. (And having personally tried several of these mattresses in stores, they really did feel about the same.)</p><p>The grounds of competition thus shifted to marketing and branding, which is why a year ago you heard so many podcast ads for Casper, Purple, and the like. When product 17 and product 130 are identical, then the only way to win is to get buyers more familiar with product 17. But <strong>when competition meets a narrow dimension of competition, profits evaporate</strong>—companies bid up marketing prices to the highest that they can endure. It became a game of chicken—how much are <em>you </em>willing to spend to acquire a customer? The best-funded startups “won” this branding battle.</p><p>But this was a short-lived victory. <strong>The ultimate result: perpetually unprofitable businesses</strong>, with <a href="https://www.marketwatch.com/investing/stock/cspr/financials" target="_blank">companies spending most of their revenue on COGS and user acquisition</a>. Casper now has a market value of just $350 million, down from its peak private valuation of $1.1 billion.&nbsp;</p><p>Meanwhile, the real beneficiaries of all this funding are:&nbsp;</p><p>1) the companies selling shovels in the gold rush, including mattress manufacturers and marketing platforms (particularly Google and Facebook)</p><p>2) customers, who enjoyed rock-bottom mattress prices subsidized by venture capital.</p><p>This situation played out in meal kit companies too, and one could argue the same is true of Uber vs Lyft and the food delivery war going on now.</p><h2><span id="Can_You_Differentiate_Yourself_with_GPT-3"><strong>Can You Differentiate Yourself with GPT-3?</strong></span></h2><p>Because GPT-3 works so well out of the box, I see this playing out a similar way. To start a new AI company, you need only cobble together a few components:</p><ul><li>A product built on GPT-3’s (very easy to use) API</li><li>A website</li><li>A marketing campaign</li></ul><p>As we see with Twitter demos, the products you can make off the shelf will frankly be pretty good.</p><p>Unfortunately, most of the products built on GPT-3 will be identical to each other, and few will have a meaningful edge. We’ll dive more into this next.</p><h3><strong>Differentiated Technology</strong></h3><p><strong>To win a market with technology, your product needs to be <em>obviously</em> better to the user.</strong> When Google first came out, it delivered such better search results than other engines—possibly by a subjective factor of 10 or more—that there was little reason to use any competitor. When Dropbox first came out, its syncing and ease of use was unbeatable. Right now SpaceX has a rocket that can do what no other company’s can, at an unbeatable price. These companies have real technology moats.</p><p>In contrast, if an industry has products that are are more or less identical—like online mattresses—the grounds of competition shift elsewhere other than product (like marketing and distribution), and there is no technology moat.</p><p>So imagine: If 100 companies build an AI therapy bot with GPT-3, how different will their user experiences be? How far ahead will company #1 be above company #2, and then over company #10? <strong>Will there be a 10x difference? Or more like a 5% difference?</strong></p><p>I argue: <strong>The better GPT-3 works out of the box, the harder it will be for any single company to build meaningful differentiation.</strong> Frankly, <a href="https://twitter.com/nicklovescode/status/1283326066338062337" target="_blank">early demos already look very good</a>.</p><figure><div><blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>I thought you made a good point so I did another run being as depressive as I could. I sampled most “John” lines only once, I think I ran one twice. I’m really impressed</p><p>The prefix makes a difference but that could be automatically prepended by an end-user therapy app <a href="https://t.co/YZmQL9EXqW" target="_blank">pic.twitter.com/YZmQL9EXqW</a></p></div>— Nick Cammarata (@nicklovescode) <a href="https://twitter.com/nicklovescode/status/1283326066338062337?ref_src=twsrc%5Etfw" target="_blank">July 15, 2020</a></blockquote> </div></figure><p>Imagine how much better it can get with just a <em>little</em> more work—a modicum of fine tuning on therapy conversations and user safeguards. This is the new baseline, the “table stakes” for any new entrant, which is going to be relatively easy to achieve.</p><p>And then from this baseline, how much better could any one company get?</p><p>Here’s one way to think about it. The pinnacle of AI therapy would be a bot that rivals the <em>best</em> human therapist. Call this the 100% experience. The <em>average</em> human therapist might be somewhere at the 85% bar. And then a human user might be willing to tolerate a “good enough” AI performing at 70%—it’s clearly worse than a human therapist, but usable enough that it can keep up a coherent conversation and remembers that you were bullied in 5th grade.</p><figure><img src="https://lh6.googleusercontent.com/d-9mr1Bo8EgQaIlWnKd4EQuSrjjJuoBmjOkpcbPwJ0h9xnyIGz832tT133eTopDQZQWr2pXAJ-lS9mhaP9KBInUCnGtSqJKAtdZV-acn55hQ25c-p7bwdHgjyl-zFJ54I9Hg4aVX" alt=""></figure><p><strong>Before GPT-3, building anything </strong><strong><em>close</em></strong><strong> to the Good Enough AI was really hard.</strong> A company would have needed to invest many millions into its own algorithms and data cleanup to get anywhere close to the human user bar.&nbsp;</p><p>In this environment, the leading company had a few advantages:</p><ul><li>The barrier to entry was high, so it faced less competition.</li><li>The spread between the #1 and #3 companies was high, meaning the leading company had a sizable moat.</li><li>It still had a lot of room to grow to get to 85%+ level—this is room in which it could carve out a meaningful edge over competition.</li><li>It owned its own technology, so it could iterate to continuously improve its experience.</li></ul><p>Here’s how the landscape might have looked:</p><figure><img src="https://lh3.googleusercontent.com/Fz675xiZWljHeS4HWUGNcrO8qbaLtjJ9zfqJNCa2HhthN84Nt7JCQpMMhC4SzO9dWfSkGpWxOwIkaz745S-XJijAd91g0JDS2A7nDXrv6ku2fckVbW5kCl-UEyZci3tRgrb4aNwl" alt=""></figure><p>(In practice, I don’t know of any <a href="https://www.healthline.com/health/mental-health/chatbots-reviews#7" target="_blank">pre-GPT-3 AI therapy bot</a> that comes anywhere close to a human therapist. So competitive lead notwithstanding, I don’t think there have been any good AI therapy businesses to date.)</p><p>Then comes GPT-3. <strong>Now <em>anyone</em> can produce a “good enough AI therapy bot,”</strong> with a modicum of fine-tuning and UX design. This outcome wouldn’t be shocking—people were producing <a href="https://twitter.com/nicklovescode/status/1283326066338062337" target="_blank">plausible demos</a> within days of accessing the private beta. Imagine what can be done with just a few weeks of work and $500,000 of investment.</p><p>The result: the range of competition narrows:</p><figure><img src="https://lh6.googleusercontent.com/BiYRcsL4EKmlGKyc5gFDCCkQ_79ijr-jBknzfVb2MVuPj-Rp-D56fLeNhVnV9F46I3tWmUgzJLfV_hh5Q-oOZuR531DWJwI11JKQWgRfFt0fDDDGybrQX7yuTvAGp0TDWmem8_K5" alt=""></figure><p>Compared to the previous situation:</p><ul><li>There are many more competitors who can offer a “good enough” product.</li><li>The range of competition is compressed into a narrower band. It becomes much harder for any single product to stand out from the median product, which is already quite good.</li><li>Because the companies don’t own the core technology behind GPT-3, their ability to improve beyond the baseline performance is limited. Yes, they can fine-tune GPT-3 with their proprietary data, but how much is this going to improve on the core algorithm, which <a href="https://venturebeat.com/2020/06/11/openai-launches-an-api-to-commercialize-its-research/" target="_blank">cost $12 million to train</a> on 40GB of Internet text? <strong>And won’t everyone else be fine-tuning like this too?</strong></li></ul><p>Again, this really gives credit to OpenAI for how well GPT-3 works—out of the gate, you can produce a pretty usable product. But for startups, this merely <em>raises the table stakes</em> instead of offering a competitive advantage, and it <strong>neutralizes the technology edge</strong> any single company can have over another. Great for OpenAI, not great for new startups.</p><p><strong>Then imagine how much worse this will get when GPT-4 comes out. And again with GPT-5. </strong>The minimum bar of quality will keep inching up inexorably, and the range of competition will be compressed further and further.</p><p>Plus, it’s likely that <strong>any proprietary progress you make on GPT-3 will be totally wiped out by GPT-4</strong>; the same way your tweaks on GPT-2 would have been wiped out by GPT-3.</p><p>We’ve talked about AI therapy here, but this argument extends easily to automated code generation, creative writing tools, chatbots, Q&amp;A services, games, and so on.</p><h3><strong>Other Avenues of Differentiation</strong></h3><p>Yes, the algorithm isn’t everything. Products can still differentiate with their user experience, product design, customer support, adding on human services, and so on.&nbsp;</p><p>But as far as AI companies typically go, this is not really the <em>hard</em> …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.allencheng.com/starting-a-business-around-gpt-3-is-a-bad-idea/">https://www.allencheng.com/starting-a-business-around-gpt-3-is-a-bad-idea/</a></em></p>]]>
            </description>
            <link>https://www.allencheng.com/starting-a-business-around-gpt-3-is-a-bad-idea/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24007929</guid>
            <pubDate>Fri, 31 Jul 2020 12:19:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google removes all Danish music from YouTube]]>
            </title>
            <description>
<![CDATA[
Score 169 | Comments 174 (<a href="https://news.ycombinator.com/item?id=24006932">thread link</a>) | @erk__
<br/>
July 31, 2020 | https://www.koda.dk/about-us/press-release-google-removes-all-danish-music-from-youtube | <a href="https://web.archive.org/web/*/https://www.koda.dk/about-us/press-release-google-removes-all-danish-music-from-youtube">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <div>   
    <p>Press Release<br>July 30, 2020</p>

<h3><strong>Google removes all Danish music from YouTube </strong></h3>
<h5>While the negotiations on a new joint Nordic agreement are in full swing, Google have chosen to leverage their total dominance in the market in the strongest way possible. On the evening of Thursday 30 July, Google announced that they will soon remove all Danish music content on YouTube.</h5>

<p>Under the auspices of the Nordic alliance of collecting societies, Polaris, negotiations on a joint Nordic agreement on the use of music on YouTube are currently in full swing. The agreement will replace the local agreements of the Norwegian, Finnish and Danish composers and songwriters’ societies, combining them in a single, joint agreement with Google. In the case of Koda, the national agreement for Denmark expired in April, after which it was temporarily extended – as is standard practice in the industry while negotiating a new agreement.</p>
<p>Now, however, Google have issued a new demand: if the agreement is to be temporarily extended, Koda must agree to reduce the payment provided to composers and songwriters for YouTube’s use of music by almost 70% – despite the fact that YouTube’s use of music has increased significantly since Koda entered into its last agreement with Google.</p>
<p>Of course, Koda cannot accept these terms, and Google have now unilaterally decided that Koda’s members cannot have their content shown on YouTube and that their fans and users on YouTube will be unable to listen to Koda members’ music until a new agreement is in place.</p>
<p>Although the parties involved in the negotiations on the new joint agreement are by no means in concord yet, progress has been made in recent weeks, and Koda is puzzled by the extremely aggressive approach taken by Google in the negotiations this time.</p>
<h5><strong>Koda’s media director, Kaare Struve, says:</strong></h5>
<p>‘Google have always taken an “our way or the highway” approach, but even for Google, this is a low point. Of course, Google know that they can create enormous frustration among our members by denying them access to YouTube – and among the many Danes who use YouTube every day. We can only suppose that by doing so, YouTube hope to be able to push through an agreement, one where they alone dictate all terms’.</p>
<p>Ever since the first agreement was signed in 2013, the level of payments received from YouTube has been significantly lower than the level of payment agreed to by subscription-based services.</p>
<h5><strong>Koda’s CEO, Gorm Arildsen, says:</strong></h5>
<p>‘It is no secret that our members have been very dissatisfied with the level of payment received for the use of their music on YouTube for many years now. And it’s no secret that we at Koda have actively advocated putting an end to the tech giants’ free-ride approach and underpayment for artistic content in connection with the EU’s new Copyright Directive. The fact that Google now demands that the payments due from them should be reduced by almost 70% in connection with a temporary contract extension seems quite bizarre’.</p>
<p><strong>Media contact</strong>&nbsp;<br>Head of Communications Eva Hein /<span>&nbsp;</span><a href="mailto:eh@koda.dk">eh@koda.dk</a><span>&nbsp;</span>/ (+45) 61893233</p>
</div>
 </div></div>]]>
            </description>
            <link>https://www.koda.dk/about-us/press-release-google-removes-all-danish-music-from-youtube</link>
            <guid isPermaLink="false">hacker-news-small-sites-24006932</guid>
            <pubDate>Fri, 31 Jul 2020 08:59:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reverse Engineering the PLA Chip in the Commodore 128]]>
            </title>
            <description>
<![CDATA[
Score 167 | Comments 26 (<a href="https://news.ycombinator.com/item?id=24004640">thread link</a>) | @segfaultbuserr
<br/>
July 30, 2020 | https://c128.se/posts/silicon-adventures/ | <a href="https://web.archive.org/web/*/https://c128.se/posts/silicon-adventures/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <h2 id="backstory-and-first-attempts">Backstory and first attempts</h2>
<p>As I mentioned in my last post I’ve been working on reverse engineering the PLA chip in the C128.
I’m now mostly done with this process so I think it’s time to share some of the findings.</p>
<p>This has been a very interesting project as I did not really know much about semiconductor design
and manufacturing. My existing knowledge extended to having seen some die shots and admiring the pretty
looking pictures.</p>
<p>It all started with me buying a cheap microscope to help with soldering surface mount components.</p>

<p><a href="https://c128.se/posts/silicon-adventures/cheapo-microscope.jpg" data-mediabox="gallery" data-title="Cheap microscope">
    <img src="https://c128.se/posts/silicon-adventures/cheapo-microscope.jpg" alt="Cheap microscope">
</a>
</p>
<p>Some time later I ended up watching a video on youtube showing a simpler way of getting silicon dies out
of the packaging.</p>


<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/ZQeHHYJYWXo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>This looked simple enough to try at home as I already had all the equipment needed. Decapping an IC usually involves heated sulphuric acid or
other similar nasty chemicals which I do not really want to play with at home. So I dug out a couple of broken MOS chips I had lying around
(never throw things away, could come in handy). After fiddling around a bit I ended up with two 8521R0 dies and one 8721 PLA.
The first real photo was the one show in the last post.</p>

<p><a href="https://c128.se/posts/now-available/pla-die.png" data-mediabox="gallery" data-title="Full 8721 PLA die photo">
    <img src="https://c128.se/posts/now-available/pla-die.png" alt="Full 8721 PLA die photo">
</a>
</p>
<h2 id="better-microscope">Better microscope</h2>
<p>While this was a success I quickly realised that this microscope did not have enough resolution for me to be able to capture images of high
enough quality. The maximum magnification is 90x, when using a 2x barlow lens. Additionally it does not have a stage so I had to place the die
on a table and then move the whole microscope, which is very unstable and makes it hard to capture the bits you want to see.</p>
<p>As such a better microscope was sourced and purchased, still within reasonable money.</p>

<p><a href="https://c128.se/posts/silicon-adventures/amscope-me580t.jpg" data-mediabox="gallery" data-title="AmScope ME580-T microscope">
    <img src="https://c128.se/posts/silicon-adventures/amscope-me580t.jpg" alt="AmScope ME580-T microscope">
</a>
</p>
<p>This proved to be much better at taking pictures of decent quality, I was however not happy with the camera I bought with it. It’s a cheap camera with no capability for me to manage it remotely except using the AmScope application. Around this time, the Raspberry Pi foundation
released the new High Quality camera for the Raspberry Pi. This camera has a C-mount on it which matches the microscope so I quickly bought
one and put in on the microscope. This camera is fantastic for this job, full control of the whole process from the comfort of linux.</p>

<p><a href="https://c128.se/posts/silicon-adventures/8521r0-detail.jpg" data-mediabox="gallery" data-title="Silicon die detail from 8521R0">
    <img src="https://c128.se/posts/silicon-adventures/8521r0-detail.jpg" alt="Silicon die detail from 8521R0">
</a>
</p>
<p>All in all a vast improvement to the previous setup. With the higher resolution I started needing to stitch the photos together to make
larger pictures. This sounded simple at the start and ended up being (as you can probably guess) not very easy at all. I’m still struggling
with the stitching, but slowly improving. One of the key things for a successful panorama stitch is to have consistent photos when it comes
to panning, focus, white balance etc. etc. The more even the photos, the easier and better the stitching becomes.</p>
<h2 id="motorizing">Motorizing</h2>
<p>This led me to start working on motorizing the table. It was getting really tiresome having to manually move the table around and the photos
ended up being moved in multiple axis etc.</p>
<p>Lots of design work, 3D printing and research into CNC firmwares later I ended up with the following setup:</p>

<p><a href="https://c128.se/posts/silicon-adventures/modded-me580t.jpg" data-mediabox="gallery" data-title="Modified AmScope ME580-T microscope">
    <img src="https://c128.se/posts/silicon-adventures/modded-me580t.jpg" alt="Modified AmScope ME580-T microscope">
</a>
</p>
<p>Going from the top we have a Raspberry 7” display, with a Raspberry Pi4 mounted on the back. Not see is also the RPi HiQ camera mounted on
the microscope. The RPi takes photos, displays previews on the display and also runs the python code that controls the CNC board.</p>
<p>The stage and the levelling table is motorized with 28BYJ-48 steppers controlled using a small board with an ESP32 running <a href="https://github.com/bdring/Grbl_Esp32">Grbl_Esp32</a> and four AD4498 stepper motor controllers.</p>
<p>This whole setup has some issues both in software and hardware but it works well enough for now to enable me to do some work.</p>

<p>With the logistics now sorted out I returned to the work of reverse engineering the chip itself. My initial focus was on the PLA chip
as this should be one of the simpler ones to figure out. PLA stands for <a href="https://en.wikipedia.org/wiki/Programmable_logic_array">Programmable Logic Array</a> and is a very common structure in designs from this era.</p>
<p>Looking at the schematic diagram from wikipedia we should expect to see two main arrays, AND and OR. Inputs are connected to AND and
outputs from the OR array.</p>
<p>Going back to the previous die shot with can improve it with some annotations for the pins and the general areas of the chip. Once we
have established the pins we can see that all the inputs are connected to one array and all the outputs to the other array, just as
expected. This also helps us establish which array is which.</p>

<p><a href="https://c128.se/posts/silicon-adventures/pla-annotated.png" data-mediabox="gallery" data-title="Annotated die shot of 8721 PLA">
    <img src="https://c128.se/posts/silicon-adventures/pla-annotated.png" alt="Annotated die shot of 8721 PLA">
</a>
</p>
<p>Here we see the I/O pins marked up with how they are connected to the lead frame and the pins on the DIP itself. We can also see the two main
areas that make up a PLA structure, the AND array and the OR array. Additionally there is some extra logic at the bottom marked with a question
mark. The function of this was unknown to me but as all the output pins are passing through it I was guessing that it was an output stage of
some kind.</p>
<h2 id="and-array">AND array</h2>
<p>So, if we take a closer look at the AND matrix to start with we will see the following. The colours are a bit off as this was still done
using the AmScope camera and I didn’t figure out how to set the white balance on it.</p>

<p><a href="https://c128.se/posts/silicon-adventures/and-matrix-metal.jpg" data-mediabox="gallery" data-title="AND matrix with metal layer">
    <img src="https://c128.se/posts/silicon-adventures/and-matrix-metal.jpg" alt="AND matrix with metal layer">
</a>
</p>
<p>This was not very helpful to understand what was going on as all the interesting bits are covered up by the top-most metal layer. This was
early on when I was still learning a lot so to remove the metal I took a very brute force approach. I use heavy mechanical scrubbing to
remove the metal which I also learned once I put it back in the microscope had removed everything but the substrate itself. Oops.</p>
<p>Fortunately, the details that I needed were in the diffusion embedded into the substrate:</p>

<p><a href="https://c128.se/posts/silicon-adventures/and-matrix-delayer.jpg" data-mediabox="gallery" data-title="AND matrix substrate">
    <img src="https://c128.se/posts/silicon-adventures/and-matrix-delayer.jpg" alt="AND matrix substrate">
</a>
</p>
<p>Looking closely at this image we can see little squiggly lines where a transistor is located to create a connection within the matrix.</p>
<h2 id="or-array">OR array</h2>
<p>Moving on to the OR array we see the exact same pattern. Hard to tell with the metal layer in place, though easier compared to the AND
matrix. Much easier with just the substrate and diffusion left.</p>


<h2 id="full-matrix-decode">Full matrix decode</h2>
<p>Armed with this knowledge we can now proceed with extracting the full PLA logic matrix from the images.</p>
<p>I marked all transistors in each matrix with a dot and got the following picture:</p>

<p><a href="https://c128.se/posts/silicon-adventures/decoded-matrix.jpg" data-mediabox="gallery" data-title="AND matrix with metal layer">
    <img src="https://c128.se/posts/silicon-adventures/decoded-matrix.jpg" alt="AND matrix with metal layer">
</a>
</p>
<p>All inputs are horizontal in the AND matrix, with each line having a normal and an inverted signal being fed in.
All outputs are horizontal in the OR matrix and they are connected with vertical lines called product terms.</p>
<p>By looking at the dots, we can decode the product terms by doing logic and for all vertical lines in the AND matrix, for example</p>
<pre><code>    p0 = CHAREN &amp; HIRAM &amp; BA &amp; !MS3 &amp; GAME &amp; RW &amp; AEC &amp; A12 &amp; !A13 &amp; A14 &amp; A15
</code></pre><p>For the outputs we instead look horizontal for each output and combine with or, for example</p>
<pre><code>    SDEN = p42 | p43 | p66 | p69
</code></pre><p>So now we have the entire set of logic equations. Hooray!</p>
<h2 id="output-stage">Output stage</h2>
<p>Going back to the full die picture, we now have everything but the box marked with a question mark in the output path.</p>
<p>Looking at higher resolution photos of this we can see similar structures for each output. In all cases except two the structure
is bypassed and the output from the OR matrix goes directly to the output pin. This is however not the case for the two pins <code>DWE</code> and <code>CASENB</code>.</p>
<p><code>DWE</code> is the Write Enable signal going to the main system DRAM chips, CASENB is gating the CAS signal towards the RAM. These two signals are
processed in some form using these output gate structures, so I had to reverse engineer this block.</p>


<p>After quite some time reading up on silicon chip design and manufacturing and a lot of attempts I managed to come up with a schematic
for this that makes sense. I’m not going to go into the whole process here but I will document and post it later. Here I would also like
to thank <a href="https://www.patreon.com/androSID">Frank Wolf</a> for his help, please support his project if you can!</p>

<p><a href="https://c128.se/posts/silicon-adventures/output-schematic.png" data-mediabox="gallery" data-title="Output block schematic">
    <img src="https://c128.se/posts/silicon-adventures/output-schematic.png" alt="Output block schematic">
</a>
</p>
<p>Going a bit further, the way this is used in the <code>DWE</code> and <code>CASENB</code> outputs makes it a normal D-latch. The latch enable for this also comes
for the PLA matrix in a pair of lines in the OR matrix.</p>
<h2 id="result">Result</h2>
<p>So as a final result we can now write down the full HDL code for the C128 PLA chip. I’m using verilog for this. Mind you this is the first
verilog I’ve ever written so it’s probably suboptimal. Using a D-latch for the output in verilog is normally seen as a bad thing, however
in this case I am doing it to replicate the logic and function of the existing chip.</p>
<p>I have validated this to the best of my knowledge, but if I’ve missed anything please let me know!</p>
<p>In difference to the C64 PLA the C128 PLA can not be replaced with just an EPROM or similar due to the presence of the output latches.</p>
<div><pre><code data-lang="verilog"><span>module</span> pla_8721(
    <span>input</span> rom_256,
    <span>input</span> va14,
    <span>input</span> charen,
    <span>input</span> hiram,
    <span>input</span> loram,
    <span>input</span> ba,
    <span>input</span> vma5,
    <span>input</span> vma4,
    <span>input</span> ms0,
    <span>input</span> ms1,
    <span>input</span> ms2,
    <span>input</span> ms3,
    <span>input</span> z80io,
    <span>input</span> z80en,
    <span>input</span> exrom,
    <span>input</span> game,
    <span>input</span> rw,
    <span>input</span> aec,
    <span>input</span> dmaack,
    <span>input</span> vicfix,
    <span>input</span> a10,
    <span>input</span> a11,
    <span>input</span> a12,
    <span>input</span> a13,
    <span>input</span> a14,
    <span>input</span> a15,
    <span>input</span> clk,

    <span>output</span> sden,
    <span>output</span> roml,
    <span>output</span> romh,
    <span>output</span> clrbnk,
    <span>output</span> from,
    <span>output</span> rom4,
    <span>output</span> rom3,
    <span>output</span> rom2,
    <span>output</span> rom1,
    <span>output</span> iocs,
    <span>output</span> dir,
    <span>output</span> <span>reg</span> dwe,
    <span>output</span> <span>reg</span> casenb,
    <span>output</span> vic,
    <span>output</span> ioacc,
    <span>output</span> gwe,
    <span>output</span> colram,
    <span>output</span> charom);

<span>wire</span> p0;
<span>wire</span> p1;
<span>wire</span> p2;
<span>wire</span> p3;
<span>wire</span> p4;
<span>wire</span> p5;
<span>wire</span> p6;
<span>wire</span> p7;
<span>wire</span> p8;
<span>wire</span> p9;
<span>wire</span> p10;
<span>wire</span> p11;
<span>wire</span> p12;
<span>wire</span> p13;
<span>wire</span> p14;
<span>wire</span> p15;
<span>wire</span> p16;
<span>wire</span> p17;
<span>wire</span> p18;
<span>wire</span> p19;
<span>wire</span> p20;
<span>wire</span> p21;
<span>wire</span> p22;
<span>wire</span> p23;
<span>wire</span> p24;
<span>wire</span> p25;
<span>wire</span> p26;
<span>wire</span> p27;
<span>wire</span> p28;
<span>wire</span> p29;
<span>wire</span> p30;
<span>wire</span> p31;
<span>wire</span> p32;
<span>wire</span> p33;
<span>wire</span> p34;
<span>wire</span> p35;
<span>wire</span> p36;
<span>wire</span> p37;
<span>wire</span> p38;
<span>wire</span> p39;
<span>wire</span> p40;
<span>wire</span> p41;
<span>wire</span> p42;
<span>wire</span> p43;
<span>wire</span> p44;
<span>wire</span> p45;
<span>wire</span> p46;
<span>wire</span> p47;
<span>wire</span> p48;
<span>wire</span> p49;
<span>wire</span> p50;
<span>wire</span> p51;
<span>wire</span> p52;
<span>wire</span> p53;
<span>wire</span> p54;
<span>wire</span> p55;
<span>wire</span> p56;
<span>wire</span> p57;
<span>wire</span> p58;
<span>wire</span> p59;
<span>wire</span> p60;
<span>wire</span> p61;
<span>wire</span> p62;
<span>wire</span> p63;</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://c128.se/posts/silicon-adventures/">https://c128.se/posts/silicon-adventures/</a></em></p>]]>
            </description>
            <link>https://c128.se/posts/silicon-adventures/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24004640</guid>
            <pubDate>Fri, 31 Jul 2020 01:11:55 GMT</pubDate>
        </item>
    </channel>
</rss>
