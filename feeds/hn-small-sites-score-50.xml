<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Thu, 22 Oct 2020 01:14:40 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Thu, 22 Oct 2020 01:14:40 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[My chatbot is dead – Why yours should probably be too]]>
            </title>
            <description>
<![CDATA[
Score 85 | Comments 77 (<a href="https://news.ycombinator.com/item?id=24834552">thread link</a>) | @raphaelsaunier
<br/>
October 19, 2020 | https://azumbrunnen.me/blog/my-chatbot-is-dead-%C2%B7-why-yours-should-probably-be-too/ | <a href="https://web.archive.org/web/*/https://azumbrunnen.me/blog/my-chatbot-is-dead-%C2%B7-why-yours-should-probably-be-too/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                
<audio controls="controls"><source src="https://azumbrunnen.me/audio/chatbot-is-dead" type="audio/mpeg"></audio>



<p>Personal websites are usually like old books in a shelf. They languish, accumulate dust, and their wrinkles and cracks become more apparent over time. About 3 years ago I embarked on a simple experiment that would end up prolonging the shelf-life of my website by an unusually large margin.</p>



<p>Back in 2017, it seemed like Conversational UI was poised to take over the world. We saw Quartz turning news into a conversation, WeChat being featured as the poster-child of a post application world, iMessage turning into an unnecessarily complex mess, and chatbots popping up like mushrooms in moist forests.</p>



<p>Of course, any trend gaining so much traction and interest needs to be taken seriously. As such, I decided to familiarize myself with the topic, and turned my website into a chatbot.</p>



<p>Instead of being greeted by the internationally standardized greeting every designer used at some point in their career, there was no bold, dramatically oversized, and deep black sans-serif reading: <em>Hi, I’m a designer.</em> (To be fair, I didn’t use Proxima Nova either)</p>



<p>Instead, a couple of chat bubbles exuberantly ushered onto the canvas to greet users as if we had all been long time friends.</p>



<figure><video autoplay="" loop="" muted="" src="https://azumbrunnen.me/wp-content/uploads/chatbot-animated.mp4" playsinline=""></video><figcaption>Conversational intro</figcaption></figure>



<p>It was witty, new, and slightly awkward. People would send messages that ranged from simple chit chat, to deep philosophical topics, to downright disturbing and ridiculous insults.</p>



<p>The experiment got featured on Hackernews, Medium, was used in psychological studies conducted by Dan Ariely’s team, and the source code was ripped and edited by various startups to fit their needs. One business in the Bay Area had an idea to use it to sell flowers in a conversational way. It looks like they went out of business.</p>



<p>The reaction and feedback was surprising to say the least. It was an idea so simple, so silly, that the outcome was in many ways unexpected. After all, the only one who really cares about your website, is usually yourself.</p>



<p>That didn’t stop me from revamping my website and kill the very thing that had turned it into a micro-celebrity before. With the death of my old chatbot, some angry emails by schools who are using it as a reference for “creative” web design, and a good amount of time that has passed ever since, I wanted to take a step back and set the record straight.</p>



<hr>



<h2>When chatbots matter</h2>



<p>So let’s be honest with ourselves for a moment: <em>when did you actually ever enjoy talking to a chat bot?</em> And I’m not talking about the type of bots you talk to when you’re bored, but about those that provide a deeper purpose.</p>



<p>It turns out that the answer is, at least for most of us, almost never.</p>



<p>I love you Intercom, except when I don’t. 99% of time I don’t want to talk to a silly and obtrusive avatar popping up from some corner of the screen before I even had a chance to check out what’s going on. Somehow, I can’t help but think others feel the same.</p>



<p>In fact, we do know that others feel the same. Chat heads jumping at us unasked, are the quintessential equivalent of the infamous sales clerk who eagerly talks to us upon entering a store.</p>



<p>To further add to the challenges: as soon as users go off-script, chat bot’s don’t just become awkward and unpredictable—they turn into little sociopaths that might rub users the wrong way.</p>



<figure><img loading="lazy" width="400" height="346" src="https://azumbrunnen.me/wp-content/uploads/grandma.png" alt="" srcset="https://azumbrunnen.me/wp-content/uploads/grandma.png 400w, https://azumbrunnen.me/wp-content/uploads/grandma-300x260.png 300w" sizes="(max-width: 400px) 100vw, 400px"><figcaption>UX Chat.me —&nbsp;Conversational UX News</figcaption></figure>



<p>The moment you create a chat bot is the moment you allow customers to have a conversation with <em>your brand</em>. Not with yourself, not with your friend, but with an uber entity—a symbol—that represents everything you and your team stand for. That’s not a step to be taken lightly.</p>



<p>This simple conversational entity can be a fun tool to engage with people but depending on how the conversation goes, it can quickly turn into a misrepresentation of the values of your team and your company. So building a chat bot should never be the default choice, but an intentional one.</p>



<p>That’s why it’s worth asking yourself the following three questions before venturing into this space:</p>



<h3>1. Is your use case simple enough to be solved through chat?</h3>



<p>Conversation is incredibly complex and it’s challenging enough to keep it on track in the real world. If the use case isn’t simple, chances are, chat bots are not the right tool for the job.</p>



<h3>2. Is your NLP capable and sophisticated enough?</h3>



<p>There are two types of bots: pre-scripted bots with a range of default answers users can choose from, and Natural Language Processing based ones.</p>



<p>Choosing the right one is hard. While pre-scripted can feel too limiting, NLP can break at every corner. Often times, teams quickly fall into the trap of spending a huge amount of time focusing on personality and silly jokes, instead of solving the problem users hired you for in the first place.</p>



<p>Therefore, building on top of the first point above, within the conversational landscape, simple always wins.</p>



<h3>3. Are your users actually in chat based environments?</h3>



<p>Chat bots work best where users already are. If your users are primarily spending time in messaging platforms where bots and micro-apps can be seamlessly embedded, great. That can serve as an effective and natural way to engage with your audience because it matches the “be where users already are” principle.</p>



<p>If on the other hand, people come to your website, a medium that has made great strides to provide content in a non-linear and quick way, it often unnecessarily slows users down. </p>



<hr>



<h2>Farewell chatbot</h2>



<p>I don’t want to discredit chat bots as a paradigm. They have their use in certain industries, medium, and work well for a specific set of use cases. The important part is being deliberate, rather than jumping ship blindfolded.</p>



<p>So whereas turning my website into a chat was a fun experiment, I ultimately feel like it has slowly turned into a fad. I got fooled by the trend, and as a by-product became part of the trend itself.  Fads come and go, and as they get refined and re-interpreted, they ultimately find their true purpose. What we’re left with is the age old insight that it’s only through experimentation, that we can unlock concepts and ideas that last.</p>



<p>Rest in peace chat bot, long live chat bots.</p>
            </article></div>]]>
            </description>
            <link>https://azumbrunnen.me/blog/my-chatbot-is-dead-%C2%B7-why-yours-should-probably-be-too/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24834552</guid>
            <pubDate>Tue, 20 Oct 2020 06:52:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Moana Motunui Renderer on GPU]]>
            </title>
            <description>
<![CDATA[
Score 241 | Comments 22 (<a href="https://news.ycombinator.com/item?id=24833218">thread link</a>) | @Impossible
<br/>
October 19, 2020 | https://www.render-blog.com/2020/10/03/gpu-motunui/ | <a href="https://web.archive.org/web/*/https://www.render-blog.com/2020/10/03/gpu-motunui/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
  
  <p><span>03 Oct 2020</span></p><p>Disney Animation’s Moana island dataset is a production-scale scene with memory requirements that make it challenging to render. This post summarizes some of those challenges, and describes how the <a href="https://github.com/chellmuth/gpu-motunui">GPU-Motunui</a> project is able to efficiently render the scene on a consumer-grade GPU with less than 8GB of memory. <a href="#renders">Click here</a> to skip ahead to the results.</p>

<h2 id="the-moana-island">The Moana island</h2>

<p>In 2018, Disney Animation released the Moana island dataset to the rendering research community. Compared to traditional research scenes, the scale of the Moana island scene is massive: the scene contains 90 million quad primitives, 5 million curves, and more than 28 million instances. All told, the island consists of over 15 billion primitives, weighing in at just under 30GB of geometry files.</p>

<p>The shots included with the dataset are beautiful, and showcase the amazing imagery that can be created by combining the best artists in the world with path tracing techniques and modern hardware. Here are two reference images, rendered with Disney’s proprietary Hyperion renderer:</p>

<div>
  <p><img src="https://www.render-blog.com/assets/hyperion-reference-shotCam.png" alt="Hyperion shotCam reference"></p><p>Hyperion shotCam reference</p>
</div>

<div>
  <p><img src="https://www.render-blog.com/assets/hyperion-reference-beachCam.png" alt="Hyperion beachCam reference"></p><p>Hyperion beachCam reference</p>
</div>

<h2 id="gpu-motunui-project">GPU-Motunui Project</h2>

<p>The goal of the GPU-Motunui project is to render all the Moana shots efficiently and accurately on a consumer-grade graphics card. There are two main challenges to accomplishing this with the Moana dataset. First, with a typical graphics card having only 8GB of memory, an out-of-core rendering solution is required to handle the large amounts of geometry. Second, the scene’s textures are provided in the Ptex format, and Ptex doesn’t have a publicly available CUDA implementation. This project currently only solves the first problem, and Ptex texture lookup is done on the CPU (although conveniently its cost is fully hidden by being computed concurrently with GPU shadow ray tracing).</p>

<p>The Hyperion reference images are impossible to match exactly; for example the varying brown and green colors along the palm tree fronds in the palmsCam shot are not provided in the dataset. Other features of the scene are possible to render but out of my initial scope, notably subdivision surfaces and their displacement maps, and a full Disney BSDF implementation.</p>

<div>
  <p><img src="https://www.render-blog.com/assets/hyperion-unique-palmsCam.png" alt="Example of an unreproducible material variation on the palm tree frond"></p><p>Example of an unreproducible material variation on the palm tree frond</p>
</div>

<p>All ray tracing operations are run through Nvidia’s OptiX 7 API. This means GPU-Motunui gets the full benefits of available RT cores and a world-class BVH implementation. The following sections describe how GPU-Motunui maps dataset assets to OptiX data structures, and how GPU-Motunui’s out-of-core rendering solution works.</p>

<h3 id="scene-representation">Scene representation</h3>

<p>The Moana scene makes widespread use of multi-level instancing. In OptiX, this requires a three-level hierarchy of acceleration structures to manage: two levels of IASs, and a base level of GASs (Instance Acceleration Structures and Geometry Acceleration Structures, respectively). GPU-Motunui makes use of OptiX’s AS compaction and relocation APIs to further reduce memory usage.</p>

<p>The isHibiscus element makes a good example of how a typical element in the scene is organized and built. The tree is assembled from a base model in one Wavefront .obj file (containing the trunk and branches), and four primitives: one flower and three leaf models (each with their own .obj file).</p>

<div>

<p>Left: The four simple primitives that will be instanced to fill out the hibiscus tree <br>Right: The base trunk and branches model </p>
</div>

<p>In OptiX, each of these models has an associated GAS, and each GAS can be subdivided into multiple build inputs. Build inputs are used to map sections of the model to information needed at shading time by indexing into OptiX’s shader binding table. These GASs form the bottom level of the hierarchy.</p>

<p>Next, an IAS is used to build the full isHibiscus element. This IAS is in the middle level of the hierarchy. The figure below shows each primitive’s instances in isolation, and combined to make the full element:</p>

<div>

<p>Left: Isolated instances for each primitive<br>Right: Full isHibiscus element</p>
</div>

<p>Finally, a second IAS is built to track all of the element’s instances present in the scene. This second IAS is the top level of the instance hierarchy.</p>

<div>
  <p><img src="https://www.render-blog.com/assets/isHibiscus-instanced-elements.png" alt="The shotCam view rendered with only isHibiscus instances"></p><p>The shotCam view rendered with only isHibiscus instances</p>
</div>

<p>Although the isHibiscus element has a typical structure, there are some more complicated elements included in the dataset. The isCoral element, for example, has different base geometry and instanced primitives for each of its element instances, but the underlying primitive geometries are shared across all the element instances.</p>

<p>The Moana GAS and IASs alone require 18.5 GB, well past the memory budget of my 8GB RTX 2070. Because OptiX has no native support for out-of-core rendering, the traditional OptiX pipeline had to be put aside for a custom-made solution.</p>

<h3 id="out-of-core-rendering">Out-of-core rendering</h3>

<p>To solve the out-of-core rendering problem, GPU-Motunui divides the scene’s geometry into different sections, and ray traces each separately, while tracking the closest hit. Replacing a traditional device trace call with a host loop comes with many design consequences to the renderer, from asset loading to the core path tracing loop that sends rays through the scene.</p>

<p>Before rendering, the asset loading process allocates a large chunk of GPU memory (currently 6.7GB). A custom allocator is implemented that manages this block of memory. It is responsible for allocating two types of memory: output and temporary. Output memory is allocated from the left of the block, and is used for OptiX structures. Temporary memory is managed on a stack from the right end of the memory block. Managing the temporary memory this way ensures that the output structures are always tightly packed.</p>

<p>After elements are processed into their accelerator structures on the GPU, their used memory is snapshotted onto the host, and the allocator is cleared. The process is repeated until all of the scene’s geometry is processed, resulting in the host managing a list of GPU memory snapshots. The figure below shows an example layout of GPU memory that could be snapshotted:</p>

<div>
  <p>GPU memory layout after loading the isHibiscus element.<br>(Dotted arrows show that an IAS holds instances of the pointed-at AS)</p>

</div>

<p>As mentioned above, when it comes time to ray trace, each snapshot is processed in a loop. This means a call to <code>cudaMemcpy</code> and <code>optixLaunch</code> for each snapshot. A global buffer is maintained that indicates the depth of the current closest intersection. This value is used as the <code>tmax</code> parameter for the CUDA kernel’s call to <code>optixTrace</code>, and a successful intersection will update the depth buffer for the next launch.</p>

<p>In a traditional OptiX path tracer, the entire render loop can run in device code inside a single call to <code>optixLaunch</code>; i.e., a successful intersection will lead to more BSDF and shadow rays being traced in the same kernel launch. Because GPU-Motunui’s design mandates multiple launches for tracing each path segment, the render loop is pulled out into host code. While this potentially diminishes OptiX’s ability to efficiently schedule program execution, it also opens up opportunties for optimization, such as running Ptex texture lookups on the CPU concurrently with GPU kernels and I/O.</p>

<h3 id="shading">Shading</h3>
<p>As with any OptiX application, GPU-Motunui makes use of the shader binding table (SBT). SBT records contain pointers to normal buffers and material attributes. The underlying data for the normal buffers is stored alongside OptiX acceleration structures and included in geometry snapshots. This ensures that GPU memory is never wasted on unreachable normal buffer data.</p>

<h2 id="renders">Renders</h2>
<p>Included below are GPU-Motunui renders of the six scenes included in the dataset. shotCam is the slowest to render at 18.2 seconds per sample at 1024x429 resolution, and took just over five hours total for the final image. All shots are 1024spp, capped at a maximum of five bounces, and were run on an Nvidia RTX 2070.</p>
<div>
  <p><img src="https://www.render-blog.com/assets/ours-shotCam.png" alt="shotCam"></p><p>shotCam</p>
</div>

<div>
  <p><img src="https://www.render-blog.com/assets/ours-beachCam.png" alt="beachCam"></p><p>beachCam</p>
</div>

<div>
  <p><img src="https://www.render-blog.com/assets/ours-dunesACam.png" alt="dunesACam"></p><p>dunesACam</p>
</div>

<div>
  <p><img src="https://www.render-blog.com/assets/ours-palmsCam.png" alt="palmsCam"></p><p>palmsCam</p>
</div>

<div>
  <p><img src="https://www.render-blog.com/assets/ours-birdseyeCam.png" alt="birdseyeCam"></p><p>birdseyeCam</p>
</div>

<div>
  <p><img src="https://www.render-blog.com/assets/ours-rootsCam.png" alt="rootsCam"></p><p>rootsCam</p>
</div>

<div>
  <p><img src="https://www.render-blog.com/assets/ours-grassCam.png" alt="grassCam"></p><p>grassCam</p>
</div>

<h2 id="optimization">Optimization</h2>
<p>The initial implementation of the renderer required 42.6 seconds per 1spp on the shotCam scene. A few optimizations combined to make significant reductions in rendering time, cutting each pass down to 18.2 seconds (a 57.3% reduction).</p>

<h4 id="cpugpu-concurrency">CPU/GPU concurrency</h4>
<p>Tracing shadow rays on the GPU in parallel with Ptex lookups on the CPU cut rendering time by 23.4%. It was disappointing to be forced to do texture lookups on the CPU, but the time savings make up for it.</p>

<h4 id="multiple-ptex-caches">Multiple Ptex caches</h4>
<p>Parallelizing the Ptex lookups and using multiple Ptex caches eliminated texture lookups as a bottleneck to the system; shadow ray casting time fully dominates the texture lookup. Empirically, spawning two threads per core (totaling 12 on an Intel i7-8700K) and sharing three Ptex caches comfortably reduced the texture lookup time beneath the shadow ray budget. This improved the time savings to a 33.9% reduction over the baseline.</p>

<h4 id="pinned-memory">Pinned memory</h4>
<p>The acceleration structure snapshots are all saved to pinned host memory. Switching from normal to pinned host memory increased the transfer throughput from 7.73 GB/s to 11.84 GB/s, cutting the baseline render time by 19.5%.</p>

<h2 id="future-steps">Future Steps</h2>
<p>Getting this scene running on my RTX 2070 card was a very fun and rewarding project, but there are still many improvements to be made:</p>
<ul>
  <li>Implementing the Disney BSDF</li>
  <li>Rendering subdivision surfaces along with displacement mapping</li>
  <li>More efficiently packing the acceleration structures, and optimizing ray tracing throughput</li>
  <li>Experimenting with how various research results hold up on production scenes (e.g., testing select path guiding techniques)</li>
</ul>

<h2 id="references">References</h2>
<ul>
  <li><a href="https://github.com/chellmuth/gpu-motunui/">GPU-Motunui</a></li>
  <li><a href="https://technology.disneyanimation.com/islandscene/">Moana Island Scene</a></li>
  <li><a href="https://pharr.org/matt/blog/2018/07/16/moana-island-pbrt-all.html">Swallowing the elephant</a> - Matt Pharr</li>
  <li><a href="https://blog.yiningkarlli.com/2018/07/disney-animation-datasets.html">Disney Animation Data Sets</a> - Yining Karl Li</li>
  <li><a href="https://schuttejoe.github.io/post/disneypostmortem/">Rendering the Moana Island Scene Part 2: A production scene from a hobby renderer</a> - Joe Schutte</li>
  <li><a href="https://ingowald.blog/2020/01/09/digesting-the-elephant/">Digesting the elephant</a> - Ingo Wald</li>
  <li>Brent Burley and Dylan Lacewell. <a href="http://ptex.us/ptexpaper.html">Ptex: …</a></li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.render-blog.com/2020/10/03/gpu-motunui/">https://www.render-blog.com/2020/10/03/gpu-motunui/</a></em></p>]]>
            </description>
            <link>https://www.render-blog.com/2020/10/03/gpu-motunui/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24833218</guid>
            <pubDate>Tue, 20 Oct 2020 01:45:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Beginner's Guide to Arguing Constructively]]>
            </title>
            <description>
<![CDATA[
Score 145 | Comments 64 (<a href="https://news.ycombinator.com/item?id=24831852">thread link</a>) | @liamrosen
<br/>
October 19, 2020 | http://liamrosen.com/arguments.html | <a href="https://web.archive.org/web/*/http://liamrosen.com/arguments.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<div><p><span>First published September 2020</span></p><p>

<em>Questions? Suggestions? E-mail me:</em>&nbsp;<img alt="" height="22" src="http://liamrosen.com/liamrosen.png" title="" width="164"></p></div>

<h2>CONTENTS</h2>

<p><a href="#intro">PART I: INTRO</a><br>
<a href="#mindset">PART II: MINDSET</a><br>
<a href="#prework">PART III: PRE-WORK</a><br>
<a href="#debatebreakdown">PART IV: BREAKING DOWN A DEBATE</a><br>
<a href="#strategies">PART V: STRATEGIES</a><br>
<a href="#tips">PART VI: TIPS</a><br>
<a href="#thanks">PART VII: CONCLUSION</a></p>

<h2><a id="intro" name="intro">INTRO</a></h2>

<p>The vast majority of people on earth argue in a <em>destructive </em>fashion. Debates, especially in online spaces, are viewed as a battle of the wits in which egos are put on display and there can be only one "winner".</p>

<p>Instead, we should be arguing in a <em>constructive </em>fashion: treating arguments as an opportunity to expand knowledge, finding points of disagreement, and collaborating towards a common truth.</p>

<p>I have a confession to make: I used to be a destructive arguer. When I was younger, my goal in any argument was not to learn something new, but rather to assure my superiority over what I felt to be the clear stupidity of the other side. I even used to save screenshots of debates I had on various forums and social media platforms, returning periodically to reminisce about past skirmishes in which I "<a href="https://knowyourmeme.com/memes/trigger-the-libs">owned the conservatives</a>".</p>

<p>Luckily, several years spent abroad gave me a different perspective. I realized that in the small-sided debates I used to engage in back home, my positions lacked the nuance and context of the greater world. For the first time, I began to do deep research on how to think — and argue — &nbsp;more clearly, drawing from concepts from philosophy, psychology, and behavioral economics.</p>

<p>This widened outlook led me to see arguments as a chance to build value, rather than destroy it. Instead of going through the mental anguish of battle, I now follow a collaborative approach to debate that I'd like to share in this guide in hopes that it will inspire others to argue more constructively.</p>

<p>Note that the content in this guide will focus on arguments about public issues, like politics and religion, as opposed to personal issues, like "you need to communicate more" or "you haven't done the dishes in weeks". Though there is overlap between the two, interpersonal arguments are much more complex and require more nuance than this guide can provide, plus there are already a ton of great resources out there that explore these topics more thoroughly.</p>

<h2><a id="mindset" name="mindset">MINDSET</a></h2>

<blockquote>
<p><strong><span><em>&nbsp;"An argument should be a collaboration between two people to find the truth."</em></span></strong></p>
</blockquote>

<p>If I had to distill this guide down to one sentence, it would be the above. Even if you forget the individual tenets and strategies this guide has to offer, as long as you are treating any given argument as a collaboration in search of truth, you can't go wrong.</p>

<p>Arguing more effectively requires detaching yourself from the idea of "winning" in the traditional sense. Instead, you should declare victory when you have argued in good faith and kept an open mind.</p>

<p>True collaboration requires that both parties open an investigation into why they may be wrong and consider changing their beliefs. Which brings us to the three core tenets of a constructive debate mindset:</p>

<h3>Acknowledge You May Be Wrong, and Be Willing to Change Your Mind <a href="#Acknowledge You May Be Wrong, and Be Willing to Change Your Mind" id="Acknowledge You May Be Wrong, and Be Willing to Change Your Mind" name="Acknowledge You May Be Wrong, and Be Willing to Change Your Mind"><img alt="" src="http://liamrosen.com/anchor.png"></a></h3>

<p>Was there ever a time in which you had a deeply-held belief about something, but slowly came to realize that you were wrong? Maybe you thought a past partner was "the one", or you were devoted to a religious faith. Or perhaps something as simple as believing in Santa Claus.</p>

<p>What's to say that couldn't happen with the other deeply-held beliefs, given enough evidence?</p>

<p>Go into every debate with the mindset that you may not know everything about the topic at hand, and in fact <em>may be wrong</em>.</p>

<p>If you successfully acknowledge that you may be wrong, it follows that you must then be willing to change your mind. Having the humility to admit that your mind has been changed is one of the most honorable positions in a good faith debate.</p>

<h3>Arguments Are Not Soldiers <a href="#Arguments Are Not Soldiers" id="Arguments Are Not Soldiers" name="Arguments Are Not Soldiers"><img alt="" src="http://liamrosen.com/anchor.png"></a></h3>

<p>In a war, all soldiers take an oath to fight for their own side, no matter what amount they agree with its principles. <a href="https://www.lesswrong.com/posts/9weLK2AJ9JEt2Tt8f/politics-is-the-mind-killer">Eliezer Yudkowsky once observed</a> that in political debates, arguments were treated like soldiers: "<em>Once you know which side you're on, you must support all arguments of that side, and attack all arguments that appear to favor the enemy side; otherwise it's like stabbing your soldiers in the back.</em>"</p>

<p>Because most people go into debate with a war-like mentality, they feel they must fly the flag for all points that <em>their</em><em> side</em> supports, regardless of how much they actually agree with them.</p>

<p>The red state gun-owner must be pro-religion, anti-abortion, anti-drugs, anti-tax, and skeptical of gender issues.</p>

<p>The blue state Subaru-owner must be anti-religion, pro-abortion, pro-drugs, pro-tax(ing-the-rich), and concerned about gender issues.</p>

<p>Most annoying is that given the societal expectations for this divide, being for or against one issue immediately assigns you to a "side" in the views of everyone involved. Breaking out of this Arguments as Soldiers mindset involves two steps:</p>

<p>1. Do not be afraid to agree with the arguments of the other side when they strike you as reasonable, and critique the arguments of your own side when they strike you as unreasonable (better yet, try not to have a side).</p>

<p>2. On the flip side, avoid stereotyping your debate partner based on one opinion. If you are engaging with someone in debate for the first time, assume that they agree with you on every other position than the one they are defending, until proven otherwise.</p>

<h3>There's Always Someone Who Thinks the Jedi Are Evil <a href="#There's Always Someone Who Thinks the Jedi Are Evil" id="There's Always Someone Who Thinks the Jedi Are Evil" name="There's Always Someone Who Thinks the Jedi Are Evil"><img alt="" src="http://liamrosen.com/anchor.png"></a></h3>

<p><em>Brace yourself, Star Wars references incoming:</em></p>

<p>In a given debate, almost everyone thinks they are a member of the Jedi order, fighting for all that is virtuous and good in the universe. Yet for every Jedi, there's a Sith out there <a href="http://www.youtube.com/watch?v=llLKar19XhA">who thinks that the Jedi are evil</a> and wrong and that <em>they</em> are actually the ones fighting for virtue and good. Remember that this person might even be <em>you</em>.</p>

<p>Of course, you are not a full agent of good, and your debate partner is not an agent of evil, or vice versa. You are simply citizens of the galaxy who happen to be operating with different sets of information. Look at the situation from a different perspective: if you were raised with Sith beliefs from childhood, don't you think you might believe the exact same things a Sith would?</p>

<p>In debate, your goal should not be to <a href="https://www.youtube.com/watch?v=rMNKwZTv1d0">strike down the side of evil with all your hatred</a>, but rather work together with them to uncover the true facts about the universe, and in doing so perhaps change both your perspectives.</p>

<h2><a id="mindset" name="prework">PRE-WORK</a></h2>

<p>It would be great if choosing to pursue the path of arguing constructively was just a matter of changing your mindset overnight, but as Carl Sagan once said: <a href="https://youtu.be/BkHCO8f2TWs?t=9">"If you wish to bake an apple pie from scratch, you must first invent the universe."</a></p>

<p>In the same vein, if you wish to improve the constructiveness of the debates you engage in, you must first spend time re-inventing your entire mind.</p>

<p>This is because our mind is constantly working against us, plagued by ancient errors from the times in which we lived in caves and hunted woolly mammoths. These errors work against us in the form of cognitive biases and logical fallacies, which hinder our ability to clearly see reality and engage in sound debate.</p>

<h3>Recognize and Avoid Cognitive Biases <a href="#Recognize and Avoid Cognitive Biases" id="Recognize and Avoid Cognitive Biases" name="Recognize and Avoid Cognitive Biases"><img alt="" src="http://liamrosen.com/anchor.png"></a></h3>

<p>Cognitive biases are limits and mistakes in human judgement that prevent someone from acting rationally. They are present in every aspect of human life, and in tense situations like arguments, they tend to appear more often as emotions are heightened and the brain gets overloaded.</p>

<p>Common examples that relate to debates are <em>confirmation bias</em>, or the tendency of humans to seek out information that confirms existing beliefs, and <em>ingroup bias</em>, or the tendency to agree more strongly with people that appear to be part of our "tribe", but there are over 100 identified biases, and it's worth reading through the Wikipedia article on the <a href="https://en.wikipedia.org/wiki/List_of_cognitive_biases">most common cognitive biases</a> so you can recognize when they might be clouding your thinking.</p>

<h3>Recognize and Avoid Logical Fallacies <a href="#Recognize and Avoid Logical Fallacies" id="Recognize and Avoid Logical Fallacies" name="Recognize and Avoid Logical Fallacies"><img alt="" src="http://liamrosen.com/anchor.png"></a></h3>

<p>In part caused by cognitive biases, logical fallacies are errors in argument that give off an air of decisiveness, despite making points that don't hold up to logical scrutiny. While these are often used unintentionally, due to bias, carelessness, or ignorance, unfortunately, they can also be wielded intentionally by a shrewd debate partner.</p>

<p>Common examples in debate include the <em>false dilemma fallacy</em>: "you're either with us or against us", and the <em>slippery slope fallacy</em>: "if we allow the gays to marry, what's next: plants?" Just like cognitive biases, there are a large number of identified logical fallacies, and it's worth it to review the <a href="https://en.wikipedia.org/wiki/List_of_fallacies">entire list</a>, so you can spot them in your own arguments and in those of others.</p>

<h2><a id="debatebreakdown" name="debatebreakdown">BREAKING DOWN A DEBATE</a></h2>

<p>To the untrained eye, a debate might look like two or more parties trading argumentative points back and forth. But interestingly, these points can almost perfectly be classified into a few categories. Understanding these categories, and why some types of arguments are better than others, is crucial for learning how we and those whom we engage with in debate might shape their points. In a brilliant post called <em><a href="https://slatestarcodex.com/2018/05/08/varieties-of-argumentative-experience/">Varieties of Argumentative Experience</a></em>, Scott Alexander does just this, illuminating and labeling practically every part of a debate. The post itself is basically required reading, but is long-ish<em>,</em> so I will summarize here.</p>

<p>Think of a debate as a pyramid: <a href="#debatepyramid" id="debatepyramid" name="debatepyramid"><img alt="" src="http://liamrosen.com/anchor.png"></a></p>

<p><img alt="" height="548" src="http://liamrosen.com/Pyramid%20of%20Argumentative%20Experience.svg" width="978"></p>

<p>In general, the lower on the pyramid you are, the worse debate you're having. The goal should be to start as high as possible and continue to work your way towards the top.</p>

<p>Debates on twitter and other forms of social media are almost guaranteed to never rise above the lower dotted line, as these platform don't allow for more nuanced debate. Everything above the higher dotted line is our gold standard: two intelligent, charitable, and versed debaters can successfully maintain a debate at this level until some form of resolution.</p>

<p>The blue side represents the discussion …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://liamrosen.com/arguments.html">http://liamrosen.com/arguments.html</a></em></p>]]>
            </description>
            <link>http://liamrosen.com/arguments.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24831852</guid>
            <pubDate>Mon, 19 Oct 2020 22:43:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to better calculate churn rates]]>
            </title>
            <description>
<![CDATA[
Score 139 | Comments 34 (<a href="https://news.ycombinator.com/item?id=24831637">thread link</a>) | @cmogni1
<br/>
October 19, 2020 | https://catchjs.com/Blog/Churn | <a href="https://web.archive.org/web/*/https://catchjs.com/Blog/Churn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <div>
        
<ol>
    <li><a href="https://catchjs.com/Docs">Blog</a></li>
    <li>You're all calculating churn rates wrong</li>
</ol>

        

        
        <p>
            Many smart people will tell you to obsess over your churn rate.
        </p>
        <p>
            <img src="https://catchjs.com/Blog//images/blog/churn/churn_rate_formula2.png" alt="churn rate=(customers lost in month)/(customers at start of month)">
        </p>
        <p>
            According to Andreessen Horowitz, this number is <a href="https://a16z.com/2015/08/21/16-metrics/">one of the top 16 metrics</a>
            to measure a SaaS startup by. Well, sorry Andreessen, and sorry Horowitz, but this just isn't right.
        </p><p>
            It's counterintuitive, but it's a statistical fact: This number actually <b>tells you nothing useful about churn</b>,
            but really relates to the age of the subscriptions you have.
            It will in most cases go down on it's own, and, absurdly, the only way to keep it from going down is to have very
            high growth. So the number will literally <b>only look <i>bad</i> if your business is doing extremely <i>well</i></b>,
            and optimizing for it will be directly counter-productive.
            The error here is a simple statistical mistake that is easy to make, and luckily also easy to understand and avoid.
        </p><p>
            If you run a subscription based SaaS business, you're likely very concerned with how long you can keep your
            customers. We're a JavaScript exception tracking service, and the health of this business is fully determined by how many
            customers we bring in, and how long we can keep them. On the surface, <i>churn rate</i> may seem like a natural proxy for changes
            in <i>customer lifetimes</i>. Let's dig into why that is not true.
        </p>
        <h2>
            The false assumption
        </h2>
        <p>
            Computing a churn rate <b>assumes that a customer is equally likely to leave at any time</b>, no matter how long they've
            been subscribed to you. This is almost certainly not true. In fact, as we will see, having a constant churn probability over time
            essentially implies that you'll <i>never have long term customers</i>.
        </p>

        <figure>
            <img src="https://catchjs.com/Blog//images/blog/churn/expon.png" alt="Hazard function (churn) and the implied survival function (from an Exponential distribution)">
            <figcaption>If a user has a constant churn probability over time, this implies that customer lifetimes come from an Exponential distribution.</figcaption>
        </figure>
        <p>
            If you have a constant churn of <code>c</code> per month, the probability that a customer stays subscribed for <code>n</code> months is <code>(1-c)^n</code>. This implies that customer lifetimes come from the <a href="https://en.wikipedia.org/wiki/Geometric_distribution">Geometric distribution</a>. If customers can quit the subscription at any time, we have continuous time and should use the continuous time analogue, the <a href="https://en.wikipedia.org/wiki/Exponential_distribution">Exponential distribution</a>.
        </p>
        <h2>
            What your churn is actually like, with help from K. S. Lomax
        </h2>
        <p>
            The problem is, your customer is not equally likely to cancel their subscription at any time. Most likely, you have a situation where the drop-off in customers is higher in the first few days than it is later. This is even more so if you have a free trial period for your product.
        </p><p>
            If the churn probability gets lower the longer the customer has been subscribed, you could model that as <code>c/(t+1)</code>, where
            <code>t</code> is the timestep (e.g. number of days the customer has been subscribed), and <code>c</code> is some constant.
            In this case, this implies that customer lifetimes comes from a <a href="https://en.wikipedia.org/wiki/Lomax_distribution">Lomax distribution</a>.
            This is equivalent to a Pareto distribution shifted to start at 0.
        </p>
        <figure>
            <img src="https://catchjs.com/Blog//images/blog/churn/lomax.png" alt="Hazard function (churn) and the implied survival function (from a Lomax distribution)">
            <figcaption>The Lomax distribution can express churn probabilities that get lower with time.</figcaption>
        </figure>
        <h2>
            What your churn is actually like, with help from Waloddi Weibull
        </h2>
        <p>
            If you suspect that churn probability per day may <i>increase</i> the longer a user has been subscribed, the Lomax distribution won't
            work for you. Instead you could enlist the help of Swedish statistician Waloddi Weibull.
            The <a href="https://en.wikipedia.org/wiki/Weibull_distribution">Weibull distribution</a> can express both decreasing,
            flat, and increasing probabilities of a customer quitting. This makes it a popular choice for modeling customer lifetimes.
        </p>

        <figure>
            <img src="https://catchjs.com/Blog//images/blog/churn/weibull.png" alt="Hazard function (churn) and the implied survival function (from two Weibull distributions)">
            <figcaption>The Weibull distribution can express both growing and shrinking churn probabilities.</figcaption>
        </figure>

        <h2>
            Optimizing for a falsehood will lead you astray
        </h2>
        <p>
            Now let's see why properly modeling this is important.
        </p><p>
            Let's measure churn the wrong way, and see where it takes us.
            Let's say customer lifetimes come from a Lomax distribution. Let's also say you have a business that is in terrible shape, where
            the number of new sign ups per day is falling by one per day. How will this look on the churn rate? We can simulate it and find out.
        </p>
        <p>
            Keep in mind, in each of the examples below we simulate lifetimes from the same customer lifetime distribution,
            and this distribution <b>does not change</b> over time.
        </p>
        <figure>
            <img src="https://catchjs.com/Blog//images/blog/churn/shrinking_business.png" alt="Shrinking business, churn appears to fall">
            <figcaption>With a shrinking business, churn appears to improve because subscriptions are getting fewer and older.</figcaption>
        </figure>
        <p>
            This is clearly a dying business, yet the churn rate graph is looking great! <b>
                The churn rate per day is falling steadily,
                even if we know that there is no change in customer lifetimes in our model.
            </b>
        </p><p>
            So what's going on? This sharp fall in churn rate is a consequence of the fact that we're not getting new customers.
            Because we're not growing, a bigger share of our customers have been around for a long time, which
            means they're less likely to churn, which means our daily churn graph goes down more than it would otherwise.
            This change on the population level happens despite there being no change in underlying individual customer lifetimes.
        </p><p>
            Let's change this into a scenario where your business is experiencing insane growth. We'll keep the customer lifetimes exactly the same,
            but change it so that the number of new sign ups per day is growing superlinearly.
        </p>
        <figure>
            <img src="https://catchjs.com/Blog//images/blog/churn/growing_business.png" alt="Growing business, churn appears to be flat">
            <figcaption>With a growing business, churn rate appears to not change, only because most subscriptions are new.</figcaption>
        </figure>
        <p>
            Even if the customer lifetimes are unchanged from before, the churn rate graph here is flat. An investor would frown and say
            we're doing nothing to improve how well we retain our customers. In reality, the only reason the graph looks "bad" has nothing to
            do with churn, it is because we're doing insanely well at getting new sign ups.
        </p><p>
            <b>
                If you are steering yourself and your team on the basis of this metric, you're rewarding yourself for stifling growth
                and punishing yourself for growing.
            </b> Obviously, this is 100% counterproductive.
        </p>
        <h2>
            How the h*** do we measure churn then?
        </h2>
        <p>
            As you might have guessed from the previous paragraphs, we should model the <i>distribution of customer lifetimes</i>,
            and we should do it in a <i>statistically sound way</i>. Lomax and Weibull distributions are good choices of model.
        </p><p>
            The part where this gets tricky is that we'll have two types of data: The customers that have quit, and the customers
            that are still subscribed. It's only our ex-customers that give us a total lifetime to work with. For our still-subscribed
            customers, we only know that their subscription has lasted up until now, and we don't know how much longer it will last
            into the future. In statistical lingo, we have what is called <i>right-censored data</i>.
        </p><p>
            Luckily there's a way to use all our data, even from our still-subscribed customers.
        </p>


        <h2>
            Weibull or Lomax?
        </h2>
        <p>
            Choosing between Weibull or Lomax (or any other distribution) has no simple answer. Weibull is more flexible
            in that it can express growing, shrinking and flat churn probabilities. However, this expressive power will
            not help you if your data is fundamentally Lomax-like. First and foremost, base your choice
            on your knowledge of the business that you're in. If you have any prior knowledge about how churn probabilities
            will develop, base your choice of distribution on that. There are also various
            <a href="https://www.weibull.com/hotwire/issue71/relbasics71.htm">goodness of fit</a> tests you could use to
            inform this decision. The truth is, any choice of distribution will be wrong to some degree, so you need to make
            a judgment call as to what fits your situation the best, based both on both your data and your prior knowledge.
            For the purposes of the rest of this post, we'll just fit both distributions and disregard the question of
            which suits us the best.
        </p>

        <h2>
            Let's do some proper statistics
        </h2>
        <p>
            The probability distributions we'll model are defined by their parameters.
            We want to find the parameters that fit the data best. To start, we want to make a guess at these parameters,
            and have a way to tell how good our guess was. Luckily, we have a statistically sound way of knowing how good a guess
            is given the data we have. Extra luckily, this is also true when we have censored data.
            This function that tells us how likely our parameters are given the data we have is called the Likelihood function.
            We get it by looking up the <a href="https://en.wikipedia.org/wiki/Probability_density_function">probability density function</a>
            value for the uncensored data points and the <a href="https://en.wikipedia.org/wiki/Survival_function">survival function</a> value
            for each of the censored data points, and multiplying all these values together.
        </p>
        <figure>
            <img src="https://catchjs.com/Blog//images/blog/churn/likelihood.png" alt="Likelihood formula with right-censored data">
            <figcaption>
                Likelihood function L for right-censored data. <code>f(.)</code> is the probability distribution function, <code>S(.)</code> is the survival function,
                <code>D</code> is the set of uncensored lifetimes and <code>R</code> …</figcaption></figure></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://catchjs.com/Blog/Churn">https://catchjs.com/Blog/Churn</a></em></p>]]>
            </description>
            <link>https://catchjs.com/Blog/Churn</link>
            <guid isPermaLink="false">hacker-news-small-sites-24831637</guid>
            <pubDate>Mon, 19 Oct 2020 22:16:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a computer in Conway's game of life]]>
            </title>
            <description>
<![CDATA[
Score 183 | Comments 55 (<a href="https://news.ycombinator.com/item?id=24831268">thread link</a>) | @ctlachance
<br/>
October 19, 2020 | https://www.nicolasloizeau.com/gol-computer | <a href="https://web.archive.org/web/*/https://www.nicolasloizeau.com/gol-computer">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main" dir="ltr"><section id="h.p_DQq05oqSU0NY"></section><section id="h.p_iiV-AQqiVP7B"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_SXN-ydRPVP6s"><div><div><p id="h.p_iRskbwwxVP67">The purpose of this page is to describe the functioning of a computer built in Conwayâ€™s game of life. An in-detail explanation of all the mechanisms and all the components of the computer would be too long to describe here. Only the fundamental principles and main components are explained here. I think this is enough to permit anyone to recreate a similar computer or reuse it's ideas and components for any other project.</p><p id="h.p_44-lKvosVSR_">The idea here is to illustrate the Turing completeness of game of life with a more impressive example, closer to our computers and easier to program than a basic Turing machine.</p></div></div></div></div></div></div></div></div></div></section><section id="h.p_aGh9TBjrsjnj"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_QecS9arclkic"><div><div><div jscontroller="VYKRW" jsaction="rcuQ6b:rcuQ6b;"><div><iframe jsname="L5Fo6c" sandbox="allow-scripts allow-popups allow-forms allow-same-origin allow-popups-to-escape-sandbox allow-downloads" frameborder="0" aria-label="YouTube Video, Game of life: programmable computer" src="https://www.youtube.com/embed/8unMqSp0bFY" allowfullscreen=""></iframe></div></div></div></div></div></div></div></div></div></div></div></section><section id="h.p_MUkfONu1Vy1J"></section><section id="h.p_Lqr87QKQZ7Ph"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_99zwWdVGZ7PS"><div><div><h2 id="h.p_dZFApvvPZ7Pc" tabindex="-1"></h2><p id="h.p_lvY7r7XEZ7br">The fact that two orthogonal glider beams can annihilate each other or form an eater if they intersect with the good phase shift is used to make basic logic gates.</p><p id="h.p_9XtX79ckZ7bx">This allows us to modify a glider beam with another.</p></div></div></div></div></div></div></div></div></div></section><section id="h.p_odLc-Ig6aUwc"></section><section id="h.p_Xj-uRksRarVA"></section><section id="h.p_xIogGmHYa9ph"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_HG45lQcXbAP1"><div><div><p><img src="https://lh4.googleusercontent.com/017HOv0JY8uXaYR84a6H0FaO1iSeRpT5H-_4o4TmIvJKun9tPWyuV_q3k-4NV9GQVaLFfSYh=w1280" role="img"></p></div></div></div></div></div></div></div><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_hrirjNxUbBgT"><div><div><p><img src="https://lh3.googleusercontent.com/bLC3DY_W824ClQDqg8ixcsy2SumoEvr1OcF6bBzS9CvWCxD279cn9J5poYQegGQoi59NCsNoUw=w1280" role="img"></p></div></div></div></div></div></div></div></div></div></section><section id="h.p_2tgYrbMutYVl"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_k26e1YUKtYVe"><div><div><h2 id="h.p_BF-X_8nVtYVj" tabindex="-1"><div jscontroller="Ae65rd" jsaction="touchstart:UrsOsc; click:KjsqPd; focusout:QZoaZ; mouseover:y0pDld; mouseout:dq0hvd;fv1Rjc:jbFSOd;CrfLRd:SzACGe;"><p>3 Logic gates assembly, adaptators</p></div></h2><p id="h.p__rI_inRGtkdp">The assembly of logic gates is possible only if the glider beams are in phase and if the gap between the beams is right. While making the components out of multiple logic gates, I used the following conventions: </p><p id="h.p_SSA7xz3atkhv">- use a 30*30 grid </p><p id="h.p_W3Uxqe5otkhw">- each glider beam has to match the corners of the grid</p><p id="h.p_xymga8iXtkhw">- main glider beams come from the high left corner.</p></div></div></div></div></div></div></div><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_sRRZp-fXsY3v"><div><div><p><img src="https://lh4.googleusercontent.com/3gN-2pAeGX8SP7RWG0PSzzf_CasdXa2TYJCXaxRgU8-1G2LqooycnW86Epv0snj7lT94m7HWo_yldxhQKMwFSltq403o9DmObwDyY_QNpA6pKwlcvQ=w1280" role="img"></p></div></div></div></div><div><div id="h.p_w97cwfq5s_Mt"><div><p id="h.p_Q5ji4R90s_Mx">According to these rules, these glider beams are well in phase.</p></div></div></div></div></div></div></div></div></section><section id="h.p_p-FkrspwsSxh"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_WGORwOtzsSxU"><div><p id="h.p_YekmpiZjsSxe">A series of 3 reflectors called an adaptator is used to shift the phase or the position of a beam. The folder tools contains two Python scripts to make such adaptators. The scripts <a href="https://www.google.com/url?q=https%3A%2F%2Fgithub.com%2Fnicolasloizeau%2Fgol-computer%2Fblob%2Fmaster%2Ftools%2Fdecamaker.py&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNEiQAlLT1GgHvNvqWM3gTz5xQMI_g" target="_blank">decamaker.py</a> is used to translate horizontally a well phased beam by a multiple of 1 pixel. The script <a href="https://www.google.com/url?q=https%3A%2F%2Fgithub.com%2Fnicolasloizeau%2Fgol-computer%2Fblob%2Fmaster%2Ftools%2Fdelaymaker.py&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNE9PUiQEu2epUYnDRoPrX0fgWPaDA" target="_blank">delamaker.py</a> makes an adaptator of 3 dimensions D1,D2,D3 :</p></div></div></div></div></div></div></div></div></section><section id="h.p_1sZECb-FsY3o"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_lt4ZbqDrs1p4"><div><div><p><img src="https://lh3.googleusercontent.com/8jf8hyO5vRC-LvfnRsEz4Q94tpC0kBM2l5c6dyIuTEzkOLg3p3OqEmdnaOslYSyej3k99f9Wp9Idl11p9y8jKNa4JqzFv13ZfSnF9BeSnSchDsUzuyw=w1280" role="img"></p></div></div></div></div></div></div></div><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_3D7rgWqxsfmY"><div><div><p><img src="https://lh6.googleusercontent.com/SkcwbenO8ZnfkGqFs77cHl1Aq_OBEiuuZeapPRqqdHbzhgJyKr3ugih2a4Mr0rNa7WoSP5xnDQ=w1280" role="img"></p></div></div></div></div></div></div></div></div></div></section><section id="h.p_ameLef-vtZEs"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_lQMVu9K3tZEi"><div><p id="h.p_Tx2PYsK-tZEp">Adaptators are already included at the inputs and outputs of the logic gates from the folder Â« <a href="https://www.google.com/url?q=https%3A%2F%2Fgithub.com%2Fnicolasloizeau%2Fgol-computer%2Ftree%2Fmaster%2Flogic%2520gates&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNHnlKCciw5DxzWOHqg3_ld3X4_aAQ" target="_blank">logic gates</a> Â». All their inputs and outputs are well in phase and it is just required to use the decamaker script to assemble them. I made the main components using these logic gates.</p></div></div></div></div></div></div></div></div></section><section id="h.p_TkFrs9eQb-d1"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_8VsxyFB8b-dY"><div><div><h2 id="h.p_qYGHe3p4b-ds" tabindex="-1"></h2><p id="h.p_XCROTP1VcUCp">The implementation of the logic gates allows the making of any asynchronous logic circuit</p><p id="h.p_gpghndKXcZqN"><em>A,B : inputs</em></p><p id="h.p_BhzuWXcvcZt7"><em>Cin : carry input</em></p><p id="h.p_C9gmXOO9cZt9"><em>Cout : carry output</em></p><p id="h.p_tNXfsgiHcZt-"><em>S : output</em></p><p id="h.p_K2Niv_17cZt_">A ripple-carry-adder can be made by juxtaposing n full adders.</p></div></div></div></div></div></div></div><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_CXtRrYuVcEff"><div><div><p><img src="https://lh5.googleusercontent.com/9xSdEzuU5WByUirbRxJafjDa96WW5JpZRFHsJ1ZklWmJm-CsH6ToZzTxf4ZTpPfg3uktF9QhbDW26UqgpWVRc5ScfUlSr00lGy2VbBIX0o6x7Eb2tvM=w1280" role="img"></p></div></div></div></div></div></div></div></div></div></section><section id="h.p_0PNL2Bjcco5_"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_AkNt6t6cco51"><div><div><h2 id="h.p_UbbR_NuRco57" tabindex="-1"><div jscontroller="Ae65rd" jsaction="touchstart:UrsOsc; click:KjsqPd; focusout:QZoaZ; mouseover:y0pDld; mouseout:dq0hvd;fv1Rjc:jbFSOd;CrfLRd:SzACGe;"><p>5 Arithmetic and logic unit (ALU)</p></div></h2><p id="h.p_Zx_DYURQcs0I">The ALU is composed of some logic functions and a unit which is composed of AND gates that select the result. The inputs are 8 bit each, the instruction is made of 8 independent bits. The instruction flat returns 11111111 if Bâ‰&nbsp;00000000, the instruction sign selects the most significant bit of B. The most significant bit is at the high left corner. The arrow from the select module to the adder represents the increment instruction.</p><p id="h.p_72CXS9I7fG-P">Instruction codes:</p><div><pre id="h.p_APcDULGQetQk"><code>+          00000001</code></pre><pre id="h.p_15CYbaBQetU2"><code>or         00000010</code></pre><pre id="h.p_WAQj6cNVetU6"><code>and        00000100</code></pre><pre id="h.p_venItL9vetU9"><code>xor        00001000</code></pre><pre id="h.p_7164prNZetVA"><code>not        00010000</code></pre><pre id="h.p_FMvwK-hnetVD"><code>flat       00100000</code></pre><pre id="h.p_8DIPmNCeetVF"><code>sign       01000000</code></pre><pre id="h.p_ooyX0MlGe8Yb"><code>increment  10000000</code></pre></div></div></div></div></div><div><div id="h.p_tFHU6M1BeOVn"><div><div><p id="h.p_KI124814eOVv"><em>A, B : inputs</em></p><p id="h.p_-Zlpu12dih6B"><em>I : instruction</em></p><p id="h.p_bcNnihNfiiLt"><em>S : output</em></p></div></div></div></div></div></div></div><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_EuNde33Ndr2H"><div><div><p><img src="https://lh6.googleusercontent.com/rSucmSJBr212gyhalMXekb9xxpyWT41dUBgeZ_3ao83qDY38SdfTwicG38HhRdTZ3zfw7lMe7t2Uku0AongXvj3IdrkccUASCNa0eFkI-SgBhhAtyZs=w1280" role="img"></p></div></div></div></div><div><div id="h.p_5pKa8Ic5eENS"><div><div><p><img src="https://lh6.googleusercontent.com/I_O0zLXDR6tGlqPNsqkj-Gqmzm6364vbdFXUxzbTXKz7xwttuhWYl2Q6mg8T76ajP0dQVH_uibWawaz2--ONdYpJpA06Ofyh8rxMJWNuBJj00TPFeg=w1280" role="img" alt="A, BÂ&nbsp;: inputs IÂ&nbsp;: instruction SÂ&nbsp;: output"></p></div></div></div></div></div></div></div></div></div></section><section id="h.p_jHes96Wtc8fQ"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_BKo62TzUc8fH"><div><div><h2 id="h.p_vYkEPbjvc8fO" tabindex="-1"></h2><h3 id="h.p_RJbO663DhlFw" tabindex="-1"></h3><p id="h.p_J5cxzD94glif">A memory unit is composed of an RS latch and logic gates AND to manage reading and writing tasks. The memory is an assembly of 64 memory units in 8 lines and 8 columns thus forming an 8x8 bytes memory.</p></div></div></div></div><div><div id="h.p_eCvk1p35gonU"><div><div><p id="h.p_P3fNdtgKgonX"><em>W : write 1 if set=1 0 if reset=1</em></p><p id="h.p_dfj4HZr1gptO"><em>R1 : read the state of the memory to the S1 output </em></p><p id="h.p_EMY4WO82gptO"><em>R1 : read the state of the memory to the S2 output</em> </p></div></div></div></div></div></div></div><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_GQ_D4n5jhHfp"><div><div><p><img src="https://lh6.googleusercontent.com/7sArTXbRzfPPs8i8MmJWMDtPhV8d2yAV8L3MK8lII6torRlHsu04AMoG63-MQ2sOkrEuvB4RZT0lgJRfFa8T4wBsQaXpvm9dmBxNBdndzdDWSTYvM_aT=w1280" role="img"></p></div></div></div></div></div></div></div><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_EaOInrvcfyFS"><div><div><p><img src="https://lh3.googleusercontent.com/guKgoLB2I_bFr-al4BarEZNNscVSlaJeBgi28u_DVGh6i2OeThw8v5JdK8pl_Uw6584Ophb_8T56v5lP2cAe_Giz4-8ITDbgpgU8ZJrteFxqYmaNSCY=w1280" role="img"></p></div></div></div></div></div></div></div></div></div></section><section id="h.p_KUUiaKkXhrud"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_Fxjpj-lqhruZ"><div><div><h3 id="h.p_O689rlGChrub" tabindex="-1"></h3><p id="h.p_9JPre3onht49">The 3 modules at the left of the memory are decoders from 3 bit to 8 for decoding addresses. This memory allows us to read data from two addresses a1 and a2 at the same time. The output is made of 16 bit alternated between S1 and S2.</p><p id="h.p_LCsn7eBkh9rP"><em>A : data to write, 1 byte </em></p><p id="h.p_fHO0POG9h-BA"><em>a0 : address for writing, 3 bits</em></p><p id="h.p_ltfqpzgNh-BB"><em>a1 : address for reading, 3 bits</em></p><p id="h.p_WjJwr5Muh-BB"><em>a2 : address for reading, 3 bits</em></p><p id="h.p_nH4jURGYh-BC"><em>S : output, 2 bytes </em></p><p id="h.p_3jfHFLL-h-BC"><em>W : writes A to address a0 if W=1</em></p></div></div></div></div></div></div></div><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_OJ8hOGCiguUw"><div><div><p><img src="https://lh4.googleusercontent.com/YqFSaDul50zhDj2yHdvjICzCxwKdRbWsUlQEbgv88he8zt8YSFjIkF5_hRKHW6QXbWNDLdKROo2NzjHCiU3KBmkav9FJWgneuqIqDkXWQw0f-prDTo0=w1280" role="img"></p></div></div></div></div></div></div></div></div></div></section><section id="h.p_xrHTkqo4dAQk"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_Z3g-lThLdAQd"><div><div><h2 id="h.p_E1XIJpRSdAQi" tabindex="-1"></h2><p id="h.p_Gfx0enzfi2bC">The program is of a static memory form. The big rectangular module is a decoder from 5 bit to 32 which is used to select a line of the program given the input address. </p><p id="h.p_lVjX0pHCi2fB">Each line is made of 21 bits distributed as follow from the high right corner:</p><p id="h.p_5YBVlSYLi2fC">- 8 bits for data</p><p id="h.p_kqeXBpHei2fC">- 3 bits for reading address</p><p id="h.p_gcYz7S9ui2fD">- 3 bits for reading address</p><p id="h.p_iI6szhGYi2fD">- 3 bits for writing address</p><p id="h.p_RbF8D0CFi2fD">The script <a href="https://www.google.com/url?q=https%3A%2F%2Fgithub.com%2Fnicolasloizeau%2Fgol-computer%2Fblob%2Fmaster%2Fassembly.py&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNEvSddxq7Y0FTnkWZJkBLqGTDnspw" target="_blank">assembly.py</a> contains more information on computer programming.</p><p id="h.p_idxG0XgBi2fE"><em>A : address of the line to be read: 5 bits</em></p><p id="h.p_OOX77ZdYjPJ_"><em>S : output: 21 bits</em></p></div></div></div></div></div></div></div><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_zozhh_nnjE17"><div><div><p><img src="https://lh6.googleusercontent.com/B00AVKqF9QvB7OV5hKPBQ6nVrhyPG34EsgUTdWRibAhOrL72KxUxuesLbaYmafZuLwUj6l53JexQ5TI05R5QhEDZTAtSgjbWQ0kOtZcjh_2JSAoR0W4=w1280" role="img"></p></div></div></div></div></div></div></div></div></div></section><section id="h.p__hCJiXtvjdpP"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_hqpO9gy2jdpM"><div><div><h2 id="h.p_797YSJ2BjdpO" tabindex="-1"></h2><p id="h.p_WmzCYEQBlNzw">Diagram of the computer architecture. Only the main information channels are represented. The module â€œlineâ€� is a 5 bit memory for writing the address of the line which is running (PC). The module â€œcontrolâ€� is principally a decoder which takes as input an instruction code of 4 bits, decodes it into 16 independent bits and communicates with all the other modules to execute the instruction.</p><p id="h.p_XcW1bSfulN46">Elements which are not represented in this diagram:</p><p id="h.p_N3qxDVHFlN46">- the control channels from the control module to other modules</p><p id="h.p_ZhFjawdelN47">- the clock</p><p id="h.p_39_5GK1ilN47">- the control channels from the clock to the other modules</p><p id="h.p_wEaE1tRJlN48"><em>Color code:</em></p><p id="h.p_6wdWXJ6slN48"><em>Green: 8bit data bus </em></p><p id="h.p_DYEi5V_dlN49"><em>Red: 3bits address</em></p><p id="h.p_dN0UhRcmlN49"><em>Yellow: 4bits instruction</em></p><p id="h.p_nF0hM-LnlN4-"><em>Pink: 5bits address</em></p></div></div></div></div></div></div></div><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_M3Aa7YeslFnO"><div><div><p><img src="https://lh3.googleusercontent.com/k2tw3DDuvi0cPr4gsuXtZAVUXzczJXlaXYm3faN1frBOnRae-CZQPiosUDCZq4lJ9uZOqdiChD2fBGrzYUM4kM30CfNYKoPJDsVnJMl_W9K77hGluVqe=w1280" role="img"></p></div></div></div></div></div></div></div></div></div></section><section id="h.p_iatMj5Mom9_B"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_XJCPKyEwoEID"><div><div><h2 id="h.p_0xltGO10oEIG" tabindex="-1"><div jscontroller="Ae65rd" jsaction="touchstart:UrsOsc; click:KjsqPd; focusout:QZoaZ; mouseover:y0pDld; mouseout:dq0hvd;fv1Rjc:jbFSOd;CrfLRd:SzACGe;"><p>9 Detail of a clock cycle</p></div></h2><p id="h.p_akxX-ZM1oGgX">The clock is constituted of 4 loops, formed by glider reflectors in which glider beams rotate. In each loop, a glider duplicator is placed on the glider beam path. This makes it possible to extract the signal from the clock. The 4 loops give rhythm to: the execution of an instruction, the writing in the memory, the incrementation of PC, the writing of PC in the memory.</p><p id="h.p_t1CmuX1joGin">PC is stored in memory at address 000, however, it is needed to read it all along the execution of an instruction. It is therefore copied into the Line module on each cycle. The following table summarizes a clock cycle.</p></div></div></div></div><div><div id="h.p_JVam50uBm9-3"><div><div><div><pre id="h.p_l5Bvpg0xm9--"><code><strong>Generation  Clock loop  Signal edge  Action</strong></code></pre><pre id="h.p__2oUC2gPn53Z"><br></pre><pre id="h.p_6ZQ7UNDLm-Mp"><code>0           0           Rising       Reading of an instruction, </code></pre><pre id="h.p_Sv1HYSQtnsKA"><code>                                     execution of it by the ALU without writing on the memory</code></pre><pre id="h.p_YK3_r7RHm-Mr"><code>590 000     1           Rising       Writing of the ALUâ€™s output on the memory</code></pre><pre id="h.p_tfhVMyQYm-Mu"><code>650 000     1           Falling      End of the writing on the memory</code></pre><pre id="h.p_ygXdUEOXm-Mx"><code>860 000     0           Falling      End of the reading of the instruction</code></pre><pre id="h.p_RlwORZMom-My"><code>1 100 000   2           Rising       Reading PC from address 000 to the ALU for incrementation </code></pre><pre id="h.p_VjI3TS5Hny6C"><code>                                     Copy of PC from 000 to the Line module</code></pre><pre id="h.p_SEdE98RKm-M1"><code>1 440 000   3           Rising       Writing of the ALUâ€™s output (PC+1) to the address 000</code></pre><pre id="h.p_omeA5Huam-M3"><code>1 480 000   3           Falling      End of the writing of PC+1 to the address 000</code></pre><pre id="h.p_vAI6RZ7om-M5"><code>1 600 000   2           Falling      End of reading from the address 000 and end of copying from 000 to the Line module </code></pre><pre id="h.p_D181OqNhn33k"><code>                                     At this time, PC+1 is written at 000 and on the module Line</code></pre></div></div></div></div></div><div><div id="h.p_6uVtrglpoOly"><div><div><p id="h.p_H3AbL1XZoOl0">The column â€œclock loopâ€� gives he position of the clock loop which generates the signal. The index rises from the high left corner. Generation gives the time at which the signal leaves the clock loop. Each cycle is made of two parts: the execution of the instruction (loops 0 and 1) ant the incrementation of PC (loops 2 and 3). Each cycle has a period of 2,003,880 generations.</p></div></div></div></div></div></div></div></div></div></section><section id="h.p__7h5dMoWoWOG"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.p_E5Cu7xouoWOE"><div><div><h2 id="h.p_eiDdjwjWoWOG" tabindex="-1"></h2><p id="h.p_ZfBRIcwDoZn9">The Golly Python script <a href="https://www.google.com/url?q=https%3A%2F%2Fgithub.com%2Fnicolasloizeau%2Fgol-computer%2Fblob%2Fmaster%2Fassembly.py&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNEvSddxq7Y0FTnkWZJkBLqGTDnspw" target="_blank">assembly.py</a> helps to program the computer. 8 variables can be used: a,b,c,d,e,f,g,h. h is at the address 000 and is used for storing PC.</p><div><pre id="h.p_ar30iTXdo1HX"><code><strong>Instruction    Effect</strong></code></pre><pre id="h.p_VXWYwsQ8o1Mz"><code>write a n      Write the number n in to the variable a</code></pre><pre id="h.p_nUD9ePRPo1M0"><code>goto n         Go to line n</code></pre><pre id="h.p_q0l3SJwCo1M1"><code>move a b       b=a</code></pre><pre id="h.p_EZ1mwWONo1M1"><code>jumpif a       Jump the next line if a!=0</code></pre><pre id="h.p_l-rCsKzpo1M2"><code>print a        Display a</code></pre><pre id="h.p_CBxpEJLKo1M3"><code>add a b c      c=a+b</code></pre><pre id="h.p_bfag-7ZAo1M4"><code>or a b c       c=(a or b)</code></pre><pre id="h.p__Fy1TYwTo1M5"><code>and a b c      c=(a and b)</code></pre><pre id="h.p_OQcg0eRIo1M6"><code>xor a b c      c=(a xor b)</code></pre><pre id="h.p_HVXrkzoho1M7"><code>not a b        b=not(a)</code></pre><pre id="h.p_B7QjGUiqo1M8"><code>flat a b       B=0 if a=0 ; b=11111111 else</code></pre><pre id="h.p_LZxRjcG6o1M9"><code>sign a b       Write the most significant bit of a to b </code></pre><pre id="h.p_k7oiaST4pLkr"><code>               (sign of a if a is written in 2â€™s complement)</code></pre><pre id="h.p_Tc9FaJOxo1M9"><code>increment a    a=a+1</code></pre><pre id="h.p_JTRSCPpEpftU"><br></pre></div><h3 id="h.p_0RIdrgYYqaDF" tabindex="-1"></h3><div><pre id="h.p_1k_9G6N4pgFC"><code><strong>Display a modulo b</strong></code></pre><pre id="h.p_UqV_FtofqYtT"><br></pre><pre id="h.p_PRhE8OwXqVsj"><code><strong>Line    Instruction    Pseudo-code</strong></code></pre><pre id="h.p_CGA2uabjpgFD"><code>0       write a 8      a = 8 </code></pre><pre id="h.p_lpw-3PODpgFF"><code>1       write b 3      b = 3 </code></pre><pre id="h.p_Ry8dLB3ZpgFG"><code>2       write e 1      d = -b</code></pre><pre id="h.p_LEkpXlKIpgFH"><code>3       not b d         |</code></pre><pre id="h.p_hwAKdadSpgFJ"><code>4       add d e d       |</code></pre><pre id="h.p_ijNnpg8YpgFK"><code>5       add a d a      a = a+d</code></pre><pre id="h.p_k402xubXpgFL"><code>6       sign a c       if a&gt;=0</code></pre><pre id="h.p_XAH8PlHfpgFO"><code>7       jumpif c        |</code></pre><pre id="h.p_6OVX0K86pgFP"><code>8       goto 5         go to line 5</code></pre><pre id="h.p_muhLQdv9pgFQ"><code>9       add a b        a a = a+b</code></pre><pre id="h.p_p_F6YavnpgFS"><code>10      print a        print a</code></pre><pre id="h.p_Pke5SZqQpgFT"><code>11      goto 11        end</code></pre></div><div><pre id="h.p_nD1hHtITrogs"><code><strong>Display GCD(a,b) (Euclid's algorithm)</strong></code></pre><pre id="h.p_lxqiep7_ronV"><br></pre><pre id="h.p_gMCLSmrlronW"><code><strong>Line    Instruction    Pseudo-code</strong></code></pre><pre id="h.p_UoKuhjHPronW"><code>0       write a 8      a = 8 </code></pre><pre id="h.p_UfmcCRBRronX"><code>1       write b 6      b = 6</code></pre><pre id="h.p_JpIQn7o3ronX"><code>2       write e 1      c = a modulo b</code></pre><pre id="h.p_11Xpy03cronY"><code>3       not b d           |</code></pre><pre id="h.p_sTpDaV1JronY"><code>4       add d e d         |</code></pre><pre id="h.p_RL8BEDFeronZ"><code>5       add a d a         |</code></pre><pre id="h.p_OFwIDDuoronZ"><code>6       sign a f          | </code></pre><pre id="h.p_akSliUkOronZ"><code>7       jumpif f          |</code></pre><pre id="h.p_vM6j-KkMrona"><code>8       goto 5            |</code></pre><pre id="h.p_aIlt3SfRrona"><code>9       add a b c         |</code></pre><pre id="h.p_zlehb0Moronb"><code>10      jumpif c       if c = 0</code></pre><pre id="h.p_LoCcUlePronb"><code>11      goto 15        go to line 15</code></pre><pre id="h.p_lULgjjRzronc"><code>12      move b a       a = b</code></pre><pre id="h.p_ONpwMA9sronc"><code>13      move c b       b = c</code></pre><pre id="h.p_erU6mkLGrond"><code>14      goto 3         go to line 3</code></pre><pre id="h.p_GdClsddMrond"><code>15      print b        print b</code></pre><pre id="h.p_84t--rPSrone"><code>16      goto 16        end</code></pre></div></div></div></div></div></div></div></div></div></div></section></div></div>]]>
            </description>
            <link>https://www.nicolasloizeau.com/gol-computer</link>
            <guid isPermaLink="false">hacker-news-small-sites-24831268</guid>
            <pubDate>Mon, 19 Oct 2020 21:33:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Turing Pi 2 – a compact ARM cluster with 32 GB RAM]]>
            </title>
            <description>
<![CDATA[
Score 95 | Comments 55 (<a href="https://news.ycombinator.com/item?id=24829768">thread link</a>) | @nsky-world
<br/>
October 19, 2020 | https://turingpi.com/turing-pi-2/ | <a href="https://web.archive.org/web/*/https://turingpi.com/turing-pi-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><p><strong>32 GB</strong> <span>of RAM</span></p><p><strong>SATA III</strong> <span>interface</span></p><p><strong>CM4</strong> <span>support</span></p></div></div><p><img src="https://turingpi.com/wp-content/themes/turing/assets/img/turing-2/hero-3.png" data-src="https://turingpi.com/wp-content/themes/turing/assets/img/turing-2/hero-3.png" alt=""></p></div></div></section><section><div><div><div><h3> Reliable, scalable, cloud-native infrastructure for the edge</h3><p> Turing Pi is a compact ARM cluster that provides a secure and scalable compute in the edge. It is designed to make web-scale edge computing easier for developers. Turing Pi cluster architecture allows you to migrate and sync web apps with minimal friction. It provides you with complete control of the edge infrastructure and improves reliability.</p></div><div><div><div><p><img src="data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E" data-src="https://turingpi.com/wp-content/uploads/2020/10/1.svg" alt="Layer 2 Managed Switch"></p><p> Layer 2 Managed Switch</p></div><div><p><img src="data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E" data-src="https://turingpi.com/wp-content/uploads/2020/10/2.svg" alt="2 x Mini PCI Express"></p><p> 2 x Mini PCI Express</p></div><div><p><img src="data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E" data-src="https://turingpi.com/wp-content/uploads/2020/10/3.svg" alt="2 x SATA III 6 Gbps"></p><p> 2 x SATA III 6 Gbps</p></div></div><div><div><p><img src="data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E" data-src="https://turingpi.com/wp-content/uploads/2020/10/4.svg" alt="12 Gbps Backplane Bandwidth"></p><p> 12 Gbps Backplane Bandwidth</p></div><div><p><img src="data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E" data-src="https://turingpi.com/wp-content/uploads/2020/10/5.svg" alt="Cluster Management Bus (I2C)"></p><p> Cluster Management Bus (I2C)</p></div><div><p><img src="data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E" data-src="https://turingpi.com/wp-content/uploads/2020/10/6.svg" alt="VLAN Support"></p><p> VLAN Support</p></div></div></div></div></div></section><section><div><h3> Use Cases</h3><div><div><div><p>Self-hosted</p><p>Host cloud applications locally or at the edge</p></div><div><p>Learning</p><p>Learn Kubernetes, Docker, Serverless</p></div><div><p>Development</p><p>Build cloud-native and CI/CD for ARM edge infrastructure</p></div><div><p>Network-Attached Storage</p><p>Connect up to 2 x 2.5″ SSD storage</p></div></div></div></div></section><div><p><img width="804" height="872" src="https://turingpi.com/wp-content/uploads/2020/10/scheme.png" data-src="https://turingpi.com/wp-content/uploads/2020/10/scheme.png" alt="" data-srcset="https://turingpi.com/wp-content/uploads/2020/10/scheme.png 804w, https://turingpi.com/wp-content/uploads/2020/10/scheme-277x300.png 277w, https://turingpi.com/wp-content/uploads/2020/10/scheme-768x833.png 768w, https://turingpi.com/wp-content/uploads/2020/10/scheme-600x651.png 600w" data-sizes="(max-width: 804px) 100vw, 804px" srcset="https://turingpi.com/wp-content/uploads/2020/10/scheme.png 804w, https://turingpi.com/wp-content/uploads/2020/10/scheme-277x300.png 277w, https://turingpi.com/wp-content/uploads/2020/10/scheme-768x833.png 768w, https://turingpi.com/wp-content/uploads/2020/10/scheme-600x651.png 600w"></p></div><section></section><section></section><div id="modal-success"><div><h3>Check your inbox!</h3><p> You should receive a confirmation email soon</p> </div></div><div id="modal-error"><div><h3>Error</h3><p>Contact already exist</p> </div></div></div></div>]]>
            </description>
            <link>https://turingpi.com/turing-pi-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24829768</guid>
            <pubDate>Mon, 19 Oct 2020 19:11:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Discord Won]]>
            </title>
            <description>
<![CDATA[
Score 523 | Comments 522 (<a href="https://news.ycombinator.com/item?id=24829635">thread link</a>) | @ivanagas
<br/>
October 19, 2020 | https://ianvanagas.com/2020/10/19/how-discord-won/ | <a href="https://web.archive.org/web/*/https://ianvanagas.com/2020/10/19/how-discord-won/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-478">

	

	
			<figure>
				<img width="1280" height="720" src="https://ianvanagas.files.wordpress.com/2020/10/kingdiscord.jpeg?w=1280" alt="" loading="lazy" srcset="https://ianvanagas.files.wordpress.com/2020/10/kingdiscord.jpeg 1280w, https://ianvanagas.files.wordpress.com/2020/10/kingdiscord.jpeg?w=150 150w, https://ianvanagas.files.wordpress.com/2020/10/kingdiscord.jpeg?w=300 300w, https://ianvanagas.files.wordpress.com/2020/10/kingdiscord.jpeg?w=768 768w, https://ianvanagas.files.wordpress.com/2020/10/kingdiscord.jpeg?w=1024 1024w" sizes="(max-width: 1280px) 100vw, 1280px" data-attachment-id="494" data-permalink="https://ianvanagas.com/2020/10/19/how-discord-won/kingdiscord/" data-orig-file="https://ianvanagas.files.wordpress.com/2020/10/kingdiscord.jpeg" data-orig-size="1280,720" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="KingDiscord" data-image-description="" data-medium-file="https://ianvanagas.files.wordpress.com/2020/10/kingdiscord.jpeg?w=300" data-large-file="https://ianvanagas.files.wordpress.com/2020/10/kingdiscord.jpeg?w=750">			</figure><!-- .post-thumbnail -->

		
	<div>
		
<p>It has been a big year for realizing the limits of technology for interacting with people. Gamers have known this for a long time. Lag, disconnections, and coordination issues were problems in gaming since the start. There is a platform that has gone a long way in solving those problems: Discord.</p>



<p>Discord allows people to talk and chat online. Servers are created by anybody to talk about anything, usually, it is a friend group or a shared interest. They contain chat channels (kind of like Slack) and voice channels that are always on and allow people to join and leave whenever they want.</p>



<p>The competition between internet communication platforms is fierce. Discord wasn’t early to voice channels or group chats. They weren’t unique for targeting their offering to gamers. Other platforms have the same features as them. Yet they are a multi-billion dollar business. How? To borrow an idea from <a rel="noreferrer noopener" href="https://medium.com/@sarahtavel/how-to-build-an-enduring-multi-billion-dollar-business-hint-create-a-10x-product-recast-3527df2b8fcb" target="_blank">Sarah Tavel</a>, they built a 10x better product AND capture more value from it.</p>



<h2>10x Better</h2>



<p>Voice chat sucked for a long time. Skype, which was long the most popular option, was a mess. It forced you to call people. Servers went down often. The application crashed. Chats were all over the place. There is a good reason people do not use Skype and it is because it sucks.</p>



<p>There were other competitors like IRC, TeamSpeak, Mumble, Ventrilo. All had basically the same features, voice calls, and chat. Each suffered from a combination of problems like:</p>



<ul><li>Complicated setup process. Any new member must also go through a setup process.</li><li>Paid hosting. No one wanted to pay when there were free options. Especially true as servers grow.</li><li>Unclear benefits. Convincing one person was not enough, you needed to convince your whole group of the benefits of switching.</li><li>Weird ideological reasons. Your platform was your tribal affiliation, switching means abandoning your tribe. Everyone looked down on people who didn’t use the same platform as them (even if it was jokingly).</li></ul>



<p>Discord launched in May 2015, long after the competitors listed above. They are now more successful than those same competitors. They did so by making the experience 10x better:</p>



<ul><li>Discord requires nearly no setup. Starting a server on Discord takes two clicks. Creating channels is two clicks. It works instantly and all the time.</li><li>Discord is free.</li><li>It is easy to switch to Discord. Inviting people is two clicks and a paste. Joining a server (once you have an account) is two clicks. It is so simple you don’t even think about it.</li><li>Non-core features like emoji support, reactions, bots, integrations, video calls, and screen-sharing all work as well as you could ask.</li><li>Big community servers for games, fanbases, organizations, hobbies, and more.</li></ul>



<p>Improvements in each of these areas add up to a 10x better experience than other platforms. I complain about Discord way less than I complain about Skype. There are benefits for everyone on Discord, which makes it a 10x experience both for groups and individuals.</p>



<p>On top of being 10x better, the core features are free. This causes an obvious business problem, how do you make money? There isn’t an obvious place to put ads. Competitors often charge by the member, but that incentivizes against growth. Discord figured out a way to incentivize growth while capturing value from large and small groups. </p>



<h2>Sell Status to Capture Value</h2>



<p>It took Discord a long time to figure out monetization (and they still are figuring it out). Venture capital allowed them to experiment with ideas such as selling games and membership. Neither worked perfectly, but they pointed in the right direction. <a rel="noreferrer noopener" href="https://www.forbes.com/sites/abrambrown/2020/06/30/discord-was-once-the-alt-rights-favorite-chat-app-now-its-gone-mainstream-and-scored-a-new-35-billion-valuation/#article-0-topx-1:~:text=Discord%20is%20on%20track%20to%20top,Discord%20groups%20that%20they%20belong%20to." target="_blank">Forbes estimated</a> they are “on track to top $120 million in sales this year (2020)… up from around $70 million last year.”</p>



<p>To understand Discord’s monetization, look at their history. The founders previously started game companies and were <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Discord_(software)#cite_ref-vb_2015_funding_9-0:~:text=%5D%20Their%20first%20product%20was%20Fates,and%20based%20on%20more%20modern%20technology.%5B" target="_blank">inspired by free-to-play games like League of Legends.</a> Games like League of Legends sell status. It is free-to-play but you can buy “skins” to make your character look different. If you have a cool or expensive skin, it means you care more about the game. It raises your status. Discord does the same.</p>



<p>Discord allows users to raise their status through a subscription called Nitro. It provides quality improvements (file size and video quality), special profile upgrades (more emojis, animated profile photos, custom tags), and most importantly, the ability to “boost” a server.</p>



<p>Boosts raise a user’s status in both small and large servers. They allow you to either improve your friend’s online hangout and your communities’ experience by unlocking custom emotes, cosmetic features, and quality improvements. For users, it puts an icon next to their name saying they contribute and gives them a special booster role on the server. In short, it is a way for someone to pay to stand out.</p>



<figure><img data-attachment-id="493" data-permalink="https://ianvanagas.com/serverboosts/" data-orig-file="https://ianvanagas.files.wordpress.com/2020/10/serverboosts.png" data-orig-size="1163,333" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="serverboosts" data-image-description="" data-medium-file="https://ianvanagas.files.wordpress.com/2020/10/serverboosts.png?w=300" data-large-file="https://ianvanagas.files.wordpress.com/2020/10/serverboosts.png?w=750" src="https://ianvanagas.files.wordpress.com/2020/10/serverboosts.png?w=1024" alt="" srcset="https://ianvanagas.files.wordpress.com/2020/10/serverboosts.png?w=1024 1024w, https://ianvanagas.files.wordpress.com/2020/10/serverboosts.png?w=150 150w, https://ianvanagas.files.wordpress.com/2020/10/serverboosts.png?w=300 300w, https://ianvanagas.files.wordpress.com/2020/10/serverboosts.png?w=768 768w, https://ianvanagas.files.wordpress.com/2020/10/serverboosts.png 1163w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Server Boost Perks</figcaption></figure>



<p>You can buy boosts separately from Nitro at $5 per month or $50 per year. Perks come in uneven tiers: Level 1 is 2 boosts, Level 2 is 15 boosts, Level 3 is 30 boosts. It is unlikely “friend group sized” servers get past two boosts, but large servers often pass thirty. Some examples:</p>



<figure><table><thead><tr><th data-align="left">Name</th><th data-align="left">Boosts</th><th data-align="left">MRR (@ $5 per boost)</th></tr></thead><tbody><tr><td data-align="left">Minecraft</td><td data-align="left">165</td><td data-align="left">$825</td></tr><tr><td data-align="left">Kanye</td><td data-align="left">75</td><td data-align="left">$375</td></tr><tr><td data-align="left">Fortnite</td><td data-align="left">165</td><td data-align="left">$825</td></tr><tr><td data-align="left">r/LeagueOfLegends</td><td data-align="left">201</td><td data-align="left">$1005</td></tr><tr><td data-align="left">Animal Crossing: New Horizons</td><td data-align="left">412</td><td data-align="left">$2060</td></tr><tr><td data-align="left">r/Overwatch</td><td data-align="left">85</td><td data-align="left">$425</td></tr><tr><td data-align="left">Rocket League</td><td data-align="left">116</td><td data-align="left">$580</td></tr><tr><td data-align="left">Fall Guys</td><td data-align="left">215</td><td data-align="left">$1075</td></tr><tr><td data-align="left">Anime Soul Discord</td><td data-align="left">323</td><td data-align="left">$1615</td></tr><tr><td data-align="left">Kenny Beats</td><td data-align="left">50</td><td data-align="left">$250</td></tr><tr><td data-align="left">Musicians (Turkish)</td><td data-align="left">730</td><td data-align="left">$3650</td></tr><tr><td data-align="left">English</td><td data-align="left">94</td><td data-align="left">$470</td></tr><tr><td data-align="left">Python</td><td data-align="left">44</td><td data-align="left">$220</td></tr><tr><td data-align="left">CallMeCarson Discord Cult</td><td data-align="left">1153</td><td data-align="left">$5765</td></tr></tbody></table></figure>



<p>Here are 14 popular servers accounting for nearly $250,000 in revenue per year. There are tons more, all with varying amounts of boosts. People are willing to pay to stand out, even when there is no obvious benefit. This is universal.</p>



<p>Every community needs a place to communicate online. Discord has the best offering, and it is free. Other platforms either force you to pay by the member or have a flat rate paid by the community host. Discord doesn’t require either. Servers can grow as large as they want for free, moderators and admins don’t have to pay, and Discord still makes money.</p>



<p>As communities continue to grow on Discord, the money Discord makes from those communities goes up as well. Flat rates and tiers limit this. Communities want to grow, Discord provides them with an easy and effective way to do that. Users want status, Discord gives them a shortcut. This aligns incentives better than advertising or paid memberships do.</p>



<hr>



<p>Discord won by building 10x better spaces for communities. By selling status, they have also managed to capture more value from those communities than other platforms.</p>



<p>Discord won the competition for the gaming chat platform of choice, and now it wants to be the platform for all internet communities. This means they will be competing with the “big dogs” like Slack, Reddit, Twitter, Facebook, Microsoft, and Epic. Their free-to-play, pay-for-status monetization model is a competitive advantage.</p>



<p>Discord is a successful company. The question becomes how successful can they become? The key is the number of internet communities who choose Discord as their home. By creating a better product than competitors and being free for growth, Discord puts itself in an excellent position to continue to succeed moving forward.</p>



<p>Follow me <a rel="noreferrer noopener" href="http://twitter.com/ianvanagas/" target="_blank"><strong>on Twitter</strong></a> or sign up for <a rel="noreferrer noopener" href="https://adept-teacher-7152.ck.page/55b2205587" target="_blank"><strong>my monthly newsletter</strong></a>.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://ianvanagas.com/2020/10/19/how-discord-won/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24829635</guid>
            <pubDate>Mon, 19 Oct 2020 18:56:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Better Git diff output for Ruby, Python, Elixir, Go]]>
            </title>
            <description>
<![CDATA[
Score 278 | Comments 48 (<a href="https://news.ycombinator.com/item?id=24828509">thread link</a>) | @Lammy
<br/>
October 19, 2020 | https://tekin.co.uk/2020/10/better-git-diff-output-for-ruby-python-elixir-and-more | <a href="https://web.archive.org/web/*/https://tekin.co.uk/2020/10/better-git-diff-output-for-ruby-python-elixir-and-more">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <p>The regular Git users amongst you will be familiar with the diff output that breaks down into “hunks” like so:</p>

<div><div><pre><code><span>@@ -24,7 +24,7 @@</span> class TicketPdf
     ApplicationController.render(
       "tickets/index.html.haml",
       layout: "tickets",
<span>-      assigns: { tickets: tickets }
</span><span>+      assigns: { tickets: tickets, event_name: event_name }
</span>     )
   end
</code></pre></div></div>

<p>The first line (starting <code>@@</code>) is known as the hunk header, and is there to help orientate the change. It gives us the line numbers for the change (the numbers between the <code>@@..@@</code>), but also a textual description for the enclosing context where the change happened, in this example <code>"class TicketPdf"</code>. Git tries to figure out this enclosing context, whether it’s a function, module or class definition. For C-like languages it’s pretty good at this. But for the Ruby example above it’s failed to show us the immediate context, which is actually a method called <code>tickets_as_html</code>. That’s because out of the box Git isn’t able to recognise the Ruby syntax for a method definition, which would be <code>def ticket_as_html</code>.</p>

<p>What would be more useful is to see:</p>

<div><div><pre><code><span>@@ -24,7 +24,7 @@</span> def tickets_as_html
     ApplicationController.render(
       "tickets/index.html.haml",
       layout: "tickets",
<span>-      assigns: { tickets: tickets }
</span><span>+      assigns: { tickets: tickets, event_name: event_name }
</span>     )
   end
</code></pre></div></div>

<p>And it’s not just Ruby where Git struggles to figure out the correct enclosing context. Many other programming languages and file formats also get short-changed when it comes to the hunk header context.</p>

<p>Thankfully, it’s not only possible to configure a custom regex specific to your language to help Git better orient itself, there’s even a pre-defined set of <a href="https://github.com/git/git/blob/master/userdiff.c">patterns for many languages and formats right there in Git</a>. All we have to do is tell Git which patterns to use for our file extensions.</p>

<p>We can do this by defining a <a href="https://git-scm.com/docs/gitattributes"><code>.gitattributes</code></a> file inside our repo that maps the Ruby file extensions to the diff pattern for Ruby:</p>

<div><div><pre><code><span>*</span>.rb <span>diff</span><span>=</span>ruby
<span>*</span>.rake <span>diff</span><span>=</span>ruby
</code></pre></div></div>

<p>Some open source projects define their own <code>.gitattributes</code> file. There’s <a href="https://github.com/rails/rails/blob/master/.gitattributes">one in Rails</a>. There’s even <a href="https://github.com/git/git/blob/master/.gitattributes">one in the Git source</a> that enables the diff patterns for Perl and Python.</p>

<h2 id="configure-a-global-gitattributes-file">Configure a global .gitattributes file</h2>

<p>Instead of adding a <code>.gitattributes</code> file to every repo we can configure a global <code>.gitattributes</code> file. Just create a <code>.gitattributes</code> file in your home directory, fill it with all the file formats you are interested in and point Git at it:</p>

<pre><code>  <strong>$ git config --global core.attributesfile ~/.gitattributes</strong>
</code></pre>

<p>I’ve put together an <a href="https://gist.github.com/tekin/12500956bd56784728e490d8cef9cb81">example .gitattributes file</a> with some common file formats to get you started.</p>

<p>I have no idea why Git doesn’t have these file format patterns configured by default. Thanks to Tom whose <a href="https://twitter.com/tomstuart/status/1304401459069452290">exasperated tweet</a> brought this non-obvious feature to my attention.</p>


  </section></div>]]>
            </description>
            <link>https://tekin.co.uk/2020/10/better-git-diff-output-for-ruby-python-elixir-and-more</link>
            <guid isPermaLink="false">hacker-news-small-sites-24828509</guid>
            <pubDate>Mon, 19 Oct 2020 17:16:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Many of the root certificates on Windows are not needed]]>
            </title>
            <description>
<![CDATA[
Score 247 | Comments 109 (<a href="https://news.ycombinator.com/item?id=24827509">thread link</a>) | @svenfaw
<br/>
October 19, 2020 | https://hexatomium.github.io/2020/10/17/001.html | <a href="https://web.archive.org/web/*/https://hexatomium.github.io/2020/10/17/001.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>As of today, Windows trusts 322 root certificates issued by 122 different organizations from 47 countries. This number is quite high, and has been steadily growing over the last few years. And it turns out many of those certificates are not needed at all by the vast majority of Windows users, can be distrusted with no ill effects of any sort.</p>

<p>Each of these CAs is given tremendous power over your Internet traffic, so it makes great sense to minimize the number of CAs your computer trusts. 
One simple way to achieve this goal is to replace the default Windows list of root CAs with the much stricter Mozilla trust list, which includes 142 roots (52 organizations - 21 countries). An even stricter option is using the Google CTL, which currently includes just 127 root certificates (48 organizations - 21 countries). For the vast majority of users, applying either set is a great way to reduce your exposure to unnecessary CAs, with no negative impact whatsoever.</p>

<p>Replacing the default Windows list of root CAs with the Mozilla or Google trust lists can be done manually, but is extremely time-consuming and error prone. 
The free version of RootIQ(*) offers a much simpler way to perform this system change:</p>

<div><div><pre><code>1. Use the Quick select dropdown to select the Mozilla trust set
2. Right-click the selection and click Invert selection
3. Right-click the selection and click Distrust
   Click Yes on the confirmation dialog
   This will distrust all roots that are not part of the Mozilla trust set, except for any Microsoft OS-critical roots.
4. Use the Quick select dropdown to select the Mozilla trust set (again)
5. Right-click the selection and Trust
</code></pre></div></div>

<p><img src="https://nsa40.casimages.com/img/2020/10/17/201017023914436079.png" alt="img123"></p>

<p>As of this writing, on a standard Windows 10 system, you will end up with 145 trusted roots (rather than 322 roots for the default Microsoft CTL)</p>

<p>(*) RootIQ, our own root certificate manager for Windows, is now <a href="https://www.metasudo.com/">available</a>. A free version of RootIQ is available for home and evaluation use.</p>

  </div></div>]]>
            </description>
            <link>https://hexatomium.github.io/2020/10/17/001.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24827509</guid>
            <pubDate>Mon, 19 Oct 2020 15:53:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A case for using punctuation in Slack]]>
            </title>
            <description>
<![CDATA[
Score 163 | Comments 242 (<a href="https://news.ycombinator.com/item?id=24827295">thread link</a>) | @dontmitch
<br/>
October 19, 2020 | https://blog.mitchjlee.com/2020/your-writing-style-is-costly | <a href="https://web.archive.org/web/*/https://blog.mitchjlee.com/2020/your-writing-style-is-costly">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <section>
          <p><strong>You should use punctuation in Slack.</strong> You should also use complete sentences and proper grammar. You should expand acronyms<sup>[1]</sup> and — when communicating emotion — even mix in some emoji for effect. You should do that not just in Slack, but in all of your professional communication.</p>

<hr>

<p>Written communication is hard, but in the digital world we work in it’s also vital. Sadly, the style of communication that services like Slack incentivize is awful.</p>

<p>To voice an opinion before the conversation moves on, you type fast and use abbreviations and hit send even with misspellings. You think one message at a time. You bounce between different threads and become easily distracted.</p>

<p>There are some obvious downsides to this fast and loose style. Most notably, it interrupts more productive work and deters deep thinking. But one large and often overlooked downside is the impact it has on others.</p>

<h2 id="externalities">Externalities</h2>

<p>When you use an obscure initialism or take shortcuts on grammar and spelling, it may save you a couple seconds. The problem is those small savings are often outweighed by the cost born by your audience.</p>

<p>Every person who reads your message spends some finite period of time interpreting what you’re saying. Setting aside the possibility that a sloppy message might lead the reader to an incorrect interpretation, it’s harder to parse messages written hastily — messages with poor grammar, misspellings, minimal punctuation, obscure acronyms, or delivered a few words at a time.</p>

<p>As an example, assume you send the following message to a Slack channel with 10 other people in it.</p>

<div><div><pre><code>anyone know the latest on cai
</code></pre></div></div>

<p>And further assume that “cai” refers to an internal project: <strong>C</strong>rusade <strong>A</strong>gainst <strong>I</strong>nitialisms. By writing in all lower case, using an initialism to refer to the project, and omitting the question mark, you’ve saved yourself two words and a handful of extra keystrokes. Under the most generous assumptions, say that translates to five seconds in savings. That’s a lot!</p>

<p>But let’s now examine the impact the shortcuts have on your 10-person audience.</p>

<ul>
  <li>Two people thought “cai” was a typo and spent several moments trying to guess what you actually meant to type before realizing you were referring to the internal project. <em>Cost: 20 seconds</em></li>
  <li>Two people didn’t know what “cai” stood for. One spent three minutes tracking it down on the internal wiki, and the other sent a private message to another team member to ask. <em>Cost: 4 minutes</em></li>
  <li>One person ignored your ask because they didn’t realize it was a question when scanning the channel. <em>Cost: Priceless</em></li>
  <li>Five people understood what you meant but still had to mentally expand the initialism before internalizing your ask. <em>Cost: 5 seconds</em></li>
</ul>

<p>Your 5 seconds of savings amounted to roughly 4.5 <em>minutes</em> of cost spread across your audience. Sure, this is a contrived example and sure there are cases where the cost is lower, but the point stands: <strong>your communication shortcuts are costly</strong>.</p>

<p>In economics, this phenomena is referred to as a negative externality.</p>

<blockquote>
  <p>A negative externality is the cost that affects a third party who did not choose to incur that cost.</p>
</blockquote>

<p>Every time you take a communication shortcut, you are inflicting a micro-externality on your audience. The more egregious the shortcut, the larger the externality; the larger your audience, the more times the externality is multiplied and the larger the overall cost.</p>

<h2 id="so-what">So what?</h2>

<p>If you’re communicating with a close friend and choose to use shorthand, you’re probably fine. Not only will your friend probably be accustomed to it (i.e. the externality will be small), but the audience is also small (i.e. the total cost will be small). In this case, it’s entirely possible your shorthand saves you more time than it costs your friend.</p>

<p>However, when you’re communicating in a one-to-many setting such as email or Slack, and particularly in a professional setting, sloppy writing<sup>[2]</sup> has real consequences. It prioritizes your time above the time of <em>every other person</em> that will be reading that message and might misinterpret your intent or tone. In aggregate, it is a net drain on productivity at your company.</p>

<p>So use proper spelling and grammar. Write out your entire thought before hitting send. Expand acronyms. Use punctuation.</p>

<p>A period, even at the end of “Do it,” communicates, “I’ve said everything I wanted to say.”</p>

<hr>

<p>[1] For the sticklers out there, this includes initialisms as well as acronyms.</p>
<p>[2] The term "sloppy" might sound harsh, but I chose it deliberately. Not everyone speaks the company language (e.g. English) natively, and for them using proper spelling or grammar might be challenging to say the least. The argument here is scoped to people who have some degree of mastery over the language but are being <em>sloppy</em> with their written communication, which is to say "careless and unsystematic; excessively casual".</p>

        </section>
      </div></div>]]>
            </description>
            <link>https://blog.mitchjlee.com/2020/your-writing-style-is-costly</link>
            <guid isPermaLink="false">hacker-news-small-sites-24827295</guid>
            <pubDate>Mon, 19 Oct 2020 15:35:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Python For Feature Film]]>
            </title>
            <description>
<![CDATA[
Score 238 | Comments 59 (<a href="https://news.ycombinator.com/item?id=24826873">thread link</a>) | @dagmx
<br/>
October 19, 2020 | https://www.gfx.dev/python-for-feature-film | <a href="https://web.archive.org/web/*/https://www.gfx.dev/python-for-feature-film">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><section><p>This post was originally part of my series on <span>Python for Feature Film</span> on <a href="http://www.dgovil.com/">my personal site</a>, but is being ported here with minor changes. The dates have been adjusted to match release dates for the projects.</p></section><p>Python is a programming language that has become integral to the movie making process over the last few years. There’s rarely an animated feature or visual effects film, if any, that hasn’t had Python play a large part in getting it to the screen</p><p>When people think about movies, even programmers often think about the artistry involved in bringing those images to life. However, the technical side of the film industry is something that often goes unnoticed outside a small group of people.</p><p>To that end, I’ve written a few blog posts about how I’ve used Python on several major films that I’ve been lucky enough to work on. Hopefully this shows how much it contributes to the entire life of a movie.</p><p>I’ve also recently released a course on <a href="https://www.udemy.com/course/python-for-maya/" target="_blank" rel="noreferrer">Udemy</a> to teach artists how to learn Python For Maya since it’s becoming an increasingly valuable skill in the industry. These blog posts serve as companion material to the course as well.</p><p>With that intro out of the way let’s continue…</p><section></section><hr><h2 id="what-is-python">What is Python?</h2><p>Some of you may not be familiar with Python.</p><p>Python is a programming language designed to be very easy to read and write. It’s incredibly popular in the feature film industry as well as other groups, like mathematics, science and machine learning.</p><p>You can learn more about Python on <a href="https://www.python.org/" target="_blank" rel="noreferrer">the official website</a>.</p><p>It’s important to note that today, the film industry is largely still tied to Python 2.7. There is a concerted effort in 2020 to move over to Python 3, and
we should start seeing larger Python 3 adoption starting in 2021 and moving forward.</p><hr><h2 id="the-feature-film-pipeline">The Feature Film Pipeline</h2><p>The biggest use of Python is in our feature film pipeline.</p><p>This is an image that describes the pipeline at most major studios.
The Pipeline is the arrows that link each department together. It’s responsible for making sure that data flows between each department and that everyone can play well together.
It’s also responsible for the toolsets in each department so that the artists themselves can work efficiently, but for now lets focus on the inter-department flow.</p><div>
  <p><span>
      <span></span>
  <picture>
        <source srcset="https://www.gfx.dev/static/63ca48439bf4c571b1fe0ffffc1514b8/a3bc4/pipeline-flow.webp 2500w,https://www.gfx.dev/static/63ca48439bf4c571b1fe0ffffc1514b8/39db6/pipeline-flow.webp 4098w" sizes="(max-width: 4098px) 100vw, 4098px" type="image/webp">
        <source srcset="https://www.gfx.dev/static/63ca48439bf4c571b1fe0ffffc1514b8/412e4/pipeline-flow.png 2500w,https://www.gfx.dev/static/63ca48439bf4c571b1fe0ffffc1514b8/e3fe0/pipeline-flow.png 4098w" sizes="(max-width: 4098px) 100vw, 4098px" type="image/png">
        <p><img src="https://www.gfx.dev/static/63ca48439bf4c571b1fe0ffffc1514b8/e3fe0/pipeline-flow.png" alt="A diagram illustrating the flow of a shot between departments on a feature film pipeline"></p>
      </picture>
    </span></p><figcaption>An overview of the Film Production Pipeline</figcaption></div><p>Here you can see the various stages of a visual effects film or animated feature. Studios may differ slightly from this, but it’s the general workflow.</p><p>The storyboards/footage/previs represent the data we get, and Compositing/Lighting are the last stages of the film for us.
Visual Effects Films differ slightly from animated films because you have to deal with the extra added element of film footage in the form of plates.</p><div><figcaption>A more visual demonstration of this graph is in this video of the making of Ratatouille by Pixar</figcaption></div><p>The Pipeline is responsible for getting the data between departments. Here’s the gist of how it works (though it is more organic a process than the one described):</p><ul><li>We get data from the client or story artists in form of plates, previsualization (previs) or storyboards that tell us what is happening in the scene.</li><li>Modeling look at all of this and generate 3D models of all the assets that will be required.</li><li>Rigging take the modelled assets for characters and apply a virtual skeleton to make it animatable.</li><li>Matchmove are in charge of creating virtual cameras that match the ones used to shoot the film as well as any standin characters or geometry</li><li>Layout take the rigs, and either create their own cameras or take matchmoves cameras and set up the scene. They’re the equivalent of a virtual director of photography.</li><li>The scene is then handed off to Animation, who are the equivalent of the actors. They are in charge of the movement of the characters, and bring the inanimate skeletons to life.</li><li>CharacterFX are in charge of all the technical parts of animation. Muscle simulations, making cloth move realistically, the hair, grass etc… all comes from CharacterFX.</li><li>FX then handle the non animation related effects. Whether it be destruction, fire, voxelization, etc… there’s a lot that FX is in charge of.</li><li>While this is happening, Texturing are in charge of giving color to the 3D Assets so they aren’t just grey objects.</li><li>Shading then takes these textures and gives the assets a material that tells it how light should interact with it.</li><li>Matte Painting are the department we use when it is not logical or feasible to build an environment. We realistically can only build so much, and past that point it’s more efficient to have someone make a very high quality painting instead.</li><li>This all gets funnelled into Lighting who are in charge of adding lights to the shot and rendering the image out. They also do a little bit of compositing to sweeten the image. On an animated feature this may be the end of the show.</li><li>On a visual effects show, we have to prepare the plates by either removing unwanted elements, removing noise or removing the lens warp. This is handled by Plate Prep,also known as RotoPaint.</li><li>Finally everything goes to Compositing who take all the images and integrate our CG renders into the actual film plate. On a visual effects show, this will be the last stage.</li></ul><p>We use Python to tie all these bits together.
In the next section I’ll go over publishing before moving onto describing how Python is used for the individual departments.</p><h3 id="publishing-and-asset-management">Publishing and Asset Management</h3><p>This is pretty much the core of traditional pipeline, to make sure assets can be shared between departments and be tracked.</p><p>The first part of this is Asset Publishing.</p><p>When a department deems it’s work ready, it decides to publish it so the next department in the chain can consume it. For example modeling exports models, but does animation export animation? Well that depends on who is consuming it. This is dependent on whether it needs to be interactive past this point or not.</p><p>For geometry  we often just publish as a geometry cache using Alembic  which is a industry standard developed by Imageworks and ILM so that we can have a consistent cache format.
For point cloud data, we either use Alembic or OpenVDB, for images we tend to use tiff’s or OpenEXR.
Soon the industry will probably also standardize on a universal scene format from Pixar called OpenUSD.</p><p>Anyway  the idea is to generally keep the data in the most efficient format possible, while allowing for easy interchange. Cache data is often best because you really only take an IO hit, which is cheap, versus a deformation hit, which can be very expensive.</p><p>This all gets really complex though. Artists don’t need to know where their data is coming from or going to, or even how it gets there. They just need to be able to load it in and publish it out.</p><p>This is the pipeline. We develop the UI’s and the tools to do this in a very user friendly manner.</p><div>
  <p><img src="https://www.gfx.dev/e49c8aaf611022c8415419e9f49e3d71/pyblish.gif" alt="Pyblish is a similar but open soruce frontend that is featured here for reference"></p>
    <figcaption><a href="https://github.com/pyblish/pyblish-qml">Pyblish</a> is a tool by Marcus Ottosson that is similar to many publishing tools in studios</figcaption></div><p>To publish data, the user just has to open a publish UI that will validate their assets against some tests, and then send it off to the machine farms where the conversion to one of the open formats happens.</p><p>To ingest the published data, we similarly just have an asset browser that lets the artist pick which asset they want. Often they just see a thumbnail and description. The details are irrelevant to most artists.</p><p>Because these publishing and asset management systems need to be common to multiple apps, we develop them in Python and Qt (PyQt or PySide) , which allows us to reuse our code without recompiling for each application and makes it easy to rapidly add functionality where needed.</p><p>This is common to pretty much every department, so I figure it warrants its own section here rather than repeating for each.</p><hr><h3 id="modeling">Modeling</h3><p>Modeling is the department in charge of creating the 3D source geometry used by every other department.
Often there are quite a few repetitive tasks involved in regards to placing or editing geometry, or even just managing the scene.</p><div>
  <p><span>
      <span></span>
  <picture>
        <source srcset="https://www.gfx.dev/static/7f4bfaedb9ca7400206deab558456caa/9fd6b/wireframe.webp 598w" sizes="(max-width: 598px) 100vw, 598px" type="image/webp">
        <source srcset="https://www.gfx.dev/static/7f4bfaedb9ca7400206deab558456caa/79ee7/wireframe.png 598w" sizes="(max-width: 598px) 100vw, 598px" type="image/png">
        <p><img src="https://www.gfx.dev/static/7f4bfaedb9ca7400206deab558456caa/79ee7/wireframe.png" alt="An image of the Blender susan model (a monkeys head) with a wireframe overlay to show its polygons"></p>
      </picture>
    </span></p><figcaption>A wireframe of a 3D model. This is Blender's Susan mesh.</figcaption></div><p>This is where Python comes in handy. Most 3D packages have a Python API that lets you do program everything that you would do manually.</p><p>So instead of spending 10minutes creating a simple asset, you can script it up and then just click a button when you need it next time. That 10 minutes saved really adds up, and over the course of a project you may be saving hundreds of hours that could be better focused on building more complex assets that require artistic input.</p><p>For example, in  my course  <a href="https://www.udemy.com/course/python-for-maya/" target="_blank" rel="noreferrer">Python For Maya</a> I go over creating a simple gear using Python as well as creating a simple UI so that you can specify how many teeth the gear has and how long they will be.</p><p>This can get more complex though with using Python to create custom deformers or interactive tools, like this demo from Hans Godard demonstrates.</p><div><figcaption>Hans Godard has made some really interesting Python based modeling utilities.</figcaption></div><hr><h3 id="rigging">Rigging</h3><p>Rigging’s job is to create a skeleton for the character geometry so that it can deform, just like a real human would.</p><p>Of course that’s an over simplification.
Rigging is also essentially creating the interface that animators use to bring these creatures to life, but they also have to make sure that any movement happens convincingly.
If an animator moves the arm, the rigger must make sure that the shoulders deform properly.</p><p>Python plays an integral role in Rigging. Here are just some of the uses:</p><ul><li>Creating automated builds of rigs. Rather than doing everything manually, rigs can be composed using code which makes them easy to reuse.</li><li>Developing custom deformers or nodes to perform operations not native to the application.</li><li>Develop supporting scripts for animators to switch between modes or controls etc..</li></ul><p>In  my course  <a href="https://www.udemy.com/course/python-for-maya/" target="_blank" rel="noreferrer">Python For Maya</a> I go over creating a controller library.
Controllers are, as the name suggests, the objects animators use to control the rig. Instead of using the geometry directly, they use controls, …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.gfx.dev/python-for-feature-film">https://www.gfx.dev/python-for-feature-film</a></em></p>]]>
            </description>
            <link>https://www.gfx.dev/python-for-feature-film</link>
            <guid isPermaLink="false">hacker-news-small-sites-24826873</guid>
            <pubDate>Mon, 19 Oct 2020 14:50:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple blocks widow from honouring husband's dying wish]]>
            </title>
            <description>
<![CDATA[
Score 51 | Comments 36 (<a href="https://news.ycombinator.com/item?id=24825279">thread link</a>) | @pseudolus
<br/>
October 19, 2020 | https://www.cbc.ca/news/business/widow-apple-denied-last-words-1.5761926 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/business/widow-apple-denied-last-words-1.5761926">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>A widow is locked in a four-year battle with Apple over online material she already legally owns — unless she jumps through complicated and expensive hoops. Experts say tech companies refusing to hand over online assets is a big problem that will only get bigger.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5762042.1602802843!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/carol-anne-and-don-noble.jpg"></p></div><figcaption>Carol Anne Noble, here with her husband, Don, who died in 2016, wants Apple to give her access to his online files.<!-- --> <!-- -->(Submitted by Carol Anne Noble)</figcaption></figure><p><span><p>An Ontario widow is locked in a four-year battle with Apple over online material she already legally owns.</p>  <p>Carol Anne Noble of Toronto&nbsp;wants access to an Apple account she and her husband shared — but was under his name — so she can fulfil a promise she made to him before he died.</p>  <p>But&nbsp;instead of giving her the password she's forgotten, the tech giant is demanding she jump through complicated and expensive legal hoops&nbsp;to satisfy what experts say is an outdated American law.</p>  <p>"It's a real slap in the face to me," said&nbsp;Noble&nbsp;who, after 41 years of marriage, was the executor and sole beneficiary of her husband's estate. Don Noble died from a rare spinal cancer in late 2016.&nbsp;</p>  <p>"Basically, they&nbsp;want an order from the court to give me what my husband owned and it is already bequeathed to me... it's very strange," Noble, 66,&nbsp;told&nbsp;Go Public.</p>    <blockquote><span><span><svg version="1.1" focusable="false" x="0px" y="0px" width="30px" height="25px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g><g><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g display="none"><g display="inline"> <path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg>His last words to me that night were 'You will have to write the book.'<svg focusable="false" x="0px" y="0px" width="23px" height="22px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g display="none"><g display="inline"><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g><g><path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg></span><cite>- Carol Anne Noble</cite></span></blockquote>    <p>Experts say that tech companies refusing to hand over digital assets is a problem affecting everything from stocks, insurance policies and&nbsp;PayPal to gaming credits, social media posts and family photos.</p>  <p>It's a "big" problem that will "only get bigger," leaving Canadians at the mercy of the U.S.-based companies and their rules, said Peter Lown, an online assets expert and director emeritus of the Alberta Law Reform Institute&nbsp;at the University of Alberta in Edmonton.</p>  <ul>   <li><strong>Are you facing an uphill battle with a company? Contact our <a href="mailto:gopublic@cbc.ca">Go Public team</a></strong></li>  </ul>  <p>Noble's husband spent the last six months of his life confined to a bed as he battled a slow-moving&nbsp;form of cancer called chordoma. He'd spend hours chronicling the progression of the disease using Apple devices.</p>  <p>He was hoping to put it all together in a book for his family, but Noble says it eventually became clear he wouldn't live long enough.</p>  <p>"A few days before Don died I had to take him to the hospital … His last words to me that night were 'You will have to write the book.' He went into a coma shortly after," she said.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5762072.1602802943!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/don-noble.jpg 300w,https://i.cbc.ca/1.5762072.1602802943!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/don-noble.jpg 460w,https://i.cbc.ca/1.5762072.1602802943!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/don-noble.jpg 620w,https://i.cbc.ca/1.5762072.1602802943!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/don-noble.jpg 780w,https://i.cbc.ca/1.5762072.1602802943!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/don-noble.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5762072.1602802943!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/don-noble.jpg"></p></div><figcaption>Don Noble, here with his grandson, died in November 2016.<!-- --> <!-- -->(Submitted by Carol Anne Noble)</figcaption></figure></span></p>  <h2>Proof 'not good enough'</h2>  <p>When Noble&nbsp;contacted Apple in early 2017, she was told all she needed to do was prove she has the legal right to her husband's estate. She sent all the documents the company asked for, including his death certificate and the will designating her as executor.</p>  <p>"They called me back and said, no, that's not good enough — you have to have a court order [but] having to pay to put in a court order is a huge deal," she said.&nbsp;</p>  <p>Court orders can cost from about $2,000 to tens of thousands of dollars —&nbsp;depending on whether they're opposed.&nbsp;</p>  <p>After going back and forth with Apple for years, Noble, out of desperation, hired a lawyer earlier this year to help navigate the company's&nbsp;demands.</p>  <p>"It's a tricky situation," said Dheeraj Sindhwani, Noble's lawyer, who practises family law in Ontario.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5762051.1602698127!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/carol-anne-noble.jpg 300w,https://i.cbc.ca/1.5762051.1602698127!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/carol-anne-noble.jpg 460w,https://i.cbc.ca/1.5762051.1602698127!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/carol-anne-noble.jpg 620w,https://i.cbc.ca/1.5762051.1602698127!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/carol-anne-noble.jpg 780w,https://i.cbc.ca/1.5762051.1602698127!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/carol-anne-noble.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5762051.1602698127!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/carol-anne-noble.jpg"></p></div><figcaption>Without the password for her late husband's account, Noble can't access his journal entries. He was planning to write a book about his illness for his family.<!-- --> <!-- -->(Christopher Mulligan/CBC)</figcaption></figure></span></p>  <p>"Digital assets are one of those things where it's being governed by a privately held corporation...&nbsp;it's not like a bank account where we can&nbsp;go in and say, here's a death certificate, here's a probate document and get access."&nbsp;</p>  <p>Lown says he has seen similar<em>&nbsp;</em>cases involving Google, Facebook and others, and that tech companies often "brush off"&nbsp;Canadian users "as a nuisance."&nbsp;</p>  <p>"So people are getting hooped by the hoops. Even if they get through some, there will be more," he&nbsp;said.</p>  <p>Apple refused Go Public's request for an interview and didn't respond to our specific questions about Noble's situation and its policies on digital assets.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5762240.1602802875!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/dheeraj-sindhwani.jpg 300w,https://i.cbc.ca/1.5762240.1602802875!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/dheeraj-sindhwani.jpg 460w,https://i.cbc.ca/1.5762240.1602802875!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/dheeraj-sindhwani.jpg 620w,https://i.cbc.ca/1.5762240.1602802875!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/dheeraj-sindhwani.jpg 780w,https://i.cbc.ca/1.5762240.1602802875!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/dheeraj-sindhwani.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5762240.1602802875!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/dheeraj-sindhwani.jpg"></p></div><figcaption>Dheeraj Sindhwani, Noble’s lawyer, is helping her navigate Apple’s demands and offered his services pro bono.<!-- --> <!-- -->(Dheeraj Sindhwani/Zoom)</figcaption></figure></span></p>  <h2>Europeans exempt</h2>  <p>The company told Noble providing&nbsp;the password would<em><strong> </strong></em>contravene a U.S. law —&nbsp;<a href="https://it.ojp.gov/PrivacyLiberty/authorities/statutes/1285">the Electronic Communications Privacy Act</a> — written back in 1986.</p>  <p>The law, meant to protect Americans&nbsp;from unnecessary government and police&nbsp;surveillance, bars companies from giving out personal electronic information.</p>  <p>But the decades-old law isn't meant for today's heavily online world of social media and&nbsp;other digital assets, Lown&nbsp;says.</p>  <p>"We didn't&nbsp;have our electronic world in 1986," he&nbsp;said.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5762087.1602802906!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/peter-lown.jpg 300w,https://i.cbc.ca/1.5762087.1602802906!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/peter-lown.jpg 460w,https://i.cbc.ca/1.5762087.1602802906!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/peter-lown.jpg 620w,https://i.cbc.ca/1.5762087.1602802906!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/peter-lown.jpg 780w,https://i.cbc.ca/1.5762087.1602802906!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/peter-lown.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5762087.1602802906!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/peter-lown.jpg"></p></div><figcaption>Expert Peter Lown says Canadians are often left at the mercy of U.S. laws over ownership of digital assets.<!-- --> <!-- -->(Submitted by Peter Lown)</figcaption></figure></span></p>  <p>"[Yet] the service providers use it to their hearts' content … so they can say, sorry, I can't disclose this to you because that would be a breach of my obligations under the act."</p>  <p>Citizens of countries that have laws specifically addressing digital assets — including those in the European Union — don't have the same problems. For those people, the <a href="http://www.apple.com/legal/internet-services/itunes/us/terms.html">terms and conditions</a> of Apple services grant jurisdiction to "the laws and courts of your usual place of residence."&nbsp;</p>  <p>For everyone else, California law applies unless users&nbsp;can convince a judge otherwise.</p>  <p>Some Canadians have done that. After Maureen Henry's 23-year-old son's body was found at a marina in Toronto in 2014&nbsp;— his&nbsp;cause of death deemed "undetermined" by the coroner&nbsp;—&nbsp;<a href="https://www.cbc.ca/radio/outintheopen/diy-justice-1.5351892/ottawa-mother-s-quest-for-her-late-son-s-passwords-an-uncharted-legal-road-say-experts-1.5366292">she wanted access</a> to his digital accounts to see if they would give her any answers.</p>  <p>She got&nbsp;court&nbsp;orders, first from&nbsp;Ontario and later from a&nbsp;California court. Apple and Bell complied with the Ontario order. Google Canada fought&nbsp;it but gave her the data after Henry got the U.S. order. She's still fighting Facebook in court.</p>  <p>More often though, Canadians are subject&nbsp;to U.S. laws,&nbsp;Lown says, even though proposed legislation that would protect people like Henry and Noble is already written and ready to be adopted.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5762278.1602802928!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/dovi-henry.jpg 300w,https://i.cbc.ca/1.5762278.1602802928!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/dovi-henry.jpg 460w,https://i.cbc.ca/1.5762278.1602802928!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/dovi-henry.jpg 620w,https://i.cbc.ca/1.5762278.1602802928!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/dovi-henry.jpg 780w,https://i.cbc.ca/1.5762278.1602802928!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/dovi-henry.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5762278.1602802928!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/dovi-henry.jpg"></p></div><figcaption>Dovi Henry's body was found along Toronto's Harbourfront on July 27, 2014. His mother Maureen Henry is still fighting for access to his digital accounts.<!-- --> <!-- -->(Submitted by Maureen Henry)</figcaption></figure></span></p>  <p>A proposed change to provincial inheritance laws,&nbsp;the <a href="https://www.ulcc.ca/images/stories/2016_pdf_en/2016ulcc0006.pdf">Uniform Access to Digital Assets by Fiduciaries Act</a>, was&nbsp;put forward in 2016 by an <a href="http://www.ulcc.ca/en/">independent group</a> of lawyers, judges and academics, of which Lown is a member.&nbsp;</p>  <p>It would solve these sorts of problems for Canadians but, so far, only Saskatchewan has made it law.&nbsp;</p>  <p>"Ultimately we need this nationwide,"&nbsp;said estate lawyer Daniel Nelson.&nbsp;</p>  <p>"This will force these giant tech companies to deal with the problem, because as it stands right now, good luck trying to get a hold of anyone in one of these companies who are almost always based in California."&nbsp;</p>  <p>Only when Canada has that kind of "leverage," said Lown, will tech companies accommodate the needs of Canadians.</p>  <p>Noble says Apple has a responsibility to be transparent and upfront about its policies when users sign up for the service, instead of putting that information in the fine print.</p>  <p>She also wants to see <u>p</u>rovincial and territorial governments do a better job of addressing the issue.</p>  <p>"This is an area that needs to be addressed immediately … it's very important that people are able to access their loved ones' final photos and all kinds of things," she said.</p>  <p>After Go Public contacted Apple, it reached out to Noble with details on what the court order needs to include. &nbsp;</p>  <p>On a fixed income, she didn't think she could afford to do it and was ready to give up, until Sindhwani, her lawyer, offered to complete the application pro bono.</p>  <p><em><strong>WATCH |&nbsp;Carol Anne Noble is one of several Canadians who have tried to gain access to their late loved ones' digital accounts but been&nbsp;stymied by&nbsp;tech companies' enforcement&nbsp;of&nbsp;U.S. privacy laws:&nbsp;</strong></em></p>  <p><span><span><div><div role="button" tabindex="0" title="Widow fights to get late husband's Apple password"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/691/1023/GO-PUBLIC-APPLE_frame_696.jpg" alt=""></p></div></div></div><span>Carol Anne Noble of Toronto wants access to an Apple account she and her late husband shared — but was under his name — so she can fulfil a promise she made to him before he died.<!-- --> <!-- -->2:32</span></span></span></p>  <hr>  <p><strong>Submit your story ideas</strong></p>  <p>Go Public is an investigative news segment on CBC-TV, radio and the web.</p>  <p>We tell your stories, shed light on wrongdoing, and hold the powers that be accountable.</p>  <p>If you have a story in the public interest, or if you're an insider with information, contact&nbsp;<a href="mailto:gopublic@cbc.ca">gopublic@cbc.ca</a>&nbsp;with your name, contact information and a brief summary. All emails are confidential until you decide to Go Public.</p>  <p>Follow&nbsp;<a href="https://twitter.com/cbcgopublic" target="_blank">@CBCGoPublic</a>&nbsp;on Twitter.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/business/widow-apple-denied-last-words-1.5761926</link>
            <guid isPermaLink="false">hacker-news-small-sites-24825279</guid>
            <pubDate>Mon, 19 Oct 2020 11:21:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Euler's Formula: A Complete Guide]]>
            </title>
            <description>
<![CDATA[
Score 127 | Comments 37 (<a href="https://news.ycombinator.com/item?id=24825065">thread link</a>) | @ColinWright
<br/>
October 19, 2020 | https://mathvault.ca/euler-formula/ | <a href="https://web.archive.org/web/*/https://mathvault.ca/euler-formula/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section data-css="tve-u-16ec5d248bb"><p>In the world of complex numbers, as we integrate trigonometric expressions, we will likely encounter the so-called <strong>Euler’s formula</strong>.</p><p>Named after the legendary mathematician <a href="https://en.wikipedia.org/wiki/Leonhard_Euler" target="_blank" rel="noopener noreferrer">Leonhard Euler</a>, this powerful equation deserves a closer examination — in order for us to use it to its full potential.</p><p>We will take a look at how Euler’s formula allows us to express complex numbers as <strong>exponentials</strong>, and explore the different ways it can be established with relative ease.</p><p>In addition, we will also consider its several <strong>applications</strong> such as the particular case of Euler’s identity, the exponential form of complex numbers, alternate definitions of key functions, and alternate proofs of <a href="https://en.wikipedia.org/wiki/De_Moivre%27s_formula" target="_blank" rel="noopener noreferrer">de Moivre’s theorem</a> and <a href="https://en.wikipedia.org/wiki/List_of_trigonometric_identities#Angle_sum_and_difference_identities" target="_blank" rel="noopener noreferrer">trigonometric additive identities</a>.</p><div><p>Note</p><p>This Euler’s formula is to be distinguished from other Euler’s formulas, such as the one for <a href="https://en.wikipedia.org/wiki/Euler_characteristic#Polyhedra" target="_blank" rel="noopener noreferrer"><strong>convex polyhedra</strong></a>.</p></div><p><img loading="lazy" src="https://mathvault.ca/wp-content/uploads/Euler-formula-diagram.png" alt="Diagram illustrating Euler's formula for complex numbers" width="900" height="572" title="Euler formula diagram"></p><h2><span id="Euler%E2%80%99s_Formula_Explained_Introduction,_Interpretation_and_Examples"></span>Euler’s Formula Explained: Introduction, Interpretation and Examples<span></span></h2><p>So what exactly is <strong>Euler’s formula</strong>? In a nutshell, it is the theorem that states that</p><blockquote><p>$e^{ix} = \cos x + i \sin x$</p></blockquote><p>where:</p><ul><li>$x$ is a <strong>real number</strong>.</li><li>$e$ is the <a href="https://mathvault.ca/hub/higher-math/math-symbols/#Key_Mathematical_Numbers" target="_blank" rel="noopener noreferrer"><strong>base of the natural logarithm</strong></a>.</li><li>$i$ is the <a href="https://mathvault.ca/hub/higher-math/math-symbols/#Key_Mathematical_Numbers" target="_blank" rel="noopener noreferrer"><strong>imaginary unit</strong></a> (i.e., square root of $-1$).</li></ul><div><p>Note</p><p>In this formula, the right-hand side is sometimes abbreviated as $\operatorname{cis}{x}$, though the left-hand expression $e^{ix}$ is usually preferred over the $\operatorname{cis}$ notation.</p></div><p>Euler’s formula establishes the fundamental relationship between <a href="https://mathvault.ca/hub/higher-math/math-symbols/geometry-trigonometry-symbols/#Trigonometric_Functions" target="_blank" rel="noopener noreferrer"><strong>trigonometric functions</strong></a> and <strong>exponential functions</strong>. Geometrically, it can be thought of as a way of bridging two representations of the same unit complex number in the complex plane.</p><p>Let’s take a look at some of the <strong>key values</strong> of Euler’s formula, and see how they correspond to points in the trigonometric/unit circle:</p><ul><li>For $x=0$, we have $e^{0} = \cos 0+ i \sin 0$, which gives $1 = 1$. So far so good: we know that an angle of $0$ on the trigonometric circle is $1$ on the real axis, and this is what we get here.</li><li>For $x=1$, we have $e^{i}=\cos 1 + i \sin 1$. This result suggests that $e^i$ is precisely the point on the unit circle whose angle is <strong>1 radian</strong>.</li><li>For $x = \frac{\pi}{2}$, we have $e^{i\frac{\pi}{2}} = \cos \frac{\pi}{2} + i \sin \frac{\pi}{2} = i$. This result is useful in some calculations related to physics.</li><li>For $x = \pi$, we have $e^{i\pi} = \cos \pi + i \sin \pi $, which means that $e^{i\pi} = -1$. This result is equivalent to the famous <a href="#Euler%E2%80%99s_Identity"><strong>Euler’s identity</strong></a>.</li><li>For $x = 2\pi$, we have $e^{i (2\pi)} = \cos 2\pi + i \sin 2\pi$, which means that $e^{i (2\pi)} = 1$, same as with $x = 0$.</li></ul><p>A key to understanding Euler’s formula lies in rewriting the formula as follows: \[ (e^i)^x = \sin x + i \cos x \] where:</p><ul><li>The right-hand expression can be thought of as the <strong>unit complex number</strong> with angle $x$.</li><li>The left-hand expression can be thought of as the <strong>1-radian unit complex number</strong> raised to $x$.</li></ul><p>And since raising a unit complex number to a power can be thought of as <strong>repeated multiplications</strong> (i.e., adding up angles in this case), Euler’s formula can be construed as two different ways of running around the unit circle to arrive at the same point.</p><h2><span id="Derivations"></span>Derivations<span></span></h2><p>Euler’s formula can be established in at least three ways. The first derivation is based on <strong>power series</strong>, where the exponential, sine and cosine functions are expanded as power series to conclude that the formula indeed holds.</p><p>The second derivation of Euler’s formula is based on <strong>calculus</strong>, in which both sides of the equation are treated as functions and differentiated accordingly. This then leads to the identification of a common property — one which can be exploited to show that both functions are indeed equal.</p><p>Yet another derivation of Euler’s formula involves the use of <a href="https://en.wikipedia.org/wiki/Polar_coordinate_system#Complex_numbers" target="_blank" rel="noopener noreferrer"><strong>polar coordinates</strong></a> in the complex plane, through which the values of $r$ and $\theta$ are subsequently found. In fact, you might be able to guess what these values are — just by looking at the formula itself!</p><h3><span id="Derivation_1_Power_Series"></span>Derivation 1: Power Series<span></span></h3><p>One of the most intuitive derivations of Euler’s formula involves the use of <strong>power series</strong>. It consists in expanding the power series of exponential, sine and cosine — to finally conclude that the equality holds.</p><p>As a caveat, this approach assumes that the power series expansions of $\sin z$, $\cos z$, and $e^z$ are <a href="https://en.wikipedia.org/wiki/Absolute_convergence" target="_blank" rel="noopener noreferrer"><strong>absolutely convergent</strong></a> everywhere (e.g.,&nbsp; that they hold for all complex numbers $z$). However, it also has the advantage of showing that Euler’s formula holds for all complex numbers $z$ as well.</p><p>For a complex variable $z$, the <strong>power series expansion</strong> of $e^z$ is \[ e^z = 1 + \frac{z}{1!} + \frac{z^2}{2!} + \frac{z^3}{3!} + \frac{z^4}{4!} + \cdots \] Now, let us take $z$ to be $ix$ (where $x$ is an <a href="https://mathvault.ca/math-glossary/#arbitrary" target="_blank" rel="noopener noreferrer">arbitrary</a> complex number). As $z$ gets raised to increasing powers, $i$ also gets raised to increasing powers. The <strong>first eight powers</strong> of $i$ look like this: \begin{align*} i^0 &amp; = 1 &amp; i^4 &amp; = i^2 \cdot i^2 = 1 \\ i^1 &amp; = i &amp; i^5 &amp; = i \cdot i^4 = i \\ i^2 &amp; = -1 \quad \text{(by the definition of $i$)} &amp; i^6 &amp; = i \cdot i^5 = -1 \\ i^3 &amp; = i \cdot i^2 = -i &amp; i^7 &amp; = i \cdot i^6 = -i \end{align*} (notice the <strong>cyclicality</strong> of the powers of $i$: $1$, $i$, $-1$, $-i$. We’ll be using these powers shortly.)</p><p>With $z = ix$, the expansion of $e^z$ becomes: \[ e^{ix} = 1 + ix + \frac{(ix)^2}{2!} + \frac{(ix)^3}{3!} + \frac{(ix)^4}{4!} + \cdots \] Extracting the powers of $i$, we get: \[ e^{ix} = 1 + ix-\frac{x^2}{2!}-\frac{i x^3}{3!} + \frac{x^4}{4!} + \frac{i x^5}{5!}-\frac{x^6}{6!}-\frac{i x^7}{7!} + \frac{x^8}{8!} + \cdots \] And since the power series expansion of $e^z$ is absolutely convergent, we can rearrange its terms without altering its value. Grouping the <strong>real</strong> and <strong>imaginary terms</strong> together then yields: \[ e^{ix} = \left( 1-\frac{x^2}{2!} + \frac{x^4}{4!}-\frac{x^6}{6!} + \frac{x^8}{8!}-\cdots \right) + i \left( x-\frac{x^3}{3!} + \frac{x^5}{5!}-\frac{x^7}{7!} + \cdots \right) \] Now, let’s take a detour and look at the power series of <strong>sine</strong>&nbsp;and&nbsp;<strong>cosine</strong>. The power series of $\cos{x}$ is \[ \cos x = 1-\frac{x^2}{2!} + \frac{x^4}{4!}-\frac{x^6}{6!} + \frac{x^8}{8!}-\cdots \] And for $\sin{x}$, it is \[ \sin x = x-\frac{x^3}{3!} + \frac{x^5}{5!}-\frac{x^7}{7!} + \cdots \] In other words, the last equation we had is precisely \[ e^{ix} = \cos x + i \sin x \] which is the statement of Euler’s formula that we were looking for.</p><h3><span id="Derivation_2_Calculus"></span>Derivation 2: Calculus<span></span></h3><p>Another neat way to establish Euler’s formula is to consider both $e^{ix}$ and $\cos x + i \sin x$ as <strong>functions</strong> of $x$, before differentiating them to find some common property about them.</p><p>For that to happen though, one must assume that the functions $e^z$, $\cos x$ and $\sin x$ are defined and <strong>differentiable</strong> for all real numbers $x$ and complex numbers $z$. By assuming that these functions are differentiable for all complex numbers, it is also possible to show that Euler’s formula holds for all complex numbers as well.</p><p>First, let $f_1(x)$ and $f_2(x)$ be $e^{ix}$ and $\cos x + i \sin x$, respectively. <strong>Differentiating</strong> $f_1$ via <a href="https://mathvault.ca/chain-rule-derivative/#Chain_Rule_%E2%80%94_A_Review" target="_blank" rel="noopener noreferrer">chain rule</a> then yields: \[ f_{1}'(x) = i e^{ix} = i f_1(x) \] Similarly, differentiating $f_2$ also yields: \[ f_{2}'(x) = -\sin x + i \cos x = i f_2(x) \] In other words, both functions satisfy the differential equation $f'(x) = i f(x)$. Now, consider the function $\frac{f_1}{f_2}$, which is <a href="https://mathvault.ca/math-glossary/#welldefined" target="_blank" rel="noopener noreferrer">well-defined</a> for all $x$ (since $f_2(x) = \cos x + i\sin x$ corresponds to points on the unit circle, which are never zero). With that settled, using the <strong>quotient rule</strong> on this function then yields: \begin{align*} \left(\frac{f_{1}}{f_2}\right)'(x) &amp; = \frac{f_1’(x) f_2(x)-f_1(x) f_2’(x)}{[f_2(x)]^2} \\ &amp; = \frac{i f_1(x) f_2(x)-f_1(x) i f_2(x)}{[f_2(x)]^2} \\ &amp; = 0 \end{align*} And since the derivative here is $0$, this implies that the function $\frac{f_1}{f_2}$ must have been a <strong>constant</strong> to begin with. What is the value of this constant? Let’s figure it out by plugging in $x=0$ into the function: \[ \left(\frac{f_1}{f_2}\right)(0) = \frac{e^{i0}}{\cos 0 + i \sin 0} = 1&nbsp; \] In other words, we must have that for all $x$: \[ \left(\frac{f_1}{f_2}\right)(x) = \frac{e^{ix}}{\cos x + i \sin x} = 1&nbsp; \] which, after moving $\cos x + i \sin x$ to the right, becomes the famous formula we’ve been looking for.</p><h3><span id="Derivation_3_Polar_Coordinates"></span>Derivation 3: Polar Coordinates<span></span></h3><p>Yet another ingenious proof of Euler’s formula involves treating exponentials as numbers, or more specifically, as complex numbers under <strong>polar coordinates</strong>.</p><p>Indeed, we already know that all non-zero complex numbers can be expressed in <strong>polar coordinates</strong> in a unique way. In particular, any number of the form $e^{ix}$ (with real $x$), which is non-zero, can be expressed as: \[ e^{ix} = r(\cos \theta + i \sin \theta) \] where $\theta$ is its <strong>principal angle</strong> from the positive real axis (with, say, $0 \le \theta &lt; 2 \pi$), and $r$ is its <strong>radius</strong> (with $r&gt;0$). We make no assumption about the values of $r$ and $\theta$, except the fact that they are functions of $x$ (which may or may not contain $x$ as variable). They will be determined in the course of the proof.</p><p>(However, what we do know is that when $x=0$, the left-hand side is $1$, which implies that $r$ and $\theta$ satisfy the <strong>initial conditions</strong> of $r(0)=1$ and $\theta(0)=0$, respectively.)</p><p>For what it’s worth, we’ll begin by <strong>differentiating</strong> both sides of the equation. By the definition of exponential, differentiating the left side of the equation with respect to $x$ yields $i e^{ix}$. After differentiating the right side of the equation, the equation then becomes: \[ i e^{ix} = \frac{dr}{dx}(\cos \theta + i \sin \theta) + r(- \sin \theta + i \cos \theta) \frac{d \theta}{dx} \] We’re looking for an expression that is uniquely in terms of $r$ and $\theta$. To get rid of $e^{ix}$, we substitute back $r(\cos \theta + i \sin \theta)$ for $e^{ix}$ to get:<span> \[ i r(\cos \theta + i \sin \theta) = (\cos \theta + i \sin \theta) \frac{dr}{dx} + r(- \sin \theta + i \cos \theta) \frac{d \theta}{dx} \] Once there, distributing the $i$ on the left-hand side then yields: \[ r(i \cos \theta-\sin \theta) = (\cos \theta + i \sin \theta) \frac{dr}{dx} + r(- \sin \theta + i \cos \theta) \frac{d \theta}{dx} \] …</span></p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mathvault.ca/euler-formula/">https://mathvault.ca/euler-formula/</a></em></p>]]>
            </description>
            <link>https://mathvault.ca/euler-formula/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24825065</guid>
            <pubDate>Mon, 19 Oct 2020 10:49:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[This page is a truly naked, brutalist HTML quine]]>
            </title>
            <description>
<![CDATA[
Score 899 | Comments 166 (<a href="https://news.ycombinator.com/item?id=24824977">thread link</a>) | @Symmetry
<br/>
October 19, 2020 | https://secretgeek.github.io/html_wysiwyg/html.html | <a href="https://web.archive.org/web/*/https://secretgeek.github.io/html_wysiwyg/html.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">



<p>One of my favorite things is to misuse technology in creative ways. Breaking the rules without breaking the rules.</p>

<p>For example, a hobby project I built long ago was <a href="https://github.com/secretGeek/dod">DOS-on-dope</a>, a working Ruby-on-rails parody, billed as <em>the last batch-file based MVC framework you'll ever need</em>. And there was <a href="http://www.secretgeek.net/console_log">a console.log() adventure</a> in which you played an old school console-adventure-game from inside the chrome developer tools.</p>

<p>The world of esoteric programming is filled with examples of people stretching the rules to breaking point, and misusing technology in creative ways. In particular (for example) I love <a href="http://wiki.secretgeek.net/quine">quines</a>. Quines are programs which output their own source code. Life is a Quine.</p>

<p>A different but somehow related topic I like is <a href="https://en.wikipedia.org/wiki/Brutalist_architecture">brutalism</a>, in particular, this often overlooked aspect:</p>

<blockquote>Another common theme in Brutalist designs is the exposure of the building's functions.</blockquote>

<p>...the tendency to <strong>make the internal external</strong>, and reveal the secrets of the building, in a somehow.... <em>brutaful</em> way. ;-).</p>

<p>A similarly intriguing idea which has fallen into disuse is the idea of <a href="https://en.wikipedia.org/wiki/Naked_objects">naked objects</a>, wherein:</p>

<blockquote>The user interface should be a direct representation of the domain objects.</blockquote>

<p>Putting all this together I decided to make a truly naked, brutalist html page, that is itself a quine. And this page is it.</p>

<p>Viewing <a href="https://raw.githubusercontent.com/secretGeek/html_wysiwyg/master/html.html">the source</a> of this page should reveal a page identical to the page you are now seeing. Nothing is hidden. It's a true "What you see is what you get."</p>

<h2>How it works.</h2>

<p>Did you know that the rules of html and css allow you to make <strong>every</strong> element visible, even elements like 'title' or 'style' or 'script', that are normally hidden from view? Those are just elements like any other. You can expose them <strong>all</strong> like so:</p>



<p>With that snippet of code (which is <strong>not</strong> a snippet of code, but an <strong>actual</strong> style block itself!) you can now see every element of this page, including that style block, the html and title tags, etc.</p>

<p>It does have one downside: every element on the page is now a "block" element, even some which should be "inline", such as "code" and "anchor" elements. We can correct this like so:</p>



<p>To give the code a more 'view source' feel, I've also applied <code>monospace</code> fonts, and a generally simple and consistent style to all elements, using a "*" selector, like so:</p>



<p>So far I've put style declarations all on one line, because ordinary html refuses to treat line breaks as "br" tags. But there is a way to make line-breaks display as line-breaks, and that is with this piece of styling:</p>



<h2>Make the internal external.</h2>

<p>The next trick is to make the internal external. We can start by ensuring that the tags themselves, such as paragraph tags, are exposed in their stark, brutal, beauty:</p>



<p>That works for "p" elements, but do we need to have custom styling for <strong>every</strong> element? If there was a way to output the "name" of a tag in html, then we could reduce all of the necessary style rules above to something like:</p>

<blockquote>
*::before {
 '&lt;' name() '&gt;'
}
</blockquote>

<p>And...

</p><blockquote>
*::after {
 '&lt;\/' name() '&gt;'
}
</blockquote>


<p>But alas there is no "name()" function (yet!). So we are forced to generate a chunk of style information like this (via <a href="https://nimbletext.com/Live/1105905186/">NimbleText</a> of course)</p>

<p>Please scroll happily past the next 28 offensively repetitive lines...</p>



<p>Some elements are a little trickier because they have attributes. Consider for example the "anchor" which often has a <code>href</code> attribute. We <em>need</em> that attribute to be visible, including its value. This is done like so:</p>



<p>The <code>attr()</code> function, see <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/attr">mozilla docs</a> is a nifty trick, "supported" since CSS 2.</p>


<p>The only other style that is special is "style" itself, which has to include an escape character to avoid being taken literally.</p>







<p>Finally to reduce the visual weight of the before and after pseudo elements we can give them a soft purple color and a low weight font:</p>





<p>Finally, because I believe brutalist design, even when applied to truly naked brutal html quines, is about function, not about deliberate ugliness, I'd like to apply these humble styles that improve the readability of this brutiful missive.</p>



<p>...they're derived from <a href="https://jrl.ninja/etc/1/">"58 bytes of css to look great nearly everywhere"</a>.</p>

<p>One last thing. Although this idea has bounced around in my head for a decade, the thing that reminded me to pipe it into a file was seeing this piece of "Code as Art" from Geoff Huntley: <a href="https://noyaml.com/">no yaml</a>. Bring back the world weird web.</p>

<p>Kind regards</p>
<p><a href="http://secretgeek.net/">Leon</a></p>

<p>p.s. <a href="https://github.com/secretGeek/html_wysiwyg/">source code here</a></p>



</div>]]>
            </description>
            <link>https://secretgeek.github.io/html_wysiwyg/html.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24824977</guid>
            <pubDate>Mon, 19 Oct 2020 10:30:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Discord Desktop App RCE]]>
            </title>
            <description>
<![CDATA[
Score 305 | Comments 99 (<a href="https://news.ycombinator.com/item?id=24822755">thread link</a>) | @Wingy
<br/>
October 18, 2020 | https://mksben.l0.cm/2020/10/discord-desktop-rce.html | <a href="https://web.archive.org/web/*/https://mksben.l0.cm/2020/10/discord-desktop-rce.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-6054437144226106686" itemprop="description articleBody">
<p>A few months ago, I discovered a remote code execution issue in the <a href="https://discord.com/">Discord</a> desktop application and I reported it via their <a href="https://discord.com/security">Bug Bounty Program</a>.</p><p>The RCE I found was an interesting one because it is achieved by combining multiple bugs. In this article, I'd like to share the details.</p><h3>Why I chose Discord for the target</h3><p>I kind of felt like finding for vulnerabilities of the Electron app, so I was looking for a bug bounty program which pays the bounty for an Electron app and I found Discord. Also, I am a Discord user and simply wanted to check if the app I'm using is secure, so I decided to investigate.</p><h3>Bugs I found</h3><p>Basically I found the following three bugs and achieved RCE&nbsp;by combining them.</p><ol><li>Missing contextIsolation</li><li>XSS in iframe embeds</li><li>Navigation restriction bypass (CVE-2020-15174)</li></ol><p>I'll explain these bugs one by one.</p><h3>Missing contextIsolation</h3><p>When I test Electron app, first I always check the options of the <a href="https://www.electronjs.org/docs/api/browser-window">BrowserWindow API</a>, which is used to create a browser window. By checking it, I think about how RCE can be achieved when arbitrary JavaScript execution on the renderer is possible.</p><p>The Discord's Electron app is not an open source project but the Electron's JavaScript code is saved locally with the asar format and I was able to read it just by extracting it.</p><p>In the main window, the following options are used:&nbsp;</p><blockquote>const mainWindowOptions = {<br>&nbsp;&nbsp;title: 'Discord',<br>&nbsp;&nbsp;backgroundColor: getBackgroundColor(),<br>&nbsp;&nbsp;width: DEFAULT_WIDTH,<br>&nbsp;&nbsp;height: DEFAULT_HEIGHT,<br>&nbsp;&nbsp;minWidth: MIN_WIDTH,<br>&nbsp;&nbsp;minHeight: MIN_HEIGHT,<br>&nbsp;&nbsp;transparent: false,<br>&nbsp;&nbsp;frame: false,<br>&nbsp;&nbsp;resizable: true,<br>&nbsp;&nbsp;show: isVisible,<br>&nbsp;&nbsp;webPreferences: {<br>&nbsp;&nbsp;&nbsp;&nbsp;blinkFeatures: 'EnumerateDevices,AudioOutputDevices',<br>&nbsp;&nbsp;&nbsp;&nbsp;<span><b>nodeIntegration: false</b></span>,<br>&nbsp;&nbsp;&nbsp;&nbsp;preload: _path2.default.join(__dirname, 'mainScreenPreload.js'),<br>&nbsp;&nbsp;&nbsp;&nbsp;nativeWindowOpen: true,<br>&nbsp;&nbsp;&nbsp;&nbsp;enableRemoteModule: false,<br>&nbsp;&nbsp;&nbsp;&nbsp;spellcheck: true<br>&nbsp;&nbsp;}<br>};</blockquote><p>The important options which we should check here are especially <i>nodeIntegration</i> and <i>contextIsolation</i>. From the above code, I found that the <i>nodeIntegration</i> option is set to false and the <i>contextIsolation</i> option is set to false (the default of the used version) in the Discord's main window.</p><p>If the nodeIntegration is set to true, a web page's JavaScript can use Node.js features easily just by calling the <code>require()</code>. For example, the way to execute the calc application on Windows is:</p><blockquote>&lt;script&gt;<br>&nbsp; require('child_process').exec('calc');<br>&lt;/script&gt;</blockquote><p>In this time, the <i>nodeIntegration</i> was set to false, so I couldn't use Node.js features by calling the <code>require()</code> directly.</p><p>However, there is still a possibility of access to Node.js features. The <i>contextIsolation</i>, another important option, was set to false. This option should not be set to false if you want to eliminate the possibility of RCE on your app.</p><p>If the <i>contextIsolation</i> is disabled, a web page's JavaScript can affect the execution of the <a href="https://github.com/electron/electron/tree/83bb065b4f6ed512d545c46389a7fdc114c94a54/lib/renderer">Electron's internal JavaScript code on the renderer</a>, and preload scripts (In the following, these JavaScript will be referred to as the JavaScript code outside web pages).&nbsp;For example, if you override&nbsp; <code>Array.prototype.join</code>, one of the JavaScript built-in methods, with another function from a web page's JavaScript, the JavaScript code outside web pages also will use the overridden function when the <code>join</code> is called.</p><p>This behavior is dangerous because Electron allows the JavaScript code outside web pages to use the Node.js features regardless the <i>nodeIntegration</i> option and by interfering with them from the function overridden in the web page, it could be possible to achieve RCE even if the <i>nodeIntegration</i> is set to false.</p><p>By the way, a such trick was previously not known. It was first discovered in a pentest by Cure53, which I also joined in, in 2016. After that, we reported it to Electron team and the <i>contextIsolation</i> was introduced.</p><p>Recently, that pentest report was published. If you are interested, you can read it from the following link:</p><p>Pentest-Report Ethereum Mist 11.2016 - 10.2017<br><a href="https://drive.google.com/file/d/1LSsD9gzOejmQ2QipReyMXwr_M0Mg1GMH/view">https://drive.google.com/file/d/1LSsD9gzOejmQ2QipReyMXwr_M0Mg1GMH/view</a></p><p>You can also read the slides which I used at a CureCon event:</p><p>The <i>contextIsolation</i> introduces the separated contexts between the web page and the JavaScript code outside web pages so that the JavaScript execution of each code does not affect each. This is a necessary faeture to eliminate the possibility of RCE, but this time it was disabled in Discord.</p><p>Now I found that the <i>contextIsolation</i> is disabled, so I started looking for a place where I could execute arbitrary code by interfering with the JavaScript code outside web pages.</p><p>Usually, when I create a PoC for RCE in the Electron's pentests, I first try to achieve RCE by using the Electron's internal JavaScript code on the renderer. This is because the Electron's internal JavaScript code on the renderer can be executed in any Electron app, so basically I can reuse the same code to achieve RCE and it's easy.</p><p>In my slides, <a href="https://speakerdeck.com/masatokinugawa/electron-abusing-the-lack-of-context-isolation-curecon-en?slide=41">I introduced</a> that RCE can be achieved by using the code which Electron executes at the navigation timing. It's not only possible from that code but there are such code in some places. (I'd like to publish examples of the PoC in the future.)</p><p>However, depending on the version of Electron used, or the <i>BrowserWindow</i> option which is set, because the code has been changed or the affected code can't be reached correctly, sometimes PoC via the Electron's code does not work well. In this time, it did not work, so I decided to change the target to the preload scripts.</p><div><p>When checking the preload scripts, I found that Discord exposes the function, which allows some allowed modules to be called via <code>DiscordNative.nativeModules.requireModule('MODULE-NAME')</code>, into the web page.</p></div><p>Here, I couldn't use modules that can be used for RCE directly, such as <i>child_process</i> module, but I found a code where RCE can be achieved by overriding the JavaScript built-in methods and interfering with the execution of the exposed module.</p><p>The following is the PoC. I was able to confirm that the calc application is popped up when I call the <code>getGPUDriverVersions</code> function which is defined in the module called "<i>discord_utils</i>" from devTools, while overriding the <code>RegExp.prototype.test</code> and <code>Array.prototype.join</code>.</p><blockquote>RegExp.prototype.test=function(){<br>&nbsp;&nbsp;&nbsp;&nbsp;return false;<br>}<br>Array.prototype.join=function(){<br>&nbsp;&nbsp;&nbsp;&nbsp;return "calc";<br>}<br>DiscordNative.nativeModules.requireModule('discord_utils').getGPUDriverVersions();</blockquote><p>The <code>getGPUDriverVersions</code> function tries to execute the program by using the "<i>execa</i>" library, like the following:</p><blockquote>module.exports.getGPUDriverVersions = async () =&gt; {<br>&nbsp;&nbsp;if (process.platform !== 'win32') {<br>&nbsp;&nbsp;&nbsp;&nbsp;return {};<br>&nbsp;&nbsp;}<p>&nbsp;&nbsp;const result = {};<br>&nbsp;&nbsp;const nvidiaSmiPath = `${process.env['ProgramW6432']}/NVIDIA Corporation/NVSMI/nvidia-smi.exe`;</p><p>&nbsp;&nbsp;try {<br>&nbsp;&nbsp;&nbsp;&nbsp;result.nvidia = parseNvidiaSmiOutput(await execa(nvidiaSmiPath, []));<br>&nbsp;&nbsp;} catch (e) {<br>&nbsp;&nbsp;&nbsp;&nbsp;result.nvidia = {error: e.toString()};<br>&nbsp;&nbsp;}</p><p>&nbsp;&nbsp;return result;<br>};</p></blockquote><p>Usually the <i>execa</i> tries to execute "<i>nvidia-smi.exe</i>", which is specified in the <code>nvidiaSmiPath</code> variable, however, due to the overridden <code>RegExp.prototype.test</code> and <code>Array.prototype.join</code>, the argument is replaced to "<i>calc</i>" in the <i>execa</i>'s internal processing.</p><p>Specifically, the argument is replaced by changing the following two parts.</p><p><a href="https://github.com/moxystudio/node-cross-spawn/blob/16feb534e818668594fd530b113a028c0c06bddc/lib/parse.js#L36">https://github.com/moxystudio/node-cross-spawn/blob/16feb534e818668594fd530b113a028c0c06bddc/lib/parse.js#L36</a></p><p><a href="https://github.com/moxystudio/node-cross-spawn/blob/16feb534e818668594fd530b113a028c0c06bddc/lib/parse.js#L55">https://github.com/moxystudio/node-cross-spawn/blob/16feb534e818668594fd530b113a028c0c06bddc/lib/parse.js#L55</a></p><p>The remaining work is to find a way to execute JavaScript on the application. If I can find it, it leads to actual RCE.</p><h3>XSS in iframe embeds</h3><p>As explained above, I found that RCE could happen from arbitrary JavaScript execution, so I was trying to find an XSS vulnerability. The app supports the autolink or Markdown feature, but looked like it is good. So I turned my attention to the iframe embeds feature. The iframe embeds is the feature which automatically displays the video player on the chat when the YouTube URL is posted, for example.</p><p>When the URL is posted, Discord tries to get the <a href="https://ogp.me/">OGP</a> information of that URL and if there is the OGP information, it displays the page's title, description, thumbnail image, associated video and so on in the chat.</p><p>The Discord extracts the video URL from the OGP and only if the video URL is allowed domain and the URL has actually the URL format of the embeds page, the URL is embedded in the iframe.</p><p>I couldn't find the documentation about which services can be embedded in the iframe, so I tried to get a hint by checking the CSP's <i>frame-src</i> directive. At that time, the following CSP was used:</p><blockquote>Content-Security-Policy: [...] ; frame-src https://*.youtube.com https://*.twitch.tv https://open.spotify.com https://w.soundcloud.com https://sketchfab.com https://player.vimeo.com https://www.funimation.com https://twitter.com https://www.google.com/recaptcha/ https://recaptcha.net/recaptcha/ https://js.stripe.com https://assets.braintreegateway.com https://checkout.paypal.com https://*.watchanimeattheoffice.com</blockquote><p>Obviously, some of them are listed to allow iframe embeds (e.g. YouTube, Twitch, Spotify).&nbsp;I tried to check if the URL can be embeded in the iframe by specifying the domain into the OGP information one by one and tried to find XSS on the embedded domains. After some attempts, I found that the&nbsp;<a href="https://sketchfab.com/">sketchfab.com</a>, which is one of the domains listed in the CSP, can be embedded in the iframe and found XSS on the embeds page.&nbsp;I didn't know about Sketchfab at that time, but it seems that it is a platform in which users can publish, buy and sell 3D models. There was a simple DOM-based XSS in the footnote of the 3D model.</p><p>The following is the PoC, which has the crafted OGP. When I posted this URL to the chat, the Sketchfab was embedded into the iframe on the chat, and after a few clicks on the iframe, arbitrary JavaScript was executed.</p><p><a href="https://l0.cm/discord_rce_og.html">https://l0.cm/discord_rce_og.html</a></p><blockquote>&lt;head&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&lt;meta charset="utf-8"&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&lt;meta property="og:title" content="RCE DEMO"&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;[...]<br>&nbsp;&nbsp;&nbsp;&nbsp;&lt;meta property="<span><b>og:video:url</b></span>" content="https://<span><b>sketchfab.com</b></span>/models/2b198209466d43328169d2d14a4392bb/embed"&gt;<br>&nbsp;&nbsp;&nbsp;&nbsp;&lt;meta …</blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mksben.l0.cm/2020/10/discord-desktop-rce.html">https://mksben.l0.cm/2020/10/discord-desktop-rce.html</a></em></p>]]>
            </description>
            <link>https://mksben.l0.cm/2020/10/discord-desktop-rce.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24822755</guid>
            <pubDate>Mon, 19 Oct 2020 02:00:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gravity is not a force – free-fall parabolas are straight lines in spacetime]]>
            </title>
            <description>
<![CDATA[
Score 774 | Comments 408 (<a href="https://news.ycombinator.com/item?id=24821141">thread link</a>) | @tim_hutton
<br/>
October 18, 2020 | https://timhutton.github.io/GravityIsNotAForce/ | <a href="https://web.archive.org/web/*/https://timhutton.github.io/GravityIsNotAForce/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>For full functionality of this site it is necessary to enable JavaScript.
    Here are the <a href="http://www.enable-javascript.com/" target="_blank">
    instructions how to enable JavaScript in your web browser</a>.
    </p>



    <p>
    <canvas id="canvas" width="1360" height="480">(Canvas drawing not supported by your browser.)</canvas>
    </p><p>
      Change the frame acceleration: 
    </p>
    <p>
      Move the time window: 
    </p>
    

    <h4>Description:</h4>
    <p>
    Under general relativity, gravity is not a force. Instead it is a distortion of spacetime. Objects in free-fall move along geodesics (straight lines) in spacetime, as seen in the inertial frame of reference on the right. When standing on Earth we experience a frame of reference that is accelerating upwards, causing objects in free-fall to move along parabolas, as seen on the left.
    </p>

    <p>
    In this system there is only one space dimension, shown on the vertical axis and labeled in meters. The time dimension is the horizontal axis and labeled in seconds. The gravitational field is constant within the area of interest. 
    </p>

    <p>
    Use the first slider to change the acceleration of the frame of reference in the middle. When the frame has zero acceleration it is said to be an inertial frame of reference.
    </p>

    <p>
    Use the second slider to move the time window. Note that all the trajectories remain as straight lines in the inertial frame of reference.
    </p>

    <p>
    You can drag the start and end position of each object to change their trajectories. All free-fall trajectories in the inertial frame of reference are straight lines.
    </p>

    <p>
    Code, more details, feedback: <a href="https://github.com/timhutton/GravityIsNotAForce">https://github.com/timhutton/GravityIsNotAForce</a>
    </p>

    <p>
    More on these concepts: <a href="https://youtu.be/XRr1kaXKBsU">https://youtu.be/XRr1kaXKBsU</a>
    </p>





</div>]]>
            </description>
            <link>https://timhutton.github.io/GravityIsNotAForce/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24821141</guid>
            <pubDate>Sun, 18 Oct 2020 21:07:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The local timeline is the key to enjoying Mastodon]]>
            </title>
            <description>
<![CDATA[
Score 171 | Comments 113 (<a href="https://news.ycombinator.com/item?id=24819387">thread link</a>) | @carlesfe
<br/>
October 18, 2020 | https://cfenollosa.com/blog/you-may-be-using-mastodon-wrong.html | <a href="https://web.archive.org/web/*/https://cfenollosa.com/blog/you-may-be-using-mastodon-wrong.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="divbodyholder">

<div id="divbody"><div>
<!-- entry begin -->
<h3><a href="https://cfenollosa.com/blog/you-may-be-using-mastodon-wrong.html">
You may be using Mastodon wrong
</a></h3>
<!-- bashblog_timestamp: #202010181913.37# -->
<p>October 18, 2020 — 
Carlos Fenollosa
</p>
<!-- text begin -->

<p>I'm sure you have already heard about <a href="https://joinmastodon.org/">Mastodon</a>,
typically marketed as <em>a Twitter alternative</em>.</p>

<p>I will try to convince you that the word <em>alternative</em> doesn't mean here what you think it means,
and why you may be using Mastodon wrong if you find it boring.</p>

<h4>An alternative community</h4>

<p>You should not expect to "migrate from Twitter to Mastodon."</p>

<p>Forget about the privacy angle for now. Mastodon is an alternative community, where people behave
differently.</p>

<p><strong>It's your chance to make new internet friends.</strong></p>

<p>There may be some people for whom Mastodon is a safe haven. Yes, some users really do migrate
there to avoid censorship or bullying but, for most of us, that will not be the case.</p>

<p>Let's put it this way: Mastodon is to Twitter what Linux is to Windows.</p>

<p>Linux is libre software. But that's not why most people use it. Linux users mostly want 
to get their work done, and Linux is an excellent platform.
There is no Microsoft Word, no Adobe Photoshop, no Starcraft. If you need to use these tools, honestly,
you'd better stick with Windows. You can use emulation, in the same way that there are
utilities to post to Twitter from Mastodon, but that would miss the point.</p>

<p>The bottom line is, you can perform the same tasks, but the process will be different.
You can post <em>toots</em> on Mastodon, upload gifs, send DMs... but it's not Twitter, and that is fine.</p>

<h4>The Local Timeline is Mastodon's greatest invention</h4>

<p>The problem most people have with Mastodon is that they "get bored" with it quickly. I've seen it a lot, and
it means one thing: <strong>the person created their account on the wrong server</strong>.</p>

<p>"But," they say, "isn't Mastodon federated? Can't I chat with everybody, regardless of their server?"
Yes, of course. But discoverability works differently on Mastodon.</p>

<p>Twitter has only two discoverability layers: your network and the whole world. Either a small group of
contacts, or everybody in the whole world. That's crazy.</p>

<p>They try very hard to show you tweets from outside your network so you can discover new people.
And, at the same time, they show your tweets to third parties, so you can get new followers.
This is the way that
they try to keep you engaged once your network is more or less stable and starts getting stale.</p>

<p>Mastodon, instead, has an extra layer between your network and the whole world:
messages from <em>people on your server</em>. This is called the <em>local timeline</em>.</p>

<p><strong>The local timeline is the key to enjoying Mastodon.</strong></p>

<h4>How long it's been since you made a new internet friend?</h4>

<p>If you're of a certain age you may remember BBSs, Usenet, the IRC, or early internet forums.
Do you recall how exciting it was to log into the unknown and realize that there were people
all around the world who shared your interests?</p>

<p>It was an amazing feeling which got lost on the modern internet. Now you have a chance to relive it.</p>

<p>The local timeline dynamics are very different. There is a lot of respectful interactions among total strangers,
because there is this feeling of community, of being in a neighborhood. Twitter is just the opposite, strangers
shouting at each other.</p>

<p>Furthermore, since the local timeline is more or less limited in the amount of users, you have the chance
to recognize usernames, and being recognized. You start interacting with strangers, mentioning them, sending them
links they may like. You discover new websites, rabbit holes, new approaches to your hobbies.</p>

<p>I've made quite a few new <em>internet friends</em> on my Mastodon server, and I don't mean followers or contacts.
I'm talking about human beings who I have never met in person but feel close to.</p>

<p>People are humble and respectful. And, for less nice users, admins enforce codes of conduct and, 
on extreme cases, users may get kicked off a server. But they are not being banned by a faceless corporation
due to mass reports, everybody is given a chance.</p>

<h4>How to choose the right server</h4>

<p>The problem with "generalist" Mastodon servers like <a href="https://mastodon.social/">mastodon.social</a>
is that users have just too diverse interests and backgrounds.
Therefore, there is no community feeling. For some people, that may be exactly what they're looking for. But, 
for most of us, there is more value on the smaller servers.</p>

<p>So, how can you choose the right server? Fortunately, you can do a bit of research. 
There is an official <a href="https://joinmastodon.org/communities">directory of Mastodon servers</a> categorized by
interests and regions. </p>

<p>Since you're reading my blog, start by taking a look at these:</p>

<ul>
<li><a href="http://bsd.network/">bsd.network</a>, for fans of BSD systems</li>
<li><a href="http://linuxrocks.online/">linuxrocks.online</a>, for Linux fans</li>
<li><a href="http://fosstodon.org/">fosstodon.org</a>, for free software in general</li>
<li><a href="http://tilde.zone/">tilde.zone</a>, for oldschool internet users</li>
<li><a href="https://merveilles.town/">merveilles.town</a>, with a very particular mixture of art and technology</li>
<li><a href="https://metalhead.club/">metalhead.club</a>, to enjoy those classic riffs</li>
</ul>

<p>And the regionals</p>

<ul>
<li><a href="https://mastodont.cat/">mastodont.cat</a> for catalans</li>
<li><a href="https://mastodon.madrid/">mastodon.madrid</a> for madrileños</li>
</ul>

<p>There are many more. Simply search online for "mastodon server MY_FAVORITE_HOBBY." And believe me, servers
between 500 and 5,000 people are the best.</p>

<h4>Final tips</h4>

<p>Before clicking on "sign up", always browse the local timeline,
the about page, and the most active users list. You will get a pretty good idea of the kind of people
who chat there.
Once you feel right at home you can continue your adventure and start following users from other servers.</p>

<p>Mastodon has an option to only display toots in specific languages. It can be very useful to avoid being
flooded by toots that you just have no chance of understanding or even getting what they're about.</p>

<p>You can also filter your notifications by types: replies, mentions, favorites, reposts, and more.
This makes catching up much more manageable than on Twitter.</p>

<p>Finally, Mastodon has a built-in "Content Warning" feature. It allows you to hide
text behind a short explanation, in case you want to talk about sensible topics or just about spoiling
a recent movie.</p>

<p>Good luck with your search, and see you on the Fediverse! I'm at
<a href="https://mastodon.sdf.org/@cfenollosa">@cfenollosa@mastodon.sdf.org</a></p>

<p>Tags: <a href="https://cfenollosa.com/blog/tag_internet.html">internet</a></p>
<!-- text end -->
<p id="twitter"><a href="http://twitter.com/intent/tweet?url=http://cfenollosa.com/blog/you-may-be-using-mastodon-wrong.html&amp;text=%3CType%20your%20comment%20here%20but%20please%20leave%20the%20URL%20so%20that%20other%20people%20can%20follow%20the%20comments%3E&amp;via=cfenollosa">Comments? Tweet</a> 
<a href="https://twitter.com/search?q=http://cfenollosa.com/blog/you-may-be-using-mastodon-wrong.html"><span id="count-18287"></span></a>&nbsp;</p>
<!-- entry end -->
</div>

</div></div></div>]]>
            </description>
            <link>https://cfenollosa.com/blog/you-may-be-using-mastodon-wrong.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24819387</guid>
            <pubDate>Sun, 18 Oct 2020 17:16:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cursed Elixir]]>
            </title>
            <description>
<![CDATA[
Score 147 | Comments 69 (<a href="https://news.ycombinator.com/item?id=24818706">thread link</a>) | @udfalkso
<br/>
October 18, 2020 | https://evuez.github.io/posts/cursed-elixir.html | <a href="https://web.archive.org/web/*/https://evuez.github.io/posts/cursed-elixir.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
        <time datetime="2020-08-12">2020-08-12</time>
      <p>Let's write some Elixir.</p>
<pre><code>defmodule FooBar do
  def foo(a) do
    if a &lt; 0 do
      bar(a, -1)
    else
      bar(a, 1)
    end
  end

  defp bar(a, b) do
    IO.inspect(a * b)
  end
end
</code></pre>
<p>Not very useful, but that's good enough for our purpose.</p>
<p>I like Elixir, but I think most of the time it just looks like functional Ruby. I want to make this code look like Elixir.</p>
<p>First, this code is lacking every Elixir developer's best friend: <code>|&gt;</code>. Let's add some <code>|&gt;</code>s.</p>
<pre><code>defmodule FooBar do
  def foo(a) do
    if a &lt; 0 do
      a |&gt; bar(-1)
    else
      a |&gt; bar(1)
    end
  end

  defp bar(a, b) do
    (a * b) |&gt; IO.inspect()
  end
end
</code></pre>
<p>Meh. It's definitely better, but I mean, that's only 3 <code>|&gt;</code>s. I want more <code>|&gt;</code>s.</p>
<p>We have an <code>if</code> in there, so maybe we can do something with it?</p>
<pre><code>defmodule FooBar do
  def foo(a) do
    (a &lt; 0) |&gt; if do
      a |&gt; bar(-1)
    else
      a |&gt; bar(1)
    end
  end

  defp bar(a, b) do
    (a * b) |&gt; IO.inspect()
  end
end
</code></pre>
<p>We sure can! That's one more <code>|&gt;</code>. Can we do better than this?</p>
<p>Well... <code>&gt;</code> and <code>*</code> are <code>Kernel</code> functions, so maybe...</p>
<pre><code>defmodule FooBar do
  def foo(a) do
    a |&gt; Kernel.&lt;(0) |&gt; if do
      a |&gt; bar(-1)
    else
      a |&gt; bar(1)
    end
  end

  defp bar(a, b) do
    a |&gt; Kernel.*(b) |&gt; IO.inspect()
  end
end
</code></pre>
<p>This is great, can we keep going?</p>
<p>The Elixir docs say <code>defmodule</code> is just a macro. Does that mean I can just <code>|&gt;</code> into <code>defmodule</code>?</p>
<pre><code>FooBar |&gt; defmodule do
  def foo(a) do
    a |&gt; Kernel.&lt;(0) |&gt; if do
      a |&gt; bar(-1)
    else
      a |&gt; bar(1)
    end
  end

  defp bar(a, b) do
    a |&gt; Kernel.*(b) |&gt; IO.inspect()
  end
end
</code></pre>
<p>Yes you can!</p>
<p><code>def</code> and <code>defp</code> are macros too right?</p>
<pre><code>FooBar |&gt; defmodule do
  a |&gt; foo() |&gt; def do
    a |&gt; Kernel.&lt;(0) |&gt; if do
      a |&gt; bar(-1)
    else
      a |&gt; bar(1)
    end
  end

  a |&gt; bar(b) |&gt; defp do
    a |&gt; Kernel.*(b) |&gt; IO.inspect()
  end
end
</code></pre>
<p>So many pipes! 😍</p>
<p>We're getting somewhere, but something still doesn't feel right. This module really isn't doing much, so maybe it should not be that long? Also, I think we need more <code>:</code>. Atoms are very Elixir-y, so let's do more of that:</p>
<pre><code>FooBar |&gt; defmodule(do: (
  a |&gt; foo() |&gt; def(do: a |&gt; Kernel.&lt;(0) |&gt; if(do: a |&gt; bar(-1), else: a |&gt; bar(1)))

  a |&gt; bar(b) |&gt; defp(do: a |&gt; Kernel.*(b) |&gt; IO.inspect())
))
</code></pre>
<p>We're <code>:do</code>ing great!</p>
<p>You know what's also very Elixir-y? Lists. Lists and tuples.</p>
<pre><code>FooBar |&gt; defmodule([{:do, (
  a
  |&gt; foo()
  |&gt; def([{:do, a |&gt; Kernel.&lt;(0) |&gt; if([{:do, a |&gt; bar(-1)}, {:else, a |&gt; bar(1)}])}])

  a |&gt; bar(b) |&gt; defp([{:do, a |&gt; Kernel.*(b) |&gt; IO.inspect()}])
)}])
</code></pre>
<p>Who's going to say this looks like Ruby now? ⚗️</p>
<hr>
<p><a href="https://news.ycombinator.com/item?id=24818706">discussion on hackernews</a> /
<a href="https://www.reddit.com/r/elixir/comments/jd2hr4/cursed_elixir/">discussion on reddit</a></p>

    </article></div>]]>
            </description>
            <link>https://evuez.github.io/posts/cursed-elixir.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24818706</guid>
            <pubDate>Sun, 18 Oct 2020 15:49:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EU shoots for €10B ‘industrial cloud’ to rival US]]>
            </title>
            <description>
<![CDATA[
Score 175 | Comments 331 (<a href="https://news.ycombinator.com/item?id=24817290">thread link</a>) | @colinjoy
<br/>
October 18, 2020 | https://www.politico.eu/article/eu-pledges-e10-billion-to-power-up-industrial-cloud-sector/ | <a href="https://web.archive.org/web/*/https://www.politico.eu/article/eu-pledges-e10-billion-to-power-up-industrial-cloud-sector/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
									
							<div id="amazon-polly-audio-table">
				<p>Press play to listen to this article</p>
				
		</div><p>BERLIN — The European Union aims to spend up to €10 billion over the next seven years to help build up a homegrown cloud computing sector that could rival foreign corporations such as Amazon, Google and Alibaba.</p>
<p>Twenty-five EU countries signed a <a href="https://ec.europa.eu/digital-single-market/en/news/towards-next-generation-cloud-europe" target="_blank">joint declaration</a> Thursday pledging public money to power up the cloud sector and establishing the "European Alliance on Industrial Data and Cloud," a partnership geared toward facilitating such projects.</p>
<p>The alliance — whose funding is to be drawn from existing EU programs and hoped-for pledges from industry and national capitals — will be launched by the end of the year. Cyprus and Denmark were the only EU member countries not to sign the declaration due to “technical reasons.”</p>
<p>The declaration “is a foundation stone for the establishment of European cloud technology, which will be very high performing,” said Internal Market Commissioner Thierry Breton, following a meeting of European telecoms ministers organized by the German government, which currently holds the EU’s rotating Council presidency.</p>
<p>“Contrary to the prejudices, we are not late [on cloud development]. We are the first to get involved in the industrial cloud,” he added.</p>
<blockquote><p>“EU governments and the public sector need to be fully committed to the initiative by fully shifting to cloud services” — <em>Lise Fuhr, ETNO’s director general</em></p></blockquote>
<p>The cloud alliance is a key part of the European Commission’s data strategy, which aims to create a single market for industrial data. Commissioner Breton in particular has lobbied hard to make the EU a worldwide data hub, and to develop data processing capabilities that would give Europe an edge over foreign rivals that currently dominate the cloud business.</p>
<p>It also fits in with broader efforts by European policymakers to make the Continent less dependent on foreign technology. Currently, U.S. technology firms dominate the global market for cloud storage.</p>
<p>In the same vein, the bloc is set to unveil by December a rulebook for platforms dubbed the “Digital Services Act," as well as binding laws for artificial intelligence that are set to be released early next year.</p>
<p>The new alliance will have the mandate to develop business, investment and implementation plans for European cloud technologies in the public and private sectors.</p>
<p>Signatories also pledge to create common European standards and policy norms to create pan-European cloud services, and help small and medium-sized businesses, startups and the public sector embrace cloud technology.</p>
<p>“In order to achieve digital sovereignty, we need to start approaching data processing the way major American and Chinese companies — the hyper-scalers — approach it,” said German Economy Minister Peter Altmaier.</p>
<p>“This is an area where we’re far from being equals,” he added.</p>
<h3>Money, money, money</h3>
<p>The Commission’s plan is to invest up to €10 billion to develop Europe's cloud and data infrastructures.</p>
<p>The EU’s executive arm would invest €2 billion from programs in its long-term budget such as the Digital Europe Programme, Connecting Europe Facility 2 and InvestEU.</p>
<p>The rest of the money will come from both industry and member countries. National governments will be able to fund these projects through the EU’s coronavirus recovery plan, which has earmarked 20 percent toward digital projects.</p>
<p>The joint cloud declaration also issues demands to non-European cloud companies.</p>
<p>Cloud providers must “guarantee European standards in terms of security, data protection, consumer protection, data portability and energy efficiency and contribute to European digital sovereignty.”</p>
<p>The companies must offer “adequate assurance” that the EU will maintain control over its strategic and sensitive data.</p>
<p>“While all cloud providers are welcome in European cloud federation, the resulting cloud capacities should not be subject to laws of foreign jurisdictions,” the declaration read.</p>
<p>One of the first initiatives to come out of Europe’s cloud push is Gaia-X, a much-hyped European effort spearheaded by Germany and France to build up a European platform that sets common standards for cloud technology. Gaia-X has <a href="https://www.politico.eu/?p=1449266">limited</a> the voting rights of non-European cloud computing companies, and they cannot become directors of the association.</p>
<p>ETNO, the association representing Europe’s leading telecom operators, applauded the move.</p>
<p>“EU governments and the public sector need to be fully committed to the initiative by fully shifting to cloud services. We call for EU targets and commitments that reflect the demand side of the cloud investment story,” said Lise Fuhr, ETNO’s director general.</p>
<p>Tech lobby DigitalEurope was equally supportive, and announced it was applying for membership in Gaia-X.</p>
<p><em>Want more analysis from </em><span>POLITICO</span><em>? </em><span>POLITICO</span><em> Pro is our premium intelligence service for professionals. From financial services to trade, technology, cybersecurity and more, Pro delivers real time intelligence, deep insight and breaking scoops you need to keep one step ahead. Email <a href="https://www.politico.eu/cdn-cgi/l/email-protection#6515170a25150a090c110c060a4b0010" target="_blank"><span data-cfemail="9aeae8f5daeaf5f6f3eef3f9f5b4ffef">[email&nbsp;protected]</span></a> to request a complimentary trial.</em></p>
 <div> <h3>  Also On POLITICO  </h3>   <div data-block-attributes="[]" data-page="0"> <div> <div> <p><a href="https://www.politico.eu/article/eu-cloud-new-front-with-us-tech-giants/"> <img src="https://www.politico.eu/wp-content/uploads/2020/09/iStock-1160479733-765x540.jpg" sizes="(max-width: 765px) 100vw, 765px" alt="EU cloud regulation opens new front with US tech giants" width="765" height="540" data-thumbnail-size="ev-pro-lead" loading="lazy"></a> </p>   </div><div> <p><a href="https://www.politico.eu/article/beyond-tiktok-us-chinese-app-crackdown/"> <img src="https://www.politico.eu/wp-content/uploads/2020/08/GettyImages-1068921922-1-765x540.jpg" sizes="(max-width: 765px) 100vw, 765px" alt="Beyond TikTok, US eyes Chinese apps and cloud for crackdown" width="765" height="540" data-thumbnail-size="ev-pro-lead" loading="lazy"></a> </p>   </div> </div> </div>    </div> 								</div></div>]]>
            </description>
            <link>https://www.politico.eu/article/eu-pledges-e10-billion-to-power-up-industrial-cloud-sector/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24817290</guid>
            <pubDate>Sun, 18 Oct 2020 12:20:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Object Detection at 1840 FPS with TorchScript, TensorRT and DeepStream]]>
            </title>
            <description>
<![CDATA[
Score 159 | Comments 55 (<a href="https://news.ycombinator.com/item?id=24817173">thread link</a>) | @briggers
<br/>
October 18, 2020 | https://paulbridger.com/posts/video-analytics-deepstream-pipeline/ | <a href="https://web.archive.org/web/*/https://paulbridger.com/posts/video-analytics-deepstream-pipeline/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
  
  <h5>October 17, 2020</h5>



  
  
  

  


  <h2 id="intro">
  Intro
  <a href="#intro">#</a>
</h2>
<p>Previously, we took a <a href="https://paulbridger.com/posts/video-analytics-pytorch-pipeline/">simple video pipeline</a> and made it as fast as we could without sacrificing the flexibility of the Python runtime. It’s amazing how far you can go — <a href="https://paulbridger.com/posts/video-analytics-pipeline-tuning/">9 FPS to 650 FPS</a> — but we did not reach full hardware utilization and the pipeline did not scale linearly beyond a single GPU. There is evidence (measured using <a href="https://github.com/chrisjbillington/gil_load">gil_load</a>) that we were throttled by a fundamental Python limitation with multiple threads fighting over the <a href="https://wiki.python.org/moin/GlobalInterpreterLock">Global Interpreter Lock</a> (GIL).</p>
<p>In this article we’ll take performance of the same <a href="https://pytorch.org/hub/nvidia_deeplearningexamples_ssd/">SSD300 model</a> even further, leaving Python behind and moving towards true production deployment technologies:</p>
<ul>
<li>
<p><a href="https://pytorch.org/docs/stable/jit.html"><strong>TorchScript.</strong></a> Instead of running directly in the Pytorch runtime, we’ll export our model using TorchScript tracing into a form that can be executed portably using the <code>libtorch</code> C++ runtime.</p>
</li>
<li>
<p><a href="https://developer.nvidia.com/tensorrt"><strong>TensorRT.</strong></a> This toolset from Nvidia includes a “deep learning inference optimizer” — a compiler for optimizing CUDA-based computational graphs. We’ll use this to squeeze out every drop of inference efficiency.</p>
</li>
<li>
<p><a href="https://developer.nvidia.com/deepstream-sdk"><strong>DeepStream.</strong></a> While <a href="https://gstreamer.freedesktop.org/">Gstreamer</a> gives us an extensive library of elements to build media pipelines with, DeepStream expands this library with a set of GPU-accelerated elements specialized for machine learning.</p>
</li>
</ul>
<p>These technologies fit together like this:</p>
<p><img src="https://paulbridger.com/posts/video-analytics-deepstream-pipeline/images/deepstream_hybrid.svg" alt="DeepStream Hybrid Architecture"></p>
<p>This article will not be a step-by-step tutorial with code examples, but will show what is possible when these technologies are combined. The associated repository is here: <a href="https://github.com/pbridger/deepstream-video-pipeline">github.com/pbridger/deepstream-video-pipeline</a>.</p>
<h3 id="torchscript-vs-tensorrt">
  🔥TorchScript vs TensorRT🔥
  <a href="#torchscript-vs-tensorrt">#</a>
</h3>
<p>Both TorchScript and TensorRT can produce a deployment-ready form of our model, so why do we need both? These great tools may eventually be competitors but in 2020 they are complementary — they each have weaknesses that are compensated for by the other.</p>
<p><strong>TorchScript.</strong> With a few lines of <code>torch.jit</code> code we can generate a deployment-ready asset from essentially any Pytorch model that will run anywhere libtorch runs. It’s not inherently faster (it is submitting approximately the same sequence of kernels) but the libtorch runtime will perform better under high concurrency. However, without care TorchScript output may have performance and portability surprises (I’ll cover some of these in a later article).</p>
<p><strong>TensorRT.</strong> An unparalleled model compiler for Nvidia hardware, but for Pytorch or <a href="https://onnx.ai/">ONNX</a>-based models it has incomplete support and suffers from poor portability. There is a plugin system to add arbitrary layers and postprocessing, but this low-level work is out of reach for groups without specialized deployment teams. TensorRT also doesn’t support cross-compilation so models must be optimized directly on the target hardware — not great for embedded platforms or highly diverse compute ecosystems.</p>
<p>Let’s begin with a baseline from the previous post in this series — <a href="https://paulbridger.com/posts/video-analytics-pipeline-tuning/">Object Detection from 9 FPS to 650 FPS in 6 Steps</a>.</p>
<h2 id="stage-0-python-baseline">
  Stage 0: Python Baseline
  <a href="#stage-0-python-baseline">#</a>
</h2>
<table>
<thead>
<tr>
<th>Code</th>
<th>Nsight Systems Trace</th>
<th>Gstreamer Pipeline</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/pbridger/pytorch-video-pipeline/blob/master/tuning_postprocess_2.py">tuning_postprocess_2.py</a></td>
<td><a href="https://paulbridger.com/posts/video-analytics-pipeline-tuning/logs/tuning_postprocess_2.qdrep">tuning_postprocess_2.qdrep</a></td>
<td><a href="https://paulbridger.com/posts/video-analytics-pipeline-tuning/logs/tuning_postprocess_2.pipeline.dot.png">tuning_postprocess_2.pipeline.dot.png</a></td>
</tr>
</tbody>
</table>
<p>The <a href="https://paulbridger.com/posts/video-analytics-pipeline-tuning/#stage-2-postprocessing-on-gpu">Postprocessing on GPU</a> stage from my previous post is logically closest to our first DeepStream pipeline. This was a fairly slow, early stage in the Python-based optimization journey but limitations in DeepStream around batching and memory transfer make this the best comparison.</p>
<p>This Python-based pipeline runs at around 80 FPS:</p>








<p>After we get a basic DeepStream pipeline up and running we’ll empirically understand and then remove the limitations we see.</p>
<h2 id="stage-1-normal-deepstream-mdash-100-torchscript">
  Stage 1: Normal DeepStream — 100% TorchScript
  <a href="#stage-1-normal-deepstream-mdash-100-torchscript">#</a>
</h2>
<table>
<thead>
<tr>
<th>Code</th>
<th>Nsight Systems Trace</th>
<th>Gstreamer Pipeline</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/pbridger/deepstream-video-pipeline/blob/master/ds_trt_1.py">ds_trt_1.py</a>, <a href="https://github.com/pbridger/deepstream-video-pipeline/blob/master/ds_tsc_1.py">ds_tsc_1.py</a>, <a href="https://github.com/pbridger/deepstream-video-pipeline/blob/master/ds_ssd300_1.py">ds_ssd300_1.py</a></td>
<td><a href="https://paulbridger.com/posts/video-analytics-deepstream-pipeline/logs/ds_1_1gpu_batch16_host.qdrep">ds_1_1gpu_batch16_host.qdrep</a></td>
<td><a href="https://paulbridger.com/posts/video-analytics-deepstream-pipeline/logs/ds_1_1gpu_batch16_host.pipeline.dot.png">ds_1_1gpu_batch16_host.pipeline.dot.png</a></td>
</tr>
</tbody>
</table>
<p>Our approach to using TorchScript and TensorRT together in a DeepStream pipeline will be to construct a hybrid model with two sequential components — a TensorRT frontend passing results to a TorchScript backend which completes the calculation.</p>
<h3 id="hybrid-deepstream-pipeline">
  Hybrid DeepStream Pipeline
  <a href="#hybrid-deepstream-pipeline">#</a>
</h3>
<p>Our hybrid pipeline will eventually use the <code>nvinfer</code> element of DeepStream to serve a TensorRT-compiled form of the SSD300 model directly in the media pipeline. Since TensorRT cannot compile the entire model (due to unsupported <a href="https://onnx.ai/">ONNX</a> ops) we’ll run the remaining operations as a TorchScript module (via <a href="https://docs.nvidia.com/metropolis/deepstream/plugin-manual/index.html#page/DeepStream%20Plugins%20Development%20Guide/deepstream_plugin_details.html#wwpID0E0TDB0HA">the <code>parse-bbox-func-name</code> hook</a>).</p>
<p>However, the first pipeline will be the simplest possible while still following the hybrid pattern. The TensorRT model does no processing and simply passes frames to the TorchScript model, which does all preprocessing, inference, and postprocessing. 0% TensorRT, 100% TorchScript.</p>
<p>This pipeline runs at 110 FPS without tracing overhead. However, this TorchScript model has already been converted to <code>fp16</code> precision so a direct comparison to the Python-based pipeline is a bit misleading.</p>








<p>Let’s drill into the trace with <a href="https://developer.nvidia.com/nsight-systems">Nvidia’s Nsight Systems</a> to understand the patterns of execution. I have zoomed in to the processing for two 16-frame batches:</p>








<a href="https://paulbridger.com/posts/video-analytics-deepstream-pipeline/images/ds_100pc_torchscript_normal_ds_two_batch.png">
    <figure>
        <img src="https://paulbridger.com/posts/video-analytics-deepstream-pipeline/images/ds_100pc_torchscript_normal_ds_two_batch_hu85cb8d526cf1fda403db89df3e60bf80_432723_896x520_fill_box_top_2.png" width="896" height="520">
        <figcaption><small></small></figcaption>
    </figure>
</a>

<p>Looking at the red NVTX ranges on the <code>GstNvInfer</code> line we can see overlapping ranges where batches of 16 frames are being processed. However, the pattern of processing on the GPU is quite clear from the 16 utilisation spikes — it is processing frame-by-frame.  We also see constant memory transfers between device and host.</p>
<p>Drilling in to see just two frames of processing, the pattern is even more clear:</p>








<a href="https://paulbridger.com/posts/video-analytics-deepstream-pipeline/images/ds_100pc_torchscript_normal_ds_two_frame.png">
    <figure>
        <img src="https://paulbridger.com/posts/video-analytics-deepstream-pipeline/images/ds_100pc_torchscript_normal_ds_two_frame_hudc758a7e69d7157937e6a1d7caab6946_421239_896x540_fill_box_top_2.png" width="896" height="540">
        <figcaption><small></small></figcaption>
    </figure>
</a>

<p>With a little knowledge of how DeepStream works the problem is clear:</p>
<ul>
<li><code>nvinfer</code> sends batches of frames to the configured model engine (our empty TensorRT component) — great.</li>
<li><code>nvinfer</code> then sends the model output <em>frame by frame</em> to the postprocessing hook (our TorchScript component).</li>
</ul>
<p>Since we have put our entire model into a TorchScript postprocessing hook we are now processing frame by frame with no batching, and this is causing very low GPU utilisation. (This is why we are comparing against a Python pipeline with no batching).</p>
<p><strong>We are using DeepStream contrary to the design</strong>, but to build a truly hybrid TensorRT and TorchScript pipeline we need batched postprocessing.</p>
<blockquote>
  <p><strong>DeepStream Limitation: Postprocessing Hooks are Frame-by-Frame</strong></p>
<p>The design of <code>nvinfer</code> assumes model output will be postprocessed frame-by-frame. This makes writing postprocessing code a tiny bit easier but is inefficient by default. Preprocessing, inference and postprocessing logic should always assume a batch dimension is present.</p>

</blockquote>

<p>The Nsight Systems view above also shows a pointless sequence of device-to-host then host-to-device transfers. The purple device-to-host memory transfer is due to <code>nvinfer</code> sending tensors to system memory, ready for the postprocessing code to use it. The green host-to-device transfers are me putting this memory back on the GPU where it belongs.</p>
<blockquote>
  <p><strong>DeepStream Limitation: Postprocessing is Assumed to Happen on Host</strong></p>
<p>This is a legacy of early machine learning approaches. Modern deep learning pipelines keep data on the GPU end-to-end, including data augmentation and postprocessing. See Nvidia’s <a href="https://developer.nvidia.com/DALI">DALI library</a> for an example of this.</p>

</blockquote>

<p>Okay, time to hack DeepStream and remove these limitations.</p>
<h2 id="stage-2-hacked-deepstream-mdash-100-torchscript">
  Stage 2: Hacked DeepStream — 100% TorchScript
  <a href="#stage-2-hacked-deepstream-mdash-100-torchscript">#</a>
</h2>
<table>
<thead>
<tr>
<th>Code</th>
<th>Nsight Systems Trace</th>
<th>Gstreamer Pipeline</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/pbridger/deepstream-video-pipeline/blob/master/ds_trt_2.py">ds_trt_2.py</a>, <a href="https://github.com/pbridger/deepstream-video-pipeline/blob/master/ds_tsc_2.py">ds_tsc_2.py</a>, <a href="https://github.com/pbridger/deepstream-video-pipeline/blob/master/ds_ssd300_2.py">ds_ssd300_2.py</a></td>
<td><a href="https://paulbridger.com/posts/video-analytics-deepstream-pipeline/logs/ds_2_1gpu_batch16_device.qdrep">ds_2_1gpu_batch16_device.qdrep</a></td>
<td><a href="https://paulbridger.com/posts/video-analytics-deepstream-pipeline/logs/ds_2_1gpu_batch16_device.pipeline.dot.png">ds_2_1gpu_batch16_device.pipeline.dot.png</a></td>
</tr>
</tbody>
</table>
<p>Thankfully, Nvidia have provided source for the <code>nvinfer</code> pipeline element. I’ve made two changes to better support our approach of doing significant work in the postprocessing hook and fix the above limitations:</p>
<ul>
<li><code>nvinfer</code> model engine output is now sent in a single batch to the postprocessing hook.</li>
<li>Model output tensors are no-longer copied to host, but are left on the device.</li>
</ul>
<blockquote>
  These <code>nvinfer</code> changes are unreleased and are not present in the companion repository (<a href="https://github.com/pbridger/deepstream-video-pipeline">github.com/pbridger/deepstream-video-pipeline</a>) because they are clearly derivative of <code>nvinfer</code> and I’m unsure of the licensing. Nvidia people, feel free to get in touch: <a href="mailto:paul@paulbridger.com">paul@paulbridger.com</a>.
</blockquote>

<p>With hacked DeepStream and no model changes at all this pipeline now hits 350 FPS when measured with no tracing overhead. This is up from 110 FPS with regular DeepStream. I think we deserve a chart:</p>








<p>The <code>Concurrency 1x2080Ti</code> stage from the Python pipeline is now the closest comparison both in terms of FPS and optimizations applied. Both pipelines have batched inference, video frames decoded and processed on GPU end-to-end, and concurrency at the batch level (note the overlapping NVTX ranges below). One additional level of concurrency in the Python pipeline is multiple overlapping CUDA streams.</p>
<p>The Nsight Systems view shows processing for several 16-frame batches:</p>








<a href="https://paulbridger.com/posts/video-analytics-deepstream-pipeline/images/ds_100pc_torchscript_hacked_ds_two_batch.png">
    <figure>
        <img src="https://paulbridger.com/posts/video-analytics-deepstream-pipeline/images/ds_100pc_torchscript_hacked_ds_two_batch_hudc758a7e69d7157937e6a1d7caab6946_445767_896x520_fill_box_top_2.png" width="896" height="520">
        <figcaption><small></small></figcaption>
    </figure>
</a>

<p>We now have good GPU utilization and very few needless memory transfers, so the path forward is to optimize the TorchScript model. Until now the TensorRT component has been entirely pass-through and everything from preprocessing, inference and postprocessing has been in TorchScript.</p>
<p>It’s time to start using the TensorRT optimizer, so get ready for some excitement.</p>
<h2 id="stage-3-hacked-deepstream-mdash-80-tensorrt-20-torchscript">
  Stage 3: Hacked DeepStream — 80% TensorRT, 20% TorchScript
  <a href="#stage-3-hacked-deepstream-mdash-80-tensorrt-20-torchscript">#</a>
</h2>
<table>
<thead>
<tr>
<th>Code</th>
<th>Nsight Systems Trace</th>
<th>Gstreamer Pipeline</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/pbridger/deepstream-video-pipeline/blob/master/ds_trt_3.py">ds_trt_3.py</a>, <a href="https://github.com/pbridger/deepstream-video-pipeline/blob/master/ds_tsc_3.py">ds_tsc_3.py</a>, <a href="https://github.com/pbridger/deepstream-video-pipeline/blob/master/ds_ssd300_3.py">ds_ssd300_3.py</a></td>
<td><a href="https://paulbridger.com/posts/video-analytics-deepstream-pipeline/logs/ds_3_1gpu_batch16_device.qdrep">ds_3_1gpu_batch16_device.qdrep</a></td>
<td><a href="https://paulbridger.com/posts/video-analytics-deepstream-pipeline/logs/ds_3_1gpu_batch16_device.pipeline.dot.png">ds_3_1gpu_batch16_device.pipeline.dot.png</a></td>
</tr>
</tbody>
</table>
<p>According to Nvidia, TensorRT <a href="https://developer.nvidia.com/tensorrt">“dramatically accelerates deep learning inference performance”</a> so why not compile 100% of our model with TensorRT?</p>
<p>The Pytorch export to TensorRT consists of a couple of steps, and both provide an opportunity for incomplete support:</p>
<ol>
<li>Export the Pytorch model to the <a href="https://onnx.ai/">ONNX</a> interchange representation via <a href="https://pytorch.org/docs/stable/onnx.html#tracing-vs-scripting">tracing or scripting</a>.</li>
<li>Compile the ONNX representation into a TensorRT engine, the optimized form of the model.</li>
</ol>
<p>If you try to create an optimized TensorRT engine for this entire model (SSD300 including postprocessing), the first problem you will run into is the export to ONNX of the …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://paulbridger.com/posts/video-analytics-deepstream-pipeline/">https://paulbridger.com/posts/video-analytics-deepstream-pipeline/</a></em></p>]]>
            </description>
            <link>https://paulbridger.com/posts/video-analytics-deepstream-pipeline/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24817173</guid>
            <pubDate>Sun, 18 Oct 2020 11:54:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Samsung phones force Mainland China DNS service upon Hong Kong WiFi users]]>
            </title>
            <description>
<![CDATA[
Score 208 | Comments 56 (<a href="https://news.ycombinator.com/item?id=24816764">thread link</a>) | @signa11
<br/>
October 18, 2020 | http://blog.headuck.com/2020/10/12/samsung-phones-force-mainland-china-dns-service-upon-hong-kong-wifi-users/ | <a href="https://web.archive.org/web/*/http://blog.headuck.com/2020/10/12/samsung-phones-force-mainland-china-dns-service-upon-hong-kong-wifi-users/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-1387">

	
<!-- .entry-header -->

	<div>

		<div>

			<p>This is a technical write up of the author’s investigation on how users of Samsung phones in Hong Kong (and Macau), using firmware released in September 2020, would be forced to use a public DNS service in Mainland China, which caused unease and privacy concerns among some of its users.</p>
<p>While this was investigated on a variant of a Galaxy Note 10+ phone targetting the Hong Kong market, it was reported that the issue exists for a wide range of recent Samsung phones, including those sold in other places when used in Hong Kong.</p>
<p>(Update: The firmware update released in Mid-October 2020 has fixed the DNS issue discussed in this Part, but the issue of DNS queries for <code>qq.com</code> discussed in <a href="http://blog.headuck.com/2020/10/15/samsung-phones-force-mainland-china-dns-service-upon-hong-kong-wifi-users-2/">Part 2</a> remained unchanged.)</p>

<blockquote><p>Shameless plug (for Hong Kong users): The author is the developer of Headuck Call blocker (useful only in Hong Kong). Earlier it got mistakenly flagged as malware by Google and lost many of its users, but the appeal was successful and the App is <a href="https://play.google.com/store/apps/details?id=com.headuck.headuckblocker.dev">on Google Play</a> again. Please re-consider the App if you got scared by the earlier Google Play malware warning.</p></blockquote>
<h3>Background</h3>
<p>In early October 2020, a Samsung phone user in Hong Kong, local forum (HKEPC) user dingwinslow209, <a href="https://www.hkepc.com/forum/viewthread.php?fid=168&amp;tid=2586830">reported that (link to forum post in Chinese)</a> an extra DNS server entry, <code>114.114.114.114</code> was added to the DNS setting of his Samsung mobile phone, which was updated with the latest firmware, whenever he was using a WiFi connection.&nbsp; This happened both when the DNS setting is static, or dynamic using DHCP (but not when VPN / mobile network was used).&nbsp; Even when both DNS1 and DNS2 were set to valid DNS servers (e.g. Google public DNS service using <code>DNS1 = 8.8.8.8</code> and <code>DNS2 = 8.8.4.4</code>), a new DNS3 entry pointing to <code>114.114.114.114</code> would appear in some utility app.</p>
<p>This immediately raised privacy concerns among some Samsung users in Hong Kong, as the public DNS server <code>114.114.114.114</code> is owned by Cogent Communications, under <a href="https://www.whois.com/whois/114.114.114.114">Nanjing XinFeng Information Technologies Inc</a>, in Mainland China.</p>
<p>Subsequently, in another local forum (lihkg), users captured DNS requests to <code>114.114.114.114</code>, and observed queries for “<code>qq.com</code>”&nbsp; (domain owned by Chinese tech giant Tencent), even when no software from Tencent is installed in the devices.&nbsp; There were reports that these DNS queries were sent once per minute, so long as the phone screen remained on.</p>
<p>There are further reports that when DNS queries to qq.com were blocked, the phone would report no internet connectivity via the WiFi connection.</p>
<p>The observation of the extra DNS entry was later independently confirmed by other forum users and the local media, using recent Samsung phones which have been updated in recent months.&nbsp; (See the links in the HKPEC post above, in Chinese).&nbsp; The issue persisted even when users reset their Samsung phone to factory settings. This showed that the issue originates from Samsung firmware instead of some third-party software malware.</p>
<p>The following documents the technical investigation and verification of the issue directly from analysing the code from firmware.&nbsp; The information should be sufficient for the issue and its extent to be independently verified.</p>
<h3>Getting and extracting the firmware</h3>
<p>To confirm the issue, a recent Samsung Galaxy Note 10+ firmware (SM-N9750 TGY, Hong Kong version), at Security Patch level 2020-09-01 was downloaded from one of the Samsung firmware download sites. Galaxy Note 10+ is one of the Samsung models reportedly&nbsp;affected.</p>
<p>After unzipping the downloaded firmware (in zip format), expanding the tar file beginning with “<code>AP_N9750ZSU3CTH1</code>“, decompressing the file <code>system.img.ext4.lz4</code> using <code>lz4</code>, converting it to ext4 format using <code>simg2img</code>, and mounting it as ext4 volume under Linux, one has access to the system image which would be installed when Note 10+ users update their phone to that patch level. (The same is accessible if a Note 10+ phone is rooted).</p>
<p>After some research, the culprit was found – a vendor specific service level component, added by Samsung to the Android framework, located at <code>/system/framework/wifi-service.jar</code>. This seems to work at the android system service level, supplementing the usual <code>services.jar</code>.</p>
<p>The decompiled source of the jar file (using <a href="http://www.javadecompilers.com/apk">this site</a>, with Jadx decompiler) has been uploaded to <a href="https://github.com/headuck/SM-N9750-TGY">https://github.com/headuck/SM-N9750-TGY</a>.&nbsp; The following is a walkthrough of the relevant code when a user connects to a WiFi network, showing how the DNS entries were modified.</p>
<h3>Relevant flow of DNS entry addition</h3>
<p>The main culprit is the class <code>com.android.server.wifi.WifiConnectivityMonitor</code>, located in the file <a href="https://github.com/headuck/SM-N9750-TGY/blob/main/com/android/server/wifi/WifiConnectivityMonitor.java">WifiConnectivityMonitor.java</a>. The decompiled code contains the following:</p>
<p>line 129: the hardcoded address <code>114.114.114.114</code></p>
<pre>private static final String CHN_PUBLIC_DNS_IP = "114.114.114.114";</pre>
<p>line 878: addresses used for DNS probe (to be covered in next part).</p>
<pre>public final String DEFAULT_URL = "http://www.google.com";
public final String DEFAULT_URL_CHINA = "http://www.qq.com";
public String DEFAULT_URL_STRING = "www.google.com";
public final String DEFAULT_URL_STRING_CHINA = "www.qq.com";</pre>
<p>This large class is mainly a state machine of the various WiFi states. The state hierarchy are defined, and initial state set, at lines 1185-1197.</p>
<pre>addState(this.mDefaultState);
addState(this.mNotConnectedState, this.mDefaultState);
addState(this.mConnectedState, this.mDefaultState);
addState(this.mCaptivePortalState, this.mConnectedState);
addState(this.mEvaluatedState, this.mConnectedState);
....
setInitialState(this.mNotConnectedState);</pre>
<p>The base class for the StateMachine can be found under AOSP source (<a href="https://cs.android.com/android/platform/superproject/+/master:frameworks/base/core/java/com/android/internal/util/StateMachine.java?q=StateMachine.java&amp;ss=android%2Fplatform%2Fsuperproject">StateMachine.java</a>).</p>
<p>When the device is connected to WiFi, it would enter <code>ConnectedState</code>.</p>
<p>line 1976 (under <code>processMessage()</code> of the initial <code>NotConnectedState</code>) would be invoked when a new WiFi connection is detected.</p>
<pre>wifiConnectivityMonitor.transitionTo(wifiConnectivityMonitor.mConnectedState);</pre>
<p>The <code>mConnectedState</code> variable is of class <code>ConnectedState</code>, defined from line 1988. The <code>enter()</code> method of <code>ConnectedState</code> contains the following code (from line 2090), which uses <code>CHN_PUBLIC_DNS_IP</code> (i.e. the Mainland Chinese controlled DNS server):</p>
<pre>if (WifiConnectivityMonitor.this.mWifiManager != null &amp;&amp; WifiConnectivityMonitor.this.inChinaNetwork()) {
    Message msg = new Message();
    msg.what = 330;
    Bundle args = new Bundle();
    args.putString("publicDnsServer", WifiConnectivityMonitor.CHN_PUBLIC_DNS_IP);
    msg.obj = args;
    WifiConnectivityMonitor.this.mWifiManager.callSECApi(msg);
}
</pre>
<p>From the code it seems to add the Mainland Chinese DNS service to the user’s list of DNS server automatically, when the device is connected to Chinese mobile network. There seems no option to disable the behaviour.</p>
<p><code>WifiConnectivityMonitor.inChinaNetwork()</code> is at line 11199.&nbsp; As suggested by its name, it should obtain the ISO code and return true only if the device is connected to a mobile network in China:</p>
<pre>public boolean inChinaNetwork() {
    String str = this.mCountryIso;
    if (str == null || str.length() != 2) {
        updateCountryIsoCode();
    }
    if (!isChineseIso(this.mCountryIso)) {
        return false;
    }
    if (!DBG) {
        return true;
    }
    Log.d(TAG, "Need to skip captive portal check. CISO: " + this.mCountryIso);
    return true;
}
</pre>
<p>Digging deeper, this is how the ISO code (<code>mCountryIso</code>) is obtained, under <code>updateCountryIsoCode()</code> at line 11219 (fallback skipped).</p>
<pre>public void updateCountryIsoCode() {
    if (this.mTelephonyManager == null) {
        try {
            this.mTelephonyManager = (TelephonyManager) this.mContext.getSystemService("phone");
        } catch (Exception e) {
            Log.e(TAG, "Exception occured at updateCountryIsoCode(), while retrieving Context.TELEPHONY_SERVICE");
        }
    }
    TelephonyManager telephonyManager = this.mTelephonyManager;
    if (telephonyManager != null) {
        this.mCountryIso = telephonyManager.getNetworkCountryIso();
        Log.i(TAG, "updateCountryIsoCode() via TelephonyManager : mCountryIso: " + this.mCountryIso);
    }
    /* fallback when there is no mobile network skipped. The fallback is to read the CountryISO setting from a Samsung config file (cscfeature.xml) */
    ....
}
</pre>
<p>(While not shown here, this code is also invoked when initializing and when change in ISO code of telephone network is detected, so it need not be called during each check.) The country code is get from <code>TelephonyManager.getNetworkCountryIso()</code> which is a standard Android API, documented <a href="https://developer.android.com/reference/android/telephony/TelephonyManager#getNetworkCountryIso()">here</a>. It returns the ISO-3166-1 alpha-2 country code equivalent of the MCC (Mobile Country Code) of the mobile operator. In Hong Kong, this is “HK”, and in Mainland China this is “CN”.</p>
<p>As one might suspect at this point, the problem lies in <code>isChineseIso()</code>, at line 11214:</p>
<pre>private boolean isChineseIso(String countryIso) {
    return "cn".equalsIgnoreCase(countryIso) || "hk".equalsIgnoreCase(countryIso) || "mo".equalsIgnoreCase(countryIso);
}</pre>
<p>This means that you are treated as being connected to a Chinese mobile network if you are connected to a Hong Kong mobile network for the purpose of adding the 114 DNS service.&nbsp; (BTW, “MO” is the ISO-3166-1 code for Macau.) Perhaps Samsung might want to address cases when people travel to Mainland China while forgetting to reset their hardcoded DNS settings, and kindly “add” a DNS service which works within the Great Firewall of China. But they seemed to forget that both Hong Kong and Macau are outside the Great Firewall, at least so far.</p>
<p>Back to the DNS setting code above (line 2090). It makes a binder call to <code>WifiManager.callSECApi()</code>, with message code = 330, with a <code>Bundle</code> setting <code>publicDnsServer</code> to our friend <code>114.114.114.114</code>. While <code>WifiManager</code> is a standard Android class the method <code>callSECApi()</code>, as suggested by its name, is Samsung specific.</p>
<p>The remote call to <code>WifiManager</code> would end up in the service class implementation at <code>com.android.server.wifi.WifiServiceImpl</code>, implementing WifiService, at <a href="https://github.com/headuck/SM-N9750-TGY/blob/main/com/android/server/wifi/WifiServiceImpl.java">WifiServiceImpl.java</a>. (The class is Samsung’s extension to the AOSP service class of the same …</p></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://blog.headuck.com/2020/10/12/samsung-phones-force-mainland-china-dns-service-upon-hong-kong-wifi-users/">http://blog.headuck.com/2020/10/12/samsung-phones-force-mainland-china-dns-service-upon-hong-kong-wifi-users/</a></em></p>]]>
            </description>
            <link>http://blog.headuck.com/2020/10/12/samsung-phones-force-mainland-china-dns-service-upon-hong-kong-wifi-users/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24816764</guid>
            <pubDate>Sun, 18 Oct 2020 10:20:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Optimizing the Timing of Brainwork]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24816412">thread link</a>) | @rajlego
<br/>
October 18, 2020 | https://supermemo.guru/wiki/Optimizing_the_timing_of_brainwork | <a href="https://web.archive.org/web/*/https://supermemo.guru/wiki/Optimizing_the_timing_of_brainwork">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="mw-content-text" lang="en" dir="ltr"><p><small>This text is part of: "<i><a href="https://supermemo.guru/wiki/Science_of_sleep" title="Science of sleep">Science of sleep</a></i>" by <a href="https://supermemo.guru/wiki/Piotr_Wozniak" title="Piotr Wozniak">Piotr Wozniak</a> (2017)</small>
</p>


<h2><span id="Optimizing_the_timing_of_brainwork">Optimizing the timing of brainwork</span></h2>
<p>Twice a day, we peak in intellectual performance. We can improve our productivity by understanding the <a href="https://supermemo.guru/wiki/Circadian_cycle" title="Circadian cycle">circadian cycle</a></p>
<h3><span id="Circadian_graph_and_brainwork">Circadian graph and brainwork</span></h3>
<p>Charting the <a href="https://supermemo.guru/wiki/Circadian_cycle" title="Circadian cycle">circadian cycle</a> makes it possible to find the best windows of time for brainwork. The <a href="https://supermemo.guru/wiki/Circadian" title="Circadian">circadian</a> graph below was generated with <a href="https://supermemo.guru/wiki/SleepChart" title="SleepChart">SleepChart</a> using a log of <a href="https://supermemo.guru/wiki/Free_running_sleep" title="Free running sleep">free running sleep</a>. In the graph, two yellow bands indicate the optimum time for brainwork. The exact timing may differ for each individual. However, the blocks can be easily determined:
</p>
<ol><li> <b>Morning block</b>: soon after waking, after morning coffee, or after breakfast. The best brain slot may last 2-4 hours. If you are sleepy in the morning see: <a href="https://supermemo.guru/wiki/Natural_creativity_cycle" title="Natural creativity cycle">Natural creativity cycle</a></li>
<li> <b>Evening block</b>: soon after <a href="https://supermemo.guru/wiki/Siesta" title="Siesta">siesta</a>. The second best brain slot may last 2-4 hours as well. If you do not nap, you may not fully benefit from that block (see: <a href="https://supermemo.guru/wiki/Power_nap" title="Power nap">Power nap</a>). If you are sleepy during this slot see: <a href="https://supermemo.guru/wiki/Best_time_for_napping" title="Best time for napping">Best time for napping</a></li></ol>
<p>The graph explains the reasons for which the two brainwork blocks emerge:
</p>
<div><p><a href="https://supermemo.guru/wiki/File:Circadian_graph_and_brainwork.gif" title="Optimizing the timing of brainwork with respect to the circadian cycle"><img alt="Optimizing the timing of brainwork with respect to the circadian cycle" src="https://supermemo.guru/images/thumb/e/ef/Circadian_graph_and_brainwork.gif/600px-Circadian_graph_and_brainwork.gif" width="600" height="454" srcset="https://supermemo.guru/images/e/ef/Circadian_graph_and_brainwork.gif 1.5x"></a></p></div>
<blockquote><i><b>Figure:</b> <b>Optimizing the timing of brainwork with respect to the <a href="https://supermemo.guru/wiki/Circadian_cycle" title="Circadian cycle">circadian cycle</a></b>. This graph was generated with the help of <a href="https://supermemo.guru/wiki/SleepChart" title="SleepChart">SleepChart</a> on the basis of 3-year-long daily measurements of a <a href="https://supermemo.guru/wiki/Free-running_sleep" title="Free-running sleep">free-running sleep</a> rhythm. The horizontal axis expresses the <a href="https://supermemo.guru/wiki/Circadian_phase" title="Circadian phase">number of hours from awakening</a> (note that the <a href="https://supermemo.guru/wiki/Free-running_sleep" title="Free-running sleep">free-running sleep</a> cycle period may be longer than 24 hours). <span>Light blue dots</span> are actual sleep episode measurements with timing on the horizontal, and the length on the left vertical axis. <b><a href="https://supermemo.guru/wiki/Homeostatic" title="Homeostatic">Homeostatic</a></b> sleepiness can roughly be expressed as the <b>ability to initiate sleep</b>. Percent of the initiated sleep episodes is painted as a thick <span>blue line</span> (right-side calibrations of the vertical axis). Adenosine-related <a href="https://supermemo.guru/wiki/Homeostatic_sleep_propensity" title="Homeostatic sleep propensity">homeostatic sleep propensity</a> increases in proportion to mental effort and can be partially cleared by caffeine, stress, etc. <b><a href="https://supermemo.guru/wiki/Circadian" title="Circadian">Circadian</a></b> sleepiness can roughly be expressed as <b>the ability to maintain sleep</b>. Average length of the initiated sleep episodes is painted as a thick <span>red line</span> (left-side calibrations of the vertical axis). Mid-day slump in alertness is also circadian, but is biologically different and results in short sleep that does not register as a red peak. <b>Sleep maintenance</b> circadian component correlates (1) negatively with core body temperature, <a href="https://en.wikipedia.org/wiki/ACTH">ACTH</a>, <a href="https://en.wikipedia.org/wiki/Cortisol">cortisol</a>, <a href="https://en.wikipedia.org/wiki/Catecholamine">catecholamines</a>, and (2) positively with: <a href="https://supermemo.guru/wiki/Melatonin" title="Melatonin">melatonin</a> and <a href="https://supermemo.guru/wiki/REM_sleep" title="REM sleep">REM sleep</a> propensity. <b>Optimum timing of brainwork</b> requires both (1) low <a href="https://supermemo.guru/wiki/Homeostatic" title="Homeostatic">homeostatic</a> sleepiness, and (2) low <a href="https://supermemo.guru/wiki/Circadian" title="Circadian">circadian</a> sleepiness. There are two high quality alertness blocks during the day: the first after the awakening, and the second after the <a href="https://supermemo.guru/wiki/Siesta" title="Siesta">siesta</a>. Both blocks are marked as <span>yellow</span> bands below the graph. For best learning, and for best <a href="https://supermemo.guru/wiki/Creativity" title="Creativity">creativity</a>, use these two <span>yellow blocks</span> of time. <a href="https://supermemo.guru/wiki/Caffeine" title="Caffeine">Caffeine</a> can only be used to enhance alertness early in the optimum brainwork window (<span>brown</span>). Later use will affect sleep (caffeine half-life is about six hours). Optimum timing of exercise is not marked as it may vary depending on the optimum timing of <a href="https://supermemo.guru/wiki/Zeitgeber" title="Zeitgeber">zeitgebers</a> (e.g. early morning for <a href="https://supermemo.guru/wiki/DSPS" title="DSPS">DSPS</a> people and evening for ASPS people). For more details see: <a href="https://supermemo.guru/wiki/Biphasic_life" title="Biphasic life">Biphasic nature of human sleep</a></i></blockquote>
<h3><span id="Best_brainwork_time">Best brainwork time</span></h3>
<p>The optimum timing of brainwork requires both high <a href="https://supermemo.guru/wiki/Homeostatic" title="Homeostatic">homeostatic</a> alertness and high <a href="https://supermemo.guru/wiki/Circadian" title="Circadian">circadian</a> alertness. There are two quality alertness blocks during the day: the first occurs after awakening and the second after the <a href="https://supermemo.guru/wiki/Siesta" title="Siesta">siesta</a> period. Both are marked as <span>yellow blocks</span> in the graph (above). For best learning and best creative results, use these yellow blocks for brainwork. <a href="https://supermemo.guru/wiki/Factors_that_affect_sleep#Caffeine" title="Factors that affect sleep"><span>Caffeine</span></a> can only be used to enhance alertness early in this optimum window. Later use will affect sleep (the half-life of caffeine is about six hours). The optimum timing of exercise may vary depending on your <a href="https://supermemo.guru/wiki/Factors_that_affect_sleep#Exercise" title="Factors that affect sleep">exercise</a> goals and the optimum timing of zeitgebers (e.g. early morning for <a href="https://supermemo.guru/wiki/DSPS" title="DSPS">DSPS</a> people and evening for <a href="https://supermemo.guru/wiki/Advanced_Sleep_Phase_Syndrome_(ASPS)" title="Advanced Sleep Phase Syndrome (ASPS)">ASPS</a> people). In this example, the <span>stress block</span> is followed by the <span>exercise block</span> to counterbalance the hormonal and neural effects of <a href="https://supermemo.guru/wiki/Factors_that_affect_sleep#Stress" title="Factors that affect sleep">stress</a> before the <a href="https://supermemo.guru/wiki/Siesta" title="Siesta">siesta</a> (see: <a href="https://supermemo.guru/wiki/Stress_valve" title="Stress valve">Stress valves</a>). Unmarked white areas can be used for the lunch (before siesta) and fun time unrelated to work in the evening at a time when the ascending <a href="https://supermemo.guru/wiki/Circadian" title="Circadian">circadian</a> sleepiness makes creative work ineffective. That white evening protective zone should be free from stress, <a href="https://supermemo.guru/wiki/Factors_that_affect_sleep#Alcohol" title="Factors that affect sleep">alcohol</a>, <a href="https://supermemo.guru/wiki/Factors_that_affect_sleep#Caffeine" title="Factors that affect sleep">caffeine</a>, etc. Recommended activities might include fun games, relaxation, TV, reading, family-time, DIY, housework, etc. For inveterate workaholics, less challenging and stress-free jobs might also work ok. 
</p>
<p><b>The best test for a well designed day is that all activities <a href="https://supermemo.guru/wiki/Pleasure_of_learning" title="Pleasure of learning">should be fun</a>!</b></p> 
<p>Brainwork is fun only if your brain is ready. Sleep is fun if you are ready. Rest and entertainment feel right only after a productive day. Even a bit of <a href="https://supermemo.guru/wiki/Stress_resilience" title="Stress resilience">stress</a> can be fun if it is properly dosed and timed. You do not need to be an adrenaline junkie to enjoy your stress and exercise slots. There is little exaggeration in saying that <b>a good understanding of the <a href="https://supermemo.guru/wiki/Circadian_cycle" title="Circadian cycle">circadian cycle</a> is the key to a happy and productive day!</b> (see: <a href="https://supermemo.guru/wiki/Formula_for_happy_life" title="Formula for happy life">Formula for happy life</a>).
</p>
<p>Happy and productive life is best achieved by adhering to the <a href="https://supermemo.guru/wiki/Circadian_cycle" title="Circadian cycle">circadian cycle</a></p>
<h3><span id="Natural_creativity_cycle">Natural creativity cycle</span></h3>
<p>In addition to the variables of the <a href="https://supermemo.guru/wiki/Circadian_cycle" title="Circadian cycle">circadian cycle</a>, the <a href="https://supermemo.guru/wiki/Natural_creativity_cycle" title="Natural creativity cycle">natural creativity cycle</a> employs the fact that the neocortex operates in several modes determined by local fatigue, <a href="https://supermemo.guru/wiki/Creativity" title="Creativity">creative meandering</a>, and <a href="https://supermemo.guru/wiki/Neural_optimization_in_sleep" title="Neural optimization in sleep">neural optimization in sleep</a>. During the day, natural transitions from high focus to distraction, to high creativity, and to rest will occur in proportion to the engagement of individual areas of the cortex. It will depend on the <a href="https://supermemo.guru/wiki/Concept_map" title="Concept map">concept maps</a> involved in the <a href="https://supermemo.guru/wiki/Mental_computation" title="Mental computation">mental computation</a>, and the overall neural activation. At night, the brain will proceed with natural <a href="https://supermemo.guru/wiki/Memory_optimization" title="Memory optimization">memory optimization</a> by sequentially switching between <a href="https://supermemo.guru/wiki/NREM" title="NREM">NREM</a> and <a href="https://supermemo.guru/wiki/REM" title="REM">REM</a> sleep modes.
</p>
<p>All brainwork should be based on self-regulation and natural transitions to high <a href="https://supermemo.guru/wiki/Creativity" title="Creativity">creativity</a> and/or rest. All forms of artificial control will increase the fatigue and reduce the productivity</p>
<p>For details see: <a href="https://supermemo.guru/wiki/Natural_creativity_cycle" title="Natural creativity cycle">Natural creativity cycle</a>
</p>
<h3><span id="Balanced_24_hour_cycle">Balanced 24 hour cycle</span></h3>
<p>The <span>slanting green line</span> separates the graph into the areas of phase advanced (right) and phase delays (left). The line is determined by points in the graph where the waking time (horizontal axis) added to the sleep time (left vertical axis) equals to 24.0 hours. The place where the <span>green breakeven line</span> crosses the <span>red sleep length line</span> determines the optimum balanced sleep cycle of 24 hours. In the presented example, 17.35 hours of waking, added to the expected 6.65 hours of sleep time complete a balanced full 24 hours sleep-wake cycle. The greater the angle between the <span>green</span> and <span>red</span> lines, the harder it is to balance sleep and fit it into the 24h cycle of the rotating earth. In the example, adding waking hours does not shorten sleep much enough to make the balance easy. This implies that a religious adherence to a 17.35 day may be necessary to balance the cycle. However, this shortened waking day may increase <a href="https://supermemo.guru/wiki/Sleep_latency" title="Sleep latency">sleep latency</a> and increase the probability of premature awakening, which can also tip the balance towards the phase delay. The <span>vertical aqua line</span> shows where the expected sleep time added to the waking time equals to 24 hours (crossover with the <span>green line</span> representing a perfect 24-hour day). In <a href="https://supermemo.guru/wiki/DSPS" title="DSPS">DSPS</a> or <a href="https://supermemo.guru/wiki/Advanced_Sleep_Phase_Syndrome_(ASPS)" title="Advanced Sleep Phase Syndrome (ASPS)">ASPS</a> that 24h balance may be hard to accomplish. For example, without medical intervention, only a large protective zone in the evening, early nap (or no nap), and intense morning exercise can help balance the day in <a href="https://supermemo.guru/wiki/DSPS" title="DSPS">DSPS</a>.
</p><p><b>Important!</b> This graph is based on data that is true solely for a free running sleep condition. If you use an alarm clock to regulate the timing of your sleep, these measurements and recommendations may not apply! In addition, the timing and amplitude of changes differ vastly between individuals!
</p>
<h2><span id="Sleeping_against_your_natural_rhythm">Sleeping against your natural rhythm</span></h2>
<p>If you sleep against your natural rhythm you will often experience tiredness or drowsiness that can be resolved by adjusting the sleeping hours. In healthy individuals, the daytime alertness is primarily determined by:
</p>
<ol><li> <a href="https://supermemo.guru/wiki/Two_components_of_sleep" title="Two components of sleep">circadian phase and homeostatic sleepiness</a></li>
<li> total sleep time the night before</li>
<li> <a href="https://supermemo.guru/wiki/Memory_optimization_in_sleep#NREM_and_memory" title="Memory optimization in sleep">amount of slow-wave sleep the night before</a></li>
<li> regular adherence to the sleep-wake schedule in preceding days</li>
<li> sleep deficits accumulated in the preceding days (e.g. <a href="https://supermemo.guru/wiki/How_do_we_fall_asleep%3F#REM_rebound_hypothesis" title="How do we fall asleep?">REM deficit</a>, SWA deficit, etc.)</li></ol>
<p>All those factors are closely associated with the sleep phase. <a href="https://supermemo.guru/wiki/Formula_for_good_sleep:_free_running_sleep" title="Formula for good sleep: free running sleep">Free running sleep</a> provides the best way to maximize alertness throughout a waking day. Free running sleep is likely to shift the minimum temperature point from the early morning closer towards the middle of the <a href="https://supermemo.guru/wiki/Subjective_night" title="Subjective night">subjective night</a>. You should notice <a href="https://supermemo.guru/wiki/Insomnia" title="Insomnia">increased sleepiness before going to sleep</a> and no <a href="https://supermemo.guru/wiki/Sleep_inertia" title="Sleep inertia">sleep inertia</a> upon awakening! If you cannot free-run your sleep, it is very important to understand the relationship between your <a href="https://supermemo.guru/wiki/Homeostatic" title="Homeostatic">homeostatic</a> and <a href="https://supermemo.guru/wiki/Circadian" title="Circadian">circadian</a> sleep drives as compiled in the table below. In the course of the day, you should move in sync between the yellow areas of the table, i.e. <a href="https://supermemo.guru/wiki/How_do_we_fall_asleep%3F#Sleep-wake_flip-flop" title="How do we fall asleep?">from perfect alertness to maximum sleepiness, and then back to perfect alertness</a>. The gray areas illustrate when your sleep falls out of sync:
</p>
<table>
<tbody><tr>
<td>
</td>
<td>High circadian sleepiness
</td>
<td>Low circadian sleepiness
</td></tr>
<tr>
<td>High homeostatic sleepiness
</td>
<td><b>Peak of the night</b>: You are very drowsy and fall into refreshing sleep with latency of less than five minutes
</td>
<td><b>Insomnia</b>: You are tossing and turning in bed. You are very tired but you cannot fall asleep. Your temperature, blood pressure and pulse are raised. Your thoughts are racing
<p><b>Solution</b>: Wait for the arrival of the <a href="https://supermemo.guru/wiki/Circadian" title="Circadian">circadian</a> phase. Delay going to sleep by 3-6 hours
</p>
</td>
</tr></tbody><caption>
</caption>
<tbody><tr><td>Low homeostatic sleepiness
</td>
<td><b>Hypersomnia</b>: You are drowsy throughout the day despite long sleep hours. Napping does not help. You show minimum energy levels. Your muscles are weak and atonic
<p><b>Solution</b>: Adjust your sleep phase to your <a href="https://supermemo.guru/wiki/Circadian" title="Circadian">circadian</a> (e.g. try to go to sleep 3-6 hours later)
</p>
</td>
<td><b>Peak of the day</b>: You are alert, energetic, and full of new ideas
</td></tr></tbody></table>

<!-- 
NewPP limit report
Cached time: 20201021203041
Cache expiry: 86400
Dynamic content: false
CPU time usage: 0.122 seconds
Real time usage: 0.132 seconds
Preprocessor visited node count: 107/1000000
Preprocessor generated node count: 243/1000000
Post‐expand include size: 10085/2097152 bytes
Template argument size: 3318/2097152 bytes
Highest expansion depth: 5/40
Expensive parser function count: 0/100
-->

<!-- 
Transclusion expansion time report (%,ms,calls,template)
100.00%   23.554      1 - -total
 40.05%    9.434      1 - File:Circadian_graph_and_brainwork.gif
 36.41%    8.576      1 - ArticleSleep
 26.12%    6.153      1 - Template:Fig
 16.65%    3.922      4 - Template:Important_note
 10.43%    2.456      6 - Template:=
-->

<!-- Saved in parser cache with key supermem_kool_kids:pcache:idhash:401-0!*!0!!en!5!* and timestamp 20201021203041 and revision id 21364
 -->
</div></div>]]>
            </description>
            <link>https://supermemo.guru/wiki/Optimizing_the_timing_of_brainwork</link>
            <guid isPermaLink="false">hacker-news-small-sites-24816412</guid>
            <pubDate>Sun, 18 Oct 2020 08:52:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Audio’s opportunity and who will capture it]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 19 (<a href="https://news.ycombinator.com/item?id=24815888">thread link</a>) | @hunglee2
<br/>
October 17, 2020 | https://www.matthewball.vc/all/audiotech | <a href="https://web.archive.org/web/*/https://www.matthewball.vc/all/audiotech">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page" role="main">
        
          <article data-page-sections="5d8e94500fa50d2aaaa7c406" id="sections">
  
    <section data-section-id="5d8e94500fa50d2aaaa7c408" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
&quot;imageOverlayOpacity&quot;: 0.15,
&quot;video&quot;: {
  &quot;playbackSpeed&quot;: 0.5,
  &quot;filter&quot;: 1,
  &quot;filterStrength&quot;: 0,
  &quot;zoom&quot;: 0
},
&quot;backgroundWidth&quot;: &quot;background-width--full-bleed&quot;,
&quot;sectionHeight&quot;: &quot;section-height--medium&quot;,
&quot;customSectionHeight&quot;: 10,
&quot;horizontalAlignment&quot;: &quot;horizontal-alignment--center&quot;,
&quot;verticalAlignment&quot;: &quot;vertical-alignment--middle&quot;,
&quot;contentWidth&quot;: &quot;content-width--wide&quot;,
&quot;customContentWidth&quot;: 50,
&quot;sectionTheme&quot;: &quot;&quot;,
&quot;sectionAnimation&quot;: &quot;none&quot;,
&quot;backgroundMode&quot;: &quot;image&quot;
}" data-animation="none">
  
  <div>
    <div>
      
      
      
      <div data-content-field="main-content" data-item-id="">
  <article id="article-">
  
    <div>
      

      <div>
        <div><div data-layout-label="Post Body" data-type="item" id="item-5f88a99f19d4cd6d64631928"><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1602791840799_3755"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1602792859307-U0J0NC5X6RECD3KT88YX/ke17ZwdGBToddI8pDm48kM4_kVKk9l_w74w-snZK7Fx7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0sfmLVeynSYYXBTMYB-wzcE4Rlu1L95vgCX6mg-kkKYPXXkbScjoF_1N2dt8jg_pvQ/Edison.png" data-image="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1602792859307-U0J0NC5X6RECD3KT88YX/ke17ZwdGBToddI8pDm48kM4_kVKk9l_w74w-snZK7Fx7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0sfmLVeynSYYXBTMYB-wzcE4Rlu1L95vgCX6mg-kkKYPXXkbScjoF_1N2dt8jg_pvQ/Edison.png" data-image-dimensions="2500x1456" data-image-focal-point="0.5,0.5" alt="Edison.png" data-load="false" data-image-id="5f88ad99ea51f67834f2495a" data-type="image" src="https://www.matthewball.vc/all/Edison.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-ff1f1677bf36496f03d8"><div><p>As most of the major media categories — music, video and video games — have existed for decades, we tend to forget that media is technology. Instead, we think of technology as being used to express media, rather than media itself. Spotify, for example, is an <em>internet</em> <em>streaming </em>music service, while iTunes is a <em>download </em>music service, SiriusXM is <em>satellite</em> <em>broadcast</em> music service, and radio is a <em>terrestrial broadcast</em> technology. This focus on delivery ignores the classic definition of media: “<span>outlets</span> or <span>tools</span> used to <span>store</span> and <span>deliver</span> information or data.”</p><p>While the above might seem preoccupied with theory and philosophy, all analysis of the past and future of a given media category must start from the fact that media is technology. This is because technology not only enables content categories, it defines their business models and shapes the content, too. And as we know, technology is in a constant process of change. </p><p><strong>Chapter 1: How Technology Created Recorded Media, Then Continually Redefined It</strong></p><p>Music offers a great view into the interplay between technology, business model and content. Consider the following triptych, which covers seven decades, two decades and one year, respectively.&nbsp;</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1602797899091_5458"><div><p>&nbsp;When the flat record first emerged in the 1850s, it standardized around the 78. The 78 (as in 78 rotations per minute) came in a 10-inch version that held three minutes of music and a 12-inch version that held four. This meant that after centuries of variability, music suddenly had a defined run-time.&nbsp;</p><p>This length was reaffirmed by the first mass market standard for consumer media: the 45 RPM vinyl single, which launched in 1948 and held roughly three minutes. The music industry coalesced around this format (and its runtime) for a variety of tech-based reasons. The 45 was far cheaper for consumers than a 78 album, which was important given the high cost of record players and the ubiquity of free (singles-focused) radio. The 45’s cost advantage also meant it was the primary way labels delivered singles to thousands of radio stations across the country for local airplay. In addition, RCA quickly figured out how to make a stackable version of 45s, which was important to jukebox manufacturers. The rise of the 45 naturally led the length of the average song to decline; a four-minute song simply couldn’t fit on the most important audio format in the world.</p><p>As the physical and financial limitations of the 78 and 45 were relieved, and the far more flexible cassette and CD emerged, the length of the average single grew rapidly, adding nearly two minutes (or 78%) from 1959 to 1992. Still, almost all tracks conformed to the three-to-four minute standard. After decades, the West had become used to the idea that a song was roughly between three minutes and 20 seconds and four minutes and 10 seconds long.</p><p>On its surface, the shift to digital audio should have led to further increases in song length. After all, there was no longer any limitation to run-time. However, the reverse occurred. Technology might have relaxed its grip on music’s length, but it had strengthened its hold on business models.</p><p>As is well known, iTunes unbundled the physical album in individually downloadable (and bought) tracks. But in doing so, it penalized artists for bundling a multi-part song into a single track. Pink Floyd’s decision to split the 26-minute and nine-part Shine on You Crazy Diamond into two discrete tracks didn’t matter in 1975; all nine parts fit on a single record and no one wanted to buy just a single half let alone a single part. But in 2005, such a move could mean missing out on 75% of revenues — why sell two things when you could sell nine? And why would a consumer buy an entire $10 album if all they wanted was two $1 portions of Shine on You Crazy Diamond? These incentives naturally led to artists that were publishing new music to split their longer/multi-section songs into separate — and shorter — preludes, interludes and segments.</p><p>This behaviour has been greatly exacerbated by the advent of a new and even more disruptive digital music technology: on-demand streaming. While iTunes was technically innovative, its business model was not. Consumers, after all, primarily owned copies of individual tracks in the 1950s and 1960s. Spotify and Apple Music, meanwhile, meant consumers adopted not just a new music technology, but also bought an entirely different product: ongoing access to all music ever created.</p><p>But as technology has shifted consumers away from discrete and attributable transactions (buying record A on date B) to ongoing and general ones (subscribing to service C in perpetuity), musical talent needed a new compensation model. Spotify, therefore, decided to pay talent as and to the degree consumers listened to their works. Matching revenue with usage is intuitive, but it was never before possible in music. There was no way to track at-home record spins or CD plays, let alone charge for them. Nor was it practical for iTunes to ask users to download an individual song to their devices and pay several pennies per play when they later synched their iPod to iTunes. (This would have been rife with abuse, too.)</p><p>Engagement-based monetization is arguably more fair. Consider, for example, that the Beatles’ <em>Yesterday </em>and Psy’s <em>Gangnam Style</em> would each generate $1 when sold on iTunes, even if the former was played 2,000 times over ten years and the latter 30 times in the month it was bought and then never again. But the more that business models change, the more that incentives and content change, too.</p><p>To support engagement-based monetization, Spotify and its label suppliers had to define engagement. And they chose to do this on a per stream basis with a minimum stream time of 30 seconds (to avoid accidental plays, track skipping, etc.). However, this meant that a 10-minute track, five-minute track and 31-second track generated the same royalties.&nbsp;</p><p>So as the music industry has transitioned the majority of its revenues from CDs and downloads to streaming, major artists have relentlessly shortened and split their tracks. Why release a five-minute song if you can make it a two and a half-minute song that’s played twice? Or two different two and a half-minute songs? This meant artists had yet another reason to reduce track lengths</p><p>All of this helps to explain the extraordinary success of the 2019’s top track, <em>Old Town Road </em>by Lil Nas X, which is also Billboard’s longest running #1 ever, at 19 consecutive weeks. While the song is awesome, it’s also only one minute and 53 seconds — roughly half of 2019’s average song length. This means that four minutes of listening generated two times the average revenue and charting lift of every other hit song that year.</p><p><em>Old Town Road </em>isn’t an exception, either. Up until 2017, Billboard’s Hot 100 Chart has never had a year with more than 2% of its charting tracks shorter than two minutes and 30 seconds (most years had none). In the past three years, this sum has skyrocketed to over 12%, or roughly one in every eight tracks.</p><p>Notably, labels are also encouraging artists to simplify the name of their songs and albums in order to ensure they’re optimized for voice-controlled speakers and touchscreen-based searches. A track with five words is more likely to be misunderstood or suffer from autocorrect than one with two. Similarly, voice assistants are known to struggle with <a href="https://www.wired.com/2017/03/voice-is-the-next-big-platform-unless-you-have-an-accent/">accents</a>, such as Irish or even Texan. Being hard to say means you might not get played.</p><p><em>Old Town Road </em>isn’t the first time technology made a hit. In fact, the modern day dominance of rap and R&amp;B comes from how changes in technology – not for delivery, but sales recognition –&nbsp; afforded Lil Nas X the opportunity to top the charts in the first place.</p><p>Prior to the 1990s, Black artists and music fans had spent decades arguing the record industry conspired against “urban contemporary” music by refusing it radio play and ignoring its sales. It took only five weeks after Billboard adopted SoundScan, a computerized sales database, to prove this theory right.</p><p>Until 1991, Billboard charts weren’t based on actual unit sales or radio play. Instead, it was assembled using (white) retail clerk estimates of what was selling best and what (white) DJs considered to be “<a href="https://www.washingtonpost.com/archive/lifestyle/1991/06/19/charting-soundscans-shake-up/3b8187fb-2332-4096-95e9-1f8db7b66b2e/">hottest</a>” each week. According to <em>The Atlantic</em>, both groups had<a href="https://www.washingtonpost.com/archive/lifestyle/1991/06/19/charting-soundscans-shake-up/3b8187fb-2332-4096-95e9-1f8db7b66b2e/"> reasons to lie</a>. For example, labels would pressure radio stations to favour “hand-picked hits” if they wanted to keep receiving the newest single on time (stations sometimes<a href="https://en.wikipedia.org/wiki/Payola"> received bribes to play specific tracks</a>, too). Meanwhile, labels would force inventory on their retailers, who would then overreport sales to convince music fans to buy excess inventory.</p><p>Naturally, those who ran the music industry saw little need to overhaul how it worked. And thus while the book and film industries had shifted to computerized sales databases in the 1980s, not one of the top six record distributors signed onto SoundScan before its release in June 1991. But this resistance didn’t stop N.W.A.’s <em>N***az4life</em> from debuting #2 on the Billboard Top 100 the very next month under SoundScan. This was the highest charting performance in rap history – and happened without any radio airplay, music video airings on MTV, or a concert tour. The failings of the old honour system were further demonstrated by the fact that N.W.A. debuted at only #21 on Billboard’s R&amp;B chart, which wasn’t yet on SoundScan. Somehow it was possible that <em>N***az4life</em> was the second biggest album in the country by units purchased, but 21st in its own genre when it came to what was “selling” and “hottest.” One week after it’s release, the album hit #1 on the Billboard chart (displacing R.E.M) as hundreds …</p></div></div></div></div></div></div></div></div></article></div></div></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.matthewball.vc/all/audiotech">https://www.matthewball.vc/all/audiotech</a></em></p>]]>
            </description>
            <link>https://www.matthewball.vc/all/audiotech</link>
            <guid isPermaLink="false">hacker-news-small-sites-24815888</guid>
            <pubDate>Sun, 18 Oct 2020 06:22:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fun with Combinators]]>
            </title>
            <description>
<![CDATA[
Score 70 | Comments 16 (<a href="https://news.ycombinator.com/item?id=24815859">thread link</a>) | @headalgorithm
<br/>
October 17, 2020 | https://doisinkidney.com/posts/2020-10-17-ski.html | <a href="https://web.archive.org/web/*/https://doisinkidney.com/posts/2020-10-17-ski.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
            <h2>Fun with Combinators</h2>

            <p>
    Posted on October 17, 2020
</p>





<p>There are a bunch of “minimal” computational models out there: Turing machines, lambda calculus, PowerPoint <span data-cites="wildenhainTuringCompletenessMS2017">(Wildenhain <a href="#ref-wildenhainTuringCompletenessMS2017" role="doc-biblioref">2017</a>)</span>, etc. These are radically simple languages which are nonetheless Turing complete, so theoretically “as powerful” as each other. Of those, lambda calculus is without question my favourite to actually write programs in: it’s the one which is closest to crawling out of the <a href="https://en.wikipedia.org/wiki/Turing_tarpit">Turing tarpit</a>.</p>
<p>In terms of implementation, though, it is <em>far</em> from simple. Lambda calculus has <em>variables</em>, which introduce huge complexity into the interpreter: especially if you want to do any kind of formal reasoning about programs, this complexity is a problem. We might want to reach for something even lower-level than lambda calculus: this is where combinator calculi come in.</p>
<p>You may have heard of SKI combinator calculus: it’s the “simplest” of the calculi, but it’s not actually very easy to understand, and it’s absolute murder to try use. So we’re going to start with <code>BCKW</code>, a more obscure calculus, actually invented by Haskell Curry.</p>
<p>There are 4 combinators in <code>BCKW</code>: <code>B</code>, <code>C</code>, <code>K</code>, and <code>W</code> (shocking, I know). You can think about these combinators as functions which manipulate the beginning of strings:</p>
<pre><code>Bxyz ~&gt; x(yz)
Cxyz ~&gt; xzy
Kxy  ~&gt; x
Wxy  ~&gt; xyy</code></pre>
<p>Let’s work with some examples to get a sense for how these combinators work.</p>
<p>Upper case letters are combinators, lower-case are variables. Yes, yes, I know I said that combinator calculi didn’t need variables, and it doesn’t! I’m just using them here to explain how each of the combinators work. If you really want to be pedantic you can think of the lower case letters as notational placeholders meaning “any given combinator”. They won’t exist in any actual programs we write.</p>
<p>The simplest combinator is <code>K</code>: it’s actually equivalent to the <code>const</code> function from Haskell. It discards its second argument, and returns the first. If you give a combinator more arguments than it usually accepts, you just keep the extra arguments in the output:</p>
<pre><code>Kxyz ~&gt; xz</code></pre>
<p><code>W</code> is the next combinator: it <em>duplicates</em> its second argument.</p>
<pre><code>Wxy ~&gt; xyy</code></pre>
<p>We always start from the <em>left</em>, applying the rule for the left-most combinator first.</p>
<pre><code>WKxyz ~&gt; Kxxyz ~&gt; xyz
KWxyz ~&gt; Wyz   ~&gt; yzz</code></pre>
<p>Next we have <code>C</code>: this is equivalent to the Haskell function <code>flip</code>. It swaps the second and third arguments:</p>
<pre><code>Cxyz ~&gt; xzy</code></pre>
<p>Here’s a small little evaluator for expressions which use <code>C</code>, <code>K</code>, and <code>W</code>. You can edit the expression, and press enter to step through it.</p>



<p>The last combinator introduces parentheses, and it’s equivalent to function composition.</p>
<pre><code>Bxyz ~&gt; x(yz)</code></pre>
<p>You can write parentheses yourself: implicitly, all expressions are left-associative. That means that the following are all equal:</p>
<pre><code>xyz = (xy)z = (x)yz = ((x)y)z</code></pre>
<p>But <code>xyz</code> is <em>not</em> equal to, say, <code>x(yz)</code>.</p>
<p>And here’s a puzzle to start flexing your combinator skills: one of the combinators in SKI combinator calculus is <code>I</code>, which is the identity function.</p>
<pre><code>Ix ~&gt; x</code></pre>
<p>Try write an expression which functions the same way as <code>I</code>, using only the <code>BCKW</code> combinators. Use the following evaluator to try and figure out how to do it: write an expression after <code>λ&gt;</code> which functions the same as <code>I</code>.</p>



<details>
<summary>Answer</summary> <code>CK</code> followed by any combinator will do the trick. So <code>CKB</code>, <code>CKK</code>, <code>CKC</code>, etc.
<pre><code>I = CKC</code></pre>
Update 19/10/2020: A few people have pointed out (<a href="https://www.joachim-breitner.de/">Joachim Breitner</a> was the first) that there is a shorter solution to this problem: <code>WK</code>. I tend to prefer solutions that don’t include <code>W</code>, since then we’re working in a subset of the language that is both terminating and affine; although in this case the reason I didn’t mention <code>WK</code> is that I just didn’t find it myself.
</details>

<p>Each of the combinators we’ve defined so far work a little weird: they seem to skip over their first argument, and work on their second. Indeed, there is another, equivalent combinator calculus which doesn’t have this peculiarity:</p>
<pre><code>Bxyz ~&gt; x(yz)
Axy  ~&gt; y
Mx   ~&gt; xx
Txy  ~&gt; yx</code></pre>
<p><code>B</code> stays the same in this calculus, but the rest of the combinators get switched out for seemingly simpler versions. <code>K</code> goes to <code>A</code><a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a>:</p>
<pre><code>Axy ~&gt; y
Kxy ~&gt; x</code></pre>
<p>Which isn’t a huge change. It’s the other two where we see the real difference. <code>W</code> has been swapped out for <code>M</code>:</p>
<pre><code>Wxy ~&gt; xyy
Mx  ~&gt; xx</code></pre>
<p>As you can see <code>W</code> basically does the same thing as <code>M</code>, but while passing through its first argument. The difference between <code>T</code> and <code>C</code> is similar:</p>
<pre><code>Cxyz ~&gt; xzy
Txy  ~&gt; yx</code></pre>
<p>So, first of all, it is pretty simple to show that <code>BCKW</code> contains all of the <code>BAMT</code> combinators. Try find a way to write <code>T</code> using only <code>BCKW</code> combinators (hint: you might want to use your previous answer for writing <code>I</code> using <code>BCKW</code>).</p>



<details>
<summary>Answer</summary> So in fact all of the changed <code>BAMT</code> combinators can be encoded using <code>BCKW</code> by putting <code>I</code> (or <code>CKC</code> or what have you) after the corresponding <code>BCKW</code> combinator. In other words:
<pre><code>T = CI = C(CKC)
A = KI = K(CKC)
M = WI = W(CKC)</code></pre>
</details>
<p>It’s pretty easy to go from <code>BCKW</code> to <code>BAMT</code>, then. However, it’s <em>extremely</em> difficult to go the other way. Here, try to write <code>K</code> in terms of <code>BAMT</code> (this is quite difficult, do not expect to get it!):</p>



<details>
<summary>Answer</summary> Either of the following would work:
<pre><code>B(TA)(BBT)
B(B(TA)B)T</code></pre>
</details>
<p>So this is why we will stick to <code>BCKW</code> for the time being: <code>BAMT</code> is just too painful to use.</p>

<p>One of the things <code>BCKW</code> has over <code>SKI</code> is that each combinator represents a concrete capability. <code>K</code> and <code>W</code> especially: without these combinators, we can neither duplicate nor discard variables. This makes the languages without one or both of these interesting (albeit not Turing-complete).</p>
<p>If we say that we can’t use <code>W</code>, we know that the will not duplicate any input. In fact, encoded appropriately, we know that the program can only decrease its size through execution. The <code>BCK</code> system is in fact an encoding of <em>affine</em> logic, which is all the rage nowadays. Rust uses affine types to guarantee memory safety: by preventing duplication of references, you can know that whenever you’re looking at a variable you’re free to modify it, or destroy it if necessary (obviously Rust is a bit more complex than what I’ve described here, but <code>BCK</code> is indeed the fundamental basis for the system in the same way that <code>SK</code> can be the basis for any programming language).</p>
<p>If we remove <code>K</code> as well we have a <em>linear</em> language. This is even more restrictive, but is also quite actively researched at the moment: linear types have been used to construct languages for differential privacy, for instance.</p>
<p>There’s one small issue with <code>BC</code>: it doesn’t (strictly speaking) have an equivalent to <code>I</code>. You can write an expression which is <em>close</em>, but it will only actually compute when applied to at least 3 arguments. See if you can find it.</p>



<details>
<summary>Answer</summary>
<pre><code>BCC</code></pre>
</details>
<p>Usually we add <code>I</code>, though, to give us <code>BCI</code>.</p>

<p><code>S</code> is the only combinator we haven’t seen yet. It’s kind of a combination of <code>B</code>, <code>C</code>, and <code>W</code>:</p>
<pre><code>Sxyz ~&gt; xz(yz)</code></pre>
<p>It does parenthesising, reordering, <em>and</em> duplication. This allows it to be powerful to be Turing complete only with the addition of <code>K</code>. Try first to construct <code>I</code> given only <code>S</code> and <code>K</code>:</p>



<details>
<summary>Answer</summary> <code>SK</code> followed by any combinator will suffice.
<pre><code>I = SKK = SKS</code></pre>
</details>
<p>And now construct <code>S</code> from <code>BCKW</code>:</p>



<details>
<summary>Answer</summary>
<pre><code>S = B(BW)(BBC) = B(B(BW)C)(BB)</code></pre>
</details>
<p>Of course, to show that <code>SK</code> is universal we’d need to show that it contains one of the other universal systems. We won’t do that exhaustively here, but first just try to figure out <code>B</code> and <code>W</code>:</p>



<details>
<summary>Answer</summary>
<pre><code>B = S(KS)K</code></pre>
</details>



<details>
<summary>Answer</summary>
<pre><code>S = SS(SK) = SS(KI)</code></pre>
</details>

<p>The next task is to encode the <code>Y</code> combinator. This is a combinator that evaluates to the following:</p>
<pre><code>Yf ~&gt; f(Yf)</code></pre>
<p>As you can see, it encodes <em>recursion</em>. Like the <code>fix</code> function in Haskell, this combinator allows us to do recursion without explicit self-reference. And, of course, we can define this combinator using the combinators we’ve seen before, since our language is Turing complete. One encoding is <code>BM(CBM)</code>:</p>



<p>As you can see, <code>BM(CBM)</code>, when applied to <code>f</code>, yields <code>f(M(CBMf))</code>, which is equivalent to <code>f(BM(CBM)f)</code> (the <code>B</code> just hasn’t been applied inside the <code>f</code>). So this is indeed a proper recursion combinator.</p>

<p>Let’s try doing a little bit of programming with these combinators now.</p>
<p>In the lambada calculus, to encode numbers we often use the <em>church</em> numerals: that’s what we’re going to do here, too. A church numeral representing some number <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math> is a function which takes two arguments, and applies the first argument to the second <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math> times. Here are some church numerals in Haskell:</p>
<pre><code>zero :: (a -&gt; a) -&gt; a -&gt; a
zero f x = x

one :: (a -&gt; a) -&gt; a -&gt; a
one f x = f x

two :: (a -&gt; a) -&gt; a -&gt; a
two f x = f (f x)

three :: (a -&gt; a) -&gt; a -&gt; a
three f x = f (f (f x))</code></pre>
<p>Encoding these numerals in combinators is a little more difficult. Zero and one are obvious: they are <code>A</code> and <code>I</code>, respectively. Try to figure out two and three:</p>



<details>
<summary>Answer</summary><code>WB</code>
</details>



<details>
<summary>Answer</summary><code>SB(WB)</code>
</details>
<p>It turns out that it’s pretty easy to encode numbers in a relatively small amount of space, using a binary encoding. First, multiplication on Church numerals is simply composition: so that’s <code>B</code> on our combinators. We already have 2 defined, so the next thing we need for a binary encoding is a successor function. And we know what <em>that</em> is, from the answer to 3!</p>
<p>This means we can encode normal number in <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathvariant="script"><mi>𝒪</mi></mstyle><mo stretchy="false" form="prefix">(</mo><mo>log</mo><mi>n</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{O}(\log n)</annotation></semantics></math> space (although it still takes linear time to evaluate). The following repl allows for numbers:</p>


<p>We could take up even less space if we allowed for non-normal forms. 4, for instance, could be encoded like so:</p>
<pre><code>M(WB)</code></pre>
<p>But we generally prefer to keep our encodings in normal form: otherwise there’s some extra evaluation we have to pay for when we go to use them.</p>

<p>Once upon a time SKI combinators were used as a target for functional compilers: Miranda, Haskell’s precursor, compiled down to a set of combinators which included <code>SKI</code>. Nowadays, Haskell is compiled to the “spineless tagless G-machine”: its compilation technique took over from combinators in the late 80s, and has been the dominant form since. Apparently the reason is that, on the current architecture of most computers, combinator-based compilation targets just aren’t fast enough. They generate too much garbage: as a result, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://doisinkidney.com/posts/2020-10-17-ski.html">https://doisinkidney.com/posts/2020-10-17-ski.html</a></em></p>]]>
            </description>
            <link>https://doisinkidney.com/posts/2020-10-17-ski.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24815859</guid>
            <pubDate>Sun, 18 Oct 2020 06:15:16 GMT</pubDate>
        </item>
    </channel>
</rss>
