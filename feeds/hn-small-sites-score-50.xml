<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sat, 07 Nov 2020 00:51:29 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sat, 07 Nov 2020 00:51:29 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Account Takeover via IDOR in Starbucks Singapore]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24995657">thread link</a>) | @eshanaswar
<br/>
November 4, 2020 | http://www.kamilonurozkaleli.com/posts/starbucks-singapore-account-takeover/ | <a href="https://web.archive.org/web/*/http://www.kamilonurozkaleli.com/posts/starbucks-singapore-account-takeover/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<h3 id="recon"><strong>Recon</strong></h3>
<p>While browsing Starbucks Singapore, I noticed a page loaded with content from a 3rd party site. Let’s call this site <em>example.com</em> in order not to disclose it. When I did some research on this site, I saw the same login page on <em>card.starbucks.com.sg</em> in the directory example.com/starbucks, and at this point I had two possibilities.</p>
<ol>
<li>This application can be an environment where current developments of <em>card.starbucks.com.sg</em> are made and tested.</li>
<li>Or it may have been used as an old test environment and is in an idle state.</li>
</ol>
<p>Both possibilities increased the probability of a bug here, but the main problem is that I did not know whether a bug I will find here would affect the production environment. To understand this, I created a user account at card.starbucks.com.sg and tried to log into example.com/starbucks with this account. BINGO! I was able to successfully login with the account I just created. Both applications seemed to be using the same authentication mechanism.</p>
<p><img src="http://www.kamilonurozkaleli.com/images/starbucks-1.png" alt="Scheme-1, both applications are using same database table."></p>
<h3 id="exploitation"><strong>Exploitation</strong></h3>
<p>From this point I browsed example.com/starbucks and discovered an endpoint which does not exist in the production app. The POST data this endpoint received was as follows.</p>
<p><code>email=hacker@hacker.com</code></p>
<p>When I write the email address of the account I want to takeover in the email parameter here and send a request, I saw the partial information of the account belonging to that email address on my profile page. I could not fully takeover the account yet, and my password change request was not successful due to the invalid CSRF token generated in this application.</p>
<p>To get around this, I copied the PHPSESSID cookie value from example.com/starbucks to card.starbucks.com.sg and BOOM! I was able to see all the information belongs to victim in the production environment, the valid CSRF tokens generated here allowed me to change the password and I was able to completely takeover an account whose e-mail address I know.</p>
<h3 id="impact"><strong>Impact</strong></h3>
<p>Except for seeing all personal information belonging to users and completely taking over the accounts, if there is a loaded credit in the user account, these credits can be spent in Starbucks stores via the mobile application.</p>
<h3 id="multiplying-the-reward"><strong>Multiplying the Reward</strong></h3>
<p>I came across two other test environments on example.com. Let’s call them <em>example.com/starbucks2</em> and <em>example.com/starbucks3</em>. With my account at card.starbucks.com.sg, I was not able to login to either test environment. example.com/starbucks2 did not allow me to create a new account, so I tried my luck at example.com/starbucks3 and successfully created a new account. Things get a little complicated here, I will try to explain it as simply as possible.</p>
<p>I think the applications example.com/starbucks2 and example.com/starbucks3 were using test tables, so users in production could not login in these applications.</p>
<p>With the account I created at example.com/starbucks3, I was able to log in to example.com/starbucks2, but not card.starbucks.com.sg. However, the PHPSESSID I copied from example.com/starbucks2 was valid on card.starbucks.com.sg and I could use that account. Considering all the scenarios, I created a chain here as follows:</p>
<ol>
<li>Create a dummy account with the victim’s email address at example.com/starbucks3. (Add to testusers table.)</li>
<li>At example.com/starbucks2, associate the account for that email with your own account via the same endpoint. (Associate the PHPSESSID with the email in the testusers table.)</li>
<li>Copy the PHPSESSID to card.starbucks.com.sg and takeover. (Takeover the real account of the same email address in the production users table.)</li>
</ol>
<p><img src="http://www.kamilonurozkaleli.com/images/starbucks-2.png" alt="Scheme-2, relations between applicaitons and tables."></p>
<p>May 17th - Report Submitted<br>
May 18th - Triaged<br>
May 20th - Rewarded $4000 bounty<br>
Jun 17th - Rewarded $2000 bounty as 1.5x multiplier</p>

		</div></div>]]>
            </description>
            <link>http://www.kamilonurozkaleli.com/posts/starbucks-singapore-account-takeover/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24995657</guid>
            <pubDate>Thu, 05 Nov 2020 04:27:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GitHub Source Code Leak]]>
            </title>
            <description>
<![CDATA[
Score 719 | Comments 258 (<a href="https://news.ycombinator.com/item?id=24994746">thread link</a>) | @resynth1943
<br/>
November 4, 2020 | https://resynth1943.net/articles/github-source-code-leak/ | <a href="https://web.archive.org/web/*/https://resynth1943.net/articles/github-source-code-leak/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="content">
		
		<p>What do Microsoft <i>really</i> think about open-source?</p>

		<p><strong>Update</strong>: according to multiple online sources, the leaked source code was from GitHub <em>Enterprise</em>, not the version hosted at <a href="http://github.com/">GitHub.com</a>. While a substantial amount of code is shared between the two, they do have some differences.</p>
<p>The entirety of the confidential source code used by GitHub Enterprise has just been leaked to the public.</p>
<p>In a suspicious <a href="https://web.archive.org/web/20201104050026if_/https://github.com/github/dmca/tree/565ece486c7c1652754d7b6d2b5ed9cb4097f9d5">commit</a> to the <a href="https://github.com/github/dmca">official GitHub DMCA repository</a>, an unknown individual uploaded the confidential source code, impersonating Nat Friedman using a bug in GitHub's application.</p>
<p>At the heart of open-source, GitHub has long been criticised for keeping its source code private. The platform hosts millions of open-source projects, and critics say GitHub's position is somewhat hypocritical.</p>
<p>However, this raises questions around the security of GitHub's source code, and whether or not GitHub have anything to lose, if they do plan to release the source code in a public setting.</p>
<p>Some worry this will damage the overall security of GitHub, and this may be true. Commonly, closed-source applications perform "security by obscurity". This means the source code is hidden, with the intention of concealing security risks.</p>
<p>Since Microsoft's <a href="https://www.theverge.com/2018/10/26/17954714/microsoft-github-deal-acquisition-complete">acquisition of GitHub</a> in 2018, Microsoft have repeatedly emphasised their "love" for open-source. We have seen this through repeated commercial advertisements, which aim to place Microsoft at the forefront of open-source development.</p>
<p>Some users, such as Drew DeVault, suggest Microsoft is attempting to <a href="https://drewdevault.com/2020/08/27/Microsoft-plays-their-hand.html">centralise open-source</a>. Through closed-source applications, and proprietary extensions to Git, GitHub is seen as a platform that tries to <em>contain</em> open-source. An example of this is when <a href="https://www.theverge.com/2020/6/29/21306674/github-down-errors-outage-june-2020">GitHub went offline for two hours</a>, leaving thousands of open-source projects inaccessible and unusable.</p>
<p>GitHub is, in many ways, the Google of open-source development.</p>
<p>Perhaps GitHub as 12 years late in finally revealing their source code to the public; and maybe this is just what we need. <a href="https://mastodon.tedomum.net/@resynth1943">What do you think?</a></p>


		<!-- Doing a little experiment here. -->
		<p aria-disabled="true">resynth1943.article</p>
	</div></div>]]>
            </description>
            <link>https://resynth1943.net/articles/github-source-code-leak/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24994746</guid>
            <pubDate>Thu, 05 Nov 2020 01:10:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Anatomy of a Binary Executable]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24994522">thread link</a>) | @WalterSobchak
<br/>
November 4, 2020 | https://oswalt.dev/2020/11/anatomy-of-a-binary-executable/ | <a href="https://web.archive.org/web/*/https://oswalt.dev/2020/11/anatomy-of-a-binary-executable/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

            <div>
                <h3>Anatomy of a Binary Executable</h3>
                
                    <p><em></em>
                        <span>Wed, Nov 4, 2020</span>
                        <em></em>
                        <span>23-minute read</span>
                    </p>
                
            </div>

            <p>Even though I’ve developed software for a number of years now, there’s one question that has always been in the back of my mind and I haven’t had the time or patience to really answer, until now: <strong>What <em>is</em> a binary executable anyways?</strong></p>
<p>For this example, I wrote a brutally simple Rust program that includes a function “<code>sum</code>” to add two integers together, and am invoking it from <code>main()</code>:</p>
<div><pre><code data-lang="rust"><span>fn</span> <span>main</span>() {
    println<span>!</span>(<span>"{}"</span>, sum(<span>5</span>, <span>8</span>));
}

<span>pub</span> <span>fn</span> <span>sum</span>(a: <span>i32</span>, b: <span>i32</span>) -&gt; <span>i32</span> {
    a <span>+</span> b
}
</code></pre></div><p>My Rust code is always structured the <a href="https://doc.rust-lang.org/cargo/guide/project-layout.html">“cargo way”</a>, so I can compile my program by running <code>cargo build</code>, and this will produce a binary for me within the <code>target/debug/</code> directory. I have named my crate <code>rbin</code>, so this is the name of the binary that is created at this location:</p>
<div><pre><code data-lang="bash">~$ cargo build
   Compiling rbin v0.1.0 <span>(</span>/home/mierdin/Code/rbin<span>)</span>
    Finished dev <span>[</span>unoptimized + debuginfo<span>]</span> target<span>(</span>s<span>)</span> in 0.15s

~$ ls -lha target/debug/rbin
-rwxrwxr-x <span>2</span> mierdin mierdin 3.1M Nov  <span>3</span> 22:46 target/debug/rbin
</code></pre></div><p>These days, it’s really easy to take such questions for granted, but if you’re curious, you may be asking:</p>
<blockquote>
<p>“But what <strong>is</strong> that file?”</p>
</blockquote>
<p>I mean we all generally know that it’s an “executable”, in that we run it and our program happens. But what does that mean? What is contained in that file that means our computer automatically just <strong>knows</strong> how to run it? And how is it possible that a program with 7 lines of code can take up over 3 megabytes of disk space?!?</p>
<p>It turns out that in order to create an executable for this ridiculously simple program, the Rust compiler must include quite a bit of additional software to make it possible.</p>

<p>Well, it turns out there is a widely accepted format for these things, called the <a href="https://en.wikipedia.org/wiki/Executable_and_Linkable_Format">“Executable and Linkable Format”</a>, or ELF!</p>
<blockquote>
<p>Note that I won’t be comprehensively covering ELF here (there are plenty of other resources, many of which I’ll link to) - rather this is an exploration of what goes into a Rust binary with the simplest, default settings, and some observations about what seems interesting to me.</p>
</blockquote>
<p>ELF is a well-known, popular format, especially in the world of Linux, but there are plenty of others. <a href="https://en.wikipedia.org/wiki/Comparison_of_executable_file_formats">Operating systems like Windows and macOS each have their own format</a>, which is a big reason why, when you’re compiling (or simply downloading) software, you have to specify the operating system you want to run it on. This is true despite the fact that the underlying machine code that executes your program may be the same on all of them (e.g. <code>x86_64</code>).</p>
<p>An <strong>exceptional</strong> visual breaking down the ELF format can be found at the link to the ELF wikipedia page above, I have found myself constantly referring back to it while writing this post:</p>
<p><a title="Ange Albertini / CC BY (https://creativecommons.org/licenses/by/1.0)" href="https://oswalt.dev/assets/2020/11/elf.png"><img width="512" alt="ELF Executable and Linkable Format diagram by Ange Albertini" src="https://oswalt.dev/assets/2020/11/elf.png"></a>
</p>
<p>Commonly, executable formats like this specify a <a href="https://en.wikipedia.org/wiki/File_format#Magic_number">magic number</a> right at the beginning of the file, so that the format can be easily identified. This occupies the first four bytes in the <a href="https://en.wikipedia.org/wiki/Executable_and_Linkable_Format#File_header">file header</a>. This is a very important field, because unless we can first identify an ELF file appropriately, we can’t reasonably expect to do anything “ELF-y” with it. We know where certain bits of information <strong>should</strong> be in an ELF file, but we first must identify using these bytes that this is what we can expect.</p>
<p>The <code>readelf</code> utility is extremely useful for printing all kinds of useful metadata and related tables of information contained within an ELF file. However, this utility expects - naturally - that the file being read is actually an ELF file, and even provides a helpful hint that the expected “magic bytes” for a non-ELF file aren’t set appropriately when used on a non-ELF file, so it doesn’t attempt to read the rest:</p>
<div><pre><code data-lang="bash">~$ readelf -l .gitignore

readelf: Error: Not an ELF file - it has the wrong magic bytes at the start
</code></pre></div><p>Once identified, the entire rest of the file can be identified using <strong>byte offsets</strong> (that is, the number of bytes from zero).</p>
<blockquote>
<p>For those that are accustomed to looking at network packet captures, this should all sound very familiar to you, as this is exactly how we know where certain fields are located in a packet header. <a href="https://en.wikipedia.org/wiki/Ethernet_frame">Ethernet frames</a> have a predictable preamble and start-of-frame delimiter. Ethernet also has a field called the “Ethertype”, which provides a clue as to what protocol is contained within the Ethernet frame (which allows computers to then parse those field as well). Just like Ethernet has a standard set of byte offsets that indicate where the various fields should be represented, the ELF format specifies its own offsets for all of the fields providing useful identifying and execution information in the <a href="https://en.wikipedia.org/wiki/Executable_and_Linkable_Format#File_header">file header</a>, which then point to other important locations within the file.</p>
</blockquote>
<p>There’s all kinds of useful information in this header, but in particular, the <code>e_entry</code> field  in the file header points to the offset location from where the execution should start. This is the “entry point” for the program. We’ll definitely be following this down the rabbit hole in a little bit.</p>
<p>We can again use <code>readelf</code>, this time on a proper ELF file (our Rust program), and also using the <code>-h</code> flag to show the file header:</p>
<div><pre><code data-lang="bash">~$ readelf -h target/debug/rbin

ELF Header:
  Magic:   7f <span>45</span> 4c <span>46</span> <span>02</span> <span>01</span> <span>01</span> <span>00</span> <span>00</span> <span>00</span> <span>00</span> <span>00</span> <span>00</span> <span>00</span> <span>00</span> <span>00</span> 
  Class:                             ELF64
  Data:                              2<span>'</span>s complement, little endian
  Version:                           <span>1</span> <span>(</span>current<span>)</span>
  OS/ABI:                            UNIX - System V
  ABI Version:                       <span>0</span>
  Type:                              DYN <span>(</span>Shared object file<span>)</span>
  Machine:                           Advanced Micro Devices X86-64
  Version:                           0x1
  Entry point address:               0x5070
  Start of program headers:          <span>64</span> <span>(</span>bytes into file<span>)</span>
  Start of section headers:          <span>3195368</span> <span>(</span>bytes into file<span>)</span>
  Flags:                             0x0
  Size of this header:               <span>64</span> <span>(</span>bytes<span>)</span>
  Size of program headers:           <span>56</span> <span>(</span>bytes<span>)</span>
  Number of program headers:         <span>12</span>
  Size of section headers:           <span>64</span> <span>(</span>bytes<span>)</span>
  Number of section headers:         <span>42</span>
  Section header string table index: <span>41</span>
</code></pre></div><p>So, the “magic number” lets us parse at least the rest of the file header, which contains not only information about the file, but byte-offset locations for other important portions of the file. One of these is the “Start of program headers”, which starts after 64 bytes.</p>

<p>The <a href="https://en.wikipedia.org/wiki/Executable_and_Linkable_Format#Program_header">program header table</a> contains information that allows the operating system to allocate memory and load the program. This is also referred to as a <a href="http://www.tldp.org/LDP/LG/issue23/flower/psimage.html">process image</a>. You can think of it as a list of “instructions” that tell the system to do various things with chunks of memory in order to prepare to execute this program.</p>
<p>The <code>readelf</code> utility also allows us to read the program headers using the <code>-l</code> flag:</p>
<div><pre><code data-lang="bash">~$ readelf -l target/debug/rbin

Elf file type is DYN <span>(</span>Shared object file<span>)</span>
Entry point 0x5070
There are <span>12</span> program headers, starting at offset <span>64</span>

Program Headers:
  Type           Offset             VirtAddr           PhysAddr
                 FileSiz            MemSiz              Flags  Align
  PHDR           0x0000000000000040 0x0000000000000040 0x0000000000000040
                 0x00000000000002a0 0x00000000000002a0  R      0x8
  INTERP         0x00000000000002e0 0x00000000000002e0 0x00000000000002e0
                 0x000000000000001c 0x000000000000001c  R      0x1
      <span>[</span>Requesting program interpreter: /lib64/ld-linux-x86-64.so.2<span>]</span>
  LOAD           0x0000000000000000 0x0000000000000000 0x0000000000000000
                 0x0000000000004ed8 0x0000000000004ed8  R      0x1000
  LOAD           0x0000000000005000 0x0000000000005000 0x0000000000005000
                 0x0000000000030571 0x0000000000030571  R E    0x1000
  LOAD           0x0000000000036000 0x0000000000036000 0x0000000000036000
                 0x000000000000be44 0x000000000000be44  R      0x1000
  LOAD           0x0000000000042520 0x0000000000043520 0x0000000000043520
                 0x0000000000002b18 0x0000000000002cf8  RW     0x1000
  DYNAMIC        0x0000000000044740 0x0000000000045740 0x0000000000045740
                 0x0000000000000230 0x0000000000000230  RW     0x8
  NOTE           0x00000000000002fc 0x00000000000002fc 0x00000000000002fc
                 0x0000000000000044 0x0000000000000044  R      0x4
  TLS            0x0000000000042520 0x0000000000043520 0x0000000000043520
                 0x0000000000000000 0x00000000000000d8  R      0x20
  GNU_EH_FRAME   0x000000000003aa8c 0x000000000003aa8c 0x000000000003aa8c
                 0x0000000000000d84 0x0000000000000d84  R      0x4
  GNU_STACK      0x0000000000000000 0x0000000000000000 0x0000000000000000
                 0x0000000000000000 0x0000000000000000  RW     0x10
  GNU_RELRO      0x0000000000042520 0x0000000000043520 0x0000000000043520
                 0x0000000000002ae0 0x0000000000002ae0  R      0x1

 Section to Segment mapping:
  Segment Sections...
   <span>00</span>     
   <span>01</span>     .interp 
   <span>02</span>     .interp .note.gnu.build-id .note.ABI-tag .gnu.hash .dynsym .dynstr .gnu.version .gnu.version_r .rela.dyn .rela.plt 
   <span>03</span>     .init .plt .plt.got .text .fini 
   <span>04</span>     .rodata .debug_gdb_scripts .eh_frame_hdr .eh_frame .gcc_except_table 
   <span>05</span>     .init_array .fini_array .data.rel.ro .dynamic .got .data .bss 
   <span>06</span>     .dynamic 
   <span>07</span>     .note.gnu.build-id .note.ABI-tag 
   <span>08</span>     .tbss 
   <span>09</span>     .eh_frame_hdr 
   <span>10</span>     
   <span>11</span>     .init_array .fini_array .data.rel.ro .dynamic .got 
</code></pre></div><p>Each <a href="https://en.wikipedia.org/wiki/Executable_and_Linkable_Format#Program_header">program header type</a> does something different to a chunk of memory (segment). Next to each header can be found two 64-bit (this is a 64 bit ELF after all) hexidecimal values. As indicated at the top of the header output, the top value is the memory offset of the segment that the header refers to (where it is located). The value below that is the size of that particular segment in the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://oswalt.dev/2020/11/anatomy-of-a-binary-executable/">https://oswalt.dev/2020/11/anatomy-of-a-binary-executable/</a></em></p>]]>
            </description>
            <link>https://oswalt.dev/2020/11/anatomy-of-a-binary-executable/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24994522</guid>
            <pubDate>Thu, 05 Nov 2020 00:26:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New study finds psilocybin greatly and quickly relieves depression]]>
            </title>
            <description>
<![CDATA[
Score 326 | Comments 171 (<a href="https://news.ycombinator.com/item?id=24993519">thread link</a>) | @neom
<br/>
November 4, 2020 | https://www.psychnewsdaily.com/new-study-psilocybin-magic-mushrooms-relieves-depression/ | <a href="https://web.archive.org/web/*/https://www.psychnewsdaily.com/new-study-psilocybin-magic-mushrooms-relieves-depression/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4933" role="main"><div><div><div><p>A <a rel="noreferrer noopener" href="https://jamanetwork.com/journals/jamapsychiatry/fullarticle/10.1001/jamapsychiatry.2020.3285?guestAccessKey=29ac3052-6203-4fb4-b1e2-d9dda5988445&amp;utm_source=For_The_Media&amp;utm_medium=referral&amp;utm_campaign=ftm_links&amp;utm_content=tfl&amp;utm_term=110420" target="_blank">new study</a> of 24 adults with major depression finds that two doses of the psychedelic substance psilocybin, given with supportive psychotherapy, produced rapid and large reductions in depressive symptoms. Most of the participants showed improvement, and half achieved remission at the four-week follow-up.</p><p><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Psilocybin" target="_blank">Psilocybin</a> is a compound found in so-called “magic mushrooms.” It produces visual and auditory hallucinations, and profound changes in consciousness, over a period of several hours.</p><p>The findings appeared on November 4 in&nbsp;<em><a href="https://jamanetwork.com/journals/jamapsychiatry" target="_blank" rel="noreferrer noopener">JAMA Psychiatry</a></em>.</p><h2>Effect of psilocybin 4x stronger than traditional antidepressants</h2><p>“The magnitude of the effect we saw was about four times larger than what clinical trials have shown for traditional antidepressants on the market,” said co-author <a rel="noreferrer noopener" target="_blank" href="https://hopkinspsychedelic.org/davis">Alan Davis</a> of Johns Hopkins University.</p><p>As the paper explains, “the effect sizes reported in this study were approximately 2.5 times greater than the effect sizes found in psychotherapy, and more than 4 times greater than the effect sizes found in psycho-pharmacological depression treatment studies.”</p><p>“Because most other depression treatments take weeks or months to work and may have undesirable effects, this could be a game changer if these findings hold up” in future clinical trials, Davis said.</p><p>And compared to traditional antidepressants, the side effects of psilocybin are more limited. These include mild-to-moderate headaches, and “challenging emotions” during the sessions. Antidepressant medications, on the other hand, have more far-reaching side effects. These include <a href="https://www.psychnewsdaily.com/new-study-finds-ethnic-variation-in-suicide-method-guns-vs-hanging/">suicidal</a> ideation, decrease in sexual drive, and weight gain.</p><p>Furthermore, the effectiveness of psilocybin <a href="https://www.psychnewsdaily.com/effects-of-therapy-for-hypochondriacs-last-10-years-or-more/">therapy</a> appears after only one or two administrations. This represents another advantage over commonly used antidepressants, which typically require daily administration.</p><h2>Two five-hour psilocybin sessions</h2><p>For the new study, the researchers recruited 24 people with a long-term history of depression. Most of the participants had experienced symptoms for about two years before enrolling in the study.</p><p>The participants underwent two five-hour psilocybin sessions, under the supervision of the researchers.</p><p>The average age of participants was 39. Sixteen were women. Twenty-two identified as white, one identified as Asian, and one identified as African American.</p><p>Participants had to taper off any antidepressants prior to the study. They did so with the help of their personal physician, to ensure safe exposure to this experimental treatment.</p><p>Treatment consisted of two psilocybin doses given by two monitors who provided guidance and reassurance. The doses were given two weeks apart, between August 2017 and April 2019. Each treatment session lasted about five hours. The participants lay on a couch wearing eyeshades and headphones that played music, in the presence of the monitors.</p><h2>A very large reduction in depressive symptoms</h2><p>All participants completed the <a rel="noreferrer noopener" href="https://pubmed.ncbi.nlm.nih.gov/18408526/" target="_blank">GRID-Hamilton Depression Rating Scale</a> upon enrollment. They also did this same assessment at one and four weeks following completion of their treatment.</p><p>A score of 24 or more indicates severe depression. A score of 17-23 means moderate depression, 8-16 mild depression, and 7 or less no depression.</p><p>At enrollment, participants had an average depression scale rating of 23. But at one week and four weeks after treatment, they had an average depression scale score of 8.</p><p>After treatment, most participants showed a substantial decrease in their symptoms. Likewise, almost half were in remission from depression at the four-week follow-up.</p><p>For the entire group of 24 participants, 67% showed a more than 50% reduction in depression symptoms at the one-week follow-up, and 71% at the four-week follow-up. Overall, four weeks post-treatment, 54% of participants were considered in remission, meaning they no longer qualified as being depressed.</p><p>Compared to ketamine, another psychoactive substance that has <a href="https://pubmed.ncbi.nlm.nih.gov/25038867/" target="_blank" rel="noreferrer noopener">recently been found</a> to alleviate depression, psilocybin has several advantages. The antidepressant effects of psilocybin seem to last longer. Psilocybin also has a lower potential for addiction and adverse events than ketamine.</p><h2>More results to follow</h2><p>The researchers say they will follow the participants for a year after the study to see how long the antidepressant effects of the psilocybin treatment last. They will report these new findings in a later publication.</p><p>In 2016, Johns Hopkins Medicine researchers first reported that treatment with psilocybin under psychologically supported conditions significantly relieved existential anxiety and depression in people with a&nbsp;<a target="_blank" href="https://www.hopkinsmedicine.org/news/media/releases/hallucinogenic_drug_psilocybin_eases_existential_anxiety_in_people_with_life_threatening_cancer_" rel="noreferrer noopener">life-threatening cancer diagnosis</a>.</p><p>According to the National Institute of Mental Health, more than 17 million people in the U.S., and 300 million people worldwide, have experienced major <a rel="noreferrer noopener" href="https://www.psychnewsdaily.com/category/mental-health/depression/" target="_blank">depression</a>.</p><p>Entrepreneur and philanthropist <a href="https://tim.blog/" target="_blank" rel="noreferrer noopener">Tim Ferriss</a> supported the funding campaign for this study. “I believe this study to be a critically important proof of concept for the medical approval of psilocybin for treatment of depression, a condition I have personally struggled with for decades,” he said.</p><p>“How do we explain the incredible magnitude and durability of effects? Treatment research with moderate to high doses of psychedelics may uncover entirely new paradigms for understanding and improving mood and mind,” Ferriss said.</p><hr><p><strong>Study: </strong>“<a rel="noreferrer noopener" href="https://jamanetwork.com/journals/jamapsychiatry/fullarticle/10.1001/jamapsychiatry.2020.3285?guestAccessKey=29ac3052-6203-4fb4-b1e2-d9dda5988445&amp;utm_source=For_The_Media&amp;utm_medium=referral&amp;utm_campaign=ftm_links&amp;utm_content=tfl&amp;utm_term=110420" target="_blank">Effects of Psilocybin-Assisted Therapy on Major Depressive Disorder: A Randomized Clinical Trial</a>“<br><strong>Authors:</strong> Alan K. Davis, Frederick S. Barrett, Darrick G. May, Mary P. Cosimano, Nathan D. Sepeda, Matthew W. Johnson, Patrick H. Finan, and Roland R. Griffiths<br><strong>Published in:</strong> <a rel="noreferrer noopener" href="https://jamanetwork.com/journals/jamapsychiatry" target="_blank"><em>JAMA Psychiatry</em></a><br><strong>Publication date: </strong>November 4, 2020<br><strong>DOI: </strong>doi:10.1001/jamapsychiatry.2020.3285<br><strong>Photo: </strong>by&nbsp;<a href="https://unsplash.com/@vanillapines?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">James Bak</a>&nbsp;via <a href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a><br></p><p>For a weekly summary of the latest psychology news, subscribe to our <a href="https://www.psychnewsdaily.com/the-psych-news-weekly-newsletter/" target="_blank" rel="noreferrer noopener">Psych News Weekly newsletter</a>.</p></div></div></div></article></div>]]>
            </description>
            <link>https://www.psychnewsdaily.com/new-study-psilocybin-magic-mushrooms-relieves-depression/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24993519</guid>
            <pubDate>Wed, 04 Nov 2020 22:05:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Dark didn't choose Rust]]>
            </title>
            <description>
<![CDATA[
Score 125 | Comments 85 (<a href="https://news.ycombinator.com/item?id=24991848">thread link</a>) | @pimterry
<br/>
November 4, 2020 | https://blog.darklang.com/why-dark-didnt-choose-rust/ | <a href="https://web.archive.org/web/*/https://blog.darklang.com/why-dark-didnt-choose-rust/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.darklang.com/content/images/size/w300/2020/11/2017-11-21-18-14-57-1200x800.jpg 300w,
                            https://blog.darklang.com/content/images/size/w600/2020/11/2017-11-21-18-14-57-1200x800.jpg 600w,
                            https://blog.darklang.com/content/images/size/w1000/2020/11/2017-11-21-18-14-57-1200x800.jpg 1000w,
                            https://blog.darklang.com/content/images/size/w2000/2020/11/2017-11-21-18-14-57-1200x800.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.darklang.com/content/images/size/w2000/2020/11/2017-11-21-18-14-57-1200x800.jpg" alt="Why Dark didn't choose Rust">
            </figure>

            <section>
                <div>
                    <p><em><em>Welcome </em>again <em>HN! <a href="https://darklang.com/">Dark</a> is a programming language, structured editor, and infrastructure—all in one—whose goal is to make it 100x easier to build backend services. Check out the <a href="https://darklang.com/">website</a>, our <a href="https://blog.darklang.com/what-is-dark/">What is Dark</a> post, and <a href="https://blog.darklang.com/how-dark-deploys-code-in-50ms/">How Dark deploys in 50ms</a></em> <em>for more. Thanks for checking us out!</em></em></p><p><em>This is the third or a 3-part series: <a href="https://blog.darklang.com/leaving-ocaml/">Leaving OCaml</a> and <a href="https://blog.darklang.com/new-backend-fsharp/">Dark's new backend will be in F#</a>. You can enjoy this without reading the previous posts.</em></p><p>With the election in the state it is, I'm going to stop pretending that I can do work right now. So instead, I'll just milk the success of my last <a href="https://blog.darklang.com/leaving-ocaml/">two</a> <a href="https://blog.darklang.com/new-backend-fsharp/">posts</a> and hope that none of you are really working right now either.</p><p>As discussed in the two <a href="https://blog.darklang.com/leaving-ocaml/">previous</a> <a href="https://blog.darklang.com/new-backend-fsharp/">posts</a>, Dark is moving to F#. This has been a bit of a surprise to people, including me. We've spoken for years about the inevitable Rust rewrite; we have a CLI written in Rust and two services, so I was pretty sure that it was going to be Rust.</p><p>People asked about a few other languages as well, so let's get them out of the way first.</p><h3 id="clojure">Clojure</h3><p>I have a lot of experience with Clojure, as CircleCI was almost all Clojure. However, we spent a whole lot of time with dealing accidental complexity, specifically "what type is this field" and nulls all over the place. So I deliberately chose not to have a dynamically typed language, even though Clojure is a lovely language. A side benefit is to escape the Cult of Rich in the Clojure community. Hearing his <a href="https://www.youtube.com/watch?v=YR5WdGrpoug">Maybe Not</a> talk really cemented for me how deep down the dynamically typed rabbit hole they are over there, and how much I disagree with that.</p><h3 id="haskell">Haskell</h3><p>I had previously tried to love Haskell, trying to <a href="https://github.com/pbiggar/rash">write an interpreter</a> in it while I was at the <a href="https://www.recurse.com/">Recurse Center</a>, and I did not like it. <a href="https://news.ycombinator.com/item?id=24978238">HN user momentumtop's explanation</a> match my feelings exactly:</p><blockquote>The Haskell community, in my experience, is far more academic. A<a href="https://mail.haskell.org/pipermail/libraries/2020-September/030789.html"> recent post to the Haskell libraries mailing list</a> began with:<p>"It was pointed out to me in a private communication that the tuple function \x-&gt;(x,x) is actually a special case of a diagonalization for biapplicative and some related structures monadicially.</p><p>It received 39 pretty enthusiast replies.</p></blockquote><h3 id="scala">Scala</h3><p>I have no experience with Scala, but my overwhelming sense of the language and the community is that the whole thing is a mess. So I didn't consider it, and still wouldn't.</p><p>I actually <a href="https://blog.darklang.com/first-thoughts-on-rust-vs-ocaml/">wrote quite a bit on why I didn't like Rust</a> a few weeks ago. I think those main reasons stand, so I'll just link to them rather than repeat the <a href="https://blog.darklang.com/first-thoughts-on-rust-vs-ocaml/">1800 words</a> again. As a quick summary, the good parts were:</p><ul><li>tooling is great</li><li>library ecosystem is great</li><li>community is great</li><li>macros are nice (though I feel I was overusing them to cover problems in the language)</li></ul><p>and the bad parts were</p><ul><li>having to do memory management sucks</li><li>pattern matching doesn't work all that well</li><li>too many ways to do things (Arc vs Rc, async vs sync, different stdlibs)</li><li>the language isn't immutable</li><li>having to fight the compiler</li></ul><p>Again, for more on those, have a <a href="https://blog.darklang.com/first-thoughts-on-rust-vs-ocaml/">read of the previous post</a>.</p><p>Ultimately, when it came time to decide, it came down to a few major things: missing a GCP library, and the low-level nature of the language.</p><h2 id="libraries">Libraries</h2><p>Rust has a ton of libraries, and they work really well and are nicely integrated. They have 3rdparty libraries for <a href="https://www.honeycomb.io/">Honeycomb</a>, <a href="https://launchdarkly.com/">LaunchDarkly</a>, and <a href="https://blog.darklang.com/why-dark-didnt-choose-rust/rollbar.com">Rollbar</a>, which are important services for us. However, the <a href="https://github.com/Byron/google-apis-rs">library for GCP</a> seems super sketch. It's autogenerated and the issues imply that they've gone as far as they can using this technique. So that seemed very risky to take on, given that the whole point was to have a much richer library ecosystem.</p><h2 id="async">Async</h2><p>When I wrote the <a href="https://blog.darklang.com/first-thoughts-on-rust-vs-ocaml/">previous post</a>, I had just gotten the <a href="https://github.com/darklang/fizzboom/tree/main/rust-hyper">synchronous version</a> of the benchmark to work in Rust. Then I tried to <a href="https://github.com/darklang/fizzboom/tree/main/rust-hyper-async/execution-engine">make it async</a>. I really struggled with making things async. Apparently, recursion adds <a href="https://rust-lang.github.io/async-book/07_workarounds/04_recursion.html">a new level of complexity</a> to async. But the thing that killed me was <a href="https://rust-lang.github.io/async-book/04_pinning/01_chapter.html">pinning</a>.</p><p>Let's see if I can explain this. When you're writing an async, multi-threaded server in using the tokio runtime, async processes can be moved between threads. This means the memory can be copied, and so you need to ... pin things? OK, that's as much as I remember. Look in the HN comments after I publish this and I'm sure someone will explain better. The code <a href="https://github.com/darklang/fizzboom/blob/main/rust-hyper-async/execution-engine/src/eval.rs">is over here</a> if you're interested.</p><p>I tried to get my head around this for some time, before deciding that this was a waste of time. Apparently, this boxing and pinning is what you get when you don't have a GC, and that when you do have a GC, you simply don't need to deal with it. So that was the final straw for me.</p><h2 id="rust-is-a-low-level-language">Rust is a low-level language</h2><p>I'm implementing a language that's basically F#/OCaml. So it makes sense that it's easier to implement in F#/OCaml. A few people pointed out that I'm trying to write OCaml in Rust, and that's not really what it was designed for. I think that's right. Rust's semantics makes many things easy, but not what I'm trying to do.</p><p>I think most of us don't need Rust. I think Rust is a wonderful community, ecosystem, and tooling, wrapping a language that nicely solves a problem very few of us have. It's just so nice over there, until you actually write code.</p><p>It's easy to forget, given how nice everything is with the error messages and the docs, that Rust is a very low-level language. We're so attracted to the community and the tooling that we forget that low-level languages suck. Maybe Rust has a better story than most low-level languages, but remember that garbage collectors are great. By having a GC, we don't have to do any of the stuff that causes all these problems in Rust. Maybe that costs performance, but I need the ability to quickly write code a lot more than I need the extra performance.</p><p>And ultimately, that's <a href="https://blog.darklang.com/new-backend-fsharp/">why I picked F#</a>.</p><hr><p><em><em><em><em><em><em><em><em>You can sign up for Dark </em></em></em></em></em></em></em></em><a href="https://darklang.com/signup" rel="noopener nofollow"><em><em><em><em><em><em><em><em>here</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em>. For more info on Dark, follow our </em></em></em></em></em></em></em></em><a href="https://blog.darklang.com/rss" rel="noopener nofollow"><em><em><em><em><em><em><em><em>RSS</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em>, follow </em></em></em></em></em></em></em></em><a href="https://twitter.com/darklang" rel="noopener nofollow"><em><em><em><em><em><em><em><em>us</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em> (or </em></em></em></em></em></em></em></em><a href="https://twitter.com/paulbiggar" rel="noopener nofollow"><em><em><em><em><em><em><em><em>me</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em>) on Twitter, join our </em></em></em></em></em></em></em></em><a href="https://darklang.com/slack-invite" rel="noopener nofollow"><em><em><em><em><em><em><em><em>Slack Community</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em>, watch our </em></em></em></em></em></em></em></em><a href="https://github.com/darklang/dark" rel="noopener nofollow"><em><em><em><em><em><em><em><em>GitHub repo</em></em></em></em></em></em></em></em></a><em>, or join our <a href="http://darklang.com/mailing-list">mailing list</a><em><em><em><em><em><em><em>.</em></em></em></em></em></em></em></em></p><p><em>Thanks to <a href="https://twitter.com/jf">Joël Franusic</a>, <a href="https://twitter.com/jonathansywulak">Jonny Sywulak</a> and <a href="https://twitter.com/algo_luca">Luca Palmieri</a> for feedback on drafts of this post.</em></p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.darklang.com/why-dark-didnt-choose-rust/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24991848</guid>
            <pubDate>Wed, 04 Nov 2020 18:52:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Economics of Sex Robots]]>
            </title>
            <description>
<![CDATA[
Score 120 | Comments 79 (<a href="https://news.ycombinator.com/item?id=24991249">thread link</a>) | @elsewhen
<br/>
November 4, 2020 | https://dianaverse.com/2020/10/30/uncanny-vulvas/ | <a href="https://web.archive.org/web/*/https://dianaverse.com/2020/10/30/uncanny-vulvas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-441">
	<!-- .entry-header -->

	
	
	<div>
		
<p>This is a lightly edited version of an article I wrote that first appeared in <a rel="noreferrer noopener" href="https://jacobitemag.com/2018/04/24/uncanny-vulvas/" target="_blank">Jacobite</a>. I had a great conversation about this article and evolutionary psychology more generally (<a rel="noreferrer noopener" href="https://philosophicaldisquisitions.blogspot.com/2018/08/episode-44-fleischman-on-evolutionary.html" target="_blank">link here</a>) with  J<a rel="noreferrer noopener" href="https://twitter.com/JohnDanaher?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor" target="_blank">ohn Danaher</a>, who <a rel="noreferrer noopener" href="https://www.amazon.com/Robot-Sex-Social-Ethical-Implications-ebook/dp/B08BT1G87G/ref=cm_cr_arp_d_product_top?ie=UTF8" target="_blank">edited a book about sex robots</a>. Most recently, <a href="https://dianaverse.com/2020/10/30/zombiesexbots/" target="_blank" rel="noreferrer noopener">I gave a presentation as a damaged android for the Zombie Apocalypse Medicine meeting about the dangers of counterfeit fitness. </a></p>



<hr>



<p><strong>Uncanny Vulvas- Diana Fleischman</strong></p>



<p>Sex is consistently underrated as a driver of innovation. Yes, space exploration helped us develop the technology for things like cochlear implants, powdered (machine) lubricants and scratch resistant lenses. Lust has furthered the development of cash transfers, point-of-view filming and video chat. I predict that historians of the development of artificial intelligence are going to see sexual gratification as one of the phenomenon’s great motivators. Evolutionary psychology can give us insight into how sex robots are going to develop and the ramifications they’ll have on society.</p>



<p>Sexbots are usually woman-shaped&nbsp;<em>gynoid</em>&nbsp;machines. At the&nbsp;present time,&nbsp;sex robots are simple: they’re silicone sex dolls that have some capacity for movement and response. Manufacturers are rolling out new models and new promises: sex robots that respond to touch and penetration, sex robots with interchangeable faces and bodies and sex robots with&nbsp;<a rel="noreferrer noopener" href="https://www.nytimes.com/2017/07/17/opinion/sex-robots-consent.html" target="_blank">different personalities</a>. Future robots will have the allure and cues of fertility of a flesh-and-blood woman combined with the artificial intelligence that creates compulsive reward directed behavior. An intelligence, unlike the intelligence of humans, that will have the gratification of its owner as the only goal. </p>



<p>Sex robots are overwhelmingly gynoid because heterosexual men drive the market for sexual products like prostitution and pornography. Across cultures, men desire more sexual partners, need to know someone for less time before they want to have sex with them, and have lower standards for a sexual liaison than women. Looking at gay men is instructive here. Their sexual interactions are not limited by women’s sexual choosiness and they, on average, have many more sexual partners than straight men or lesbians.</p>



<figure><img data-attachment-id="448" data-permalink="https://dianaverse.com/time-partner-known-consenting-to-sex/" data-orig-file="https://dianafleischman.files.wordpress.com/2020/10/time-partner-known-consenting-to-sex.png" data-orig-size="568,512" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="time-partner-known-consenting-to-sex" data-image-description="" data-medium-file="https://dianafleischman.files.wordpress.com/2020/10/time-partner-known-consenting-to-sex.png?w=300" data-large-file="https://dianafleischman.files.wordpress.com/2020/10/time-partner-known-consenting-to-sex.png?w=568" src="https://dianafleischman.files.wordpress.com/2020/10/time-partner-known-consenting-to-sex.png?w=568" alt="" srcset="https://dianafleischman.files.wordpress.com/2020/10/time-partner-known-consenting-to-sex.png 568w, https://dianafleischman.files.wordpress.com/2020/10/time-partner-known-consenting-to-sex.png?w=150 150w, https://dianafleischman.files.wordpress.com/2020/10/time-partner-known-consenting-to-sex.png?w=300 300w" sizes="(max-width: 568px) 85vw, 568px"><figcaption>A woman would have to know someone for 3 months to be as likely to have sex with someone as a man would be after one day- via<a href="https://en.wikipedia.org/wiki/David_Buss" target="_blank" rel="noreferrer noopener"> David Buss</a></figcaption></figure>



<p>It isn’t hard to see the reason for this. Men don’t get pregnant and don’t lactate, and they have smaller, easier-to-produce sex cells than women.&nbsp;For a man, the cost of producing offspring is cheap. Getting one’s genes into the next generation is the engine of evolution. The low opportunity costs make men motivated to take every opportunity, even if it comes in the form of a robot. Ever think a dog is dumb for growling at his reflection in the mirror? Human men can become aroused looking at flat images of nude women in black and white,&nbsp;<a href="https://en.wikipedia.org/wiki/Evolutionary_mismatch" target="_blank" rel="noreferrer noopener">our evolved psychology can respond in maladaptive ways towards novel stimuli.</a></p>



<p>Courtship is expensive and complicated by design,&nbsp;and it’s the limiting factor&nbsp;of the sexual fulfillment of men.&nbsp;Women impose costs on men to gain sexual access for very good reasons: to test their genetic fitness and their long-term potential supporting a&nbsp;family. If courtship is costly and the costs are not clearly defined, this not only tests a man’s motivation toward a specific woman, it also acts to monopolize a man’s resources so he can’t afford to woo anyone else. Pornography and prostitution are popular because they arrive at sexual end goals, or a reasonable facsimile, with more clarity and lower costs than in the mating market.</p>



<p>The complications of courtship are driving improvements in sexual substitutes, like masturbation aids (e.g. fleshlight, fliphole) and 3-D&nbsp;porn. There are already thousands of <a href="https://en.wikipedia.org/wiki/RealDoll" target="_blank" rel="noreferrer noopener">RealDolls </a>in the world, silicone sex dolls that cost around $6,000 each.&nbsp;<a href="https://en.wikipedia.org/wiki/LovePlus" target="_blank" rel="noreferrer noopener"><em>LovePlus</em>&nbsp;</a>is a Japanese game in which players interact with a virtual girlfriend including kissing her by touching the screen and taking her out on dates, has&nbsp;<a href="https://www.dailydot.com/irl/video-game-girlfriend-loveplus-japan/" target="_blank" rel="noreferrer noopener">hundreds of thousands of users</a>.&nbsp;<em>LovePlus</em>&nbsp;is a great demonstration of how this market&nbsp;<a href="https://www.kotaku.com.au/2014/05/love-plus-makes-you-care-about-a-virtual-girl/" target="_blank" rel="noreferrer noopener">isn’t only about providing sex</a>, but also virtual companionship. You can’t even have virtual sex with Rinko, the ingénue of the game. These substitutes aren’t very good, and yet they are already competing with flesh-and-blood companionship.</p>



<figure><img data-attachment-id="444" data-permalink="https://dianaverse.com/sex-doll-mouth/" data-orig-file="https://dianafleischman.files.wordpress.com/2020/10/sex-doll-mouth.jpg" data-orig-size="621,472" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="sex-doll-mouth" data-image-description="" data-medium-file="https://dianafleischman.files.wordpress.com/2020/10/sex-doll-mouth.jpg?w=300" data-large-file="https://dianafleischman.files.wordpress.com/2020/10/sex-doll-mouth.jpg?w=621" src="https://dianafleischman.files.wordpress.com/2020/10/sex-doll-mouth.jpg?w=621" alt="" srcset="https://dianafleischman.files.wordpress.com/2020/10/sex-doll-mouth.jpg 621w, https://dianafleischman.files.wordpress.com/2020/10/sex-doll-mouth.jpg?w=150 150w, https://dianafleischman.files.wordpress.com/2020/10/sex-doll-mouth.jpg?w=300 300w" sizes="(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 984px) 61vw, (max-width: 1362px) 45vw, 600px"><figcaption>A silicone facsimile of a woman’s face- <a href="https://www.shutterstock.com/image-photo/shenzhen-china-1108-female-silicone-doll-1343425748" target="_blank" rel="noreferrer noopener">via Alex Raysikh from shutterstock</a></figcaption></figure>







<p>Union&nbsp;power, increases in mandatory working standards, and minimum wage&nbsp;laws&nbsp;accelerate the push toward&nbsp;automation.&nbsp;Machines&nbsp;are already replacing cashiers&nbsp;and&nbsp;factory workers. Soon the jobs of truck drivers, clerks, and accountants&nbsp;will be automated. The current political climate around courtship and interactions between the sexes is more powerful than&nbsp;the&nbsp;market forces that are&nbsp;replacing jobs,&nbsp;because escalating costs aren’t transparent and neither is the punishment for not paying them. If a business owner wants to adhere to employment laws, he reads them. The costs of courtship are codified nowhere.</p>



<p>The average single man paying attention to&nbsp;contemporary&nbsp;social fashions&nbsp;will struggle to understand the new rules of meeting, courting, or having sex with women. Something as banal as trying to converse with a woman wearing headphones&nbsp;<a href="https://uk.askmen.com/news/dating/talking-to-women-who-are-wearing-headphones.html" target="_blank" rel="noreferrer noopener">is now often considered harassment</a>. A man’s chances of mating success increase when he approaches many women, but so too do his chances of a gaining reputation as sexist, exploitative, or immoral. To take a fraught example, how does a man know that a woman is genuinely consenting to sex?&nbsp;A lack of ability to pick up on cues can incur catastrophic costs.</p>



<p>Men high in conscientiousness, who are sensitive to social disapproval but who nonetheless have difficulty reading subtle social cues, could make good husbands for women.&nbsp;These men are unlikely to want to take the risk of approaching women. As substitutes like sex robots and virtual companions become better and cheaper,&nbsp;they will monopolize the attention of such men.</p>



<p>Think of an introverted engineer with Asperger’s syndrome who wasn’t sure how to broach a conversation with a woman back in 2015 and definitely isn’t sure how to&nbsp;do that in today’s climate. In 10 years he could have a beautiful robot companion (indeed, he could have one that could emulate the experience of having sex with dozens of&nbsp;different&nbsp;women) that has a lower barrier to entry than the mating market and that keeps him satisfied enough to&nbsp;remain a&nbsp;happy&nbsp;bachelor. Some woman misses out on a conscientious guy with a good income who might not know exactly how to respond when she says “nothing’s wrong,” but will definitely keep the cars tuned up to get the kids to their mathematics championships. The world might miss out on his sons and daughters and their analytical approaches to some of the world’s problems.</p>



<p>The kinds of men described above, who have difficulty reading social signals but who are nonetheless strongly sexually motivated, have a characteristic that means&nbsp;they’ll be less put off by sex robots than the average person: resistance to perceiving the uncanny valley. “<a href="https://en.wikipedia.org/wiki/Uncanny_valley" target="_blank" rel="noreferrer noopener">The uncanny valley</a>” is the way that representations that fall just short of looking like humans&nbsp;<a href="https://www.strangerdimensions.com/2013/11/25/10-creepy-examples-uncanny-valley/" target="_blank" rel="noreferrer noopener">often look “creepy.”</a>&nbsp;Anthropomorphized robots are more relatable and trustworthy than machine-like robots. It’s also difficult to imagine that many people would want to have sex with a conglomeration of gears and wheels.</p>



<p>My view is that&nbsp;the uncanny valley&nbsp;is something analogous to&nbsp;<a href="https://en.wikipedia.org/wiki/Capgras_delusion" target="_blank" rel="noreferrer noopener">Capgras delusion</a>,&nbsp;a psychological disorder that causes sufferers to believe that someone&nbsp;they&nbsp;know has been taken over by an imposter,&nbsp;often inhuman. According to&nbsp;<a href="https://www.ted.com/talks/vilayanur_ramachandran_on_your_mind" target="_blank" rel="noreferrer noopener">VS Ramachandran</a>, there are two aspects to recognizing faces: the identification of the external familiar representation and the “internal” validation – the warm emotion that goes along with it. In the uncanny valley, you recognize a robot as humanlike, but it’s missing the facial movement or some other characteristic that gives you a warm feeling of recognition. Many men won’t experience the uncanny valley, especially with regards to sex robots. These men are going to be the early adopters. Men are worse at identifying faces than women and are far more likely to have&nbsp;<a href="https://en.wikipedia.org/wiki/Prosopagnosia" target="_blank" rel="noreferrer noopener">prosopagnosia</a>, the inability to recognize faces.</p>



<p>Sex is weird.&nbsp;Sex is&nbsp;gross&nbsp;and awkward.&nbsp;Natural selection addressed this issue by causing arousal to attenuate the&nbsp;human&nbsp;disgust response. It’s worth noting that men have&nbsp;a&nbsp;much lower&nbsp;baseline&nbsp;sexual disgust than women,&nbsp;and that sexual excitement&nbsp;further reduces&nbsp;disgust sensitivity in men.&nbsp;In a&nbsp;<a href="http://people.duke.edu/~dandan/webfiles/PapersPI/Sexual%20Arousal%20and%20Decision%20making.pdf" target="_blank" rel="noreferrer noopener">classic paper</a>&nbsp;by Dan Ariely,&nbsp;aroused men&nbsp;had much more positive attitudes about all kinds of unusual sexual acts.&nbsp;Sexually aroused men were&nbsp;more likely to say&nbsp;that it would be fun to watch a woman urinating or that they could imagine getting sexually excited by contact with an animal). 3-D pornography of video game or cartoon characters that might be creepy in a nonsexual context are&nbsp;<a href="https://www.rollingstone.com/glixel/news/daily-glixel-people-were-thirsty-for-overwatch-zelda-porn-in-2017-w515316/the-top-video-game-porn-searches-of-2017-w515317" target="_blank" rel="noreferrer noopener">popular genres</a>. The most direct evidence that men won’t be put off by uncanny vulvas is from a&nbsp;<a href="http://faculty.utrgv.edu/zhixiang.chen/cs6174/papers/Strait_paper2.pdf" target="_blank" rel="noreferrer noopener">paper</a>&nbsp;that laments the “unabashed sexualization of female-gendered robots” in comments on YouTube&nbsp;videos of&nbsp;robots.&nbsp;Bawdy comments&nbsp;on gynoids&nbsp;– “you’ll have to replace it monthly due to semen corrosion,”&nbsp;for example&nbsp;– were more frequent than comments expressing unease.</p>



<p>Perhaps&nbsp;we should encourage&nbsp;some men&nbsp;to use sex robots. Men who get&nbsp;environmental&nbsp;cues that they’re evolutionary dead-ends disproportionately menace society. In the 1980s, evolutionary psychologist couple Wilson and Daly found that perpetrators of violence and homicide had something in common: they were young, single and didn’t have access to the kinds of resources&nbsp;<a href="https://www.economist.com/news/special-report/21688587-young-single-idle-males-are-dangerous-work-and-wedlock-can-tame-them-men-and-mayhem" target="_blank" rel="noreferrer noopener">with which to win mates</a>. Polygynous societies in which wealthier men have access to multiple women are more violent and less stable because they have a class of young men without the prospect of getting a mate. Monogamy, rather than being the state of nature, may have been an …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dianaverse.com/2020/10/30/uncanny-vulvas/">https://dianaverse.com/2020/10/30/uncanny-vulvas/</a></em></p>]]>
            </description>
            <link>https://dianaverse.com/2020/10/30/uncanny-vulvas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24991249</guid>
            <pubDate>Wed, 04 Nov 2020 17:45:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mutated Coronavirus from Minks is a threat to Humans]]>
            </title>
            <description>
<![CDATA[
Score 73 | Comments 47 (<a href="https://news.ycombinator.com/item?id=24990845">thread link</a>) | @xbmcuser
<br/>
November 4, 2020 | https://www.bt.dk/politik/alle-mink-skal-slaas-ihjel-muteret-coronavirus-fra-mink-er-en-trussel-for | <a href="https://web.archive.org/web/*/https://www.bt.dk/politik/alle-mink-skal-slaas-ihjel-muteret-coronavirus-fra-mink-er-en-trussel-for">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    

    

<p>Situationen omkring coronasmitte blandt mink har nu udviklet sig til et kritisk stadie i Nordjylland.</p>
<p>Helt inde i regeringskontorerne kategoriseres situationen som meget alvorlig, og der tales om en coronavirus 2.0.</p>


<p>Derfor har regeringen besluttet, at alle minkbesætninger nu skal slås ihjel, fordi coronavirus er muteret blandt mink og har spredt sig til mennesker.</p>
<p>Det fortæller statsminister Mette Frederiksen på et pressemøde onsdag.</p>
<div><p>»I mister livsværk, som i nogle tilfælde er gået i arv igennem flere generationer. Det er en sorgens dag for jer og for alle, der arbejder i mink-erhvervet. Det er regeringen bevidst om,« siger Mette Frederiksen til minkavlerne.</p><p>En muteret coronavirus er vandret fra mink til mennesker og har siden spredt sig kraftigt blandt borgerne i Nordjylland.</p></div>
<p>Tirsdag modtog regeringen et notat fra Statens Serum Institut (SSI), som har udsat den muterede coronavirus for antistoffer.</p>


<p>Resultatet var ifølge SSI dybt bekymrende, fordi den muterede coronavirus ikke reagerede godt på antistofferne.</p>
<figure itemprop="image" itemscope="" itemtype="https://schema.org/ImageObject">
        <a href="https://bt.bmcdn.dk/media/cache/resolve/image_1240/image/156/1564385/23568501-mink2.jpg" title="When the Danish Veterinary and Food Administration killed mink in Brovst, they had no containers for the dead mink. Therefore, they were just thrown to the ground. Foto: Private photo">
                        <img src="https://bt.bmcdn.dk/media/cache/resolve/image_1240/image/156/1564385/23568501-mink2.jpg" width="" height="" alt="When the Danish Veterinary and Food Administration killed mink in Brovst, they had no containers for the dead mink. Therefore, they were just thrown to the ground." data-original="https://bt.bmcdn.dk/media/cache/resolve/image_1240/image/156/1564385/23568501-mink2.jpg" data-old-src="data:image/gif;base64,R0lGODlhEAAJAIAAAP///wAAACH5BAEAAAAALAAAAAAQAAkAAAIKhI+py+0Po5yUFQA7">
        
    
        </a>
                    <figcaption>
                <span>
                                            When the Danish Veterinary and Food Administration killed mink in Brovst, they had no containers for the dead mink. Therefore, they were just thrown to the ground.
                                                                <span>Foto: Private photo</span>
                                    </span>
            </figcaption>
            <a href="">Vis mere</a>
            
            </figure>

<p>Dermed er der risiko for, at en eventuel vaccine mod covid-19 ikke vil have den ønskede effekt, hvis den muterede virus fra mink spreder sig yderligere blandt mennesker.</p>
<p>Samtidig er bekymringen, at den nye coronavirus fra mink betyder, at alle mennesker, som har været smittet med corona, igen kan blive ramt af den muterede coronavirus.</p>
<p>Der er desuden nye restriktioner på vej for borgere i en række kommuner i det nordjyske for at stoppe spredningen af coronavirussen fra mink.</p>


<p>Det drejer sig indtil videre om kommunerne Hjørring, Frederikshavn, Brønderslev, Jammerbugt, Thisted og Læsø, oplyser Mette Frederiksen.</p>
<p>»Vi ved godt, at vi efterlader jer i Nordjylland i uvished til i morgen. Det beklager jeg. Men vi skal handle nu. Det drejer sig om liv og død ikke kun i Danmark, men i hele verden,« siger Mette Frederiksen.</p>
<p>De nye restriktioner bliver meldt ud torsdag.</p>
<p>Siden regeringen modtog det bekymrende notat fra SSI tirsdag, har man i regeringskontorerne arbejdet på højtryk for at finde ud af, hvilke restriktioner der skal til.</p>


<p>Coronavirussen har spredt sig voldsomt på de danske minkfarme siden sommer. I skrivende stund har mere end 207 minkbesætninger fået konstateret corona, og derfor skal alle disse mink aflives.</p>
<p>Men nu lyder befalingen fra Mette Frederiksen, at samtlige mink på de godt 1.100 minkfarme i Danmark skal aflives.</p>

</div></div>]]>
            </description>
            <link>https://www.bt.dk/politik/alle-mink-skal-slaas-ihjel-muteret-coronavirus-fra-mink-er-en-trussel-for</link>
            <guid isPermaLink="false">hacker-news-small-sites-24990845</guid>
            <pubDate>Wed, 04 Nov 2020 17:06:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Denmark to cull millions of minks over mutated coronavirus]]>
            </title>
            <description>
<![CDATA[
Score 315 | Comments 230 (<a href="https://news.ycombinator.com/item?id=24990724">thread link</a>) | @ndanmand
<br/>
November 4, 2020 | https://www.thelocal.dk/20201104/denmark-to-cull-millions-of-minks-over-mutated-coronavirus | <a href="https://web.archive.org/web/*/https://www.thelocal.dk/20201104/denmark-to-cull-millions-of-minks-over-mutated-coronavirus">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://storage.googleapis.com/ddos-shield.appspot.com/shield-logo-mono-darktext.svg" width="250px" height="50px" alt="Project Shield Logo"></p><p>You will be connected to <b>www.thelocal.dk</b> in just a moment...</p><p><a href="https://g.co/shield">Learn about Project Shield</a></p></div></div>]]>
            </description>
            <link>https://www.thelocal.dk/20201104/denmark-to-cull-millions-of-minks-over-mutated-coronavirus</link>
            <guid isPermaLink="false">hacker-news-small-sites-24990724</guid>
            <pubDate>Wed, 04 Nov 2020 16:54:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Notes on Paxos]]>
            </title>
            <description>
<![CDATA[
Score 145 | Comments 22 (<a href="https://news.ycombinator.com/item?id=24990613">thread link</a>) | @matklad
<br/>
November 4, 2020 | https://matklad.github.io/2020/11/01/notes-on-paxos.html | <a href="https://web.archive.org/web/*/https://matklad.github.io/2020/11/01/notes-on-paxos.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <article>
  
  <p>Nov 1, 2020</p>
  <div id="preamble">
<div>
<p>These are my notes after learning the <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a> algorithm.
The primary goal here is to sharpen my own understanding of the algorithm, but maybe someone will find this explanation of Paxos useful!
This post assumes fluency with mathematical notation.</p>


<p>That means that I didn’t actually understand the algorithm.</p>
<p>What finally made the whole thing click are</p>

<p>I now think that the thing is actually much simpler than it is made to believe :-)</p>
<p>Buckle in, we are starting!</p>
</div>
</div>
<div>
<h2 id="what-is-paxos"><a href="#what-is-paxos"></a>What is Paxos?</h2>
<div>
<p>Paxos is an algorithm for implementing distributed consensus.
Suppose you have <code>N</code> machines which communicate over a faulty network.
The network may delay, reorder, and lose messages (it can not corrupt them though).
Some machines might die, and might return later.
Due to network delays, “machine is dead” and “machine is temporary unreachable” are indistinguishable.
What we want to do is to make machines agree on some value.
“Agree” here means that if some machine says “value is X”, and another machine says “value is Y”, then X necessary is equal to Y.
It is OK for machine to answer “I don’t know yet”.</p>
<p>The problem with this formulation is that Paxos is an elementary, but subtle algorithm.
To understand it (at least for me), a precise, mathematical formulation is needed.
So, let’s try again.</p>
<p>What is Paxos?
Paxos is a theorem about sets!
This is definitely mathematical, and is true (as long as you base math on set theory), but is not that helpful.
So, let’s try again.</p>
<p>What is Paxos?
Paxos is a theorem about nondeterministic state machines!</p>
<p>A system is characterized by a state.
The system evolves in discrete steps: each step takes system from <code>state</code> to <code>state'</code>.
Transitions are non-deterministic: from a single current <code>s1</code>, you may get to different next states <code>s2</code> and <code>s3</code>.
(non-determinism models a flaky network).
An infinite sequence of system’s states is called a behavior:</p>
<div>
<div>
<pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>state_0 → state_1 → ... → state_n → ...
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>Due to non-determinism, there’s a potentially infinite number of possible behaviors.
Nonetheless, depending on the transition function, we might be able to prove that some condition is true for any state in any behavior.</p>
<p>Let’s start with a simple example, and also introduce some notation.
I won’t use TLA+, as I don’t enjoy its concrete syntax.
Instead, math will be set in monospaced unicode.</p>
<p>The example models an integer counter.
Each step the counter decrements or increments (non-deterministically), but never gets too big or too small</p>
<div>
<p>Counter</p>
<div>
<pre><code><table><tbody><tr><td><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
</pre></td><td><pre>Sets:
  ℕ -- Natural numbers with zero

Vars:
  counter ∈ ℕ

Init ≡
  counter = 0

Next ≡
    (counter &lt; 9 ∧ counter' = counter + 1)
  ∨ (counter &gt; 0 ∧ counter' = counter - 1)

Theorem:
  ∀ i: 0 ≤ counter_i ≤ 9

-- Notation
-- ≡: equals by definition
-- ∧: "and", conjunction
-- ∨: "or",  disjunction
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>The sate of the system is a single variable — <code>counter</code>.
It holds a natural number.
In general, we will represent a state of any system by a fixed set of variables.
Even if the system logically consists of several components, we model it using a single unified state.</p>
<p>The <code>Init</code> formula specifies the initial state, the <code>counter</code> is zero.
Note that <code>=</code> is a mathematical equality, and not an assignment.
<code>Init</code> is a <em>predicate</em> on states.</p>
<p><code>Init</code> is true for <code>{counter: 0}</code>.<br>
<code>Init</code> is false for <code>{counter: 92}</code>.</p>
<p><code>Next</code> defines a non-deterministic transition function.
It is a predicate on pairs of states, <code>s1</code> and <code>s2</code>.
<code>counter</code> is a variable in the <code>s1</code> state, <code>counter'</code> is the corresponding variable in the <code>s2</code> state.
In plain English, transition from <code>s1</code> to <code>s2</code> is valid if one of these is true:</p>
<div>
<ul>
<li>
<p>Value of <code>counter</code> in <code>s1</code> is less than <code>9</code> and value of <code>counter</code> in <code>s2</code> is greater by 1.</p>
</li>
<li>
<p>Value of <code>counter</code> in <code>s1</code> is greater than <code>0</code>, and value of <code>counter</code> in <code>s2</code> is smaller by 1.</p>
</li>
</ul>
</div>
<p><code>Next</code> is true for <code>({counter: 5}, {counter: 6})</code>.<br>
<code>Next</code> is false for <code>({counter: 5}, {counter: 5})</code>.</p>
<p>Here are some behaviors of this system:</p>
<div>
<ul>
<li>
<p><code>0 → 1 → 2 → 3 → 4 → 5 → 6 → 7 → 8 → 9</code></p>
</li>
<li>
<p><code>0 → 1 → 0 → 1 → 0 → 1</code></p>
</li>
<li>
<p><code>0 → 1 → 2 → 3 → 3 → 2 → 1 → 0</code></p>
</li>
</ul>
</div>
<p>Here are some <strong>non</strong> behaviors of this system:</p>
<div>
<ul>
<li>
<p><code>1 → 2 → 3 → 4 → 5</code>: <code>Init</code> does not hold for initial state</p>
</li>
<li>
<p><code>0 → 2</code>: <code>Next</code> does not hold for <code>(0, 2)</code> pair</p>
</li>
<li>
<p><code>0 → 1 → 0 → -1</code>: <code>Next</code> does not hold for <code>(0, -1)</code> pair</p>
</li>
</ul>
</div>
<p>“behavior” means that the initial state satisfies <code>Init</code>, and each transition satisfies <code>Next</code>.</p>
<p>We can state and prove a theorem about this system: for every state in every behavior, the value of counter is between 0 and 9.
Proof is by induction:</p>
<div>
<ul>
<li>
<p>The condition is true in the initial state.</p>
</li>
<li>
<p>If the condition is true for state <code>s1</code>, and <code>Next</code> holds for <code>(s1, s2)</code>, then the condition is true for <code>s2</code>.</p>
</li>
<li>
<p>QED.</p>
</li>
</ul>
</div>
<p>As usual with induction, sometimes we would want to prove a <em>stronger</em> property, because it gives us more powerful base for an induction step.</p>
<p>To sum up, we define a non-deterministic state machine using two predicates <code>Init</code> and <code>Next</code>.
<code>Init</code> is a predicate on states which restricts possible initial states.
<code>Next</code> is a predicate on <em>pairs</em> of states, which defines a non-deterministic transition function.
<code>Vars</code> section describes the state as a fixed set of typed variables.
<code>Sets</code> defines auxiliary fixed sets, elements of which are values of variables.
<code>Theorem</code> section specifies a predicate on behaviors: <em>sequences</em> of steps evolving according to <code>Init</code> and <code>Next</code>.</p>
<p>The theorem does not automatically follow from <code>Init</code> and <code>Next</code>, it needs to be proven.
Alternatively, we can simulate a range of possible behaviors on a computer and check the theorem for the specific cases.
If the set of reachable states is small enough (finite would be a good start), we can enumerate <em>all</em> behaviors and produce a brute force proof.
If there are too many reachable states, we can’t prove the theorem this way, but we often can prove it to be wrong, by finding a counter example.
This is the idea behind model checking in general and TLA+ specifically.</p>
</div>
</div>
<div>
<h2 id="what-is-consensus"><a href="#what-is-consensus"></a>What is Consensus?</h2>
<div>
<p>Having mastered the basic vocabulary, let’s start slowly building towards Paxos.
We begin with defining what consensus is.
As this is math, we’ll do it using sets.</p>
<div>
<div>
<pre><code><table><tbody><tr><td><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
</pre></td><td><pre>Sets:
  𝕍 -- Arbitrary set of values

Vars:
  chosen ∈ 2^𝕍 -- Subset of values

Theorem:
    ∀ i: |chosen_i| ≤ 1
  ∧ ∀ i, j: i ≤ j ∧ chosen_i ≠ {} ⇒ chosen_i = chosen_j

-- Notation
-- {}:  empty set
-- 2^X: set of all subsets of X, powerset
-- |X|: cardinality (size) of the set
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>The state of the system is a set of chosen values.
For this set to constitute consensus (over time) we need two conditions to hold:</p>
<div>
<ul>
<li>
<p>at most one value is chosen</p>
</li>
<li>
<p>if we choose a value at one point in time, we stick to it (math friendly: any two chosen values are equal to each other)</p>
</li>
</ul>
</div>
<p>Here’s the simplest possible implementation of consensus:</p>
<div>
<p>Consensus</p>
<div>
<pre><code><table><tbody><tr><td><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
</pre></td><td><pre>Sets:
  𝕍 -- Arbitrary set of values

Vars:
  chosen ∈ 2^𝕍 -- Subset of values

Init ≡
  chosen = {}

Next ≡
  chosen = {} ∧ ∃ v ∈ 𝕍: chosen' = {v}


Theorem:
    ∀ i: |chosen_i| ≤ 1
  ∧ ∀ i, j: i ≤ j ∧ (chosen_i ≠ {} ⇒ chosen_i = chosen_j)
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>In the initial state, the set of chosen values is empty.
We can make a step if the current set of chosen values is empty, in which case we select an arbitrary value.</p>
<p>This technically breaks our behavior theory: we require behaviors to be infinite, but, for this spec, we can only make a single step.
The fix is to allow empty steps: a step which does not change the state at all is always valid.
We call such steps “stuttering steps”.</p>
<p>The proof of the first condition of the consensus theorem is a trivial induction.
The proof of the second part is actually non-trivial, here’s a sketch.
Assume that <code>i</code> and <code>j</code> are indices, which violate the condition.
They might be far from each other in state-space, so we can’t immediately apply <code>Next</code>.
So let’s choose the <em>smallest</em> <code>j1 ∈ [i+1;j]</code> such that the condition is violated.
Let <code>i1 = j1 - 1</code>.
The condition is still violated for <code>(i1, j1)</code> pair, but this time they are subsequent steps, and we can show that <code>Next</code> does not hold for them, concluding the proof.</p>
<p>Yay! We have a distributed consensus algorithm which works for 1 (one) machine:</p>
<div>
<p>Distributed Consensus For One Machine</p>
<ol>
<li>
<p>Pick arbitrary value.</p>
</li>
</ol>
</div>
</div>
</div>
<div>
<h2 id="simple-voting"><a href="#simple-voting"></a>Simple Voting</h2>
<div>
<p>Let’s try to extend this to a truly distributed case, where we have <code>N</code> machine (“acceptors”).
We start with formalizing the naive consensus algorithm: let acceptors vote for values, and select the value which gets a majority of votes.</p>
<div>
<p>Majority Vote</p>
<div>
<pre><code><table><tbody><tr><td><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
</pre></td><td><pre>Sets:
  𝕍 -- Arbitrary set of values
  𝔸 -- Finite set of acceptors

Vars:
  votes ∈ 2^(𝔸×𝕍) -- Set of (acceptor, value) pairs

Init ≡
  votes = {}

Next ≡
  ∃ a ∈ 𝔸:
      ∃ v ∈ V: votes' = votes ∪ {(a, v)}
    ∧ ∀ v ∈ V: (a, v) ∉ votes

chosen ≡
  {v ∈ V: |{a ∈ 𝔸: (a, v) ∈ votes}| &gt; |𝔸| / 2}
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>The state of the system is the set of all votes cast by all acceptors.
We represent a vote as a pair of an acceptor and the value it voted for.
Initially, the set of votes is empty.
On each step, some acceptor casts a vote for some value (adds <code>(a, v)</code> pair to the set of votes), but only if it hasn’t voted yet.
Remember that <code>Next</code> is a predicate on pairs of states, so we check <code>votes</code> for existing vote, but add a new one to <code>votes'</code>.
The value is chosen if the set of acceptors which voted for the value (<code>{a ∈ 𝔸: (a, v) ∈ votes}</code>) is at least half as large as the set of all acceptors.
In other words, if a majority of acceptors has voted for the value.</p>

<p>Let’s prove consensus theorem for Majority Vote protocol.
TYPE ERROR, DOES NOT COMPUTE.
The consensus theorem is a predicate on behaviors of states consisting of <code>chosen</code> variable.
Here, <code>chosen</code> isn’t a variable, <code>votes</code> is!
<code>chosen</code> is a function which maps current state to some boolean.</p>
<p>While it is intuitively clear what “consensus theorem” would look like for this case, let’s make this precise.
Let’s <em>map</em> states with <code>votes</code> variable to states with <code>chosen</code> variable using the majority rule, <code>f</code>.
This mapping naturally extends to a mapping between corresponding behaviors (sequences …</p></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://matklad.github.io/2020/11/01/notes-on-paxos.html">https://matklad.github.io/2020/11/01/notes-on-paxos.html</a></em></p>]]>
            </description>
            <link>https://matklad.github.io/2020/11/01/notes-on-paxos.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24990613</guid>
            <pubDate>Wed, 04 Nov 2020 16:43:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Victims of school bullying are at a higher risk of developing violent behavior]]>
            </title>
            <description>
<![CDATA[
Score 196 | Comments 146 (<a href="https://news.ycombinator.com/item?id=24990064">thread link</a>) | @rustoo
<br/>
November 4, 2020 | https://www.uco.es/ucci/es/noticias-ingles/item/3138-victims-of-school-bullying-are-at-a-higher-risk-of-developing-violent-behavior-in-the-future | <a href="https://web.archive.org/web/*/https://www.uco.es/ucci/es/noticias-ingles/item/3138-victims-of-school-bullying-are-at-a-higher-risk-of-developing-violent-behavior-in-the-future">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>A University of Cordoba and University of Cambridge study analyzed what factors in childhood and adolescence increase the likelihood of having violent behavior in adulthood</p><div>
			
<p>There is another pandemic that humans have been experiencing for a long time now and for which effective preventive measures have yet to be found: violence. This is shown in various ways in different aspects of life and continues to have serious consequences for society, the economy, our health and human relations. The onset of violent behavior can be observed from childhood and adolescence, so studying what aspects lead to the development of these kinds of behaviors and which curb them has become a necessary step in their prevention.</p>
<p>The University of Cordoba and the University of Cambridge have been collaborating for a long time now on research into aspects related to violence, thus helping decrease its risks and prevent it. In their latest piece of research, they studied possible risk and protection factors for violence and, in this way, they verified whether violent behavior can be predicted months or even years before it develops.</p>
<p>Specifically, the study focused on finding out if morality, victimization, empathy and social and emotional skills predict the expression of different violent behaviors in children and adolescents in different contexts, including at school and in a family setting. "These behaviors refer to, for instance, troubling behavior at home, including physical violence towards parents and siblings, at school, including physical violence towards teaching staff and schoolmates, and other settings, including bad behavior in public", explains Raquel Espejo Siles, doctoral student at the University of Cordoba who carried out this research during her stay at the Institute of Criminology at the University of Cambridge thanks to one of the ELMER grants from the Diputación de Córdoba (Cordoba's county government).</p>
<p>Raquel Espejo worked with Izabela Zych, Professor at the Psychology Department at the University of Cordoba and part of the LAECOVI (Study Laboratory on Coexistence and Violence Prevention) research group, whose line of research is this study's framework. The study also had the participation of David P. Farrington, Emeritus Professor of Criminology at the University of Cambridge, and Vicente J. Llorent, Professor at the Education Department at the University of Cordoba.</p>
<p>871 students between 10 and 17 years of age at different Andalusian educational centers took part in the research. They filled out two questionnaires, one in June 2017 and one in June 2018.</p>
<p>Interesting conclusions were drawn from the results. "We found that violence used directly towards people was related to a tendency to make impulsive decisions and to a blind motivation to accomplish one's aims, without regard for the disadvantages or negative consequences from using violence", reveals Raquel Espejo.</p>
<p>What is more, being a victim of bullying was detected as a risk factor for developing violent behavior at home against their family as well as at school. Likewise, those people who were violent in public or in class were shown to have higher scores in moral disengagement, meaning that they usually made excuses so that these acts would seem less serious than they really were.</p>
<p>At school, it was verified that higher scores for social and emotional competencies such as social awareness, self-management, motivation and decision making are protection factors against violence. Therefore, these results support prevention initiatives based on the potential of learning social and emotional skills at home as well as at school.</p>
<p>The data show that reducing victimization in a school setting could be effective in decreasing violence in different contexts in the future. "It is important to prevent violence, both victimization and bullying, since the data found in this study and others indicate that violence is a vicious cycle. Being the aggressor or the victim entails a high risk of developing the opposite role, reinforcing and increasing violence both at school and outside of school", points out Raquel Espejo.</p>
<p>According to this research study, enabling teenagers to reassess their goals and the consequences of their violent behavior could have an impact on decreasing violence further down the road. In addition, teaching different strategies to resolve issues in a different way could help them to compare and see the high individual and social price to pay for violent behavior.</p>
<p>This study is part of the "E-intelligence: risks and opportunities of emotional competencies expressed online" (PSI-2015-64114-R) project of the National Research, Development and Innovation Program, subsidized by the Ministry of Economic Affairs and Competitiveness. With the aim of having greater understanding of the reality of violence in childhood and adolescence, the team will continue to research about violent behavior in face to face and online contexts. Firstly, they have studied the factors that can curb or increase cyberhate in a study funded by the Center for Andalusian Studies. Secondly, they will continue working on the same line of research, investigating the link between bullying and drug use in a study financed by the Ministry of Health.</p>
<p>Raquel Espejo-Siles, Izabela Zych, David P. Farrington, Vicente J. Llorent. Moral disengagement, victimization, empathy, social and emotional competencies as predictors of violence in children and adolescents. Children and Youth Services Review. Doi: <a href="https://doi.org/10.1016/j.childyouth.2020.105337">https://doi.org/10.1016/j.childyouth.2020.105337</a></p>		</div></div>]]>
            </description>
            <link>https://www.uco.es/ucci/es/noticias-ingles/item/3138-victims-of-school-bullying-are-at-a-higher-risk-of-developing-violent-behavior-in-the-future</link>
            <guid isPermaLink="false">hacker-news-small-sites-24990064</guid>
            <pubDate>Wed, 04 Nov 2020 15:49:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Disclosure: Unlimited Chase Ultimate Rewards Points]]>
            </title>
            <description>
<![CDATA[
Score 1097 | Comments 242 (<a href="https://news.ycombinator.com/item?id=24988301">thread link</a>) | @ic4l
<br/>
November 4, 2020 | https://chadscira.com/post/5fa269d46142ac544e013d6e/DISCLOSURE-Unlimited-Chase-Ultimate-Rewards-Points | <a href="https://web.archive.org/web/*/https://chadscira.com/post/5fa269d46142ac544e013d6e/DISCLOSURE-Unlimited-Chase-Ultimate-Rewards-Points">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://chadscira.com/post/5fa269d46142ac544e013d6e/DISCLOSURE-Unlimited-Chase-Ultimate-Rewards-Points</link>
            <guid isPermaLink="false">hacker-news-small-sites-24988301</guid>
            <pubDate>Wed, 04 Nov 2020 12:10:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Get Started with Infection Monkey, Open Source Security Tool]]>
            </title>
            <description>
<![CDATA[
Score 51 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24988227">thread link</a>) | @morchen
<br/>
November 4, 2020 | https://swimm.io/blog/infection-monkey-tutorial-start-contributing-using-swimm/ | <a href="https://web.archive.org/web/*/https://swimm.io/blog/infection-monkey-tutorial-start-contributing-using-swimm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section data-v-f94c7cca=""> <!----> <div data-v-0cf44990="" data-v-f94c7cca=""><div><p><img src="https://swimm.io/media/screen-shot-2020-11-04-at-10.34.43.png" alt="Infection monkey "></p>
<p>Infection Monkey powered by Guardicore is a popular Open Source project and essentially a Breach and Attack Simulation (BAS) tool that analyzes and breaks down the robustness of cloud-based development environments, regardless of if they are of the private or public type.</p>
<p><a href="https://twitter.com/ShayNehmad">Shay Nehmad</a>, a seasoned Open Source developer, and Shreya Malviya, a contributor to Infection Monkey, spoke to the participants about how Swimm is making it easier to contribute to the project and make a difference.</p>
<p>The resiliency to post-breach attacks and lateral movement is done with the help of automatic attack simulations that inject a random machine with a proprietary Infection Monkey code, which helps gauge and discover security loopholes and vulnerabilities. Think of it as an automated Pen Testing tool.</p>
<p>The 48 hour online event devoted to encouraging contributions to open source projects hosted by Brian Douglas of Github,&nbsp; the Open Sauced community and backed by Swimm.</p>
<p>Check out the event <a href="https://www.youtube.com/playlist?list=PLHyZ0Wz_A44Ul9-YwiT-zt-JgEy3lRGns">here</a>.</p>
<h2>Getting Started with Infection Monkey using Swimm</h2>
<p><a href="https://github.com/guardicore/monkey#:~:text=The%20Infection%20Monkey%20is%20an,a%20centralized%20Monkey%20Island%20server.">Infection Monkey</a> is very straightforward and user-friendly. The Monkey, is a proprietary tool that infects random machines in the target environment and propagates to them. And there is Monkey Island, a dedicated centralized dashboard to monitor the results and findings. More about the Infection Monkey installation process <a href="https://www.guardicore.com/infectionmonkey/wt/">here</a>.</p>
<p><img src="https://swimm.io/media/screen-shot-2020-11-04-at-11.02.48.png" alt="The Map" title="github.com/guardicore/monkey"></p>
<p>Besides being a non-intrusive and plug-and-play tool, Infection Monkey requires zero maintenance and runs around the clock for comprehensive security analysis. Furthermore, users can also get actionable insights and recommendations with the ability to define alerts as per their requirements.</p>
<blockquote>
<p>Swimm makes the onboarding of contributors to open source projects easier. Since everything related to Swimm is within the Infection Monkey (henceforth: IM) repository, all that you have to do is to clone that repo, start the terminal, and run the command “swimm start” on your terminal.</p>
</blockquote>
<p>Once the server starts, it automatically opens the Swimm homepage, which already has playlists for IM. Currently, the repository includes three playlists (Post-breach action, Configuration, and System Info Collection). For this tutorial, we will use an extra-verbose playlist called “Adding a PBA in 5 Simple Steps”.</p>
<p><img src="https://lh6.googleusercontent.com/wbkmZQhpI08v8F6ivT_mEp0Dsa7mAQ-g9xS4VGAs5-GZniEwnEl_BHm4ui5BqxZRB613RULmPIk1uXOmsVQOVCR5xFmHjUevYXWcrkOk7Rs6BdYT-qQe9bZGhZL-aC1neoYxnROu" alt=""></p>
<p>In a nutshell, Infection Monkey is a penetration testing tool and it simulates a person breaking into your system. Once the person is inside your system, they can perform additional actions after conducting the breach. In IM terminology, these are referred to as the “post-breach actions” or PBAs.</p>
<h4>Define What Your New PBA Does</h4>
<p>This is the actual coding step. As the name suggests, it basically defines what your new PBA does. So, briefly, you have to define what this step will do in IM (as stated in the description). This step also gives you instructions to run the manual test after you are done. But first, let’s do the main coding part.</p>
<p>All you have to do is copy the command from the Swimm interface and run it on your terminal. This will give you some information about this particular unit.</p>
<p><img src="https://lh4.googleusercontent.com/n--uGoeV2gCm-JCZzKWr3nchhCZsHE8AkrldGNKm-L6uzNRQ4LDeB1zjwooiiENFs5_AAvdu3nSLMKeW0EUTfcewurPHMBbs_3a5RA0F_Nva7nfwAURu_3FGKjhO9QVSejoWHFL6" alt=""></p>
<p>For example, the “Definition of done” says that you need a new constant defining what the PBA does. Now, you can ask Swimm to tell you which particular files are relevant to this specific Unit by running the command “Swimm Files”. It shows you the name of one file which is relevant to this Unit.</p>
<p><img src="https://lh3.googleusercontent.com/vtfc9Vr61m_8KQr9uOBS6eK2qMRVgoeCPZRuatXYzAVR40xiq41d3jKJKNql6FRg5GIDNwo26-2X2PPhMAsXNlboVXxKwwcOXdHMrf0bun0_ZYCQtUGOGQxvxRfUSmHS-GEgg4i_" alt=""></p>
<blockquote>
<p>“This is pretty cool if you think about how you would do personal onboarding with someone. You would guide them toward the files relevant to what you are teaching.” - Shay Nehmad</p>
</blockquote>
<p>So we have to see how to define the name of the PBA which is to be done in this file. This really shows how building the Unit correctly can “emulate” or replace the personal onboarding process. Also, another thing we should notice here is that this particular file is in the module called “common”.</p>
<p>This suggests that everything we will do here is going to affect both the Monkey and the Swimm server. Open this file.</p>
<p><img src="https://lh4.googleusercontent.com/lnAb1DR5i9wnsoAZJNe76VeHqwv0wW4xyI9drUrGrH8MgXU6GK_-DRCbL8OGFHCfumQfR0KlvKALtpT-KMfox3wTMdbt0RDAyi89AZZ7CJx9ojaycexEHjTJshfvqdAXyoDGfMxd" alt=""></p>
<p>The comments generated by Swimm show you where you need to add your code. But if you are not sure about what to do next, Swimm provides hints via the command `swimm hint`.</p>
<p>If you go back to the file and look at that PBA, it basically tells you what the PBA with the name “Timestomping” does. That’s how you will also define the name of your new PBA. Add your new PBA “POST_BREACH_SCHEDULE_JOBS” and save the file. You have refined your new PBA, but how do we know this works?</p>
<p><img src="https://lh5.googleusercontent.com/ZMTPTwtUn17Qz2ABXXby8GipDAQSj9vwCgdlWgzYq85FoEBCOHHfkdijUQ5pBFPM-zXneonQNd1fuD0BFgWKtcc3tCE2CxvwD7dOelMiHXvAh9ahDusmIWZWCaEKe84Jghxvreom" alt=""></p>
<p>It's pretty easy when you are using Swimm. Let’s go back to the Swimm interface and learn about some easy and straightforward instructions to run the test.</p>
<p><img src="https://lh4.googleusercontent.com/oj-L3LjKzRhVqKbmPagGdHtkj-AoNYzEgKJ0P8tcg4es6sf1s-TnbG-Ig3BR0t4quDKl6UummO4FJXc-ifobCpWy79QOY-OfQYFexiqYVB3QnrFMxxnZ1dnFvuTuBapRClBTVMyN" alt=""></p>
<p>Let’s study the result of this test from its image.</p>
<p><img src="https://lh3.googleusercontent.com/bVQos7iG-I40XJfiDKJ7DH-SnUCed0Xtp5csLgqyLAmDTlUWkqzSRuG6H5DZB6xaLgav7qzcnEhIZrZRW1PZMemZyWYlVLp2YNNWH6Sjdfpz9jAcS4mCxMBKv_SAPd4W91wsmu7o" alt=""></p>
<p>Whatever you added to the PBA definitions file, you should be able to see in the test report. Once you are done studying it, you can mark it as done with the command `swimm done`. This will take you to a Swimm status page (see below) that also allows you to compare your solution to the original codebase.</p>
<p><img src="https://lh4.googleusercontent.com/nU2b4mGCv-mhVLPL8PotXYIeFC70Sid_prw7-oBbknXgnHJxIDSNG8DcwMZ6-19m90mJW4MPX6tEcHPLr3D6YkoO8A90Lya1T0iA9U8My7Eb3BTZntGwb20p6Tf256apGCynI5il" alt=""></p>
<h2>Implement a New PBA</h2>
<p>Now, we know that the schedule jobs PBA is pretty dangerous because if someone is able to schedule jobs on your system, they can leave open a backdoor or ensure a virus downloads itself in case it gets deleted.</p>
<p>So do you now have to schedule jobs in your operating systems? Luckily, Infection Monkey already has these commands in the codebase.</p>
<p><img src="https://lh6.googleusercontent.com/Wc1t9yejLqPPj7VTsIiOB-yIh9N-EVy27EiH9conClOaIA1HAtSpgXlqXrRK0zTqSxK2v1I7Wzw0z94HlAZy8mzfOV0D9sZ-tu5vU1MpfTJi_szhgNGrBjU2v-VRRVfiH0_tsUpI" alt=""></p>
<p>So, all you need to do is fetch commands from a function called `get_commands_to_schedule_jobs`.</p>
<p>Once again, the description of this Unit also shows a manual test to run after writing the code. Just like in the previous Unit, we can play the Unit by copying the command from the Swimm interface and running it on your terminal. You can also request Swimm to tell you the relevant files with the same command.</p>
<p><img src="https://lh3.googleusercontent.com/bMfq0Tlu_TT2BXFJ6z7Bb9SCrN158jAPBO-UKGbhAj2XLqISnxL3c6T_cKXpSGXV-FPlYcgVyQ2R7ejaeFsYM71saNVBIbiIFJ8T3irHqE75aE1TtBp7UORLrR1uAljI3NmkEBZJ" alt=""></p>
<p>This time it tells you that the relevant file is in a module called “infection_monkey” which suggests that whatever we will be doing is going to affect the Monkey (i.e. the virtual intruder simulated by Infection Monkey) itself. This makes sense because you will basically be adding new functionality.</p>
<p>So, once you open the file, you will see a comment that tells you where you need to add your new code. This is something that leaves no place for error.</p>
<p><img src="https://lh4.googleusercontent.com/wD6oSMRb2YH2qY-ZJALKj3FEs10TJO7GaZuU2CFJW2ysPjvYvyPVolFmakq549bFyec4P_hsDNr1iPqpijLwDE6uWEizlQdn9YeJMCMeiQ3BCrd5-8v-ulefx5vfCSaoyouk5EVT" alt=""></p>
<p>Let’s ask Swimm for more hints about how to proceed with coding in this Unit.</p>
<p><img src="https://lh4.googleusercontent.com/ffI32iZ3jXpwLuGRb-EGO9tQyZLRIQASQa5AUFY2tImzdEo8ZVMqoNkg0T0h6iniEx-IfowbVRxNpnUELuWi3eGjBidBtl9dP8BINBHzP5AVCkZ__u0hrW6n1EYw4t8JqaMtHTNX" alt=""></p>
<p>Swimm provides you with two hints. Let’s go ahead with the first one which suggests you check the “Time Stomping” PBA to get an idea about the implementation.</p>
<p><img src="https://lh5.googleusercontent.com/RtASkWQPjlZjjUAdFvzPXiV0Zttvuj7VxpbODATTF1aALEv4B9kKhas61sDZO7ikmID77Bs7jX2EF7n1Du-RD8djCShbTW2EpXZZy3dCyG9svG8OoXaoC_z7lgP49NHSxxgY35Vz" alt=""></p>
<p>We can see here that we are basically fetching Linux and Windows commands from a function called `get_timestomping_commands`. Then you will call the constructor for the parent class with the name of the PBA, the Linux commands, and the Windows commands as arguments.</p>
<p>So, you will do something similar to “schedule jobs” PBA.</p>
<p><img src="https://lh4.googleusercontent.com/HhKuTh0wzVAHddeJHHGY7PYUKSweb0TdHtM3hgd3WPgYVIfNL1bKzRuUsvwbH0RC1ml4wsNeivKW9AxrjUd9CvBF6wNQO0txtFfJJPFcljUrS50Gd5P3jSS8fVBygPubLS3ZMGdk" alt=""></p>
<p>Here, you can see the code fetches the commands from the function given in the description and it calls the constructor of the parent class.</p>
<p>Swimm has given you a second hint that notifies you to remove your PBA by removing the schedule jobs.</p>
<p>For that purpose, you can see a call to the function called `remove_scheduled_jobs`.</p>
<p>You can really walk through each line of the solution and see how building the Unit correctly nudged whoever’s solving it to write each line. So, from lines 13 to 18, that was the first hint telling you the general structure of how to implement post-breach actions in IM that are based on shell commands.</p>
<p>Following the hint shows you an example of how to write that code. Another cool thing pops up when we look at line 16. We can see the code is pulling the name of the PBA from the variable we defined in the previous Unit. The last line is from the second hint.</p>
<p>You may decide to not look at the hints and go blind trying to solve it. In this case, when you mark your unit done in Swimm and then compare it to the actual solution, you’ll find that discrepancy. If you forgot to remove the scheduled jobs, you will find it in the diff. It’s up to you as the Swimmer to choose if you’d rather see hints or not.</p>
<p>Now that you have added the code, let’s run the manual test by following the instructions in the Unit’s description.</p>
<p><img src="https://lh6.googleusercontent.com/h2EUcy5vZxKp9DkINaiSFjQ-5Yv7f_MtnaL5q27cucqc61GrB7xU1OlTH1w5W_1PCKJJE4Pkk1nRdAVlcsDg1EZshdSJvzHqkJS8SlV1_A5icgii59WgGcXCVtVGUX2JJPpR2gZp" alt=""></p>
<p>You can see in the attack report that it successfully scheduled a job using `crontab`. Let’s mark the Unit as done in Swimm with the command `swimm done`. Just like the last step, you will be taken to a page that gives you more information about what changes you’ve just made.</p>
<p><img src="https://lh5.googleusercontent.com/gintBnsEcmxzAzpSPUnZfi8t1657nzb4b0votoNDt9C3sVe6MkR28hl_taR46cOsVwidaJ3imRdeV439FMYmQq6VLxTEe1k6AWR7Ct7bdLSC7SKEj7YdLxL1gjyozdSNewzooDeX" alt=""></p>
<p>This summary guides the person solving the Unit to read other parts of the code. Now that you have made some contributions, you are already more familiar with the lexicon, and manually tested your changes, you now have the context to figure out the code much quicker and improve your productivity when contributing to Infection Monkey!</p>
<p><img src="https://lh5.googleusercontent.com/Ue285WOS8WBBNqmcS6QndVxB1ZHrt2U_CzeKFqxRSqP-ylm-j5nmseJ1L6l-vVNCu2ZOvh68qJGynji0p6iEyOv8Ri5eFfKKi3yV3BH2ONLZ2E7eNccTyWx6Y9rvNo8kG4Z1t9eR" alt=""></p>
<p>Once again, Swimm will let you compare your solution to the original codebase. Now that you named the PBA and implemented it, the next step is to make sure that it actually shows up in the configuration. So, let’s move on to the fourth step, where you will be adding details about your PBA.</p>
<h2>Add Details About Your New PBA</h2>
<p><img src="https://lh6.googleusercontent.com/_eTNZp-OGjYt84lmYqnQZR9_TB2QWd_I7X9T5i9cyLvDdi9vSt-2fdDdFvhdlPkG_REI1Iq9vSKoPzyACek-EqstoIe6FbZxj8wFgIhTPMf_NYUqZpyNKK0rSBiixcwsJ5mZ2bcO" alt=""></p>
<p>This is actually a pretty good example of how learning begets learning. Whenever you are trying to learn something new, you come across new terms, new terminology, and you look it up and research it. The MITRE ATT&amp;CK technique is something you will encounter a lot and you need to be ready for it.</p>
<blockquote>
<p>“The MITRE ATT&amp;CK framework is an open-source knowledge base of attack tactics and techniques which were derived from real-world scenarios. This is something professionals in the cybersecurity industry refer to a lot." - Shreya Malviya</p>
</blockquote>
<p>In this particular example, the “schedule jobs” PBA is related to two MITRE techniques that are shown in the description with their IDs. They basically do what the PBA does - scheduling jobs for Linux and Windows.</p>
<p><img src="https://lh6.googleusercontent.com/3mTHvCgEGmqJY6erSnouIhmtLugxxaCAJfOI56umZVBcgOypbl_12zUMzrtItPzrYFle2ClJwaPV74bK2k7egoJLUZTcGBTXh_QZPFNJlxGdqUBi6fnaY42VA54THouAaQtVzdka" alt=""></p>
<p>Here you can see a short recording of how the finder test should look so that it’s easier to ensure that whatever you’ve done is correct. Now, you …</p></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://swimm.io/blog/infection-monkey-tutorial-start-contributing-using-swimm/">https://swimm.io/blog/infection-monkey-tutorial-start-contributing-using-swimm/</a></em></p>]]>
            </description>
            <link>https://swimm.io/blog/infection-monkey-tutorial-start-contributing-using-swimm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24988227</guid>
            <pubDate>Wed, 04 Nov 2020 11:54:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to Google Cloud Functions]]>
            </title>
            <description>
<![CDATA[
Score 75 | Comments 47 (<a href="https://news.ycombinator.com/item?id=24987197">thread link</a>) | @adrianancona
<br/>
November 4, 2020 | https://ncona.com/2020/11/introduction-to-google-cloud-functions/ | <a href="https://web.archive.org/web/*/https://ncona.com/2020/11/introduction-to-google-cloud-functions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Cloud Functions are Google’s offering for serverless architecture (similar to AWS lambdas).</p>

<h2 id="what-is-serverless">What is serverless?</h2>

<p>Before we look into how to use Cloud Functions, we should understand some things about it.</p>

<p>Code needs servers to run, so <code>serverless</code> doesn’t mean there are no servers, it means that we don’t need to manage those servers ourselves.</p>

<p>In a usual server based architecture, we might create a service and deploy it to a machine. This service will be running in the machine all the time waiting for requests. This has the disadvantage that even if there are no requests, the machine would need to be up, and incurring cost.</p>

<p>On the other hand, if we use Cloud Functions, we write a service and register it with Google. Google will then listen to the endpoint this service cares about and will only start it when there are requests. If it detects that there haven’t been requests for some time, it will stop the service again.</p>

<!--more-->

<p>While Google Compute Engine instances are billed by time, Cloud Functions are billed by execution time. If a Cloud Function is not being executed, then it is not being billed. This sounds very attractive, but there are draw backs, namely:</p>

<ul>
  <li>Running a Compute Engine instance for a full month is most of the time cheaper than having a Cloud Function executing for one month straight. This means that if we need a service to be always doing work, it’s better to get a whole machine for it.</li>
  <li>Cloud Functions need to warm up. If a Cloud Function hasn’t been used for a while, Google will stop the server that was running it. Next time we get a new request, a new server needs to be started, which takes some time. This will make this first request take long (This time varies a lot, but usually less than 4 seconds)</li>
</ul>

<p>For these reasons, serverless shouldn’t be used in all scenarios.</p>

<h2 id="creating-a-cloud-function">Creating a Cloud Function</h2>

<p>To make it easy to work on our Cloud Function, we need a way to run the function from our development machine.</p>

<p>Let’s start by creating a module:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre>mkdir test-functions
cd test-functions
go mod init test.com/functions
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Now, we can create a file for our function:</p>



<p>With this content:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
</pre></td><td><pre><span>package</span> <span>functions</span>

<span>import</span> <span>(</span>
	<span>"net/http"</span>
	<span>"fmt"</span>
<span>)</span>

<span>func</span> <span>DoYouLikeTacos</span><span>(</span><span>w</span> <span>http</span><span>.</span><span>ResponseWriter</span><span>,</span> <span>r</span> <span>*</span><span>http</span><span>.</span><span>Request</span><span>)</span> <span>{</span>
	<span>fmt</span><span>.</span><span>Fprint</span><span>(</span><span>w</span><span>,</span> <span>"Of course I like tacos!</span><span>\n</span><span>"</span><span>)</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>To be able to test our functions from our development machine, we need to create a server. Let’s create a file for it:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre>mkdir cmd
touch cmd/main.go
</pre></td></tr></tbody></table></code></pre></div></div>

<p>And add this content:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
</pre></td><td><pre><span>package</span> <span>main</span>

<span>import</span> <span>(</span>
  <span>"log"</span>
  <span>"context"</span>
  <span>"github.com/GoogleCloudPlatform/functions-framework-go/funcframework"</span>
  <span>"test.com/functions"</span>
<span>)</span>

<span>func</span> <span>main</span><span>()</span> <span>{</span>
  <span>ctx</span> <span>:=</span> <span>context</span><span>.</span><span>Background</span><span>()</span>

  <span>// Our function will be executed when a request to /do-you-like-tacos is received</span>
  <span>if</span> <span>err</span> <span>:=</span> <span>funcframework</span><span>.</span><span>RegisterHTTPFunctionContext</span><span>(</span>
      <span>ctx</span><span>,</span> <span>"/do-you-like-tacos"</span><span>,</span> <span>functions</span><span>.</span><span>DoYouLikeTacos</span><span>);</span> <span>err</span> <span>!=</span> <span>nil</span> <span>{</span>
    <span>log</span><span>.</span><span>Fatalf</span><span>(</span><span>"funcframework.RegisterHTTPFunctionContext: %v</span><span>\n</span><span>"</span><span>,</span> <span>err</span><span>)</span>
  <span>}</span>

  <span>// The server will run on port 8080</span>
  <span>port</span> <span>:=</span> <span>"8080"</span>
  <span>if</span> <span>err</span> <span>:=</span> <span>funcframework</span><span>.</span><span>Start</span><span>(</span><span>port</span><span>);</span> <span>err</span> <span>!=</span> <span>nil</span> <span>{</span>
    <span>log</span><span>.</span><span>Fatalf</span><span>(</span><span>"funcframework.Start: %v</span><span>\n</span><span>"</span><span>,</span> <span>err</span><span>)</span>
  <span>}</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>To run the server:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre>cd cmd
go run main.go
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Once the server is running, we can use curl to test it:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>curl localhost:8080/do-you-like-tacos
</pre></td></tr></tbody></table></code></pre></div></div>

<p>The output should be:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>Of course I like tacos!
</pre></td></tr></tbody></table></code></pre></div></div>

<p>This example is very simple, but we can have our fucntion do whatever we want.</p>

<p>We can also add more functions by adding more files and updating our <code>main.go</code> server. Let’s create another function just to show it.</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre>cd ..
touch cerveza.go
</pre></td></tr></tbody></table></code></pre></div></div>

<p>With this content:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
</pre></td><td><pre><span>package</span> <span>functions</span>

<span>import</span> <span>(</span>
	<span>"net/http"</span>
	<span>"fmt"</span>
<span>)</span>

<span>func</span> <span>Thirsty</span><span>(</span><span>w</span> <span>http</span><span>.</span><span>ResponseWriter</span><span>,</span> <span>r</span> <span>*</span><span>http</span><span>.</span><span>Request</span><span>)</span> <span>{</span>
	<span>fmt</span><span>.</span><span>Fprint</span><span>(</span><span>w</span><span>,</span> <span>"Cerveza, por favor</span><span>\n</span><span>"</span><span>)</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>And add this to <code>cmd/main.go</code>:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
</pre></td><td><pre>  <span>if</span> <span>err</span> <span>:=</span> <span>funcframework</span><span>.</span><span>RegisterHTTPFunctionContext</span><span>(</span>
      <span>ctx</span><span>,</span> <span>"/thirsty"</span><span>,</span> <span>functions</span><span>.</span><span>Thirsty</span><span>);</span> <span>err</span> <span>!=</span> <span>nil</span> <span>{</span>
    <span>log</span><span>.</span><span>Fatalf</span><span>(</span><span>"funcframework.RegisterHTTPFunctionContext: %v</span><span>\n</span><span>"</span><span>,</span> <span>err</span><span>)</span>
  <span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Run the server:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre>cd cmd
go run main.go
</pre></td></tr></tbody></table></code></pre></div></div>

<p>And hit the new url:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>curl localhost:8080/thirsty
</pre></td></tr></tbody></table></code></pre></div></div>

<h2 id="deploying-to-google-cloud">Deploying to Google Cloud</h2>

<p>Once we have our functions ready, we want to make them available to the public by deploying them to Google Cloud.</p>

<p>From the root of our project we can use this command:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre>gcloud functions deploy DoYouLikeTacos \
    --runtime go113 --trigger-http --allow-unauthenticated
</pre></td></tr></tbody></table></code></pre></div></div>

<p>This will spit out a bunch of information. The most important part is the URL:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre>httpsTrigger:
  url: https://us-central1-proj-1234567.cloudfunctions.net/DoYouLikeTacos
</pre></td></tr></tbody></table></code></pre></div></div>

<p>We can curl this endpoint, the same way we did for our local endpoint:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>curl https://us-central1-proj-1234567.cloudfunctions.net/DoYouLikeTacos
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Let’s take a closer look to the command we used to deploy our function:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre>gcloud functions deploy DoYouLikeTacos \
    --runtime go113 --trigger-http --allow-unauthenticated
</pre></td></tr></tbody></table></code></pre></div></div>

<ul>
  <li><code>DoYouLikeTacos</code> is the name of the function we are deploying. The tool will search the package for a function with that name.</li>
  <li><code>--runtime go113</code> tells google to use Golang 1.13. We can see the available runtimes in the help (<code>gcloud functions deploy --help</code>)</li>
  <li><code>--trigger-http</code> means that an http endpoint will be assigned to the function</li>
  <li><code>--allow-unauthenticated</code> means that the function will be available for everybody without authentication. Note that the function code itself could expect some kind of authentication independently of this flag</li>
</ul>

<h2 id="conclusion">Conclusion</h2>

<p>This was a quick introduction to Google Cloud Functions. We learned how to create a function, test it locally and deploy it to Google Cloud.</p>

<p>Complete applications can be built using Cloud Functions, so I’ll explore a little more in another article.</p>

  </div></div>]]>
            </description>
            <link>https://ncona.com/2020/11/introduction-to-google-cloud-functions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24987197</guid>
            <pubDate>Wed, 04 Nov 2020 08:04:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[All systems go for UK’s £55M fusion energy experiment]]>
            </title>
            <description>
<![CDATA[
Score 247 | Comments 76 (<a href="https://news.ycombinator.com/item?id=24986528">thread link</a>) | @danboarder
<br/>
November 3, 2020 | https://ccfe.ukaea.uk/all-systems-go-for-uks-55m-fusion-energy-experiment/ | <a href="https://web.archive.org/web/*/https://ccfe.ukaea.uk/all-systems-go-for-uks-55m-fusion-energy-experiment/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
						
			<div>
			
			
<article id="post-14051">
  
  <div>

		<div data-hide-featured-media="0">
      
        <div><p>Clean energy from fusion is a step closer with the launch of the MAST Upgrade tokamak.</p>
<div id="attachment_14062"><p><img aria-describedby="caption-attachment-14062" src="data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgOTYwIDY0MCIgd2lkdGg9Ijk2MCIgaGVpZ2h0PSI2NDAiIGRhdGEtdT0iaHR0cHMlM0ElMkYlMkZjY2ZlLnVrYWVhLnVrJTJGd3AtY29udGVudCUyRnVwbG9hZHMlMkYyMDIwJTJGMTAlMkZnb3YudWtfLmpwZyIgZGF0YS13PSI5NjAiIGRhdGEtaD0iNjQwIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPjwvc3ZnPg==" data-spai="1" alt="MAST Upgrade first plasma" width="400" height="267" sizes="(max-width: 400px) 100vw, 400px"></p><p id="caption-attachment-14062">MAST Upgrade first plasma</p></div>
<p>For the first time, after a seven-year build, UKAEA’s £55M-machine, labelled <a href="https://ccfe.ukaea.uk/research/mast-upgrade/">Mega Amp Spherical Tokamak (MAST) Upgrade</a>, has achieved “first plasma” – where all the essential components work together simultaneously.</p>
<p>The project at Culham Centre for Fusion Energy was funded by the Engineering &amp; Physical Sciences Research Council, part of UK Research &amp; Innovation and the Department for Business, Energy &amp; Industrial Strategy.</p>
<p>Fusion energy offers the potential of an abundant, inherently safe low-carbon electricity supply (the raw materials are found in seawater and the Earth’s crust). It involves fusing hydrogen particles in a hot gas known as a ‘plasma’ to unlock large amounts of energy.</p>
<p>Operating fusion technologies requires a careful balancing act of controlling extreme heat, gas and powerful magnetic fields, amongst other complex systems.</p>
<h3>Super-X factor</h3>
<p>One of the biggest challenges in fusion research has been to extract the amount of excess heat from the plasma. UKAEA’s scientists now plan to test a new exhaust system called the ‘Super-X divertor’ at MAST Upgrade.</p>
<p>This system is designed to channel plasma out of the machine at temperatures low enough for its materials to withstand – meaning that components can last much longer. The approximate tenfold reduction in heat arriving at the internal surfaces of the machine has the potential to be a game-changer for the long-term viability of future fusion power stations.</p>
<h3>A step towards fusion power</h3>
<p>MAST Upgrade will be the forerunner of the UK’s prototype fusion power plant, <a href="https://ccfe.ukaea.uk/research/step/">Spherical Tokamak for Energy Production (“STEP”)</a>, due for completion by 2040.</p>
<p>STEP – which UKAEA is designing in an initial £220 million programme funded by the UK Government – will be based on MAST Upgrade’s ‘spherical tokamak’ fusion concept. The spherical tokamak could offer a route to a compact fusion power plant. The success of MAST Upgrade is another step along the way to designing future fusion power facilities, which could have an important role as part of a future portfolio of low-carbon energy.</p>
<p>MAST Upgrade will also aid preparations for <a href="https://www.iter.org/" target="_blank" rel="noopener noreferrer">ITER</a> – the world’s largest science megaproject, now being built in the South of France, which intends to demonstrate fusion power on an industrial scale.</p>
<p><iframe title="Shaping fusion power for the future - Mega Amp Spherical Tokamak Upgrade" width="1080" height="608" src="https://www.youtube.com/embed/PVUnOZwrSx8?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p>UK Science Minister, Amanda Solloway, said: “We want the UK to be a world leader in fusion energy and to capitalise on its amazing potential as a clean energy source that could last for hundreds of years.</p>
<p>“Backed by £55 million of government funding, powering up the MAST Upgrade device is a landmark moment for this national fusion experiment and takes us another step closer towards our goal of building the UK’s first fusion power plant by 2040.”</p>
<p>Commenting on the achievement of first plasma, UKAEA CEO, Professor Ian Chapman, said:</p>
<p>“MAST Upgrade will take us closer to delivering sustainable, clean fusion energy. This experiment will break new ground and test technology that has never been tried before. It ensures the UK is in the premier league of countries working on fusion – and will be vital in achieving UKAEA’s goal of building the STEP fusion power plant.”</p>
<p>Video of the first plasma on MAST Upgrade:</p>

</div>        
      </div><!--/post-content-->
      
    </div><!--/inner-wrap-->
    
</article>
		</div><!--/post-area-->
			
							
		</div></div>]]>
            </description>
            <link>https://ccfe.ukaea.uk/all-systems-go-for-uks-55m-fusion-energy-experiment/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24986528</guid>
            <pubDate>Wed, 04 Nov 2020 05:01:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Three Months of Go from a Haskeller’s perspective (2016)]]>
            </title>
            <description>
<![CDATA[
Score 175 | Comments 156 (<a href="https://news.ycombinator.com/item?id=24986132">thread link</a>) | @amzans
<br/>
November 3, 2020 | https://memo.barrucadu.co.uk/three-months-of-go.html | <a href="https://web.archive.org/web/*/https://memo.barrucadu.co.uk/three-months-of-go.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemscope="" itemtype="http://schema.org/BlogPosting" itemprop="mainEntity">
      

      <article>
        
<header>
  
</header>

<section itemprop="articleBody">
<p>This summer I’ve been interning at <a href="https://pusher.com/">Pusher</a>, and have been writing a lot of Go. It’s been a bit of a change coming from a Haskell background, so I decided to write up my thoughts now, at the end.</p>
<h2 id="the-good">The Good</h2>
<h3 id="incredibly-easy-to-pick-up">Incredibly easy to pick up</h3>
<p>There’s not a lot to Go, it’s quite a small language. I had never written a line of it before June, and now I’ve written about 30,000. It’s very easy to get started and become productive.</p>
<p>Haskell, on the other hand, is notorious for being hard to learn (<em>cough</em> monad tutorials <em>cough</em>). People often find it really hard to take the step from evaluating pure mathematical expressions to writing actual programs. I experienced no such disconnect in Go.</p>
<h3 id="garbage-collector-keeps-getting-better-and-better">Garbage collector keeps getting better and better</h3>
<p>Pusher previously tried to use Haskell for the project I was working on, but eventually had to give up due to unpredictable latency caused by garbage collection pauses. GHC’s garbage collector is <a href="https://blog.pusher.com/latency-working-set-ghc-gc-pick-two/">designed for throughput, not latency</a>. It is a generational copying collector, which means that pause times are proportional to the amount of live data in the heap. To make matters worse, it’s also stop-the-world.</p>
<p><a href="https://blog.golang.org/go15gc">Go’s garbage collector</a> is a concurrent mark-sweep with very short stop-the-world pauses, and it just seems to <a href="https://golang.org/doc/go1.7#performance">keep getting better</a>. This is definitely a good thing for a garbage collected language. We did have some issues with unacceptable latencies, but were able to work them all out. No such luck with the Haskell project.</p>
<h3 id="style-wars-are-a-thing-of-the-past">Style wars are a thing of the past</h3>
<p>Say what you like about <code>gofmt</code>, but it makes arguments over code style almost impossible. Just run it on save, and your code will always be consistently formatted.</p>
<p>I do find it a little strange that <code>gofmt</code> has been completely accepted, whereas Python’s significant whitespace (which is there for exactly the same reason: enforcing readable code) has been much more contentious across the programming community.</p>
<h2 id="the-neutral">The Neutral</h2>
<h3 id="code-generation-seems-to-be-the-accepted-solution-to-a-lot-of-problems">Code generation seems to be the accepted solution to a lot of problems</h3>
<p>I am not a huge fan of code generation (and I say this as <a href="https://blog.pusher.com/go-interface-fuzzer/">the author of a code generation tool</a>). I think it can do good, but it can also obscure what’s actually going on. In every discussion on Go generics, someone will come along and say you can add generics with code generation: that’s true, but at the cost of introducing additional, nonstandard, syntax.</p>
<p>I suspect the strong culture of code generation is largely because it lets you work around the flaws of the language.</p>
<h3 id="strict-not-lazy-evaluation">Strict, not lazy, evaluation</h3>
<p>Strict evaluation is typically better for performance than lazy evaluation (thunks cause allocation, so you’re gambling that <a href="https://www.barrucadu.co.uk/posts/2016-02-12-strict-vs-lazy.html">the computation saved offsets the memory cost</a>), but it does make things less composable. There have been a couple of times where I’ve gone to split up a function, only to realise that doing so would require allocating a data structure in memory which before was not needed.</p>
<p>I could trust the compiler to inline things for me, and so optimise away the additional allocations, but in a lazy language you just don’t have that issue at all.</p>
<h3 id="the-standard-library-is-not-so-great">The standard library is not so great</h3>
<p>If you know me in person, it might seem a little odd that I specifically comment on this. Normally I am all for languages having a small, really well-written, stdlib and everything else provided through libraries. I am picking on Go here a bit because the standard library seems to get a lot of praise, but I was unimpressed.</p>
<p>Parts of it are good, a lot of it is mediocre, and some of it is downright bad (like the <a href="https://golang.org/pkg/go/ast/">go/ast</a> package documentation). It seems a lot of Go’s use is in webdev, so perhaps those bits of the stdlib (which I haven’t touched at all) are consistently good.</p>
<h2 id="the-bad">The Bad</h2>
<p>I also agree with this Quora answer by Tikhon Jelvis to <a href="https://www.quora.com/Do-you-feel-that-golang-is-ugly">do you feel that golang is ugly?</a>, so have a look at that once you’ve read this section.</p>
<h3 id="a-culture-of-backwards-compatibility-at-all-costs">A culture of “backwards compatibility at all costs”</h3>
<p>In Go, you import packages by URL. If the URL points to, say, GitHub, then <code>go get</code> downloads HEAD of master and uses that. There is no way to specify a version, unless you have separate URLs for each version of your library.</p>
<p>This is just insane.</p>
<p>Go has a very strong culture of backwards compatibility, which I think is largely due to this. Even if you have a flaw in the API of your library, you can’t actually <em>fix</em> it because that would break all of your reverse-dependencies, unless they do vendoring, or pin to a specific commit.</p>
<p>Coming from the Haskell world, where the attitude is far more towards correctness than compatibility, this was probably the biggest culture shock for me. Things break backwards compatibility in Haskell, and the users just update their code because they <em>know</em> the library author did it for a reason. In Go, it just doesn’t happen <em>at all</em>.</p>
<h3 id="the-type-system-is-really-weak">The type system is really weak</h3>
<p>A common mantra in Haskell is “make illegal states unrepresentable,” which is great. If you’ve never come across it before it means to <em>choose your types such that an illegal value is a static error</em>. Want to avoid nulls? Use an option type. Want to ensure a list has at least one element? Use a nonempty list type. Use proper enums, not just ints. etc etc</p>
<p>In Go you just can’t do that, the type system isn’t strong enough. So a lot of things which are (or can be) a <em>compile-time</em> error in Haskell are a <em>runtime</em> error in Go, which is just worse.</p>
<p>Let’s pick on some specifics:</p>
<ul>
<li><p><strong>No generics</strong></p>
<p>Want to write a tree where every element is statically <em>guaranteed</em> to be the same type? Well, have fun implementing a “uinttree”, an “inttree”, a “stringtree”, and so on. You can’t just implement a generic tree.</p>
<p>But Go <em>does</em> have generics, for the built-in types. Arrays, channels, maps, and slices all have generic type parameters. So it seems that the Go developers want generics, but they don’t want to bother implementing it properly, so it remains a special case for a few things in the compiler.</p></li>
<li><p><strong>No sum types</strong></p>
<p>The way in Go to handle possibly-failing functions is to have multiple return values: an actual result, and an error. If the error is <code>nil</code>, then the actual result is sensible; otherwise the actual result is meaningless.</p>
<p>This means you can forget to check the error and use a bogus result and, because there are no compiler warnings (another wtf), you will know nothing of this until things fail at runtime.</p>
<p>With a sum type, like <code>Either error result</code>, that just can’t happen.</p></li>
<li><p><strong>No separation of pure code from effectful code</strong></p>
<p>It is very nice to know, just by looking at the type of a function, that it <em>cannot</em> perform any side-effects. Go’s type system doesn’t do that.</p></li>
</ul>
<h3 id="the-tooling-is-bad">The tooling is bad</h3>
<p>Haskell gets a lot of criticism for bad tooling, but I think it’s worlds ahead of Go in some cases.</p>
<ul>
<li><p><strong>Godoc makes it really difficult to write good documentation</strong></p>
<p>Godoc groups bindings by type, and then sorts alphabetically. Code is not written like that, code is written with related functions in proximity to each other. The source order is <em>almost always</em> better than how godoc sorts things.</p>
<p>Also, <a href="https://github.com/golang/go/issues/7873">godoc doesn’t even support lists</a>:</p>
<blockquote>
<p>Previous proposals similar to this have been rejected on grounds that it’s a slippery slope from this to Markdown or worse.</p>
</blockquote>
<p>I think that comment is particularly discouraging. Because the developers don’t like Markdown (and similar languages), they refuse to add even the most basic of formatting to godoc.</p></li>
<li><p><strong>There is nothing like GHC’s heap profiling</strong></p>
<p>Go has a snapshot-based memory profiler. You can take a snapshot at a point in time, and see which functions and types are taking up the heap space. However, there is <a href="https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/profiling.html#profiling-memory-usage">nothing like this</a>.</p>
<p>Being able to see not only a snapshot, but also how things have changed over time, is incredibly useful for spotting memory leaks. If all you have is a snapshot, all you can really say is “well, the number of allocated <code>Foo</code>s looks a bit high, is that right?” With a graph you can say “the number of allocated <code>Foo</code>s is increasing when it shouldn’t be.”</p></li>
<li><p><strong>There is (was?) nothing like ThreadScope</strong></p>
<p><a href="https://wiki.haskell.org/ThreadScope">ThreadScope</a> is a tool for profiling performance of concurrent Haskell programs. It shows which Haskell threads are running on which OS threads, when garbage collection happens, and a bunch of other information.</p>
<p>If things are slower than expected, it’s great: you can see <em>exactly</em> how things are executing. Go doesn’t <em>currently</em> have anything like it, although towards the end of Dave Cheney’s <strong>Seven ways to profile Go applications</strong> talk at <a href="http://golanguk.com/">GolangUK</a>, he did whip out something which looked rather like ThreadScope (sadly, a video isn’t up at the time of writing, that I can see).</p></li>
</ul>
<h3 id="zero-values-are-almost-never-what-you-want">Zero values are almost never what you want</h3>
<p>Go avoids the issue of uninitialised memory by having “zero values”. If you declare a variable of type <code>int</code>, but don’t give it a value, it gets the value 0. Simple.</p>
<p>Except that that’s almost never what you want.</p>
<p>What is a sensible default value for a type? Well, it depends on what you’re using it for! Sometimes there isn’t a sensible default, and not initialising a value should be an error. You can’t define a zero value for your own types, so you’re kind of stuck.</p>
<p>Zero values caused so many problems over the summer, because everything would <em>appear</em> to be fine, then it suddenly breaks because the zero value wasn’t sensible for its context of use. Perhaps it’s an unrelated change that causes things to break (like a struct getting an extra field).</p>
<p>I would much rather:</p>
<ol type="1">
<li>Drop the syntax for declaring a variable without giving it a value.</li>
<li>Make it an error to not initialise a struct field.</li>
</ol>
<h3 id="lots-of-boilerplate">Lots of boilerplate</h3>
<p>The cause of the lots of code generation, I feel.</p>
<ul>
<li><p>Because you have to check error values, if you want to perform a sequence of possibly-erroring computations, where the successful result of one feeds into the next, there is a lot of typing. In Haskell, you’d just use the <code>Either</code> monad.</p></li>
<li><p>If you want to sort a slice, because there are no generics, you need to wrap the slice in another type and implement three methods on that type. So that’s four lines of code to sort a slice of uints, four lines to sort a slice of uint8s, …</p></li></ul></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://memo.barrucadu.co.uk/three-months-of-go.html">https://memo.barrucadu.co.uk/three-months-of-go.html</a></em></p>]]>
            </description>
            <link>https://memo.barrucadu.co.uk/three-months-of-go.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24986132</guid>
            <pubDate>Wed, 04 Nov 2020 02:33:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bevy 0.3: game engine built in Rust]]>
            </title>
            <description>
<![CDATA[
Score 240 | Comments 54 (<a href="https://news.ycombinator.com/item?id=24983956">thread link</a>) | @_cart
<br/>
November 3, 2020 | https://bevyengine.org/news/bevy-0-3/ | <a href="https://web.archive.org/web/*/https://bevyengine.org/news/bevy-0-3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><img src="https://bevyengine.org/news/bevy-0-3/sheep_game.png"></p>
      
    
  </div><div><p>A little over a month after releasing Bevy 0.2, and thanks to <strong>59</strong> contributors, <strong>122</strong> pull requests, and our <a href="https://github.com/sponsors/cart"><strong>generous sponsors</strong></a>, I'm happy to announce the <strong>Bevy 0.3</strong> release on <a href="https://crates.io/crates/bevy">crates.io</a>!</p>
<p>For those who don't know, Bevy is a refreshingly simple data-driven game engine built in Rust. You can check out <a href="https://bevyengine.org/learn/book/getting-started/">Quick Start Guide</a> to get started. Bevy is also free and open source forever! You can grab the full <a href="https://github.com/bevyengine/bevy">source code</a> on GitHub.</p>
<p>Here are some of the highlights from this release:</p>
<h2 id="initial-android-support">Initial Android Support</h2>

<p>You can try out the <a href="https://github.com/bevyengine/bevy/tree/master/examples/android">Bevy Android example</a> by following the <a href="https://github.com/bevyengine/bevy/blob/master/examples/README.md#android">instructions here</a>. While many things work, please note that this is <em>very hot</em> off the presses. Some features will work and others probably won't. Now is a great time to dive in and help us close the gaps!</p>
<p><img src="https://bevyengine.org/news/bevy-0-3/android.png" alt="android"></p>
<p>This was a massive group effort that spanned multiple projects:</p>
<ul>
<li>Bevy: rewrote bevy-glsl-to-spirv to support android / static libraries (@PrototypeNM1, @enfipy)</li>
<li>Bevy: <code>bevy_asset</code> backend using Android Asset Manager (@enfipy)</li>
<li>Bevy: Touch support (@naithar)</li>
<li>Bevy: Texture format fix (@enfipy)</li>
<li>Bevy: UI touch fixes, touch force, and android example (@enfipy)</li>
<li>Cpal: android audio support (@endragor) </li>
<li>android-ndk-rs / cargo-apk: fix to support Bevy project structure (@PrototypeNM1)</li>
</ul>
<h2 id="initial-ios-support">Initial iOS Support</h2>
<p>authors: @simlay, @MichaelHills, @Dash-L, @naithar</p>
<p>Bevy can now run on iOS!</p>
<p><img src="https://bevyengine.org/news/bevy-0-3/ios.png"></p><p>You can try out the <a href="https://github.com/bevyengine/bevy/tree/master/examples/ios">Bevy iOS example</a> by following the <a href="https://github.com/bevyengine/bevy/tree/master/examples#ios">instructions here</a>. This one is also hot off the presses: some features will work and others probably won't.</p>
<p>This was another large group effort that spanned multiple projects:</p>
<ul>
<li>Bevy: XCode Project / Example (@simlay with help from @MichaelHills)</li>
<li>Bevy: Runtime shader compilation using shaderc (@MichaelHills)</li>
<li>Bevy: Rodio upgrade (@Dash-L)</li>
<li>Bevy: Touch support (@naithar)</li>
<li>Winit: Fix iOS portrait view (@MichaelHills) </li>
<li>RustAudio: iOS support (@simlay and @MichaelHills)</li>
</ul>
<p>Known issues:</p>
<ul>
<li><a href="https://github.com/RustAudio/cpal/pull/485">Audio doesn't quite work yet</a></li>
</ul>
<h2 id="wasm-asset-loading">WASM Asset Loading</h2>
<p>authors: @mrk-its (and ported to the new AssetIo by @cart)</p>
<p>@mrk-its has been hard at work on expanding Bevy's WASM support. In this release we landed WASM asset loading. You can now load assets when you publish to WASM just like you would on any other platform:</p>
<pre><code><span>asset_server</span><span>.</span><span>load</span><span>("</span><span>sprite.png</span><span>");
</span></code></pre>
<p>If the asset hasn't already been loaded, this will make a <code>fetch()</code> request to retrieve the asset over HTTP.</p>
<p>@mrk-its has also been building a custom WebGL2 <code>bevy_render</code> backend. It is already pretty usable, but its not <em>quite</em> ready yet. Expect more news on this soon!</p>
<h2 id="touch-input">Touch Input</h2>
<p>authors: @naithar</p>
<p>Bevy now has support for touches:</p>
<pre><code><span>fn </span><span>touch_system</span><span>(</span><span>touches</span><span>: </span><span>Res</span><span>&lt;</span><span>Touches</span><span>&gt;) {
    </span><span>// you can iterate all current touches and retrieve their state like this:
    </span><span>for</span><span> touch </span><span>in</span><span> touches</span><span>.</span><span>iter</span><span>() {
        </span><span>println!</span><span>("</span><span>active touch: {:?}</span><span>",</span><span> touch</span><span>);
    }

    </span><span>for</span><span> touch </span><span>in</span><span> touches</span><span>.</span><span>iter_just_pressed</span><span>() {
        </span><span>println!</span><span>("</span><span>just pressed {:?}</span><span>",</span><span> touch</span><span>);
    }

    </span><span>for</span><span> touch </span><span>in</span><span> touches</span><span>.</span><span>iter_just_released</span><span>() {
        </span><span>println!</span><span>("</span><span>just released {:?}</span><span>",</span><span> touch</span><span>);
    }

    </span><span>for</span><span> touch </span><span>in</span><span> touches</span><span>.</span><span>iter_just_cancelled</span><span>() {
        </span><span>println!</span><span>("</span><span>just cancelled {:?}</span><span>",</span><span> touch</span><span>);
    }
}
</span></code></pre>
<p>You can also consume raw touch events using the <code>Events&lt;TouchInput&gt;</code> resource.</p>
<h2 id="asset-system-improvements">Asset System Improvements</h2>
<p>authors: @cart</p>
<h3 id="asset-handle-reference-counting">Asset Handle Reference Counting</h3>
<p>Assets are now automatically freed when their "handle reference count" reaches zero. This means you no longer need to think about freeing assets manually:</p>
<pre><code><span>// Calling load() now returns a strong handle:
</span><span>let</span><span> handle </span><span>=</span><span> asset_server</span><span>.</span><span>load</span><span>("</span><span>sprite.png</span><span>");

</span><span>// Note that you no longer need to unwrap() loaded handles. Ergonomics for the win!

// Cloning a handle increases the reference count by one
</span><span>let</span><span> second_handle </span><span>=</span><span> handle</span><span>.</span><span>clone</span><span>();

</span><span>// Spawn a sprite and give it our handle
</span><span>commands</span><span>.</span><span>spawn</span><span>(</span><span>SpriteComponents </span><span>{
</span><span>    material</span><span>:</span><span> materials</span><span>.</span><span>add</span><span>(</span><span>handle</span><span>.</span><span>into</span><span>()),
    ..</span><span>Default</span><span>::</span><span>default</span><span>()
});

</span><span>// Later in some other system:
</span><span>commands</span><span>.</span><span>despawn</span><span>(</span><span>sprite_entity</span><span>);

</span><span>// There are no more active handles to "sprite.png", so it will be freed before the next update
</span></code></pre><h3 id="asset-loaders-can-now-load-multiple-assets">Asset Loaders can now load multiple assets</h3>
<p>In past releases, <code>AssetLoaders</code> could only produce a single asset of a single type. In <strong>Bevy 0.3</strong>, they can now produce any number of assets for any type. The old behavior was extremely limiting when loading assets like GLTF files, which might produce many meshes, textures, and scenes. </p>
<h3 id="sub-asset-loading">Sub-Asset Loading</h3>
<p>Sometimes you only want to load a specific asset from an asset source. You can now load sub assets like this:</p>
<pre><code><span>// Mesh0/Primitive0 references the first mesh primitive in "my_scene.gltf"
</span><span>let</span><span> mesh </span><span>=</span><span> asset_server</span><span>.</span><span>load</span><span>("</span><span>my_scene.gltf#Mesh0/Primitive0</span><span>");
</span></code></pre><h3 id="assetio-trait">AssetIo Trait</h3>
<p>The <code>AssetServer</code> is now backed by the <code>AssetIo</code> trait. This allows us to load assets from whatever storage we want. This means on desktop we now load from the filesystem, on Android we use the Android Asset Manager, and on the web we make HTTP requests using the <code>fetch()</code> api.</p>
<h3 id="asset-dependencies">Asset Dependencies</h3>
<p>Assets can now depend on other assets, which will automatically be loaded when the original asset is loaded. This is useful when loading something like a "scene" which might reference other asset sources. We utilize this in our new GLTF loader.</p>
<h3 id="removed-assetserver-load-sync">Removed AssetServer::load_sync()</h3>
<p>This might rustle some feathers, but <code>AssetServer::load_sync()</code> had to go! This api wasn't WASM friendly, encouraged users to block game execution for the sake of convenience (which causes "hitching"), and was incompatible with the new AssetLoader api. Asset loading is now always asynchronous. Users of <code>load_sync()</code> should instead <code>load()</code> their assets, check load status in their systems, and change game state accordingly. </p>
<h2 id="gltf-scene-loader">GLTF Scene Loader</h2>
<p>authors: @cart</p>
<p>Up until this point, the GLTF loader was painfully limited. It could only load the first mesh with a single texture in a GLTF file. For <strong>Bevy 0.3</strong>, we took advantage of the asset system improvements to write a new <code>GltfLoader</code> that loads GLTF files as Bevy <code>Scenes</code>, along with all meshes and textures in the files.</p>
<p>Here's Bevy loading the Khronos Flight Helmet example, which consists of multiple meshes and textures!</p>
<p><img src="https://bevyengine.org/news/bevy-0-3/flight_helmet.png" alt="flight helmet"></p>
<p>Here is the complete code for a system that loads a GLTF file and spawns it as a scene:</p>
<pre><code><span>fn </span><span>load_gltf_system</span><span>(</span><span>mut </span><span>commands</span><span>:</span><span> Commands, </span><span>asset_server</span><span>: </span><span>Res</span><span>&lt;</span><span>AssetServer</span><span>&gt;) {
    </span><span>let</span><span> scene_handle </span><span>=</span><span> asset_server</span><span>.</span><span>load</span><span>("</span><span>models/FlightHelmet/FlightHelmet.gltf</span><span>");
</span><span>    commands</span><span>.</span><span>spawn_scene</span><span>(</span><span>scene_handle</span><span>);
}
</span></code></pre><h2 id="bevy-ecs-improvements">Bevy ECS Improvements</h2>
<p>authors: @cart</p>
<h3 id="query-ergonomics">Query Ergonomics</h3>
<p>In this release I finally was able to remove the one thing I <em>truly despised</em> in Bevy ECS. In previous versions of Bevy, iterating over the components in a <code>Query</code> looked like this:</p>
<pre><code><span>for </span><span>(</span><span>a</span><span>,</span><span> b</span><span>) in &amp;</span><span>mut</span><span> query</span><span>.</span><span>iter</span><span>() {
    </span><span>// The `&amp;mut` here just felt so unnatural
</span><span>}

</span><span>// Or if you preferred you could do this
</span><span>for </span><span>(</span><span>a</span><span>,</span><span> b</span><span>) in</span><span> query</span><span>.</span><span>iter</span><span>().</span><span>iter</span><span>() {
    </span><span>// query.iter().iter()? Really???
</span><span>}
</span></code></pre>
<p>Similarly, retrieving a specific entity's component's looked like this:</p>
<pre><code><span>if let </span><span>Ok</span><span>(</span><span>mut</span><span> result</span><span>) =</span><span> query</span><span>.</span><span>entity</span><span>(</span><span>entity</span><span>) {
    </span><span>if let </span><span>Some</span><span>((</span><span>a</span><span>,</span><span> b</span><span>)) =</span><span> result</span><span>.</span><span>get</span><span>() {
        </span><span>// access components here
    </span><span>}
}
</span></code></pre>
<p>In <strong>Bevy 0.3</strong> you can just do this:</p>
<pre><code><span>// iteration
</span><span>for </span><span>(</span><span>a</span><span>,</span><span> b</span><span>) in</span><span> query</span><span>.</span><span>iter</span><span>() {
    </span><span>// sweet ergonomic bliss
</span><span>}

</span><span>// entity lookup
</span><span>if let </span><span>Ok</span><span>((</span><span>a</span><span>,</span><span>b</span><span>)) =</span><span> query</span><span>.</span><span>get</span><span>(</span><span>entity</span><span>) {
    </span><span>// boilerplate be gone!
</span><span>}
</span></code></pre>
<p>You might naturally be thinking something like:</p>
<p><em>Why did this take so long? Why would removing a single <code>&amp;mut</code> be hard?</em></p>
<p>It's a long story! In summary:</p>
<ul>
<li>The old api looked the way it did for a reason. It was the result of good design choices that protect against unsafe memory access in a parallel environment.</li>
<li><code>query.iter()</code> didn't actually return an iterator. It returned a <em>wrapper</em> that held an atomic lock on the component storages. The same was true for the type returned by <code>query.entity()</code></li>
<li>Removing these "wrapper types" would have allowed unsafe behavior because another Query could access the same components in a way that violated Rust's mutability rules.</li>
<li>Due to the iterator implementation and quirks in the rust compiler, removing the wrapper type <em>tanked</em> iteration performance by about ~2-3x.</li>
</ul>
<p>Fortunately we finally found ways to solve all of these problems. The newly added <code>QuerySets</code> allow us to completely remove the locks (and wrapper types). And by completely rewriting <code>QueryIter</code> we were able to avoid the performance hit that removing the wrapper incurred. Read on for the details!</p>
<h3 id="100-lockless-parallel-ecs">100% Lockless Parallel ECS</h3>
<p>Bevy ECS is now completely lock free. In Bevy 0.2, we made direct <code>World</code> access and "for-each" systems lock free. This is possible because the Bevy ECS scheduler ensures that systems only run in parallel in ways that respect Rust's mutability rules. </p>
<p>We couldn't remove locks from <code>Query</code> systems because of systems like this:</p>
<pre><code><span>fn </span><span>conflicting_query_system</span><span>(</span><span>mut </span><span>q0</span><span>: </span><span>Query</span><span>&lt;&amp;</span><span>mut</span><span> A</span><span>&gt;</span><span>, </span><span>mut </span><span>q1</span><span>: </span><span>Query</span><span>&lt;(&amp;</span><span>mut</span><span> A, </span><span>&amp;</span><span>B</span><span>)&gt;) {
    </span><span>let</span><span> a </span><span>=</span><span> q0</span><span>.</span><span>get_mut</span><span>(</span><span>some_entity</span><span>).</span><span>unwrap</span><span>();
    </span><span>let </span><span>(</span><span>another_a</span><span>,</span><span> b</span><span>) =</span><span> q1</span><span>.</span><span>get_mut</span><span>(</span><span>some_entity</span><span>).</span><span>unwrap</span><span>();
    </span><span>// Aaah!!! We have two mutable references to some_entity's A component!
    // Very unsafe!
</span><span>}
</span></code></pre>
<p>The locks ensured that the second <code>q1.get_mut(some_entity)</code> access panicked, keeping us nice and safe. In <strong>Bevy 0.3</strong>, a system like <code>conflicting_query_system</code> will fail when the schedule is constructed. By default, <em>systems cannot have conflicting queries</em>.</p>
<p>However there are some cases where a system <em>needs</em> conflicting queries to do what it needs to do. For these cases, we added <code>QuerySets</code>: </p>
<pre><code><span>fn </span><span>system</span><span>(</span><span>mut </span><span>queries</span><span>: </span><span>QuerySet</span><span>&lt;(</span><span>Query</span><span>&lt;&amp;</span><span>mut</span><span> A</span><span>&gt;</span><span>, Query</span><span>&lt;(&amp;</span><span>mut</span><span> A, </span><span>&amp;</span><span>B</span><span>)&gt;)&gt;) {
    </span><span>for</span><span> a </span><span>in</span><span> queries</span><span>.</span><span>q0_mut</span><span>().</span><span>iter_mut</span><span>() {
    }

    </span><span>for </span><span>(</span><span>a</span><span>,</span><span> b</span><span>) in</span><span> queries</span><span>.</span><span>q1_mut</span><span>().</span><span>iter_mut</span><span>() {
    }
}
</span></code></pre>
<p>By putting our conflicting <code>Queries</code> in a <code>QuerySet</code>, the Rust borrow checker protects us from unsafe query accesses.</p>
<p>Because of this, we were able to remove <em>all</em> safety checks from <code>query.iter()</code> and <code>query.get(entity)</code>, which means these methods are now <em>exactly</em> as fast as their <code>World</code> counterparts (which we made lock-free in Bevy 0.2). </p>
<h3 id="performance-improvements">Performance Improvements</h3>
<p>Bevy had a number of nice performance improvements this release:</p>
<ul>
<li>Removed atomic locks from Query access, making Bevy ECS 100% lock free</li>
<li>Removed archetype "safety checks" from Query access. At this point we have already verified …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bevyengine.org/news/bevy-0-3/">https://bevyengine.org/news/bevy-0-3/</a></em></p>]]>
            </description>
            <link>https://bevyengine.org/news/bevy-0-3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24983956</guid>
            <pubDate>Tue, 03 Nov 2020 21:04:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mind-Melting Decision Proves a Dialer Can Never Be Too Old to Be an ATDS]]>
            </title>
            <description>
<![CDATA[
Score 86 | Comments 38 (<a href="https://news.ycombinator.com/item?id=24983532">thread link</a>) | @guerrilla
<br/>
November 3, 2020 | https://tcpaworld.com/2020/11/03/heres-your-tcpa-distraction-for-a-normal-tuesday-with-nothing-else-going-on-mind-melting-decision-proves-a-dialer-can-never-be-too-old-to-be-an-atds/ | <a href="https://web.archive.org/web/*/https://tcpaworld.com/2020/11/03/heres-your-tcpa-distraction-for-a-normal-tuesday-with-nothing-else-going-on-mind-melting-decision-proves-a-dialer-can-never-be-too-old-to-be-an-atds/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p><em>Editor’s Note: Welcome Hackers! Not sure how Hacker News found this article but I see a ton of folks headed in from that website, which I presume is some sort of aggregator for news articles of interest to folks that like to hack stuff. Feel free to have a look around the website–<a href="https://tcpaworld.com/podcast/">check out our cool podcast</a>–and tell any friends that might like this nerdy stuff. But don’t hack anything please. Thanks.&nbsp;</em></p>
<p>Since there is absolutely nothing else going on today I figured I’d share one of the weirdest TCPA cases I’ve seen recently.</p>
<p>So apparently some guy in Nebraska named Mort who really doesn’t like a gas station called Bucky’s Gas Station. He hates it so much, in fact, that he has created a stark raving mad loony-toons (my opinion) gripes board on the internet to assail it. You can visit it, if you’d like, but be warned that your brain will melt a little: <a href="http://www.buckysgasstationsucks.com/">www.buckysgasstationsucks.com</a>.</p>
<p>I spent more time than I’d care to admit reviewing the website last night but I can’t quite figure out where the beef originated. (If you can figure it out let me know, as I am actually genuinely curious.)</p>
<p>So Bucky’s Gas Station is owned by a guy named Buchanan— who I will assume goes by Bucky whether he wants to or not—and his wife who have allegedly been subjected to years of abuse at the hands of Mort using something called a FaxTel 2000, which is something directly out of a 90s era Simpsons. Apparently Mort revs up his FaxTel 2000 and blasts Bucky and his wife with unwanted messages from time to time, just to make sure Bucky remembers how much Mort dislikes him.</p>
<p>Not stopping there, Mort also—allegedly—encourages members of the public to blast poor Bucky with calls “day and night” and to do the same with his associates and neighbors, many of whose contact information is listed on the brain-melting website. As the order tersely words it: “<em>[Mort] encourages members of the public to contact the Buchanans, their neighbors, and others they are affiliated with; and notes that the Buchanans and others will be contacted daily and nightly regarding Sullivan’s grievances</em>.”</p>
<p>Since I don’t actually know why Mort is so agitated by Bucky I can’t say that his conduct is totally inappropriate. I mean, maybe Bucky threw Mort’s puppy in a microwave or something. But either way the conduct of blasting someone’s cell phone with unwanted messages is illegal—if an ATDS is used.</p>
<p>And here’s where things finally get interesting in this yawner of a case.</p>
<p>The Plaintiff alleged that FaxTel 2000 is an autodialer because, I mean, look at the thing.</p>
<p><img data-attachment-id="9016" data-permalink="https://tcpaworld.com/2020/11/03/heres-your-tcpa-distraction-for-a-normal-tuesday-with-nothing-else-going-on-mind-melting-decision-proves-a-dialer-can-never-be-too-old-to-be-an-atds/faxtel-20007jpeg/" data-orig-file="https://i0.wp.com/tcpaworld.com/wp-content/uploads/2020/11/FAXTEL-20007jpeg.jpg?fit=350%2C267&amp;ssl=1" data-orig-size="350,267" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="FAXTEL 20007jpeg" data-image-description="" data-medium-file="https://i0.wp.com/tcpaworld.com/wp-content/uploads/2020/11/FAXTEL-20007jpeg.jpg?fit=300%2C229&amp;ssl=1" data-large-file="https://i0.wp.com/tcpaworld.com/wp-content/uploads/2020/11/FAXTEL-20007jpeg.jpg?fit=350%2C267&amp;ssl=1" loading="lazy" src="https://i0.wp.com/tcpaworld.com/wp-content/uploads/2020/11/FAXTEL-20007jpeg.jpg?resize=300%2C229&amp;ssl=1" alt="" width="300" height="229" srcset="https://i0.wp.com/tcpaworld.com/wp-content/uploads/2020/11/FAXTEL-20007jpeg.jpg?resize=300%2C229&amp;ssl=1 300w, https://i0.wp.com/tcpaworld.com/wp-content/uploads/2020/11/FAXTEL-20007jpeg.jpg?w=350&amp;ssl=1 350w" sizes="(max-width: 300px) 100vw, 300px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/tcpaworld.com/wp-content/uploads/2020/11/FAXTEL-20007jpeg.jpg?resize=300%2C229&amp;ssl=1 300w, https://i0.wp.com/tcpaworld.com/wp-content/uploads/2020/11/FAXTEL-20007jpeg.jpg?w=350&amp;ssl=1 350w" data-lazy-src="https://i0.wp.com/tcpaworld.com/wp-content/uploads/2020/11/FAXTEL-20007jpeg.jpg?resize=300%2C229&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p>But Mort had a clever response—this device is so old and beaten up that it can no longer dial randomly and sequentially, plus no replacement parts are available so it lacks the capacity to dial that way in the future either. So it can’t possibly meet the TCPA’s ATDS definition.</p>
<p>I mean, its kind of a brilliant argument if you think about it (and your mind has melted a little.)</p>
<p>Unfortunately for Mort, however, the case was decided at the pleadings stage and the Court simply could not accept Mort’s assertions on the FaxTel’s dialing capacity as those “facts” were outside the pleadings. Instead the Court had to accept Bucky’s claim that the dialer had all the needed functionality to behave as an ATDS.</p>
<p>Undeterred, Mort also argued that the TCPA infringed on his First Amendment rights but—as <strong><a href="https://tcpaworld.com/2020/10/29/happy-halloween-tcpaworld-heres-are-the-top-10-scariest-tcpa-stories-going-to-freak-you-out-this-halloween/">readers of my Halloween column know</a></strong>—the Constitution won’t save you in TCPAWorld.</p>
<p>*Insert left-over evil laugh from Halloween bargain bin here*</p>
<p>Mort finished his motion to dismiss with a claim that the TCPA only applies to telemarketing harassment, not good-ole-fashioned harassment harassment. No dice. The Court looks at the words of the statute and cannot find the “I just want to abuse people out of spite” TCPA exemption.</p>
<p>On the other hand, and somewhat amusingly, the Court refused to enter a preliminary injunction prohibiting Mort’s conduct finding that it wanted more information and evidence before doing so. Under the circumstances of this case one might have thought ordering one party to temporarily stop blasting the other with&nbsp; robocalls would have been pretty perfunctory. But I guess the Court also wants to know about the condition of Mort’s puppies before ordering him to stop FaxTeling Bucky.</p>
<p>The case is <em>Buchanan v. Sullivan</em>, 8:20-CV-301, 2020 U.S. Dist. LEXIS 202519 (D. Ne. October 30, 2020).</p>
<p>And now you may return to your low-anxiety and worry free Tuesday.</p>
<p>Hey, look at that bird outside.</p>
<p><strong>UPDATE: 11/3/2020 at 2:24 pm pacific</strong></p>
<p>So I apparently have a new team of hackers that work for me– Czar of TCPAWorld and Czar of the Hackers?– and they think they’ve uncovered what happened here. Below is an exchange from a hacker news message board, because that’s how I roll now:</p>

	</div></div>]]>
            </description>
            <link>https://tcpaworld.com/2020/11/03/heres-your-tcpa-distraction-for-a-normal-tuesday-with-nothing-else-going-on-mind-melting-decision-proves-a-dialer-can-never-be-too-old-to-be-an-atds/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24983532</guid>
            <pubDate>Tue, 03 Nov 2020 20:19:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Decision Journal in Notion]]>
            </title>
            <description>
<![CDATA[
Score 74 | Comments 16 (<a href="https://news.ycombinator.com/item?id=24983435">thread link</a>) | @saviorand
<br/>
November 3, 2020 | https://optemization.com/decision-journal-notion | <a href="https://web.archive.org/web/*/https://optemization.com/decision-journal-notion">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><article id="decision-journal-notion"><p><span><span>Using the Farnam Street framework to prompt you to document and reflect on important decisions. Digitally templated in Notion. </span></span></p><h2><span id="288d7840441747b18e822ebbbc8ad065"></span><span><span>"Your success will be the sum of the decisions you make over your career."</span></span></h2><p><span><span>Says Shane Parish, author, mental model expert and the founder and CEO of Farnam Street (FS), a company focused on timeless ideas for upgrading life and business. FS runs a remarkable newsletter,  podcast and community on multidisciplinary thinking and mental models. </span></span></p><p><span><span>Members include students, teachers, CEOs, coaches, athletes, artists, leaders, followers, politicians, and more. They’re not defined by gender, age, income, geography, or politics but rather by a shared passion for living a meaningful life, doing good, and avoiding problems before they happen.</span></span></p><p><span><span>I found Parrish on Twitter, where he compresses and shares FS learning into digestible fire tweets like these ones (that's why I love Twitter):</span></span></p><h2><span id="e3f5175809104bc08c044cc9a1d8622f"></span><span><span>Decision Journal</span></span></h2><p><span><span>In 2014, Parish shared the "decision journal ", a tool to "collect accurate and honest feedback on what you were thinking at the time you made a certain decision that will help you see when you were stupid and lucky as well as when you were smart and unlucky; all to make better decisions."</span></span></p><p><span><span>Read more about the thinking and structure behind this decision making framework at the link below.</span></span></p><p><span><span>Later, FS came out with a pocket-sized journal capture decisions with a pen (who uses those anymore). </span></span></p><div id="c28b706b637d401c847f6452fb722421"><div id="8911e52c145840c3b08b1b092b19e9cd"><div id="707ab5d696434b29bb032672582f06da"><picture><source srcset="https://api.super.so/asset/optemization.com/41fd0e7f-be21-4730-9937-33c6fe959acd.png?w=300&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/41fd0e7f-be21-4730-9937-33c6fe959acd.png?w=300" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/41fd0e7f-be21-4730-9937-33c6fe959acd.png?w=300&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/41fd0e7f-be21-4730-9937-33c6fe959acd.png?w=300" alt="image" loading="lazy"></picture></div></div><div id="f31dee76d0ec4c7e883d9dfddf29f1c5"><div id="b1f81624f9754bf98987069098c371d4"><picture><source srcset="https://api.super.so/asset/optemization.com/6aea8598-b36d-4f59-8e84-0f11c6227ba4.gif?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/6aea8598-b36d-4f59-8e84-0f11c6227ba4.gif?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/6aea8598-b36d-4f59-8e84-0f11c6227ba4.gif?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/6aea8598-b36d-4f59-8e84-0f11c6227ba4.gif?w=1500" alt="image" loading="lazy"></picture></div></div></div><p><span><span>The journal invites you to break down an important decision with the following prompts:</span></span></p><ul><li id="f84732a96cb34f75b493316d75535c81"><span><span>Mental or Physical State</span></span></li><li id="1945d55968eb4cd4a32e8e840e250ee6"><span><span>Situation or context</span></span></li><li id="2b061e1623b9405d96f1c55380e1b59e"><span><span>Problem statement of frame</span></span></li><li id="0a0d150ed00c461083c613b4c1d0d793"><span><span>Variables that govern the situation</span></span></li><li id="ba1ae1514f934fefbf163d92bd3da053"><span><span>Complications or complexities as you see them</span></span></li><li id="898fd35a5232468ca0f58541946f967f"><span><span>Range of outcomes</span></span></li><li id="03fb7f6338404c9a9417a6d597e1a3b6"><span><span>Expectations and probabilities</span></span></li><li id="d860f50788f84cf2a47086cc074df8ab"><span><span>Outcome </span></span></li><li id="a450fc0f701f49d492b659d6ed75da72"><span><span>Reflection (six months after decision was made)</span></span></li></ul><p><span><span>I found this framework to be quite thought provoking and challenging. Like most, I'm not used to documenting decision-making whatsoever. But approaching decisions this way and writing even just a few lines invited me to </span><span><em>think deeper. </em></span></span></p><p><span><span>After using the journal digitally (more on that below) for a few months, I've integrated it across Optemization. I find documenting hiring and strategic decisions to be the most useful. And</span><span><em> </em></span><span>that in turn, will make me a better person and entrepreneur.</span></span></p><p><span><span>Now paper and physical journals are </span><span><em>great</em></span><span> but if you know me; you know I have an obsession with digitizing my operations and productivity in Notion.</span></span></p><h2><span id="1ee913d94f9a482499b0dcb53bd778cf"></span><span><span>Decision Journal </span><span><em>in Notion</em></span></span></h2><p><span><span>As you might know, </span><span><a target="_blank" rel="noopener noreferrer" href="http://notion.so/">Notion</a></span><span> is a incredible all-in-one software tool that works like a digital paper. Many use it for journaling, so keeping decisions alongside with notes, for example, would be a perfect use case.</span></span></p><p><span><span>Recently, I digitized FS's decision journal and integrated it into my personal life and our work at Optemization. Here's how it looks</span></span></p><div id="6be5237cecb34854b190e8980484b179"><picture><source srcset="https://api.super.so/asset/optemization.com/6af3e079-6105-419e-ad0b-ef6a97172cce.png?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/6af3e079-6105-419e-ad0b-ef6a97172cce.png?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/6af3e079-6105-419e-ad0b-ef6a97172cce.png?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/6af3e079-6105-419e-ad0b-ef6a97172cce.png?w=1500" alt="A real decision that Shane Parrish documented and I re-created in Notion (dark mode) 🌑" loading="lazy"></picture><figcaption><span><span>A real decision that Shane Parrish documented and I re-created in Notion (dark mode) 🌑</span></span></figcaption></div><h2><span id="e24cfb65a0864da78d99c4bc119005ab"></span><span><span>How it Works</span></span></h2><p><span><span>Here's a video breakdown on YouTube (or </span><span><a target="_blank" rel="noopener noreferrer" href="https://www.loom.com/share/b3498e89e9b2451994b0d35ee4fd30e6">Loom</a></span><span>). You can read a deeper dive below or on Optemization, which is formatted nicer.</span></span></p><h2><span id="10053c973581433e9ff2f5ebcc3e8d0c"></span><span><span>Grab the Free Template</span></span></h2><h2><span id="c28450588b8a4dee9ce9676b30ad0247"></span><span><span>How it Works (Deep Dive)</span></span></h2><p><span><span>I structured each decision to be a database entry while splitting the aforementioned decision factors into database properties (columns) and page contents. If you haven't used Notion yet, that's one of the coolest features: any content can be stored as a property or inside of a database record.  </span></span></p><div id="5d36fc34fd80465b9b23af606a8f026a"><picture><source srcset="https://api.super.so/asset/optemization.com/faad4ab7-8193-4258-978e-6e7f89731201.png?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/faad4ab7-8193-4258-978e-6e7f89731201.png?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/faad4ab7-8193-4258-978e-6e7f89731201.png?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/faad4ab7-8193-4258-978e-6e7f89731201.png?w=1500" alt="image" loading="lazy"></picture></div><p><span><span>To contextualize a specific decision record in the database, apply the template  that brings up the aforementioned prompts . A new decision by default will be marked as </span><span><code>undecided</code></span><span>. The rest of the properties will be left for you to fill</span></span></p><div id="bddd80415c3a48daa7f506900c691cb0"><picture><source srcset="https://api.super.so/asset/optemization.com/ffb5a424-0518-48ef-81b5-2065671a54f2.gif?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/ffb5a424-0518-48ef-81b5-2065671a54f2.gif?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/ffb5a424-0518-48ef-81b5-2065671a54f2.gif?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/ffb5a424-0518-48ef-81b5-2065671a54f2.gif?w=1500" alt="image" loading="lazy"></picture></div><p><span><span>One of the core tenets of decision making in this framework is reflection and feedback. It's so easy to overlook this part but reflecting on past decisions will improve your decision making 10x (don't @ me). Anyway,  I built a three properties that help with facilitating this behavior:</span></span></p><p><span><span>Firstly, </span><span><code>Review in</code></span><span>, a single choice label for the duration of weeks or months after which you want to review your decision. Parrish recommended six months as the default time frame but I thought that was too constrained, so I expanded it to one week, two weeks, one month, three month and six months. Below I will explain how you can add your own .</span></span></p><p><span><span>Secondly, I find unnecessarily annoying to add the dates and figure out where you need to set the reminder, so I wrote the </span><span><code>Review at</code></span><span> formula. It's a bunch of nested IF statements that look at </span><span><code>Review in</code></span><span> and add the corresponding timeframe to </span><span><code>Created at</code></span><span>. It looks like this:</span></span></p><pre id="2ed841786e93444cb3aeb16bcea725e5"><code><span><pre><code><span>if</span><span>(</span><span>prop</span><span>(</span><span>"Review in"</span><span>)</span><span> </span><span>==</span><span> </span><span>"One week"</span><span>,</span><span> </span><span>format</span><span>(</span><span>dateAdd</span><span>(</span><span>prop</span><span>(</span><span>"Made at"</span><span>)</span><span>,</span><span> </span><span>1</span><span>,</span><span> </span><span>"weeks"</span><span>)</span><span>)</span><span>,</span><span> </span><span>if</span><span>(</span><span>prop</span><span>(</span><span>"Review in"</span><span>)</span><span> </span><span>==</span><span> </span><span>"Two weeks"</span><span>,</span><span> </span><span>format</span><span>(</span><span>dateAdd</span><span>(</span><span>prop</span><span>(</span><span>"Made at"</span><span>)</span><span>,</span><span> </span><span>2</span><span>,</span><span> </span><span>"weeks"</span><span>)</span><span>)</span><span>,</span><span> </span><span>if</span><span>(</span><span>prop</span><span>(</span><span>"Review in"</span><span>)</span><span> </span><span>==</span><span> </span><span>"One month"</span><span>,</span><span> </span><span>format</span><span>(</span><span>dateAdd</span><span>(</span><span>prop</span><span>(</span><span>"Made at"</span><span>)</span><span>,</span><span> </span><span>1</span><span>,</span><span> </span><span>"months"</span><span>)</span><span>)</span><span>,</span><span> </span><span>if</span><span>(</span><span>prop</span><span>(</span><span>"Review in"</span><span>)</span><span> </span><span>==</span><span> </span><span>"Three months"</span><span>,</span><span> </span><span>format</span><span>(</span><span>dateAdd</span><span>(</span><span>prop</span><span>(</span><span>"Made at"</span><span>)</span><span>,</span><span> </span><span>3</span><span>,</span><span> </span><span>"months"</span><span>)</span><span>)</span><span>,</span><span> </span><span>if</span><span>(</span><span>prop</span><span>(</span><span>"Review in"</span><span>)</span><span> </span><span>==</span><span> </span><span>"Six months"</span><span>,</span><span> </span><span>format</span><span>(</span><span>dateAdd</span><span>(</span><span>prop</span><span>(</span><span>"Made at"</span><span>)</span><span>,</span><span> </span><span>6</span><span>,</span><span> </span><span>"months"</span><span>)</span><span>)</span><span>,</span><span> </span><span>"Decision has not been made yet"</span><span>)</span><span>)</span><span>)</span><span>)</span><span>)</span></code></pre></span></code></pre><div id="8defbfbe696d40628a3b56bc53b88a33"><p><span><span>Right now, you can only compute one result in </span><span><code>Review at</code></span><span> that's why </span><span><code>Review in</code></span><span> is single choice. That can be changed but I didn't find it necessary.</span></span></p></div><p><span><span>There's probably a way to run this better, so let me know if you think there are better ways to write it.</span></span></p><p><span><span>Note that if the </span><span><code>Made at</code></span><span> property is empty the </span><span><code>Review at</code></span><span> will return "Decision has not been made yet" string.</span></span></p><p><span><span>If you want to add a new time segment to </span><span><code>Review in</code></span><span> do this:</span></span></p><ol><li id="20c7d79cdad34949893347e3232ef233"><span><span>Add the label. For example "Three weeks"</span></span></li><li id="ccbb98282393418794103bf03eb934de"><span><span>In the formula, after the last comma add </span><span><code>if(prop("Review in") == "Three weeks", format(dateAdd(prop("Made at"), 3, "weeks")),</code></span><span>.
There are three variables that you need to input the if condition (Three weeks), the duration (3) and the time format (weeks).</span></span></li><li id="76b8f79bad30438e93655859b9d505fd"><span><span>Add one </span><span><code>)</code></span><span> to the end of the formula and press </span><span><code>cmd+enter</code></span><span> to accept.</span></span></li></ol><p><span><span>Finally there's the </span><span><code>Remind at</code></span><span> property, which is a simple text field where you can put your actual reminder. Unfortunately the formula field cannot do that for you. To add a reminded type </span><span><code>@ remind</code></span><span> and enter the date that </span><span><code>Review in</code></span><span> gave you.</span></span></p><div id="3e0da30d538742b6a261295467ec8902"><picture><source srcset="https://api.super.so/asset/optemization.com/93e01ed2-90d5-41c1-b887-49212e628cf7.gif?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/93e01ed2-90d5-41c1-b887-49212e628cf7.gif?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/93e01ed2-90d5-41c1-b887-49212e628cf7.gif?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/93e01ed2-90d5-41c1-b887-49212e628cf7.gif?w=1500" alt="image" loading="lazy"></picture></div><div id="c3704eda0bc443b79eb785ef40a360ae"><p><span><span>Notion reminders will default to the current year, so make sure to specify 2021 as the year for your reminder.</span></span></p></div><p><span><span>That's it! Farewell and I hope this helps you make some great decisions. Please share on Twitter if you found this post insightful or the template useful — I'm @optemization 👉</span></span></p><h3><span id="7eb481733824435d8164671e498f430b"></span><span><span>Want more DOPE content? Join </span><span><em>Digital Opsessions</em></span><span> 💌</span></span></h3></article></div></div></div>]]>
            </description>
            <link>https://optemization.com/decision-journal-notion</link>
            <guid isPermaLink="false">hacker-news-small-sites-24983435</guid>
            <pubDate>Tue, 03 Nov 2020 20:07:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Programming R at native speed using Haskell (2015)]]>
            </title>
            <description>
<![CDATA[
Score 116 | Comments 11 (<a href="https://news.ycombinator.com/item?id=24981356">thread link</a>) | @behnamoh
<br/>
November 3, 2020 | https://www.tweag.io/blog/2015-09-08-programming-r-at-native-speed-in-haskell/ | <a href="https://web.archive.org/web/*/https://www.tweag.io/blog/2015-09-08-programming-r-at-native-speed-in-haskell/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>Most good data stories start with a interesting question. If the
average request latency went down by a further 100ms, by how much
could we expect user engagement to increase? How can we detect
evidence of corruption of government officials given a list of all
bids nationwide for the building of new roads and repair of existing
ones? Can we identify a new pandemic in the making given a timeline of
common search terms? Often though, we know we have the data, but we
don’t even know what questions the data might help answer, or how the
story will unfold. From the data scientist who scratched an itch on an
idle afternoon, to a low latency, high availability, real-time
analysis deployed on hundreds of machines, the story typically
involves lots of rewrites, meanderings and building out of a lot of
code and utilities to improve the precision, speed or scale of the
analysis.</p>
<!--more-->
<p>R provides a great interactive environment for poking at the dataset
<em>du jour</em> and find what answers might be lurking in there. It provides
a wealth of readily available libraries for banging out an initial
story to tell. But R is a special purpose scripting language. Its
strength in supporting throwaway “do what I mean” programming to test
and iterate on hypotheses quickly becomes a hindrance when a model is
to be built out into an industrial scale, performant and maintainable
product or service. By then, a more general purpose language
encouraging structured, modular programming, providing strong static
guarantees of correctness and that compiles down to native code for
maximum speed becomes more appropriate. Haskell is such a language.</p>
<p>Mind you, Haskell makes for a great language to support rapid
iteration, “in the small” exploratory programming too, but it as of
yet lacks the plethora of high quality libraries from machine learning
to visualization that R provides, and perhaps also some syntactic
facilities to play it fast and loose. Today we’re proud to announce
the first public release of the
<a href="https://tweag.github.io/HaskellR/">HaskellR</a> project, which includes
a library and two interactive environments for seamlessly programming
in <em>both</em> R and Haskell in the same source file, or indeed at the same
prompt.</p>
<p>At the heart of the project lies <code>inline-r</code> (whose design later
inspired
<a href="https://www.fpcomplete.com/blog/2015/05/inline-c">inline-c</a> - they
share a coauthor), which exports a few quasiquoters for expressing
calls to R functions and indeed arbitrary R code in R’s syntax. The
principles behind the design of <code>inline-r</code> are,</p>
<ul>
<li>use R libraries the way R intends them to be used: using R’s syntax
and calling conventions;</li>
<li>keep the overhead of crossing language boundaries as low as possible
to encourage fine grained interleaving of code in both languages;</li>
<li>zero marshalling overhead in the common case;</li>
<li>optional typing of R data as executable documentation of what
functions expect and return;</li>
<li>let the user stoop as low or jump as high as (s)he likes in the
abstraction stack: everything is under the user’s control control in
case (s)he needs it.</li>
</ul>
<p>We’ll touch upon each of the above points in more detail below and in
future posts. But first, let’s get a taste of this stuff. You may want
to consider the below setup as your go-to interactive shell if you
haven’t already: it reuses existing projects and works much like GHCi,
in an isolated sandbox if you like, except that you have inline
graphics and formulas out-of-the-box, as Shae Erisson first pioneered
in the Haskell world with <a href="https://github.com/shapr/ghclive/">ghclive</a>
and Manuel Chakravarty realized more recently on OS X with
<a href="http://haskellformac.com/">Haskell for Mac</a>.</p>
<h2>Charts, code, prose and formulas in a playground</h2>
<p>HaskellR features two interactive prompts:</p>
<ul>
<li>a bare bones REPL, called H. This is a thin wrapper around GHCi
initializing it with all the right extensions and imports to hit the
road running;</li>
<li>an all singing, all dancing interactive notebook, powered by
<a href="https://jupyter.org/">Jupyter</a> (formerly IPython) and Andrew
Gibiansky’s fantastic
<a href="https://github.com/gibiansky/IHaskell">IHaskell</a> kernel.</li>
</ul>
<p>In this post, we’ll talk mostly about the latter. Thanks to
<a href="https://github.com/commercialhaskell/stack">stack</a>, getting started
with <strong>HaskellR</strong> is pretty straightforward, and more importantly,
comparatively reliable. We put together
<a href="https://hub.docker.com/r/tweag/haskellr/">a Docker container</a> to get
you started hassle-free. It includes <strong>Jupyter</strong> and <strong>IHaskell</strong>
preinstalled. To build <strong>HaskellR</strong> inside it:</p>
<div data-language="bash"><pre><code>$ <span>git</span> clone http://github.com/tweag/HaskellR
$ <span>cd</span> HaskellR
$ stack --docker build
$ stack --docker <span>exec</span> ihaskell <span>install</span></code></pre></div>
<p>And get started in your browser:</p>
<div data-language="bash"><pre><code>$ stack --docker <span>exec</span> ipython notebook</code></pre></div>
<p><span>
      <a href="https://www.tweag.io/static/41a8b35719ee8bafb01f70190d40a529/c1b63/haskellr-jupyter.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="HaskellR in Jupyter" title="HaskellR in Jupyter" src="https://www.tweag.io/static/41a8b35719ee8bafb01f70190d40a529/fcda8/haskellr-jupyter.png" srcset="https://www.tweag.io/static/41a8b35719ee8bafb01f70190d40a529/12f09/haskellr-jupyter.png 148w,
https://www.tweag.io/static/41a8b35719ee8bafb01f70190d40a529/e4a3f/haskellr-jupyter.png 295w,
https://www.tweag.io/static/41a8b35719ee8bafb01f70190d40a529/fcda8/haskellr-jupyter.png 590w,
https://www.tweag.io/static/41a8b35719ee8bafb01f70190d40a529/efc66/haskellr-jupyter.png 885w,
https://www.tweag.io/static/41a8b35719ee8bafb01f70190d40a529/c83ae/haskellr-jupyter.png 1180w,
https://www.tweag.io/static/41a8b35719ee8bafb01f70190d40a529/c1b63/haskellr-jupyter.png 1200w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>Or remain in your terminal:</p>
<div data-language="bash"><pre><code>$ stack --docker <span>exec</span> ipython</code></pre></div>
<p>With <strong>IHaskell</strong>, you can keep your notes and formulas together with
your code in one place, called a notebook. With <strong>HaskellR</strong>’s plugin
for <strong>IHaskell</strong>, you can use widely acclaimed and very popular
R visualization packages such as <a href="http://ggplot2.org/">ggplot2</a> for
embedding plots in your notebook. Working in notebooks (aka
<a href="http://blog.haskellformac.com/blog/from-the-read-eval-print-loop-to-playgrounds">playgrounds</a>)
is convenient: they are self contained units that is easy to share
with colleagues, via email or
<a href="https://nbviewer.jupyter.org/">on the web</a>, and you can edit earlier
definitions while keeping the later ones in sync.</p>
<p>Here’s a simple example of using R’s data analysis facilities on data
generated in Haskell. Say you have a cluster of noisy data. We’ll use
the <code>random</code> package to generate a sample set:</p>
<div data-language="haskell"><pre><code><span><span>import</span> Control.Monad</span>
<span><span>import</span> System.Random.MWC <span>as</span> MWC</span>
<span><span>import</span> System.Random.MWC.Distributions</span>

<span>main</span> <span>=</span> <span>do</span>
  <span>gen</span> <span>&lt;-</span> <span>MWC.create</span>
  <span>xs</span> <span>&lt;-</span> <span>replicateM</span> <span>500</span> <span>$</span> <span>normal</span> <span>10</span> <span>3</span> <span>gen</span>
  <span>ys</span> <span>&lt;-</span> <span>replicateM</span> <span>500</span> <span>$</span> <span>normal</span> <span>10</span> <span>3</span> <span>gen</span>
  <span>...</span></code></pre></div>
<p>We can now plot the list of x-ordinates against the list of
y-ordinates using R’s standard library <code>plot()</code> function:</p>
<div data-language="haskell"><pre><code>  <span>[</span><span>r</span><span>|</span> <span>plot</span><span>(</span><span>xs_hs</span><span>,</span> <span>ys_hs</span><span>)</span> <span>|</span><span>]</span></code></pre></div>
<p><span>
      <a href="https://www.tweag.io/static/c6d47a04f8ebdbbdef96de235500886f/e17e5/haskellr-plot1.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Randomly generated points" title="Randomly generated points" src="https://www.tweag.io/static/c6d47a04f8ebdbbdef96de235500886f/e17e5/haskellr-plot1.png" srcset="https://www.tweag.io/static/c6d47a04f8ebdbbdef96de235500886f/12f09/haskellr-plot1.png 148w,
https://www.tweag.io/static/c6d47a04f8ebdbbdef96de235500886f/e4a3f/haskellr-plot1.png 295w,
https://www.tweag.io/static/c6d47a04f8ebdbbdef96de235500886f/e17e5/haskellr-plot1.png 400w" sizes="(max-width: 400px) 100vw, 400px" loading="lazy">
  </a>
    </span></p>
<p>Better yet: say we want some kind of visualization of the density
estimation of these points. We can use R’s 2D kernel density
estimation function, available out-of-the-box:</p>
<div data-language="haskell"><pre><code><span>[</span><span>r</span><span>|</span> <span>k</span> <span>&lt;-</span> <span>kde2d</span><span>(</span><span>Xv</span><span>,</span> <span>Yv</span><span>,</span> <span>n</span><span>=</span><span>500</span><span>)</span>
    <span>image</span><span>(</span><span>k</span><span>,</span> <span>col</span><span>=</span><span>topo</span><span>.</span><span>colors</span><span>(</span><span>8</span><span>)</span><span>)</span> <span>|</span><span>]</span></code></pre></div>
<p><span>
      <a href="https://www.tweag.io/static/b56b1373f1fb40b96ee512eb43296cb8/e17e5/haskellr-plot2.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Density estimation for our random points" title="Density estimation for our random points" src="https://www.tweag.io/static/b56b1373f1fb40b96ee512eb43296cb8/e17e5/haskellr-plot2.png" srcset="https://www.tweag.io/static/b56b1373f1fb40b96ee512eb43296cb8/12f09/haskellr-plot2.png 148w,
https://www.tweag.io/static/b56b1373f1fb40b96ee512eb43296cb8/e4a3f/haskellr-plot2.png 295w,
https://www.tweag.io/static/b56b1373f1fb40b96ee512eb43296cb8/e17e5/haskellr-plot2.png 400w" sizes="(max-width: 400px) 100vw, 400px" loading="lazy">
  </a>
    </span></p>
<p>Notice how in the above, some code appears delineated in
quasiquotation blocks. This is a syntactic facility to tell the
Haskell compiler that any code inside the block should be understood
to be in R’s syntax, not Haskell’s syntax as is normally the case
outside of these blocks. We implemented a mechanism to get an embedded
instance of the R interpreter to parse that code for us, so that we
don’t have to grok R’s full surface syntax ourselves.</p>
<p>By convention, <code>_hs</code> suffixed variables don’t refer to bindings in the
R environment, but rather to bindings in the Haskell environment. In
technical terms, these variables are actually
<a href="https://downloads.haskell.org/~ghc/7.8.4/docs/html/users_guide/template-haskell.html">antiquotations</a>
(we use convention over extra syntax so that we can reuse R’s stock
parser as-is and not implement our own). Antiquotation is the
fundamental mechanism for communicating data between R and Haskell. In
common cases, we can do so with no marshalling at all, so you can
cross the language boundaries repeatedly in a tight loop with impunity
if you like.</p>
<h2>Elements of design</h2>
<p>The core idea behind <strong>HaskellR</strong> is that language interop should be
zero-cost, or close to. There should be no reason why you would
hesitate to dip into a little bit of R to get the job done, over
reimplementing the same thing in Haskell because you’re worried about
performance or the cost of sending large volumes of data to some
remote R interpreter instance. We believe that making foreign calls
practically as fast as native calls is the key to making the
experience programming with both <a href="https://cran.r-project.org/">CRAN</a>
and <a href="https://hackage.haskell.org/">Hackage</a> package functions at the
same time seamless.</p>
<p>To this end, we decided to embed the R interpreter instance, that is
to say link together in the same binary the C code of the
R interpreter with the Haskell code of Haskell programs. In this way,
we can communicate with the R interpreter in the same process address
space. Many R functions are actually written in C, for speed, and
compile down to native code. Some of these primitives can be called
from Haskell as cheaply as any other foreign function call.</p>
<p>But that’s not the end of the performance story. A typically vexing
issue in cross-language programming is that the one language insists
on one representation of the data, while the other language wants its
own representation. Therefore, data typically has to be marshalled
from one representation to another constantly. In <strong>HaskellR</strong>, we
solved that problem in the following way: just use R’s representation
throughout. It’s the form that R functions expect, so they can get
straight to computing on that data when called. The trouble is, R’s
data representation is foreign to Haskell, so you lose Haskell’s
extremely powerful language facilities that work with any native
algebraic datatype, such as pattern matching. Or do you?…</p>
<p>The trick to get the best of both worlds, zero marshalling but also
pattern matching, is to define so-called view functions that provide
you with a native view as an algebraic datatype of the foreign data.
Here’s a toy and contrived example, where we define the factorial
function in Haskell but over R integers:</p>
<div data-language="haskell"><pre><code><span>fact</span> <span>::</span> <span>SEXP</span> <span>s</span> '<span>R.Int</span> <span>-&gt;</span> <span>R</span> <span>s</span> <span>(</span><span>SEXP</span> <span>s</span> '<span>R.Int</span><span>)</span>
<span>fact</span> <span>(</span><span>hexp</span> <span>-&gt;</span> <span>Int</span> <span>[</span><span>0</span><span>]</span><span>)</span> <span>=</span> <span>R.cast</span> <span>sing</span> <span>&lt;$&gt;</span> <span>[</span><span>r</span><span>|</span> 1L <span>|</span><span>]</span>
<span>fact</span> <span>n</span><span>@</span><span>(</span><span>hexp</span> <span>-&gt;</span> <span>Int</span> <span>_</span><span>)</span> <span>=</span>
    <span>R.cast</span> <span>sing</span> <span>&lt;$&gt;</span> <span>[</span><span>r</span><span>|</span> <span>n_hs</span> <span>*</span> <span>fact_hs</span><span>(</span><span>n_hs</span> <span>-</span> 1L<span>)</span> <span>|</span><span>]</span></code></pre></div>
<p><code>hexp</code> is a view function, mapping native R data (everything is
a <code>SEXP</code> internally in R) to a Haskell-native GADT. Thanks to the type
annotations (more on that in future posts), we know statically that
the R data can only be some kind of integer vector, so we pattern
match on that, check whether it’s the singleton zero vector or not,
and recurse.</p>
<p>Aren’t we now back to marshalling? Yes and no! We carefully engineered
these view functions to be non-recursive. Non-recursive functions can
be inlined. So that when you use a view function only to pattern match
on the result immediately afterwards, as is the case above, <strong>GHC</strong> is
smart enough to recognize that the view function is constructing
a datatype value only to destructure it later, so it simplifies the
allocation away! Yes this is marshalling of sorts, but it’s
marshalling for free: there is no trace of it at runtime.</p>
<p>There’s plenty more to talk about regarding the design of
<strong>HaskellR</strong>, but this post is already …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.tweag.io/blog/2015-09-08-programming-r-at-native-speed-in-haskell/">https://www.tweag.io/blog/2015-09-08-programming-r-at-native-speed-in-haskell/</a></em></p>]]>
            </description>
            <link>https://www.tweag.io/blog/2015-09-08-programming-r-at-native-speed-in-haskell/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24981356</guid>
            <pubDate>Tue, 03 Nov 2020 16:53:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I got 10k post karma on Reddit with (and without) fast.ai]]>
            </title>
            <description>
<![CDATA[
Score 123 | Comments 97 (<a href="https://news.ycombinator.com/item?id=24981153">thread link</a>) | @ameerkat
<br/>
November 3, 2020 | https://www.a8b.io/posts/10k-karma-reddit-bot/ | <a href="https://web.archive.org/web/*/https://www.a8b.io/posts/10k-karma-reddit-bot/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

    

    
      

    

    
<p><a href="https://www.a8b.io/posts/10k-karma-reddit-bot/" title="How I got 10k post karma on reddit with (and without) fast.ai">
        <img src="">
    </a>
</p>



    <figure>
    <img src="https://www.a8b.io/images/reddit/reddit_badge.png#mid" alt="My reddit profile with 10,088 post karma">
    <figcaption>Profile image made by AI Gahaku</figcaption>
  </figure>

<p>Back in 2006-2007 my friend and I put together a spreadsheet of 20 or so high-level achievements called “Everything’s a Contest”. This included goals like “Photograph a live grizzly bear in the wild”, “Have something named after you”, and <em>“Get 10,000 (post) karma on Reddit”</em>. Despite our heated discussions about what should be on this list and the criteria for success none of us ever really did anything substantial to complete any of these goals. In early 2020 I decided to tackle one of these long-standing contests. <em>But I was going to do it with AI since I wanted to see how I could apply AI to more of my problems</em>. I’m a huge fan of <a href="https://www.fast.ai/">fast.ai</a> and I appreciate its high-level abstractions and simple interfaces. For someone trying to get into deep learning, I would highly recommend it and the associated courses. This is a post about how I built a bot to gain karma on Reddit with fast.ai.</p>
<h2 id="approach">Approach</h2>
<p>Content on Reddit, in general, falls into two categories which you might call original content and found content. Trying to automate generating original content to post would be implementing something like <a href="https://imgflip.com/ai-meme">imgflip’s AI meme generator</a> and posting the resulting content to r/memes. While the memes that are generated are an amusing juxtaposition of tropes, they generally aren’t as good as memes that are generated by human users skilled in the art of observational comedy. Try the meme generator out and you’ll see what I mean. At some point, I did try posting one of those just to see how well it did.</p>
<figure>
    <img src="https://www.a8b.io/images/reddit/3migr03n6m251.jpg#mid" alt="Drake meme with text Staying in the Server / Watching Anime">
    <figcaption>I went through about 100 auto generated memes before I got this. This post got ~35 points with the title 'An AI generated this meme. Good to know it's putting its sentience to good use.'</figcaption>
  </figure>

<p>The other approach would be finding content online and posting it. I chose this route for automation because while generating high-quality content is more interesting it’s also far more challenging and involved. Rather than being disadvantaged in trying to catch up to the “human quality” of content, a computer is at the advantage since the primary differentiator between posters is the ability to search through large amounts of content and speed (who finds and posts something first). In particular, I ended up looking at news based subreddits due to a few reasons:</p>
<ul>
<li>Little chances of content being a repost</li>
<li>Lots of content being generated frequently</li>
<li>Large member bases</li>
<li>A lot of the content comes from the same set of known sites</li>
</ul>
<figure>
    <img src="https://www.a8b.io/images/reddit/business_submissions_by_domain.png" alt="">
    <figcaption>Domains for all the &gt; 1 score articles from /r/business in the last week as of October 29th 2020, showing the top few sites supply the majority of content.</figcaption>
  </figure>

<p>Why use AI at all though? If I was going to automate posting why not just create a bot that submits all links and leaves it up to the masses to sort my fate. In general, spamming on Reddit is looked down upon, though I believe banning is up to the discretion of the subreddit moderators. While in theory I might have gotten away with it or used some sort of generic rate-limiting and hope for the best, I wanted my bot to be more like a productive member of the community submitting thoughtful content, an extension of myself, rather than a spam bot that would be the bane of its existence until forcibly removed.</p>
<p>I searched for and found many good news subreddits but I targeted initially /r/business and /r/worldnews, somewhat arbitrarily and somewhat because those areas seemed interesting to me. /r/business had a sizeable community (577k members) and relatively low frequency of posts for a news subreddit so it seemed approachable as a first target. I would build a web crawler to watch popular business news sites for new articles, and then leverage an NLP-based article classifier to determine if the article had a high chance of receiving upvotes.</p>
<h2 id="implementation">Implementation</h2>
<h3 id="finding-and-loading-posts">Finding and loading posts</h3>
<p>To train the NLP model that will classify articles I need the article text and their corresponding Reddit scores. Unfortunately, the official Reddit API limits the amount of historic post data you can retrieve to 1000 items. Luckily there is an alternative, you can grab historic post data from <a href="https://pushshift.io/">pushshift.io</a> using code I shamelessly adapted from <a href="https://www.osrsbox.com/blog/2019/03/18/watercooler-scraping-an-entire-subreddit-2007scape/">WaterCooler: Scraping an Entire Subreddit (/r/2007scape)</a>. The output file of the script has individual lines like the one below, containing a JSON object of a post per line:</p>
<pre><code>{"author": "CALIPHATEMEDIA", "author_flair_css_class": null, "author_flair_text": null, "brand_safe": true, "can_mod_post": false, "contest_mode": false, "created_utc": 1514767344, "domain": "caliphatemedia.info", "full_link": "https://www.reddit.com/r/business/comments/7nc5yf/south_korea_to_regulate_bitcoin_trading_further/", "id": "7nc5yf", "is_crosspostable": false, "is_reddit_media_domain": false, "is_self": false, "is_video": false, "locked": false, "num_comments": 0, "num_crossposts": 0, "over_18": false, "parent_whitelist_status": "all_ads", "permalink": "/r/business/comments/7nc5yf/south_korea_to_regulate_bitcoin_trading_further/", "pinned": false, "retrieved_on": 1514841750, "score": 1, "selftext": "", "spoiler": false, "stickied": false, "subreddit": "business", "subreddit_id": "t5_2qgzg", "subreddit_type": "public", "thumbnail": "default", "thumbnail_height": 140, "thumbnail_width": 140, "title": "South korea to regulate bitcoin trading further with tougher measures", "url": "http://www.caliphatemedia.info/2017/12/south-korea-govt-to-introduce-tougher.html", "whitelist_status": "all_ads"}
</code></pre><p>After generating a file with all the historic posts, I loaded the contents referenced by the “url” field of each JSON line into <a href="https://github.com/slaveofcode/boilerpipe3">boilerpipe3</a> which is a python library that simplifies HTML documents into their primary content text.</p>
<figure>
    <img src="https://www.a8b.io/images/reddit/reuters_article.jpg" alt="">
    <figcaption>boilerpipe3 simplifies this (mostly) down to what we really want which is 'By Jeffrey Dastin, Akanksha Rana 4 Min Read (Reuters) - Amazon.com INC AMZN.O on Thursday...'</figcaption>
  </figure>

<p>After loading the article text I did some processing to remove pages that didn’t load properly and to truncate page text to 10k characters at most.</p>
<h3 id="training-the-model">Training the model</h3>
<p>I trained the NLP model for /r/business over a few days on approximately 271k articles from 2018-01-01 to mid-April 2020. I used an <a href="https://docs.fast.ai/text.models.awdlstm">AWD_LSTM</a> (e.g. <code>language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3)</code> and <code>text_classifier_learner(data, AWD_LSTM, drop_mult=0.5)</code>) for the model with discrete labels based on the article score: neutral (0-10 points), okay (10-100), good (100-500), and great (500+). The classes are kind of arbitrary and I’ve changed them around for different iterations and subreddits. The only thing I ended up paying attention to at runtime was the non-neutral class score, so this could have been a binary classifier or even better a classifier that looks at an individual article as a candidate for multiple subreddits rather than training an individual model per subreddit. For world news I had around double the number of articles. In either case I trained in 100k article chunks due to memory limitations, reloading the existing model and tuning with the new data each time.</p>

<h3 id="building-the-bot">Building the bot</h3>
<p>I chose a few sites (Business Insider, Reuters, Bloomberg, CNN, CNBC, BBC, etc.) based on frequent sites for /r/business and put them into a script and built a crawler using requests and BeautifulSoup. Every minute or so I’d crawl the site root for new links and process the linked page with boilerpipe and pass it through the NLP model for scoring. New pages with a non-neutral score of greater than 0.25 (an arbitrary threshold I picked for this particular model) would be flagged and emailed to me using AWS SNS. Initially, I relied on filtering these incoming suggestions and submitting the articles myself using the Reddit app.</p>
<figure>
    <img src="https://www.a8b.io/images/reddit/example_email.png" alt="">
    <figcaption>An example email I received from my site poller that I called 'Reddit Postmaster'.</figcaption>
  </figure>

<h2 id="automation">Automation</h2>
<p>My site poller is acting as a personal news aggregator that I use to generate suggestions for things to post. To remove me from this loop there are a few “last mile” problems to solve. Coding up submitting via the Reddit API is easy enough, but I don’t just submit all the articles that get passed to me, I act as a quality filter choosing not to submit things which don’t seem appropriate. I also gather an appropriate title for the Reddit post. The page title is usually not good as a post title (for example containing redundancies like the site name) directly and needs to be reformatted or the title should instead be extracted from the content for example by picking the most appropriate h1 tag on the page. Rather than refining the model to be better at classifying articles and improve the accuracy of the scoring mechanism, and then coding a new component for extracting the title, I decided to try to encapsulate these tasks into a mechanical turk task and have humans as the final gate-keeper and title generator. I can take the results from these mechanical turk tasks and submit the articles to Reddit via the Reddit API utilizing those results.</p>
<h3 id="mechanical-turk">Mechanical Turk</h3>
<p>Mechanical turk is a service for leveraging humans to complete small tasks for your application. It’s great for augmenting AI applications and collecting data via labeling tasks for them. But using it effectively isn’t without difficulties. The important thing to know about mechanical turk is that many workers on the platform are (sensibly) optimizing for task completion quantity. When using a custom qualifier for tasks, ensure the qualification you’re looking for is not apparent from the question. Similarily a bad HIT (human intelligence task) would be one where you ask the user to read an article and check some box if they think it belongs in some category. For example, I did this with /r/worldnews candidates to ensure that among other things didn’t pertain to US news, however the first fully automated submission I made to /r/worldnews was “Johnson &amp; Johnson to stop selling baby powder in the United States” which was …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.a8b.io/posts/10k-karma-reddit-bot/">https://www.a8b.io/posts/10k-karma-reddit-bot/</a></em></p>]]>
            </description>
            <link>https://www.a8b.io/posts/10k-karma-reddit-bot/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24981153</guid>
            <pubDate>Tue, 03 Nov 2020 16:34:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Color-balancing vote margins and vote totals in the US election map]]>
            </title>
            <description>
<![CDATA[
Score 201 | Comments 57 (<a href="https://news.ycombinator.com/item?id=24979807">thread link</a>) | @mygo
<br/>
November 3, 2020 | https://stemlounge.com/muddy-america-color-balancing-trumps-election-map-infographic/ | <a href="https://web.archive.org/web/*/https://stemlounge.com/muddy-america-color-balancing-trumps-election-map-infographic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">

			<!-- start: #header -->

<!-- end: #header -->




			


<!-- start: #single -->
<main id="single" role="main">

    
    <!-- start: .center -->
    <div>


            <!-- start: .content -->
            <div>

                <article>

                        <header>
                            
                                <p><img src="https://stemlounge.com/content/images/size/w1500/2019/10/muddy_america_2016_weru_animated-1.gif">
                                    
                                </p>

                            <!-- start: .meta -->
                            
                            <!-- end: .meta -->

                            

                        </header>

                    <section>


                        <div><p>Graphs can inform, and informed discussions can be more civil than uninformed ones. But graphs can also mislead, so we need to understand what a graph is saying when we're using it. In 2015 I gave gave a TEDx talk on making clearer election maps. The original recording was lost, then recovered and <a href="https://www.youtube.com/watch?v=U5qn33KR7us">uploaded to Youtube</a> this summer. As election season ramps up, I'd like to continue the discussion by talking about this often-misleading map.</p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/countywinner_2016.png"><figcaption>2016 County-Level Winner-Takes-All map</figcaption></figure><!--kg-card-end: image--><p>Different graphs are designed for different purposes. The graph above is a county-level winner-takes-all map. I'll call it a County Winner map for short. Scientists use it to quickly see which way the counties went in an election. While there is arguably no better map for seeing who won in which county, this map can be misleading when used for other purposes. We need to be aware of two of its characteristics:</p><ol><li>It doesn’t express the <strong>relative voting populations</strong> between each county. Instead, it can make people feel like each county has the same population.</li><li>It’s not designed to express the <strong>margin of victory</strong> within each county. It shows who won in a county, even if they won by just one vote. It’s a winner-takes-all graph, after all.</li></ol><h3 id="relative-voting-population">Relative Voting Population</h3><p>Half of the US population lives in these counties:</p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/image-1.jpg"><figcaption>Half lives in blue. Half lives in gray. Census/Business Insider</figcaption></figure><!--kg-card-end: image--><p>America can be described as a collection of densely populated metros buffered by less densely populated communities. Here’s what the “population mountains” look like:</p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/where_we_live_pop_lg.jpg"><figcaption>This map of U.S. population density appeared in Time magazine Oct. 30, 2006 issue.</figcaption></figure><!--kg-card-end: image--><p>When we take the County Winner map and resize each county’s land-area to be proportionate to its population, here’s how the US looks.</p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/image-4.jpg"><figcaption>Mark Newman, University of Michigan</figcaption></figure><!--kg-card-end: image--><p>One downside to the cartogram, however, is that the shape and location of many territories are distorted beyond recognition. This is maybe one reason why the cartogram isn't very mainstream.</p><p>The County Winner map, however, doesn’t convey this relative population information. It's not designed to. But one might think it does. </p><h3 id="margin-of-victory">Margin of Victory</h3><p>In the general election, there are 50 concurrent presidential races, one for each state. In some of these states, the margin of victory turns out to be very small. In New Hampshire, <code>743,117 votes</code> were cast for the president in the 2016 general election. Hillary Clinton won New Hampshire by <code>2,701 votes</code>. We can seat as many people in a set of high school football bleachers.<br></p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/IMG_2944.jpeg"><figcaption>How New Hampshire was won.</figcaption></figure><!--kg-card-end: image--><p>There was a <code>75.03% turnout</code> in New Hampshire, so more people could have voted that didn’t. If just 2,702 more eligible voters in New Hampshire exercised their right to vote and voted for Trump, then New Hampshire would have gone to Trump instead. With such hair thin margins, New Hampshire is neither Blue nor Red in 2016. It’s <code>50:50</code> and leaning red or blue depending on traffic and dinner plans. It would be misleading to have all of New Hampshire colored as either blue or red to represent the statewide popularity of a presidential candidate. </p><p>This characteristic also holds true at the county level. The losing candidate in a county can receive a significant number of votes. In many counties the winner won by less than a 25% margin.</p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/2016_margin_histogram_rb.jpg"><figcaption>Kenneth Tay, Stanford University. Modified to add color to the scale and to highlight 25% range.</figcaption></figure><!--kg-card-end: image--><h6 id="a-margin-of-0-is-50-50-clinton-s-county-level-percent-win-margins-are-on-the-left-trump-s-county-level-percent-win-margins-are-on-the-right-the-yellow-area-highlights-counties-won-with-vote-margins-within-25-note-that-these-are-percent-vote-margins-not-absolute-vote-margins">A margin of 0 is 50:50. Clinton's county-level percent-win margins are on the left. Trump's county-level percent-win margins are on the right. The yellow area highlights counties won with vote margins within 25%. Note that these are percent vote margins, not absolute vote margins</h6><p>In general, smaller counties were won by larger percent margins. Larger counties were won by smaller percent margins. So in the counties with the most votes cast, the runner up got a lot of votes, too. </p><p>Here’s what the County Winner map looks like when we account for vote margins by blending each red and blue vote together within each county. Purple represents 50:50:</p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/purple-map-2016.png"><figcaption>2016 Purple Map</figcaption></figure><!--kg-card-end: image--><p>The neutralizing map is designed to express vote margins more clearly. It uses a grey intermediary, adjusting for <a href="https://www.fastcompany.com/3035951/the-glaring-design-flaw-in-us-election-maps">the way humans perceive purple</a>. Here’s the 2016 neutralizing map:</p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/2016_neutralizing_map.png"><figcaption>2016 Neutralizing Map</figcaption></figure><!--kg-card-end: image--><p>Rarely are all of the votes in a county cast for one candidate. The County Winner map, however, doesn’t convey this win margin information.</p><p>The contiguous United States aren't very contiguous. The County Winner map's inability to express vote population and margin of victory can be misleading. Cartograms account for population, but they distort the shape of the US, which can add confusion. The neutralizing map accounts for vote margin, but it doesn't account for population.</p><p><strong>Can we construct a single map that shows both vote margin and vote population without distorting the shape of the US?</strong></p><p>Here's one way:</p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/muddy_america_2016_weru_animated.gif"><figcaption>Animated GIF that goes from the County Winner map to old muddy.</figcaption></figure><!--kg-card-end: image--><p>Here's a less-distracting, static version of the graph:</p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/muddy_america_2016_static-1.png"></figure><!--kg-card-end: image--><p>The map leverages Color Theory to express <code>vote margins</code> and <code>vote populations</code> in a 2-dimensional scale. </p><p>Here's the key blown up:</p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/muddy_key_labeled_compressed.png"></figure><!--kg-card-end: image--><p>Horizontal scale represents vote margins. Vertical scale represents vote totals.</p><h4 id="lightness-vertical-scale-">Lightness (Vertical Scale)</h4><p>The lighter counties had fewer votes. The darker counties had more votes. </p><h4 id="hue-saturation-horizontal-scale-">Hue + Saturation (Horizontal Scale)</h4><p>The closer a county gets to gray, the closer the votes were 50:50. </p><p>A highly saturated red county was won by Trump with high percent vote margins. A highly saturated blue county was won by Hillary with high percent vote margins.</p><h2 id="the-mathematics-of-the-muddy-map">The mathematics of the muddy map</h2><h4 id="hsl">HSL</h4><p>All colors can be described as a combination of <code><u>H</u>ue(°)</code>, <code><u>S</u>aturation(%)</code>, and <code><u>L</u>ightness(%)</code>. </p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/640px-HSL_color_solid_cylinder_saturation_gray.png"><figcaption>The HSL color model.</figcaption></figure><!--kg-card-end: image--><p>We can leverage these individual components of the <code>HSL color model</code> to faithfully express 2-dimensional data such as vote totals vs margin on a 2d color scale.</p><h4 id="county-fill-colors">County Fill Colors</h4><p>The fill-color of each county is constructed using the MuddyColor algorithm, which is expressed as the following mathematical formula:</p><!--kg-card-begin: html--><!--
MuddyColor =

HSL \left (  

Hue \left (winner(D,R ) \right ), 

\frac{ \left |D-R \right | }{totalVote}, 

 \frac{ \left (1-\frac{totalVote}{upperFence}   \right )*100}{2} + 50

\right )
--><!--kg-card-end: html--><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/muddyColor_Formula-1.gif"><figcaption>Formula for county fill color</figcaption></figure><!--kg-card-end: image--><p>This produces the following two dimensional scale, which also doubles as a map key, with the upper fence labeled for the 2016 data set:</p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/muddy_key_labeled_compressed.png"><figcaption>Color scale produced by MuddyColor, used for county fill colors.</figcaption></figure><!--kg-card-end: image--><h4 id="county-border-colors">County Border Colors</h4><p>For the borders of each county, I use the same formula, but just give them a constant lightness (L) of 50%. </p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/muddyBorderColor_Formula.gif"><figcaption>Formula for county border color</figcaption></figure><!--kg-card-end: image--><p>This results in a 1-dimensional scale which we use for the county borders. It's the same color-scale scale used in the Neutralizing Map, which is designed to more-accurately express vote margins. &nbsp;<code>Left = higher DEM %margin</code>. <code>Right = higher GOP %margin</code>.</p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/neutralized_scale.png"><figcaption>Color scale produced by MuddyBorderColor, used for county border colors.</figcaption></figure><!--kg-card-end: image--><p>Giving each county an opaque border color allows even the lightest-filled counties to be recognized, including their vote margins.</p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/muddy_zoom.png"><figcaption>With opaque county borders, you can see the counties with even the lowest vote totals.</figcaption></figure><!--kg-card-end: image--><p>You don't need to look at the whole nation to see where one county's vote total lies on the overall lightness scale. The &nbsp;<code>county border color</code> and the &nbsp;<code>county fill color</code> differ only by lightness, so the greater the <code>contrast</code> between a county's border color and its fill color, the lower its vote total.</p><h4 id="upper-fence">Upper Fence</h4><p>A few counties have enough votes to skew the vote totals scale. Here's how the graph looks when the <code>vote totals</code> scale maxes out at <code>2,514,055</code>, the maximum number of votes in a county:</p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/muddy_no_upper_limit-1.jpg"><figcaption>A few counties have enough votes to skew the whole vote scale.</figcaption></figure><!--kg-card-end: image--><p>One may suggest using a logarithmic scale to bring the sky-high outliers down to Earth. However, this would be visually misleading. A logarithmic scale flattens the min:max vote totals proportion from <code>1:39,282</code> closer to<code>1:3.5</code>, visually equating population mountains with population plains.</p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/logarithmic_scale-16.png"><figcaption>In this log-scale graph of northwest Texas, can you distinguish a county with 1,000 votes from one with 50,000 votes?</figcaption></figure><!--kg-card-end: image--><p>We maintain a linear vote totals scale and use the statistical <code>upper fence</code> to account for outliers. The statistical upper fence can be calculated using the formula <code>Q3 + 1.5 * IQR</code>. Since the county vote margins are only concerned with %DEM|%GOP, county vote totals are DEM+GOP. For vote totals, we calculate the statistical upper fence to be <code>59,828 DEM+GOP votes</code>. We need to keep in mind that <code>432 counties</code> have vote totals ≥ <code>59,828 DEM+GOP</code> and are fully opaque in the Muddy Map. </p><h2 id="practical-uses-of-the-muddy-map">Practical uses of the Muddy Map</h2><p>The formulas give the Muddy Map graph some interesting characteristics. For each county, both the percent vote margin, as well as the vote totals (≤ the statistical upper fence), are embedded in the colors of the graph.</p><p>The Practical Characteristics of the Muddy Map Algorithm:</p><ul><li>There are only two hues, <code>red (hue#0 aka hue#360)</code> and <code>blue (hue#240)</code>. Red indicates GOP win, blue indicates DEM win.</li><li>A county with a <code><em>vote margin</em> of 100%</code> will have <code>100% saturation</code>. </li><li>A county with a <code><em>vote margin</em> of 0%</code> will have <code>0% saturation</code>. Such a county will be a pure gray, since gray appears at 0% saturation. So the closer a county gets to 50:50, the more gray it appears. No county in the 2016 election had a vote margin of 0%.</li><li>A county with <code>0 <em>total votes</em></code> will have <code>100% lightness</code>. Pure white appears at 100% lightness, so the closer the vote totals get to 0, the more white the counties appear. &nbsp;No county in the 2016 election had 0 votes. </li><li>A county with <code>≥ 59,828 <em>total votes</em></code> (the statistical upper fence) has <code>50% lightness</code>. &nbsp;432 counties in the 2016 election have this property.</li></ul><p>If a computer can faithfully render all of the colors described by the formula, then you can use a color picker to get …</p></div></section></article></div></div></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://stemlounge.com/muddy-america-color-balancing-trumps-election-map-infographic/">https://stemlounge.com/muddy-america-color-balancing-trumps-election-map-infographic/</a></em></p>]]>
            </description>
            <link>https://stemlounge.com/muddy-america-color-balancing-trumps-election-map-infographic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24979807</guid>
            <pubDate>Tue, 03 Nov 2020 14:16:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dark’s new backend will be in F#]]>
            </title>
            <description>
<![CDATA[
Score 343 | Comments 256 (<a href="https://news.ycombinator.com/item?id=24979578">thread link</a>) | @nikivi
<br/>
November 3, 2020 | https://blog.darklang.com/new-backend-fsharp/ | <a href="https://web.archive.org/web/*/https://blog.darklang.com/new-backend-fsharp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.darklang.com/content/images/size/w300/2020/11/El5FcMQWkAAnkTX.jpeg 300w,
                            https://blog.darklang.com/content/images/size/w600/2020/11/El5FcMQWkAAnkTX.jpeg 600w,
                            https://blog.darklang.com/content/images/size/w1000/2020/11/El5FcMQWkAAnkTX.jpeg 1000w,
                            https://blog.darklang.com/content/images/size/w2000/2020/11/El5FcMQWkAAnkTX.jpeg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.darklang.com/content/images/size/w2000/2020/11/El5FcMQWkAAnkTX.jpeg" alt="Dark's new backend will be in F#">
            </figure>

            <section>
                <div>
                    <p><em>Welcome HN! Dark is a programming language, structured editor, and infrastructure—all in one—whose goal is to make it 100x easier to build backend services. Check out the <a href="https://darklang.com/">website</a>, our <a href="https://blog.darklang.com/what-is-dark/">What is Dark</a> post, and <a href="https://blog.darklang.com/how-dark-deploys-code-in-50ms/">How Dark deploys in 50ms</a> for more. Thanks for checking us out!</em></p><hr><p><em>Part of a set with <a href="https://blog.darklang.com/leaving-ocaml/">Leaving OCaml</a> and <a href="https://blog.darklang.com/why-dark-didnt-choose-rust/">Why Dark didn't choose Rust</a>.</em></p><p>Nothing in my life so far would have prepared me for the fact that I would be willfully choosing to move to .NET, but it's 2020, and nothing matters anymore.</p><p>I've been evaluating new languages for the Dark backend over the last 2 months or so. For a <a href="https://blog.darklang.com/leaving-ocaml/">bunch of reasons</a>, OCaml has been a little unsatisfactory.</p><p>Over the last few years we've always said "when we rewrite the backend", "at some point we'll rewrite and this will go away", etc. There's a lot of new code to be written on the backend, to meet our roadmap. Are we really going to write it once, and then rewrite it later? Or would it be faster to just port it now, and write the new code in the new stack?</p><p>Ultimately, I decided that if there was going to be a change, now was the time. And more importantly, if there wasn't going to be a change, now was an excellent time to fully commit to OCaml, and not be second guessing the choice.</p><p>Initially, I expected to go to Rust. <a href="https://blog.darklang.com/first-thoughts-on-rust-vs-ocaml/">Rust has excellent tooling, great libraries, a delightful community, etc</a>. But after spending about a month on it, I can't say I like writing Rust. Especially, I don't like writing async code in Rust. I like a nice high level language, and that's kinda what you need when you have a project as big as Dark to build. And Rust is not that. I'll publish "Why Dark didn't choose Rust" next. Or I might call it "you'll never believe just how much a Garbage Collector does for you!", because that's the summary.</p><p>When I was working on <a href="https://github.com/darklang/fizzboom/">Async benchmarks</a> before, what I was really doing was evaluating "are any of these OCaml alternatives better? And if so are they also faster?". I evaluated and expected not to like F#. I actually quite like it. It's close enough to OCaml, has great library support, and tooling which so far has been a mix of great and terrible. The 90's Microsoft tooling is still there, and that bit isn't all that great, but overall it's a much better situation than OCaml or Rust.</p><h2 id="why-did-i-chose-f-">Why did I chose F#?</h2><p>Let's start with the obvious, F# is OCaml. It's OCaml backed by the world's largest and most experienced creators of programming languages. And in the areas that OCaml is great, F# is also great! Sum types, static typing, eager execution, pipelines, immutable values, all of this is really great.</p><p>It actually has a much better type system, in my opinion. One thing that sticks out is that OCaml made it really cumbersome to use maps. Like, hashtables, associative arrays, whatever you call them. It seems the old version of Real World OCaml has been taken down, so I can't show you how unpleasant they were at the start. Now, in the latest version, they are <a href="https://dev.realworldocaml.org/maps-and-hashtables.html">more moderately unpleasant</a> to use. Whereas in F#, you have a <code>Map&lt;OneType,AnotherType&gt;</code> and that's really it. Magic!</p><p>Of course, the main reason I chose .NET was the libraries. It has libraries for everything, what a surprise. While there aren't all that many F# first-party libraries, every vendor out there has a .NET SDK that you can use directly from F#. I look forward to finally having first-party support for <a href="https://honeycomb.io/">Honeycomb</a>, <a href="https://rollbar.io/">Rollbar</a>, and Google Cloud. I'm even finally going to get to use <a href="https://launchdarkly.com/">LaunchDarkly</a>, after <a href="https://www.heavybit.com/library/podcasts/to-be-continuous/">years of telling Edith</a> I would.</p><p>The other thing I've really enjoyed is how good the docs and community content are. A lot of OCaml community content is on the language and what you can do with it. F# developers seem to just want to get shit done. There's a million blog posts, youtube videos, etc, from enterprise software developers talking about the best way to build web software. And then of course the massively detailed and useful <a href="https://fsharpforfunandprofit.com/">FSharpForFunAndProfit</a>, as well as <a href="http://tomasp.net/">Tomas Petricek</a>'s work - it's really great.</p><p>I think most of this is due to the size of the community. I've heard people say that there are very few F# developers; something like there's 1M C# users, 100k VB users, and 10K F# users, or something like that. I'm not sure exactly what counts as user, but I would imagine that OCaml has fewer than 100 "users" in this metric, so it feels like I'm moving to a massive community.</p><p>Not everything is amazing though. The build system is attrocious. While <code>paket</code> is roughly on par with <code>esy</code>, msbuild is 1000 times worse than <code>dune</code>. An incremental build in dune is like 1s for me, and 6s in .NET, even if nothing is happening. I know they have fancy incremental compilers for .NET so this puzzles me; if anyone has tips on getting really fast compilation in F#, <a href="mailto:paul@darklang.com">I would appreciate them</a>.</p><p>An important thing to check was whether I could compile my code to JS. Dark's execution engine runs it the editor as well, and that's one of the core things that makes Dark special. Because of this, I want to take unaltered backend code and compile it directly to JS. This isn't like <a href="https://rescript-lang.org/">Rescript</a> (which is OCaml compiled to JS with slightly different semantics and ecosystem, or it's equivalent in F#, <a href="https://fable.io/">Fable</a>). Fortunately, F# code can be compiled to Wasm using <a href="https://dotnet.microsoft.com/apps/aspnet/web-apps/blazor">Blazor</a>. Blazor compiles the .NET runtime to WASM and runs your code in that. It <a href="https://github.com/darklang/dark/tree/main/fsharp-backend/src/Wasm">barely took any code</a> to get working either (though figuring out the right incantation was not trivial).</p><h2 id="feedback-from-leaving-ocaml-blog-post">Feedback from "Leaving OCaml" blog post</h2><p><a href="https://blog.darklang.com/leaving-ocaml/">Yesterday's post</a> got a lot of people to add their opinions. In addition to some <a href="https://news.ycombinator.com/item?id=24976630">Scala</a> and <a href="https://twitter.com/fakenickels/status/1323304778089304070">Erlang</a> love, a lot of people pointed to F#:</p><blockquote>So...I think a decent choice to make here is to switch from OCaml to F#. You'll get almost all of the benefits and most of the drawbacks go away. And for the most part, you can directly translate the code from OCaml to F#. - <a href="https://news.ycombinator.com/item?id=24978526">darksaints</a></blockquote><blockquote>I've been using F# on GCP in production for 3 years now and it's fantastic and only getting better. You can leverage existing .NET libraries (for example, you get official GCP libraries from google) and if you use them enough it's easy enough to write a functional wrapper around them. - <a href="https://news.ycombinator.com/item?id=24978526">angio</a></blockquote><blockquote>We have considered OCaml but went for F# instead. I could not be happier. Great libraries, good tooling, in 2020 F# is a first class citizen in the cloud thanks to C# and .NET Core. You can develop on Linux, Windows, MacOS and without modification it works. Compilation times are great. Unless you want to deal with the low level nature and the C++ influence in Rust F# is a much more logical step to move from OCaml. There is dotnet fsi for REPL too. F# has access to C# libraries and it is relatively easy to write a thin wrapper that convert nulls to Nones, so you are null safe or C# style functions to ML style functions so you can use |&gt; or &lt;| etc. - <a href="https://lobste.rs/s/bcwbuw/leaving_ocaml#c_uoy61u">l1x</a></blockquote><h2 id="next-steps">Next steps</h2><p>I recently merged the <a href="https://github.com/darklang/dark/tree/main/fsharp-backend">first F# code into the codebase</a>. It's an async version of the core of the Dark interpreter, connected to Giraffe (F#'s low-level interface to .NET's Kestrel web server).</p><p>My plan is to reimplement the same language, but with some of the learnings that are in the <a href="https://roadmap.darklang.com/">roadmap</a>. For example:</p><ul><li><code>Result</code> and <code>Options</code> will be types, not special cased into the language</li><li><code>Int</code> will be infinite precision (this is technically a breaking change, but not a significant one AFAICT)</li><li>breaking out the API server, using F# builtin middleware libraries</li><li>refactoring the Dark public HTTP server into composable middleware, available from within Dark</li></ul><p>I'll be working on making the equivalent to the existing Dark interpreter, keeping the semantics the same. After that, I'll be making new features from the <a href="https://roadmap.darklang.com/">Dark Roadmap</a>.</p><h2 id="implementation-plan">Implementation plan</h2><p>Dark's backend is 37K lines of OCaml, of which 8K lines are tests, and 10K lines are the Dark standard library. So there's about 20K lines to port. Should be fun. My implementation plan is to get to parity - there's plenty of time after that to take advantage of the ecosytem:</p><ul><li>finish the interpreter</li><li>connect Dark's F# backend to Dark's DB, so it can read the same data</li><li><s>compile Dark's F# interpreter to JS</s> (done, see above)</li><li>make an OCaml library to deserialize the binary opcodes in the DB and covert them into F# (via, I presume, a JSON intermediary). This will allow incoming requests to (optionally) be routed to the F# service.</li><li>add a fuzzer to ensure the semantics of the OCaml and F# versions of Dark are the same (especially the library functions)</li><li>do all the devops (getting it into k8s, etc)</li><li>add the APIs we have available in OCaml</li><li>add a way for users to safely try their code in the new version</li><li>port over 170 or so functions we have in the standard library</li><li>start recording traces using <a href="https://blog.darklang.com/evolving-darks-tracing-system/">the new design</a> (this is actually the main thing driving the whole change, believe it or not!)</li><li>use <a href="https://www.honeycomb.io/">Honeycomb</a>, R<a href="http://rollbar.com/">ollbar</a>, and Google Cloud using their .NET native interfaces</li><li>port our <a href="https://github.com/darklang/dark/tree/main/services">various services</a> to F# (lower priority)</li><li>port our accounts to self-managed from Auth0</li><li>translate the <a href="https://docs.darklang.com/contributing/ocaml-for-dark-developers">contributor docs</a> to F#</li></ul><p>There's lots to do, and <a href="https://docs.darklang.com/contributing/getting-started">Dark contributors</a> are welcome to take part. Porting standard library functions might be an easy place to get started, as is adding language features. Most things are a straight port from OCaml, except as mentioned above. As always, feel free to ask in <a href="https://darklang.com/slack-invite">the Slack</a> or <a href="https://github.com/darklang/dark/issues">issues</a> if you've any questions.</p><hr><p><em><em><em><em><em><em><em><em>You can sign up for Dark </em></em></em></em></em></em></em></em><a href="https://darklang.com/signup" rel="noopener nofollow"><em><em><em><em><em><em><em><em>here</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em>. For more info on Dark, follow our </em></em></em></em></em></em></em></em><a href="https://blog.darklang.com/rss" rel="noopener nofollow"><em><em><em><em><em><em><em><em>RSS</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em>, follow </em></em></em></em></em></em></em></em><a href="https://twitter.com/darklang" rel="noopener nofollow"><em><em><em><em><em><em><em><em>us</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em> (or </em></em></em></em></em></em></em></em><a href="https://twitter.com/paulbiggar" rel="noopener nofollow"><em><em><em><em><em><em><em><em>me</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em>) on Twitter, join our </em></em></em></em></em></em></em></em><a href="https://darklang.com/slack-invite" rel="noopener nofollow"><em><em><em><em><em><em><em><em>Slack Community</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em>, watch our </em></em></em></em></em></em></em></em><a href="https://github.com/darklang/dark" rel="noopener nofollow"><em><em><em><em><em><em><em><em>GitHub repo</em></em></em></em></em></em></em></em></a><em>, or join our <a href="http://darklang.com/mailing-list">mailing list</a><em><em><em><em><em><em><em>.</em></em></em></em></em></em></em></em></p><p><em>Thank you<a href="https://twitter.com/JaggerJo1/status/1323571699330260993"> JaggerJo</a> for the header image!</em></p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.darklang.com/new-backend-fsharp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24979578</guid>
            <pubDate>Tue, 03 Nov 2020 13:45:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[URLs in C (2011)]]>
            </title>
            <description>
<![CDATA[
Score 61 | Comments 23 (<a href="https://news.ycombinator.com/item?id=24979396">thread link</a>) | @susam
<br/>
November 3, 2020 | https://susam.in/blog/urls-in-c/ | <a href="https://web.archive.org/web/*/https://susam.in/blog/urls-in-c/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>By <b>Susam Pal</b> on 03 Jun 2011</p>
<p>
Here is an interesting C puzzle I created recently. It is a silly one
but you might find it amusing.
</p>

<pre><code>#include &lt;stdio.h&gt;

int main()
{
    https://susam.in/
    printf("hello, world\n");
    return 0;
}</code>
</pre>

<p>
This code compiles and runs successfully.
</p>

<pre><samp>$ <kbd>c99 hello.c &amp;&amp; ./a.out</kbd>
hello, world</samp>
</pre>

<p>
However, the <a href="http://www.open-std.org/JTC1/SC22/WG14/www/docs/n1256.pdf">C99
standard</a> does not mention anywhere that a URL is a valid syntactic
element in C. How does this code work then?
</p>

<p>
<em><strong>Update on 04 Jun 2011:</strong> The puzzle has been solved
in the <a href="https://susam.in/blog/urls-in-c/comments/">comments</a> section. If you want to think
about the problem before you see the solutions, this is a good time to
pause and think about it. There are spoilers ahead.</em>
</p>

<p>
The code works fine because <code>https:</code> is a label and
<code>//</code> following it begins a comment. In case, you are
wondering if <code>//</code> is indeed a valid comment in C, yes, it is,
since C99. Download the <a href="http://www.open-std.org/JTC1/SC22/WG14/www/docs/n1256.pdf">C99
standard</a>, go to section 6.4.9 (Comments) and read the second
point which mentions this:
</p>

<blockquote>
Except within a character constant, a string literal, or a comment, the
characters <code>//</code> introduce a comment that includes all
multibyte characters up to, but not including, the next new-line
character. The contents of such a comment are examined only to identify
multibyte characters and to find the terminating new-line character.
</blockquote>

<div>
  <h2>More ...</h2>
  <p>
    If you liked this post, you might also like these:
  </p>
  <ul>
     <li><a href="https://susam.in/blog/sequence-points/">Sequence Points in C</a></li>
     <li><a href="https://susam.in/blog/stack-overwriting-function/">Stack Overwriting Function in C</a></li>
     <li><a href="https://susam.in/blog/writing-boot-sector-code/">Writing Boot Sector Code in ASM</a></li>
     <li><a href="https://github.com/susam/uncap">Map Caps Lock to Escape</a></li>
  </ul>
  <p>
    Also,
    <a href="https://twitter.com/intent/follow?screen_name=susam">follow me on Twitter</a>
    where I often post about Python, Lisp, Linux, Unix Shell, TeX, Vim,
    InfoSec, mathematics, etc.
  </p>
</div>


</div></div>]]>
            </description>
            <link>https://susam.in/blog/urls-in-c/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24979396</guid>
            <pubDate>Tue, 03 Nov 2020 13:25:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We made our SaaS home page cookie-free]]>
            </title>
            <description>
<![CDATA[
Score 374 | Comments 181 (<a href="https://news.ycombinator.com/item?id=24979167">thread link</a>) | @jivings
<br/>
November 3, 2020 | https://blog.leavemealone.app/no-more-cookies/ | <a href="https://web.archive.org/web/*/https://blog.leavemealone.app/no-more-cookies/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.leavemealone.app/content/images/size/w300/2020/11/cookies.jpg 300w,
                            https://blog.leavemealone.app/content/images/size/w600/2020/11/cookies.jpg 600w,
                            https://blog.leavemealone.app/content/images/size/w1000/2020/11/cookies.jpg 1000w,
                            https://blog.leavemealone.app/content/images/size/w2000/2020/11/cookies.jpg 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 700px,
                            1400px" src="https://blog.leavemealone.app/content/images/size/w2000/2020/11/cookies.jpg" alt="How we made our SaaS homepage cookie-free 🍪">
            </figure>

            <section>
                <div>
                    <p>If you've browsed the web in the last 10 years then you'll have seen more than your fair share of cookie banners!</p><p>Intended as a workaround to the <a href="https://www.cookielaw.org/the-cookie-law/">2011 EU Cookie Law</a>, cookie consent banners have become so commonplace that most people <a href="https://www.amazeemetrics.com/en/blog/76-ignore-cookie-banners-the-user-behavior-after-30-days-of-gdpr/">don't even bother to look at them</a>, or just click accept on everything. </p><!--kg-card-begin: image--><figure><img src="https://blog.leavemealone.app/content/images/2020/11/image-10.png"></figure><!--kg-card-end: image--><!--kg-card-begin: image--><figure><img src="https://blog.leavemealone.app/content/images/2020/11/image-9.png"></figure><!--kg-card-end: image--><p>As I see it, the purpose of the Cookie Law was to <strong>stop websites from storing data in your browser unless they absolutely needed to</strong>, by requiring them to prompt their visitors for consent. The end goal being to give you more control over your online privacy, stop needless tracking, and make website owners think twice about what they were doing. In short - a good intentioned idea.</p><p>However, basically every website in the world took the easier, less introspective approach - prompting for consent - creating an objectively worse web experience for everyone.</p><p>Since at <a href="https://leavemealone.app/">Leave Me Alone</a> we're trying to set an example of how to run a privacy friendly company, we decided to figure out how we could remove all the cookies from our landing page without sacrificing anything important. This means no more cookie banner, no more tracking! 🍪</p><p>We had three main cookie monsters that will be well known to SaaS companies;</p><ol><li>Web analytics</li><li>Live Chat</li><li>Security (DDOS protection etc)</li></ol><p>Before we start, I'm not neccessarily saying I distrust any of these companies and how they use cookies...so make your own judgement about them. We're just in this to get cookie free! </p><h2 id="web-analytics">Web Analytics</h2><p>To track our page views and general visitor behaviour, like <a href="https://trends.builtwith.com/analytics/Google-Analytics">most sites</a>, we were using Google Analytics. </p><p>Google Analytics sets a little cookie on page load to "remember" what a visitor has done on each page as they navigate around a site. This allows it to create a profile of the visitor so you can figure out exactly what it takes to get a visitor to sign up or convert, or whatever it is that you're trying to measure.</p><p>Realistically we never really use this information, so it's an easy one to get rid of. There are actually a handful of simpler web analytics platforms that don't use cookies, and we opted to try <a href="https://simpleanalytics.com/">Simple Analytics</a>. With this we get basically all the info we ever got out of Google Analytics (page views), so it seems like a great compromise.</p><p>You can even make your analytics pages public, which fits nicely with our "<a href="https://blog.leavemealone.app/how-we-share-company-stats-and-metrics-publicly/">open startup</a>" work ethic. For example you can view the stats for this <a href="https://simpleanalytics.com/blog.leavemealone.app">blog post here</a>!</p><!--kg-card-begin: image--><figure><img src="https://blog.leavemealone.app/content/images/2020/11/image-1.png"><figcaption>The page view anaylitcs for Simple Analyics - meta!</figcaption></figure><!--kg-card-end: image--><p>🍪 Cookie Verdict = 5/5, no cookies, no problem.</p><!--kg-card-begin: html--><!--kg-card-end: html--><h2 id="live-chat">Live Chat</h2><p>Having an annoying chat widget is another common thing for a SaaS homepage. We used to use Crisp for this, which uses a cookie to match a browser session to messages in their system. Their <a href="https://help.crisp.chat/en/article/crisp-chatbox-cookie-and-ip-policy-1147xor/">privacy policy</a> says this is "not used for tracking purposes", but given all the data they show in their UI about visitors that's not exactly much comfort. </p><p>(It even guesses a load of personal info from the visitors' email address like what company they work for and their job title using something called <a href="https://go.crisp.chat/notice/domain-enrich/">Crisp Enrich</a> which is apparently impossible to find any info about but sounds shady as hell).</p><!--kg-card-begin: image--><figure><img src="https://blog.leavemealone.app/content/images/2020/11/image-6.png"><figcaption>I don't know why I would care about half of the stuff Crisp automatically collect on people who are just asking for help on my website 🤷‍♂️</figcaption></figure><!--kg-card-end: image--><p>So, this is a top priority since it looks like an absolute privacy and tracking nightmare.</p><p>I get that this is a difficult one, but there's literally no service we could find to do this cookieless (or even mildly privacy focused) so we ended up heavily modifying an open-source project called <a href="https://github.com/idoco/intergram">Intergram</a> to do what we wanted. Intergram works like a regular chat widget, but it communicates with the chat app Telegram via a self-hosted server - meaning at least we're in control of the code. Our modified chat widget now looks like this (and the code is <a href="https://github.com/squarecat/squarechat">open-source</a>);</p><!--kg-card-begin: image--><figure><img src="https://blog.leavemealone.app/content/images/2020/11/Group-54.png"></figure><!--kg-card-end: image--><p>Unfortunately it still requires some place to store the messages locally so that the visitor has a copy of them, but we still made this work by only storing anything <em>after</em> the chat has been opened. Unlike Crisp that injected it's cookies when it felt like it. We also don't collect any tracking crap like Crisp does, only chat messages!</p><p>We sweetened the deal by adding a consent prompt to the chat widget itself like this;</p><!--kg-card-begin: image--><figure><img src="https://blog.leavemealone.app/content/images/2020/11/Group-53.png"></figure><!--kg-card-end: image--><p>🍪 Cookie Verdict = 3/5 - fewer cookies, more privacy.</p><h2 id="security">Security</h2><p>This was a tricky one. We use Cloudflare as a security layer to protect the website from denial-of-service attacks. We also use their CDN to cache our assets so that the site loads extra fast, and use their DNS because it's hella convenient.</p><p>To perform their protection Cloudflare stores a cookie called <em><code>_cfduid</code></em>,<em> </em>which is used to track each client and somehow figure out if they're a malicious actor or something. I don't really know and <a href="https://support.cloudflare.com/hc/en-us/articles/200170156-Understanding-the-Cloudflare-Cookies">their description is clear as mud</a>. Whatever it does, it's got to go.</p><p>I didn't really know where to start with this one, so <a href="https://twitter.com/JamesIvings/status/1315945593471205376">I tweeted about it</a> and got a reply from a systems engineer that works there:</p><!--kg-card-begin: image--><figure><img src="https://blog.leavemealone.app/content/images/2020/11/Slice-1-1.png"></figure><!--kg-card-end: image--><p>Which is a bit of a non-answer, since the Enterprise plan costs $200/month and I'd end up with fewer features for my trouble.</p><p>Since we've never actually had to use Cloudflare protection, my solution was to disable Cloudflare forwarding completely and switch to a proper CDN provider. You can do this by clicking the cloud icon on the DNS settings switching to "DNS only":</p><!--kg-card-begin: image--><figure><img src="https://blog.leavemealone.app/content/images/2020/11/image-11.png"></figure><!--kg-card-end: image--><p>This means we are now just using Cloudflare for DNS. But it's possible to hit this button again and <strong>re-enable</strong> Cloudflare forwarding temporarily if we find ourselves under attack, so I figure this is a good option.</p><p>For a CDN provider we decided on recommendation to check out <a href="https://bunnycdn.com/">BunnyCDN</a>. I'm actually really impressed by this service, compared to Cloudflare everything feels a bit faster and it's easier to know what's going on, which I like. Also since it's just a file CDN there are zero cookies of course!</p><p>🍪 Cookie Verdict = 6/5 - No cookies AND a faster website!</p><p>The website now has no cookies on load, with some storage being used if a visitor opens the chat widget, which I think is a pretty successful outcome! </p><!--kg-card-begin: image--><figure><img src="https://blog.leavemealone.app/content/images/2020/11/image-8.png"></figure><!--kg-card-end: image--><p>You can check it out <a href="https://leavemealone.app/">here</a>, you'll notice there's no cookie banner to annoy you, it's almost like stepping back in time ;)</p><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><p>PS.</p><p>If you enjoyed this post then check out <a href="https://twitter.com/JamesIvings">my Twitter</a>. I spend my free time tweeting about how much I hate anti-privacy web practices and crappy mailing list emails. See you there!</p><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><p>Cover photo by <a href="https://unsplash.com/@clemono?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Clem Onojeghuo</a> on <a href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</p><!--kg-card-begin: html--><!--kg-card-end: html-->
                </div>
            </section>

            <section>
                <h3>Subscribe to Leave Me Alone Blog</h3>
                <p>Get the latest posts delivered right to your inbox</p>
                


            </section>

            


        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.leavemealone.app/no-more-cookies/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24979167</guid>
            <pubDate>Tue, 03 Nov 2020 12:53:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[React Fundamentals: What I’m Learning]]>
            </title>
            <description>
<![CDATA[
Score 100 | Comments 63 (<a href="https://news.ycombinator.com/item?id=24979103">thread link</a>) | @buaiscia
<br/>
November 3, 2020 | https://buaiscia.github.io/posts/learning-on-epic-react-fundamentals | <a href="https://web.archive.org/web/*/https://buaiscia.github.io/posts/learning-on-epic-react-fundamentals">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2 id="intro"><a href="#intro" aria-label="intro permalink"></a>Intro</h2>
<p>At this moment in my career, I’m a Javascript fullstack developer in the early stages. I’ve a good knowledge of Javascript, however React gives me sometimes a little more than a headache to understand deeply. I grew up in my learning with class based components, so later, when hooks were introduced, I found a little difficult to transition to this new way of writing React. That’s why I wanted this course. </p>
<p>As part of my learning process, I’m going to note down not everything, but what I learnt, for each section. Often my solution was, although working, more complicated and less elegant than Kent’s one. That’s another aspect I wish to improve in my coding. </p>
<p>Of course you will find many more details and, well, the workshop itself directly in <a href="https://epicreact.dev/">epicreact.dev</a>
I hope this will be useful to somebody else apart from me, and forgive my mistakes in English (not a native speaker).
<br></p>
<h2 id="01-basic-javascript-rendered"><a href="#01-basic-javascript-rendered" aria-label="01 basic javascript rendered permalink"></a>01: Basic JavaScript-rendered</h2>
<p>In the first exercise, it’s necessary to make some DOM manipulation with plain Javascript. As I’m using this method in my daily work, I had no difficulties in the first part. As a matter of fact, I’m learning a lot into transforming a codebase that is heavily relying on jQuery into plain Javascript.</p>
<p>However, I did have to do some thinking on the additional exercise, as I’m not used to work with the root element of the body. So I personally didn’t know -but now that I know, it makes sense - that there’s a body object inside the document object. I won’t give here the solution, but it’s an important reminder to always check the parent elements… what are they hiding inside :)
<br></p>
<h2 id="02-intro-to-raw-react-apis"><a href="#02-intro-to-raw-react-apis" aria-label="02 intro to raw react apis permalink"></a>02: Intro to raw React APIs</h2>
<p>The second exercise of the workshop was already trickier - which I was happy about because definitely I didn’t want to learn again the same stuff.
It’s not often, if ever, that we are using the React.createElement. Using JSX we just skip this part, but that’s how it works under the hood.
So after learning what jQuery is doing in Javascript, now it’s React in Javascript. </p>
<p>First thing I learnt here is that the famous property ‘children’, in React, corresponds to textContent in plain JS. It makes sense, of course, as a matter of fact we are rendering some text made visually in HTML.</p>
<p>The second thing is that createElement has three - or more - arguments that can be passed. </p>
<ol>
  <li>The type of element (span, div, etc)</li>
  <li>The object passed inside the element (class, children, etc)</li>
  <li>A n number of other objects, that will be rendered as additional children.</li>
</ol>
<p>As a matter of fact, the children property doesn’t even have to be defined inside the second argument of createElement, but can be listed at the end of the method.
<br></p>
<h2 id="03-using-jsx"><a href="#03-using-jsx" aria-label="03 using jsx permalink"></a>03: Using JSX</h2>
<p>The third exercise was about creating simple JSX elements that Babel will transform in normal JS with React.createElement. As it’s basically almost a reverse engineering of the previous exercises, it was not difficult. However, it was interesting the use of the spread operator inside a div element, which createElement puts in the correct position:</p>
<div data-language="text"><pre><code>const className = 'myClass';
const children = 'this is my text';
const props = { children, className }
element = &lt;div {...props}/&gt;</code></pre></div>
<p>It will create a div with its own class and the innertext as children.</p>
<p>Another interesting point in the video is about prioritazion of position using the spread operator. Supposing that we have the above props, but then we want to override the className with another name, we have to place the spread props before. In synthesis, the right argument will always override the left ones.</p>
<div data-language="text"><pre><code>&lt;div {...props, className='secondClass'} /&gt; // &lt;div className="secondClass"&gt;
&lt;div {className='secondClass', ...props} /&gt; // &lt;div className="myClass"&gt;</code></pre></div>
<h2 id="04-creating-custom-components"><a href="#04-creating-custom-components" aria-label="04 creating custom components permalink"></a>04: Creating custom components</h2>
<p>So here we go finally to start creating components. The first part consists in creating a function that basically returns a div, so instead of repeating div div in the rendered element, we just pass the function with the string as “children”. One thing that I knew but forgot explicitly is that if I pass a parameter to the function as an object, the argument must be an object as well. So:</p>
<div data-language="text"><pre><code>helloFunction = ({children}) =&gt; {
  return &lt;div&gt;{children}&lt;/div&gt;
}

helloFunction({ children: 'Hello' });</code></pre></div>
<p>The next point was to implement this function as an element:</p>
<p><code>const myElement = React.createElement(message, { children: 'Hello!' })</code></p>
<p>and finally incorporate it in the element itself, which will be taken into ReactDom.render:</p>
<div data-language="text"><pre><code>const element = (
  ...
  {myElement}
)</code></pre></div>
<p>Following that, it’s about referring the same helloFunction but make it directly compiled through Babel as an element, without needing to pass through createElement. This is possible thanks to JSX, and it’s enough to make the function name with first letter as capital, and reference it inside the element object as that.
<code>HelloFunction = () = {}</code></p>
<p><code>&lt;HelloFunction&gt;Hello!&lt;/HelloFunction&gt;</code></p>
<p>This is the equivalent of <code>React.createElement(HelloFunction, null, 'Hello!')</code></p>
<p>Next, it was the time of implementing propTypes for typechecking, giving the same above function to have two parameters, both strings. In the workshop, it’s explained how to make a propTypes function for checking manually the type. But it’s interesting that it’s not taking advantage of the prop-types library. It is true that for a simple check of two props, importing a whole library is excessive; but I don’t think I’ll ever just use two checks. </p>
<p><code>&lt;script src="https://unpkg.com/prop-types@15.6/prop-types.js"&gt;&lt;/script&gt;</code></p>
<div data-language="text"><pre><code>HelloFunction.propTypes = {
      greeting: PropTypes.string,
      subject: PropTypes.string,
    }</code></pre></div>
<p>I’m not getting either a personalized message, but the standard warning is understandable enough</p>
<div data-language="text"><pre><code>Invalid prop `subject` of type `number` supplied to `Message`, expected `string`. in HelloFunction</code></pre></div>
<p>Ah, here we go, in the next exercise there’s the implementation of the library… ooooops, I went a little over head. But good point, to implement also ‘isRequired’</p>
<div data-language="text"><pre><code>HelloFunction.propTypes = {
      greeting: PropTypes.string.isRequired,
      subject: PropTypes.string.isRequired,
    }</code></pre></div>
<p>Anyway, Typescript rules!
<br></p>
<h2 id="05-styling"><a href="#05-styling" aria-label="05 styling permalink"></a>05: Styling</h2>
<p>In this  exercise it was needed to apply style to a custom component in various ways. On a first part, just adding inline styling to a small div; then to a custom component passing its className prop; finally, passing only a string as a size prop and selecting dynamically the style inside the custom component.</p>
<p>First note: when making a reusable component, normally it’s good to place all defaults on the left and what the user is providing (spread operator) after, because we don’t want to enforce something.</p>
<p>Second note: as usual I overcomplicated things. As the size property passed would be only small, medium and large, and the classes are called box—small, box—medium, box—large, it’s enough to substitute the size with the size prop passed into the component.</p>
<p><code>box--${size}</code></p>
<p>adding that to a ternary operator in case it’s the prop is not present.
What I did instead was a nested ternary operator with an object created with the classes names inside. Much more complicated, although it was working 😁</p>
<div data-language="text"><pre><code>const sizes = {
  small: 'box--small',
  medium: 'box--medium',
  large: 'box--large'
}

className={`box ${size === 'small' ? sizes.small : size === 'medium' ? sizes.medium : sizes.large}`}</code></pre></div>
<h2 id="06-forms"><a href="#06-forms" aria-label="06 forms permalink"></a>06: Forms</h2>
<p>In the first exercise, the object is creating a submit listener/handler that will call the function in the main component, which is passed through as a prop.</p>
<p>We can put events (will be React synthetic events) on each element; however, the onSubmit goes inside the form to catch every field that is contained.
Synthetic events are objects that React creates that look and behave like regular DOM events.
It’s still possible to access the DOM event with <code>event.nativeEvent</code>, however, the synthetic one is optimized to work with React code, and the virtual DOM.</p>
<p>I created then a function inside the function (a callback), called once the submit button is clicked. And I’ve added the preventDefault() to that event to prevent the page to refresh (as default event for a form).</p>
<p>Another interesting thing is about accessibility. Screen readers need to associate the input with its label. So it’s needed to give the input an id and the label a htmlFor (the same for= parameter in normal HTML). Moreover, this gives the property of focusing on the input when clicking on it.</p>
<p>The second part of the exercise was about doing the same as above but using the useRef hook. UseRef are simply reference pointers to an element.
First, it’s needed to be imported from ‘react’ and not ‘react-dom’.</p>
<p>Then, adding the reference to our input
<code>&lt;input ref={usernameInput}&gt;</code>
In the main function (or custom component), we can call the hook: <code>const usernameInput = useRef(null);</code>
Why null? The argument of useRef is the initial value. But in this case we don’t need that, just what will be in usernameInput.</p>
<p>Finally, we can access all our referenced properties, like the input value, this way: <code>usernameInput.current.value</code></p>
<p>In the next credit, it was needed to create a controlled input. A controlled input is an input field that is controlled by the component state. That means setting the value of the input by the state: <code>&lt;input ref={usernameInput}  value={username} onChange={handleChange} /&gt;</code></p>
<p>Then, we can set the state at the top of the component: <code>const [username, setUsername] = useState('');</code>
And finally, use that state to change the value of the input in the handleChange function. In this case, transforming every key to lowercase:</p>
<div data-language="text"><pre><code>const { value } = event.target;
setUsername(value.toLowerCase());</code></pre></div>
<p>So the flow is the following:
input from user —&gt; update input state —&gt; transforming input state -&gt; sending the state as value of the input —&gt; input appears on screens.
<br></p>
<h2 id="07-rendering-arrays"><a href="#07-rendering-arrays" aria-label="07 rendering arrays permalink"></a>07: Rendering Arrays</h2>
<p>The exercises were just little demonstrations in this case, to show the importance of using a unique index key when showing elements in the DOM through a mapping. Not without, not with the pre-built index of the map function, but with a preset set of keys to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://buaiscia.github.io/posts/learning-on-epic-react-fundamentals">https://buaiscia.github.io/posts/learning-on-epic-react-fundamentals</a></em></p>]]>
            </description>
            <link>https://buaiscia.github.io/posts/learning-on-epic-react-fundamentals</link>
            <guid isPermaLink="false">hacker-news-small-sites-24979103</guid>
            <pubDate>Tue, 03 Nov 2020 12:44:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When Computers Were Cool]]>
            </title>
            <description>
<![CDATA[
Score 118 | Comments 79 (<a href="https://news.ycombinator.com/item?id=24978637">thread link</a>) | @aphrax
<br/>
November 3, 2020 | https://datagubbe.se/coolcomp.html | <a href="https://web.archive.org/web/*/https://datagubbe.se/coolcomp.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p>
When I was a kid, computers were cool.</p><p>

Nowadays? Not so much.</p><p>

I know, I know. Grumpy old gits are a dime a dozen, and their views about the past are often filtered through a golden haze of blissful forgetfulness and nostalgia. This is of course the case for me, too, but I still think the point is valid: computers used to be much cooler - by orders of magnitude - than they are now.</p><p>

The situation can perhaps be explained by an analogy: You've got a rusty old 1994 FIAT Punto and there is a rather pressing need for you to invest in a new vehicle. Of course, you can dream big - maybe you'd like some kind of armoured personnel carrier, perhaps a souped-up, pimped-out Tesla with all the bells and whistles or why not a Ferrari? Realistically, though, you're probably considering something along the lines of a brand new Ford: the kind of sensible family car that would still be an upgrade to the withering piece of junk you're currently driving. And, as soon as you've amassed enough funds, that's probably what you're going to buy. That APC, though... Man, how sweet would it be to drive one of those? Just thundering through morning traffic, fist pumping in the air, shouting crude insults at that guy with the SUV who always cuts in front of you at the intersection down by the grocery store. Not so smug now, eh, Mr. Sports Utility?</p><p>

That's what it used to be like with computers.</p><p>

Don't get me wrong. You can spend nearly infinite amounts of money on a computer if you'd like to - it's always been like that and probably will be for the foreseeable future. This is especially true for supercomputer clusters used in science and the mainframes keeping the banks and stock markets ticking. But when dreaming about computer power, few of us imagine having access to a behemoth like that. The things we do with our machines can only go faster up to a certain point, unless we dabble in computational biology in our spare time. It would be like replacing our feeble FIAT with an aircraft carrier: sure, it's powerful, but it's not very practical for getting to and from work.</p><p>

No, the computer we dream about having on our desk is usually something a little bit faster, a little bit sleeker and just a little bit more expensive than what we can actually afford. If you're a dedicated games player, there's always the next graphics card, that extra gig of RAM, those extra few frames per second you can chase - but that's still the realistic dreaming, it's something within reach; perhaps not quite in line with a sensible Ford, but not as far out there as an APC.</p><p>

And, even if you are currently dreaming of the home computer equivalent of an APC (let's pretend that's a top of the line Mac Pro, just for the sake of argument), getting one won't make much of a difference in day to day use. Sure, the machine might be faster than your current one, but except for the rare few cases when you actually utilize all that power, it won't provide a profoundly different user experience compared to what an iMac will deliver at a fraction of the cost. It's the same OS, the same applications and the same basic architecture. This is true for Windows and Linux machines as well: you can add more RAM and disk and CPU cores, but the machine won't behave in a significantly different way from what you're used to.</p><p>

Now, when I was a kid... computers were cool.</p><p>

In 1994, I bought a second hand Amiga 1200 with a 120 megabyte hard drive. It was a low cost, capable home computer with good sound and graphics. It was more than enough for the kind of gaming and school work a kid my age wanted to do, but the 14 MHz processor was a tad slow when it came to heavy lifting. Applying just a hint of Gaussian blur to a very low resolution JPEG file took ages. Dabbling in animation, I frequently hit the barrier of the 2 megs of RAM it came with. However, it also had a motherboard connector for adding more memory and a faster CPU. This was the reasonable dream: it was within my reach, it was the sensible family Ford.</p><p>

Thus, in 1995, I got a CPU and RAM upgrade for it, making it roughly four times faster. In those days, that was a pretty hefty upgrade: speeding up from 10 to 40 MPH is more noticeable to a human compared to the difference between the 10000 and 40000 MPH speeds of today's machines. But the speed-up didn't profoundly change my user experience. I was still shuffling about with the same old software and I was still waiting around for that Gaussian blur calculation to finish - although not quite as many minutes as before.</p><p>

As I sat there, watching the Gaussian blur progress bar, I of course dreamt of the computing equivalent of an Armoured Personnel Carrier. It wasn't an Amiga 4000 or a Pentium PC or one of those new-fangled PowerMacs. It was something completely different, something that would have utterly changed my all-round user experience, from boot-up to shutdown. I wanted something the likes of which actually no longer exists: I dreamt of a Unix Workstation.</p><p>

Not just any old Unix box mind you, but a rather specific one: a Silicon Graphics Indy with a 24-bit frame buffer, 128 megabytes of memory and a 175 MHz MIPS R4400 CPU.</p><p>

It was, hands down, just about the most maxed-out piece of hardware that could grace the top of a desk. Design-wise, computers have always been kind of beige - literally and figuratively. Black computers became commonplace some time around, say, 2000, but that was hardly a giant leap in design. Depending on your tastes, you might think companies like Apple or Alienware produce attractive machines - but then again, perhaps you've never seen an SGI Indy.</p><p>

The teal blue pizza box case sports a horizontal, slightly diagonally skewed cut along the middle, shifting the top and bottom parts in a slight offset. The monitor was huge for its time: a 17" CRT cased in grey granite plastic, matching the mouse and keyboard. Both the computer and the screen were adorned with embossed SGI cube logos in a gleaming silver finish. It was over the top, maximalist 1990s more-is-more design in a strangely tasteful package and a far cry from the sleek, subdued designer machines of today. Yet, it wasn't an overstatement - it might've talked the talk, but it sure as hell could walk the walk.</p><p>

For example, it didn't even have a regular floppy drive - it had a bizarre floptical unit capable of storing 20 megabytes on a single, magneto-optical disk. On top of the giant screen a webcam was poised, surely one of the absolutely first computers to come with such a device as standard. In fact, it was called an IndyCam - the term webcam hadn't really caught on yet and was more commonly used to describe just about any camera that regularly uploaded a still image to a public web server.</p><p>

And that, of course, are all trivial oddities compared to the guts of the machine. Even though it was an entry-level workstation, SGI's custom hardware was capable of churning out both 2D and 3D graphics unmatched by any contemporaneous gaming PC, however expensive, and the CPU could run in circles around even the most outrageously-priced Pentium home computer available at the time.</p><p>

And then there was the operating system. And the software.</p><p>

IRIX, SGI's in-house Unix flavour, came with their own proprietary GUI and desktop. It was called Indigo Magic and, featuring things like scalable vector icons, animated desktop backgrounds and visual feedback cues, it was just about as outlandish as the name suggests. It should be noted that this was ten years before any PC owner had gotten the chance to grow tired of such pointless flash and that for the serious hacker, there was always a terminal emulator with a capable shell on hand.</p><p>

Apart from all the usual Unix-related niceties such as stability, pre-emptive multitasking, multi-user support, excellent command line utilities and a bunch of readily available programming languages, it had an impressive array of professional productivity software. Most of it was not available on my home computer, and even if it was, the Indy could run it both faster and in higher resolution. Apart from industry standards such as Photoshop and Netscape, there was a world of curious and wonderful applications written with nothing but SGI hardware in mind: web authoring, video editing, image manipulation and graphics creation unavailable on any other platform. It was a true digital media production workhorse, an overgrown distant cousin to the machines available on the then budding multimedia PC market.</p><p>

In short, it was a cool computer. Far too expensive for any home user, of course. But so. Damn. Cool.</p><p>

There are computers aimed at this kind of work today as well. One of the high-end Macs mentioned before, for example, or perhaps a suitably high-powered Windows machine. In fact, pretty much any dirt cheap home computer will, pixel for pixel, do what the Indy did - except faster, cheaper and in many cases better.</p><p>

Yet there isn't, today, an equivalent of the SGI Indy, or the Sun SPARCstation, or the DEC Alpha, or any of the other professional workstations. The only thing that's on offer is more of the same user experience, only slightly faster.</p><p>

That's why computers are so boring these days. Because even though IRIX, Indigo Magic and the Indy by no means was a perfect solution to all of my computational desires back then, it had the lure of the unknown and unattainable: it was a goal to strive for, a source of inspiration and aspiration and a promise that better things were possible.</p><p>

Today, we all know about the different quirks, mannerisms, privacy issues, drawbacks and occasional benefits of Windows update loops, overpriced Mac hardware and the tiresome fiddliness of Linux. Those are the choices we have and they're not going to change any time soon.</p><p>

I'd somehow be more okay with all of this if it wasn't for the fact that, to top it all off, we have no other platform left to dream of.</p><p>

That's just not cool.
</p></div></div>]]>
            </description>
            <link>https://datagubbe.se/coolcomp.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24978637</guid>
            <pubDate>Tue, 03 Nov 2020 11:30:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Model of Small Decisions]]>
            </title>
            <description>
<![CDATA[
Score 61 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24978356">thread link</a>) | @SerCe
<br/>
November 3, 2020 | https://ahitrin.github.io/work/2020/11/03/a-model-of-small-decisions/ | <a href="https://web.archive.org/web/*/https://ahitrin.github.io/work/2020/11/03/a-model-of-small-decisions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
<p><img src="https://ahitrin.github.io/images/a-model-of-small-decisions/forest.jpg" alt="a dence forest">
<small>Would you like to walk here at night? Photo: Andrey Hitrin</small></p>

<p>Sometimes thoughts of our human nature makes me sad.
Our attempts to share own thoughts to others can be compared with attempts to find a way out from the dense forest during a moonless night aimed only with a laser pointer.
The only thing you could show to others is a little spot of light randomly jumping back and forth, appearing and disappearing spontaneously.
How could you find a trail with such a weak tool?
How could you convince your party to follow it?
How could you understand if this trail should take you out of the forest?</p>

<p>That’s why people try to invent new and new words to explain same conceptions.
Everyone hopes that his/her explanations will be good enough to make other understand “the inner nature of things”.
Most of the time it’s worthless: others don’t see more than chaotically jumping light spot.</p>

<p>Nevertheless, here is my own attempt.
Words written here are not the truth, they are nothing more than my biased reflection of it, based on my limited experience.
I don’t know if they are contains some wisdom, or just a bunch of useless commonplace.
That’s you who will judge.</p>

<h2 id="the-quest-for-mastery">The quest for mastery</h2>

<p>As usual, I want to speak about programming.</p>

<p>There is an idea that programming has many similarities with martial arts or musical performing.
In all of these areas you could show some results after relatively little amount of practice, but it requires years of studying and training if you want to achieve truly significant level.
Often you even have to perform at the edge of your own abilities.</p>

<p>And when you want to perform at such level, you must be aware of all aspects of your profession.
Today I want to speak about small and often invisible decisions that guide you through your everyday work.</p>

<h2 id="small-decisions">Small decisions</h2>

<p>In our job, you need to do a lot of small decisions every day.
Just watch after yourself during work process, and soon you will be able to notice them.</p>

<p>Imagine you’ve just started to work on some feature.
Small decisions appear instantly.
How will you start you work?
By reading documentation, or by checking code out, or by asking your colleagues?
Change some code first, or think about test cases?
Implement straightforward change, or roll out few refactorings beforehand?</p>

<p>How will you deal with “bad code” challenging your way: ignore it, or try to fix right now, or defer a fix for a “better time”?
How will you act when feeling struck: ask your teammate (and which one, when you have several of them), google your problem, stackoverflow it?
Or maybe simply wait until an answer forms inside your head (also known as ‘procrastinating’)?
Or maybe wait until someone asks you about the progress?</p>

<p>That’s what I mean by the “small decisions” term.
A lot (tens, or even hundreds per day) micro-choices you make in your work.
Sometimes you make this choice consciously, but often not!
You choose your path without even thinking about it, without even noticing the fact of choosing.</p>

<p>Does this matter?
I think it does.</p>

<h2 id="choosemove-dichotomy">Choose/move dichotomy</h2>

<p>Let’s draw your way through the imaginary “work task”.
I like to draw graphs, so it’s depicted as a graph.</p>

<p><img src="https://ahitrin.github.io/images/a-model-of-small-decisions/01_a_to_b.jpg" alt="one way from Start to Goal"></p>

<p>Every node here is a small choice you’ve made.
Arrows represent the “movement” between them.
A number of intermediate steps is arbitrary and depends on your own definition of “small decision”.
When you zoom out, they almost disappear.
When you zoom in, a single decision could be even as small as “<em>which finger should hit the given keyboard button?</em>”.
Here I choose something intermediate.</p>

<p>And now let’s imagine more possible moves that also could solve your task.</p>

<p><img src="https://ahitrin.github.io/images/a-model-of-small-decisions/02_a_to_b.jpg" alt="many ways from Start to Goal"></p>

<p>Here we see a whole net of possible decisions.
What would happen if you choose another step at the start?
Some of alternative ways could be shorter (containing less hops), some of them could be much, much longer!
Of course, here I simplify the problem <strong>a lot</strong>.
But I need this simplification to show you few important things.
Here are following key points:</p>

<ol>
  <li>
    <p><strong>You have to make a lot of decisions</strong>.
There are points in almost every task that requires your decision.
For example, you need to ask yourself at least once: “<em>have I reached my goal?</em>”.
And then either get done with it or continue to work.</p>
  </li>
  <li>
    <p><strong>Even small decisions may have big impact</strong>.
When you choose the wrong path at start, it may lead you far away from the goal.
You have to move along the non-optimal path or return back to the start.</p>
  </li>
  <li>
    <p><strong>Every decision takes your time and energy</strong>.
Usually delay on decision come from one of two or three sources.
The first source is <strong>delay between a question and an answer</strong>.
Say you’re struck and don’t know where to move next.
You try to ask your colleague via IM for help.
But currently he/she is busy, and only can answer you in 20 minutes.
This delay is the cost of your decision.
The second source is <strong>delay on choosing</strong> by itself.
It may happen when you see two or more alternative paths and hesitate which one should be followed on (maybe a “frustration” word is suitable here).
The third one is <strong>a need to remember</strong> a known, but currently forgotten solution (more on this in the next chapter).</p>
  </li>
</ol>

<p>All of these make me conclude that it’s important to consider the impact of decision making to our work.
Low-quality decisions reduce your productivity <em>every day</em>.
They make you stray in the dark without help.</p>

<p>Surprisingly, even after reading a lot of books and articles on programmer’s productivity, I haven’t found enough much attention to this theme (please correct me if I’m wrong!).
That’s the main reason why I’ve started to write this article.</p>

<h2 id="a-table-of-decision-rules">A table of decision rules</h2>

<p>OK, maybe quality of decisions is important.
But how could we ever manage them?
Here I suggest a simple <em>model</em>.
As any other model, it doesn’t describe things as they are, but uses simpler (and more manageable) view on it instead.
The main power of modeling is its ability to predict effects of our actions, but we should never forget about its boundaries.
Outside boundaries, our model will be wrong - and I don’t know where they are.
I sincerely hope that your feedback could help determine them.</p>

<p>The model is heavily inspired by the work [1].
Think for a minute: this paper is already 40 years old!
Why no one still haven’t developed it into the similar direction as I did?
I don’t know (or maybe I’m just wrong - please let me know in that case).</p>

<p>This prelude was necessary - but now let’s proceed to the model.
So, suppose each of us have some kind of <em>table</em> in the head (I warned you, it’s a simplified view).
It contains two columns:</p>

<ol>
  <li>
    <p><strong>Trigger</strong>.
An external stimulus that could activate current “table row” or <em>rule</em>.
For example: a piece of code you’re looking at; a letter from CI server; a message from your colleague; your current thoughts about your task; and so on.</p>
  </li>
  <li>
    <p><strong>Acton</strong>.
A thing you do when the <em>rule</em> is being activated.</p>
  </li>
</ol>

<p>It may look like this:</p>

<table>
<colgroup>
<col width="35%">
<col width="5%">
<col width="60%">
</colgroup>
<thead>
<tr>
<th>Trigger</th>
<th></th>
<th>Action</th>
</tr>
</thead>
<tbody>
<tr>
<td>You need to find the source of a bug</td>
<td>→</td>
<td>Run <code>git bisect</code> to find a commit where it was introduced. Then analyse the code</td>
</tr>
<tr>
<td>You want to check if your code is ready to deploy</td>
<td>→</td>
<td>Push changes to remote repository and run CI service</td>
</tr>
<tr>
<td>You want to check if your code is ready to deploy</td>
<td>→</td>
<td>Push changes to remote repository and ask someone to review it</td>
</tr>
<tr>
<td>You have detected the "smell of ugly code"</td>
<td>→</td>
<td>Try to refactor it out immediately</td>
</tr>
<tr>
<td>You have detected the "smell of ugly code"</td>
<td>→</td>
<td>Ignore it: we don't have time to refactor</td>
</tr>
<tr>
<td>Selenium test on CI server has failed</td>
<td>→</td>
<td>Look at screenshot to check where is the problem</td>
</tr>
<tr>
<td>Selenium test on CI server has failed</td>
<td>→</td>
<td>Look at job logs</td>
</tr>
<tr>
<td>Selenium test on Ci server has failed</td>
<td>→</td>
<td>Launch that job again: maybe it's just flaky test?</td>
</tr>
<tr>
<td>You're struck and don't know what to do next</td>
<td>→</td>
<td>Ask your teammates for help</td>
</tr>
<tr>
<td>You're struck and don't know what to do next</td>
<td>→</td>
<td>Wait until someone asks you what's going on</td>
</tr>
<tr>
<td>...</td>
<td>→</td>
<td>...</td>
</tr>
</tbody>
</table>

<p>This table has important properties:</p>

<ol>
  <li>
    <p>It <strong>changes over time</strong>, depending on your own experience and knowledge.
When you discover new tricks, they have a chance to hold in the table.
In other hand, even the best practices without repetition pass away from your memory.
Of course, they do not always being erased completely.
Rather, they are removed from “the cache”, the fastest part of your memory.
And you’ll have to make an effort of remembering to bring it back.</p>
  </li>
  <li>
    <p>It has <strong>limited size</strong>.
You cannot know literally everything.
You cannot have the best solution for every possible situation you may face.</p>
  </li>
  <li>
    <p>It may have <strong>several rules for one situation</strong>.
In that case your final choice may depend on current context.
Sometimes you may even need to spend additional time and effort to make a choice between alternative actions (“resolve a conflict”).</p>
  </li>
  <li>
    <p>It models <strong>only small decisions</strong>.
Only little choices that often even pass your spotlight and perform automatically could be modelled that way.
In terms of “Thinking, Fast and Slow” [2], it relies to the “System 1” only.</p>
  </li>
</ol>

<p>There could be different sources where these rules come from:</p>

<ul>
  <li>Your previous successful and unsuccessful experience.</li>
  <li>Observations of your teammates: how do they behave in different situations.</li>
  <li>Direct rules of the project you’re working on (like “use <code>./gradlew check</code> to verify correctness of your code”).</li>
</ul>

<p>I hope to write more on it in following articles, but the current one has grown big enough.
Seems like I have to go to conclusions.</p>

<h2 id="any-benefits">Any benefits?</h2>

<p>What benefits could the awareness about these rules bring to you?</p>

<p>First of all, you should take into consideration the limited size of your memory.
In order to make better decisions, you need to consciously “tune” your rule table.
How could it be done?</p>

<ul>
  <li>
    <p><strong>Remember your good (effective) decision rules</strong>.
Practice them from time to time so they don’t leave your working memory.
Write them down in known place so they could be remembered effectively when needed.</p>
  </li>
  <li>
    <p>Try to <strong>free your memory from unneeded decision rules</strong>.
If they aren’t needed, forget them.
If they still may be useful, keep them in an external place.
For example, imagine you have a complex …</p></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ahitrin.github.io/work/2020/11/03/a-model-of-small-decisions/">https://ahitrin.github.io/work/2020/11/03/a-model-of-small-decisions/</a></em></p>]]>
            </description>
            <link>https://ahitrin.github.io/work/2020/11/03/a-model-of-small-decisions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24978356</guid>
            <pubDate>Tue, 03 Nov 2020 10:46:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Untimely Demise of Workstations]]>
            </title>
            <description>
<![CDATA[
Score 145 | Comments 192 (<a href="https://news.ycombinator.com/item?id=24977652">thread link</a>) | @ingve
<br/>
November 3, 2020 | https://deprogrammaticaipsum.com/the-untimely-demise-of-workstations/ | <a href="https://web.archive.org/web/*/https://deprogrammaticaipsum.com/the-untimely-demise-of-workstations/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<p>Last month’s news that <a href="https://arstechnica.com/information-technology/2020/10/ibm-to-split-into-two-companies-by-the-end-of-2021/">IBM would do a Hewlett-Packard</a> and divide into two—an IT consultancy and a buzzword compliance unit—marks the end of “business as usual” for yet another of the great workstation companies.</p>
<p>A quick aside on computing history. You can imagine personal computing being driven by two distinct schools of thought. The “top down” school, represented by research-led organisations including Xerox PARC, Bell Labs,academia and the military, asked “what would the world be like if everyone had their own minicomputer”? They took large, time-sharing systems like UNIX and installed them first under, then on, employees’ desks for their own personal use.</p>
<p>The “bottom up” school was made up of hobbyists who asked “can we make an interesting computer out of inexpensive components”? Thus companies like Apple and MITS in the US, Acorn and Sinclair Radionics in the UK, and others took chips that were usually used as peripherals controllers in “real” computers and built interactive programming systems around them. The microcomputer revolution came from the bottom-up school, as they made home computing affordable. The workstation revolution came from the top-down school, as they made powerful on-demand computing feasible.</p>
<p>The two schools came into very close proximity in the 1980s, when the Motorola 68000 family of CPUs (along with the 68881/68882 FPU and 68851 MMU) were the processors of choice in everything from entry-level PCs like the Atari 520ST, through games consoles like the Sega Mega Drive (Genesis in the US), to the most expensive UNIX workstations from NeXT Computer, Sun Microsystems, and Apollo Computer.</p>
<p>But then the workstation makers invested heavily in their own CPU architectures based on RISC design principles and again the two diverged. The workstation market became highly differentiated: RS/6000 from IBM (later PowerPC), Alpha from Digital Equipment Corp, MIPS from, well, MIPS, SPARC from Sun, PA-RISC from HP. The software on these workstations, while superficially very similar, was also differentiated and surprisingly incompatible. Take a program from HP-UX and you’ll have difficulty running it on NeXTSTEP, unless the authors shared the source code and used the nascent GNU autotools to support portable building. As Yoda said: begun, the <a href="https://www.livinginternet.com/i/iw_unix_war.htm">UNIX wars</a> have.</p>
<p>Of course we know that the (desktop) computing world today is mostly Intel and that workstations are mostly fancy PCs, rather than bespoke designs by vertically-integrated companies, Apple being the two trillion dollar outlier. How we got here was that the commodity parts got good enough that there was no evident advantage to workstation-grade hardware. A high-end PC could easily run a workstation OS like System V UNIX (Solaris was an early example), BSD (386BSD which later became FreeBSD, or NeXTSTEP) or Windows NT.</p>
<p>Along the way, the workstation companies consolidated (Apollo and eventually DEC got absorbed into HP; MIPS into SGI) or disappeared altogether (Sun became Oracle Hardware; SGI went bankrupt and sold its assets to sgi; Symbolics did similar—incidentally Symbolics was the first company with a .com domain). IBM long ago stopped even making its own brand PCs, and the news of its split means that there are now very few workstation companies trading in the same form they had “back in the day”. The only ones I can think of that have not had major changes to their corporate structures are Xerox and Sony, whose management may not even have known that they sold workstations.</p>
<p>What’s got lost alongside the death of the workstation is the business model where you sell expensive computers as part of an integrated solution into a particular vertical market, where that expensive solution will cost a lot less than cobbling something together out of cheap PCs. Why? I think people have a lower expectation and higher pain threshold when using computers now; they expect an amount of friction based on their own experience and translate that expectation into realms where it doesn’t belong. As I described way back in issue 2, <a href="https://deprogrammaticaipsum.com/the-various-meanings-of-quality/" target="_blank" rel="noopener noreferrer">computing is a lemon market</a>.</p>
<p>Organisations would go to the workstation vendors because they solved particular problems very well. If you’re in AI, you need Symbolics. Computer graphics, SGI. Telecoms, that’d be Sun. If you want to write software in Ada for the military-industrial complex, you’ll be buying a Rational workstation. Yes, the first IDE was a completely integrated package of hardware and software. And, of course, Apple for Desktop Publishing, the Mac being a workstation of sorts itself. People would buy computers <em>because</em> applications like AutoCAD, Quark or Mathematica ran well on them. They wouldn’t buy the computer then browse the App Store to see whether it could do anything useful.</p>
<p>And the strange thing is that catering to those vertical markets with integrated solutions is easier than ever now. The wide availability of free software means that the basic job of “being a desktop computer” is taken care of at zero cost, so business can focus on contributing valuable bespoke behaviour. And hardware costs are lower than ever: the availability of high-capability SoCs and single-board computers like the Raspberry Pi and Rock64 should make it a no-brainer to sell the computers as accessories for the applications, not the other way around.</p>
<p>In high-tech domains, an engineer could readily have a toolchest of suitable computers in the same way that a mechanic has different tools for their tasks. This one has an FPGA connected by both PCI-E and JTAG to allow for quick hardware prototyping. This one is connected to a high-throughput GPU for visualisations; that one to a high-capacity GPU for scientific simulations.</p>
<p>The general purpose hardware vendors want us to believe that an okay-at-anything computer is the best for everything: you don’t need a truck, so here’s a car. But when you’re hauling a ton of goods, you’ll find it cheaper and more satisfying to shell out more for a truck. Okay-at-anything is good for nothing.</p>
<p>Cover photo by <a href="https://unsplash.com/@serejahh">Serhii Butenko</a> on <a href="https://unsplash.com/photos/zx2Vc1zPDIs">Unsplash</a>.</p>
	</div></div>]]>
            </description>
            <link>https://deprogrammaticaipsum.com/the-untimely-demise-of-workstations/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24977652</guid>
            <pubDate>Tue, 03 Nov 2020 08:34:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nassim Taleb vs. Nate Silver: who is right about election forecasting?]]>
            </title>
            <description>
<![CDATA[
Score 92 | Comments 154 (<a href="https://news.ycombinator.com/item?id=24976175">thread link</a>) | @probe
<br/>
November 2, 2020 | http://quant.am/statistics/2020/10/11/taleb-silver-feud/ | <a href="https://web.archive.org/web/*/http://quant.am/statistics/2020/10/11/taleb-silver-feud/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>Perhaps lost in the whirlwind of presidential name-calling, a lesser-known multi-year old feud has resurfaced on Twitter this election season. Nate Silver is the founder of <a href="https://fivethirtyeight.com/">FiveThirtyEight</a> and is a popular statistician frequently called upon by media members to give commentary and expertise on election forecasting. Nassim Taleb is a statistician/quant turned philosopher, perhaps most well known for authoring the book “The Black Swan”. He is second most well known for calling people names on Twitter. In this 2018 instance he seemed to take issue with FiveThirtyEight’s election forecasts, saying that <a href="https://twitter.com/nntaleb/status/1059202026184282113">“klueless Nate Silver” “doesn’t know how math works”</a>, among a host of other insults. Silver responded that Taleb was an <a href="https://twitter.com/NateSilver538/status/1062782704159256576">“intellectual-yet-idiot”</a>, an phrase coined by Taleb himself. Ouch. A litany of statisticans, mathematicians, and data scientists came out of the woodwork to take sides. Taleb himself <a href="https://twitter.com/nntaleb/status/1314902682570764288">doubled down</a> on Oct. 10, 2020, again calling Silver “totally clueless”.</p>

<p>In this article I take a look behind the mathematical premises of Taleb’s arguments, and give intuitive explanations of why or why not they hold up. In short, while Taleb’s math is sound, he still manages to miss the mark by ignoring the nuance of Silver’s forecasts.</p>

<p>Taleb’s main gripe is that forecasters change their opinion too much over time. Take a look at FiveThirtyEight’s forecast from the 2016 presidential election, where the probability of Clinton winning peaked at 90%, and hit a low of 50%. 
<img src="http://quant.am/assets/2016election.png" alt="2016 election"></p>

<p>Taleb insists that Clinton never should’ve received a probability of winning of 90%. Even if polls were heavily in favor of Clinton at the time, he says Silver should’ve taken into account the uncertainty that polls would change over the next few months leading up to the election, or the possibility of major news breaking. If Silver had factored in the “unknown unknowns” his forecast should’ve been closer to 50%. In essence, this single number should reflect all <em>current and future uncertainty</em>. Taleb constructs this argument by way of quantitative finance, which perhaps led to him and traditional statisticians talking past each other. In the following sections I step through his argument in intuitive terms.</p>


<p>A well known truth to economists, quants, and traders: if I tell you a number, I must be willing to transact at that number. If I tell you the fair value of this house is $500,000, I must be willing to buy AND sell at that price. Otherwise, the number I gave you is meaningless. Likewise, if I tell you the probability of Biden winning this election is 73%, I must be willing to pay $0.73 to make the following wager: if Biden wins I receive $1, if he loses I receive $0.</p>

<p>This is important because it turns the predicted probabilities into a tradeable financial instrument known as a binary option. If the prediction is 50%, I can buy the option at $0.50. If the prediction moves to 65%, I can now sell the option at $0.65, turning a $0.15 profit.</p>

<p>This brings us to another important principle known as the <em>no-arbitrage condition</em>. If the election predictions are accurate, there should be no way for a trader to make guaranteed money by trading this option. To give an illustrative example, let’s say that we live in an unchanging world where the probability of Candidate A winning is static at 50%. If a pollster does not report a static forecast day after day, he will create an arbitrage opportunity. We will sell when the prediction is above 50%, and buy below. 
<img src="http://quant.am/assets/arbitrage-pollster.jpeg" alt="Arbitrage condition"></p>

<p>OK, so now we’ve established that if an arbitrage condition exists, then the pollster is wrong and should not have made that prediction in the first place. Still, it’s not obvious that there’s an arbitrage condition within Silver’s predictions yet (remember, the trader doesn’t have access to an oracle, and only has the same information available to him as the pollster). There’s two more building blocks that we need in order to establish an arbitrage condition.</p>


<p>To paraphrase Taleb, if I tell you an event has a 0% chance of occurring, I cannot change my mind and tell you tomorrow it now has a 50% chance of occurring. Otherwise I shouldn’t have told you it has a 0% chance in the first place. Probability and confidence are inextricably linked, and the number a pollster predicts should encapsulate both. To go to the other extreme, if the uncertainty is extremely high (and therefore confidence low), <em>it does not matter what the polls today are saying</em>. I should give both candidates a 50% chance of winning, because I am admitting the extremely likely possibility that an external event will happen that will invalidate today’s polls. To put it in technical terms, maximum uncertainty implies maximum entropy, and the maximum entropy distribution on the [0, 1] interval is the uniform distribution, which has a mean at .5. The following figure (from <a href="https://arxiv.org/pdf/1703.06351.pdf">this paper</a>) shows the relationship between probability (x-axis) and volatility (y-axis) under a specific option pricing formulation.
<img src="http://quant.am/assets/confidence-probability.png" alt="Confidence vs volatility"></p>

<p>At this point we are suspecting something doesn’t look right with FiveThirtyEight’s predictions, as they seem to have both high volatility and high probability, which contradict each other. Where is the threshold though? How can we prove that the volatility is too high?</p>


<p>Now we’re going to go a little bit technical and show that a no-arbitrage condition was likely violated. The basic construction is as follows:</p>

<ol>
  <li>In order to satisfy the no-arbitrage condition, all information must be “priced in” into the pollster’s current prediction.</li>
  <li>Therefore, the time series of predictions must be a martingale.</li>
  <li>Martingales cannot show trending or mean-reverting behavior, therefore Silver’s predictions violated the martingale property, and therefore the no-arbitrage condition.</li>
</ol>

<p>The definition of a martingale is a stochastic process \(X_1, X_2, ... X_t\) that satisfies</p><p>

\[E[X_{t+1} | X_1, ... ,X_t] = X_t\]

</p><p>To quote <a href="https://www.researchgate.net/profile/Christopher_Wlezien/publication/344419648_Information_incentives_and_goals_in_election_forecasts/links/5f73c994a6fdcc0086484861/Information-incentives-and-goals-in-election-forecasts.pdf">Andrew Gelman</a>,</p>

<blockquote>
  <p>In non-technical terms, the martingale property says that knowledge of the past will be of no use in predicting the future…One implication of this is
that it should be unlikely for forecast probabilities to change too much during the campaign (Taleb, 2017). Big events can still lead to big changes in the forecast: for example, a series of polls with Biden or Trump doing much better than before will translate into an inference that public opinion has shifted in that candidate’s favor. The point of the martingale property is not that this cannot happen, but that the possibility of such shifts should be anticipated in the model, to an amount corresponding to their prior probability. If large opinion shifts are allowed with high probability, then there should be a correspondingly wide uncertainty in the vote share forecast a few months before the election, which in turn will lead to win probabilities closer to 50%.</p>
</blockquote>

<p>In other words, all information is already priced into the current market. If it were not so, a trader could make money by taking advantage of the information that is not priced in already. So last thing we need to check: is it likely that Silver’s predictions have the martingale property? It is not in dispute that the answer is no…it shows clear mean-reversion behavior and can be validated by a statistical test of the martingale hypothesis (for example, a <a href="http://www.planchet.net/EXT/ISFA/1226.nsf/9c8e3fd4d8874d60c1257052003eced6/35822efeb009804cc1257afe006b0063/$FILE/11park.pdf">Kolmogorov-Smirnov test</a>). It seems that Taleb’s math is sound here. So where did he go wrong?</p>


<p>I believe Nate Silver is answering a subtly different question with his election forecasts. Each data point that Silver produces is answering the question: <em>if the election were to happen today</em>, what is the probability of each candidate winning? I argue that this is a valid and useful formulation. To put it slightly differently: if the question is “Who will win the election on Nov. 3?”, which of the following answers is more satisfying?</p>

<ul>
  <li>“If nothing else changes between now and the election, Joe Biden has a 85% chance of winning.” (Silver’s argument)</li>
  <li>“I dunno, anything could happen between now and the election, I give neither candidate chances much more than 50%.” (Taleb’s argument)</li>
</ul>

<p>It is a valid criticism that perhaps Silver is not very clear on explaining what his numbers represent, and therefore the media misreports his predictions. Still, I wager that most people would find the first answer more useful. In this interpretation, the “financial instrument” is a binary option that expires every day. Thefore the time series of Silver’s predictions is not interpretable as a martingale, as it strings together the price of a completely different instrument every day.</p>

<p>It is also a valid criticism that Silver’s predictions prior to Nov. 3 mean absolutely nothing, whereas in the Taleb formulation it has a natural interpretation as the betting odds for each candidate. Silver has explicitly stated that he only judges his models based on his finalized prediction. To that end, his models are extremely well calibrated, i.e., when he says something has a 50% chance of happening it actually does happen 50% of the time.
<img src="http://quant.am/assets/538-calibration.png" alt="538 calibration"></p>

<p>In conclusion, Taleb and Silver should be having a philosophical debate on what pollsters’ numbers actually mean, and stay away from the useless distraction of calling each other names on Twitter.</p>

<h3 id="update-10122020">Update (10/12/2020)</h3>
<p>Andrew Gelman, Aubrey Clayton, Dhruv Madeka and many other statisticians respond and give their thoughts: <a href="https://statmodeling.stat.columbia.edu/2020/10/12/more-on-martingale-property-of-probabilistic-forecasts-and-some-other-issues-with-our-election-model/">https://statmodeling.stat.columbia.edu/2020/10/12/more-on-martingale-property-of-probabilistic-forecasts-and-some-other-issues-with-our-election-model/</a></p>

<h3 id="update-2-1132020">Update 2 (11/3/2020)</h3>
<ul>
  <li>Nassim Taleb responds to this post on <a href="https://twitter.com/nntaleb/status/1323594733797679104">Twitter</a></li>
  <li><a href="https://news.ycombinator.com/item?id=24976175">Hacker News discussion</a></li>
</ul>

		</div></div>]]>
            </description>
            <link>http://quant.am/statistics/2020/10/11/taleb-silver-feud/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24976175</guid>
            <pubDate>Tue, 03 Nov 2020 04:04:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EME, CDM, AES, CENC, and Keys – Building Blocks of DRM]]>
            </title>
            <description>
<![CDATA[
Score 92 | Comments 48 (<a href="https://news.ycombinator.com/item?id=24975487">thread link</a>) | @jayjohn436
<br/>
November 2, 2020 | https://ottverse.com/eme-cenc-cdm-aes-keys-drm-digital-rights-management/ | <a href="https://web.archive.org/web/*/https://ottverse.com/eme-cenc-cdm-aes-keys-drm-digital-rights-management/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<figure>
<img src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/08/eme-cdm-cenc-featured-image.png?resize=678%2C381&amp;ssl=1" alt="eme cdm cenc keys" title="eme-cdm-cenc-featured-image" data-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/08/eme-cdm-cenc-featured-image.png?resize=678%2C381&amp;ssl=1" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">
</figure>


<p><strong>Anyone trying to understand DRM (Digital Rights Management) will be confronted with acronyms such as AES, CDM, CENC, EME, etc. This can get very confusing for a newcomer, but understanding them is important to get a good understanding of DRM. In this article, let’s take a gentle tour of the building blocks of DRM:- EME, CDM, AES, CENC, and the use of Keys &amp; Key Servers.</strong></p>








<h2 id="simplified-architecture-of-a-drm-system"><span id="Simplified_Architecture_of_a_DRM_System"></span>Simplified Architecture of a DRM System<span></span></h2>



<p>As we saw&nbsp;<a href="https://ottverse.com/what-is-drm-digital-rights-management/">in the previous article</a>,&nbsp;<strong>DRM is a combination of encryption and business rules to control access and consumption of digital content.</strong></p>



<p>Simply put, DRM is a system that,</p>



<ul><li>provides the tools and infrastructure to enable a content provider to encrypt their content, and</li><li>build an ecosystem around the encrypted content so that the content provider can control who/what can decrypt and consume their content.</li></ul>



<p><a href="https://ottverse.com/what-is-drm-digital-rights-management/">In the previous article of the series</a>, we saw Ram and Shyam sending coded messages to each other. At the same time, Hari maintained the codebooks and decided who got to read/write the notes – remember?</p>



<figure><img data-attachment-id="156" data-permalink="https://ottverse.com/with-drm/" data-orig-file="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/with-drm.png?fit=1316%2C878&amp;ssl=1" data-orig-size="1316,878" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="with-drm" data-image-description="" data-medium-file="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/with-drm.png?fit=300%2C200&amp;ssl=1" data-large-file="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/with-drm.png?fit=1024%2C683&amp;ssl=1" loading="lazy" width="1024" height="683" src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/with-drm.png?resize=1024%2C683&amp;is-pending-load=1#038;ssl=1" alt="aes-cenc-cdm-eme-keys" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/with-drm.png?resize=1024%2C683&amp;ssl=1 1024w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/with-drm.png?resize=300%2C200&amp;ssl=1 300w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/with-drm.png?resize=768%2C512&amp;ssl=1 768w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/with-drm.png?resize=1200%2C801&amp;ssl=1 1200w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/with-drm.png?w=1316&amp;ssl=1 1316w" data-lazy-sizes="(max-width: 1000px) 100vw, 1000px" data-lazy-src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/with-drm.png?resize=1024%2C683&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>Now, let’s take this simple system and replace it with the technology needed to secure and distribute video. What do we get?</p>



<figure><img data-attachment-id="138" data-permalink="https://ottverse.com/step-0/" data-orig-file="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0.png?fit=1396%2C818&amp;ssl=1" data-orig-size="1396,818" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="step-0" data-image-description="" data-medium-file="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0.png?fit=300%2C176&amp;ssl=1" data-large-file="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0.png?fit=1024%2C600&amp;ssl=1" loading="lazy" width="1024" height="600" src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0.png?resize=1024%2C600&amp;is-pending-load=1#038;ssl=1" alt="aes-cenc-cdm-eme-keys" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0.png?resize=1024%2C600&amp;ssl=1 1024w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0.png?resize=300%2C176&amp;ssl=1 300w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0.png?resize=768%2C450&amp;ssl=1 768w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0.png?resize=1200%2C703&amp;ssl=1 1200w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0.png?w=1396&amp;ssl=1 1396w" data-lazy-sizes="(max-width: 1000px) 100vw, 1000px" data-lazy-src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0.png?resize=1024%2C600&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>Let’s describe what we have here. There is a movie that we want to send to an authenticated user securely.</p>



<p>So,</p>



<ol><li>we ask a DRM company’s server for a codebook to encrypt our video,</li><li>then, we encrypt the video using that codebook</li><li>we send the movie to the user.</li><li>the user then asks the DRM company’s server for the codebook to unlock the video (decrypt it)</li><li>and then he watches the movie!</li></ol>



<p>Fantastic!</p>



<p>Is this all there is to know about DRM for video?</p>



<p>Nope! What we have here is a simple, toy-example of how to transfer movies securely using DRM. It captures the essence of DRM perfectly but wouldn’t work well in the real world.</p>



<p>In the rest of this article, let’s take each piece of this simple system, re-think it, re-design it, and see how it fits within the world of video delivery and DRM, shall we?</p>



<h2 id="step-0-lets-move-to-adaptive-bitrate-streaming"><span id="Step_0_Let%E2%80%99s_Move_to_Adaptive_Bitrate_Streaming"></span>Step 0: Let’s Move to Adaptive Bitrate Streaming<span></span></h2>



<p>Before we talk about the order, let’s modify our example to suit the ABR (<strong>A</strong>daptive&nbsp;<strong>B</strong>it<strong>R</strong>ate) model of video delivery.</p>



<p><strong>ABR Refresher:</strong>&nbsp;in ABR, a movie is encoded into different bitrate-resolution combinations&nbsp;<em>(a.k.a ladder)</em>&nbsp;and then split into&nbsp;<strong>chunks or segments</strong>. Each chunk represents a few seconds of video and it is independently decodable.</p>



<p><strong>“Packaging”</strong>&nbsp;refers to chunking or breaking up a movie into small pieces and describing it in a manifest or playlist document. When the user wants to play the movie, he needs to refer to this manifest.</p>



<p>Depending on the available bandwidth, the player requests a chunk/segment of a particular bitrate&nbsp;<em>(rendition, or rung of the ladder)</em>&nbsp;and a CDN (Content Delivery Network) responds with the requested chunk.</p>



<p>Popular methods of video delivery using ABR are MPEG DASH and HLS. For a deeper understanding, please refer to our articles on&nbsp;<a href="https://ottverse.com/what-is-ott-video-streaming/">OTT</a>&nbsp;and&nbsp;<a href="https://ottverse.com/what-is-abr-video-streaming/">ABR</a>&nbsp;video streaming.</p>



<p>Let’s change our block digram to reflect ABR video delivery.</p>



<figure><img data-attachment-id="139" data-permalink="https://ottverse.com/step-0-with-abr/" data-orig-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0-with-abr.png?fit=1476%2C868&amp;ssl=1" data-orig-size="1476,868" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="step-0-with-abr" data-image-description="" data-medium-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0-with-abr.png?fit=300%2C176&amp;ssl=1" data-large-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0-with-abr.png?fit=1024%2C602&amp;ssl=1" loading="lazy" width="1024" height="602" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0-with-abr.png?resize=1024%2C602&amp;is-pending-load=1#038;ssl=1" alt="aes-cenc-cdm-eme-keys" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0-with-abr.png?resize=1024%2C602&amp;ssl=1 1024w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0-with-abr.png?resize=300%2C176&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0-with-abr.png?resize=768%2C452&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0-with-abr.png?resize=1200%2C706&amp;ssl=1 1200w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0-with-abr.png?w=1476&amp;ssl=1 1476w" data-lazy-sizes="(max-width: 1000px) 100vw, 1000px" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0-with-abr.png?resize=1024%2C602&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>The only changes here are the packaging and CDN-based delivery steps. That’s all.</p>



<p>Okay, let’s move on and start with the encryption process.</p>



<h2 id="step-1-video-encryption"><span id="Step_1_Video_Encryption"></span>Step 1: Video Encryption<span></span></h2>



<p>The whole idea of encryption is to ensure that when someone intercepts our data, they should not read it or watch it in the case of video.</p>



<p><strong>Encryption refresher:</strong>&nbsp;–&nbsp;<em>encryption is a technique used to keep data confidential and prevent unauthorized people from reading it. Encryption uses a “key” to convert input data (plaintext) into an alternate form called ciphertext. It is almost impossible to convert the ciphertext back to plaintext without the key.</em></p>



<p><em>However, practically speaking, decryption without the key is possible, and encryption algorithms are designed make reverse-engineering extremely expensive – in terms of time, money, and computing resources needed.</em></p>



<p>One of the most popular encryption techniques is the “Advanced Encryption Standard” or “AES” for short. It is also called Rijndael (after its inventor) and was established by the U.S. National Institute of Standards and Technology (NIST) in 2001 to encrypt electronic data.</p>



<p>Some important points to remember about AES:-</p>



<ul><li>It’s a&nbsp;<strong>symmetric-key algorithm</strong>: encryption and decryption are performed using the same key.</li><li>It has three variants based on the key-length: 128, 192, and 256 bits. The longer the key, the harder it is to crack.</li><li>Cracking the AES-128 without the key would require a “billion times a billion years” and a super-computer (<a href="https://www.eetimes.com/how-secure-is-aes-against-brute-force-attacks/" target="_blank" rel="noopener">source</a>).</li></ul>



<p>If you are interested in going deep into the AES standard, look at the&nbsp;<a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard" target="_blank" rel="noopener">AES’s Wikipedia page</a>.&nbsp;<em>I am not an expert in cryptography and won’t be able to do justice to the AES.</em></p>



<p><strong>Note:</strong>&nbsp;Please remember that&nbsp;<strong>encryption is not encoding, and decryption is not decoding in the video space</strong>. For videos, encoding and decoding are words used to refer to compression and decompression, respectively. To learn more about encoding, decoding, and video codecs, please read our articles on&nbsp;<a href="https://ottverse.com/need-for-video-compression/">the need for compression</a>&nbsp;and a&nbsp;<a href="https://ottverse.com/what-is-a-video-codec/">simple introduction to video codecs</a>.</p>



<h3 id="is-aes-128-the-only-encryption-technique"><span id="Is_AES128_The_Only_Encryption_Technique"></span>Is AES-128 The Only Encryption Technique?<span></span></h3>



<p>No, it isn’t, and let’s think about the implication of this for a minute.</p>



<p>If a content provider decides to engage with three different DRM companies, and all three use different encryption techniques, then it means that the content provider needs to encrypt their videos three times, resulting in a waste of storage space and other resources.</p>



<p>That is why the CENC specification came into being – to reduce this encryption-driven fragmentation of the market and to reduce storage requirements.</p>



<p>Let’s learn about this next.</p>



<h3 id="cenc-or-common-encryption"><span id="CENC_or_Common_Encryption"></span>CENC or Common Encryption<span></span></h3>



<p><strong>Actually, before we dive into CENC, let’s step back and take a look at the state of OTT streaming protocols and CMAF in particular.</strong></p>



<p>There are primarily two protocols in use today – MPEG-DASH and HLS.&nbsp;<em>There are others such as MSS (Microsoft Smooth Streaming) and HDS, but, we’ll leave them aside for this discussion.</em></p>



<p>MPEG-DASH uses the&nbsp;<code>mp4</code>&nbsp;container format for its videos and HLS uses the MPEG-TS (<code>ts</code>) container for its files. If a content provider uses both MPEG-DASH and HLS, then they need to store a copy of their videos in both&nbsp;<code>mp4</code>&nbsp;and&nbsp;<code>ts</code>&nbsp;file formats.</p>



<p>Now, let’s add the DRM encryption problem to it. If our three hypothetical DRM providers use three different encryption standards, then a content providers needs to store&nbsp;<code>2 * 3</code>&nbsp;… six copies of each video! What a waste of storage space!!</p>



<p><strong>To combat the first problem posed by video streaming protocols, the&nbsp;<a href="https://mpeg.chiariglione.org/standards/mpeg-a/common-media-application-format" target="_blank" rel="noopener">CMAF</a>&nbsp;specification was created</strong> which said that videos can be stored in the&nbsp;<strong>fragmented mp4</strong>&nbsp;container format (<code>fmp4</code>). With support from both MPEG-DASH and HLS, you can now create only one set of videos, store it in&nbsp;<code>fmp4</code>&nbsp;format, and use a common set of files for both protocols. </p>



<p><strong>Just make sure you create two manifests (sigh!).</strong></p>



<h3><span id="How_About_Unifying_the_Encryption"></span><strong>How About Unifying the Encryption?</strong><span></span></h3>



<p>We still need to store multiple copies of each file if different DRM technologies use different encryption standards, right?</p>



<p>For this purpose, the MPEG developed the&nbsp;<a href="https://www.iso.org/standard/68042.html" target="_blank" rel="noopener">CENC or Common Encryption specification</a>, specifying that videos can be encrypted using either&nbsp;<code>cenc</code>&nbsp;(AES-128 CTR) or&nbsp;<code>cbcs</code>&nbsp;(AES-128 CBC).&nbsp;<em>CTR stands for Counter; and CBC stands for Cipher Block Chaining.</em></p>



<p>The implication of CENC is that a content provider needs to encrypt his videos only once and any decryption module can decrypt it.&nbsp;<em>Note: Exposing the encryption algorithm is not a problem as long as the keys are strongly protected.</em></p>



<p><strong>Well, CENC might sound like a magic wand for DRM-unification, but it is not.</strong></p>



<p>There are three primary DRM technologies in the market – Apple FairPlay, Google Widevine, and Microsoft PlayReady.</p>



<ul><li>Apple FairPlay supports only AES-CBC&nbsp;<code>cbcs</code>&nbsp;mode.</li><li>HLS supports only AES-CBC&nbsp;<code>cbcs</code>&nbsp;mode (irrespective of CMAF)</li><li>Widevine and PlayReady support both AES-128 CTR&nbsp;<code>cenc</code>&nbsp;or AES-128 CBC&nbsp;<code>cbcs</code>&nbsp;modes.</li><li>MPEG-DASH with CMAF supports both AES-128 CTR&nbsp;<code>cenc</code>&nbsp;or AES-128 CBC&nbsp;<code>cbcs</code>&nbsp;modes.</li><li>MPEG-DASH without CMAF supports only AES-128 CTR&nbsp;<code>cenc</code>&nbsp;mode.</li></ul>



<p>As you can see, the CMAF and CENC specs have lead to confusion and fragmentation in the streaming space. </p>



<p><strong>A possible convergence point is the universal use of CMAF and AES-CBC&nbsp;cbcs&nbsp;mode, but, how will these impact legacy devices that support only CTR or only MPEG-TS?</strong></p>



<p>That’s a discussion for another time.</p>



<h2 id="step-2-key-keyid-and-the-license-server"><span id="Step_2_Key,_KeyID,_and_the_License_Server"></span>Step 2: Key, KeyID, and the License Server<span></span></h2>



<p>By now, we have established that we will be encrypting or videos using AES-128 bit encryption. At this stage, a few questions that come up are –</p>



<ol><li>Where do we get the AES-128 Encryption Keys?</li><li>How do we associate an Encryption Key with a movie?</li><li>Where do we store the Encryption Keys?</li></ol>



<p>Let’s answer them one at a time.</p>



<h3 id="where-do-we-get-the-aes-128-bit-encryption-keys"><span id="Where_do_we_get_the_AES128_bit_encryption_keys"></span>Where do we get the AES-128 bit encryption keys?<span></span></h3>



<p>Any content provider can generate the encryption keys manually using specialized software. Alternatively, several DRM vendors provide the necessary tools and software to generate these keys.</p>



<h3 id="how-do-we-associate-an-encryption-key-with-a-movie"><span id="How_do_we_associate_an_encryption_key_with_a_movie"></span>How do we associate an encryption key with a movie?<span></span></h3>



<p>Let’s understand the “why” first. When you go to a hotel, you ask the receptionist for the keys to a particular room by mentioning the room number – right? You’re providing the association here between a key and a room by telling her the room number.</p>



<p>Similarly, when we encrypt a movie with a particular key, we need to create that association and provide that to the DRM license server&nbsp;<em>(our receptionist, if you will)</em>.</p>



<p>In DRM, a “<strong>KeyID</strong>” provides the association between an encryption key and a movie. It is a&nbsp;<strong>unique</strong>&nbsp;string of characters generated at the time of creating an encryption key for a particular movie.</p>



<p><em>And finally,</em></p>



<h3 id="where-do-we-store-the-encryption-key--its-keyid"><span id="Where_do_we_store_the_Encryption_Key_its_KeyID"></span>Where do we store the Encryption Key &amp; its KeyID?<span></span></h3>



<p><strong>The Encryption Key and the KeyID are stored in a secure server (Key Store) that works alongside a DRM license server</strong>.</p>



<p>When a client needs to play an encrypted movie, it requests the DRM license server for the decryption key by providing that …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ottverse.com/eme-cenc-cdm-aes-keys-drm-digital-rights-management/">https://ottverse.com/eme-cenc-cdm-aes-keys-drm-digital-rights-management/</a></em></p>]]>
            </description>
            <link>https://ottverse.com/eme-cenc-cdm-aes-keys-drm-digital-rights-management/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24975487</guid>
            <pubDate>Tue, 03 Nov 2020 01:38:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Leaving OCaml]]>
            </title>
            <description>
<![CDATA[
Score 236 | Comments 180 (<a href="https://news.ycombinator.com/item?id=24974907">thread link</a>) | @rbanffy
<br/>
November 2, 2020 | https://blog.darklang.com/leaving-ocaml/ | <a href="https://web.archive.org/web/*/https://blog.darklang.com/leaving-ocaml/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.darklang.com/content/images/size/w300/2020/11/skeleton-camel.jpg 300w,
                            https://blog.darklang.com/content/images/size/w600/2020/11/skeleton-camel.jpg 600w,
                            https://blog.darklang.com/content/images/size/w1000/2020/11/skeleton-camel.jpg 1000w,
                            https://blog.darklang.com/content/images/size/w2000/2020/11/skeleton-camel.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.darklang.com/content/images/size/w2000/2020/11/skeleton-camel.jpg" alt="Leaving OCaml">
            </figure>

            <section>
                <div>
                    <p><em>Part of a 3 part series. Followups on <a href="https://blog.darklang.com/new-backend-fsharp/">F#</a>, <a href="https://blog.darklang.com/why-dark-didnt-choose-rust/">Rust</a></em></p><p>I built the first demo of Dark in Python, in about two weeks. A few months later when I started productizing it, I rebuilt it in OCaml. Back in 2017, when I was considering the language and platform to use for Dark, OCaml was extremely compelling:</p><ul><li>it's a high-level language with static types, so easy to make large scale changes as we figure out what the language/product was</li><li>you mostly model data with sum types, which in my mind are the best way to model data</li><li>it's very similar to the language I wanted to build (in particular, we could reuse built-in immutable data structures for Dark's values)</li><li>it had a reputation for being high-performance, which meant that we could write an interpreter for Dark and not have it be terribly slow (vs writing an interpreter in python, which might be too slow)</li></ul><p>Unfortunately, as we've built Dark we've run into significant problems that have made it challenging to build in OCaml.</p><h2 id="lack-of-libraries">Lack of libraries</h2><p>When you bet on an off-mainstream language, one of the things you accept is that many libraries are not going to be available. When there is a small community, often there aren't enough people working in the language to make important libraries. This is especially true if few people are building business applications.</p><p>In OCaml there are many high quality libraries, especially for data structures and data manipulation. The annual<a href="https://opensource.janestreet.com/core/"> Jane Street code dump</a> has been quite useful and very high quality. However, we really felt the lack of several libraries. The most obvious of these is that we had to build a <a href="https://github.com/darklang/dark/blob/main/backend/libexecution/unicode_string.mli">Unicode string library</a> ourselves (built on top of the <a href="https://erratique.ch/software/uuseg">very impressive OCaml Unicode libraries</a> built by <a href="https://erratique.ch/contact.en">Daniel Bünzli</a>), but we needed many more libraries than that.</p><p>The lack of an SDK for Google Cloud has affected us greatly. When you're searching for product-market fit, you do the simplest, easiest thing. If you lack a good SDK for your cloud provider, the simplest, easiest thing is often a terrible architectural choice. We've built our own queue on top of our database rather than using the production-quality cloud queues available on GCP. Similarly, we barely use the Cloud Storage (GCP's version of S3), because we initially put things in the database <a href="https://blog.darklang.com/evolving-darks-tracing-system/">because it was easier</a>. We've built 3 services, 2 <a href="https://github.com/darklang/dark/tree/main/containers/stroller">in</a> <a href="https://github.com/darklang/dark/tree/main/containers/queue-scheduler">Rust</a>, and 1 in <a href="https://github.com/darklang/dark/tree/main/containers/postgres-honeytail">Go</a>, to workaround the challenges we've faced.</p><p>The biggest challenge here is our use of Postgres. Postgres is a great database and we're big fans, but Cloud SQL is not a great hosted database. GCP's position is that Cloud SQL is there to tick a box and we should be using Cloud Spanner. I would love to switch to Cloud Spanner, but we have no driver for it in OCaml. Given the Postgres driver in OCaml is not particularly mature, it's hard to expect that a Cloud Spanner driver would exist, and indeed it doesn't. We've had to contribute to the <a href="https://github.com/mmottl/postgresql-ocaml/commit/81a4ae5240decd8f483a90568257cfbc1558c7ed">OCaml Postgres driver</a>, and some parts of our codebase have been <a href="https://github.com/darklang/dark/blob/main/backend/libbackend/serialize.ml#L226">well and truly mangled</a> when working around features not supported in that driver.</p><p>We've also suffered from a lack of a high-level, production web stack (there are <a href="https://github.com/anmonteiro/ocaml-h2">low-level stacks with good reputations</a> that I've struggled to use, and a <a href="https://github.com/oxidizing/sihl">few</a> <a href="https://github.com/reason-native-web/morph">new</a> ones out there that look good), in particular lacking a user authentication module. We've been using <a href="https://auth0.com/">Auth0</a> to work around this for now, which has more moving pieces than I'd like, and a shockingly high cost (our 7000 users, most of whom never log in, costs us over $500/mo).</p><p>We've worked around other missing vendor SDKs by calling their HTTP endpoints directly and that's been mostly fine. However, for libraries like encryption we don't have that option - we <a href="https://github.com/darklang/dark/pull/1455/files">hacked around a missing encryption library</a>, but decided not to ship it to production until we audited it for security (which was never actually worth the cost).</p><p>At CircleCI, we bet on Clojure. That was also a non-mainstream language, but its ability to call Java SDKs meant we had a mature cloud library, which was essential for building CircleCI. Of course, in OCaml we could call C libraries (and <a href="https://github.com/darklang/dark/pull/1841">even Rust libraries</a>, perhaps), but it doesn't match having native libraries we can call directly.</p><h2 id="learnability">Learnability</h2><p>I'm mostly in the camp that anyone can learn any language, but I saw a team struggle with OCaml, and for good reason. Language tutorials are extremely poor in OCaml compared to other languages; they're mostly lecture notes from academic courses.</p><p>The compiler isn't particularly helpful, certainly compared to Rust or Elm (both of which have been in our stack at one point). Often it gives no information about an error. Syntax errors typically say "Syntax error"; though it will try to give a good error for a mismatched brace, often incorrectly. Type errors can be a real burden to read, even after 3 years of experience with it.</p><p>The docs in OCaml are often challenging to find. The <a href="https://ocaml.janestreet.com/ocaml-core/latest/doc/base/index.html">Jane Street docs</a> have improved significantly in the last few years, but it can be a challenge to even figure out what functions are available in a particular module for most libraries. Compare to the excellent <a href="https://docs.rs/">docs.rs</a> in Rust, which has comprehensive API docs for every package in Rust.</p><p>One of the ways I personally struggled in OCaml is around <code>Lwt</code>. Lwt is (one of!) OCaml's async implementations. I couldn't figure it out several years ago and so just built a single-threaded server. The amount of workarounds and downtime we've suffered from that single decision is immense. A tutorial around building high-performance (or even medium performance!) web servers would be very valuable. </p><p>Tooling is something I read would be good in OCaml. I remember reading there was a debugger that could go back in time! I don't know where that's gone but I've never heard of anyone using it.</p><p>We have struggled to make editor tooling work for us. This is partially because we also use ReasonML and this seems to break things. Unfortunately, this is common in programming, but even more so in small communities: you might be the first person to ever try to use a particular configuration.</p><p>Finally, the disconnect between the various tools is immense. You need to understand Opam, Dune, and Esy, to be able to get something working (you could also do it without Esy and just rely on Opam, but that's much worse). I talked about a bunch of these challenges <a href="https://blog.darklang.com/first-thoughts-on-rust-vs-ocaml/">here</a>.</p><h2 id="language-problems">Language problems</h2><p>Multicore is coming Any Day Now™️, and while this wasn't a huge deal for us, it was annoying. </p><h2 id="minor-annoyances">Minor annoyances</h2><p>One of my biggest annoyances was how often OCaml folks talk about Fancy Type System problems, instead of how to actually build products and applications. In other communities for similar languages (ReasonML, Elm, F#), people talk about building apps and solving their problems. In OCaml, it feels like people spend an awful lot of time discussing Functors. It's not quite at the level that I perceived in the Haskell world, but it pointed out that the people building the core of the ecosystem do not have the same problems that I do (which is building web-y stuff).</p><p>I honestly think OCaml was a great choice at the start. Being able to quickly and safely make large-scale changes to your app is something that staticly-typed functional languages excel at. I'm happy that we made the choice, and in retrospect, it still seems like the best choice of those we had at the time.</p><p>I'm working on building the next version of the backend. We have about 20k lines to be replaced, and they'll be rewritten in a new language while keeping the semantics the same. I plan to leave keep the frontend in ReasonML: it doesn't suffer from the same library problems as it can interface nicely to JS, and it's nearly 50k lines of code so it would be a much bigger undertaking.</p><p>Read <a href="https://blog.darklang.com/new-backend-fsharp/">the followup</a> to see what we picked!</p><hr><p><em><em><em><em><em><em><em><em>You can sign up for Dark </em></em></em></em></em></em></em></em><a href="https://darklang.com/signup" rel="noopener nofollow"><em><em><em><em><em><em><em><em>here</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em>. For more info on Dark, follow our </em></em></em></em></em></em></em></em><a href="https://blog.darklang.com/rss" rel="noopener nofollow"><em><em><em><em><em><em><em><em>RSS</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em>, follow </em></em></em></em></em></em></em></em><a href="https://twitter.com/darklang" rel="noopener nofollow"><em><em><em><em><em><em><em><em>us</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em> (or </em></em></em></em></em></em></em></em><a href="https://twitter.com/paulbiggar" rel="noopener nofollow"><em><em><em><em><em><em><em><em>me</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em>) on Twitter, join our </em></em></em></em></em></em></em></em><a href="https://darklang.com/slack-invite" rel="noopener nofollow"><em><em><em><em><em><em><em><em>Slack Community</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em>, watch our </em></em></em></em></em></em></em></em><a href="https://github.com/darklang/dark" rel="noopener nofollow"><em><em><em><em><em><em><em><em>GitHub repo</em></em></em></em></em></em></em></em></a><em>, or join our <a href="http://darklang.com/mailing-list">mailing list</a><em><em><em><em><em><em><em>.</em></em></em></em></em></em></em></em></p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.darklang.com/leaving-ocaml/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24974907</guid>
            <pubDate>Tue, 03 Nov 2020 00:03:20 GMT</pubDate>
        </item>
    </channel>
</rss>
