<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sat, 05 Sep 2020 08:43:53 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sat, 05 Sep 2020 08:43:53 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[How to Be Indistractable]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 19 (<a href="https://news.ycombinator.com/item?id=24360966">thread link</a>) | @nireyal
<br/>
September 2, 2020 | https://psyche.co/guides/to-become-indistractable-recognise-that-it-starts-within-you | <a href="https://web.archive.org/web/*/https://psyche.co/guides/to-become-indistractable-recognise-that-it-starts-within-you">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><h2 data-guide-section-number="1"><span>Need to know</span></h2><div><p>√¢‚Ç¨ÀúJust a second. I just need to respond to this one thing,√¢‚Ç¨‚Ñ¢ I said to my daughter, as I attended to my iPhone.</p>
<p>Only much later could I count the mistakes in that statement. No, it wouldn√¢‚Ç¨‚Ñ¢t take √¢‚Ç¨Àújust a second√¢‚Ç¨‚Ñ¢; no, I didn√¢‚Ç¨‚Ñ¢t √¢‚Ç¨Àúneed√¢‚Ç¨‚Ñ¢ to respond to the email √¢‚Ç¨‚Äú I√¢‚Ç¨‚Ñ¢m an author and researcher, and thus rarely receive messages that have a drop-everything-and-answer urgency to them. And no, it wouldn√¢‚Ç¨‚Ñ¢t be √¢‚Ç¨Àúone thing√¢‚Ç¨‚Ñ¢. My brain would be too tempted, I√¢‚Ç¨‚Ñ¢d feast on it all.</p>
<p>After I finished, I looked up and my daughter was gone. The worst part: before I became distracted, we had been playing a lovely game, telling each other what superpower we most wished for. It could have brought us closer together, but I√¢‚Ç¨‚Ñ¢d just blown the spirit and substance of it big-time.</p>
<p>If you√¢‚Ç¨‚Ñ¢re a parent in the 21st century, I bet you√¢‚Ç¨‚Ñ¢ve experienced your own version of this. But it√¢‚Ç¨‚Ñ¢s not just parents, it√¢‚Ç¨‚Ñ¢s all of us in our interactions with each other. Distraction has become the norm. We√¢‚Ç¨‚Ñ¢re blessed with pocket-sized supercomputers that connect us to anyone and everyone, and a buffet of information. But there√¢‚Ç¨‚Ñ¢s a dark side: those same gadgets distract us, often at the moments that matter most.</p>
<p>Of course, smartphones didn√¢‚Ç¨‚Ñ¢t invent distraction √¢‚Ç¨‚Äú they√¢‚Ç¨‚Ñ¢re just the latest culprit. Before that, we blamed television. And before that, it was the telephone, or comic books, or the radio. Go back more than 2,000 years, and Socrates was even criticising the written word, for causing √¢‚Ç¨Àúforgetfulness in the learners√¢‚Ç¨‚Ñ¢ souls√¢‚Ç¨‚Ñ¢.</p>
<p>Still, our present feels different, with the sources of distraction seeming greater in number and more ubiquitous. One <a href="https://journals.sagepub.com/doi/full/10.1177/0013916514539755">study</a> in 2014 showed that when two people are talking, the mere presence of a smartphone resting on a table is enough to change the character of their conversation. That√¢‚Ç¨‚Ñ¢s a tame example. To see the seriousness of the problem, look at the sobering <a href="https://www.nhtsa.gov/risky-driving/distracted-driving">statistics</a> on √¢‚Ç¨Àúdistracted driving√¢‚Ç¨‚Ñ¢ in the United States.</p>
<p>After I abandoned my daughter and our game for an utterly inconsequential email, I realised I needed to deal with my distraction problem. First, I tried a popular approach: I blamed technology and made a serious attempt at a √¢‚Ç¨Àúdigital detox√¢‚Ç¨‚Ñ¢. I bought a flip phone, subscribed to a print newspaper, and even purchased a 1990s-era word processor without an internet connection. I convinced myself that, once I banished all the technology from my life, I√¢‚Ç¨‚Ñ¢d become the disciplined writer and focused father I√¢‚Ç¨‚Ñ¢d always strived to be.</p>
<p>Talk about a rude awakening. Sitting at my ancient word processor, my eyes began to peer over to my now-tantalising bookshelf. √¢‚Ç¨ÀúHmmm,√¢‚Ç¨‚Ñ¢ I said to myself, √¢‚Ç¨ÀúI really should take a glance at this book√¢‚Ç¨‚Ñ¢. I√¢‚Ç¨‚Ñ¢d justify the distraction as necessary for √¢‚Ç¨Àúresearch√¢‚Ç¨‚Ñ¢. And if it wasn√¢‚Ç¨‚Ñ¢t reading, then I√¢‚Ç¨‚Ñ¢d find something else √¢‚Ç¨‚Äú the laundry that <em>needed</em> to be folded right now, my desk that <em>needed</em> to be tidied-up this minute. The technology wasn√¢‚Ç¨‚Ñ¢t distracting me. <em>I</em> was distracting me.</p>
<p>That√¢‚Ç¨‚Ñ¢s when I started a five-year journey to understand <a href="https://www.nirandfar.com/distractions/">distraction</a>, its causes and its cures. I discovered a great deal that I found surprising and counterintuitive, and I developed methods to deal with my distraction that actually worked √¢‚Ç¨‚Äú and didn√¢‚Ç¨‚Ñ¢t involve me trying to turn back time and operate a flip phone. I realised that distraction often begins from within, not without, and found that the fix came from identifying and managing the psychological discomfort that leads us off track.</p>
<p>As often as not, distraction is your brain ducking challenging feelings such as boredom, loneliness, insecurity, fatigue and uncertainty. These are the internal triggers √¢‚Ç¨‚Äú the <a href="https://www.nirandfar.com/kids-video-game-obsession/">root causes</a> √¢‚Ç¨‚Äú that prompt you to find the comfort of distraction and open a browser tab, Twitter or email, instead of focusing on the matter at hand. Once you identify these internal triggers, you can decide to respond in a more advantageous manner. You won√¢‚Ç¨‚Ñ¢t always be able to control how you feel √¢‚Ç¨‚Äú but you can learn to control how you react to the way you feel. A trigger that once sent you to Twitter can perhaps lead instead to 10 deep breaths.</p>
<p>Distraction, in other words, is a symptom of a problem √¢‚Ç¨‚Äú not the problem itself. Those deeper and systemic reasons √¢‚Ç¨‚Äú such as an inability to cope with fear, anxiety or stress √¢‚Ç¨‚Äú deserve our concern, because it√¢‚Ç¨‚Ñ¢s only when we start to address them that we can make real progress. When we begin to understand what we√¢‚Ç¨‚Ñ¢re trying to avoid by clicking over to Twitter or checking the news for the 10th time today, we can begin to address the issue itself, and not medicate it through more distraction. We also begin to appreciate how habitual the act of avoiding discomfort via distraction can be, and how much it√¢‚Ç¨‚Ñ¢s become a part of how we work and live.</p>
<p>The good news is that there√¢‚Ç¨‚Ñ¢s something paradoxical about discomfort: it√¢‚Ç¨‚Ñ¢s actually the best tool we have for evolving and developing as a species. Feeling bad isn√¢‚Ç¨‚Ñ¢t actually bad; it√¢‚Ç¨‚Ñ¢s what helped us survive. Writing in 2001, the American psychologist Roy Baumeister and his colleagues <a href="https://psycnet.apa.org/record/2018-70020-001">observed</a>: √¢‚Ç¨ÀúIf satisfaction and pleasure were permanent, there might be little incentive to continue seeking further benefits or advances.√¢‚Ç¨‚Ñ¢ If we didn√¢‚Ç¨‚Ñ¢t feel bad, in other words, we√¢‚Ç¨‚Ñ¢d never achieve good.</p>
<p>Once you understand the depth of distraction, you can start to manage it and improve. After years of experiments, I found myself less distracted √¢‚Ç¨‚Äú a quality that improved nearly every aspect of my life. It turns out that being able to focus on the subjects and people in my life who matter improved everything from my health to my happiness to my productivity. That can seem obvious, but I couldn√¢‚Ç¨‚Ñ¢t have fully appreciated the joys of living an indistractable life if I hadn√¢‚Ç¨‚Ñ¢t gotten there on my own after a five-year journey. Being indistractable can lead you to not just change your life for the better, but also experience life fully.</p></div></div></section><section><div><h2 data-guide-section-number="2"><span>What to do</span></h2><div><p><strong>Self-explore</strong></p>
<p>Identifying the triggers that made you feel bad in the first place requires self-exploration. When you notice yourself feeling distracted, pause and ask yourself what you√¢‚Ç¨‚Ñ¢re feeling. Are you worried? Are you afraid? Then go one step deeper. What caused the sensation? How does it feel in your body?</p>
<p>In exploring my own internal triggers, I began to appreciate that my anxiety about a project, which might lead me to find a tempting Wikipedia rabbit hole, was actually adaptive: the fact that I was anxious was good because it meant I was trying to become better. It was sometimes even as easy as saying to myself: √¢‚Ç¨ÀúYou√¢‚Ç¨‚Ñ¢re getting distracted right now because you√¢‚Ç¨‚Ñ¢re worried this won√¢‚Ç¨‚Ñ¢t be up to snuff. That√¢‚Ç¨‚Ñ¢s okay. It means you√¢‚Ç¨‚Ñ¢re trying to do your best work, and that√¢‚Ç¨‚Ñ¢s something to feel good about.√¢‚Ç¨‚Ñ¢ It seems like a simple mental trick, but even that thought can have a profound influence in keeping you on track.</p>
<p>There√¢‚Ç¨‚Ñ¢s an interesting paradox about internal triggers: they can be big, imposing, powerful issues, and yet the fixes can sometimes be easy and quick. Here√¢‚Ç¨‚Ñ¢s an example: let√¢‚Ç¨‚Ñ¢s say that an internal trigger when you√¢‚Ç¨‚Ñ¢re about to get started on a looming project is boredom. You just can√¢‚Ç¨‚Ñ¢t bring yourself to get excited about doing your taxes. And because you get bored, you get distracted. But if you know you√¢‚Ç¨‚Ñ¢re going to get bored, you can find ways to avoid the distraction that will soothe the boredom. For instance, if you set a time limit to work on the otherwise mind-numbing task that is so short, you won√¢‚Ç¨‚Ñ¢t have a chance to get bored. Anyone can work on their taxes for just 10 minutes. This is called the <a href="https://www.nirandfar.com/strange-sex-habits-of-silicon-valley/">10-minute rule</a>, and it√¢‚Ç¨‚Ñ¢s an effective way to avoid distractions of all sorts. The point is to anticipate the internal trigger and then intercept it with a new routine rather than allowing yourself to slink away into doing something you didn√¢‚Ç¨‚Ñ¢t intend to do.</p>
<p>In the case of my interaction with my daughter, the internal trigger might have been anxiety about work or <a href="https://www.nirandfar.com/fomo/">fear of missing out</a> (on an email). But I can address both of those proactively, so that they don√¢‚Ç¨‚Ñ¢t interfere with precious daddy-daughter time. In the case of my work anxiety, I could make sure that someone on my team is monitoring incoming messages. I could put up an √¢‚Ç¨Àúout of office√¢‚Ç¨‚Ñ¢ email that encourages people to call me if there√¢‚Ç¨‚Ñ¢s really an emergency. Or in reality, I could get comfortable with the discomfort that I might indeed be missing out on something, but that√¢‚Ç¨‚Ñ¢s all right too. Any one of those is a better and more constructive response to the internal trigger than being distracted.</p>
<p>Whatever approach you take to address your inner triggers, it√¢‚Ç¨‚Ñ¢s encouraging to note that merely recognising uncomfortable feelings and identifying them could be beneficial. For instance, in a smoking-cessation <a href="https://www.sciencedirect.com/science/article/abs/pii/S0376871611002535?via%3Dihub">study</a>, researchers found that participants who learned to acknowledge and explore their cravings managed to quit smoking at double the rates of those in the American Lung Association√¢‚Ç¨‚Ñ¢s best-performing cessation programme. Just identifying and investigating a craving had a tremendous impact.</p>
<p><strong>Reframe</strong></p>
<p>Once you√¢‚Ç¨‚Ñ¢ve identified the triggers, you can reframe the task at hand. Sure, you might be √¢‚Ç¨Àúforced to do your taxes√¢‚Ç¨‚Ñ¢. But another way of thinking about that is that you √¢‚Ç¨Àúget to review last year√¢‚Ç¨‚Ñ¢s business successes√¢‚Ç¨‚Ñ¢. It sounds laughable, but it works. When I hit rough patches mid-book writing, I would say: √¢‚Ç¨ÀúI get to share this with my audience,√¢‚Ç¨‚Ñ¢ as opposed to: √¢‚Ç¨ÀúI really have to work on the book today.√¢‚Ç¨‚Ñ¢</p>
<p>Here√¢‚Ç¨‚Ñ¢s one strategy: I found the fun in whatever I was doing. Yes, I know, this is where you roll your eyes, but hear me out. I learned to stay focused on the tedious work of writing books by looking for and finding the mystery embedded in my work. I wasn√¢‚Ç¨‚Ñ¢t √¢‚Ç¨Àúwriting√¢‚Ç¨‚Ñ¢, I was √¢‚Ç¨Àúexploring√¢‚Ç¨‚Ñ¢. I wasn√¢‚Ç¨‚Ñ¢t Ernest Hemingway; I was Scooby-Doo. Research indicates that even the simple act of thinking of something that you don√¢‚Ç¨‚Ñ¢t enjoy as ‚Ä¶</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://psyche.co/guides/to-become-indistractable-recognise-that-it-starts-within-you">https://psyche.co/guides/to-become-indistractable-recognise-that-it-starts-within-you</a></em></p>]]>
            </description>
            <link>https://psyche.co/guides/to-become-indistractable-recognise-that-it-starts-within-you</link>
            <guid isPermaLink="false">hacker-news-small-sites-24360966</guid>
            <pubDate>Thu, 03 Sep 2020 05:12:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Even in Go, concurrency is still not easy]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 76 (<a href="https://news.ycombinator.com/item?id=24359650">thread link</a>) | @benhoyt
<br/>
September 2, 2020 | https://utcc.utoronto.ca/~cks/space/blog/programming/GoConcurrencyStillNotEasy | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/programming/GoConcurrencyStillNotEasy">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Even in Go, concurrency is still not easy (with an example)</h2>

	<p><small>September  1, 2020</small></p>
</div><div><p>Go is famous for making concurrency easy, through good language
support for <a href="https://golangbot.com/goroutines/">goroutines</a>. Except
what Go makes easy is only one level of concurrency, the nuts and
bolts level of making your code do things concurrently and communicating
back and forth through channels. Making it do the right things
concurrently is still up to you, and unfortunately Go doesn't
currently provide a lot of standard library support for correctly
implemented standard concurrency patterns.</p>

<p>For example, one common need is for a limited amount of concurrency;
you want to do several things at once, but only so many of them.
At the moment this is up to you to implement on top of goroutines,
channels, and things like the <a href="https://golang.org/pkg/sync/"><code>sync</code></a>
package. This is not as easy as it looks, and quite competent people
can make mistakes here. As it happens, I have an example ready to
hand today.</p>

<p><a href="https://github.com/google/gops">Gops</a> is a convenient command to
list (and diagnose) Go processes that are currently running on your
system. Among other things, it'll tell you which version of Go they
were compiled with, which is handy if you want to see if you have out
of date binaries that should be rebuilt and redeployed. One of the
things <code>gops</code> needs to do is look at all of the Go processes on your
system, which it does concurrently. However, it doesn't want to look
at too many processes at once, because <a href="https://github.com/google/gops/pull/118">that can cause problems with
file descriptor limits</a>. This
is a classic case of <em>limited concurrency</em>.</p>

<p>Gops implements this at the moment with code in <a href="https://github.com/google/gops/blob/6fb0d860e5fa50629405d9e77e255cd32795967e/goprocess/gp.go#L29">goprocess.FindAll()</a>
that looks like this, in somewhat sketched and reduced form:</p>

<blockquote><pre>func FindAll() []P {
   pss, err := ps.Processes()
   [...]
   found := make(chan P)
   limitCh := make(chan struct{}, concurrencyProcesses)

   for _, pr := range pss {
      limitCh &lt;- struct{}{}
      pr := pr
      go func() {
         defer func() { &lt;-limitCh }()
         [... get a P with some error checking ...]
         found &lt;- P
      }()
   }
   [...]

   var results []P
   for p := range found {
      results = append(results, p)
   }
   return results
}
</pre>
</blockquote>

<p>(In the real code there's a WaitGroup for coordination, and the
<code>found</code> channel gets closed appropriately.)</p>

<p>How this works is clear, and is a standard pattern (covered in eg
Go 101's <a href="https://go101.org/article/channel-use-cases.html">Channel Use Cases</a>). We use a
buffered channel to provide a limited number of tokens; sending a
value into the channel implicitly takes a token (and blocks if the
token supply is exhausted), while receiving a value from it puts a
token back in. We take a token before we start a new goroutine, and
the goroutine releases the token when it's done.</p>

<p>Except that <a href="https://github.com/google/gops/issues/123">this code has a bug if there are too many processes
to examine</a>. Even knowing
that there is a bug in this code, it may not be obvious.</p>

<p>The bug is that the goroutines only receive from <code>limitCh</code> to release
their token after sending their result to the unbuffered <code>found</code>
channel, while the main code only starts receiving from <code>found</code>
after running through the entire loop, and <strong>the main code takes
the token in the loop and blocks if no tokens are available</strong>. So
if you have too many processes to go through, you start N goroutines,
they all block trying to write to <code>found</code> and don't receive from
<code>limitCh</code>, and the main <code>for</code> loop blocks trying to send to <code>limitCh</code>
and never reaches the point where it starts receiving from <code>found</code>.</p>

<p>At one level, this bug is a very fragile bug; it only exists because
of multiple circumstances. If the goroutines took the token by
sending to <code>limitCh</code> instead of the main <code>for</code> loop doing it, the
bug would not exist; the main <code>for</code> loop would start them all, many
would stop, and then it would go on to receive from <code>found</code> so that
they could receive from <code>limitCh</code> and release their token so other
goroutines would run. If the goroutines received from <code>limitCh</code> to
release their token before sending to <code>found</code>, it wouldn't exist
(but because of error handling, it's simpler and more reliable to
do the receive in a <code>defer</code>). And if the entire <code>for</code> loop was in
an additional goroutine, the main code would go on to receive from
<code>found</code> and unblock completed goroutines to release their tokens,
so the fact that the <code>for</code> loop was blocked waiting to send to
<code>limitCh</code> wouldn't matter.</p>

<p>At another level, this shows how concurrency is not easy as easy
as it looks in Go. All you need is one mistake and things skid to
a halt, and all of the code involved can look good to a casual
examination. Getting concurrency correct is simply hard for people
(we can debate about why, but I think that it is is very clear).</p>

<p>(I'm sure that the people who wrote and approved the change that
added this concurrency limiting code to gops were good programmers.
A tricky case still tripped them up, passing all of their scrutiny.
Even when I knew that there was a concurrency problem in the code
and where it was (because my <code>gops</code> was hanging all of a sudden,
and <a href="https://github.com/go-delve/delve">Delve</a> told me where
everything was stuck), it still took me some time to see what the
exact problem was.)</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/programming/GoConcurrencyStillNotEasy</link>
            <guid isPermaLink="false">hacker-news-small-sites-24359650</guid>
            <pubDate>Thu, 03 Sep 2020 00:15:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I built a keyboard/video/mouse switch for my two 4k monitors]]>
            </title>
            <description>
<![CDATA[
Score 398 | Comments 188 (<a href="https://news.ycombinator.com/item?id=24357308">thread link</a>) | @car
<br/>
September 2, 2020 | https://haim.dev/posts/2020-07-28-dual-monitor-kvm/ | <a href="https://web.archive.org/web/*/https://haim.dev/posts/2020-07-28-dual-monitor-kvm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I like my two big hi-res monitors. I love my keyboard and my mouse. And I connect them to my stationary
‚Äúmain‚Äù PC and to several other Windows and Mac laptops, alternatively. I‚Äôd like to easily switch where these peripheral
devices are connected to, and that‚Äôs the traditional role of a <a href="https://en.wikipedia.org/wiki/KVM_switch">KVM switch</a>.</p><p>Unfortunately for me, KVM switches that support 4K/60hz resolutions cost hundreds of dollars, there are
no KVM switches that support USB-C, and I couldn‚Äôt find KVM switches that support multiple high-res monitors
either.</p><p>So I decided to implement a mixed hardware/software solution: my monitors (all monitors today really) have more
than one input, so I can connect all my computers simultaneously. The idea is:</p><ul><li>Switch USB devices in hardware.</li><li>Detect this switch in software, and switch monitors inputs as needed.</li></ul><p>To switch USB devices, I ordered <a href="https://www.amazon.ca/gp/product/B01N6GD9JO">this USB 3.0 two-computer switch</a> from Amazon,
that‚Äôs $38 Canadian, under $30 USD.</p><p>To automatically switch monitor inputs, I <a href="https://github.com/haimgel/display-switch">wrote some software</a>.</p><p>My plan was:</p><ul><li>Watch for USB device connections/disconnections.</li><li>When a configured device is connected, use <a href="https://en.wikipedia.org/wiki/Display_Data_Channel#DDC/CI">DDC/CI</a> to
send a command to all connected monitors to switch inputs.</li><li>In case the power management turned the video output off, turn it on again (otherwise the monitors will auto-switch
back to the input that actually supplies video output).</li></ul><p>I needed this to happen on Windows and on a Mac, and mature cross-platform support for USB low-level
control and hot plug, DDC/CI and monitor power management is non-existent. I ended up implementing this two
times: <a href="https://github.com/haimgel/display-switch/tree/master/MacOS">once in Swift</a>, for MacOS, and the
<a href="https://github.com/haimgel/display-switch/tree/master/Windows">second time in Rust</a>, for Windows.</p><p>Amazingly enough, this works really well: when I press the button on the USB switch, monitor input is changed
instantaneously, it feels like a ‚Äúreal‚Äù KVM switch! üéâ</p></div></div>]]>
            </description>
            <link>https://haim.dev/posts/2020-07-28-dual-monitor-kvm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24357308</guid>
            <pubDate>Wed, 02 Sep 2020 19:56:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[XLS: Accelerated HW Synthesis]]>
            </title>
            <description>
<![CDATA[
Score 119 | Comments 52 (<a href="https://news.ycombinator.com/item?id=24354083">thread link</a>) | @victor82
<br/>
September 2, 2020 | https://google.github.io/xls/ | <a href="https://web.archive.org/web/*/https://google.github.io/xls/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-md-component="container">
      
        
      
      
        
      
      <main data-md-component="main">
        <div>
          
            
              
            
            
              
            
          
          <div>
            <article>
              
                
                  <a href="https://github.com/google/xls/tree/main/docs_src/README.md" title="Edit this page">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"></path></svg>
                  </a>
                
                
                  
                
                
                <p><img src="https://google.github.io/xls/images/xls_logo_623_250.png" alt="XLS Logo">
</p>


<!-- nav -->

<h2 id="what-is-xls">What is XLS?</h2>
<p>The XLS (Accelerated HW Synthesis) project aims to enable the rapid development
of <em>hardware IP</em> that also runs as efficient <em>host software</em> via "software
style" methodology.</p>
<p>XLS implements a High Level Synthesis (HLS) toolchain which produces
synthesizable designs from flexible, high-level descriptions of functionality.
It is fully Open Source: Apache 2 licensed and developed via GitHub.</p>
<p>XLS is used inside of Google for generating feed-forward pipelines from
"building block" routines / libraries that can be easily retargeted, reused, and
composed in a latency-insensitive manner.</p>
<p><em>Not yet available</em>, but active work in progress is the implementation of XLS
<em>concurrent processes</em>, in Communicating Sequential Processes (CSP) style, that
allow pipelines to communicate with each other and induct over time.</p>
<p>XLS is still experimental, undergoing rapid development, and not an officially
supported Google product. Expect bugs and sharp edges. Please help by trying it
out, <a href="https://github.com/google/xls/issues">reporting bugs</a>, and letting us know
what you think!</p>
<h2 id="building-from-source">Building From Source</h2>
<p>Currently, XLS must be built from source using the Bazel build system.</p>
<p><em>Note:</em> Binary distributions of the XLS library are not currently available, but
we hope to enable them via continuous integration, <a href="https://github.com/google/xls/issues/108">see this issue</a>.</p>
<p>The following instructions are for the Ubuntu 20.04 (Focal) Linux distribution.
Note that we start by assuming <a href="https://docs.bazel.build/versions/master/install-ubuntu.html">Bazel has been
installed</a>.</p>
<pre><code># Follow the bazel install instructions:
# https://docs.bazel.build/versions/master/install-ubuntu.html
#
# Afterwards we observe:

$ bazel --version
bazel 3.2.0

$ sudo apt install python3-dev python3-distutils python3-dev libtinfo5

# py_binary currently assume they can refer to /usr/bin/env python
# even though Ubuntu 20.04 has no `python`, only `python3`.
# See https://github.com/bazelbuild/bazel/issues/8685

$ mkdir -p $HOME/opt/bin/
$ ln -s $(which python3) $HOME/opt/bin/python
$ echo 'export PATH=$HOME/opt/bin:$PATH' &gt;&gt; ~/.bashrc
$ source ~/.bashrc

$ bazel test -c opt ...
</code></pre>

<p>A reference build/test environment setup is also provided via <code>Dockerfile</code>:</p>
<pre><code>~$ git clone https://github.com/google/xls.git
~$ cd xls
~/xls$ docker build .  # Performs optimized build and test.
</code></pre>

<h2 id="stack-diagram-and-project-layout">Stack Diagram and Project Layout</h2>
<p>Navigating a new code base can be daunting; the following description provides a
high-level view of the important directories and their intended organization /
purpose, and correspond to the components in this XLS stack diagram:</p>
<p><img src="https://google.github.io/xls/images/xls_stack_diagram.png" alt="XLS Stack Diagram">
</p>

<ul>
<li><a href="https://github.com/google/xls/tree/main/dependency_support"><code>dependency_support</code></a>:
  Configuration files that load, build, and expose Bazel targets for <em>external</em>
  dependencies of XLS.</li>
<li><a href="https://github.com/google/xls/tree/main/docs"><code>docs</code></a>: Generated documentation
  served via GitHub pages:
  <a href="https://google.github.io/xls/">https://google.github.io/xls/</a></li>
<li><a href="https://github.com/google/xls/tree/main/docs_src"><code>docs_src</code></a>: Markdown file
  sources, rendered to <code>docs</code> via
  <a href="https://google.github.io/xls/contributing/#rendering-documentation">mkdocs</a>.</li>
<li>
<p><a href="https://github.com/google/xls/tree/main/xls"><code>xls</code></a>: Project-named
  subdirectory within the repository, in common Bazel-project style.</p>
<ul>
<li><a href="https://github.com/google/xls/tree/main/xls/build"><code>build</code></a>: Build macros
  that create XLS artifacts; e.g. convert DSL to IR, create test targets for
  DSL code, etc.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/codegen"><code>codegen</code></a>: Verilog
  AST (VAST) support to generate Verilog/SystemVerilog operations and FSMs.
  VAST is built up by components we call <em>generators</em> (e.g.
  PipelineGenerator, SequentialGenerator for FSMs) in the translation from XLS
  IR.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/common"><code>common</code></a>: "base"
  functionality that layers on top of standard library usage. Generally we use
  <a href="https://abseil.io/">Abseil</a> versions of base constructs wherever possible.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/contrib/xlscc"><code>contrib/xlscc</code></a>:
  Experimental C++ syntax support that targets XLS IR (alternative path to
  DSLX) developed by a sister team at Google, sharing the same open source /
  testing flow as the rest of the XLS project. May be of particular interest
  for teams with existing C++ HLS code bases.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/data_structures"><code>data_structures</code></a>:
  Generic data structures used in XLS that augment standard libraries; e.g.
  BDDs, union find, min cut, etc.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/delay_model"><code>delay_model</code></a>:
  Functionality to characterize, describe, and interpolate data delay for
  XLS IR operations on a target backend process. Already-characterized
  descriptions are placed in <code>xls/delay_model/models</code> and can be referred to via
  command line flags.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/dslx"><code>dslx</code></a>: A DSL (called
  "DSLX") that mimics Rust, while being an immutable expression-language
  dataflow DSL with hardware-oriented features; e.g.  arbitrary bitwidths,
  entirely fixed size objects, fully analyzeable call graph. XLS team has found
  dataflow DSLs are a good fit to describe hardware as compared to languages
  designed assume von Neumann style computation.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/dslx/fuzzer"><code>dslx/fuzzer</code></a>: A
  whole-stack multiprocess fuzzer that generates programs at the DSL level and
  cross-compares different execution engines (DSL interpreter, IR interpreter,
  IR JIT, code-generated-Verilog simulator). Designed so that it can easily be
  run on different nodes in a cluster simultaneously and accumulate shared
  findings.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/examples"><code>examples</code></a>: Example
  computations that are tested and executable through the XLS stack.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/experimental"><code>experimental</code></a>:
  Artifacts captured from experimental explorations.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/ir"><code>ir</code></a>:
  XLS IR definition, text parser/formatter, and facilities for abstract
  evaluation and execution engines (<a href="https://google.github.io/xls/interpreters/">IR interpreter</a>,
  <a href="https://google.github.io/xls/ir_jit/">JIT</a>).</li>
<li><a href="https://github.com/google/xls/tree/main/xls/modules"><code>modules</code></a>:
  Hardware building block DSLX "libraries" (outside the DSLX standard library)
  that may be easily reused or instantiated in a broader design.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/netlist"><code>netlist</code></a>: Libraries
  that parse/analyze/interpret netlist-level descriptions, as are
  generally given in simple structural Verilog with an associated cell library.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/passes"><code>passes</code></a>: Passes that
  run on the XLS IR as part of optimization, before scheduling / code
  generation.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/scheduling"><code>scheduling</code></a>:
  Scheduling algorithms, determine when operations execute (e.g. which
  pipeline stage) in a clocked design.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/simulation"><code>simulation</code></a>:
  Code that wraps Verilog simulators and generates Verilog testbenches for XLS
  computations.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/solvers"><code>solvers</code></a>:
  Converters from XLS IR into SMT solver input, such that formal proofs can be
  run on XLS computations; e.g. Logical Equalence Checks between XLS IR and a
  netlist description.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/synthesis"><code>synthesis</code></a>:
  Interface that wraps backend synthesis flows, such that tools can be
  retargeted e.g. between ASIC and FPGA flows.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/tests"><code>tests</code></a>:
  Integration tests that span various top-level components of the XLS project.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/tools"><code>tools</code></a>:
  <a href="https://google.github.io/xls/tools/">Many tools</a> that work with the XLS system and its libraries in a
  decomposed way via command line interfaces.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/uncore_rtl"><code>uncore_rtl</code></a>:
  Helper RTL that interfaces XLS-generated blocks with device top-level for e.g.
  FPGA experiments.</li>
<li><a href="https://github.com/google/xls/tree/main/xls/visualzation"><code>visualization</code></a>:
  Visualization tools to inspect the XLS compiler/system interactively. See
  <a href="https://google.github.io/xls/ir_visualization/">IR visualization</a>.</li>
</ul>
</li>
</ul>

<p>Discussions about XLS - development, debugging, usage, and anything else -
should go to the <a href="https://groups.google.com/g/xls-dev">xls-dev mailing list</a>.</p>
<h2 id="contributors">Contributors</h2>
<p>The following are
<a href="https://github.com/google/xls/graphs/contributors">contributors</a> to the XLS
project, see our
<a href="https://google.github.io/xls/contributing/">contributing documentation</a> and
<a href="https://github.com/google/xls/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22">good first issues</a>!</p>
<ul>
<li><a href="https://github.com/brajiang">Brandon Jiang</a></li>
<li><a href="https://github.com/cdleary">Chris Leary</a></li>
<li><a href="https://github.com/dmlockhart">Derek Lockhart</a></li>
<li><a href="https://github.com/felixzhuologist">Felix Zhu</a></li>
<li><a href="https://github.com/hmontero1205">Hans Montero</a></li>
<li><a href="https://github.com/jbaileyhandle">Jonathan Bailey</a></li>
<li><a href="https://github.com/julianviera99">Julian Viera</a></li>
<li><a href="https://github.com/kevineharlley">Kevin Harlley</a></li>
<li><a href="https://github.com/meheffernan">Mark Heffernan</a></li>
<li><a href="https://github.com/per-gron">Per Gr√∂n</a></li>
<li><a href="https://github.com/rchen152">Rebecca Chen (Pytype)</a></li>
<li><a href="https://github.com/rhundt">Robert Hundt</a></li>
<li><a href="https://github.com/RobSpringer">Rob Springer</a></li>
<li><a href="https://github.com/spurserh">Sean Purser-Haskell</a></li>
</ul>
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        

      
    </div></div>]]>
            </description>
            <link>https://google.github.io/xls/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24354083</guid>
            <pubDate>Wed, 02 Sep 2020 15:19:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Programming with Categories]]>
            </title>
            <description>
<![CDATA[
Score 313 | Comments 97 (<a href="https://news.ycombinator.com/item?id=24353976">thread link</a>) | @kercker
<br/>
September 2, 2020 | http://brendanfong.com/programmingcats.html | <a href="https://web.archive.org/web/*/http://brendanfong.com/programmingcats.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<img src="http://brendanfong.com/programmingcats_files/seal.gif" width="150">
<h2>
<a href="http://brendanfong.com/">Brendan Fong</a>,
<a href="https://bartoszmilewski.com/">Bartosz Milewski</a>,
and
<a href="http://math.mit.edu/~dspivak/">David Spivak</a>
</h2>
Department of Mathematics<br>
Massachusetts Institute of Technology<br>
<b>Office:</b> 2-180<br>
<b>Email:</b> {bfo,dspivak} -- mit/edu  <center>

<h2> IAP 2020</h2>
<img src="http://brendanfong.com/programmingcats_files/pigskell.jpeg" width="300">
</center>

<h3> General information</h3>

<table>
<colgroup><col width="105"> <col width="300">
</colgroup><tbody><tr><td>Room:</td><td>4-163</td></tr>
<tr><td>Dates:</td><td> Jan 7‚Äî31 (MTWRF)</td></tr>
<tr><td>Time:</td><td> 2‚Äî3pm</td></tr>
<tr><td>Prerequisites:</td><td> None</td></tr>
<tr><td>Credit:</td><td> 3 units (1-0-2) (P/D/F)</td></tr>
</tbody></table>
<p>

<b>Summary</b>: In this course we explain how category theory‚Äîa branch of mathematics known for its ability to organize the key abstractions that structure much of the mathematical universe‚Äîhas become useful for writing elegant and maintainable code. In particular, we'll use examples from the Haskell programming language to motivate category-theoretic constructs, and then explain these constructs from a more abstract and inclusive viewpoint. Hands-on programming exercises will be used to demonstrate categorical ideas like "the universal property of products" in working Haskell code. A rough list of topics includes: 
</p><ol>
<li>Sets, types, categories, functors, natural transformations</li>
<li>Universal constructions and associated data types</li>
<li>Adjunctions and cartesian closed categories</li>
<li>Algebras, catamorphisms, anamorphisms</li>
<li>Monads, comonads, Kleisli arrows</li>
<li>Monoids, monoidal categories, lax monoidal functors, applicatives</li>
<li>Profunctors, (co)ends, optics</li>
</ol>
<b>We will assume no background knowledge on behalf of the student</b>, starting from scratch on both the programming and mathematics.

(<a href="http://brendanfong.com/programmingcats_files/flyer.pdf">Flyer</a>)
<p>
Students are very welcome to audit.
</p><hr>

<h3>Course details</h3>
<p>
Course notes and videos will be published here following each class. Feedback about the notes is welcome <a href="https://docs.google.com/document/d/1CQF1k01Ik_ehEpvE0KzYhLZbfMQY-kPW8QAm48xTe7k/edit">
here</a> or via email to the instructors.
</p>
<p>
Students taking the course for credit will be required to complete three problem
sets. There will be no exam. See the <a href="http://brendanfong.com/programmingcats_files/C4P-syllabus.pdf">syllabus</a> for more details.
</p>

<p>The instructors will lead problem discussion and be available for questions each
day from 3 to 4pm, in the course classroom, 4-163.
</p>

<p>
There will be no class on Monday 1/20 (MLK Day).
</p>

<hr>

<h3>Course resources</h3>
    
<ul>
    <li>
        <a href="http://brendanfong.com/programmingcats_files/cats4progs-DRAFT.pdf">Course notes: Programming with Categories</a>
    </li>
    <li>
        <a href="https://www.youtube.com/playlist?list=PLhgq-BqyZ7i7MTGhUROZy3BOICnVixETS">Class videos</a>
    </li>
    <li>
        <a href="https://roamresearch.com/#/app/programming-with-categories/page/4PUHYRX13">David Dalrymple's summaries of each class</a>
    </li>
    <li>
        <a href="https://forum.azimuthproject.org/categories/programming-with-categories-course">Discussion forum</a>
    </li>
</ul>
    
<hr>

<h3>Problem sets</h3>
<ul>
<li>
  <a href="http://brendanfong.com/programmingcats_files/ps1.pdf">PS1</a> (<a href="http://brendanfong.com/programmingcats_files/pset1-solutions.pdf">Solutions</a>)
</li>

<li>
  <a href="http://brendanfong.com/programmingcats_files/ps2.pdf">PS2</a> (Due 1/24)
</li>

<li>
  <a href="http://brendanfong.com/programmingcats_files/ps3.pdf">PS3</a> (Due 1/31)
</li>
</ul>

<hr>

<h3>Open access and remote participation</h3>

<p>
  All are welcome to attend the lectures in person. We encourage those participating remotely to post questions and discuss course content on the <a href="https://forum.azimuthproject.org/categories/programming-with-categories-course">Azimuth Forum</a>.
</p>
<hr>

<h3>Additional resources</h3>
<ul>
  <li>
    <a href="https://bartoszmilewski.com/2014/10/28/category-theory-for-programmers-the-preface/">Bartosz' blog and book on Category Theory for Programmers</a>
  </li>
  <li>
    <a href="https://www.youtube.com/user/DrBartosz/playlists">Bartosz' lectures on Category Theory</a>
  </li>
  <li>
    <a href="https://ocw.mit.edu/courses/mathematics/18-s097-applied-category-theory-january-iap-2019/">Brendan and David's previous MIT course on Applied Category Theory</a>
  </li>
  <li>
    <a href="https://forum.azimuthproject.org/categories/programming-with-categories-course">An online forum dedicated to discussing this course, and applied category theory in general</a>
  </li>
</ul>

<hr>

<h3> Mailing list </h3>
Join the <a href="https://docs.google.com/forms/d/e/1FAIpQLSdnuk-lIrjBJPLAO17ZkxeSgV7f6oCp3VUmuAJd138daYDQXA/viewform">mailing list</a> to get updates.
<hr>


<a rel="license" href="http://creativecommons.org/licenses/by-sa/3.0/"><img alt="Creative
Commons License" width="50" src="http://brendanfong.com/programmingcats_files/88x31.png"></a>
<span size="-2">This
<span xmlns:dc="http://purl.org/dc/elements/1.1/" href="http://purl.org/dc/dcmitype/Text" rel="dc:type">work</span> by <span xmlns:cc="http://creativecommons.org/ns#" property="cc:attributionName">Brendan Fong, Bartosz Milewski, and David Spivak</span> is licensed 
under a
<a rel="license" href="http://creativecommons.org/licenses/by-sa/3.0/">Creative Commons
Attribution-Share Alike 3.0 Unported License</a>.
</span>


</div>]]>
            </description>
            <link>http://brendanfong.com/programmingcats.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24353976</guid>
            <pubDate>Wed, 02 Sep 2020 15:08:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Clojure in the command line with Babashka]]>
            </title>
            <description>
<![CDATA[
Score 142 | Comments 36 (<a href="https://news.ycombinator.com/item?id=24353476">thread link</a>) | @Borkdude
<br/>
September 2, 2020 | https://www.karimarttila.fi/clojure/2020/09/01/using-clojure-in-command-line-with-babashka.html | <a href="https://web.archive.org/web/*/https://www.karimarttila.fi/clojure/2020/09/01/using-clojure-in-command-line-with-babashka.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><img src="https://www.karimarttila.fi/img/2020-09-01-using-clojure-in-command-line-with-babashka_img_1.png" alt="Ordinary Clojure code"></p>

<p><em>Ordinary Clojure code - can be run in REPL or in command line with Babashka (the whole file can be found <a href="https://github.com/karimarttila/clojure/blob/master/webstore-demo/integrant-simple-server/postgres/bb_postgres.clj">here</a> )</em></p>

<h3 id="introduction">Introduction</h3>

<p>I never bothered to learn <a href="https://en.wikipedia.org/wiki/Bash_(Unix_shell)">Bash</a> so that I could be really fluent with it. If I needed anything beyond basic Bash stuff I immediately used <a href="https://www.python.org/">Python</a> in command-line scripting.</p>

<p>I‚Äôm currently implementing my Clojure simple server again, this time using the <a href="https://github.com/weavejester/integrant">Integrant</a> library. In this new version, I implemented three data stores: CSV, AWS DynamoDB, and Postgres. I had already implemented importing development data into DynamoDB (using Python), this time I used <a href="https://github.com/borkdude/Babashka">Babashka</a> to import development data into Postgres - mainly just to have an excuse to try if I could replace Python with Clojure when scripting something with Bash.</p>

<p>The scripts can be found in my <a href="https://github.com/karimarttila/clojure">Clojure git</a> repo in directory <a href="https://github.com/karimarttila/clojure/tree/master/webstore-demo/integrant-simple-server/postgres">postgres</a>.</p>

<h3 id="developing-with-babashka">Developing with Babashka</h3>

<p>The really neat thing with Babashka is that you can develop your Babashka scripts as part of your Clojure project, or independently but using your favorite Clojure IDE. The picture above shows Clojure code in my favorite Clojure IDE, <a href="https://cursive-ide.com/">Cursive</a>. I have the Clojure code that imports data into the Postgres database in directory <a href="https://github.com/karimarttila/clojure/tree/master/webstore-demo/integrant-simple-server/postgres">postgres</a>, so I have the following extra path in my <a href="https://github.com/karimarttila/clojure/blob/master/webstore-demo/integrant-simple-server/deps.edn">deps.edn</a>:</p>

<div><div><pre><code><span> </span><span>:postgres</span><span> </span><span>{</span><span>:extra-paths</span><span> </span><span>[</span><span>"postgres"</span><span>]}</span><span>
</span></code></pre></div></div>

<p>Then the nice thing is that I can develop the Clojure code as part of project‚Äôs other Clojure code. Let‚Äôs first create a short bash script that tells Babashka to run your Clojure code with a flag so that we know in the Clojure code when we are running the code using Babashka or using Clojure IDE REPL (file <a href="https://github.com/karimarttila/clojure/blob/master/webstore-demo/integrant-simple-server/postgres/run-bb-load-data.sh">run-bb-load-data.sh</a>):</p>

<div><div><pre><code><span>#/bin/bash</span>

<span>export </span><span>POSTGRES_PASSWORD</span><span>=</span>simpleserver
<span>export </span><span>RUNNING_BB</span><span>=</span>TRUE
bb bb_postgres.clj
</code></pre></div></div>

<p>The flag is the <code>RUNNING_BB</code> export above.</p>

<p>Then in the Clojure code we have a top level form <code>(run-me)</code> in the namespace (file <a href="https://github.com/karimarttila/clojure/blob/master/webstore-demo/integrant-simple-server/postgres/bb_postgres.clj">bb_postgres.clj</a>):</p>

<div><div><pre><code><span>(</span><span>defn</span><span> </span><span>run-me</span><span> </span><span>[]</span><span>
  </span><span>"Loads data only if running from Babashka script which sets the environment variable.
  We don't want the repl to load the data when reloading the namespace.
  In repl experimentation use the rich comment below."</span><span>
  </span><span>(</span><span>let</span><span> </span><span>[</span><span>running-bb?</span><span> </span><span>(</span><span>System/getenv</span><span> </span><span>"RUNNING_BB"</span><span>)]</span><span>
    </span><span>(</span><span>if</span><span> </span><span>(</span><span>=</span><span> </span><span>running-bb?</span><span> </span><span>"TRUE"</span><span>)</span><span>
      </span><span>(</span><span>import-data</span><span>))))</span><span>

</span><span>(</span><span>run-me</span><span>)</span><span>
</span></code></pre></div></div>

<p>I.e. when reloading the namespace REPL runs the code but if the flag is not set it doesn‚Äôt actually do anything - it imports the code only if we are running the code using Babashka. The reason for this is that when I reload the namespace as part of my Clojure workflow I don‚Äôt want the data import to happen. For development purposes to test importing data, or any other function, I have a <code>rich comment</code> at the end of the file:</p>

<div><div><pre><code><span>(</span><span>comment</span><span>
  </span><span>(</span><span>def</span><span> </span><span>data-dir</span><span> </span><span>"dev-resources/data"</span><span>)</span><span>
  </span><span>(</span><span>get-raw-products</span><span> </span><span>data-dir</span><span> </span><span>2</span><span>)</span><span>
  </span><span>(</span><span>get-product-groups</span><span> </span><span>data-dir</span><span>)</span><span>
  </span><span>(</span><span>do</span><span>
    </span><span>(</span><span>delete-products!</span><span>)</span><span>
    </span><span>(</span><span>delete-product-groups!</span><span>))</span><span>
  </span><span>(</span><span>vals</span><span> </span><span>(</span><span>get-users</span><span> </span><span>data-dir</span><span>))</span><span>
  </span><span>(</span><span>load-users</span><span> </span><span>(</span><span>vals</span><span> </span><span>(</span><span>get-users</span><span> </span><span>data-dir</span><span>)))</span><span>
  </span><span>(</span><span>import-data</span><span>)</span><span>
  </span><span>(</span><span>db-get-all-product-groups</span><span>)</span><span>
  </span><span>(</span><span>db-get-all-products</span><span>)</span><span>
  </span><span>)</span><span>
</span></code></pre></div></div>

<p>The <code>comment</code> block is here so that REPL does not run this code when reloading, of course. The function calls you see inside the comment block are just experiments added in no particular order. I can send any of these forms individually to be evaluated in the REPL - a typical Clojure trick when developing with REPL.</p>

<h3 id="babashka-use-cases">Babashka Use Cases</h3>

<p>I really like the idea that I can now use Clojure in shell scripting. Of course I could use Clojure in shell scripting also without Babashka but JVM boot takes quite a long time which makes testing of the script in command line a bit painful. Not so with Babashka - Babashka boots lightning fast:</p>

<div><div><pre><code>Œª&gt; <span>time </span>bb <span>'(println "Hello world!")'</span>
Hello world!

real	0m0.006s
user	0m0.003s
sys	0m0.003s
</code></pre></div></div>

<p>The use cases using Babashka in my personal scripting probably is a bit like I used Babashka to import data into the Postgres database in this exercise:</p>

<div><div><pre><code><span>(</span><span>defn</span><span> </span><span>run-sql</span><span> </span><span>[</span><span>command</span><span>]</span><span>
  </span><span>(</span><span>sh/sh</span><span> </span><span>"psql"</span><span> </span><span>"--host"</span><span> </span><span>"localhost"</span><span> </span><span>"--port"</span><span> </span><span>"5532"</span><span> </span><span>"--username=simpleserver"</span><span> </span><span>"--dbname=simpleserver"</span><span> </span><span>"-c"</span><span> </span><span>command</span><span>))</span><span>

</span><span>(</span><span>defn</span><span> </span><span>insert-product-group!</span><span> </span><span>[</span><span>product-group</span><span>]</span><span>
  </span><span>(</span><span>println</span><span> </span><span>"Inserting product-group: "</span><span> </span><span>product-group</span><span>)</span><span>
  </span><span>(</span><span>let</span><span> </span><span>[[</span><span>id</span><span> </span><span>name</span><span>]</span><span> </span><span>product-group</span><span>
        </span><span>command</span><span> </span><span>(</span><span>str</span><span> </span><span>"INSERT INTO product_group VALUES ('"</span><span> </span><span>id</span><span> </span><span>"', '"</span><span> </span><span>name</span><span> </span><span>"');"</span><span>)]</span><span>
    </span><span>(</span><span>run-sql</span><span> </span><span>command</span><span>)))</span><span>

</span><span>(</span><span>defn</span><span> </span><span>load-product-groups</span><span> </span><span>[</span><span>product-groups</span><span>]</span><span>
  </span><span>(</span><span>doseq</span><span> </span><span>[</span><span>pg</span><span> </span><span>product-groups</span><span>]</span><span>
    </span><span>(</span><span>insert-product-group!</span><span> </span><span>pg</span><span>)))</span><span>

</span><span>(</span><span>defn</span><span> </span><span>get-product-groups</span><span> </span><span>[</span><span>data-dir</span><span>]</span><span>
  </span><span>(</span><span>let</span><span> </span><span>[</span><span>raw</span><span> </span><span>(</span><span>with-open</span><span> </span><span>[</span><span>reader</span><span> </span><span>(</span><span>io/reader</span><span> </span><span>(</span><span>str</span><span> </span><span>data-dir</span><span> </span><span>"/product-groups.csv"</span><span>))]</span><span>
              </span><span>(</span><span>doall</span><span>
                </span><span>(</span><span>csv/read-csv</span><span> </span><span>reader</span><span>)))</span><span>
        </span><span>product-groups</span><span> </span><span>(</span><span>into</span><span> </span><span>{}</span><span>
                             </span><span>(</span><span>map</span><span>
                               </span><span>(</span><span>fn</span><span> </span><span>[[</span><span>item</span><span>]]</span><span>
                                 </span><span>(</span><span>str/split</span><span> </span><span>item</span><span> </span><span>#</span><span>"\t"</span><span>))</span><span>
                               </span><span>raw</span><span>))]</span><span>
    </span><span>product-groups</span><span>))</span><span>

</span><span>(</span><span>defn</span><span> </span><span>import-data</span><span> </span><span>[]</span><span>
  </span><span>(</span><span>let</span><span> </span><span>[</span><span>data-dir</span><span> </span><span>"dev-resources/data"</span><span>
        </span><span>product-groups</span><span> </span><span>(</span><span>get-product-groups</span><span> </span><span>data-dir</span><span>)]</span><span>
</span><span>;...</span><span>
    </span><span>(</span><span>load-product-groups</span><span> </span><span>product-groups</span><span>)</span><span>
</span><span>;...</span><span>
</span></code></pre></div></div>

<p>I.e. parsing CSV, transforming data, and then call some program with the transformed data, possibly read what was returned and do other stuff. You could possibly do all this using plain old Bash but I never bothered to learn Bash in that level that I can do more than test some flags and call other programs using Bash.</p>

<h3 id="how-do-i-use-the-babashka-script-in-this-exercise">How Do I Use the Babashka Script in This Exercise?</h3>

<p>I used Babashka to load development data into the Postgres data store. During development I built a custom Postgres image and provided a <a href="https://github.com/casey/just">Just</a> recipe to start the data store (file <a href="https://github.com/karimarttila/clojure/blob/master/webstore-demo/integrant-simple-server/Justfile">Justfile</a>):</p>

<div><div><pre><code><span># Start local postgres</span>
@postgres:
    <span>cd </span>postgres <span>&amp;&amp;</span> ./run-docker-compose.sh
</code></pre></div></div>

<p>The <a href="https://github.com/karimarttila/clojure/blob/master/webstore-demo/integrant-simple-server/postgres/run-docker-compose.sh">run-docker-compose.sh</a> starts the Postgres docker container, creates the schema and finally calls <a href="https://github.com/karimarttila/clojure/blob/master/webstore-demo/integrant-simple-server/postgres/run-bb-load-data.sh">./run-bb-load-data.sh</a> which loads the data into the development Postgres data store:</p>

<div><div><pre><code><span>#!/usr/bin/env bash</span>

<span>echo</span> <span>"NOTE: Remember to destroy the container if running again!"</span>
<span>echo</span> <span>"Starting docker compose..."</span>
docker-compose <span>-p</span> ss-postgres <span>-f</span> docker-compose-setup-local-postgres.yml up <span>-d</span>
<span>sleep </span>5
<span>echo</span> <span>"Creating Simple Server schemas..."</span>
./create-schema.sh
<span>sleep </span>1
<span>echo</span> <span>"Loading data..."</span>
./run-bb-load-data.sh
<span>sleep </span>1
docker logs <span>-f</span> ss-postgres_postgres_1
</code></pre></div></div>

<h3 id="clojure-babashka-vs-python-in-shell-scripting">Clojure (Babashka) vs Python in Shell Scripting</h3>

<p>Let‚Äôs finally compare Python and Clojure (Babashka) when doing some Linux shell scripting.</p>

<p><strong>Easiness</strong>. Both languages are pretty easy and fast to work if you have used them. Developing Python scripts is pretty fast - you just run the script in command line. Working with Clojure has one additional plus: you can use the Clojure REPL.</p>

<p><strong>Library support</strong>: Python wins. When you are scripting in Python and you realize that it would be nice e.g. to use some AWS library - just use it (e.g. <a href="https://github.com/karimarttila/clojure/blob/master/webstore-demo/integrant-simple-server/dynamodb/pysrc/table_importer.py">table_importer.py</a> - the AWS <a href="https://boto3.amazonaws.com/v1/documentation/api/latest/index.html">boto3</a> library). The library support for Babashka is not as extensive, of course - but Babashka supports quite many namespaces outside <code>clojure.core</code> and also some additional libraries: <a href="https://github.com/borkdude/babashka#built-in-namespaces">Babashka built-in namespaces</a> - keep eye on that page, maybe Babashka library support is growing in the future!</p>

<p>So, the library support might not be as good as with Python. But I really do love Clojure and if I‚Äôm implementing apps using Clojure it is really nice to do some ad hoc scripting using Babashka.</p>

<h3 id="conclusions">Conclusions</h3>

<p>It‚Äôs nice to have another scripting tool in my toolbox: <a href="https://github.com/borkdude/babashka">Babashka</a>. Time will tell if I start using Clojure instead of Python as my preferred scripting language, thanks to Babashka. At least in this exercise Babashka did really well.</p>

<p><em>The writer is working at Metosin using Clojure in cloud projects. If you are interested to start a Clojure project in Finland or you are interested to get Clojure training in Finland you can contact me by sending email to my Metosin email address or contact me via LinkedIn.</em></p>

<p>Kari Marttila</p>

<ul>
  <li>Kari Marttila‚Äôs Home Page in LinkedIn: <a href="https://www.linkedin.com/in/karimarttila/">https://www.linkedin.com/in/karimarttila/</a></li>
</ul>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://www.karimarttila.fi/clojure/2020/09/01/using-clojure-in-command-line-with-babashka.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24353476</guid>
            <pubDate>Wed, 02 Sep 2020 14:16:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AWS Tagging Best Practices: Using Terraform and CloudFormation to Enforce Tags]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 24 (<a href="https://news.ycombinator.com/item?id=24353412">thread link</a>) | @toeknee123
<br/>
September 2, 2020 | https://cloudforecast.io/blog/aws-tagging-best-practices-guide-part-2/ | <a href="https://web.archive.org/web/*/https://cloudforecast.io/blog/aws-tagging-best-practices-guide-part-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <!-- Toc if any -->            
                
                <!-- End Toc -->
				

<p>Once <a href="https://www.cloudforecast.io/blog/aws-tagging-best-practices/" target="_blank">you have adopted an AWS tagging strategy</a>, you‚Äôll need to make sure that all your existing AWS resources and any new ones you create abide by it. Consistency is the key - if you don‚Äôt proactively enforce your AWS tagging strategy, you‚Äôll always be playing catch up and chasing down team members to make sure they add the right tags to their resources.</p>

<p>While you can apply AWS tags to your resources manually using the <a href="https://docs.aws.amazon.com/cli/latest/reference/resourcegroupstaggingapi/tag-resources.html" target="_blank">AWS CLI</a> or <a href="https://docs.aws.amazon.com/ARG/latest/userguide/tag-editor.html" target="_blank">AWS Tag Editor</a>, you‚Äôll probably find this cumbersome and error-prone at scale. A better approach is to automatically apply AWS tags to your resources and use rules to enforce their consistent usage.</p>

<p>Depending on the tool you use to maintain your infrastructure on AWS, your method of proactively enforcing AWS tags on new resources may vary. In this guide, I‚Äôll highlight two tools: Terraform and AWS CloudFormation. You‚Äôll see how to use each to create and update AWS cost allocation tags on your resources and then enforce the proper use of specific tags for new resources. By proactively enforcing your AWS tagging strategy, you‚Äôll minimize your time spent auditing and correcting improper AWS tags and force developers to learn best AWS tagging best practices for your environment.</p>



<p>The first infrastructure management tool I‚Äôll cover is <a href="https://www.terraform.io/" target="_blank">Terraform</a>. Terraform works across a variety of cloud hosting providers to help you provision and maintain your AWS resources. With Terraform, you can define your servers, databases, and networks in code and apply your changes programmatically to your AWS account.</p>

<p>If you‚Äôre new to Terraform, they have a well-documented <a href="https://learn.hashicorp.com/terraform/getting-started/intro" target="_blank">Getting Started guide</a> and several <a href="https://github.com/terraform-providers/terraform-provider-aws/tree/master/examples" target="_blank">AWS template examples on GitHub</a>. In this section, I‚Äôll show you some snippets from a demo Terraform project and module that <a href="https://github.com/CloudForecast/cf-terraform-demo" target="_blank">is available on GitHub</a>. You‚Äôll learn the following in this Terraform AWS tags:</p>

<ol>
  <li>Tag a New AWS EC2 Instance with Terraform</li>
  <li>Using Terraform to Update Existing AWS Tags</li>
  <li>Enforce AWS Tags with Terraform</li>
</ol>

<h3 id="tag-a-new-aws-ec2-instance-with-terraform">Tag a New AWS EC2 Instance with Terraform</h3>

<p>If you want to deploy an EC2 instance with AWS Tags using Terraform, your configuration might include something like this:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
</pre></td><td><pre>resource "aws_instance" "cart" {
  connection {
    type = "ssh"
    user = "ubuntu"
    host = self.public_ip
    private_key = file(var.private_key_path)
  }

  instance_type = "t2.micro"

  ami = var.aws_amis[var.aws_region]

  key_name = aws_key_pair.auth.key_name

  vpc_security_group_ids = [aws_security_group.default.id]

  subnet_id = aws_subnet.default.id

  provisioner "remote-exec" {
    inline = [
      "sudo apt-get -y update",
      "sudo apt-get -y install nginx",
      "sudo service nginx start",
    ]
  }
  tags = {
    contact = "j-mark"
    env = "dev"
    service = "cart"
  }
}
</pre></td></tr></tbody></table></code></pre></div></div>

<p>The above example includes three AWS cost allocation tags: <code>contact</code>, <code>env</code>, and <code>service</code> with values described as strings. When you <a href="https://www.terraform.io/docs/commands/apply.html" target="_blank">apply this configuration</a>, Terraform will connect to AWS and deploy an EC2 instance having the AWS tags you specified.</p>

<p><img src="https://paper-attachments.dropbox.com/s_11675783F6270CC3362B9903B770D88B278C2B2D779D11551760688B8EA1DFC4_1596383259429_cf-2020-08-02-a.png" alt=""></p>

<h3 id="using-terraform-to-update-existing-aws-tags">Using Terraform to Update Existing AWS Tags</h3>

<p>Terraform makes it easy to update already existing resources with AWS tags in reversible and consistent ways. If you‚Äôre using AWS tags to keep track of a resource‚Äôs contact (e.g.: <code>j-mark</code> in the above example), you‚Äôre likely to need to update the AWS tag when the team member leaves or changes roles.</p>

<p>To update the AWS tags on your resource, simply update the corresponding tags in your Terraform configuration. The new tags will overwrite any previous tags assigned to the resource, including tags added outside of Terraform.</p>

<p>For example, to change the <code>contact</code> cost allocation tag on the EC2 instance above, you might update the <code>tags</code> block above with the following:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
</pre></td><td><pre>tags = {
  contact = "l-duke"
  env = "dev"
  service = "cart"
}
</pre></td></tr></tbody></table></code></pre></div></div>

<p>When you apply this configuration, the AWS tags will be automatically updated in the AWS console:</p>

<p><img src="https://paper-attachments.dropbox.com/s_11675783F6270CC3362B9903B770D88B278C2B2D779D11551760688B8EA1DFC4_1596383277121_cf-2020-08-02-b.png" alt=""></p>

<p>If you keep your Terraform configuration files in version control - which is probably a good idea - you will be able to see how tags have changed over time. You can also review changes using the same code review process that your application code goes through to help you catch mistakes in the execution of your tagging strategy.</p>

<h3 id="enforce-aws-tags-with-terraform">Enforce AWS Tags with Terraform</h3>

<p>As your infrastructure grows, a code review process likely won‚Äôt be enough to prevent improper AWS tagging. Fortunately, you can enforce AWS tag names and values using <a href="https://www.terraform.io/docs/configuration/variables.html" target="_blank">variables</a> and custom validation rules in Terraform.</p>

<p>In the examples above, the <code>tags</code> list was hard-coded into the EC2 instance definition. A more scalable pattern would be to break your EC2 instance template into its own <a href="https://www.terraform.io/docs/configuration/modules.html" target="_blank">module</a> and use a <code>tags</code> variable. You can then write a <a href="https://www.terraform.io/docs/configuration/variables.html#custom-validation-rules" target="_blank">custom validation rule</a> to check that the tags comply with your strategy.</p>

<p>For example, if you want to check that:</p>

<ol>
  <li>The user specifies at least one tag</li>
  <li>The <code>contact</code> tag is either <code>j-mark</code> or <code>l-duke</code></li>
  <li>The <code>env</code> tag is set</li>
  <li>The <code>service</code> tag is either <code>cart</code> or <code>search</code></li>
</ol>

<p>You might create a module with a variable specified like this:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
</pre></td><td><pre>variable "tags" {
  description = "The tags for this resource."
  validation {
    condition = length(var.tags) &gt; 0 &amp;&amp; contains(["j-mark", "l-duke"], var.tags.contact) &amp;&amp; var.tags.env != null &amp;&amp; contains(["cart", "search", "cart:search"], var.tags.service)
    error_message = "Invalid resource tags applied."

  }
}
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Now when you run <code>terraform plan</code> with a missing or invalid tag, you‚Äôll get an error:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre>Error: Invalid value for variable
...
Invalid resource tags applied.
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Your rules can be as complex as <a href="https://www.terraform.io/docs/configuration/index.html" target="_blank">Terraform‚Äôs Configuration Language</a> allows, so functions like <code>regex()</code>, <code>substr()</code>, and <code>distinct()</code> are all available. That said, there are some caveats to this approach.</p>

<p>First, custom variable validation is an experimental feature in Terraform. <a href="https://www.terraform.io/docs/configuration/terraform.html#experimental-language-features" target="_blank">Experimental features</a> are subject to change, meaning that you might need to pay attention to Terraform update mores closely. To enable <code>variable_validation</code>, add the following to your <code>terraform</code> block:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre>terraform {
  experiments = [variable_validation]
}
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Second, Terraform‚Äôs variable validation only happens during the <code>terraform plan</code> phase of your infrastructure‚Äôs lifecycle. It can‚Äôt prevent users from accidentally changing your tags directly in the AWS console, and it‚Äôs only as good as the validation rules you write. If you start using a new resource but forget to add validation rules, you might end up with lots of resources that don‚Äôt adhere to your tagging strategy.</p>

<p>Another option for paid Terraform Cloud customers is <a href="https://www.terraform.io/docs/cloud/sentinel/index.html" target="_blank">Sentinel</a>, which allows you to create custom policies for your resources. I won‚Äôt cover this method here, but Terraform has created an <a href="https://www.terraform.io/docs/cloud/sentinel/examples.html" target="_blank">example policy</a> to show you how to enforce mandatory AWS tags.</p>



<p>Similar to Terraform, AWS <a href="https://aws.amazon.com/cloudformation/" target="_blank">CloudFormation</a> lets you provision AWS resources based on configuration files. Unlike Terraform, CloudFormation is part of Amazon‚Äôs offerings, so it won‚Äôt necessarily help you if you want to use another infrastructure provider. The approach to tagging your resources in CloudFormation is similar to that used by Terraform, but as you‚Äôll see, the configuration format is different.</p>

<p>If you‚Äôre new to AWS CloudFormation, <a href="https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/GettingStarted.Walkthrough.html" target="_blank">Amazon‚Äôs official walkthrough</a> will help you get started deploying some basic templates. In this section, I‚Äôll show you some snippets from a demo AWS CloudFormation template which is <a href="https://github.com/CloudForecast/cf-cloudformation-demo" target="_blank">also available on GitHub</a>. You‚Äôll learn the following in this Terraform AWS tags section:</p>

<ol>
  <li>AWS CloudFormation Template to Deploy Tags</li>
  <li>Using CloudFormation to Update AWS Tags</li>
  <li>CloudFormation Template to Enforce AWS Tags</li>
</ol>

<h3 id="aws-cloudformation-template-to-deploy-tags">AWS CloudFormation Template to Deploy Tags</h3>

<p>AWS CloudFormation is designed to make it easy to create AWS resources with a single template file. Using a CloudFormation template, every resource that can be deployed with an AWS tag.</p>

<p>For example, to create a new EC2 instance with the same three AWS tags used in the Terraform example above, add an array of <code>Tags</code> to the resource‚Äôs <code>Properties</code> block:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
</pre></td><td><pre>"Resources" : {
  "WebServerInstance": {  
    "Type": "AWS::EC2::Instance",
    "Metadata" : {...},
    "Properties": {
      "Tags" : [
       {
          "Key" : "contact",
          "Value" : "j-mark"
       },
       {
          "Key" : "env",
          "Value" : "dev"
       },
       {
          "Key" : "service",
          "Value" : "cart"
       }
      ],
      ...       
    }
  },
  ...         
},
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Using <a href="https://aws.amazon.com/cli/" target="_blank">AWS CLI</a>, you can <a href="https://awscli.amazonaws.com/v2/documentation/api/latest/reference/cloudformation/create-stack.html" target="_blank">deploy this CloudFormation template as a new stack</a>. This will ensure your template is valid and create the specified resources with their tags on AWS:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>aws cloudformation create-stack --template-body file://path/to/your/template.json --stack-name=&lt;YOUR_STACK_NAME&gt;
</pre></td></tr></tbody></table></code></pre></div></div>

<p>If you have lots of similar resources in your template, you can deploy AWS tags to all the resources in the stack at once using the <code>--tags</code>  flag with the <code>create-stack</code> or <code>update-stack</code> commands:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
</pre></td><td><pre># Creating a stack with tags
aws cloudformation create-stack --template-body file://path/to/your/template.json --stack-name=&lt;YOUR_STACK_NAME&gt; --tags="Key=env,Value=dev"

# Updating a stack with tags
aws cloudformation update-stack --template-body file://path/to/your/template.json --stack-name=&lt;YOUR_STACK_NAME&gt; --tags="Key=env,Value=dev"
</pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="using-cloudformation-to-update-aws-tags">Using CloudFormation to Update AWS Tags</h3>

<p>If you want to change the contact on your EC2 instance created above, simply change the <code>Tags</code> section of your template file and use the <code>[update-stack](https://awscli.amazonaws.com/v2/documentation/api/latest/reference/cloudformation/update-stack.html)</code> <a href="https://awscli.amazonaws.com/v2/documentation/api/latest/reference/cloudformation/update-stack.html" target="_blank">command</a> to deploy your changes.</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
</pre></td><td><pre>"Tags" : [
 {
    "Key" : "contact",
    "Value" : "l-duke"
 },
  ...
],
</pre></td></tr></tbody></table></code></pre></div></div>

<p>AWS CloudFormation behaves the same way that Terraform does when you update tags outside your template file. Any tags set manually will be overridden by the <code>update-stack</code> ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cloudforecast.io/blog/aws-tagging-best-practices-guide-part-2/">https://cloudforecast.io/blog/aws-tagging-best-practices-guide-part-2/</a></em></p>]]>
            </description>
            <link>https://cloudforecast.io/blog/aws-tagging-best-practices-guide-part-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24353412</guid>
            <pubDate>Wed, 02 Sep 2020 14:10:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[To be creative, Chinese philosophy teaches us to abandon ‚Äòoriginality‚Äô]]>
            </title>
            <description>
<![CDATA[
Score 148 | Comments 64 (<a href="https://news.ycombinator.com/item?id=24353137">thread link</a>) | @canada_random1
<br/>
September 2, 2020 | https://psyche.co/ideas/to-be-creative-chinese-philosophy-teaches-us-to-abandon-originality | <a href="https://web.archive.org/web/*/https://psyche.co/ideas/to-be-creative-chinese-philosophy-teaches-us-to-abandon-originality">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><strong>When I was 15</strong>, one of my closest friends died unexpectedly. Our physics teacher broke the news to me after I√¢‚Ç¨‚Ñ¢d sat an exam, having wondered all the way through why my friend wasn√¢‚Ç¨‚Ñ¢t there doing the same. I still don√¢‚Ç¨‚Ñ¢t have the words to describe how I felt: it was something approaching shock, distress, disorientation. I didn√¢‚Ç¨‚Ñ¢t know what to think, much less what to do. I spent many nights awake and many days in a daze.</p>
<p>Fifteen years later, when I was in graduate school, another friend died suddenly, a man I loved very much. I remember checking my phone and finding out, to my dismay, via text message. But while my initial response was much the same as before, there was a palpable difference in how I felt later on. While I was again surprised and saddened, I was much less disoriented than I√¢‚Ç¨‚Ñ¢d been as a teenager. I could still think, and I could still get things done. It seemed to me that I√¢‚Ç¨‚Ñ¢d become better at living with loss.</p>
<p>You might think that the reason for this difference is obvious √¢‚Ç¨‚Äú I was older, and I√¢‚Ç¨‚Ñ¢d had more experience in coping with death. But raw experience alone isn√¢‚Ç¨‚Ñ¢t enough: what matters more is whether we learn from experience. And learning from experience, especially an experience as difficult as the death of a loved one, can involve quite a lot. Among other things, it can involve creativity.</p>
<p>This claim might seem surprising. After all, creativity is often associated with the idea of a lone creative genius, an individual who not only excels at what they do, but also transforms the world in the process. Further, even if we don√¢‚Ç¨‚Ñ¢t limit ourselves to romantic or heroic perspectives on the nature and value of creativity, it√¢‚Ç¨‚Ñ¢s commonly thought that creativity at least aims at novelty or originality.</p>
<p>This way of thinking about creativity isn√¢‚Ç¨‚Ñ¢t universal. The <a href="http://cup.columbia.edu/book/the-complete-works-of-zhuangzi/9780231164740"><em>Zhuangzi</em></a> (√®≈Ω≈†√•¬≠ÔøΩ), a classical Chinese philosophical and literary text, provides a different perspective. On one interpretation, creativity isn√¢‚Ç¨‚Ñ¢t conceived as aiming at novelty or originality, but rather <em>integration</em>. Instead of aiming at something new, it aims at something that combines well with the situation of which it√¢‚Ç¨‚Ñ¢s a part.</p>
<p>The story of Wheelwright Pian, from a chapter of the Zhuangzi known as the <em>Tian Dao</em> (√•¬§¬©√©ÔøΩ‚Äú), meaning √¢‚Ç¨ÀúHeaven√¢‚Ç¨‚Ñ¢s Way√¢‚Ç¨‚Ñ¢ or √¢‚Ç¨ÀúThe Way of Heaven√¢‚Ç¨‚Ñ¢, effectively illustrates this perspective on creativity as it pertains to artists or artisans. In this short vignette, a wheelwright known as Pian (√¶‚Ä∞ÔøΩ) tells a duke that the book of sages√¢‚Ç¨‚Ñ¢ advice he√¢‚Ç¨‚Ñ¢s reading is nothing but √¢‚Ç¨Àúchaff and dregs√¢‚Ç¨‚Ñ¢. Angered, the duke demands an explanation. The wheelwright responds that, at least concerning his craft, he can create what he does only because he√¢‚Ç¨‚Ñ¢s developed a √¢‚Ç¨Àúknack√¢‚Ç¨‚Ñ¢ for it that can√¢‚Ç¨‚Ñ¢t be wholly conveyed in words. If the blows of his mallet are too gentle, his chisel slides and won√¢‚Ç¨‚Ñ¢t take hold. If they√¢‚Ç¨‚Ñ¢re too hard, it bites in and won√¢‚Ç¨‚Ñ¢t budge. √¢‚Ç¨ÀúNot too gentle, not too hard √¢‚Ç¨‚Äú you can get it in your hand and feel it in your mind,√¢‚Ç¨‚Ñ¢ he says. √¢‚Ç¨ÀúSo, I√¢‚Ç¨‚Ñ¢ve gone along for 70 years and at my age I√¢‚Ç¨‚Ñ¢m still chiselling wheels. When the men of old died, they took with them the things that couldn√¢‚Ç¨‚Ñ¢t be handed down. So, what you are reading there must be nothing but the chaff and dregs of the men of old.√¢‚Ç¨‚Ñ¢</p>
<p>Although he√¢‚Ç¨‚Ñ¢s a √¢‚Ç¨Àúlowly√¢‚Ç¨‚Ñ¢ craftsperson, the wheelwright has something important to teach the duke. He√¢‚Ç¨‚Ñ¢s been creating wheels by hand for many years and has developed an ability to act and to execute his craft in an integrated manner that can√¢‚Ç¨‚Ñ¢t be fully captured through an algorithmic list of instructions. He responds to precise particularities in the wood, his tools and his body to create what he wants √¢‚Ç¨‚Äú something he doesn√¢‚Ç¨‚Ñ¢t accomplish by imposing a plan.</p>
<p>Striving for originality can be counterproductive when it comes to achieving genuinely fresh results</p>
<p>The sages√¢‚Ç¨‚Ñ¢ advice for living well is therefore mere √¢‚Ç¨Àúdregs√¢‚Ç¨‚Ñ¢ if it√¢‚Ç¨‚Ñ¢s interpreted as instructions that one can simply read and then complete. Living well in general involves much more than this; namely, a spontaneous integration between contrasting types such as the hard and the soft, as well as the learned and the spontaneous, the active and the passive, and even the unproductive and the productive √¢‚Ç¨‚Äú all of which apply in the case of carving wheels, as well as elsewhere. In other words, living well involves creativity.</p>
<p>This kind of creativity isn√¢‚Ç¨‚Ñ¢t taken to aim at novelty or originality as such. The wheelwright is presented as creative not because of anything to do with his, or his projects√¢‚Ç¨‚Ñ¢, novelty or originality, but instead because of his ability to create wheels in a sensitive, responsive and √¢‚Ç¨‚Äú crucially √¢‚Ç¨‚Äú well-integrated manner: one not learned by rote, but rather via engaging in sustained, spontaneous activity.</p>
<p>We can use the story of Wheelwright Pian to better understand why learning to live with loss is a creative pursuit. Although there√¢‚Ç¨‚Ñ¢s an abundance of books dispensing advice on how to do so, ultimately learning to live with death is a deeply personal endeavour that √¢‚Ç¨‚Äú like carving wheels √¢‚Ç¨‚Äú can√¢‚Ç¨‚Ñ¢t be fully captured through a programmatic set of directions. We must respond to precise particularities of our situation (concerning our thoughts, feelings and overall circumstances) to create what we want to create (such as a sense of peace or closure). This isn√¢‚Ç¨‚Ñ¢t something that can be accomplished by imposing a plan, even if we make various provisional and highly malleable √¢‚Ç¨Àúplans√¢‚Ç¨‚Ñ¢ on the fly as we go along.</p>
<p>Moreover, in working through our thoughts, feelings and circumstances in all their particularities, it√¢‚Ç¨‚Ñ¢s not that we√¢‚Ç¨‚Ñ¢re doing anything all that different from what countless others have had to do as they√¢‚Ç¨‚Ñ¢ve learned to cope with loss. Nonetheless √¢‚Ç¨‚Äú again, like carving wheels √¢‚Ç¨‚Äú it√¢‚Ç¨‚Ñ¢s plausibly a creative activity, in that it involves a spontaneous integration between contrasting types such as the grieving and the celebratory, the resentful and the grateful, the distressed and the joyous. The ability to live with death, too, in a sensitive, responsive, and well-integrated manner isn√¢‚Ç¨‚Ñ¢t learned by rote, but rather via engaging in sustained, spontaneous activity. Indeed, even the philosopher Zhuangzi himself can be understood as engaging in such a creative process after the death of his own wife in chapter 18 of the text, the <em>Zhi Le</em> (√®‚Ä°¬≥√¶¬®‚Äö), meaning √¢‚Ç¨ÀúPerfect Happiness√¢‚Ç¨‚Ñ¢ or √¢‚Ç¨ÀúPerfect Joy√¢‚Ç¨‚Ñ¢.</p>
<p><strong>This way of thinking</strong> about creativity has a variety of other potential benefits. First, even if creativity were taken to aim at originality, de-emphasising originality might ironically result in greater creativity. This is because striving for originality can actually be counterproductive when it comes to achieving genuinely fresh results: if we focus on the task of achieving something original, we√¢‚Ç¨‚Ñ¢ll explore only the range of possibilities deemed sufficiently likely to yield that result, leaving out a lot that could have contributed to achieving something original.</p>
<p>But imagine instead that we worked with idea that creativity wasn√¢‚Ç¨‚Ñ¢t about novelty. That doesn√¢‚Ç¨‚Ñ¢t mean we√¢‚Ç¨‚Ñ¢d have to give up the value of originality entirely, but rather see it as one of a range of possible outcomes. Casting a wider net in this way might hence make creativity (whatever it involves) easier to achieve.</p>
<p>Second, focusing on integration could encourage us to better understand creative agents as being intimately connected with, and products of, their environments. This would broaden our notion of creativity in a way that might allow us to see creativity demanded in a greater range of activities. After all, many of life√¢‚Ç¨‚Ñ¢s activities, from the mundane to the meaningful, aren√¢‚Ç¨‚Ñ¢t learned by rote, but rather via spontaneous action that integrates contrasting aspects. Just for starters, additional examples might include getting along with one√¢‚Ç¨‚Ñ¢s family, building relationships with colleagues and organising one√¢‚Ç¨‚Ñ¢s finances.</p>
<p>This alternative perspective on creativity might help us to see it as an everyday phenomenon in which we all participate √¢‚Ç¨‚Äú rather than an extraordinary talent or gift that only a few enjoy. And it might also allow us to make sense of the idea of <a href="https://link.springer.com/chapter/10.1007/978-3-319-43893-1_19#:~:text=As%20an%20art%20practice%2C%20calligraphy,Daoist%20aesthetic%20concerns%20discussed%20here.&amp;text=The%20aesthetic%20of%20the%20everyday,and%20the%20need%20for%20imagination">living creatively</a>: of an integrated life, lived spontaneously, in which all of life√¢‚Ç¨‚Ñ¢s contrasting aspects can be arranged to form a rich and variegated whole.</p></div></div></div>]]>
            </description>
            <link>https://psyche.co/ideas/to-be-creative-chinese-philosophy-teaches-us-to-abandon-originality</link>
            <guid isPermaLink="false">hacker-news-small-sites-24353137</guid>
            <pubDate>Wed, 02 Sep 2020 13:44:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I Actively Discourage Online Tooling like jwt.io and Online JSON Validators]]>
            </title>
            <description>
<![CDATA[
Score 197 | Comments 162 (<a href="https://news.ycombinator.com/item?id=24352360">thread link</a>) | @pcr910303
<br/>
September 2, 2020 | https://www.jvt.me/posts/2020/09/01/against-online-tooling/ | <a href="https://web.archive.org/web/*/https://www.jvt.me/posts/2020/09/01/against-online-tooling/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Something my colleagues know well is how little I trust online tools like <a href="https://jwt.io/">jwt.io</a>, online JSON validators or online tooling in general, but it also bleeds into <a href="https://www.jvt.me/mf2/2020/08/zebqf/">comments I make online</a> and in my blog posts, too, and I thought I'd share a little bit of a reason as to why.</p><p>Instead of using an online service, I will reach for a way to run it locally, using whichever programming language toolchain I have available. But why? Why wouldn't I recommend something like jwt.io? Or an online JSON validator, especially if they boast client-side functionality, and mean I don't need things installed?</p><p>Let's start with a bit of background. Firstly, I'd just like to caveat this all with the note that <strong>I have no access to Production data, customer or otherwise</strong>. All of these examples are referencing Non-Production examples.</p><p>I also want to caveat this with the fact that this is <strong>not a personal attack</strong> on jwt.io. I am using them as an example as they're a well-known and well-used service, and I've seen issues with it before. Auth0 run it, and are probably one of the few companies we'd want to be running it. It's also <a href="https://github.com/jsonwebtoken/jsonwebtoken.github.io">Open Source</a> <em>but</em> one of the great difficulties of Web-hosted services are that we have no idea if the source code that we're told is being used is actually being used!</p><p>I'm currently working on the Open Banking platform for Capital One. We're fortunate to have very restricted access to Production, which makes things safer for everyone. One thing we strive to do is to treat Non-Production secrets like Production ones where possible - where we shouldn't have access to them at all, and shouldn't be sharing them with external services. Some of these Non-Production secrets may be usable outside of Capital One, for instance Open Banking Sandbox signing certificates.</p><p>We perform a fair bit of testing in our Non-Production environments and sometimes need to debug things, such as what's inside a JWT (as Open Banking introduces several places they're used). I've been burned a number of times by folks putting a Non-Production JWT or an Open Banking Sandbox certificate into jwt.io. Although Non-Production, these are sensitive in of themselves, as they have implementation details for our services, and as mentioned, certain things could be used outside of Capital One.</p><p>The biggest reason I hear from folks using online tooling is that it's easier, and that they'd rather do that than find out how to run it locally. I disagree with this, but am quite biased, as I often have a blog post for many of these common issues. I love sharing my blog with others and having a handy solution, or if I don't have an answer to a problem, I'll find out how and <a href="https://www.jvt.me/tags/blogumentation/">blogument it for later</a>. So I see that reaching for online tooling is more just because we've got folks who aren't aware of how they could do otherwise.</p><p>One great thing about removing the need for an online tool is that you can self-serve it once you have the tools locally. You can run it locally when you've got no internet (which isn't as much of an issue in these Coronavirus times) but also regardless of whether the upstream service is broken. You can use it with other i.e. command-line tooling, for instance how I've set up <a href="https://gitlab.com/jamietanna/dotfiles-arch/-/blob/master/terminal/home/bin/unpack">this command-line script</a> to handle a lot of common data formats I deal with and unpack them to a human-readable format.</p><p>But most importantly, by telling people to put sensitive data (such as credentials, configuration files, etc) it's a really dangerous lesson for our teams. We're teaching people to blindly trust arbitrary websites that they don't have any relationship with, nor have fully audited the source code, when posting potentially sensitive data.</p><p>I realise this may not be something you do when running it locally, but it's less likely for a well-known library running locally to need to reach outbound.</p><p>jwt.io is an interesting example, because although it boasts that it runs as a client-side solution, you may not have been aware that <a href="https://github.com/jsonwebtoken/jsonwebtoken.github.io/commit/b362ab19a9f37e337b5f8ea38987aa680aa6e0a9">until last September</a>, there were metrics being determined which although may have seemed innocent, show that it's easy for other functionality to be hidden in a seemingly client-side-only website. Unless you audit everything, every time, you're in a risky position where you may be leaking data you're not expecting to.</p><p>I feel that we can do something to help services that handle potentially sensitive data with helping educate the user that they should be more careful, because jwt.io's warning definitely doesn't help with folks who don't fully appreciate what the risk is if jwt.io isn't actually as trustworthy as the user thinks:</p><blockquote><p>Warning: JWTs are credentials, which can grant access to resources. Be careful where you paste them! We do not record tokens, all validation and debugging is done on the client side.</p></blockquote><p>What do you think? Am I maybe being a little too sensitive? Am I not being sensitive enough?</p><p>Edit: Based on some conversations being had in response to the post, I thought it'd mention I've written about how to <a href="https://www.jvt.me/posts/2019/06/13/pretty-printing-jwt-openssl/">pretty-print a JWT locally with OpenSSL</a> and <a href="https://www.jvt.me/posts/2018/08/31/pretty-printing-jwt-ruby/">a Ruby alternative</a>.</p></div></div>]]>
            </description>
            <link>https://www.jvt.me/posts/2020/09/01/against-online-tooling/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24352360</guid>
            <pubDate>Wed, 02 Sep 2020 12:01:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[In Defense of a Switch]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 36 (<a href="https://news.ycombinator.com/item?id=24351706">thread link</a>) | @pkolaczk
<br/>
September 2, 2020 | https://pkolaczk.github.io/in-defense-of-switch/ | <a href="https://web.archive.org/web/*/https://pkolaczk.github.io/in-defense-of-switch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <header>
  
  <time datetime="2020-09-02T00:00:00+00:00">September 02, 2020</time>
</header>

  <p>Recently I came across a <a href="https://levelup.gitconnected.com/if-else-is-a-poor-mans-polymorphism-ab0b333b7265">blog post</a>
whose author claims, from the perspective of good coding practices, polymorphism is strictly superior to branching. 
In the post they make general statements about how branching statements lead to unreadable, unmaintainable, inflexible code and
how they are a sign of immaturity. However, in my opinion, the topic is much deeper and in this post 
I try to objectively discuss the reasons for and against branching.</p>

<!--more-->



<p>Before I dive into polymorphism vs branching dilemma, let‚Äôs first define what we mean when we say some code is
flexible and easy to extend. In my career I reviewed thousands of lines of code, and I had thousands of lines of my code
reviewed by others, and during these reviews it often occured that the terms <em>code extensibility</em> or <em>flexibility</em> 
mean different things to different people. Familiarity with the code-base or particular programming style plays a huge role.</p>

<p>For example, someone used to writing code in a Java/C# OOP style would generally consider dynamic polymorphism through 
interfaces a standard way of providing extensibility to the code, 
while a C programmer may find a switch or if/else much more 
approachable than OOP. There are also many other factors related 
to maintainability as quality of documentation, good naming, separation of concerns, etc. These factors are orthogonal 
to the ‚Äúpolymorphism vs branching‚Äù dimension and also far too broad for a single blog post, so I won‚Äôt discuss them.</p>

<p>For the sake of this post, let‚Äôs define <em>extensibility</em> as the inverse of number of distinct units in the codebase
that need to be changed in order to implement a new feature. The more places you have to touch to implement the feature, 
the harder the code is to change. Obviously, it is much better when you have to touch only
one unit of code (one function, one class, one module, one package) rather than change 10 distinct unrelated units.</p>


<p>Imagine you‚Äôre writing a calculator. Your program gets an expression as an input and outputs the computed value.
For example the user inputs <code>1 + 2 * 3</code> and the output is <code>7</code> 
(or <code>9</code> if you‚Äôve messed up the operator precedence like one of my former CS students).</p>

<p>Why such a silly example? Who is writing calculators these days? Probably no-one, but this looks like a classic example given
in many programming classes. And it is easy enough to illustrate the concept.</p>

<p>How can we model a structure to represent an expression?
You‚Äôd probably use classes or structures. Here is the code in Scala:</p>

<div><div><pre><code><span>trait</span> <span>Expression</span> <span>{</span>
    <span>def</span> <span>eval</span><span>:</span> <span>Double</span>
<span>}</span>

<span>case</span> <span>class</span> <span>Const</span><span>(</span><span>value</span><span>:</span> <span>Double</span><span>)</span> <span>extends</span> <span>Expression</span> <span>{</span>
    <span>def</span> <span>eval</span><span>:</span> <span>Double</span> <span>=</span> <span>value</span>
<span>}</span>

<span>case</span> <span>class</span> <span>Add</span><span>(</span><span>left</span><span>:</span> <span>Expression</span><span>,</span> <span>right</span><span>:</span> <span>Expression</span><span>)</span> <span>extends</span> <span>Expression</span> <span>{</span>
    <span>def</span> <span>eval</span><span>:</span> <span>Double</span> <span>=</span> <span>left</span><span>.</span><span>eval</span> <span>+</span> <span>right</span><span>.</span><span>eval</span>
<span>}</span>
</code></pre></div></div>

<p>Then it is quite easy to build an expression and evaluate it:</p>
<div><div><pre><code><span>Add</span><span>(</span><span>Const</span><span>(</span><span>2</span><span>),</span> <span>Const</span><span>(</span><span>3</span><span>)).</span><span>eval</span> <span>// evaluates to 5 </span>
</code></pre></div></div>


<p>This OOP-based solution is indeed very extensible when it comes to add a new operator.
The example above is missing subtraction operation. We can add one by defining a new class:</p>

<div><div><pre><code><span>case</span> <span>class</span> <span>Sub</span><span>(</span><span>left</span><span>:</span> <span>Expression</span><span>,</span> <span>right</span><span>:</span> <span>Expression</span><span>)</span> <span>extends</span> <span>Expression</span> <span>{</span>
    <span>def</span> <span>eval</span><span>:</span> <span>Double</span> <span>=</span> <span>left</span><span>.</span><span>eval</span> <span>-</span> <span>right</span><span>.</span><span>eval</span>
<span>}</span>
</code></pre></div></div>

<p>That‚Äôs really awesome ‚Äì we didn‚Äôt have to touch any old code at all! 
OOP definitely rocks here.</p>


<p>Imagine you continued to extend our calculation engine with more operation classes over the next few years.
You‚Äôve added multiplication, division, modulo, variables, logarithms, trigonometric functions, etc.</p>

<p>Then suddenly a new requirement comes ‚Äì users want to not only evaluate the value of an expression,
but also do symbolic manipulation ‚Äì e.g. simplify expressions. For example, given an expression
<code>a + a</code> they want to get an expression <code>2 * a</code> as a result.</p>

<p>This requirement can‚Äôt be captured by the <code>eval</code> method on the <code>Expression</code> interface. We need a new method:</p>

<div><div><pre><code><span>trait</span> <span>Expression</span> <span>{</span>
    <span>def</span> <span>eval</span><span>:</span> <span>Double</span>
    <span>def</span> <span>simplify</span><span>:</span> <span>Expression</span>
<span>}</span>
</code></pre></div></div>

<p>And as the next step, they would likely want to be able to display the expression as a String:</p>

<div><div><pre><code><span>trait</span> <span>Expression</span> <span>{</span>
    <span>def</span> <span>eval</span><span>:</span> <span>Double</span>
    <span>def</span> <span>simplify</span><span>:</span> <span>Expression</span>
    <span>def</span> <span>toString</span><span>:</span> <span>String</span>
<span>}</span>
</code></pre></div></div>

<p>How many units of code do you have to change now to implement these features?
<strong>All the implementations of <code>Expression</code></strong>. Before touching all the classes, the code wouldn‚Äôt even compile.
It looks like in the context of this kind of feature, our polymorphic solution is terribly non-extensible.</p>


<p>Let‚Äôs take a step back and let‚Äôs see how we could implement this differently.
Scala and many other modern languages have a feature called <em>pattern matching</em>
which can be considered a very flexible, powerful switch.</p>

<p>Instead of defining the operations like <code>eval</code> or <code>simplify</code> on the case classes,
let‚Äôs pull them up:</p>

<div><div><pre><code><span>trait</span> <span>Expression</span> <span>{</span>
<span>case</span> <span>class</span> <span>Const</span><span>(</span><span>value</span><span>:</span> <span>Double</span><span>)</span> <span>extends</span> <span>Expression</span>
<span>case</span> <span>class</span> <span>Add</span><span>(</span><span>left</span><span>:</span> <span>Expression</span><span>,</span> <span>right</span><span>:</span> <span>Expression</span><span>)</span> <span>extends</span> <span>Expression</span>


<span>def</span> <span>eval</span><span>(</span><span>e</span><span>:</span> <span>Expression</span><span>)</span><span>:</span> <span>Double</span> <span>=</span> <span>{</span>
  <span>e</span> <span>match</span> <span>{</span>
    <span>case</span> <span>Const</span><span>(</span><span>x</span><span>)</span> <span>=&gt;</span> <span>x</span>
    <span>case</span> <span>Add</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>)</span> <span>=&gt;</span> <span>a</span> <span>+</span> <span>b</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Now adding a new operation like <code>Sub</code> would require two changes to the code ‚Äì adding a new class
<em>and</em> adding a new case in the match (switch) statement.</p>

<p>Some may say this much worse not only because of more places to update, but because of a possibility of
forgetting to update the switches which could lead to runtime errors due to unhandled cases.
Fortunately, Scala designers thought about this by providing the <code>sealed</code> keyword, which instructs the compiler
that all case classes can be defined in the same module only. This unlocks pattern exhaustiveness analysis and the
compiler would warn about missing cases:</p>

<div><div><pre><code><span>sealed</span> <span>trait</span> <span>Expression</span>
<span>case</span> <span>class</span> <span>Const</span><span>(</span><span>value</span><span>:</span> <span>Double</span><span>)</span> <span>extends</span> <span>Expression</span>
<span>case</span> <span>class</span> <span>Add</span><span>(</span><span>left</span><span>:</span> <span>Expression</span><span>,</span> <span>right</span><span>:</span> <span>Expression</span><span>)</span> <span>extends</span> <span>Expression</span>

<span>def</span> <span>eval</span><span>(</span><span>e</span><span>:</span> <span>Expression</span><span>)</span><span>:</span> <span>Double</span> <span>=</span> <span>{</span>
  <span>e</span> <span>match</span> <span>{</span>
    <span>case</span> <span>Const</span><span>(</span><span>x</span><span>)</span> <span>=&gt;</span> <span>x</span>
    <span>case</span> <span>Add</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>)</span> <span>=&gt;</span> <span>a</span> <span>+</span> <span>b</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>What about adding new functions like <code>simplify</code> or <code>toString</code>? 
It requires to changle only <strong>one place</strong> ‚Äì by adding the required methods. 
No changes to the existing code are needed!</p>

<div><div><pre><code><span>def</span> <span>simplify</span><span>(</span><span>e</span><span>:</span> <span>Expression</span><span>)</span><span>:</span> <span>Expression</span> <span>=</span> <span>{</span>
  <span>e</span> <span>match</span> <span>{</span>
    <span>case</span> <span>Add</span><span>(</span><span>Const</span><span>(</span><span>0</span><span>),</span> <span>x</span><span>)</span> <span>=&gt;</span> <span>x</span>
    <span>case</span> <span>Add</span><span>(</span><span>x</span><span>,</span> <span>Const</span><span>(</span><span>0</span><span>))</span> <span>=&gt;</span> <span>x</span>
    <span>case</span> <span>other</span> <span>=&gt;</span> <span>other</span>
  <span>}</span>
<span>}</span>

<span>def</span> <span>toString</span><span>(</span><span>e</span><span>:</span> <span>Expression</span><span>)</span><span>:</span> <span>String</span> <span>=</span> <span>{</span>
  <span>e</span> <span>match</span> <span>{</span>
    <span>case</span> <span>Const</span><span>(</span><span>x</span><span>)</span> <span>=&gt;</span> <span>x</span><span>.</span><span>toString</span>
    <span>case</span> <span>Add</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>)</span> <span>=&gt;</span> <span>"("</span> <span>+</span> <span>toString</span><span>(</span><span>a</span><span>)</span> <span>+</span> <span>" + "</span> <span>+</span> <span>toString</span><span>(</span><span>b</span><span>)</span> <span>+</span> <span>"</span><span>)</span> 
  <span>}</span>
<span>}</span>
</code></pre></div></div>


<p>The blog post I mentioned in the introduction stated that using polymorphism instead of
branching leads to more readable code. I find this statement far too general and actually very debatable.</p>

<p>First, even in their own example given by the author of that blog, the solution using branching was a lot
shorter and less complex than the solution using OOP. While brief code is not always more readable than a longer version of it,
in that case, I found branching to be very explicit and easy to follow. 
It is much easier to understand the control flow
in such a program because all targets are explicitly given in a single place. In the OOP solution, 
the actual implementations are hidden behind the interface and it is much harder to find them all without additional 
help of a good IDE with a ‚Äújump to implementations‚Äù feature 
(which fortunately often works well for statically typed languages, but I‚Äôve seen IDEs sometimes 
struggle with dynamic languages like Python).</p>

<p>Second, in general case, branching has an advantage that the function logic may depend on more than
one object type or even the actual data. For example, in the example from this post, 
the transformation <code>a * (b + c)</code> =&gt; <code>a * b + a * c</code> would depend on 
both addition and multiplication. In the classic OOP solution, would you place it in the <code>Add</code> or in the <code>Mul</code> class? 
Neither seems right. Also, putting it into one of them creates a dependency on the other one. 
An expression simplifier with code scattered accross multiple classes heavily depending on each other 
would be hard to understand.</p>


<p>This is a blog on high performance programming, so the post would be incomplete without a 
section on performance. In theory, a sufficiently good compiler should produce the same
code regardless of the choice between branching or dynamic polymorphism, but is this the case in reality?
Compilers have limitations and often don‚Äôt generate the best result code possible.</p>

<p>Let‚Äôs consider a more realistic example this time.
Some time ago I was working on serializing/deserializing code in a database system.
I stumbled upon a set of classes that described data types. They all implemented 
a common interface defining methods for serializing and deserializing values of given data type
and also computing serialized data lenghts. The following Rust snippet is a huge simplification 
of that code, but it illustrates the concept:</p>

<div><div><pre><code><span>pub</span> <span>trait</span> <span>DataType</span> <span>{</span>
    <span>fn</span> <span>len</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>usize</span><span>;</span>
<span>}</span>

<span>pub</span> <span>struct</span> <span>BoolType</span><span>;</span>
<span>pub</span> <span>struct</span> <span>IntType</span><span>;</span>
<span>pub</span> <span>struct</span> <span>LongType</span><span>;</span>

<span>impl</span> <span>DataType</span> <span>for</span> <span>BoolType</span> <span>{</span>
    <span>fn</span> <span>len</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>usize</span> <span>{</span> <span>1</span> <span>}</span>
<span>}</span>

<span>impl</span> <span>DataType</span> <span>for</span> <span>IntType</span> <span>{</span>
    <span>fn</span> <span>len</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>usize</span> <span>{</span> <span>4</span> <span>}</span>
<span>}</span>

<span>impl</span> <span>DataType</span> <span>for</span> <span>LongType</span> <span>{</span>
    <span>fn</span> <span>len</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>usize</span> <span>{</span> <span>8</span> <span>}</span>
<span>}</span>

<span>pub</span> <span>fn</span> <span>data_len</span><span>(</span><span>data_type</span><span>:</span> <span>&amp;</span><span>dyn</span> <span>DataType</span><span>)</span> <span>-&gt;</span> <span>usize</span> <span>{</span>
    <span>data_type</span><span>.len</span><span>()</span>
<span>}</span>
</code></pre></div></div>

<p>Given a reference to a <code>DataType</code> object, it is trivial to compute the data size associated with it, 
without knowing the exact static type:</p>

<div><div><pre><code><span>let</span> <span>t1</span> <span>=</span> <span>IntType</span><span>;</span>
<span>let</span> <span>t2</span> <span>=</span> <span>LongType</span><span>;</span>
<span>let</span> <span>v</span><span>:</span> <span>Vec</span><span>&lt;&amp;</span><span>dyn</span> <span>DataType</span><span>&gt;</span> <span>=</span> <span>vec!</span><span>[</span><span>&amp;</span><span>t1</span><span>,</span> <span>&amp;</span><span>t2</span><span>];</span>
<span>println!</span><span>(</span><span>"{}"</span><span>,</span> <span>data_len</span><span>(</span><span>v</span><span>[</span><span>0</span><span>]));</span>  <span>// prints 4</span>
<span>println!</span><span>(</span><span>"{}"</span><span>,</span> <span>data_len</span><span>(</span><span>v</span><span>[</span><span>1</span><span>]));</span>  <span>// prints 8</span>
</code></pre></div></div>

<h2 id="performance-of-dynamic-dispatch">Performance of Dynamic Dispatch</h2>

<p>The implementation of the <code>data_len</code> function is actually very simple:</p>


<p>Wow! A single assembly instruction! 
It jumps to the address stored in the the vtable of the object pointed by the <code>rsi</code> register.
The target of the jump depends on the actual type of the object. Here is the code generated for <code>IntType.len</code>:</p>



<p>The codes for the other types differ only in the constant value.</p>

<p>These are only 3 instructions to return the result. Shouldn‚Äôt it be fast? 
Let‚Äôs measure this. Let‚Äôs put more random <code>DataType</code> objects ‚Ä¶</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pkolaczk.github.io/in-defense-of-switch/">https://pkolaczk.github.io/in-defense-of-switch/</a></em></p>]]>
            </description>
            <link>https://pkolaczk.github.io/in-defense-of-switch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24351706</guid>
            <pubDate>Wed, 02 Sep 2020 10:11:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kubernetes: Make your services faster by removing CPU limits]]>
            </title>
            <description>
<![CDATA[
Score 122 | Comments 99 (<a href="https://news.ycombinator.com/item?id=24351566">thread link</a>) | @iansinnott
<br/>
September 2, 2020 | https://erickhun.com/posts/kubernetes-faster-services-no-cpu-limits/ | <a href="https://web.archive.org/web/*/https://erickhun.com/posts/kubernetes-faster-services-no-cpu-limits/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>At Buffer, we‚Äôve been using <a href="https://kubernetes.io/case-studies/buffer/">Kubernetes since 2016</a>.  We‚Äôve been managing our k8s (kubernetes) cluster with <a href="https://kops.sigs.k8s.io/">kops</a>, it has about 60 nodes (on AWS), and runs about 1500 containers. Our transition to a micro-service architecture has been full of trial and errors. Even after a few years running k8s, we are still learning its secrets. This post will talk about how something we thought was a good thing, but ended up to be not as great as we thought: <strong>CPU limits</strong>.</p>
<h2 id="cpu-limits-and-throttling">CPU limits and Throttling</h2>
<p>It is s general recommendation to set CPU limits. <a href="https://cloud.google.com/blog/products/gcp/kubernetes-best-practices-resource-requests-and-limits">Google, among others, highly recommends it</a>. The danger of not setting a CPU limit is that containers running in the node could exhaust all CPU available. This can trigger a cascade of unwanted events such as having key Kubernetes processes (such as <code>kubelet</code>) to become unresponsive. So it is in theory a great thing to set CPU limit in order to protect your nodes.</p>
<p>CPU limits is the maximum CPU time a container can uses at a given period (100ms by default). The CPU usage for a container will never go above that limit you specified. Kubernetes use a mechanism called <a href="https://en.wikipedia.org/wiki/Completely_Fair_Scheduler">CFS Quota</a> to <strong>throttle</strong> the container to prevent the CPU usage from going above the limit. That means CPU will be artificially restricted, making the performance of your containers lower (and slower when it comes to latency).</p>
<h2 id="what-can-happen-if-we-dont-set-cpu-limits">What can happen if we don‚Äôt set CPU limits?</h2>
<p>We unfortunately experienced the issue. The <code>kubelet</code> , a process running on every node, and in charge of managing the containers (pods)  in the nodes became unresponsive. The node will turn into a <code>NotReady</code> state, and containers (pods) that were present will be rescheduled somewhere else, and create the issue in the new nodes. Definitely not ideal isn‚Äôt it?</p>
<h2 id="discovering-the-throttling-and-latency-issue">Discovering the throttling and latency issue</h2>
<p>A key metric to check when you are running container is the <code>throttling</code> . This indicate the number of time your container has been throttled. Interestingly, we‚Äôve discovered a lot of containers having throttling no matter if the CPU usage was near the limits or not. Here the example of one of our main API:</p>
<p><img src="https://erickhun.com/img/kubernetes-cpu-limits/cpu-usage-limits.png" alt="Kubernetes pods CPU usage and limits"></p>
<p>You can see in the animation that the CPU limits is set at <code>800m</code> (0.8 core, 80% of a core), and the peak usage is at most <code>200m</code> (20% of a core). After seeing, we might think we have plenty of CPU to let the service running before it throttle right? . Now check this one out:</p>
<p><img src="https://erickhun.com/img/kubernetes-cpu-limits/cpu-throttling-low-usage.gif" alt="Kubernetes pods Low CPU usage, High limit, lot of throttling"></p>
<p>You can notice the CPU throttling occurs, even though the CPU usage is below the CPU Limits. The maximum CPU usage isn‚Äôt even near the CPU limits.</p>
<p>We‚Äôve then found a few resources(<a href="https://github.com/kubernetes/kubernetes/issues/67577">github issue</a>, <a href="https://www.youtube.com/watch?v=LpFApeaGv7A&amp;feature=youtu.be&amp;t=1204">zanado talk</a>,  <a href="https://medium.com/omio-engineering/cpu-limits-and-aggressive-throttling-in-kubernetes-c5b20bd8a718">omio post</a>) talking about how throttling lead to poorer performances and latency for your services.</p>
<p><strong>Why do we see CPU throttling while CPU usage is low?</strong>
The tldr is basically a bug in the Linux kernel throttling unecessarly containers with CPU limit. If you‚Äôre curious about the nature of it, I invite you to check Dave Chiluk‚Äôs <a href="https://www.youtube.com/watch?v=UE7QX98-kO0">great talk</a>, a <a href="https://engineering.indeedblog.com/blog/2019/12/unthrottled-fixing-cpu-limits-in-the-cloud/">written version</a> also exists with more details.</p>

<p>After many long discussions, we‚Äôve decided to remove the CPU limits for all services that were directly or indirectly on the critical path of our users.</p>
<p>This wasn‚Äôt an easy decision since we value the stability of our cluster. We‚Äôve experimented in the past some instability in our cluster with services using too much resources and disrupting all other services present in the same node.  That time was a bit different, we understood more about how our services needed to be and had a good strategy to roll this out.</p>
<p><img src="https://erickhun.com/img/kubernetes-cpu-limits/unleash-k8s.jpg" alt="Buffer-remove-cpu-limits-announcement"></p>
<h2 id="how-to-keep-your-nodes-safe-when-removing-limits-">How to keep your nodes safe when removing limits ?</h2>
<p><strong>Isolating ‚ÄúNo CPU Limits‚Äù services:</strong></p>
<p>In the past we‚Äôve seen some nodes going to a <code>notReady</code> state, mainly because some services were using too much resources in a node.</p>
<p>We‚Äôve decided to put those services on some specific nodes (tainted nodes), so those services will not disrupt all the ‚Äúbounded‚Äù ones.  We have better control and could identify easier if any issue occurs with a node. We did this by tainting some nodes and adding toleration to services that were ‚Äúunbounded‚Äù. Check <a href="https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/">the documentation</a> on how you can do that.</p>
<p><img src="https://erickhun.com/img/kubernetes-cpu-limits/buffer-k8s-infrastructure-nodes.jpg" alt="Buffer k8s nodes infrastructure"></p>
<p><strong>Assigning the correct CPU and memory request:</strong></p>
<p>The main worry we had was service using too much resources and leading to nodes becoming unresponsive. Because we now had great observability of all services running in our cluster (with Datadog), I‚Äôve analyzed a few months of usage of each service we wanted to ‚Äúunbound‚Äù. I‚Äôve assigned the maximum CPU usage as the CPU request with a &gt; 20% margin. This will make sure to have allocated space in a node. If k8s won‚Äôt try to schedule any other service in that node.</p>
<p><img src="https://erickhun.com/img/kubernetes-cpu-limits/choose-cpu-request-based-on-max.png" alt="Chose CPU request based on max"></p>
<p>You can see in the graph that the peak CPU usage was <code>242m</code> CPU core (0.242 CPU core). Simply take this number and make it a bit higher to become the CPU request. You can notice that since the service is user facing, the peak CPU usage matches peak traffic time.</p>
<p>Do the same with your memory usage and requests, and you will be all set!
To add more safety, you can use the horizontal pod autoscaler to create new pods if the resource usage is high, so kubernetes will schedule it in nodes that have room for it. Set an alert if your cluster do not have any room, or use the node austoscaler to add it automatically.</p>
<p>The downsides are that we lose in ‚Äú<a href="https://wiki.openvz.org/WP/Containers_density">container density</a>‚Äù, the number of containers that can run in a single node. We could also end up with a lot of ‚Äúslack‚Äù during a low traffic time.
You could also hit some high CPU usage, but nodes autoscaling should help you with it.</p>
<h2 id="results">Results</h2>
<p>I‚Äôm happy to publish really great results after few weeks of experimentation, we‚Äôve already seen really great latency improvements across all the services we‚Äôve modified:</p>
<p><img src="https://erickhun.com/img/kubernetes-cpu-limits/speedup-no-cpu-limits2.png" alt="faster-kubernetes-containers"></p>
<p>The best result happened on our main landing page (<a href="https://buffer.com/">buffer.com</a>) where we speed the service up to <strong>22x</strong> faster!</p>
<p><img src="https://erickhun.com/img/kubernetes-cpu-limits/no-cpu-limit-speedup-buffer-com.jpg" alt="buffer.com speedup without cpu limits"></p>
<h2 id="is-the-linux-kernel-bug-fixed">Is the Linux kernel bug fixed?</h2>
<p>The bug <a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=763a9ec06c4">has been fixed and merged into the kernel</a> for Linux distribution running 4.19 or higher (kudo again to <a href="https://twitter.com/dchiluk">Dave Chiluk</a> for finding and fixing that).</p>
<p>However, as for <em>September 2nd 2020</em>, when reading <a href="https://github.com/kubernetes/kubernetes/issues/67577">the kubernetes issue</a>, we can see various Linux projects that keep referencing the issue, so I guess some Linux distribution still have the bug and working into integrating the fix.</p>
<p>If you are below a Linux distribution that has a kernel version below 4.19, I‚Äôd recommend you to upgrade to the latest Linux distribution for your nodes, but in any case, you should try removing the CPU limits and see if you have any throttling.  Here a non exhausting list of various managed Kubernetes services or Linux distribution:</p>
<ul>
<li>Debian: The latest version <a href="https://erickhun.com/posts/kubernetes-faster-services-no-cpu-limits/%5Bhttps://www.debian.org/releases/buster/">buster</a> has the fix,  it looks <a href="https://tracker.debian.org/news/1167353/accepted-linux-latest-419-105deb10u5deb9u1-source-amd64-into-oldstable-oldstable/">quite recent (august 2020)</a>. Some previous version might have get patched</li>
<li>Ubuntu: The latest version <a href="https://releases.ubuntu.com/20.04/">Ubuntu Focal Fosa 20.04</a> has the fix.</li>
<li>EKS has the fix since <a href="https://github.com/aws/containers-roadmap/issues/175">December 2019</a>. Upgrade your AMI if you have a version below than that</li>
<li>kops: Since <a href="https://github.com/kubernetes/kops/pull/9283">June 2020</a>,  <code>kops 1.18+</code> will start using <code>Ubuntu 20.04</code> as the default host image. If you‚Äôre using a lower version of kops, you‚Äôll have to probably to wait the fix. We are currently in this situation.</li>
<li>GKE (Goggle Cloud) : The kernel fix was merged in <a href="https://cloud.google.com/container-optimized-os/docs/release-notes#cos-stable-77-12371-141-0">January 2020</a>. But it does looks like throttling are <a href="https://news.ycombinator.com/item?id=24356903">still hapenning</a></li>
</ul>
<p>ps: Feel free to <a href="https://news.ycombinator.com/item?id=24351566">comment</a> if you have more precise information, I‚Äôll update the post accordingly</p>
<p><strong>If the fix solved the throttling issue?</strong></p>
<p>I‚Äôm unsure if totally solved the issue. I will give it a try once we hit a kernel version where the fix has been implemented and will update this post accordingly. If anyone have upgrade I‚Äôm keen to hear their results.</p>
<h2 id="takeaways">Takeaways</h2>
<ul>
<li>If you run Docker containers under Linux (no matter Kubernetes/Mesos/Swarm) you might have your containers underperforming because of throttling</li>
<li>Upgrade to the latest version of your distribution hoping the bug is fixed</li>
<li>Removing CPU limit is a solution to solve this issue, but this is dangerous and should be made with extra-care (prefer upgrading your kernel first and monitor throttling first)</li>
<li>If you remove CPU limits, carefully monitor CPU and  memory usage in your nodes, and make sure your CPU requests are</li>
<li>A safe way to is to use the Horizontal pod autoscaler to create new pods if the resource usage is high, so kubernetes will schedule it in nodes that have space.</li>
</ul>
<p>üëâ<strong>Hacker news update: lot of insighful <a href="https://news.ycombinator.com/item?id=24351566">comments</a>. I‚Äôve updated the post to have better recommendations. You should prefer upgrading your kernel version over removing the CPU limits. Be really mindful, set the proper CPU requests, add the necessary monitoring when you do this</strong></p>
<p>I hope this post helps you get performance gains on the containers you are running. If so, don‚Äôt hesitate to share or <a href="https://news.ycombinator.com/item?id=24351566">comment</a> with always some insighful comments</p>
<p>Special thanks to <a href="https://www.linkedin.com/in/dilyevsky/">Dmitry</a>, <a href="https://coderanger.net/">Noah</a> and <a href="https://mydev.org/">Andre</a> that adviced me on this.</p>
<h4 id="next-reads">Next reads:</h4>
<p>üëâ <a href="https://erickhun.com/posts/why-you-should-have-a-side-project/">Why you should have a side project</a></p>
<p>üëâ <a href="https://erickhun.com/posts/sharing-knowledge-in-a-remote-team/">How we share technical knowledge in a remote team, across timezones</a></p>




        <center>

            
            <a href="https://twitter.com/eric_khun" data-size="large" data-show-count="true">Follow @eric_khun</a>
            <br>
            <a href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2ferickhun.com%2fposts%2fkubernetes-faster-services-no-cpu-limits%2f&amp;s=fb" target="_blank" rel="noopener" aria-label="Facebook">
              
            </a>
  
            
            <a href="https://twitter.com/intent/tweet/?text=Kubernetes%3a%20Make%20your%20services%20faster%20by%20removing%20CPU%20limits%20by%20@eric_khun%20&amp;url=https%3a%2f%2ferickhun.com%2fposts%2fkubernetes-faster-services-no-cpu-limits%2f&amp;s=tw" target="_blank" rel="noopener" aria-label="Twitter">
              
            </a>
  
            
            <a href="https://erickhun.com/cdn-cgi/l/email-protection#82bdf1f7e0e8e7e1f6bfc9f7e0e7f0ece7f6e7f1a7b1e3a7b0b2cfe3e9e7a7b0b2fbedf7f0a7b0b2f1e7f0f4ebe1e7f1a7b0b2e4e3f1f6e7f0a7b0b2e0fba7b0b2f0e7efedf4ebece5a7b0b2c1d2d7a7b0b2eeebefebf6f1a2a4e3eff2b9e0ede6fbbfc9f7e0e7f0ece7f6e7f1a7b1e3a7b0b2cfe3e9e7a7b0b2fbedf7f0a7b0b2f1e7f0f4ebe1e7f1a7b0b2e4e3f1f6e7f0a7b0b2e0fba7b0b2f0e7efedf4ebece5a7b0b2c1d2d7a7b0b2eeebefebf6f1a2afa2eaf6f6f2f1a7b1e3a7b0e4a7b0e4e7f0ebe1e9eaf7ecace1edefa7b0e4f2edf1f6f1a7b0e4e9f7e0e7f0ece7f6e7f1afe4e3f1f6e7f0aff1e7f0f4ebe1e7f1afecedafe1f2f7afeeebefebf6f1a7b0e4a4f1bfe7efe3ebee" target="_self" rel="noopener" aria-label="E-Mail">
              
            </a>
  
            
            <a href="https://reddit.com/submit/?url=https%3a%2f%2ferickhun.com%2fposts%2fkubernetes-faster-services-no-cpu-limits%2f&amp;resubmit=true&amp;title=Kubernetes%3a%20Make%20your%20services%20faster%20by%20removing%20CPU%20limits&amp;s=red" target="_blank" rel="noopener" aria-label="Reddit">
              
            </a>
  
            
            <a href="whatsapp://send?text=Kubernetes%3a%20Make%20your%20services%20faster%20by%20removing%20CPU%20limits%20-%20https%3a%2f%2ferickhun.com%2fposts%2fkubernetes-faster-services-no-cpu-limits%2f&amp;s=whatsapp" target="_blank" rel="noopener" aria-label="WhatsApp">
              
            </a>
    
          </center>
      </div></div>]]>
            </description>
            <link>https://erickhun.com/posts/kubernetes-faster-services-no-cpu-limits/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24351566</guid>
            <pubDate>Wed, 02 Sep 2020 09:47:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Hash Monster: ESP-32 Tamagotchi for WiFi Cracking]]>
            </title>
            <description>
<![CDATA[
Score 167 | Comments 25 (<a href="https://news.ycombinator.com/item?id=24351269">thread link</a>) | @wolframio
<br/>
September 2, 2020 | https://telescope.ac/petazzoni/the-hash-monster-esp32-tamagotchi-for-wifi-cracking | <a href="https://web.archive.org/web/*/https://telescope.ac/petazzoni/the-hash-monster-esp32-tamagotchi-for-wifi-cracking">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>Would you like to have a portable WiFi capture tool that fits in your pocket? A device that saves PCAP captures into micro sd card to later review them on Wireshark or crack those WPA / WPA2 passphrases. Sounds like something out of the <a href="https://nsa.gov1.info/dni/nsa-ant-catalog/wireless-lan/index.html" target="_blank" rel="nofollow noopener">NSA spy WiFi toolset</a> but It's very easy to setup with the ESP32 WiFi Hash Monster and the <a href="https://bit.ly/3jFAnl8" target="_blank" rel="nofollow noopener">M5 Stack Development Kit</a>.</p><p><img src="https://telescopecdn.ams3.digitaloceanspaces.com/images/37366466393830322d656263312d343530392d396463372d653761313033646136666237/5658dfbd47952c4395bccb7da3699c7ff86527064f6b43771f3da3456ec43fa9.png"></p><p><strong>The Hash Monster</strong></p><p>If you are now thinking it seems similar to the <a href="https://www.vice.com/en_us/article/xwekw4/pwnagotchi-is-the-open-source-handheld-that-eats-wi-fi-handshakes" target="_blank" rel="nofollow noopener">Pwnagotchi project</a> and is not causal, G4lile0 the author of Hash Monster was inspired by it to make an alternative that runs on the M5 Stack Development Kit, an ESP32 powered portable platform. ESP32 is a series of dual-core up to 240Mhz, low-cost, low-power system on a chip microcontroller with integrated Wi-Fi and dual-mode Bluetooth/BLE.</p><p><img src="https://telescopecdn.ams3.digitaloceanspaces.com/images/37366466393830322d656263312d343530392d396463372d653761313033646136666237/ac7ba2d12ae49bb808d323edae91463b7f97656872f7d24c91dab86d4ba1653d.jpeg"></p><p>Pwnagotchi is a tamagochi like device powered by bettercap and running on a Raspberry Pi Zero W that learns from its surrounding WiFi environment in order to maximize the crackable WPA key material it captures (either through passive sniffing or by performing deauthentication and association attacks). This material is collected on disk as PCAP files containing any form of handshake supported by hashcat, including full and half WPA handshakes as well as PMKIDs. Or put quickly, it's a tamagochi who eats WiFi handshakes to be happy.</p><p>Hash Monster runs in a smaller size and cheaper platform superior to the Pwnagotchi in several aspects. While Pwnagotchi is based on the Raspberry Pi Zero and requires assembling a DIY kit with various components such as an eInk screen and an external powerbank, the Hash Monster works on directly on the tiny M5Stack device. M5 Stack couples an ESP32 with a small LCD display, buttons and internal battery. It‚Äôs a modular, stackable, scalable, and portable device which is powered with an ESP-32 core, which makes it open source, low cost, full-function, and easy for developers to handle ESP32 IoT product development. You can program M5Stack through Arduino, C++, Blockly or MicroPython to name a few. The complete development kit for M5 Stack just under $45 provides a friendly price and full-featured resources which makes it a good starter kit for you to explore ESP32. While the M5 Stack includes a built-in battery 110mAh, it can be upgraded with a stackable 700 mAh lipo battery extension module.</p><p><img src="https://telescopecdn.ams3.digitaloceanspaces.com/images/37366466393830322d656263312d343530392d396463372d653761313033646136666237/615059260bcadb5085e71de543154bec6c52222f5d1efda91cdcafdbe403cce2.png"></p><p>The similarity between Pwnagotchi and Hash Monster is that they capture both PSK handshakes from WPA / WPA2 networks and PSK hashes contained in beacon frames with PMKID. A great advantage of PMKID cracking is that everything you need is available over the air even if there are no stations connected and only a single packet capture is required. Later we can crack these hashes with standard tools such as aircrack or hashcat, and thus obtain the credentials. Of course, we should only do this in networks that we manage ourselves or that we have permission to audit.</p><p><strong>The process.</strong></p><p>Hardware requirements:</p><ul><li><a href="https://bit.ly/3jFAnl8" target="_blank" rel="nofollow noopener">M5Stack CORE Development Kit</a> with built-in 110mAh Battery ($45)</li></ul><p>Optionally:</p><ul><li><a href="https://bit.ly/3gYtI48" target="_blank" rel="nofollow noopener">Extended Battery M5Stack Core Development Kit Capacity 700mAh Stackable Module</a> (USD$12)</li><li><a href="https://www.banggood.com/M5Stack-Multi-function-Digital-Watch-with-700mAh-Battery-for-M5Stack-ESP32-Core-p-1551727.html?rmmds=search&amp;cur_warehouse=CN" target="_blank" rel="nofollow noopener">Smart Watch Module with 700mAh Battery for M5Stack ESP32 Core</a> ($15)</li></ul><p>The software installation is pretty straight forward:</p><p>1.Setup Arduino IDE environment.</p><p><em>M5Stack Arduino IDE Setup in 5 minutes <a href="https://www.youtube.com/watch?v=U2es-l4z2Zg" target="_blank" rel="nofollow noopener">https://www.youtube.com/watch?v=U2es-l4z2Zg</a></em></p><p>2. Add M5 stack / ESP32 library. (read the <a href="https://docs.m5stack.com/" target="_blank" rel="nofollow noopener">M5 Stack documentation</a> , its pretty solid. As far as ‚Äúinstallation‚Äù goes)</p><p>3. Git clone G4lile0 code.</p><p><a href="https://github.com/G4lile0/ESP32-WiFi-Hash-Monster" target="_blank" rel="nofollow noopener">https://github.com/G4lile0/ESP32-WiFi-Hash-Monster</a></p><p>4. Compile &amp; upload the file to the M5Stack.</p><p>5. Go handshake/PMKID fishing.</p><p>6. Review captures.</p><p>The monster hash saves the files in the micro sd card in pcap format so they can be used by most network analysis tools directly. The files are saved sequentially with the pattern 1.pcap, 2.pcap, etc.</p><p><img src="https://telescopecdn.ams3.digitaloceanspaces.com/images/37366466393830322d656263312d343530392d396463372d653761313033646136666237/3dfd72fd0d7415f58f7320b77d722a313f4568f49c863c9bbb502f18d8f454f9.png"></p><p><strong>Cracking notes: Aircrack &amp; hashcat.</strong></p><p>In order to complete this tutorial, we will try doing dictionary attacks against a handshake file from Hash Monster. We will do this with two known tools ‚Äì Aircrack-ng and Hashcat, which relies respectively on CPU and GPU power. We will be running these tools from linux, even though they are both found in a Windows version as well. Remember to use recent versions to benefit from the PMKID attack in addition to the traditional cracking of handshakes.</p><p><img src="https://telescopecdn.ams3.digitaloceanspaces.com/images/37366466393830322d656263312d343530392d396463372d653761313033646136666237/adb3724e47a02d9fe14b83454cae422f882a9c99ccc78f0f2db6ef6e7a7f6f9b.png"></p><p>Aircrack-ng can be used for very basic dictionary attacks running on your CPU. Before you run the attack you need a wordlist. I recommend using the infamous rockyou dictionary file:</p><p># download the 134MB rockyou dictionary file</p><pre><code><code>curl -L -o rockyou.txt https://github.com/brannondorsey/naive-hashcat/releases/download/data/rockyou.txt</code></code></pre><p>Note, that if the network password is not in the wordlist you will not crack the password.</p><p># -a2 specifies WPA2, -b is the BSSID, -w is the wordfile</p><pre><code><code>aircrack-ng -a2 -b AC:FC:E3:C9:AB:C0 -w rockyou.txt 3.cap</code></code></pre><p>If the password is cracked you will see a KEY FOUND! message in the terminal followed by the plain text version of the network password.</p><p>Cracking an WiFi password using brute force attack for a long WiFi password without GPUs or Cloud help, will be a nightmare but if the password is short or you know the key pattern it will be "easily" cracked.</p><p>Here you have a small guide for linux (Ubuntu) to crack the WiFi password using the files stored on the SD_Card of the Purple Hash Monster using your computer.</p><p>First we need to install <strong>hashcat</strong></p><pre><code><code>sudo apt-get update</code><br>
<code> sudo apt install hashcat</code></code></pre><p>EAPOL/PMKID stored on the SD-Card are <em>pcap</em> files, we have to convert to <em>hccapx</em> format to work with hashcat. In terminal from the directory were we have the <em>pcap</em> file from the SD-CARD:</p><pre><code><code>wget https://raw.githubusercontent.com/hashcat/hashcat-utils/master/src/cap2hccapx.c</code><br>
<code> gcc -o cap2hccapx cap2hccapx.c</code><br>
<code> ./cap2hccapx 1.pcap 1.hccapx</code></code></pre><p>For example if we know that the wifi password has a lenght of 8 digits we can run the following command, and in few seconds we will have the WiFi Password :)</p><pre><code><code>hashcat --force -m 2500 -a 3 -1 ?d -o cracked 1.hccapx ?1?1?1?1?1?1?1?1</code></code></pre><p><strong>Final notes</strong></p><p>Although in my case I exclusively use the M5 Stack for the pocket monster hash, there are undoubtedly several projects that run on the M5 Stack and you will certainly want to take a look if you are interested in wifi and bluetooth security attack tools for this platform.</p><p>M5 Stack WiFi SSID Scanner by Elkentaro</p><p><a href="https://github.com/elkentaro/M5_SSID_scanner_collector" target="_blank" rel="nofollow noopener">https://github.com/elkentaro/M5_SSID_scanner_collector</a></p><p>Covid Sniffer: BLE COVID exposure app sniffer using M5 Stack</p><p><a href="https://gitlab.com/mschmidl/covidsniffer" target="_blank" rel="nofollow noopener">https://gitlab.com/mschmidl/covidsniffer</a></p><p><img src="https://telescopecdn.ams3.digitaloceanspaces.com/images/37366466393830322d656263312d343530392d396463372d653761313033646136666237/02ee78aa44062073eb950642e19a44a548daf55d3217643f1a98cc84d37bc7d6.jpeg"></p></article></div>]]>
            </description>
            <link>https://telescope.ac/petazzoni/the-hash-monster-esp32-tamagotchi-for-wifi-cracking</link>
            <guid isPermaLink="false">hacker-news-small-sites-24351269</guid>
            <pubDate>Wed, 02 Sep 2020 08:51:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Economics of Skyscraper Height]]>
            </title>
            <description>
<![CDATA[
Score 75 | Comments 73 (<a href="https://news.ycombinator.com/item?id=24351069">thread link</a>) | @keiferski
<br/>
September 2, 2020 | https://buildingtheskyline.org/economics-of-skyscraper-height-series/ | <a href="https://web.archive.org/web/*/https://buildingtheskyline.org/economics-of-skyscraper-height-series/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><main><article class="page"><div><p><img src="https://buildingtheskyline.org/wp-content/uploads/2019/06/re-manhattan-skyline-1.jpg" alt="" width="978" height="652" srcset="https://buildingtheskyline.org/wp-content/uploads/2019/06/re-manhattan-skyline-1.jpg 978w, https://buildingtheskyline.org/wp-content/uploads/2019/06/re-manhattan-skyline-1-300x200.jpg 300w, https://buildingtheskyline.org/wp-content/uploads/2019/06/re-manhattan-skyline-1-768x512.jpg 768w, https://buildingtheskyline.org/wp-content/uploads/2019/06/re-manhattan-skyline-1-640x427.jpg 640w" sizes="(max-width: 978px) 100vw, 978px"></p>
<hr>
<p><a href="http://buildingtheskyline.org/skyscraper-height-i" target="_blank" rel="noopener noreferrer">The Economics of Skyscraper Height (Part I)</a></p>
<p><a href="https://www.jasonmbarr.com/" target="_blank" rel="noreferrer noopener" aria-label="Jason M. Barr&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; December 17, 2018 (opens in a new tab)">Jason M. Barr</a>&nbsp;&nbsp;&nbsp;&nbsp; December 17, 2018</p>
<p>Many people look at skyscrapers around the world and conclude they are unnecessarily tall. This blog post discusses the economics of skyscraper height. Contrary to popular belief, most skyscrapers have a strong economic rational. <a href="http://buildingtheskyline.org/skyscraper-height-i" target="_blank" rel="noopener noreferrer">Read More ¬ª</a></p>
<hr>
<p><a href="http://buildingtheskyline.org/skyscraper-height-ii/" target="_blank" rel="noopener noreferrer">The Economics of Skyscraper Height (Part II)</a></p>
<p><a href="https://www.jasonmbarr.com/" target="_blank" rel="noreferrer noopener" aria-label="Jason M. Barr&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; December 17, 2018 (opens in a new tab)">Jason M. Barr</a>&nbsp;&nbsp;&nbsp;&nbsp; January 3, 2019</p>
<p>What drives the heights of the world‚Äôs tallest buildings? This post reviews some of the theories that may causes skyscrapers to be economically ‚Äútoo tall.‚Äù Some theories are ‚Äúnefarious,‚Äù some are benign, while others are productive. <a href="http://buildingtheskyline.org/skyscraper-height-ii/" target="_blank" rel="noopener noreferrer">Read More ¬ª</a></p>
<hr>
<p><a href="http://buildingtheskyline.org/skyscraper-height-iii/" target="_blank" rel="noopener noreferrer">The Economics of Skyscraper Height (Part III)</a></p>
<p><a href="https://www.jasonmbarr.com/" target="_blank" rel="noreferrer noopener" aria-label="Jason M. Barr&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; December 17, 2018 (opens in a new tab)">Jason M. Barr</a>&nbsp;&nbsp;&nbsp;&nbsp; January 21, 2019</p>
<p>Supertall skyscrapers are assumed to be driven by greed and ego. This blog post reviews the evidence for eight world-record-breaking buildings completed since 1930. The case studies demonstrate, however, that the reality is a bit more complex. <a href="http://buildingtheskyline.org/skyscraper-height-iii/" target="_blank" rel="noopener noreferrer">Read More ¬ª</a></p>
<hr>
<p><a href="http://buildingtheskyline.org/skyscraper-height-iv/" target="_blank" rel="noopener noreferrer">The Economics of Skyscraper Height (Part IV): Construction Costs Around the World</a></p>
<p><a href="https://www.jasonmbarr.com/" target="_blank" rel="noopener noreferrer">Jason M. Barr</a>&nbsp;&nbsp;&nbsp;&nbsp; June 4, 2019</p>
<p>What does it cost to build a skyscraper? The blog post reviews the economics of skyscraper supply. One of the reasons why we increasingly see supertalls in Asia is the because of cost of construction is so low there.&nbsp; So, what are the ‚Äúcostnomics‚Äù that generate building height? <a href="http://buildingtheskyline.org/skyscraper-height-iv/" target="_blank" rel="noopener noreferrer">Read More ¬ª</a></p>
<hr>

<!-- AddThis Advanced Settings above via filter on the_content --><!-- AddThis Advanced Settings below via filter on the_content --><!-- AddThis Advanced Settings generic via filter on the_content --><!-- AddThis Share Buttons above via filter on the_content --><!-- AddThis Share Buttons below via filter on the_content --><!-- AddThis Share Buttons generic via filter on the_content --></div></article></main></div></div></div>]]>
            </description>
            <link>https://buildingtheskyline.org/economics-of-skyscraper-height-series/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24351069</guid>
            <pubDate>Wed, 02 Sep 2020 08:06:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lesser-known Web APIs]]>
            </title>
            <description>
<![CDATA[
Score 377 | Comments 126 (<a href="https://news.ycombinator.com/item?id=24350647">thread link</a>) | @Sandeepg33k
<br/>
September 1, 2020 | https://blog.greenroots.info/10-lesser-known-web-apis-you-may-want-to-use-ckejv75cr012y70s158n85yhn | <a href="https://web.archive.org/web/*/https://blog.greenroots.info/10-lesser-known-web-apis-you-may-want-to-use-ckejv75cr012y70s158n85yhn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p><code>API</code> is the acronym for Application Programming Interface which defines interactions between multiple software architecture layers. Programmers carry out complex tasks easily using APIs in software development. Without APIs, a programmer's life would have been miserable with no proper(security, for example) access to data,  knowing unnecessary low level details etc.</p>
<p>When it comes to Web APIs, there are extremely useful  objects, properties and functions available to perform tasks as minor as accessing DOM to as complex as managing audios, videos, graphics, etc. </p>

<p>If you are from the web development background, you are using many of them already. Here is the list of very well known web APIs.</p>
<ul>
<li><a target="_blank" href="https://developer.mozilla.org/en-US/docs/Web/API/Canvas_API">Canvas</a></li>
<li><a target="_blank" href="https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API">Fetch</a></li>
<li><a target="_blank" href="https://developer.mozilla.org/en-US/docs/Web/API/History_API">History</a> </li>
<li><a target="_blank" href="https://developer.mozilla.org/en-US/docs/Web/API/Geolocation_API">Geolocation</a> </li>
<li><a target="_blank" href="https://developer.mozilla.org/en-US/docs/Web/API/Document_Object_Model">DOM</a></li>
<li><a target="_blank" href="https://developer.mozilla.org/en-US/docs/Web/API/Console_API">Console</a></li>
<li><a target="_blank" href="https://developer.mozilla.org/en-US/docs/Web/API/HTML_Drag_and_Drop_API">Drag &amp; Drop API</a></li>
</ul>
<p>In this article, I am going to talk about 10 more web APIs that are not so popular. Lesser popular doesn't mean, they are not useful. You can use them in various use-cases of your project. Please have a look.</p>

<p>If you would like to jump into the source code or see the demonstration immediately, here are the quick links to them:</p>
<blockquote>
<ul>
<li><a target="_blank" href="https://github.com/atapas/demolab/tree/master/code/src/demos/web-apis">Link to the Source Code @GitHub</a></li>
<li><a target="_blank" href="https://demo.greenroots.info/categories/web-apis/">Link to the Web API DemoLab</a></li>
</ul>
</blockquote>
<p>Note: Web APIs are nothing but the interfaces, functions, objects, properties written and exposed using vanilla JavaScript. However the usage of the web APIs is not limited to the vanilla JavaScript based application alone. It is very straightforward to use them with an Angular, React or Vue based applications as well.</p>
<p>All the examples I have used to demonstrate the web apis in this article are written using reactjs. You can find them in the github link mentioned above. Please feel free to fork, change and use!</p>

<p>A big (pain) point about  using a web API is, most of them are not standardized yet. It means, the support for a web API  may differ from one browser vendor to another. For example, You may find an API working with the Chrome browser but, not supported by Firefox or Edge browsers yet.</p>
<p>I would suggest a couple of ways to have a check on this,</p>


<p>Alright, time to get started knowing them. Hope you also find these useful.</p>
<h2 id="1-fullscreen-api">1. üì∫ Fullscreen API</h2>
<p>Do you have the need to show any of the DOM elements in full-screen mode? The full-screen use-case is very demanding for gaming applications, online video platforms(like, youtube) etc. </p>
<p>The <code>Fullscreen API</code> provides methods to present a specific Element (and its children) in a full-screen mode. There is a method available to exit full-screen mode once it is no longer needed. Not only that, this API can also help to perform any actions when a DOM element transition into a full-screen mode or comes out of it.</p>
<p>In the example below, my favorite Santa Claus can get into the full-screen mode and come out of it with ease.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598715764074/fR7trCfsA.gif?auto=format,compress&amp;gif-q=60" alt="full_screen.gif"></p>
<p>In the code below, the <code>manageFullScreen()</code> function uses  the <code>requestFullscreen()</code> API on an element which is having an id called, <code>fs_id</code>. </p>
<pre><code><span>const</span> manageFullscreen = () =&gt; {
   <span>document</span>.getElementById(<span>'fs_id'</span>).requestFullscreen();
}
</code></pre>
<p>This element with id, <code>fs_id</code> is a <code>DIV</code> with a child element, i.e, the Santa Clause image.</p>
<pre><code>&lt;div className=<span>"column"</span>&gt;
  <span><span>&lt;<span>div</span> <span>id</span>=<span>"fs_id"</span>&gt;</span>
    <span>&lt;<span>Img</span> <span>fixed</span>=<span>{imageData.image.childImageSharp.fixed}</span> <span>alt</span>=<span>"santa"</span> /&gt;</span>
   <span>&lt;/<span>div</span>&gt;</span>

    <span>&lt;<span>StyledButton</span> 
         <span>onClick</span>=<span>{manageFullscreen}</span>&gt;</span>
            Enter Fullscreen with Santa
    <span>&lt;/<span>StyledButton</span>&gt;</span>
 <span>&lt;/<span>div</span>&gt;</span></span>
</code></pre>
<p>You can check if the <code>Fullscreen API</code> is supported by the browser,</p>
<pre><code><span>if</span> (<span>document</span>.fullscreenEnabled) {
   setSupported(<span>true</span>);
} <span>else</span> {
   setSupported(<span>false</span>);
}
</code></pre>
<p>Also watch out for the useful handlers like,</p>
<ul>
<li><code>onfullscreenchange</code>: An event handler for the fullscreenchange event.</li>
<li><code>onfullscreenerror</code>: An event handler for the fullscreenerror event.</li>
</ul>
<p>Direct link to the demo: <a target="_blank" href="https://demo.greenroots.info/web-apis/web-apis-fullscreen/">https://demo.greenroots.info/web-apis/web-apis-fullscreen/</a></p>
<h2 id="2-clipboard-async-api">2. üìã Clipboard Async API</h2>
<p>What is a clipboard in comuping?</p>
<blockquote>
<p>The clipboard is a buffer that some operating systems provide for short-term storage and transfer within and between application programs.</p>
</blockquote>
<p>There are mainly three operations you can perform with the clipboard. They are, <code>copy</code>, <code>cut</code> and <code>paste</code>. The Clipboard API provides the ability to respond to these three operations. </p>
<p>Interestingly, copying content to the clipboard is open as in, there is no need of a user permission. However, for pasting the content from the clipboard to the user application, the user needs to grant permission for it. It is achieved using another web API called, <a target="_blank" href="https://developer.mozilla.org/en-US/docs/Web/API/Permissions_API">Permission API</a></p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598716493747/PwPwDDK8Y.png?auto=format&amp;q=60" alt="image.png"></p>
<p>Here is a simple example of the copy-paste operation,</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598716547383/PoXUNZmnr.gif?auto=format,compress&amp;gif-q=60" alt="clip_board.gif"></p>
<p>This is how to check if the feature is supported by the browser,</p>
<pre><code><span>if</span> (navigator.clipboard 
     &amp;&amp; navigator.clipboard.read 
     &amp;&amp; navigator.clipboard.write) {
   setSupported(<span>true</span>);
} <span>else</span> {
   setSupported(<span>false</span>);
}
</code></pre>
<p>Here is the async API function for writing the content to the clipboard,</p>
<pre><code><span>async</span> <span><span>function</span> <span>performCopy</span>(<span>event</span>) </span>{
   event.preventDefault();
   <span>try</span> {
      <span>await</span> navigator.clipboard.writeText(copyText);
      <span>console</span>.log(<span>`<span>${copyText}</span> copied to clipboard`</span>);
   } <span>catch</span> (err) {
      <span>console</span>.error(<span>'Failed to copy: '</span>, err);
   }
}
</code></pre>
<p>The Async API function to read the content from the clipboard and do something with it,</p>
<pre><code><span>async</span> <span><span>function</span> <span>performPaste</span>(<span>event</span>) </span>{
   event.preventDefault();
   <span>try</span> {
       <span>const</span> text = <span>await</span> navigator.clipboard.readText();
       setPastetext(text);
       <span>console</span>.log(<span>'Pasted content: '</span>, text);
   } <span>catch</span> (err) {
      <span>console</span>.error(<span>'Failed to read clipboard contents: '</span>, err);
   }
}
</code></pre>
<p>Note: With the inclusion of the <code>Clipboard Async API</code>, you can get rid of the usage of <a target="_blank" href="https://developer.mozilla.org/en-US/docs/Web/API/Document/execCommand">document.execCommad()</a> function as it is obsolete now.</p>
<p>Direct link to the demo: <a target="_blank" href="https://demo.greenroots.info/web-apis/web-apis-clipboard-apis/">https://demo.greenroots.info/web-apis/web-apis-clipboard-apis/</a></p>
<h2 id="3-resize-observer-api">3. üßê Resize Observer API</h2>
<p>Do you want to take some actions based on the changes to the content or border box of a DOM element? Are you thinking of writing a handler by yourself? What if I tell you, there is already one provided by the web API implementation?</p>
<p>Here is a story about a dumb button. We use a range slider to resize the button. While the button gets resized, we also want to control the text color, without letting the button know much about it. </p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598717277220/dITL6Nog2.gif?auto=format,compress&amp;gif-q=60" alt="resizer.gif"></p>
<p>First, create a button and specify an id so that, we can access the button later using the id.</p>
<pre><code>&lt;StyledButton id=<span>"dumbBtnId"</span>&gt;
   I am a Dumb Button
&lt;<span>/StyledButton&gt;</span>
</code></pre>
<p>Now we create a slider using the <code>range</code> input type from HTML5. A <code>resize()</code> function is invoked when the slider value changes.</p>
<pre><code>&lt;div&gt;
   <span><span>&lt;<span>input</span> 
         <span>onChange</span>=<span>{(event)</span> =&gt;</span> resize(event)} 
         type="range" 
         min={minRange} 
         max={maxRange} 
         defaultValue={rangeValue} /&gt;
<span>&lt;/<span>div</span>&gt;</span></span>
</code></pre>
<p>The <code>resize()</code> function simply sets the width of the button as the slider range value so that, it can be resized dynamically.</p>
<pre><code><span>const</span> resize = event =&gt; {
   <span>const</span> value = event.target.valueAsNumber;
   setRangeValue(value);
   <span>let</span> dumbBtn = <span>document</span>.getElementById(<span>'dumbBtnId'</span>);
   dumbBtn.style.width = <span>`<span>${value}</span>px`</span>;
 }
</code></pre>
<p>So far, so good? Now for every range value change, the button gets resized. We have a <code>ResizeObserver</code> observing this change and change the color of the button text.</p>
<pre><code>useEffect(() =&gt; {
   <span>try</span> {
            <span>let</span> dumbBtn = <span>document</span>.getElementById(<span>'dumbBtnId'</span>);
            <span>var</span> resizeObserver = <span>new</span> ResizeObserver(entries =&gt; {
                <span>for</span>(<span>const</span> entry <span>of</span> entries) {
                    
                    
                   entry.target.style.color = <span>'green`;
                }
      });
      resizeObserver.observe(dumbBtn);
   } catch(e) {
            setSupported(false);
            console.log(e);      
   }
}, [rangeValue]);</span>
</code></pre>
<p>Direct link to the demo: <a target="_blank" href="https://demo.greenroots.info/web-apis/web-api-resize-observer/">https://demo.greenroots.info/web-apis/web-api-resize-observer/</a></p>
<h2 id="4-image-capture-api">4. üì∑ Image Capture API</h2>
<p>There are some cool and useful APIs around user media like, audio, video etc. I love the <code>Image Capture API</code> which helps us to capture an image or grab a frame from the video devices(like webcam). Not only that, you can also perform actions on capturing an image or grabbing a frame.</p>
<p>First, get the user media access. In this case we are getting the webcam access.</p>
<pre><code>navigator.mediaDevices.getUserMedia({video: <span>true</span>})
  .then(mediaStream =&gt; {
     <span>document</span>.querySelector(<span>'video'</span>).srcObject = mediaStream;
     <span>const</span> track = mediaStream.getVideoTracks()[<span>0</span>];
     setTrack(track);
  }).catch(error =&gt; {
     <span>console</span>.error(<span>` <span>${error}</span> is not yet supported`</span>);
     setError(error);
});
</code></pre>
<p>Just like the clipboard paste operation, a webcam media access permission has to be granted by the user.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598717565379/MCRNY49Tl.png?auto=format&amp;q=60" alt="image.png"></p>
<p>Now Grab a frame and do something. In this example, I am just drawing the frame on a Canvas.</p>
<pre><code><span>const</span> imageCapture = <span>new</span> ImageCapture(track);
    imageCapture.grabFrame()
      .then(imageBitmap =&gt; {
          <span>const</span> canvas = <span>document</span>.querySelector(<span>'#grabFrameCanvas'</span>);
          drawCanvas(canvas, imageBitmap);
    }).catch(error =&gt; {
          <span>console</span>.log(error);
          setError(error);
});
</code></pre>
<p>I can also take a picture and do the similar thing.</p>
<pre><code><span>const</span> imageCapture = <span>new</span> ImageCapture(track);
    imageCapture.takePhoto().then(blob =&gt; createImageBitmap(blob))
      .then(imageBitmap =&gt; {
          <span>const</span> canvas = <span>document</span>.querySelector(<span>'#takePhotoCanvas'</span>);
          drawCanvas(canvas, imageBitmap);
    }).catch(error =&gt; {
          <span>console</span>.log(error);
          setError(error);
});
</code></pre>
<p>To stop the video streaming from the webcam, just call he method <code>stop()</code> on the running video track.</p>
<pre><code><span>const</span> videoOff = () =&gt; {
   track.stop();
 }
</code></pre>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1598717833234/MPOxVZ92M.png?auto=format&amp;q=60" alt="chrome_Umvi16wUlu.png"></p>
<p>Also watch out for the methods,</p>
<ul>
<li><code>getPhotoCapabilities()</code>: To get the ranges of available configuration options.</li>
<li><code>getPhotoSettings()</code>: To get the current photo configuration settings.</li>
</ul>
<p>Direct link to the demo: <a target="_blank" href="https://demo.greenroots.info/web-apis/web-apis-image-capture/">https://demo.greenroots.info/web-apis/web-apis-image-capture/</a></p>
<h2 id="5-broadcast-channel-api">5. üì° Broadcast Channel API</h2>
<p>The <code>Broadcast Channel API</code> allows communication between browsing contexts (windows, tabs, iframes) and workers on the <strong>same origin</strong>. Think of a use-case like, once you logout from an app running in a browser tab, you want to broadcast it to the app instances opened in other tabs of the same browser.</p>
<p>Here is an example where a sender is sending a message to the receiver and the same is being ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.greenroots.info/10-lesser-known-web-apis-you-may-want-to-use-ckejv75cr012y70s158n85yhn">https://blog.greenroots.info/10-lesser-known-web-apis-you-may-want-to-use-ckejv75cr012y70s158n85yhn</a></em></p>]]>
            </description>
            <link>https://blog.greenroots.info/10-lesser-known-web-apis-you-may-want-to-use-ckejv75cr012y70s158n85yhn</link>
            <guid isPermaLink="false">hacker-news-small-sites-24350647</guid>
            <pubDate>Wed, 02 Sep 2020 06:44:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A round-up of topology-based papers at ICML 2020]]>
            </title>
            <description>
<![CDATA[
Score 102 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24350436">thread link</a>) | @Topolomancer
<br/>
September 1, 2020 | https://bastian.rieck.me/blog/posts/2020/icml_topology_roundup/ | <a href="https://web.archive.org/web/*/https://bastian.rieck.me/blog/posts/2020/icml_topology_roundup/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>With this year‚Äôs <a href="https://icml.cc/Conferences/2020">International Conference on Machine Learning&nbsp;(ICML)</a>
being over, it is time to have another instalment of this series.
Similar to <a href="http://bastian.rieck.me/blog/posts/2019/icml_tda_roundup/">last year‚Äôs post</a>, I shall cover
several papers that caught my attention because of their use of
topological concepts‚Äîhowever, <em>unlike</em> last year, I shall not
restrict the selection to papers using <a href="https://en.wikipedia.org/wiki/Topological_data_analysis">topological data analysis&nbsp;(TDA)</a>.</p>
<p><strong>Caveat lector:</strong> I might have missed some promising papers. Any
suggestions for additions are more than welcome! Please reach out
to me via <a href="https://twitter.com/Pseudomanifold">Twitter</a> or
<a href="mailto:bastian@rieck.me">e-mail</a>.</p>

<div>
<figure>
    <img src="https://bastian.rieck.me/images/icml20_chen.png" alt="Learning Flat Latent Manifolds with VAEs" width="500"> 
</figure>

</div>
<p><a href="https://arxiv.org/abs/2002.04881">Learning Flat Latent Manifolds with VAEs</a>
by <a href="https://argmax.ai/team/nutan-chen">Nutan Chen</a>, <a href="https://www.argmax.ai/team/alexej-klushyn">Alexej Klushyn</a>,
Francesco Ferroni, <a href="http://bayerj.github.io/">Justin Bayer</a>, and
<a href="https://argmax.ai/team/patrick-van-der-smagt">Patrick van der Smagt</a>
discusses an interesting modification of variational autoencoders, viz.
an extended loss term that regularises the latent space to be
<em>flat</em>&nbsp;(i.e. having no <a href="https://en.wikipedia.org/wiki/Curvature">curvature</a>).
The main idea is to ensure that the <a href="https://en.wikipedia.org/wiki/Metric_tensor">Riemannian metric tensor</a>
is the identity matrix.</p>
<p>The ingenious implication of such a latent space is that the Euclidean
distance is a good proxy for the similarity between data points, whereas
this is <em>not</em> a priori the case for other latent spaces. It is interesting
to note that there is a ‚Äòsibling‚Äô paper to this one, which was published
at ICLR 2020, namely <a href="https://openreview.net/pdf?id=S1g6xeSKDS">Mixed-curvature Variational Autoencoders</a>.
This paper presents an autoencoder whose latent space is a product of
Riemannian manifolds, whose curvature is either fixed or learnable.</p>
<p>I am glad to see that curvature is starting to attract more attention
from the machine learning community. It is such a fundamental property
of a manifold but can influence the validity of many calculations in
latent spaces. It also has some beneficial properties for <a href="https://openreview.net/pdf?id=BylEqnVFDB">graph
classification</a>, but this is
maybe a better topic for a subsequent post!</p>

<div>
<figure>
    <img src="https://bastian.rieck.me/images/icml20_hoferb.png" alt="Graph Filtration Learning" width="500"> 
</figure>

</div>
<p><a href="https://arxiv.org/abs/1905.10996">Graph Filtration Learning</a> by
<a href="https://www.researchgate.net/profile/Christoph_Hofer8">Christoph Hofer</a>,
<a href="https://www.uni-salzburg.at/index.php?id=213185&amp;L=1">Florian Graf</a>,
<a href="https://bastian.rieck.me/">Bastian Rieck</a>,
<a href="http://wwwx.cs.unc.edu/~mn/?q=content/overview">Marc Niethammer</a>, and
<a href="https://rkwitt.github.io/">Roland Kwitt</a> is arguably<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> the first step
towards properly integrating topological features into neural networks
for graph classification! Briefly put, we developed a homological
<code>READOUT</code> function&nbsp;(to use the parlance of graph neural networks)
that gives rise to a learnable filter function‚Äîa <em>filtration</em>.</p>
<p>This concept might be unknown to some readers, but a filtration in this
context is a scalar-valued function on the vertices of a graph that
permits <em>sorting</em> it. Filtrations serve as the backbone for many
topology-based algorithms, primarily for the aforementioned <a href="https://christian.bock.ml/posts/persistent_homology/">persistent homology</a>,
which permits us to study multi-scale topological
features&nbsp;(connected components, cycles, etc.) of an object.
Prior to this paper, filtrations were pre-defined or chosen based on
some target function, such as the vertex degree function of a graph. Our
approach changes this‚Äîleading to a filtration that is learnable in an
end-to-end fashion and thus specifically designed for a classification
problem.</p>
<p>We manage to achieve this by first initialising our filter function
based on a regular graph neural network; essentially, one level of
message passing between nodes is sufficient. This provides us with
a non-trivial filter function whose performance we can subsequently
adjust by calculating the topological features induced by said filter,
and vectorising the resulting representations. Since each of these steps
is differentiable<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>, the resulting function is also differentiable,
making it possible to adjust the filter for the best classification
results.</p>
<p>I would recommend this paper to anyone who is interested in learning
more about the benefits that a topology-based perspective brings to
certain application problems. Being able to learn the <em>right</em> topological features
to classify a set of graphs opens up exciting opportunities.</p>

<div>
<figure>
    <img src="https://bastian.rieck.me/images/icml20_hofera.png" alt="Topologically Densified Distribution" width="500"> 
</figure>

</div>
<p><a href="https://arxiv.org/abs/2002.04805">Topologically Densified Distributions</a>
by <a href="https://www.researchgate.net/profile/Christoph_Hofer8">Christoph Hofer</a>,
<a href="https://www.uni-salzburg.at/index.php?id=213185&amp;L=1">Florian Graf</a>,
<a href="http://wwwx.cs.unc.edu/~mn/?q=content/overview">Marc Niethammer</a>, and
<a href="https://rkwitt.github.io/">Roland Kwitt</a> studies regularisation properties of
over-parametrised neural networks in the context of small sample-size learning.
This is achieved by studying the properties of latent
representations&nbsp;(the paper uses the term <em>internal representation</em>,
but this is equivalent). More precisely, generalisation properties are
analysed via the <a href="https://en.wikipedia.org/wiki/Pushforward_measure">push-forward probability measure</a>
induced by the latent representation&nbsp;(or <em>encoding</em>).</p>
<p>The authors show that probability mass concentration around training
samples in the latent space is linked to the generalisation capabilities
of a model, but, even more exciting, such a concentration can be achieved by applying
topological constraints on samples from that space! In the context of
this paper, such constraints pertain to measuring the <em>connectivity</em> of
samples. This is achieved using <a href="https://christian.bock.ml/posts/persistent_homology/">persistent homology</a>, specifically,
by calculating a zero-dimensional Vietoris‚ÄìRips complex‚Äîif you are
not familiar with this term, just think of a minimum spanning tree.</p>
<p>What I particularly enjoyed about this paper is that it starts providing
solid answers to fundamental concepts in machine learning. All too often,
we remain in the realm of the empirical and just <em>observe</em> whether our
network generalises. This paper ventures into hitherto-unknown territories
and gives us a theoretical justification!</p>

<div>
<figure>
    <img src="https://bastian.rieck.me/images/icml20_moor.png" alt="Topological Autoencoders" width="250"> 
</figure>

</div>
<p><a href="https://arxiv.org/abs/1906.00722">Topological Autoencoders</a> by
<a href="https://michaelmoor.ml/">Michael Moor</a>,
<a href="https://expectationmax.github.io/">Max Horn</a>,
<a href="https://bastian.rieck.me/">Bastian Rieck</a>, and
<a href="https://bsse.ethz.ch/mlcb/karsten.html">Karsten Borgwardt</a> deals with
regularising the latent space in terms of its topology. More precisely,
we preserve the topological features of the input data in the respective
latent space&nbsp;(on the batch level, respectively). While we restrict
our experiments to connected components for now&nbsp;(so no cycles
yet, even though our method generalises to higher dimensions),
our approach makes it possible to create latent representations
that ‚Äòmimic‚Äô the topological features of the input.</p>
<p>This leads to a nice plug-and-play loss term that can be easily
integrated into most architectures, and we can demonstrate that, among
others, it considerably improves the quality of a ‚Äòvanilla‚Äô autoencoder
architecture. To achieve this goal, we had to solve all kinds of
interesting adventures, one of them being how to make everything
differentiable. Interestingly, we end up with a similar necessary
condition for differentiability than for the graph filtration learning
paper, viz. the pairwise distances between different samples of the
input batch need to be <em>unique</em>.</p>
<p>The coolest feature of our method is that it technically <em>only</em> requires
a distance metric between input samples<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>, nothing more‚Äîno feature
vector representation or anything. It can thus conceivably be used to
represent the topology of any object you fancy&nbsp;(including
documents, images, and graphs).</p>
<p>If you are interested in a beautifully-animated high-level introduction
to this publication, you should take the time to read Michael‚Äôs <a href="https://michaelmoor.ml/blog/topoae/main/">blog post on our paper</a>.</p>

<div>
<figure>
    <img src="https://bastian.rieck.me/images/icml20_rezende.png" alt="Normalizing Flows on Tori and Spheres" width="500"> 
</figure>

</div>
<p><a href="https://arxiv.org/abs/2002.02428">Normalizing Flows on Tori and Spheres</a> by
<a href="https://danilorezende.com/">Danilo Jimenez Rezende</a>,
<a href="https://gpapamak.github.io/">George Papamakarios</a>,
<a href="https://scholar.google.com/citations?user=o-h0vrQAAAAJ">S√©bastien Racani√®re</a>,
<a href="http://malbergo.me/">Michael S. Albergo</a>,
<a href="https://scholar.google.com/citations?user=zK77P6MAAAAJ">Gurtej Kanwar</a>,
<a href="https://web.mit.edu/physics/people/faculty/shanahan_phiala.html">Phiala E.  Shanahan</a>,
and <a href="http://theoryandpractice.org/">Kyle Cranmer</a>
present a novel method for calculating normalising flows on more complex
spaces than the usual Euclidean ones. Specifically, as the title
implies, they develop methods for calculating such flows on tori and
spheres.</p>
<p>What I enjoyed about this paper is the smart way of constructing flows
iteratively: first, flows on the circle are being constructed&nbsp;(using
different concepts for defining a <a href="https://en.wikipedia.org/wiki/Diffeomorphism">diffeomorphism</a>, the most favourite of
mine being a <a href="https://en.wikipedia.org/wiki/M%C3%B6bius_transformation">M√∂bius transformation</a>).
Since a torus can be described as the Cartesian product of circles, this
is sufficient to describe flows on tori of arbitrary dimensions! Next,
the flows are generalised to higher-dimensional spheres.</p>
<p>While I am by no means and expert in normalising flows, I liked
reading this paper a lot. The theory is well-developed and it is another
one of those publications that shows you how to go beyond the boundaries
of what is currently possible. Moreover, I enjoyed the discussion of the
implementation details‚Äîit turns out that achieving numerical stability
here is another feat that deserves some mention!</p>

<p>This year‚Äôs ICML also featured an interesting array of topology-based
papers. Not all of them fit neatly into the field of topological data
analysis&nbsp;(TDA), but I am happy to see that the community is
starting to pick up this fundamental topic. I remain convinced that
a topology-driven perspective is needed to answer certain foundational
questions in machine learning. Here‚Äôs to the future of topology!</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Even if say so myself. <a href="#fnref:1" role="doc-backlink">‚Ü©Ô∏é</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>Under mild assumptions, viz. provided that the filter function
values are unique for each vertex. This can always be achieved by
a small symbolic perturbation. <a href="#fnref:2" role="doc-backlink">‚Ü©Ô∏é</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>Practically, it might not even require the properties of a metric,
although the mathematician in me is screaming at the horrors of this
thought. <a href="#fnref:3" role="doc-backlink">‚Ü©Ô∏é</a></p>
</li>
</ol>
</section>

      </div></div>]]>
            </description>
            <link>https://bastian.rieck.me/blog/posts/2020/icml_topology_roundup/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24350436</guid>
            <pubDate>Wed, 02 Sep 2020 06:03:30 GMT</pubDate>
        </item>
    </channel>
</rss>
