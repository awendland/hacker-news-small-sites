<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 50]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 50. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Fri, 09 Oct 2020 08:29:16 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-50.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Fri, 09 Oct 2020 08:29:16 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[VSCode on Google Colab]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 10 (<a href="https://news.ycombinator.com/item?id=24705599">thread link</a>) | @amitness
<br/>
October 6, 2020 | https://amitness.com/vscode-on-colab/ | <a href="https://web.archive.org/web/*/https://amitness.com/vscode-on-colab/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<header>

<p>
<span>

2 minute read
</span>
</p>
</header>
<section itemprop="text">
<p>I recently discovered a way to set up VSCode on Google Colab and use it as an editor to write code and run experiments on the Colab VM.</p>
<p>With this setup, you can still prototype in the Colab Notebook while also using VSCode for all the advantages of a full-fledged code editor. Here is how you can replicate my setup.</p>
<h2 id="approach-1-python-package">Approach 1: Python Package</h2>
<p>In this setup, we use the <a href="https://github.com/abhishekkrthakur/colabcode">colab-code</a> package that automates all the manual setup steps previously described in the <strong>Approach 2</strong> section of this blog post. You can make a copy of this <a href="https://colab.research.google.com/github/abhishekkrthakur/colabcode/blob/master/colab_starter.ipynb">notebook</a> directly to get started.</p>
<ol>
<li>
<p>First, install the <code>colab-code</code> package using the following command:</p>

</li>
<li>
<p>Now, import <code>ColabCode</code> class from the package and specify the port and password.</p>
<div><div><pre><code> <span>from</span> <span>colabcode</span> <span>import</span> <span>ColabCode</span>
 <span>ColabCode</span><span>(</span><span>port</span><span>=</span><span>10000</span><span>,</span> <span>password</span><span>=</span><span>"password123"</span><span>)</span>
</code></pre></div> </div>
<p>You can also use it directly with the default port and without any password as shown below.</p>
<div><div><pre><code> <span>from</span> <span>colabcode</span> <span>import</span> <span>ColabCode</span>
 <span>ColabCode</span><span>()</span>
</code></pre></div> </div>
</li>
<li>
<p>You will get the ngrok URL in the output. Click the link and a login page will open in a new tab.</p>
<p><img src="https://amitness.com/images/colab-code-step-1.png" alt="Generated NGROK URL"></p>
</li>
<li>
<p>Type the password you had set in step 2 and click submit. If the page gets stuck for more than 4-5 seconds, refresh the page and you should be redirected to the editor.</p>
<p><img src="https://amitness.com/images/colab-code-step-2.png" alt="Authenticating with password in VSCode"></p>
</li>
<li>
<p>Now you will get access to the editor interface and can use it to work on python files.</p>
<p><img src="https://amitness.com/images/colab-code-step-3.png" alt="VSCode Interface"></p>
</li>
</ol>
<h2 id="approach-2-manual-setup">Approach 2: Manual Setup</h2>
<p>I have described the setup steps in detail below. After going through all the steps, please use this <a href="https://colab.research.google.com/drive/1yvUy5Gn9lPjmCQH6RjD_LvUO2NE0Z7RM?usp=sharing">colab notebook</a> to try it out directly.</p>
<ol>
<li>
<p>First, we will install the <a href="https://github.com/cdr/code-server">code-server</a> package to run VSCode editor as a web app. Copy and run the following command on colab to install <code>code-server</code>.</p>
<div><div><pre><code> !curl -fsSL https://code-server.dev/install.sh | sh
</code></pre></div> </div>
</li>
<li>
<p>After the installation is complete, we will expose a random port <code>9000</code> to an external URL we can access using the <code>pyngrok</code> package. To install <code>pyngrok</code>, run</p>
<div><div><pre><code> <span>!</span>pip <span>install</span> <span>-qqq</span> pyngrok
</code></pre></div> </div>
</li>
<li>
<p>Then, run the following command to get a public ngrok URL. This will be the URL we will use to access VSCode.</p>
<div><div><pre><code> <span>from</span> <span>pyngrok</span> <span>import</span> <span>ngrok</span>
 <span>url</span> <span>=</span> <span>ngrok</span><span>.</span><span>connect</span><span>(</span><span>port</span><span>=</span><span>9000</span><span>)</span>
 <span>print</span><span>(</span><span>url</span><span>)</span>
</code></pre></div> </div>
</li>
<li>
<p>Now, we will start the VSCode server in the background at port 9000 without any authentication using the following command.</p>
<div><div><pre><code> !nohup code-server --port 9000 --auth none &amp;
</code></pre></div> </div>
</li>
<li>
<p>Now, you can access the VSCode interface at the URL you got from step 3. The interface and functionality are the same as the desktop version of VSCode.</p>
</li>
</ol>
<p><img src="https://amitness.com/images/colab-vscode.png" alt="Example of a running instance of VSCode server"></p>
<h2 id="usage-tips">Usage Tips</h2>
<ol>
<li>
<p>You can switch to the dark theme by going to the bottom-left corner of the editor, clicking the <strong>settings icon</strong>, and then clicking ‚Äò<strong>Color Theme</strong>‚Äô.</p>
<p><img src="https://amitness.com/images/colab-dark-theme-step-1.png" alt="Switching to dark theme on VSCode"></p>
<p>A popup will open. Select <strong>Dark (Visual Studio)</strong> in the options and the editor will switch to a dark theme.
<img src="https://amitness.com/images/colab-dark-theme-step-2.png" alt="Theme selection interface on VSCode"></p>
</li>
<li>
<p>All the keyword shortcuts of regular VSCode works with this. For example, you can use <code>Ctrl + Shift + P</code> to open a popup for various actions.</p>
<p><img src="https://amitness.com/images/vscode-ctrl-shift-p.png" alt="Action popup in VSCode"></p>
</li>
<li>
<p>To open a terminal, you can use the shortcut <code>Ctrl + Shift + `</code>.</p>
<p><img src="https://amitness.com/images/vscode-terminal.png" alt="Opening integrated terminal in VSCode"></p>
</li>
<li>
<p>To get python code completions, you can install the Python(<code>ms-python</code>) extension from the extensions page on the left sidebar.</p>
<p><img src="https://amitness.com/images/vscode-code-completions.png" alt="Installing extensions in VSCode"></p>
</li>
<li>
<p>The Colab interface is still usable as a notebook and regular functions to upload and download files and mount with Google Drive. Thus, you get the benefits of both a notebook and a code editor.</p>
</li>
</ol>
<h2 id="references">References</h2>
<ul>
<li><a href="https://github.com/cdr/code-server/blob/v3.5.0/doc/FAQ.md">Code-Server FAQs</a></li>
<li><a href="https://pyngrok.readthedocs.io/en/latest/">pyngrok - a Python wrapper for ngrok</a></li>
</ul>
</section>



</div></div>]]>
            </description>
            <link>https://amitness.com/vscode-on-colab/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24705599</guid>
            <pubDate>Wed, 07 Oct 2020 05:38:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[USB3: Why it's a bit harder than USB2]]>
            </title>
            <description>
<![CDATA[
Score 117 | Comments 55 (<a href="https://news.ycombinator.com/item?id=24704298">thread link</a>) | @panic
<br/>
October 6, 2020 | https://lab.ktemkin.com/post/why-is-usb3-harder/ | <a href="https://web.archive.org/web/*/https://lab.ktemkin.com/post/why-is-usb3-harder/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    

    <p>A few people on twitter have asked me to explain why the USB3 winds up being much harder to implement than USB2.
The answer is more than will fit in a single tweet, so I thought I'd put a quick-but-rough answer, here. This is
by no means comprehensive; consider it <del>a longer tweet</del> what a tweet would be given I had more than 240 characters and a proclivity to babble. (I do.)</p>
<p>A lot of the challenges come from the way we work around <em>physical-layer</em> limitations. Put poetically, physics gives
us lots of little obstacles we have to work around in order to talk at 5 billion transfers per second (5GT/s).</p>
<h5 id="its-hard-to-establish-common-dc-operating-conditions-on-both-sides-of-a-link">It's hard to establish common ‚ÄúDC operating conditions‚Äù on both sides of a link.</h5>
<p>It's not trivial to get the same bias voltages ‚Äì and common grounds ‚Äì across a long motherboard or down a cable ‚Äì and when you're operating at really high frequencies, you're a lot more sensitive to changes in your operating environment. In USB3, we work around this by <em>capacitively isolating</em> both sides of the link from each other ‚Äì in short, we use capacitors to ensure only signal <em>changes</em> are carried across the link, which means that both sides can establish their own local operating conditions.</p>
<figure>
    <img src="https://lab.ktemkin.com/post-media/why-is-usb3-harder/circuit.png" alt="diagram showing the transmitter is connected to the receiver through a pair of AC coupling capacitors"> <figcaption>
            <h4>From the USB3.2 specification: diagram showing how signals are isolated</h4>
        </figcaption>
</figure>

<p>This puts some requirements on the digital protocols used to exchange data. Because data currents are exchanged as the relevant capacitors charge and discharge, <em>capacitive coupling</em> only works when those capacitors have room to charge and discharge. <strong>This means our data must be DC-balanced; we have to spend as much time charging those capacitors as we do discharging them</strong>. In digital terms, this means we have to encode the data in a way that sends the same amount of <code>1</code>s and <code>0</code>s.</p>
<h5 id="its-hard-to-establish-a-common-clock-across-both-sides-of-a-link">It's hard to establish a ‚Äúcommon clock‚Äù across both sides of a link.</h5>
<p>When sending serial data, you typically have two challenges: you need to make sure both sides are sampling the data <em>at the same rate</em>, and that both sample clocks are <em>synchronized enough</em> that you're sampling at the right point. Many high-speed protocols deal with this using a technique called <em>clock recovery</em>, which essentially means that each receiver looks at the data it receives and tries to figure out what the clock that produced it looks like.</p>
<p>If both sides have agreed on a clock rate, this can be simple, in theory: if the receiver sees a change in its
received data, it can infer that that changed happened <em>on an active edge of the transmitter's clock</em>, and so it can start to figure out how to align its internal clock with the transmitter's.</p>
<p>This introduces another protocol requirement: <strong>for <em>clock recovery</em> to work, the data has to change frequently enough that the two sides can keep synchronized</strong>. At 5GT/s and high data throughputs, there's not much time for clocks to become synchronized when a packet is received; accordingly, it's important that data is encoded with lots of transitions, even when the line is idle.</p>
<p><strong>To ensure both <em>DC-Balance</em> and <em>sufficient transition density</em>, USB3 uses a method of encoding called 8b10b encoding.</strong>
In this encoding scheme, every single byte of data is transmitted as ten bits, with encodings chosen so that:</p>
<ul>
<li>A typical data byte can be transmitted <em>either</em> as a code with <em>one more one than zero</em>, or <em>one more zero than one</em>.
This allows the transmitter to choose between the two encodings, in order to keep the data stream at 50% ones.</li>
<li>Every valid encoding has sufficient <em>transition density</em> to ensure that it's useful for clock recovery.</li>
</ul>
<p>I won't go into more 8b10b background here, but you can read about the typical IBM implementation <a href="https://en.wikipedia.org/wiki/8b/10b_encoding">on wikipedia</a>.</p>
<h5 id="its-hard-to-run-both-sides-of-the-link-at-the-same--clock-rate-">It's hard to run both sides of the link at the same <em>clock rate</em>.</h5>
<p>Even with successful <em>clock recovery</em>, it's difficult to have both sides of the link produce and consume data at
the same rate. Each side's internal logic is running off of its own <em>clock source</em>; and every clock has a bit of deviation from its nominal frequency. For the protocol to function despite these differences, the USB3 specification allows each clock to deviate from its nominal value by up to a certain <em>tolerance</em>; and specifies a method for compensating for this tolerance. This technique is appropriately named <em>clock tolerance compensation</em>, or CTC.</p>
<p><strong>To compensate for mismatches in sender/receiver clock rates, USB3 requires senders to periodically insert filler data into their transmitted data-stream</strong>. Receivers can then discard this data; allowing a brief pause in which the slower
side of the link can ‚Äúcatch up‚Äù. For this to be useful, the filler data (called ‚Äòskip sets‚Äô) must be sent regularly;
which means additional logic on the transmitter side for insertion, and additional logic on the receiver side for
removal.</p>
<h5 id="its-hard-to-deal-with-varying-electrical-properties-of-different-transmitters-receivers-and-cables">It's hard to deal with varying electrical properties of different transmitters, receivers, and cables.</h5>
<p>When operating at very high frequencies, all of the little non-idealities along your transmission path really add up. At slower data rates, there's plenty of time for digital signals to ‚Äúsettle‚Äù after a change; making the non-ideal properties of your transmission lines less important. The faster your data gets, the more important it is for your data
to reach a ‚Äúreadable‚Äù value quickly.</p>
<p>To help with this, most high-speed receivers employ a technique called <em>receiver equalization</em>, which uses analog hardware
to help reshape signal transitions, so they can be more reliably sampled. Equalization helps to ‚Äúcancel out‚Äù some of the ways the non-ideal transmission path adversely affects the signal.</p>
<figure>
    <img src="https://lab.ktemkin.com/post-media/why-is-usb3-harder/eye.png" alt="diagram showing a variety of slow rises and falls; illustrating that the physical link slows transitions"> <figcaption>
            <h4>From the USB3.2 specification: an 'eye diagram', which shows an overlay of many rising and falling transitions, illustrating how non-ideal properties affect the link.</h4>
        </figcaption>
</figure>

<p>Since every transmission path is different ‚Äì due to different transmitter, receiver, and cable properties ‚Äì it's impossible to create a single ‚Äúone size fits all‚Äù equalizer. Instead, each USB3 equalizer needs to be tuned to its transmission path via a process called <em>link training</em>.</p>
<p><strong>At the start of each USB3 communication, link partners repeatedly exchange collections of known data called <em>training sets</em>, which give the opportunity for each side to tune their equalizer.</strong> Training sets include both sets of data chosen to have high transition density and sets designed to include a wide range of ‚Äúnormally-distributed‚Äù data.</p>
<p>During a few milliseconds of data exchange ‚Äì an eternity in fast-protocol terms ‚Äì both sides of the link gradually
tweak their equalizer settings until they're clearly seeing the expected values from the other side.</p>
<h5 id="its-hard-not-to-generate-harmful-interference">It's hard not to generate harmful interference.</h5>
<p>USB3 has a very high transition rate ‚Äì it easily qualifies as high radio-frequency signaling ‚Äì and its link
often tends to exchange repeating data. This has a nasty side effect: even a well-functioning link can act as an
antenna; unintentionally emitting RF that can interfere with nearby systems. The more repeating elements this signaling
has, the more troublesome the interference tends to be.</p>
<p><strong>To reduce the amount of harmful interference generated, USB3 links use a technique called <em>scrambling</em>, in which data is XOR'd with a fixed pattern before transmission.</strong> The receiver is then capable of applying the same transform to <em>descramble</em> the data stream, recovering the relevant data.</p>
<p>You can think of scrambling as being very similar to encryption ‚Äì except everyone knows the key. Once data is scrambled, it looks a lot more like ‚Äúrandom numbers‚Äù than the pre-scrambling data ‚Äì and accordingly, it's a lot less likely to
generate troublesome interference. Once the scrambled data travels the link, it can be <em>descrambled</em> by the receiving end ‚Äì a process similar to decryption ‚Äì restoring the original data stream.</p>
<h5 id="in-summary">In summary‚Ä¶</h5>
<p>In summary, before you can even exchange meaningful data, the digital side of your device needs:</p>
<ul>
<li><strong>8b10b encoding and decoding hardware</strong>, so the data exchanged is <em>DC-balanced</em> and contains sufficient transitions as to allow <em>clock recovery</em>;</li>
<li><strong>Clock Tolerance Compensation hardware</strong>, which allows the two sides to communicate even with slightly-varying clock frequencies;</li>
<li>Hardware to orchestrate <strong>link training</strong> and <strong>receiver equalization</strong>, which helps to deal with non-ideal transmission properties;</li>
<li><strong>Scrambling</strong> and <strong>descrambling</strong> hardware, which help to reduce harmful interference.</li>
</ul>
<p>This omits a few minor things, such as USB3's <em>Low Frequency Periodic Signaling</em>; but these are the major components.</p>
<h5 id="oh-and-one-more-thing-its-hard-to-get-good-resources">Oh, and one more thing: it's hard to get good resources.</h5>
<p>Finally, ignoring all the physical layer challenges associated with bringing a link up, there's one more major obstacle: it's hard to get good resources for working with USB3:</p>
<ul>
<li>Most hardware enabling custom USB designs is expensive; and <a href="https://lab.ktemkin.com/post/ab07-usb3fmc-wtf/">still rife with issues</a>.</li>
<li>Most USB3 tooling is <a href="https://www.totalphase.com/products/beagle-usb5000-v2-ultimate/">very expensive</a>, and still rife with issues.</li>
<li>There's very little documentation in support of the specification; and what documentation exists still hasn't been
used enough to <a href="https://lab.ktemkin.com/post/mindshare-usb3/">identify all of its errors</a>.</li>
</ul>
<p>Hopefully, at some point, I'll have built enough tooling to change this.</p>


  </article></div>]]>
            </description>
            <link>https://lab.ktemkin.com/post/why-is-usb3-harder/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24704298</guid>
            <pubDate>Wed, 07 Oct 2020 01:11:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DOMPurify bypass: XSS via HTML namespace confusion]]>
            </title>
            <description>
<![CDATA[
Score 138 | Comments 59 (<a href="https://news.ycombinator.com/item?id=24703230">thread link</a>) | @fanf2
<br/>
October 6, 2020 | https://research.securitum.com/mutation-xss-via-mathml-mutation-dompurify-2-0-17-bypass/ | <a href="https://web.archive.org/web/*/https://research.securitum.com/mutation-xss-via-mathml-mutation-dompurify-2-0-17-bypass/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1639">
	<!-- .entry-header -->

	
	<div>
		
<p>In this blogpost I‚Äôll explain my recent bypass in <a href="https://github.com/cure53/DOMPurify/">DOMPurify</a> ‚Äì the popular HTML sanitizer library. In a nutshell, DOMPurify‚Äôs job is to take an untrusted HTML snippet, supposedly coming from an end-user, and remove all elements and attributes that can lead to Cross-Site Scripting (XSS).</p>



<p>This is the bypass:</p>



<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-5f801f5815cb7983640176" data-settings=" minimize scroll-mouseover">
		
			
			
			
			<div>
				<table>
					<tbody><tr>
				<td data-settings="show">
					
				</td>
						<td><div><p><span>&lt;</span><span>form</span><span>&gt;</span></p><p><span>&lt;</span><span>math</span><span>&gt;</span><span>&lt;</span><span>mtext</span><span>&gt;</span></p><p><span>&lt;</span><span>/</span><span>form</span><span>&gt;</span><span>&lt;</span><span>form</span><span>&gt;</span></p><p><span>&lt;</span><span>mglyph</span><span>&gt;</span></p><p><span>&lt;</span><span>style</span><span>&gt;</span><span>&lt;</span><span>/</span><span>math</span><span>&gt;</span><span>&lt;</span><span>img </span><span>src </span><span>onerror</span><span>=</span><span>alert</span><span>(</span><span>1</span><span>)</span><span>&gt;</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
		</div>
<!-- [Format Time: 0.0003 seconds] -->




<p>Believe me that there‚Äôs not a single element in this snippet that is superfluous üôÇ </p>



<p>To understand why this particular code worked, I need to give you a ride through some interesting features of HTML specification that I used to make the bypass work.</p>



<h2>Usage of DOMPurify</h2>



<p>Let‚Äôs begin with the basics, and explain how DOMPurify is usually used. Assuming that we have an untrusted HTML in <code>htmlMarkup</code> and we want to assign it to a certain <code>div</code>, we use the following code to sanitize it using DOMPurify and assign to the <code>div</code>:</p>



<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-5f801f5815cbe576224927" data-settings=" minimize scroll-mouseover">
		
			
			
			
			<div>
				<table>
					<tbody><tr>
				<td data-settings="show">
					
				</td>
						<td><div><p><span>div</span><span>.</span><span>innerHTML</span><span> </span><span>=</span><span> </span><span>DOMPurify</span><span>.</span><span>sanitize</span><span>(</span><span>htmlMarkup</span><span>)</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
		</div>
<!-- [Format Time: 0.0001 seconds] -->




<p>In terms of parsing and serializing HTML as well as operations on the DOM tree, the following operations happen in the short snippet above:</p>



<ol><li><code>htmlMarkup</code> is parsed into the DOM Tree.</li><li>DOMPurify sanitizes the DOM Tree (in a nutshell, the process is about walking through all elements and attributes in the DOM tree, and deleting all nodes that are not in the allow-list).</li><li>The DOM tree is serialized back into the HTML markup.</li><li>After assignment to <code>innerHTML</code>, the browser parses the HTML markup again.</li><li>The parsed DOM tree is appended into the DOM tree of the document.</li></ol>



<p>Let‚Äôs see that on a simple example. Assume that our initial markup is <code>A&lt;img src=1 onerror=alert(1)&gt;B</code>. In the first step it is parsed into the following tree:</p>



<figure><img src="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-1-1024x104.png" alt="" srcset="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-1-1024x104.png 1024w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-1-300x30.png 300w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-1-768x78.png 768w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-1-1536x155.png 1536w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-1-1320x134.png 1320w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-1.png 1956w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Then, DOMPurify sanitizes it, leaving the following DOM tree:</p>



<figure><img src="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-2-1024x107.png" alt="" srcset="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-2-1024x107.png 1024w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-2-300x31.png 300w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-2-768x80.png 768w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-2-1536x161.png 1536w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-2-1320x138.png 1320w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-2.png 1952w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Then it is serialized to:</p>



<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		
<!-- [Format Time: 0.0001 seconds] -->




<p>And this is what <code>DOMPurify.sanitize</code> returns. Then the markup is parsed again by the browser on assignment to innerHTML:</p>



<figure><img src="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-3-1024x107.png" alt="" srcset="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-3-1024x107.png 1024w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-3-300x31.png 300w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-3-768x80.png 768w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-3-1536x161.png 1536w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-3-1320x138.png 1320w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-3.png 1952w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>The DOM tree is identical to the one that DOMPurify worked on, and it is then appended to the document.</p>



<p>So to put it shortly, we have the following order of operations: <strong>parsing ‚û°Ô∏è serialization ‚û°Ô∏è parsing</strong>. The intuition may be that serializing a DOM tree and parsing it again should always return the initial DOM tree. But this is not true at all. There‚Äôs even <a href="https://html.spec.whatwg.org/multipage/parsing.html#serialising-html-fragments:escapingString-3:~:text=It%20is%20possible%20that%20the%20output,not%20return%20the%20original%20tree%20structure">a warning in the HTML spec</a> in a section about serializing HTML fragments:</p>



<blockquote><p>It is possible that the output of this algorithm [serializing HTML], if parsed with an HTML parser, will not return the original tree structure. <strong>Tree structures that do not roundtrip a serialize and reparse step can also be produced by the HTML parser itself</strong>, although such cases are typically non-conforming.</p></blockquote>



<p>The important take-away is that serialize-parse roundtrip is not guaranteed to return the original DOM tree (this is also a root cause of a type of XSS known as <strong>mutation XSS</strong>). While usually these situations are a result of some kind of parser/serializer error, there are at least two cases of spec-compliant mutations.</p>



<h2>Nesting FORM element</h2>



<p>One of these cases is related to the FORM element. It is quite special element in the HTML because it cannot be nested in itself. The specification is explicit that<a href="https://html.spec.whatwg.org/#the-form-element"> it cannot have any descendant that is also a FORM</a>:</p>



<figure><img src="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-4-1024x279.png" alt="" srcset="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-4-1024x279.png 1024w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-4-300x82.png 300w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-4-768x209.png 768w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-4-1536x419.png 1536w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-4-1320x360.png 1320w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-4.png 1936w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>This can be confirmed in any browser, with the following markup:</p>



<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-5f801f5815cc6154054943" data-settings=" minimize scroll-mouseover">
		
			
			
			
			<div>
				<table>
					<tbody><tr>
				<td data-settings="show">
					
				</td>
						<td><div><p><span>&lt;</span><span>form </span><span>id</span><span>=</span><span>form1</span><span>&gt;</span></p><p><span>INSIDE_FORM1</span></p><p><span>&lt;</span><span>form </span><span>id</span><span>=</span><span>form2</span><span>&gt;</span></p><p><span>INSIDE_FORM2</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
		</div>
<!-- [Format Time: 0.0001 seconds] -->




<p>Which would yield the following DOM tree:</p>



<figure><img src="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-5-1024x80.png" alt="" srcset="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-5-1024x80.png 1024w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-5-300x24.png 300w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-5-768x60.png 768w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-5-1536x121.png 1536w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-5-1320x104.png 1320w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-5.png 1960w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>The second <code>form</code> is completely omitted in the DOM tree just as it wasn‚Äôt ever there.</p>



<p>Now comes the interesting part. If we keep reading the HTML specification, it actually gives <a href="https://html.spec.whatwg.org/multipage/parsing.html#serialising-html-fragments:the-script-element-4:~:text=DOM.-,For%20example%2C%20consider%20the%20following%20markup%3A,%3Cform">an example</a> that with a slightly broken markup with mis-nested tags, it is possible to create nested forms. Here it comes (taken directly from the spec):</p>



<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-5f801f5815ccd748015350" data-settings=" minimize scroll-mouseover">
		
			
			
			
			<div>
				<table>
					<tbody><tr>
				<td data-settings="show">
					
				</td>
						<td><div><p><span>&lt;</span><span>form </span><span>id</span><span>=</span><span>"outer"</span><span>&gt;</span><span>&lt;</span><span>div</span><span>&gt;</span><span>&lt;</span><span>/</span><span>form</span><span>&gt;</span><span>&lt;</span><span>form </span><span>id</span><span>=</span><span>"inner"</span><span>&gt;</span><span>&lt;</span><span>input</span><span>&gt;</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
		</div>
<!-- [Format Time: 0.0001 seconds] -->




<p>It yields the following DOM tree, which contains a nested form element:</p>



<figure><img src="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-6-1024x141.png" alt="" srcset="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-6-1024x141.png 1024w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-6-300x41.png 300w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-6-768x106.png 768w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-6-1536x211.png 1536w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-6-1320x182.png 1320w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-6.png 1948w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>This is not a bug in any particular browser; it results directly from the HTML spec, and is described in the algorithm of parsing HTML. Here‚Äôs the general idea:</p>



<ul><li>When you open a <code>&lt;form&gt;</code> tag, the parser needs to keep record of the fact that it was opened with a <strong>form element pointer</strong> (that‚Äôs how it‚Äôs called in the spec). If the pointer is not <code>null</code>, then <code>form</code> element cannot be created.</li><li>When you end a <code>&lt;form&gt;</code> tag, the form element pointer is always set to <code>null</code>. </li></ul>



<p>Thus, going back to the snippet:</p>



<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-5f801f5815ccf064463256" data-settings=" minimize scroll-mouseover">
		
			
			
			
			<div>
				<table>
					<tbody><tr>
				<td data-settings="show">
					
				</td>
						<td><div><p><span>&lt;</span><span>form </span><span>id</span><span>=</span><span>"outer"</span><span>&gt;</span><span>&lt;</span><span>div</span><span>&gt;</span><span>&lt;</span><span>/</span><span>form</span><span>&gt;</span><span>&lt;</span><span>form </span><span>id</span><span>=</span><span>"inner"</span><span>&gt;</span><span>&lt;</span><span>input</span><span>&gt;</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
		</div>
<!-- [Format Time: 0.0001 seconds] -->




<p>In the beginning, the form element pointer is set to the one with <code>id="outer"</code>. Then, a <code>div</code> is being started, and the <code>&lt;/form&gt;</code> end tag set the form element pointer to <code>null</code>. Because it‚Äôs <code>null</code>, the next form with <code>id="inner"</code> can be created; and because we‚Äôre currently within <code>div</code>, we effectively have a <code>form</code> nested in <code>form</code>.</p>



<p>Now, if we try to serialize the resulting DOM tree, we‚Äôll get the following markup:</p>



<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-5f801f5815cd4655660939" data-settings=" minimize scroll-mouseover">
		
			
			
			
			<div>
				<table>
					<tbody><tr>
				<td data-settings="show">
					
				</td>
						<td><div><p><span>&lt;</span><span>form </span><span>id</span><span>=</span><span>"outer"</span><span>&gt;</span><span>&lt;</span><span>div</span><span>&gt;</span><span>&lt;</span><span>form </span><span>id</span><span>=</span><span>"inner"</span><span>&gt;</span><span>&lt;</span><span>input</span><span>&gt;</span><span>&lt;</span><span>/</span><span>form</span><span>&gt;</span><span>&lt;</span><span>/</span><span>div</span><span>&gt;</span><span>&lt;</span><span>/</span><span>form</span><span>&gt;</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
		</div>
<!-- [Format Time: 0.0001 seconds] -->




<p>Note that this markup no longer has any mis-nested tags. And when the markup is parsed again, the following DOM tree is created:</p>



<figure><img src="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-7-1024x101.png" alt="" srcset="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-7-1024x101.png 1024w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-7-300x30.png 300w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-7-768x76.png 768w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-7-1536x151.png 1536w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-7-2048x202.png 2048w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-7-1320x130.png 1320w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>So this is a proof that serialize-reparse roundtrip is not guaranteed to return the original DOM tree. And even more interestingly, this is basically <strong>a spec-compliant mutation</strong>.</p>



<p>Since the very moment I was made aware of this quirk, I‚Äôve been pretty sure that it must be possible to somehow abuse it to bypass HTML sanitizers. And after a long time of not getting any ideas of how to make use of it, I finally stumbled upon another quirk in HTML specification. But before going into the specific quirk itself, let‚Äôs talk about my favorite Pandora‚Äôs box of the HTML specification: foreign content.</p>



<h2>Foreign content</h2>



<p>Foreign content is a like a Swiss Army knife for breaking parsers and sanitizers. I used it in my <a href="https://research.securitum.com/dompurify-bypass-using-mxss/">previous DOMPurify bypass</a> as well as in <a href="https://research.securitum.com/html-sanitization-bypass-in-ruby-sanitize-5-2-1/">bypass of Ruby sanitize library</a>.</p>



<p>The HTML parser can create a DOM tree with elements of three namespaces:</p>



<ul><li>HTML namespace (<code>http://www.w3.org/1999/xhtml</code>)</li><li>SVG namespace (<code>http://www.w3.org/2000/svg</code>)</li><li>MathML namespace (<code>http://www.w3.org/1998/Math/MathML</code>)</li></ul>



<p>By default, all elements are in HTML namespace; however if the parser encounters <code>&lt;svg&gt;</code> or <code>&lt;math&gt;</code> element, then it ‚Äúswitches‚Äù to SVG and MathML namespace respectively. And both these namespaces make foreign content.</p>



<p>In foreign content markup is parsed differently than in ordinary HTML. This can be most clearly shown on parsing of <code>&lt;style&gt;</code> element. In HTML namespace, <code>&lt;style&gt;</code> can only contain text; no descendants, and HTML entities are not decoded. The same is not true in foreign content: foreign content‚Äôs <code>&lt;style&gt;</code> can have child elements, and entities are decoded.</p>



<p>Consider the following markup:</p>



<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-5f801f5815cd6348574795" data-settings=" minimize scroll-mouseover">
		
			
			
			
			<div>
				<table>
					<tbody><tr>
				<td data-settings="show">
					
				</td>
						<td><div><p><span>&lt;style&gt;</span><span>&lt;a&gt;</span><span>ABC&lt;/style&gt;</span><span>&lt;</span><span>svg</span><span>&gt;</span><span>&lt;</span><span>style</span><span>&gt;</span><span>&lt;</span><span>a</span><span>&gt;</span><span>ABC</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
		</div>
<!-- [Format Time: 0.0004 seconds] -->




<p>It is parsed into the following DOM tree</p>



<figure><img src="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-8-1024x206.png" alt="" srcset="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-8-1024x206.png 1024w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-8-300x60.png 300w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-8-768x154.png 768w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-8-1536x308.png 1536w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-8-1320x265.png 1320w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-8.png 1962w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p><strong>Note:</strong> from now on, all elements in the DOM tree in this blogpost will contain a namespace. So <code>html style</code> means that it is a <code>&lt;style&gt;</code> element in HTML namespace, while <code>svg style</code> means that it is a <code>&lt;style&gt;</code> element in SVG namespace.</p>



<p>The resulting DOM tree proves my point: <code>html style</code> has only text content, while <code>svg style</code> is parsed just like an ordinary element.</p>



<p>Moving on, it may be tempting to make a certain observation. That is: if we are inside <code>&lt;svg&gt;</code> or <code>&lt;math&gt;</code> then all elements are also in non-HTML namespace. But this is not true. There are certain elements in HTML specification called <strong>MathML text integration points</strong> and <strong>HTML integration point</strong>. And the children of these elements have HTML namespace (with certain exceptions I‚Äôm listing below).</p>



<p>Consider the following example:</p>



<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-5f801f5815cdb908326048" data-settings=" minimize scroll-mouseover">
		
			
			
			
			<div>
				<table>
					<tbody><tr>
				<td data-settings="show">
					
				</td>
						<td><div><p><span>&lt;</span><span>math</span><span>&gt;</span></p><p><span>&lt;style&gt;</span><span>&lt;/style&gt;</span></p><p><span>&lt;</span><span>mtext</span><span>&gt;</span><span>&lt;style&gt;</span><span>&lt;/style&gt;</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
		</div>
<!-- [Format Time: 0.0001 seconds] -->




<p>It is parsed into the following DOM tree:</p>



<figure><img src="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-9-1024x138.png" alt="" srcset="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-9-1024x138.png 1024w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-9-300x40.png 300w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-9-768x104.png 768w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-9-1536x207.png 1536w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-9-1320x178.png 1320w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-9.png 1956w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Note how the <code>style</code> element that is a direct child of <code>math</code> is in MathML namespace, while the <code>style</code> element in <code>mtext</code> is in HTML namespace. And this is because <code>mtext</code> is <strong>MathML text integration points</strong> and makes the parser switch namespaces. </p>



<p>MathML text integration points are:</p>



<ul><li><code>math mi</code></li><li><code>math mo</code></li><li><code>math mn</code></li><li><code>math ms</code></li></ul>



<p>HTML integration points are:</p>



<ul><li><code>math annotation-xml</code> if it has an attribute called <code>encoding</code> whose value is equal to either <code>text/html</code> or <code>application/xhtml+xml</code></li><li><code>svg foreignObject</code></li><li><code>svg desc</code></li><li><code>svg title</code></li></ul>



<p>I always assumed that all children of MathML text integration points or HTML integration points have HTML namespace by default. How wrong was I! The HTML specification says that children of MathML text integration points are by default in HTML namespace with two exceptions: <code>mglyph</code> and <code>malignmark</code>. And this only happens if they are a direct child of MathML text integration points.</p>



<p>Let‚Äôs check that with the following markup:</p>



<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-5f801f5815cdc148662785" data-settings=" minimize scroll-mouseover">
		
			
			
			
			<div>
				<table>
					<tbody><tr>
				<td data-settings="show">
					
				</td>
						<td><div><p><span>&lt;</span><span>math</span><span>&gt;</span></p><p><span>&lt;</span><span>mtext</span><span>&gt;</span></p><p><span>&lt;</span><span>mglyph</span><span>&gt;</span><span>&lt;</span><span>/</span><span>mglyph</span><span>&gt;</span></p><p><span>&lt;</span><span>a</span><span>&gt;</span><span>&lt;</span><span>mglyph</span><span>&gt;</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
		</div>
<!-- [Format Time: 0.0001 seconds] -->




<figure><img src="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-10-1024x168.png" alt="" srcset="https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-10-1024x168.png 1024w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-10-300x49.png 300w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-10-768x126.png 768w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-10-1536x252.png 1536w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-10-1320x217.png 1320w, https://research.securitum.com/wp-content/uploads/sites/2/2020/10/image-10.png 1974w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Notice that <code>mglyph</code> that is a direct child of <code>mtext</code> is in MathML namespace, while the one that is a child of <code>html a</code> element is in HTML namespace.</p>



<p>Assume that we have a ‚Äúcurrent element‚Äù, and we‚Äôd like determine its namespace. I‚Äôve compiled some rules of thumb:</p>



<ul><li>Current element is in the namespace of its parent unless conditions from the points below are met.</li><li>If current element is <code>&lt;svg&gt;</code> or <code>&lt;math&gt;</code> and parent is in HTML namespace, then current element is in SVG or MathML namespace respectively.</li><li>If parent of current element is an HTML integration point, then current element is in HTML namespace unless it‚Äôs <code>&lt;svg&gt;</code> or <code>&lt;math&gt;</code>.</li><li>If parent of current element is an MathML integration point, then current element is in HTML namespace unless it‚Äôs <code>&lt;svg&gt;</code>, <code>&lt;math&gt;</code>, <code>&lt;mglyph&gt;</code> or <code>&lt;malignmark&gt;</code>.</li><li>If current element is one of <code>&lt;b&gt;, &lt;big&gt;, &lt;blockquote&gt;, &lt;body&gt;, &lt;br&gt;, &lt;center&gt;, &lt;code‚Ä¶</code></li></ul></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://research.securitum.com/mutation-xss-via-mathml-mutation-dompurify-2-0-17-bypass/">https://research.securitum.com/mutation-xss-via-mathml-mutation-dompurify-2-0-17-bypass/</a></em></p>]]>
            </description>
            <link>https://research.securitum.com/mutation-xss-via-mathml-mutation-dompurify-2-0-17-bypass/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24703230</guid>
            <pubDate>Tue, 06 Oct 2020 22:43:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hootsuite employee fired after speaking out about company's ICE deal]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 20 (<a href="https://news.ycombinator.com/item?id=24702114">thread link</a>) | @foofoo55
<br/>
October 6, 2020 | https://bc.ctvnews.ca/hootsuite-employee-fired-after-speaking-out-about-company-s-ice-deal-1.5135073 | <a href="https://web.archive.org/web/*/https://bc.ctvnews.ca/hootsuite-employee-fired-after-speaking-out-about-company-s-ice-deal-1.5135073">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://bc.ctvnews.ca/hootsuite-employee-fired-after-speaking-out-about-company-s-ice-deal-1.5135073</link>
            <guid isPermaLink="false">hacker-news-small-sites-24702114</guid>
            <pubDate>Tue, 06 Oct 2020 20:40:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Simulating Machines in Clojure]]>
            </title>
            <description>
<![CDATA[
Score 145 | Comments 15 (<a href="https://news.ycombinator.com/item?id=24701737">thread link</a>) | @stopachka
<br/>
October 6, 2020 | https://stopa.io/post/255 | <a href="https://web.archive.org/web/*/https://stopa.io/post/255">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span><p><a href="https://twitter.com/stopachka/status/1295411936625074178" target="_blank">My cofounder Joe and I recently finished SICP.</a> It was a mind-bending experience: you start from just 3 concepts, and you recursively build up algebraic equation solvers, circuit simulators, 4 interpreters, and a compiler. </p><p>At some point you experience a visceral feeling: If you were dropped in a forest‚Ä¶you could create your own computer. The project that contributed most significantly to this feeling was creating a machine simulator.</p><p>We diverged from the book by writing the simulator in Clojure rather than Scheme. Immutable data structures and higher-level concepts available to us in Clojure compressed the solution, to the point where I think you can build your own in a few days worth of hacking.</p><p>This essay will guide you through doing just that: let‚Äôs build a machine simulator, over a good few days worth of hacking! I hope this inspires you to play with Clojure and to take a deeper look at SICP. </p><p>Before we simulate general machines, let‚Äôs think about a concrete machine. <strong>How could we create a machine that could figure out factorials?</strong> </p><p>If we were writing code, factorial could look something like this:</p><pre><code><span>(</span><span>defn</span><span> factorial [n]</span>
<span>  (</span><span>loop</span><span> [res </span><span>1</span>
<span>         counter </span><span>1</span><span>]</span>
<span>    (</span><span>if</span><span> (</span><span>&gt;</span><span> counter n)</span>
<span>      res</span>
<span>      (</span><span>recur</span>
<span>        (</span><span>*</span><span> counter res)</span>
<span>        (</span><span>inc</span><span> counter)))))</span></code></pre><p>Let‚Äôs see if we could build factorials using <em>physical</em> devices.</p><p>Well, we need a way to keep track of <code value="counter">counter</code>, <code value="res">res</code>, and <code value="n">n</code>. To do that, we‚Äôll need a device that stores information. </p><h2>Bulbs</h2><p>Imagine a device that has some light bulbs inside of it. </p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1MjUwNDUyLTFlNzkzODgwLTA3ZTgtMTFlYi04MjI4LWQwYzE4ZTcwNTZhYS5wbmc" alt="image"></span></p><p>We can say that if a light bulb is <em>on,</em> that represents the number 1, and if a light bulb is <em>off</em> that represents the number 0. </p><p>If we had a bunch of light bulbs in the device, we could interpret the state of these bulbs as larger and larger binary numbers. The light bulbs in the device I just showed you for example, would represent ‚Äú10101‚Äù, which is binary for ‚Äú21‚Äù.</p><h2>Incoming Current</h2><p>Now, imagine that at all times there are a bunch of other wires connected to this device. These wires carry ‚Äúnew‚Äù charges for the light bulbs, but with a twist: the incoming charges <em>do not</em> affect the light bulbs inside just yet.</p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1MjUwNjIxLTVhMTQwMjgwLTA3ZTgtMTFlYi05ZjM2LTU2MDFkZTIyOWUwOS5wbmc" alt="image"></span></p><p>Notice how the <em>incoming charge</em> for the ‚Äúa‚Äù light bulb is ‚Äúoff‚Äù, but the bulb inside is still on. Conversely, the incoming charge "b" is "on", but the bulb is off. If our device can do this, it means that whatever the charges for the light bulbs are inside is a <em>stored value</em>. Very cool! </p><h2>Save</h2><p>Now, we need these incoming wires to do something at some point. What if this device had a ‚Äúsave‚Äù button. </p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1MjUwNjQ1LTYzMDRkNDAwLTA3ZTgtMTFlYi04NjVjLWE3YTg3OTE5Njg3ZC5wbmc" alt="image"></span></p><p>Once we pressed ‚Äúsave‚Äù, the incoming current would transfer inside the box:  </p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1MjUwNjU0LTY3Yzk4ODAwLTA3ZTgtMTFlYi04MjU1LTExNmEzMGUxNTcwMy5wbmc" alt="image"></span></p><p>Here, light bulb ‚Äúa‚Äù changes from ‚Äúon‚Äù to ‚Äúoff‚Äù, and the light bulb "b" changed from "on" to "off".</p><p>Great, now we have a way to ‚Äúsave‚Äù new numbers inside! </p><h2>Outgoing current</h2><p>We also need a way to share the state of what‚Äôs inside to other devices.  All we‚Äôd need to do to make that work, is to have a bunch of wires that leave our device, which carry the sames charges as the light bulbs: </p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1MjUxNzQ2LWY5ODVjNTAwLTA3ZTktMTFlYi05YzczLTY4ZWYwNzc3OGJlMi5wbmc" alt="image"></span></p><p>Now, if we hooked those outgoing charges to some other device, that device would receive the ‚Äúnumber‚Äù that was stored in this one. </p><h2>Registers</h2><p>What we just described is analogous to a computer‚Äôs <em>register</em> (1). Registers let us store and share information. </p><p>Now, we could use three of registers to store the value of <code value="res">res</code> <code value="counter">counter</code> and <code value="n">n</code>.</p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1MjUwODUxLWIxYjI2ZTAwLTA3ZTgtMTFlYi04NzRjLTQxODgyODAxNTQ2OC5wbmc" alt="image"></span></p><p>Next up, we‚Äôll need a device that that can ‚Äúadd‚Äù two registers. Imagine a device that had two register‚Äôs worth of incoming wires, and one register‚Äôs worth of outgoing wires: </p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1MjUwODY5LWI4ZDk3YzAwLTA3ZTgtMTFlYi05ZDM0LTQwMDE0YmQ5NDAyOC5wbmc" alt="image"></span></p><h2>Adder</h2><p>If the device could connect those incoming wires in such a way, that the outgoing wires represented the ‚Äúaddition‚Äù of those registers, we‚Äôd have an ‚Äúadder‚Äù device! </p><p>In the example above, the left register represents ‚Äú10101‚Äù (21), and the right represents ‚Äú00001‚Äù (1). The output wires are charged as ‚Äú10110‚Äù‚Ä¶which represent 22!</p><p>Similarly, we could have a device that has two register‚Äôs worth input wires, and one register‚Äôs worth of output wires: </p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1MjUwODkyLWMxMzFiNzAwLTA3ZTgtMTFlYi05OTQ1LTI4ZDljNmU4N2IzNy5wbmc" alt="image"></span></p><h2>Multiplier</h2><p>If we could connect the incoming wires in such a way, that the outgoing wires represent the result of a multiplication, boom we would have a multiplying device! </p><p>The left register above represents ‚Äú00101‚Äù (5), the right register represents ‚Äú00010‚Äù (2), and the charge of the outgoing wire is ‚Äú01010‚Äù (10). Nice! That gives us a multiplier machine. </p><h2>Comparator</h2><p>We need one more device. Imagine a device that takes two register‚Äôs worth of input wires, and only has <em>one</em> output wire: </p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1MjUwOTE1LWNhMjI4ODgwLTA3ZTgtMTFlYi05Y2RiLWM2ZDEwZTYxNzc1Yi5wbmc" alt="image"></span></p><p>If we could combine the input wires in such a way, that the output wire was ‚Äúon‚Äù when the left register was bigger, and off otherwise, we could use this as a comparator machine! </p><p>If we had all these machines, we can wire them in such a way, that lets us compute factorials: </p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1MjUwOTg1LWRlZmYxYzAwLTA3ZTgtMTFlYi05MDRjLTE2NmUzNTIyMjJkOS5wbmc" alt="image"></span></p><p>Here, we wired the output wires of <code value="res">res</code> and <code value="counter">counter</code> to the <code value="*">*</code> machine. We wired the output wires of the <code value="*">*</code> machine, to <em>be</em> the input wires of <code value="res">res</code>. </p><p>This way, if we press ‚ÄúA‚Äù, we would ‚Äústore‚Äù the result of multiplying <code value="counter">counter</code> with <code value="res">res</code>! </p><p>Similarly, we wired up the output wires of <code value="counter">counter</code> and a register that keeps the value <code value="1">1</code>, to the <code value="+">+</code> machine. We wired the output wires of the <code value="+">+</code> machine, to <em>be</em> the input wires of <code value="counter">counter</code>. </p><p>Now, If we pressed ‚ÄúB‚Äù, <code value="counter">counter</code> would be stored with the result of adding <code value="1">1</code>! </p><p>Next up, we also wired up <code value="counter">counter</code> and <code value="n">n</code> with the <code value=">">&gt;</code> machine. If we hooked up a light bulb to the output wire of the <code value=">">&gt;</code> machine for example, then whenever it was on, we would know that <code value="counter">counter</code> was larger than <code value="n">n</code>. </p><p>We‚Äôve just drawn out the ‚Äúdata path‚Äù of our machine. </p><h2>Manual Recipe</h2><p>Let‚Äôs remember our code for factorial: </p><pre><code><span>  (</span><span>loop</span><span> [res </span><span>1</span>
<span>         counter </span><span>1</span><span>]</span>
<span>    (</span><span>if</span><span> (</span><span>&gt;</span><span> counter n)</span>
<span>      res</span>
<span>      (</span><span>recur</span>
<span>        (</span><span>*</span><span> counter res)</span>
<span>        (</span><span>inc</span><span> counter))))</span></code></pre><p>imagine if we had our ‚Äúdata path‚Äù machine. What would happen if we followed the following recipe:</p><ol><li>Take a look at the output of the <code value=">">&gt;</code> machine. </li><li>If the light bulb connected to the <code value=">">&gt;</code>  machine is on, <strong>stop</strong></li></ol><p><em>Otherwise‚Ä¶</em></p><ol><li>"Press A". This will update <code value="res">res</code>  with the result of the <code value="*">*</code>  machine on <code value="res">res</code> and <code value="counter">counter</code> </li><li>‚ÄúPress B‚Äú. This will update <code value="counter">counter</code> with the result of the <code value="+">+</code>  machine on <code value="1">1</code> and <code value="counter">counter</code></li><li>Go back up to the start of the recipe</li></ol><p><strong>If we did this over and over again, once the light bulb connected to the output of the</strong>  <strong><code value=">">&gt;</code></strong> <strong>machine turns on,</strong> <strong><code value="res">res</code></strong> <strong>would contain the result of factorial!</strong> </p><h2>Automation</h2><p>Pretty cool, but this kind of manual work would be annoying. If you look at these instructions though, there‚Äôs a pretty significant insight: <em>all of those instructions are simple: "look at charge of light bulb", "press button..."</em></p><p>In fact, they‚Äôre so simple that we could wire up a machine that goes through that recipe! Imagine if we created a machine that could ‚Äúpress‚Äù buttons for us, depending on whether the output wire of the <code value=">">&gt;</code> machine is on:</p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1MjUxMDIwLWU5MjExYTgwLTA3ZTgtMTFlYi04MDJlLTI4YzIyNjZiNzQwOC5wbmc" alt="image"></span></p><p>We would be able to automate computing factorials üôÇ</p><h2>Balls and Hills</h2><p>Now, at this stage, you may be wondering: exactly <em>how</em> would <code value="*">*</code> produce output wires that represent the multiplication? How would <code value="+">+</code> work, and how would the <code value="controller">controller</code> move along? </p><p>If you think about it, these can all be reduced to very simple machines. They don‚Äôt even necessarily have to be electronic: </p><p>Imagine you had a ball rolling down some hill. You could construct something like the <code value=">">&gt;</code> machine, by putting <code value="res">res</code> and <code value="counter">counter</code> on a scale: based on what‚Äôs bigger, the ball would take a different path</p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1MjUxMDQ4LWY4MDdjZDAwLTA3ZTgtMTFlYi04NTg3LWRiYjE2ZDU3NGZkMy5wbmc" alt="image"></span></p><p>With sufficient energy, space, time, and ingenuity you really could build all of this with a ball on a hill. Now, you wouldn‚Äôt necessarily do that (2), but you can imagine how the electronic parts that make up our machines are similarly simple, logical machines: <em>turn on if off, turn off if on, etc</em>. These logical machines are called ‚Äúlogic gates‚Äù. You can look them up, but hopefully I‚Äôll have an essay for you about these machines soon üôÇ. </p><p>Now, we drew out our machine and saw how we could build them with simple devices. How could we simulate these machines? </p><p>To simulate these machines, we need to transform our <em>picture descriptions</em> into something that computers can manipulate. Computers can manipulate text much better: let‚Äôs create a <em>language</em> for describing these machines. </p><p>If we remember the pictures again:</p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1MjUxMTg3LTJmNzY3OTgwLTA3ZTktMTFlYi05ZTNlLTg3Zjg0NDkxZjQxYS5wbmc" alt="image"></span></p><p>we could transform them into a language that looks like this:</p><pre><code><span>(</span><span>def</span><span> factorial-instructions</span>
<span>  '(</span>
<span>     start</span>
<!-- -->
<span>     (</span><span>test</span><span> (</span><span>op</span><span> &gt;) (</span><span>reg</span><span> counter) (</span><span>reg</span><span> n))</span>
<span>     (</span><span>branch</span><span> (</span><span>label</span><span> done))</span>
<!-- -->
<span>     (</span><span>assign</span><span> res (</span><span>op</span><span> *) (</span><span>reg</span><span> counter) (</span><span>reg</span><span> res))</span>
<span>     (</span><span>assign</span><span> counter (</span><span>op</span><span> +) (</span><span>reg</span><span> counter) (</span><span>const</span><span> </span><span>1</span><span>))</span>
<span>     (</span><span>goto</span><span> (</span><span>label</span><span> start))</span>
<!-- -->
<span>     done))</span></code></pre><p>When the <code value="test">test</code> instruction runs, we run the <code value=">">&gt;</code> machine with <code value="counter">counter</code> and <code value="n">n</code>.</p><p>Our <code value="branch">branch</code> instruction checks if the <code value="test">test</code> instruction said <code value="yes">yes</code>. If it did, it moves to <code value="done">done</code>. Otherwise it no-ops and the machine moves forward by one.</p><p>After that, our <code value="(assign res">(assign res</code> expression is analogous to ‚Äúpress A‚Äù. <code value="(assign counter">(assign counter</code> is analogous to ‚Äúpress B‚Äù, and <code value="(goto (label start)">(goto (label start)</code> is analogous to the arrow bringing us back to the start.</p><p>With this textual representation, we can build an interpreter and simulate our machine. Let‚Äôs do this! </p><p>What does the state of our machine look like in Clojure? Well, how do we represent most things in Clojure? With maps!  Let‚Äôs represent the state of our machine as a map:</p><pre><code><span>(</span><span>def</span><span> ex-machine-state-v0</span>
<span>  {</span><span>:registry-map</span><span> {'n </span><span>10</span><span> 'res </span><span>1</span><span> 'counter </span><span>1</span><span>}</span>
<span>   </span><span>:label-&gt;idx</span><span> {'start </span><span>0</span><span> 'done </span><span>5</span><span>}})</span></code></pre><p><code value="registry-map">registry-map</code> could keep a mapping of registers to values. 
<code value="label‚Üíidx">label‚Üíidx</code> could keep a mapping of labels to their <code value="idx">idx</code> in the instruction list</p><p>With this, we can get the most foundational part of our language to work: We use <code value="(const‚Ä¶">(const‚Ä¶</code>  <code value="(reg...">(reg...</code> and <code value="(label‚Ä¶">(label‚Ä¶</code> all over the place.</p><ol><li>If our machine sees <code value="(const 1)">(const 1)</code>, it should return the actual value <code value="1">1</code></li><li>If our machine sees <code value="(reg foo)">(reg foo)</code>, it should look up whatever is in the <code value="foo">foo</code> register, and return that </li><li>If our machine sees <code value="(label foo)">(label foo)</code>, it should return the correct index in our instruction list.</li></ol><p>Let‚Äôs write this out in Clojure:</p><pre><code><span>(</span><span>def</span><span> tag first) </span><span>; (tag '(const 1)) =&gt; const</span>
<span>(</span><span>defn</span><span> tag-of? [sym s] (</span><span>=</span><span> sym (</span><span>tag</span><span> s))) </span><span>; (tag-of? 'const '(const 1)) =&gt; true</span>
<!-- -->
<span>(</span><span>defn</span><span> parse-primitive [{</span><span>:keys</span><span> [registry-map label-&gt;idx] </span><span>:as</span><span> machine-state}</span>
<span>                       prim-exp]</span>
<span>  (</span><span>condp</span><span> tag-of? prim-exp</span>
<span>    'const</span>
<span>    (</span><span>second</span><span> prim-exp)</span>
<span>    'reg</span>
<span>    (</span><span>g‚Ä¶</span></code></pre></span></p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://stopa.io/post/255">https://stopa.io/post/255</a></em></p>]]>
            </description>
            <link>https://stopa.io/post/255</link>
            <guid isPermaLink="false">hacker-news-small-sites-24701737</guid>
            <pubDate>Tue, 06 Oct 2020 20:01:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I remember what I learn]]>
            </title>
            <description>
<![CDATA[
Score 436 | Comments 107 (<a href="https://news.ycombinator.com/item?id=24700647">thread link</a>) | @flreln
<br/>
October 6, 2020 | https://vasilishynkarenka.com/learning/ | <a href="https://web.archive.org/web/*/https://vasilishynkarenka.com/learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://vasilishynkarenka.com/content/images/size/w300/2020/09/IMG_1517.jpg 300w,
                            https://vasilishynkarenka.com/content/images/size/w600/2020/09/IMG_1517.jpg 600w,
                            https://vasilishynkarenka.com/content/images/size/w1000/2020/09/IMG_1517.jpg 1000w,
                            https://vasilishynkarenka.com/content/images/size/w2000/2020/09/IMG_1517.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://vasilishynkarenka.com/content/images/size/w2000/2020/09/IMG_1517.jpg" alt="How to remember what you learn">
            </figure>

            <section>
                <div>
                    <p><em>‚ÄúI don‚Äôt remember a damn thing.‚Äù</em></p><p>The book I held my hands was full of highlights. It seemed like I‚Äôve got all colors of the rainbow on a page. Apparently, this didn‚Äôt help. When I tried recalling ideas from the book, I didn‚Äôt hear a thing. Just. Silence.</p><p>Terrified, I started questioning how much I <em>really</em> know. If I forget everything I read, I can‚Äôt apply my knowledge to the problem at hand. I can‚Äôt transfer it. And without transfer, knowledge is very much like music for deaf ears.</p><p>I quickly did the math. I was planning to invest in learning a few hours a day for the next ~75 years of my life. Staring at the number of potentially wasted hours, I knew exactly what I had to do.</p><hr><p>In the past six months, I‚Äôve devoured dozens of books, research papers, and studies on how people learn. As a result, I‚Äôve designed a learning process that works for me. It‚Äôs not perfect, but an order of magnitude better than what I had before. </p><p>In this work, I outline my workflow so that you can try it out. It applies to any subject or discipline, from programming to economics. If you stumble upon something where it doesn‚Äôt work, let me know.</p><blockquote><em>Make it time-based, take regular breaks, and learn what you‚Äôre curious about.</em></blockquote><p>The most important thing is that my learning is time-based, not goal-based. Setting learning goals such as ‚Äúread X pages today‚Äù is a way to fail because you set up the wrong incentives. When you plan to read X pages by lunch, you can‚Äôt help but begin optimizing for the goal, which leads to focusing on speed instead of understanding. And when you don‚Äôt have those ‚Äúaha‚Äù moments, it is hard to remember what you learn.</p><p>It‚Äôs also important to not overload yourself and take breaks. I do 3h learning sessions every day split into 30 min intervals with 5 min breaks. Breaks help to fall back into the diffuse mode of thinking and get access to a broader set of neural networks in my head. They also warm up my body, and I feel better after moving around for a few minutes.</p><p>As for material, I learn what I‚Äôm interested in. First, because life is <a href="http://www.paulgraham.com/vb.html">too short</a> to do things that you don‚Äôt love. Second, I‚Äôve found that studying stuff I genuinely like awakens my curiosity. And curiosity is essential to develop mastery because mastery is about depth and breadth of knowledge. </p><p>For example, if you‚Äôre learning JavaScript and you‚Äôre curious about it, you‚Äôll go and figure out how JS runtime environment works in Chrome even though the tutorial doesn‚Äôt cover it. Just because you‚Äôre interested. But if you‚Äôre not curious, then you‚Äôll just memorize the tutorial, and your knowledge will be shallow.</p><h2 id="how-my-learning-session-works">How my learning session works</h2><blockquote>Clean up working memory, apply metacognition, and "siege" the thing with questions to improve understanding.</blockquote><p>When I learn, I always have two devices on my desk. I have my laptop with the study material (ie, a book, a video, an article) on the right, and I have my iPad with a text editor open on the left.</p><p>This is how my current setup looks like:</p><figure><img src="https://vasilishynkarenka.com/content/images/2020/09/IMG_2658.jpg" alt="" srcset="https://vasilishynkarenka.com/content/images/size/w600/2020/09/IMG_2658.jpg 600w, https://vasilishynkarenka.com/content/images/size/w1000/2020/09/IMG_2658.jpg 1000w, https://vasilishynkarenka.com/content/images/size/w1600/2020/09/IMG_2658.jpg 1600w, https://vasilishynkarenka.com/content/images/size/w2400/2020/09/IMG_2658.jpg 2400w" sizes="(min-width: 720px) 720px"><figcaption>Morning learning session.</figcaption></figure><p>When I begin learning, I set a timer for 30 minutes and create three files in Drafts:</p><ol><li>A file with a timestamp where my random thoughts go.</li><li>A file with a timestamp where I think about the subject.</li><li>A file with questions.</li></ol><p><strong>The first file is a mind dump.</strong> When I start learning, I immediately begin thinking about things. It‚Äôs almost as if my brain wakes up and starts throwing ideas, tasks, and memories at me. I suspect this comes from the associative memory because I present myself with many triggers when I‚Äôm learning; words and sentences that bear special meaning to me and invoke these ideas.</p><p>But here‚Äôs the problem. If I don‚Äôt write thoughts down, I can‚Äôt focus. My working memory is overloaded with todos, ideas, and emotions. You‚Äôve probably experienced this for yourself ‚Äì your mind is running too fast, and you can‚Äôt really concentrate on what you‚Äôre learning. Having this ‚Äúdump‚Äù file is immensely useful to a) free up my working memory to focus on my learning instead of thinking about these things, and b) store these thoughts somewhere safe to go back to them later and take action.</p><p><strong>The second file is where I write about what I‚Äôm learning.</strong> Folks in the kitchen call it metacognition, which means thinking about thinking. Metacognition is the single best trick I‚Äôve found to improve understanding, and I will write more about it in the future. Whenever I don‚Äôt understand something or see that my understanding is shallow, I begin writing in the first person. It looks like this: ‚ÄúSo Peter explains that there are four characteristics of a monopoly, but I don‚Äôt really understand why branding is one of them; why so?‚Äù</p><p>It‚Äôs also important to note that I don‚Äôt write in a usual sentence-paragraph manner. Instead, I write every thought on a new line. I don‚Äôt even put dots at the end of the sentences. This helps me to focus on understanding instead of nitty-gritty styling and typos. The ‚Äúenter‚Äù key on a keyboard serves as the ‚Äúend of thought‚Äù symbol and helps formulate ideas more clearly.</p><p>Another important idea is that my editor is plain text. I‚Äôve found it incredibly liberating to operate in a plain text environment where you don‚Äôt have incentives to color, underline, bold, italicize, or do some other weird things with the text you‚Äôre writing. Instead of choosing the right font for my heading, I can focus on meaning instead. Also, my plain text app is way faster than all feature-rich text editors, and I‚Äôve found it essential for a thought input environment to be fast. Otherwise, I can't think.</p><p>Here‚Äôs a fragment from my learning of React yesterday:</p><figure><img src="https://vasilishynkarenka.com/content/images/2020/09/IMG_D7F6BD12F133-1.jpeg" alt="" srcset="https://vasilishynkarenka.com/content/images/size/w600/2020/09/IMG_D7F6BD12F133-1.jpeg 600w, https://vasilishynkarenka.com/content/images/size/w1000/2020/09/IMG_D7F6BD12F133-1.jpeg 1000w, https://vasilishynkarenka.com/content/images/size/w1600/2020/09/IMG_D7F6BD12F133-1.jpeg 1600w, https://vasilishynkarenka.com/content/images/size/w2400/2020/09/IMG_D7F6BD12F133-1.jpeg 2400w" sizes="(min-width: 720px) 720px"><figcaption>Metacognition notes from studying React.js.</figcaption></figure><p>You‚Äôre probably thinking that it‚Äôs quite a bit of writing. It is. For an hour-long learning session, I usually do about 500-1000 words in this file. But it‚Äôs worth every character, and here‚Äôs why:</p><ul><li>When I apply metacognition, I understand things <em>way</em> better than when I don‚Äôt. I‚Äôve tested many different learning modes and found metacognition to perform at least 2x better based on my later ability to recall and transfer knowledge. Also, there‚Äôs <a href="https://academicpublishingplatforms.com/downloads/pdfs/ati/volume18/201607070302_09_ATI_Vol11_Issue2_2015_Todorova_and_Karamanska_Study_motivation_satisfaction_students_e-learning_pp.82-89.pdf">some</a> <a href="http://www.csun.edu/science/ref/reasoning/how-students-learn/1.html">research</a> on metacognition as well.</li><li>Having a file with my thinking about the subject keeps my working memory clean. I don‚Äôt feel overloaded as I usually feel after reading many articles at one go. You‚Äôve probably experienced this yourself; your brain is almost melting after an hour of scrolling through the web. That‚Äôs because you present yourself with too much information without really making sense of it. After a few months of applying metacognitive practices, I realized that I can‚Äôt go back. It just feels so strange to experience that cognitive load again.</li><li>Metacognition improves remembering through elaboration and interleaving. When I‚Äôm writing my thoughts in the file, I can‚Äôt help but begin connecting them with other ideas on that topic because of associative memory. And interleaving leads to mastery.</li><li>(Speculation) Training metacognition improves my ability to transform vague notions and thoughts that I have during the day into specific words that I can write down for later analysis. This one is particularly interesting to me, but there‚Äôs no evidence besides my own experiments. And I might be biased because I‚Äôve come up with this method.</li></ul><p>Moreover, I type 2-3x faster than most people because I use <a href="https://barehands.substack.com/p/how-to-type-3x-faster">shortcuts</a>. So it‚Äôs not that bad.</p><p><strong>The third file is questions. </strong>Whenever I stumble upon something that I don‚Äôt understand, I try to break it down into a set of simple questions. Each question in the group takes on a small part of the problem. If the concept is particularly challenging, I try to ‚Äúsiege‚Äù it with questions from many many different angles and break it down even further.</p><p>When I‚Äôm beginning a new session, I always start from the previous one‚Äôs questions file. I only look at questions and answer them before I‚Äôm beginning new learning. This doesn‚Äôt sound like very much fun, but it‚Äôs actually pretty interesting to explain stuff to yourself if you do it out loud. Answering questions improves my understanding and helps to connect ideas together. And yes, answering questions counts as learning ‚Äì probably the most efficient learning you could be doing.</p><p><em>I'm not going into much detail on questions because Michael Nielsen has done a phenomenal job describing it <a href="http://augmentingcognition.com/ltm.html">here</a>.</em></p><h2 id="what-happens-after-the-session">What happens after the session</h2><blockquote>Write a dense summary, provoke elaboration, interleaving, and transfer, and choose what to never forget.</blockquote><p>After the session is done, and my three files are full of information, I begin the recap process.</p><p><strong>First, I write a three to five sentence-long summary of what I‚Äôve just studied.</strong> Here I try to distill the material‚Äôs core idea and compress the whole thing into a maximally dense chunk. When I‚Äôm summarizing, my laptop is closed. Not looking at the text helps to ‚Äúcompress‚Äù the idea to its core and make a small ‚Äúhook‚Äù to my memory to later see what the whole book was about.</p><p>Here‚Äôs how my summary note looks like: </p><figure><img src="https://vasilishynkarenka.com/content/images/2020/09/IMG_9771D059CFD1-1.jpeg" alt="Recap of studying React.js." srcset="https://vasilishynkarenka.com/content/images/size/w600/2020/09/IMG_9771D059CFD1-1.jpeg 600w, https://vasilishynkarenka.com/content/images/size/w1000/2020/09/IMG_9771D059CFD1-1.jpeg 1000w, https://vasilishynkarenka.com/content/images/size/w1600/2020/09/IMG_9771D059CFD1-1.jpeg 1600w, https://vasilishynkarenka.com/content/images/size/w2400/2020/09/IMG_9771D059CFD1-1.jpeg 2400w" sizes="(min-width: 720px) 720px"><figcaption>Recap of studying React.js.</figcaption></figure><p>Very often, what I‚Äôm writing in the summary section is not what the text was about, but what it means to me. In other words, if both of us read this text and wrote a summary of it, mine would be very different than yours.</p><p>After I‚Äôm done with the summary, I write down the answers to three questions:</p><ol><li>What are the key ideas? </li><li>How can I apply this knowledge that I learned? </li><li>How do these ideas relate to what I already know?</li></ol><p><strong>The first question speaks for itself.</strong> I try to remember what I just read and write down as many ideas as I can bring back. When I began applying the metacognition trick that I mentioned earlier, I noticed a 3x increase in the number of concepts I could recall. And as I speculate that long-term memory recall is influenced by initial interleaving and recall, this might actually help to improve your long-term memory.</p><p><strong>The second question is about transfer.</strong> The sole purpose of learning is to apply the knowledge that we learn. Without application, ‚Ä¶</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vasilishynkarenka.com/learning/">https://vasilishynkarenka.com/learning/</a></em></p>]]>
            </description>
            <link>https://vasilishynkarenka.com/learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24700647</guid>
            <pubDate>Tue, 06 Oct 2020 18:06:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Q3 Linux touchpad update: Multitouch gesture test packages now ready]]>
            </title>
            <description>
<![CDATA[
Score 379 | Comments 101 (<a href="https://news.ycombinator.com/item?id=24700537">thread link</a>) | @wbharding
<br/>
October 6, 2020 | https://bill.harding.blog/2020/10/06/q3-linux-touchpad-like-macbook-update-multitouch-gesture-test-packages-are-ready/ | <a href="https://web.archive.org/web/*/https://bill.harding.blog/2020/10/06/q3-linux-touchpad-like-macbook-update-multitouch-gesture-test-packages-are-ready/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="comments">

		<div id="respond">
		<h3 id="reply-title">Leave a Reply <small></small></h3><form action="https://bill.harding.blog/wp-comments-post.php" method="post" id="commentform" novalidate=""><p><span id="email-notes">Your email address will not be published.</span> Required fields are marked <span>*</span></p><p><label for="comment">Comment</label> </p><p><label for="author">Name <span>*</span></label> </p>
<p><label for="email">Email <span>*</span></label> </p>
<p><label for="url">Website</label> </p>
<p> <label for="wp-comment-cookies-consent">Save my name, email, and website in this browser for the next time I comment.</label></p>
<!-- Anti-spam plugin wordpress.org/plugins/anti-spam/ --><div><p><label>Current ye@r <span>*</span></label>
					
					
				  </p>

</div><!--\End Anti-spam plugin --></form>	</div><!-- #respond -->
	
</div></div>]]>
            </description>
            <link>https://bill.harding.blog/2020/10/06/q3-linux-touchpad-like-macbook-update-multitouch-gesture-test-packages-are-ready/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24700537</guid>
            <pubDate>Tue, 06 Oct 2020 17:54:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A quick introduction to data parallelism in Julia]]>
            </title>
            <description>
<![CDATA[
Score 152 | Comments 15 (<a href="https://news.ycombinator.com/item?id=24700436">thread link</a>) | @amkkma
<br/>
October 6, 2020 | https://juliafolds.github.io/data-parallelism/tutorials/quick-introduction/ | <a href="https://web.archive.org/web/*/https://juliafolds.github.io/data-parallelism/tutorials/quick-introduction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p>If you have a large collection of data and have to do similar computations on each element, <a href="https://en.wikipedia.org/wiki/Data_parallelism">data parallelism</a> is an easy way to speedup computation using multiple CPUs and machines as well as GPU(s). While this is not the only kind of parallelism, it covers a vast class of compute-intensive programs. A major hurdle for using data parallelism is that you need to unlearn some habits useful in sequential computation (i.e., patterns result in mutations of data structure). In particular, it is important to use libraries that help you describe <em>what</em> to compute rather than <em>how</em> to compute. Practically, it means to use generalized form of map and reduce operations and learn how to express your computation in terms of them. Luckily, if you already know how to write <a href="https://docs.julialang.org/en/v1/manual/arrays/#Generator-Expressions">iterator comprehensions</a>, there is not much more to learn for accessing a large class of data parallel computations.</p>  <p>This introduction primary focuses on the Julia packages that I (Takafumi Arakaki <strong><code>@tkf</code></strong>) have developed. As a result, it currently focuses on thread-based parallelism. There is simple distributed computing support. GPU support is a frequently requested feature but <a href="https://github.com/JuliaFolds/Transducers.jl/issues/236">it hasn't been implemented yet</a>. See also <a href="https://juliafolds.github.io/data-parallelism/explanation/libraries/">other parallel-computation libraries in Julia</a>.</p> <p>Also note that this introduction does not discuss how to use threading primitives such as <a href="https://docs.julialang.org/en/v1/base/multi-threading/"><code>Threads.@spawn</code></a> since it is too low-level and error-prone. For data parallelism, a higher-level description is much more appropriate. It also helps you write more reusable code; e.g., using the same code for single-threaded, multi-threaded, and distributed computing.</p>   <h2 id="getting_julia_and_libraries"><a href="#getting_julia_and_libraries">Getting <code>julia</code> and libraries</a></h2> <p>Most of the examples here may work in all Julia 1.x releases. However, for the best result, it is highly recommended to get the latest released version (1.5.2 as of writing). You can download it at <a href="https://julialang.org/">https://julialang.org/</a>.</p> <p>Once you get <code>julia</code>, you can get the dependencies required for this tutorial by running <code>using Pkg; Pkg.add(["Transducers", "ThreadsX", "OnlineStats", "FLoops", "MicroCollections", "BangBang", "Plots", "BenchmarkTools"])</code> in Julia REPL.</p> <p>If you prefer using exactly the same environment used for testing this tutorial, run the following commands</p> <pre><code>git <span>clone</span> https://github.com/JuliaFolds/data-parallelism
<span>cd</span> data-parallelism
julia --project</code></pre> <p>and then in the Julia REPL:</p> <pre><code><span>julia&gt;</span><span> <span>using</span> Pkg
</span>
<span>julia&gt;</span><span> Pkg.instantiate()</span></code></pre> <h2 id="starting_julia"><a href="#starting_julia">Starting <code>julia</code></a></h2> <p>To use multi-threading in Julia, you need to start it with multiple execution threads. If you have Julia 1.5 or higher, you can start it with the <code>-t auto</code> (or, equivalently, <code>--threads auto</code>) option:</p> <pre><code>$ julia -t auto
               _
   _       _ _(_)_     |  Documentation: https://docs.julialang.org
  (_)     | (_) (_)    |
   _ _   _| |_  __ _   |  Type "?" for help, "]?" for Pkg help.
  | | | | | | |/ _` |  |
  | | |_| | | | (_| |  |  Version 1.5.2 (2020-09-23)
 _/ |\__'_|_|_|\__'_|  |  Official https://julialang.org/ release
|__/                   |

julia&gt; Threads.nthreads()  # number of core you have
8</code></pre> <p>The command line option <code>-t</code>/<code>--threads</code> can also take the number of threads to be used. In older Julia releases, use the <code>JULIA_NUM_THREADS</code> environment variable. For example, on Linux and macOS, <code>JULIA_NUM_THREADS=4 julia</code> starts <code>juila</code> with 4 execution threads.</p> <p>For more information, see <a href="https://docs.julialang.org/en/v1/manual/multi-threading/#Starting-Julia-with-multiple-threads">Starting Julia with multiple threads</a> in the Julia manual.</p> <h3 id="starting_julia_with_multiple_worker_processes"><a href="#starting_julia_with_multiple_worker_processes">Starting <code>julia</code> with multiple worker processes</a></h3> <p>A few examples below mention <a href="https://docs.julialang.org/en/v1/stdlib/Distributed/">Distributed.jl</a>-based parallelism. Like how multi-threading is setup, you need to setup multiple worker processes to get speedup. You can start <code>julia</code> with <code>-p auto</code> (or, equivalently, <code>--procs auto</code>). Distributed.jl also lets you add worker processes after starting Julia with <a href="https://docs.julialang.org/en/v1/stdlib/Distributed/#Distributed.addprocs"><code>addprocs</code></a>:</p> <pre><code><span>using</span> Distributed
addprocs(<span>8</span>)</code></pre> <p>For more information, see <a href="https://docs.julialang.org/en/v1/manual/distributed-computing/#Starting-and-managing-worker-processes">Starting and managing worker processes</a> section in the Julia manual.</p> <h2 id="mapping"><a href="#mapping">Mapping</a></h2> <p>Mapping is probably the most frequently used function in data parallelism. Recall how Julia's sequential <code>map</code> works:</p> <pre><code>a1 = map(string, <span>1</span>:<span>9</span>, <span>'a'</span>:<span>'i'</span>)</code></pre>
<pre><code>9-element Array{String,1}:
 "1a"
 "2b"
 "3c"
 "4d"
 "5e"
 "6f"
 "7g"
 "8h"
 "9i"</code></pre>
<p>We can simply replace it with <a href="https://github.com/tkf/ThreadsX.jl"><code>ThreadsX.map</code></a> for thread-based parallelism (see also <a href="https://juliafolds.github.io/data-parallelism/explanation/libraries/">other libraries</a>):</p>
<pre><code><span>using</span> ThreadsX
a2 = ThreadsX.map(string, <span>1</span>:<span>9</span>, <span>'a'</span>:<span>'i'</span>)
<span>@assert</span> a1 == a2</code></pre>

<p>Julia's standard library Distributed.jl contains <a href="https://docs.julialang.org/en/v1/stdlib/Distributed/#Distributed.pmap"><code>pmap</code></a> as a distributed version of <code>map</code>:</p>
<pre><code><span>using</span> Distributed
a3 = pmap(string, <span>1</span>:<span>9</span>, <span>'a'</span>:<span>'i'</span>)
<span>@assert</span> a1 == a3</code></pre>

<div><div><p>üî¨ Test Code</p>
<pre><code><span>using</span> Test
    <span>@testset</span> <span>begin</span>
        <span>@test</span> a1 == a2
        <span>@test</span> a1 == a3
    <span>end</span></code></pre></div> <div><p>‚òë Pass</p>
<pre><code>Test Summary: | Pass  Total
test set      |    2      2
</code></pre></div></div>
<h3 id="practical_example_stopping_time_of_collatz_function"><a href="#practical_example_stopping_time_of_collatz_function">Practical example: Stopping time of Collatz function</a></h3>
<p>As a slightly more "practical" example, let's play with the <a href="https://en.wikipedia.org/wiki/Collatz_conjecture">Collatz conjecture</a> which states that recursive application the <em>Collatz function</em> defined as</p>
<pre><code>collatz(x) =
    <span>if</span> iseven(x)
        x √∑ <span>2</span>
    <span>else</span>
        <span>3</span>x + <span>1</span>
    <span>end</span></code></pre>

<p>reaches the number 1 for all positive integers.</p>
<p>I'll skip the mathematical background of it (as I don't know much about it) but let me mention that there are plenty of fun-to-watch explanations in YouTube :)</p>
<p>If the conjecture is correct, the number of iteration required for the initial value is finite.  In Julia, we can calculate it with</p>
<pre><code><span>function</span> collatz_stopping_time(x)
    n = <span>0</span>
    <span>while</span> <span>true</span>
        x == <span>1</span> &amp;&amp; <span>return</span> n
        n += <span>1</span>
        x = collatz(x)
    <span>end</span>
<span>end</span></code></pre>

<p>Just for fun, let's plot the stopping time of the initial values from 1 to 10,000:</p>
<pre><code><span>using</span> Plots
plt = scatter(
    map(collatz_stopping_time, <span>1</span>:<span>10_000</span>),
    xlabel = <span>"Initial value"</span>,
    ylabel = <span>"Stopping time"</span>,
    label = <span>""</span>,
    markercolor = <span>1</span>,
    markerstrokecolor = <span>1</span>,
    markersize = <span>3</span>,
    size = (<span>450</span>, <span>300</span>),
)</code></pre>
<p><img src="https://juliafolds.github.io/data-parallelism/assets/tutorials/quick-introduction/code/output/collatz_stopping_time_scatter.png" alt=""></p><p>We can easily parallelize <code>map(collatz_stopping_time, 1:10_000)</code> and get a good speedup:</p>
<pre><code><span>julia&gt;</span><span> Threads.nthreads()  
</span>4

<span>julia&gt;</span><span> <span>using</span> BenchmarkTools
</span>
<span>julia&gt;</span><span> <span>@btime</span> map(collatz_stopping_time, <span>1</span>:<span>100_000</span>);
</span>  18.116 ms (2 allocations: 781.33 KiB)

<span>julia&gt;</span><span> <span>@btime</span> ThreadsX.map(collatz_stopping_time, <span>1</span>:<span>100_000</span>);
</span>  5.391 ms (1665 allocations: 7.09 MiB)</code></pre>
<h2 id="iterator_comprehensions"><a href="#iterator_comprehensions">Iterator comprehensions</a></h2>
<p>Julia's <a href="https://docs.julialang.org/en/v1/manual/arrays/#Generator-Expressions">iterator comprehension syntax</a> is a powerful tool for composing mapping, filtering, and flattening. Recall that mapping can be written as an array or iterator comprehension:</p>
<pre><code>b1 = map(x -&gt; x + <span>1</span>, <span>1</span>:<span>3</span>)
b2 = [x + <span>1</span> <span>for</span> x <span>in</span> <span>1</span>:<span>3</span>]         
b3 = collect(x + <span>1</span> <span>for</span> x <span>in</span> <span>1</span>:<span>3</span>)  
<span>@assert</span> b1 == b2 == b3
b1</code></pre>
<pre><code>3-element Array{Int64,1}:
 2
 3
 4</code></pre>
<p>The iterator comprehension can be executed with threads by using <a href="https://github.com/tkf/ThreadsX.jl"><code>ThreadsX.collect</code></a>:</p>
<pre><code>b4 = ThreadsX.collect(x + <span>1</span> <span>for</span> x <span>in</span> <span>1</span>:<span>3</span>)
<span>@assert</span> b1 == b4</code></pre>

<div><div><p>üî¨ Test Code</p>
<pre><code><span>using</span> Test
    <span>@testset</span> <span>begin</span>
        <span>@test</span> b1 == b2 == b3
    <span>end</span></code></pre></div> <div><p>‚òë Pass</p>
<pre><code>Test Summary: | Pass  Total
test set      |    1      1
</code></pre></div></div>
<p>Note that more complex composition of mapping, filtering, and flattening can also be executed in parallel:</p>
<pre><code>c1 = ThreadsX.collect(y <span>for</span> x <span>in</span> <span>1</span>:<span>3</span> <span>if</span> isodd(x) <span>for</span> y <span>in</span> <span>1</span>:x)</code></pre>
<pre><code>4-element Array{Int64,1}:
 1
 1
 2
 3</code></pre>
<p><a href="https://juliafolds.github.io/Transducers.jl/dev/reference/manual/#Transducers.dcollect"><code>Transducers.dcollect</code></a> is for using iterator comprehensions with a distributed backend:</p>
<pre><code><span>using</span> Transducers
c2 = dcollect(y <span>for</span> x <span>in</span> <span>1</span>:<span>3</span> <span>if</span> isodd(x) <span>for</span> y <span>in</span> <span>1</span>:x)
<span>@assert</span> c1 == c2</code></pre>

<div><div><p>üî¨ Test Code</p>
<pre><code><span>@test</span> c1 == c2 == [<span>1</span>, <span>1</span>, <span>2</span>, <span>3</span>]</code></pre></div> </div>
<h2 id="pre-defined_reductions"><a href="#pre-defined_reductions">Pre-defined reductions</a></h2>
<p>Functions such as <code>sum</code>, <code>prod</code>, <code>maximum</code>, and <code>all</code> are the examples of <em>reduction</em> (aka <a href="https://en.wikipedia.org/wiki/Fold_(higher-order_function)"><em>fold</em></a>) that can be parallelized.  They are very powerful tools when combined with iterator comprehensions.  Using ThreadsX.jl, a sum of an iterator created by the comprehension syntax</p>
<pre><code>d1 = sum(x + <span>1</span> <span>for</span> x <span>in</span> <span>1</span>:<span>3</span>)</code></pre>
<pre><code>9</code></pre>
<p>can easily be parallelized by</p>
<pre><code>d2 = ThreadsX.sum(x + <span>1</span> <span>for</span> x <span>in</span> <span>1</span>:<span>3</span>)</code></pre>
<pre><code>9</code></pre>
<div><div><p>üî¨ Test Code</p>
<pre><code><span>@test</span> d1 == d2</code></pre></div> </div>
<p>For the full list of pre-defined reductions and other parallelized functions, type <code>ThreadsX.</code> and press <kbd>TAB</kbd> in the REPL.</p>
<h3 id="practical_example_maximum_stopping_time_of_collatz_function"><a href="#practical_example_maximum_stopping_time_of_collatz_function">Practical example: Maximum stopping time of Collatz function</a></h3>
<p>We can use <code>maximum</code> to compute the maximum stopping time of Collatz function on a given the range of initial values</p>
<pre><code>max_time = ThreadsX.maximum(collatz_stopping_time, <span>1</span>:<span>100_000</span>)</code></pre>
<pre><code>350</code></pre>
<div><div><p>üî¨ Test Code</p>
<pre><code><span>@test</span> max_time == <span>350</span></code></pre></div> </div>
<p>We get a speedup similar to the <code>map</code> example above:</p>
<pre><code><span>julia&gt;</span><span> <span>@btime</span> maximum(collatz_stopping_time, <span>1</span>:<span>100_000</span>)
</span>  17.625 ms (0 allocations: 0 bytes)
350

<span>julia&gt;</span><span> <span>@btime</span> ThreadsX.maximum(collatz_stopping_time, <span>1</span>:<span>100_000</span>)
</span>  5.024 ms (1214 allocations: 69.17 KiB)
350</code></pre>
<h3 id="onlinestatsjl"><a href="#onlinestatsjl">OnlineStats.jl</a></h3>
<p><a href="https://github.com/joshday/OnlineStats.jl">OnlineStats.jl</a> provides a <a href="https://joshday.github.io/OnlineStats.jl/latest/stats_and_models/">very rich</a> and <a href="https://joshday.github.io/OnlineStats.jl/latest/collections/">composable</a> set of reductions.  You can pass it as the first argument to <a href="https://github.com/tkf/ThreadsX.jl#onlinestatsjl"><code>ThreadsX.reduce</code></a>:</p>
<pre><code><span>using</span> OnlineStats: Mean
e1 = ThreadsX.reduce(Mean(), <span>1</span>:<span>10</span>)</code></pre>
<pre><code>Mean: n=10 | value=5.5</code></pre>
<div><div><p>üî¨ Test Code</p>
<pre><code><span>using</span> OnlineStats; <span>@test</span> e1 == fit!(Mean(), <span>1</span>:<span>10</span>)</code></pre></div> </div>
<div><p>üí° Note</p>
<p>While OnlineStats.jl often does not provide the fastest way to compute the given statistics when all the intermediate data can fit in memory, in many cases you don't really need the absolute best performance. However, it may be worth considering other ways to compute statistics if ThreadsX.jl + OnlineStats.jl becomes the bottleneck.</p></div>
<h2 id="manual_reductions"><a href="#manual_reductions">Manual reductions</a></h2>
<p>For non-trivial parallel computations, you need to write a custom reduction.  <a href="https://github.com/JuliaFolds/FLoops.jl">FLoops.jl</a> provides a concise set of syntax for writing custom reductions.  For example, this is how to compute sums of two quantities in one sweep:</p>
<pre><code><span>using</span> FLoops

<span>@floop</span> <span>for</span> (x, y) <span>in</span> zip(<span>1</span>:<span>3</span>, <span>1</span>:<span>2</span>:<span>6</span>)
    a = x + y
    b = x - y
    <span>@reduce</span>(s += a, t += b)
<span>end</span>
(s, t)</code></pre>
<pre><code>(15, -3)</code></pre> <div><div><p>üî¨ Test Code</p>
<pre><code><span>@test</span> (s, t) == (<span>15</span>, -<span>3</span>)</code></pre></div> </div>
<p>In this example, we do not initialize <code>s</code> and <code>t</code>; but it is not a typo.  In parallel sum, the only reasonable value of the initial state of the accumulators like <code>s</code> and <code>t</code> is zero.  So, <code>@reduce(s += a, t
+= b)</code> works as if <code>s</code> and <code>t</code> are initialized to appropriate type of zero.  However, since there are many zeros in Julia (<code>0::Int</code>, <code>0.0::Float64</code>, <code>(0x00 + 0x00im)::Complex{UInt8}</code>, ...), <code>s</code> and <code>t</code> are undefined if the input collection (i.e., the value of <code>xs</code> in <code>for
x in xs</code>) is empty.</p>
<p>To control the type of the accumulators and also to avoid <code>UndefVarError</code> in the empty case, you can set the initial value with <code>accumulator = initial_value op input</code> syntax</p>
<pre><code><span>@floop</span> <span>for</span> (x, y) <span>in</span> zip(<span>1</span>:<span>3</span>, <span>1</span>:<span>2</span>:<span>6</span>)
    a = x + y
    b = x - y
    <span>@reduce</span>(s2 = <span>0.0</span> + a, t2 = <span>0</span><span>im</span> + b)
<span>end</span>
(s2, t2)</code></pre>
<pre><code>(15.0, -3 + 0im)</code></pre> <div><div><p>üî¨ Test Code</p>
<pre><code><span>@test</span> (s2, t2) === (<span>15.0</span>, -<span>3</span> + <span>0</span><span>im</span>)</code></pre></div> </div>
<p>To understand the computation of <code>@floop</code>‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://juliafolds.github.io/data-parallelism/tutorials/quick-introduction/">https://juliafolds.github.io/data-parallelism/tutorials/quick-introduction/</a></em></p>]]>
            </description>
            <link>https://juliafolds.github.io/data-parallelism/tutorials/quick-introduction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24700436</guid>
            <pubDate>Tue, 06 Oct 2020 17:44:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gradient Boosted Decision Trees]]>
            </title>
            <description>
<![CDATA[
Score 133 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24700250">thread link</a>) | @simonwardjones
<br/>
October 6, 2020 | https://www.simonwardjones.co.uk/posts/gradient_boosted_decision_trees/ | <a href="https://web.archive.org/web/*/https://www.simonwardjones.co.uk/posts/gradient_boosted_decision_trees/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

<article>
  <div>
    <div>
      
      
      
      <p>What is a <code>gradient boosted decision tree</code>? ü§∑‚Äç‚ôÇÔ∏è</p>
<p>This article is the fifth in a series covering fundamental machine learning algorithms. Each post will be split into two parts</p>
<ol>
<li><a href="#the-idea-and-key-concepts"><strong>The idea and key concepts</strong></a>
- Most people should be able to follow this section and learn how the algorithm works</li>
<li><a href="#the-maths"><strong>The maths</strong></a>
- This is for the interested reader and will include detailed mathematical derivations followed by an implementation in Python</li>
</ol>
<p>Click</p>
<ul>
<li><a href="https://www.simonwardjones.co.uk/posts/linear_regression/">here</a> if you missed <code>From zero to Linear Regression</code></li>
<li><a href="https://www.simonwardjones.co.uk/posts/logistic_regression/">here</a> if you missed <code>From zero to Logistic Regression</code></li>
<li><a href="https://www.simonwardjones.co.uk/posts/decision_trees/">here</a> if you missed <code>From zero to Decision Tree</code></li>
<li><a href="https://www.simonwardjones.co.uk/posts/random_forests/">here</a> if you missed <code>From zero to Random Forest</code></li>
</ul>
<p>Great if you have already read these!</p>
<hr>
<h2 id="the-idea-and-key-concepts">The idea and key concepts</h2>
<p>In the last post we talked about <code>underfitting</code>, <code>overfitting</code>, <code>bias</code> and <code>variance</code>. We explained how a <code>random forest</code> uses the average output of multiple trees to reduce the chance of overfitting without introducing bias by oversimplifying (such as using only one tree but restricting the depth).</p>
<p><code>Gradient boosting</code> is a machine learning technique for regression and classification where multiple models are trained <code>sequentially</code> with each model trying to learn the mistakes from the previous models. The individual models are known as <code>weak learners</code> and in the case of <code>gradient boosted decision trees</code> the individual models are decision trees.</p>
<p>In order to give intuition it is easiest to consider first the case of regression. Imagine we are again trying to predict house prices in a desirable area of north London. With training data that looks like the following</p>





<table <thead="">
<tbody><tr>
<th></th>
<th>House size üè†</th>
<th>Garden size üå≥</th>
<th>Garage? üöô</th>
<th>True House Price üí∞</th>
</tr>

</tbody><tbody>
<tr>
<td>1</td>
<td>1000</td>
<td>700</td>
<td>Garage</td>
<td>¬£1m</td>
</tr>
<tr>
<td>2</td>
<td>770</td>
<td>580</td>
<td>No Garage</td>
<td>¬£0.75m</td>
</tr>
<tr>
<td>3</td>
<td>660</td>
<td>200</td>
<td>Garage</td>
<td>¬£0.72m</td>
</tr>
</tbody>
</table>

<p><strong>Initial prediction $f_0$</strong></p>
<p>We can make an initial prediction for each of the house prices based on an initial model, let‚Äôs call this initial model $f_0$. Often this model is very simple - just using the mean of the target variable in the training data. The following table shows the initial predictions as well as the <code>errors</code> $e_1$ (also known as the <code>residuals</code>) defined for each sample as $e_1 = y - f_0$ where $y$ is the true value and $f_0$ is our initial prediction</p>





<table <thead="">
<tbody><tr>
<th></th>
<th>True House Price üí∞</th>
<th>Initial Prediction $f_0$</th>
<th>Error $e_1$</th>
</tr>

</tbody><tbody>
<tr>
<td>1</td>
<td>¬£1m</td>
<td>¬£0.82m</td>
<td>¬£(1m - 0.82) = ¬£0.18m</td>
</tr>
<tr>
<td>2</td>
<td>¬£0.75m</td>
<td>¬£0.82m</td>
<td>¬£(0.75m - 0.82m) = -¬£0.07m</td>
</tr>
<tr>
<td>3</td>
<td>¬£0.72m</td>
<td>¬£0.82m</td>
<td>¬£(0.72m - 0.82m) = -¬£0.1m</td>
</tr>
</tbody>
</table>

<p><strong>Predicting the error</strong></p>
<p>Our initial prediction isn‚Äôt very accurate as it is just the mean house price of the training data! In order to improve this we introduce another model $f_1$ trying to predict the error $e_1$ from the sample feature values. In gradient boosted decision trees this model is itself a decision tree. So now we can predict what the error $e_1$ will be for each sample using $f_1$</p>





<table <thead="">
<tbody><tr>
<th></th>
<th>True House Price üí∞</th>
<th>Initial Prediction $f_0$</th>
<th>Error $e_1$</th>
<th>Predicted Error $f_1$</th>
</tr>

</tbody><tbody>
<tr>
<td>1</td>
<td>¬£1m</td>
<td>¬£0.82m</td>
<td>¬£(1m - 0.82) = ¬£0.18m</td>
<td>¬£0.17m</td>
</tr>
<tr>
<td>2</td>
<td>¬£0.75m</td>
<td>¬£0.82m</td>
<td>¬£(0.75m - 0.82m) = -¬£0.07m</td>
<td>¬£-0.09m</td>
</tr>
<tr>
<td>3</td>
<td>¬£0.72m</td>
<td>¬£0.82m</td>
<td>¬£(0.72m - 0.82m) = -¬£0.1m</td>
<td>¬£-0.1m</td>
</tr>
</tbody>
</table>

<p><strong>Updating our prediction using the error prediction</strong></p>
<p>For the first house our initial prediction $f_0$ was ¬£0.82m (using the mean) and as we actually know the true value we can see this gave an error $e_1$ of 0.18m. We then trained $f_1$ - a decision tree - to predict the error $e_1$ for each sample. In practise this is only a prediction of the error so it wont be exactly equal, in this toy example our $f_1$ model predicted an error of ¬£0.17m. We could now combine the two models into a new second prediction called $F_1$ by adding the predicted error $f_1$ to the initial prediction $f_0$ as in the table below</p>





<table <thead="">
<tbody><tr>
<th></th>
<th>True House Price üí∞</th>
<th>Initial Prediction $f_0$</th>
<th>Predicted Error $f_1$</th>
<th>Prediction $F_1 =f_0 + f_1$</th>
</tr>

</tbody><tbody>
<tr>
<td>1</td>
<td>¬£1m</td>
<td>¬£0.82m</td>
<td>¬£0.17m</td>
<td>¬£0.99m</td>
</tr>
<tr>
<td>2</td>
<td>¬£0.75m</td>
<td>¬£0.82m</td>
<td>-¬£0.09m</td>
<td>¬£0.73m</td>
</tr>
<tr>
<td>3</td>
<td>¬£0.72m</td>
<td>¬£0.82m</td>
<td>-¬£0.1m</td>
<td>¬£0.71m</td>
</tr>
</tbody>
</table>

<p><strong>Additive model</strong></p>
<p>Now we have a second prediction $F_1$ we can continue in a sequential manner, again calculating the error of our second prediction $e_2$ and training a tree $f_2$ to predict this second error. Then once again we add this second predicted error to the second prediction to get a third prediction $F_2 = F_1 + f_2$ and so on. As the models are summed together this approach is known as an <code>aditive model</code>. In general we have
$$F_m =  F_{m-1} + f_m$$
Where the next prediction $F_m$ is made up of the current prediction $F_{m-1}$ and the prediction of the error $f_m \sim e_m =y - F_{m-1}$ at this stage. In general the number of <code>weak learners</code> is a <code>hyper parameter</code> you have to choose.</p>
<p><strong>learning rate</strong></p>
<p>We can think of each individual <code>weak learner</code> $f_m$ as stepping our predictions closer to the true target values $y$. To reduce the variance and overfitting rather than stepping the whole predicted error we can instead add only a fraction of the step controlled by the learning rate. So rather than
$$F_m =  F_{m-1} + f_m$$
In gradient boosting we use
$$F_m =  F_{m-1} + (\text{learning rate}*f_m)$$
This process requires more steps but reduces the variance and overfitting overall.</p>
<p><strong>Summary of the algorithm</strong></p>
<ol>
<li>Make initial model $f_0$ (often the mean of y)</li>
<li>Train decision tree model $f_1$ on the error $e_1 = y - f_0$ where y is the true value</li>
<li>Calculate new prediction $F_1 = f_0 + \eta * f_1$ where $\eta$ is the learning rate</li>
<li>Repeat 2, 3 as many times as chosen where in general
<ol>
<li>Train model $f_m$ on the error $e_m = y - F_{m-1}$</li>
<li>Calculate new prediction as $F_{m-1} + \eta * f_m$</li>
</ol>
</li>
</ol>
<p>In short gradient boosting uses an initial prediction and then sequentially updates this prediction by fitting a model to the error at that stage.</p>
<p>In the following section we explore the mathematical details and extend the algorithm to the classification setting. We also cover the intuition behind gradient boosting as gradient descent.</p>
<hr>
<h2 id="the-maths">The maths</h2>
<p><strong>Why is it called gradient boosting?</strong></p>
<p>In general in <code>supervised learning</code> we aim to find a model $F$ to fit the data such that the predicted value $\hat{y}_i$ for the $j$th training example $\mathbf{x}_i$ is approximately equal to the $j$th target value $y_i$ or equivalently</p>
<p>
    $$
\hat{y}_i=F(\mathbf{x}_i)\sim y_i \quad\forall j \in {1,\dots,n} 
$$
</p><p>
Where n is the number of training samples.</p>
<p>Equivalently we aim to minimise a loss function $\mathcal{L(y, \hat{y})}$ which tells us how badly the model $\hat{y}$ currently fits the data $y$.</p>
<p>In a <code>parametric</code> setting (e.g. logistic regression) the model can be written as

</p><p>
    $$
\hat{y}_i=F_{\mathbf{\theta}}(\mathbf{x}_i)
$$
</p>
<p>Where the subscript $\mathbf{\theta}$ indicates the models dependence on the parameters. We can also write the loss in terms of $\mathbf{\theta}$ as $\mathcal{L(y, \hat{y}(\mathbf{\theta})})$. In this setting we update the model parameters using gradient descent. That is we iteratively update the model parameters by stepping the parameters in the direction of the negative gradient of the loss function with respect to the parameters (where $\eta$ is the learning rate).</p>

<p>
    $$
\mathbf{\theta}^{m+1} = \mathbf{\theta}^{m} - \eta* \frac{\partial\mathcal{L}}{\partial{\mathbf{\theta}^m}}
$$
</p>
<p>Instead of differentiating the loss with respect to $\mathbf{\theta}$ we can differentiate with respect to the prediction $\hat{y}$ directly. If we think about gradient descent ideally we would update $\hat{y}$ as follows to reduce the cost function</p>

<p>
    $$
\hat{y}_i \to \hat{y}_i - \eta\frac{\partial\mathcal{L}}{\partial{\hat{y}_i}}
$$
</p>
<p>Equivalently we update $F_{m-1}$ by adding another ‚Äúdelta model‚Äù $f_{m+1}$</p>

<p>
    $$
\hat{y}_i = F_m(\mathbf{x}_i) + f_{m+1}(\mathbf{x}_i) \quad\forall j \in {1,\dots,n} 
$$
</p>
<p>Where $\eta$ is the learning rate and

</p><p>
    $$
f_{m+1}(\mathbf{x}_i)= -\eta\frac{\partial\mathcal{L}}{\partial{\hat{y}_i}}
$$
</p>
<p>In practise we cannot set this delta model exactly so we train a model on the data to fit

</p><p>
    $$
 - \eta\frac{\partial\mathcal{L}}{\partial{\hat{y}_i}}$$
</p><p>
In general this gradient can be fitted with any model but gradient boosted decision trees use a decision tree - hence the name! Note each tree will have it‚Äôs own Loss $\mathcal{L}^{f_{m+1}}$ separate to the global loss $\mathcal{L}$.</p>
<p><strong>Key Point</strong></p>
<p>The gradient boosted decision tree is not trained on the residuals at each step. Rather it is trained on the negative gradient of the loss function evaluated using the prediction of the current step - which happens to be the residual for some common cost functions.</p>
<h3 id="regression">Regression</h3>
<p>In the case of regression we define the loss function as the mean square error</p>
<p>$$
\mathcal{L}(\hat{y}) = \frac{1}{2n}\sum_{i=1}^{n}(y_i-\hat{y}_i)^2
$$
hence
$$
-\eta\frac{\partial\mathcal{L}}{\partial{\hat{y}_i}} = \frac{\eta}{n}(y_i-\hat{y}_i)
$$</p>
<p>How the process looks:</p>
<p>We fit $f_0(x)\sim y$ then $F_0(x) = f_0(x)$<br>
We fit $f_1(x)\sim (y-F_0(x))$ then $F_1(x) = F_0(x) + \eta f_1(x)$<br>
We fit $f_2(x)\sim (y-F_1(x))$ then $F_2(x) = F_1(x) + \eta f_2(x)$<br>
We fit $f_3(x)\sim (y-F_2(x))$ then $F_3(x) = F_2(x) + \eta f_3(x)$<br>
‚Ä¶<br>
We fit $f_m(x)\sim (y-F_{m-1}(x))$ then $F_m(x) = F_{m-1}(x) + \eta f_m(x)$</p>
<p>Then predictions $\hat{y} = F_m(x)$</p>
<h4 id="binomial-classification">Binomial Classification</h4>
<p>Suppose our iterative model was $\hat{y}_i = F_m(x_i)$ where the $\hat{y}_i$ directly represented the probability $x_i$ is in class 1. i.e. $P(x_i \in C_1)$ where $C_1$ represents class 1.</p>
<p>In this case the delta model doesn‚Äôt make sense as we would be directly adding to a probability value. As in logistic regression it is often the case to fit the model to a transformation of probability.</p>
<p>We define a model
$$
\hat{y}\sim F(x)
$$
where
$$
\hat{p} = \frac{1}{1+e^{-\hat{y}}}
$$
so
$$
\hat{y} = \log\left(\frac{\hat{p}}{1-\hat{p}}\right)
$$</p>
<p>where $\hat{p}$ represents the probability of being in class 1, $\hat{y}$ is sometimes known as the logit.</p>
<p>Note $\hat{p}\in[0,1],\quad \hat{y}\in(-\infty,\infty),\quad y\in{0,1}$</p>
<p>Hence in the classification setting the gradient boosted decision tree predicts $\hat{y}$ as a sum of multiple delta models. The probability values are then calculated by transforming $\hat{y}$ using the sigmoid function (a.k.a the expit function).</p>
<p>We will use the following fact later on</p>

<p>
    $$
\begin{align}
\hat{p} &amp;= \frac{1}{1+e^{-\hat{y}}} \quad so \\
\hat{p} &amp;= ‚Ä¶</p></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.simonwardjones.co.uk/posts/gradient_boosted_decision_trees/">https://www.simonwardjones.co.uk/posts/gradient_boosted_decision_trees/</a></em></p>]]>
            </description>
            <link>https://www.simonwardjones.co.uk/posts/gradient_boosted_decision_trees/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24700250</guid>
            <pubDate>Tue, 06 Oct 2020 17:26:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Time for a WTF MySQL Moment]]>
            </title>
            <description>
<![CDATA[
Score 306 | Comments 110 (<a href="https://news.ycombinator.com/item?id=24698660">thread link</a>) | @gbl08ma
<br/>
October 6, 2020 | https://gbl08ma.com/time-for-a-wtf-mysql-moment/ | <a href="https://web.archive.org/web/*/https://gbl08ma.com/time-for-a-wtf-mysql-moment/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content-holder" role="main">
	<div>
		<article id="post-21465">			
			
	<p>
				October 4, 2020 / gbl08ma / 0 Comments	</p>
	<p>Many people have been experiencing strange time perception phenomenon throughout 2020, but certain database management systems have been into time shenanigans for way longer. This came to my attention when a friend received the following exception in one of his projects (his popular Discord bot, <a href="https://accord.abcric.net/">Accord</a>), coming from the MySQL connector being used with EF Core:</p>
<pre>MySqlException: Incorrect TIME value: '960:00:00.000000'</pre>
<p>Not being too experienced with MySQL, as I prefer PostgreSQL for reasons that will soon become self-evident, for a brief moment I assumed the incorrection in this value was the hundreds of hours, as one could reasonably assume that maybe TIME values were capped at 24 hours, or that a different syntax was needed for values spanning multiple days, and that one would need to use, say, ‚Äú40:00:00:00‚Äù to represent 40 days. But reality turned out to be more complex and harder to explain.</p>
<p>With checking the documentation being the most natural next step, the MySQL documentation goes:</p>
<blockquote><p>MySQL retrieves and displays <code>TIME</code> values in <em><code>'hh:mm:ss'</code></em> format (or <em><code>'hhh:mm:ss'</code></em> format for large hours values).</p></blockquote>
<p>So far so good, our problematic TIME value respects this format, but the fact that <code>hh</code> and <code>hhh</code> are explicitly pointed out is already suspect (what about values with over 999 hours?). The next sentence in the documentation explains why, and left me with even more questions of the WTF kind:</p>
<blockquote><p><code>TIME</code> values may range from <code>'-838:59:59'</code> to <code>'838:59:59'</code>.</p></blockquote>
<p>Oooh Kaaay‚Ä¶ that‚Äôs an oddly specific range, but I‚Äôm sure there has to be a technical reason for it. 839 hours is 34.958(3) days, and the whole range spans exactly 6040798 seconds. The documentation also mentions the following:</p>
<blockquote><p>MySQL recognizes <code>TIME</code> values in several formats, some of which can include a trailing fractional seconds part in up to microseconds (6 digits) precision.</p></blockquote>
<p>Therefore, it also makes sense to point out that the whole interval spans <span id="display">6 040 798 </span>000 000 microseconds, but again, these seem like oddly specific numbers. They are not near any power of two, the latter being between 2<sup>42</sup> and 2<sup>43</sup>, so MySQL must be using some awkward internal representation format. But before we dive into that, let me just point out how bad this type is. It is the closest MySQL has to a time interval type, and yet it can‚Äôt deal with intervals that are just a bit over a month long. How much is that ‚Äúbit‚Äù? Not even a nice, rounded number of days, it seems.</p>
<p>To make matters worse, it appears that the most popular EF Core MySQL provider maps .NET‚Äôs <code>TimeSpan</code> to <code>TIME</code> by default, despite the fact that&nbsp;<code>TimeSpan</code> can contain intervals in the dozens of millennia (it uses a 64 bit integer and has 10<sup>-8</sup> s precision) compared to TIME‚Äôs measly ‚Äúa bit over two months‚Äù. This is an <a href="https://github.com/PomeloFoundation/Pomelo.EntityFrameworkCore.MySql/issues/1046">issue other people have run into</a>, and the discussion in that issue includes a ‚ÄúThis mimics the behavior of SQL Server‚Äù remark, which made me go check and, sure enough, SQL Server‚Äôs <code>time</code> is meant to encode a time of day and has a range of 00:00:00.0000000 through 23:59:59.9999999, something which overall makes more sense to me than MySQL‚Äôs odd TIME range.</p>
<p>So let‚Äôs go back to MySQL. What is the reasoning behind such an <em>interesting</em> range? The <a href="https://dev.mysql.com/doc/internals/en/date-and-time-data-type-representation.html">MySQL Internals Manual</a> says that the storage for the TIME type has changed with version 5.6.4, having gained support for fractional seconds in this version. It uses 3 bytes for the non-fractional type. Now, had they just used these 3 bytes to encode a number of seconds, they would have been able to support intervals spanning over 2330 hours, which would already be a considerable improvement over the current 838 hours maximum, even if still a bit useless when it comes to mapping a <code>TimeSpan</code> to it.</p>
<p>This means their encoding must be wasting bits, probably so it is easier to work with‚Ä¶ not sure in what circumstances exactly, but maybe it makes more sense if your database management system (and/or your conception of what the users will do with it) just loves strings, and you really want to speed up the hh:mm:ss representation. So, behold:</p>
<blockquote>
<pre>1 bit sign (1= non-negative, 0= negative)
1 bit unused (reserved for future extensions)
10 bits hour (0-838)
6 bits minute (0-59) 
6 bits second (0-59) 
---------------------
24 bits = 3 bytes</pre>
</blockquote>
<p>This explains everything, right? Well, look closely. 10 bits for the hour‚Ä¶ and a range of 0 to 838. I kindly remind you that 2<sup>10</sup> is 1024, not 838. The plot thickens. I‚Äôm not the first person to wonder about this, of course, <a href="https://stackoverflow.com/questions/39259910/why-is-mysqls-maximum-time-limit-8385959">this was asked on StackOverflow before</a>. The accepted answer in that question explains everything, but <em>it almost didn‚Äôt</em>, as it initially dismisses the odd choice of 838 as ‚Äúbackward compatibility with applications that were written a while ago‚Äù, and only later it is explained that this choice had to do with compatibility with MySQL version‚Ä¶ 3, from the times when, you know, Windows 98 was a fresh operating system and Linux wasn‚Äôt 10 years old yet.</p>
<p>In MySQL 3, the TIME type used 3 bytes as well, but they were used differently. One of the bits was used for the sign as well, but the remaining 23 bits were an integer value produced like this: Hours √ó 10000 + Minutes √ó 100 + Seconds; in other words, the two least significant decimal digits of the number contained the seconds, the next two contained the minutes, and the remaining ones contained the hours. 2<sup>23</sup> is 83888608, i.e. 838:86:08, therefore, the maximum valid time in this format is 838:59:59. This format is even less wieldy than the current one, requiring multiplication and division to do basically anything with it, except string formatting and parsing ‚Äì once again showing that MySQL places too much value on string IO and not so much on having types that are convenient for internal operations and non-string-based protocols.</p>
<p>MySQL developers had ample opportunities to fix this type, or at the very least introduce an alternative one that is free of this reduced range. They changed this type twice from MySQL 3 until now, but decided to retain the range every time, supposedly for compatibility reasons. I am struggling to imagine the circumstances where increasing the value range for a type can break compatibility with an application ‚Äì do types in MySQL have defined overflow behaviors? Is any sane person writing applications where they are relying on a database type‚Äôs intrinsic limits for validation? If yes, who looked at this awkward 838 hours range and thought of it as an appropriate limitation to carry unchanged into their application‚Äôs data model? At this point, I don‚Äôt even want to know.</p>
<p>Despite having changed twice throughout MySQL‚Äôs lifetime, the TIME type is still quite an awkward and limited one. That unused, ‚Äúreserved for future extensions‚Äù bit is, in my opinion, really the <em>pi√®ce de r√©sistance</em> here. Here‚Äôs hoping that one day it will be used to signify a ‚Äúlegacy‚Äù TIME value and that, by then, MySQL and/or MariaDB will have support for a proper type like <a href="https://www.postgresql.org/docs/current/datatype-datetime.html">PostgreSQL‚Äôs INTERVAL</a>, which has a range of +/- 178000000 years and a very reasonable microsecond precision.</p>
	</article>		
	</div>
	</div></div>]]>
            </description>
            <link>https://gbl08ma.com/time-for-a-wtf-mysql-moment/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24698660</guid>
            <pubDate>Tue, 06 Oct 2020 15:23:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hiring for tech jobs has increased more than 100% in these Midwestern cities]]>
            </title>
            <description>
<![CDATA[
Score 118 | Comments 277 (<a href="https://news.ycombinator.com/item?id=24698449">thread link</a>) | @KaiserSanchez
<br/>
October 6, 2020 | https://www.purpose.jobs/blog/hiring-tech-jobs-has-increased-in-midwestern-cities | <a href="https://web.archive.org/web/*/https://www.purpose.jobs/blog/hiring-tech-jobs-has-increased-in-midwestern-cities">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><img src="https://www.purpose.jobs/hubfs/social-suggested-images/www.michiganbusiness.org49d2d3globalassetsimagesnews1440-bannersdetroit-1440.jpg" alt="Hiring for Tech Jobs has Increased More than 100% in These Midwestern Cities">
</p></div><div>
<p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p>When people think tech jobs, they tend to think Silicon Valley or New York City.</p>
<!--more-->
<p>They don‚Äôt think about the Midwest, which is better known for rolling farmland and wide-open spaces than a booming tech scene where startups thrive.</p>
<p>But it‚Äôs time to think again about the Midwest.&nbsp;</p>
<p><a href="https://www.purpose.jobs/midwest-salary-report?utm_source=blog&amp;utm_medium=web&amp;utm_campaign=community" rel="noopener" target="_blank"><img src="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-1-midwest.jpg?width=600&amp;name=img-1-midwest.jpg" alt="img-1-midwest" width="600" srcset="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-1-midwest.jpg?width=300&amp;name=img-1-midwest.jpg 300w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-1-midwest.jpg?width=600&amp;name=img-1-midwest.jpg 600w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-1-midwest.jpg?width=900&amp;name=img-1-midwest.jpg 900w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-1-midwest.jpg?width=1200&amp;name=img-1-midwest.jpg 1200w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-1-midwest.jpg?width=1500&amp;name=img-1-midwest.jpg 1500w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-1-midwest.jpg?width=1800&amp;name=img-1-midwest.jpg 1800w" sizes="(max-width: 600px) 100vw, 600px"></a></p>
<p>This region comprises 19 percent of the <em>entire U.S. GDP</em>. Twenty-five percent of all computer science grads get their degrees in the Midwest. Forty-five percent of Fortune 500 countries are located here, as is 60 percent of all U.S. manufacturing.</p>
<p>And, as icing on the cake, seven of the top 10 <a href="https://www.purpose.jobs/midwest-salary-report?utm_source=blog&amp;utm_medium=web&amp;utm_campaign=community" rel="noopener" target="_blank">most affordable states</a> in the nation are in the Midwest.</p>
<p>What does that have to do with tech jobs? Well, increasingly, startup founders and investors are taking note of all those things the Midwest has to offer, as well as the excellent quality of life and affordable cost of living you can find in so many cities in the Heartland. They‚Äôre realizing you don‚Äôt have to be based in the Golden State or the Big Apple if you want your startup to succeed. You can be based in the Midwest and find just as much success.</p>
<div><p>So tech startups are booming in the Midwest. Don‚Äôt believe us? The proof is in the numbers.</p></div>
<h2><span>In 3 of the Midwest‚Äôs Top 10 Cities, Tech Hiring Is Up More than 100% In the Last 3 Years</span></h2>
<div><p>We‚Äôll let the numbers tell the full story. These are the Midwest‚Äôs top 10 cities in terms of growth and offerings for tech workers.&nbsp;</p></div>
<h3><span>Chicago: 8th in the U.S. for Net Tech Employment</span><a href="https://www.purpose.jobs/midwest-salary-report?utm_source=blog&amp;utm_medium=web&amp;utm_campaign=community" rel="noopener" target="_blank"><img src="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-2-chicago.jpg?width=600&amp;name=img-2-chicago.jpg" alt="img-2-chicago" width="600" srcset="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-2-chicago.jpg?width=300&amp;name=img-2-chicago.jpg 300w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-2-chicago.jpg?width=600&amp;name=img-2-chicago.jpg 600w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-2-chicago.jpg?width=900&amp;name=img-2-chicago.jpg 900w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-2-chicago.jpg?width=1200&amp;name=img-2-chicago.jpg 1200w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-2-chicago.jpg?width=1500&amp;name=img-2-chicago.jpg 1500w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-2-chicago.jpg?width=1800&amp;name=img-2-chicago.jpg 1800w" sizes="(max-width: 600px) 100vw, 600px"></a></h3>
<div><p><a href="https://www.purpose.jobs/chicago" rel="noopener" target="_blank">Chicago</a> is the No. 1 city in the Midwest for growth in the tech sector, and it ranks eighth in the country for net tech employment. Currently, there are 344,146 people in Chicago working in tech jobs. The city saw nearly 18 percent growth in its net tech employment from 2010 to 2018, and from just 2017 to 2018, job posting in the tech sector increased by a whopping 73 percent.</p></div>
<h3><span>Detroit: 11th in the U.S. for Net Tech Employment</span><a href="https://www.purpose.jobs/midwest-salary-report?utm_source=blog&amp;utm_medium=web&amp;utm_campaign=community" rel="noopener" target="_blank"><img src="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-3-detroit.jpg?width=600&amp;name=img-3-detroit.jpg" alt="img-3-detroit" width="600" srcset="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-3-detroit.jpg?width=300&amp;name=img-3-detroit.jpg 300w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-3-detroit.jpg?width=600&amp;name=img-3-detroit.jpg 600w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-3-detroit.jpg?width=900&amp;name=img-3-detroit.jpg 900w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-3-detroit.jpg?width=1200&amp;name=img-3-detroit.jpg 1200w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-3-detroit.jpg?width=1500&amp;name=img-3-detroit.jpg 1500w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-3-detroit.jpg?width=1800&amp;name=img-3-detroit.jpg 1800w" sizes="(max-width: 600px) 100vw, 600px"></a></h3>
<p>Coming in just behind Chicago is <a href="https://www.purpose.jobs/detroit" rel="noopener" target="_blank">Detroit</a>, which ranks 11th in the U.S. for its net tech employment. 241,135 people work in the tech sector in Detroit, where net tech employment increased by 37.2 percent from 2010 to 2018. From 2017 to 2018, job postings in tech rose 41 percent, making Detroit a fantastic spot to look for a startup job.</p>
<p><em>Looking to get connected with top startups? Join the purpose.jobs talent community to start applying for Midwest startup jobs.</em> <!--HubSpot Call-to-Action Code --><span id="hs-cta-wrapper-6fe04a32-7b40-49d0-873c-8f8ae79aa1dd"><span id="hs-cta-6fe04a32-7b40-49d0-873c-8f8ae79aa1dd"><!--[if lte IE 8]><div id="hs-cta-ie-element"></div><![endif]--><a href="https://cta-redirect.hubspot.com/cta/redirect/2873777/6fe04a32-7b40-49d0-873c-8f8ae79aa1dd" target="_blank"><img id="hs-cta-img-6fe04a32-7b40-49d0-873c-8f8ae79aa1dd" src="https://no-cache.hubspot.com/cta/default/2873777/6fe04a32-7b40-49d0-873c-8f8ae79aa1dd.png" alt="Create a free profile."></a></span></span><!-- end HubSpot Call-to-Action Code --></p>

<h3><span>Minneapolis: Nearly 200,000 Tech Jobs and Growing</span><a href="https://www.purpose.jobs/midwest-salary-report?utm_source=blog&amp;utm_medium=web&amp;utm_campaign=community" rel="noopener" target="_blank"><img src="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-4-minn.jpg?width=600&amp;name=img-4-minn.jpg" alt="img-4-minn" width="600" srcset="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-4-minn.jpg?width=300&amp;name=img-4-minn.jpg 300w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-4-minn.jpg?width=600&amp;name=img-4-minn.jpg 600w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-4-minn.jpg?width=900&amp;name=img-4-minn.jpg 900w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-4-minn.jpg?width=1200&amp;name=img-4-minn.jpg 1200w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-4-minn.jpg?width=1500&amp;name=img-4-minn.jpg 1500w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-4-minn.jpg?width=1800&amp;name=img-4-minn.jpg 1800w" sizes="(max-width: 600px) 100vw, 600px"></a></h3>
<div><p>Third in the Midwest for growth is Minneapolis, a thriving city many overlook, despite its tech workforce of 196,151 and growing. Minneapolis is ranked 14th in the U.S. overall for net tech employment, which increased 17 percent in the city from 2010 to 2018. What‚Äôs even more impressive is that job postings in the tech sector increased 76 percent in Minneapolis from 2017 to 2018.</p></div>
<h3><span>Kansas City: Where New Tech Jobs Have Almost Doubled in Recent Years<br></span><a href="https://www.purpose.jobs/midwest-salary-report?utm_source=blog&amp;utm_medium=web&amp;utm_campaign=community" rel="noopener" target="_blank"><img src="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-5-kc.jpg?width=600&amp;name=img-5-kc.jpg" alt="img-5-kc" width="600" srcset="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-5-kc.jpg?width=300&amp;name=img-5-kc.jpg 300w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-5-kc.jpg?width=600&amp;name=img-5-kc.jpg 600w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-5-kc.jpg?width=900&amp;name=img-5-kc.jpg 900w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-5-kc.jpg?width=1200&amp;name=img-5-kc.jpg 1200w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-5-kc.jpg?width=1500&amp;name=img-5-kc.jpg 1500w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-5-kc.jpg?width=1800&amp;name=img-5-kc.jpg 1800w" sizes="(max-width: 600px) 100vw, 600px"></a></h3>
<div><p>Kansas City has more to boast about than its Super Bowl win. The city is home to 100,782 people who work in the tech sector, making it 24th in the U.S. for net tech employment. Kansas City also saw 17.3 percent growth in its net tech employment from 2010 to 2018, and 82 percent growth in its tech job posting just from 2017 to 2018, indicating that its rate of growth is ramping up even faster in recent years than over the last decade.</p></div>
<h3><span>Cincinnati: Nearly 100,000 Tech Workers and Steady Growth of New Jobs<br></span><a href="https://www.purpose.jobs/midwest-salary-report?utm_source=blog&amp;utm_medium=web&amp;utm_campaign=community" rel="noopener" target="_blank"><img src="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-6-cinci.jpg?width=600&amp;name=img-6-cinci.jpg" alt="img-6-cinci" width="600" srcset="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-6-cinci.jpg?width=300&amp;name=img-6-cinci.jpg 300w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-6-cinci.jpg?width=600&amp;name=img-6-cinci.jpg 600w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-6-cinci.jpg?width=900&amp;name=img-6-cinci.jpg 900w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-6-cinci.jpg?width=1200&amp;name=img-6-cinci.jpg 1200w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-6-cinci.jpg?width=1500&amp;name=img-6-cinci.jpg 1500w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-6-cinci.jpg?width=1800&amp;name=img-6-cinci.jpg 1800w" sizes="(max-width: 600px) 100vw, 600px"></a></h3>
<div><p>Fifth on the list of growing Midwest cities in <a href="https://www.purpose.jobs/cincinnati" rel="noopener" target="_blank">Cincinnati</a>, where 82,088 workers already have tech jobs. From 2010 to 2018, the city saw a 23.9 percent increase in its net tech employment, and job postings in the tech sector jumped up 41 percent just from 2017 to 2018. That lands Cincinnati 28th in the U.S. for net tech employment, and there‚Äôs plenty of opportunity here as the city continues to grow.</p></div>
<h3><span>Cleveland: Job Growth that Nearly Doubled in Just One Year</span><a href="https://www.purpose.jobs/midwest-salary-report?utm_source=blog&amp;utm_medium=web&amp;utm_campaign=community" rel="noopener" target="_blank"><img src="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-7-cleveland.jpg?width=600&amp;name=img-7-cleveland.jpg" alt="img-7-cleveland" width="600" srcset="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-7-cleveland.jpg?width=300&amp;name=img-7-cleveland.jpg 300w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-7-cleveland.jpg?width=600&amp;name=img-7-cleveland.jpg 600w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-7-cleveland.jpg?width=900&amp;name=img-7-cleveland.jpg 900w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-7-cleveland.jpg?width=1200&amp;name=img-7-cleveland.jpg 1200w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-7-cleveland.jpg?width=1500&amp;name=img-7-cleveland.jpg 1500w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-7-cleveland.jpg?width=1800&amp;name=img-7-cleveland.jpg 1800w" sizes="(max-width: 600px) 100vw, 600px"></a></h3>
<div><p>Sixth in the Midwest is <a href="https://www.purpose.jobs/cleveland" rel="noopener" target="_blank">Cleveland</a>, an oft-overlooked Ohio metropolis that has plenty to offer tech workers ‚Äî&nbsp;just ask the 76,698 workers who have tech jobs there. Cleveland saw 16.3 percent growth in its net tech employment from 2010 to 2018, which led to its 93 percent increase in tech job postings from 2017 to 2018. Of all the cities in the U.S., Cleveland ranks 29th for net tech employment, making it a place well worth considering whether you‚Äôre looking for a tech job or hoping to found a startup in a new home.</p></div>
<h3><span>Indianapolis: More than 100 Percent Job Growth in One Year</span><a href="https://www.purpose.jobs/midwest-salary-report?utm_source=blog&amp;utm_medium=web&amp;utm_campaign=community" rel="noopener" target="_blank"><img src="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-8-indi.jpg?width=600&amp;name=img-8-indi.jpg" alt="img-8-indi" width="600" srcset="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-8-indi.jpg?width=300&amp;name=img-8-indi.jpg 300w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-8-indi.jpg?width=600&amp;name=img-8-indi.jpg 600w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-8-indi.jpg?width=900&amp;name=img-8-indi.jpg 900w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-8-indi.jpg?width=1200&amp;name=img-8-indi.jpg 1200w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-8-indi.jpg?width=1500&amp;name=img-8-indi.jpg 1500w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-8-indi.jpg?width=1800&amp;name=img-8-indi.jpg 1800w" sizes="(max-width: 600px) 100vw, 600px"></a></h3>
<div><p><a href="https://www.purpose.jobs/indianapolis" rel="noopener" target="_blank">Indianapolis</a> is the first of our three Midwestern cities that increased their startup job growth more than 100 percent ‚Äî&nbsp;the city saw a 121 percent increase in new tech job postings from 2017 to 2018, after 24.2 percent growth in net tech employment from 2010 to 2018. As of now, there are 74,615 people employed in the tech sector in Indy, and that number is only going up.</p></div>
<h3><span>Milwaukee: Tied for Highest Increase in New Tech Jobs in the Midwest</span><a href="https://www.purpose.jobs/midwest-salary-report?utm_source=blog&amp;utm_medium=web&amp;utm_campaign=community" rel="noopener" target="_blank"><img src="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-9-milwak.jpg?width=600&amp;name=img-9-milwak.jpg" alt="img-9-milwak" width="600" srcset="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-9-milwak.jpg?width=300&amp;name=img-9-milwak.jpg 300w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-9-milwak.jpg?width=600&amp;name=img-9-milwak.jpg 600w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-9-milwak.jpg?width=900&amp;name=img-9-milwak.jpg 900w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-9-milwak.jpg?width=1200&amp;name=img-9-milwak.jpg 1200w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-9-milwak.jpg?width=1500&amp;name=img-9-milwak.jpg 1500w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-9-milwak.jpg?width=1800&amp;name=img-9-milwak.jpg 1800w" sizes="(max-width: 600px) 100vw, 600px"></a></h3>
<div><p>With an astonishing 137 percent increase in new tech job postings from 2017 to 2018, Milwaukee is one of the most promising spots in the Midwest for anyone looking for a tech position. The city currently boasts 71,755 tech workers after a 9.2 percent increase in net tech employment from 2010 to 2018. Sure, that‚Äôs slower growth over the course of the decade than some of the cities on our list, but the rate of new job postings in Milwaukee show this city is just getting started.</p></div>
<h3><span>Omaha: An Unlikely Hotspot for New Tech Job Postings</span><a href="https://www.purpose.jobs/midwest-salary-report?utm_source=blog&amp;utm_medium=web&amp;utm_campaign=community" rel="noopener" target="_blank"><img src="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-10-omaha.jpg?width=600&amp;name=img-10-omaha.jpg" alt="img-10-omaha" width="600" srcset="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-10-omaha.jpg?width=300&amp;name=img-10-omaha.jpg 300w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-10-omaha.jpg?width=600&amp;name=img-10-omaha.jpg 600w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-10-omaha.jpg?width=900&amp;name=img-10-omaha.jpg 900w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-10-omaha.jpg?width=1200&amp;name=img-10-omaha.jpg 1200w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-10-omaha.jpg?width=1500&amp;name=img-10-omaha.jpg 1500w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-10-omaha.jpg?width=1800&amp;name=img-10-omaha.jpg 1800w" sizes="(max-width: 600px) 100vw, 600px"></a></h3>
<div><p>Like Milwaukee, Omaha also had a stunning 137 percent increase in new tech job postings from 2017 to 2018. While growth in net tech jobs in the city was only 10.7 percent from 2010 to 2018, all that seems to indicate is that tech workers are <em>just</em> starting to realize what Omaha has to offer. 37,508 tech workers live in the city now, but with such a marked increase in new tech jobs, we can only see that number going up.</p></div>
<h3><span>Des Moines: Second-Highest 10-Year Growth in the Midwest</span><a href="https://www.purpose.jobs/midwest-salary-report?utm_source=blog&amp;utm_medium=web&amp;utm_campaign=community" rel="noopener" target="_blank"><img src="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-11-des-moines.jpg?width=600&amp;name=img-11-des-moines.jpg" alt="img-11-des-moines" width="600" srcset="https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-11-des-moines.jpg?width=300&amp;name=img-11-des-moines.jpg 300w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-11-des-moines.jpg?width=600&amp;name=img-11-des-moines.jpg 600w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-11-des-moines.jpg?width=900&amp;name=img-11-des-moines.jpg 900w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-11-des-moines.jpg?width=1200&amp;name=img-11-des-moines.jpg 1200w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-11-des-moines.jpg?width=1500&amp;name=img-11-des-moines.jpg 1500w, https://www.purpose.jobs/hs-fs/hubfs/Hiring%20Tech/img-11-des-moines.jpg?width=1800&amp;name=img-11-des-moines.jpg 1800w" sizes="(max-width: 600px) 100vw, 600px"></a></h3>
<div><p>While Des Moines is 10th in the top 10 Midwestern cities, it‚Äôs had the second-highest rate of growth in net tech employment from 2010 to 2018: 26.9 percent, behind only Detroit. Des Moines is currently home to 28,693 tech workers, and from 2017 to 2018, saw a 47 percent increase in new tech job postings.&nbsp;</p></div>
<h2><span>Midwestern Companies Are Hiring Tens of Thousands of Tech Workers Right Now</span></h2>
<div><p>In Chicago, Detroit, and Indianapolis alone, there are nearly 31,000 open tech positions at any given time. The Midwest is next for tech workers. Find out more with a free download of the Midwest Salary and Cost of Living Handbook.</p></div>
<p><!--HubSpot Call-to-Action Code --><span id="hs-cta-wrapper-d825b188-3a7f-4d00-ac4a-1ef02e65ec84"><span id="hs-cta-d825b188-3a7f-4d00-ac4a-1ef02e65ec84"><!--[if lte IE 8]><div id="hs-cta-ie-element"></div><![endif]--><a href="https://cta-redirect.hubspot.com/cta/redirect/2873777/d825b188-3a7f-4d00-ac4a-1ef02e65ec84" target="_blank"><img id="hs-cta-img-d825b188-3a7f-4d00-ac4a-1ef02e65ec84" height="709" width="1600" src="https://no-cache.hubspot.com/cta/default/2873777/d825b188-3a7f-4d00-ac4a-1ef02e65ec84.png" alt="New call-to-action"></a></span></span><!-- end HubSpot Call-to-Action Code --></p>

<p><strong><br></strong><strong><img src="https://www.purpose.jobs/hs-fs/hubfs/Christina%20headshot.png?width=120&amp;name=Christina%20headshot.png" alt="Christina headshot" width="120" srcset="https://www.purpose.jobs/hs-fs/hubfs/Christina%20headshot.png?width=60&amp;name=Christina%20headshot.png 60w, https://www.purpose.jobs/hs-fs/hubfs/Christina%20headshot.png?width=120&amp;name=Christina%20headshot.png 120w, https://www.purpose.jobs/hs-fs/hubfs/Christina%20headshot.png?width=180&amp;name=Christina%20headshot.png 180w, https://www.purpose.jobs/hs-fs/hubfs/Christina%20headshot.png?width=240&amp;name=Christina%20headshot.png 240w, https://www.purpose.jobs/hs-fs/hubfs/Christina%20headshot.png?width=300&amp;name=Christina%20headshot.png 300w, https://www.purpose.jobs/hs-fs/hubfs/Christina%20headshot.png?width=360&amp;name=Christina%20headshot.png 360w" sizes="(max-width: 120px) 100vw, 120px"></strong><em><strong>Christina Marfice</strong> is a born and raised Midwesterner who traveled the globe and came right back. She has been a journalist and freelance writer for almost ten years. In addition to her other projects, she explores startup strategies, business operations, and eCommerce topics for&nbsp;<a target="_blank" data-stringify-link="https://www.yesoptimist.com/" delay="150" data-sk="tooltip_parent" href="https://www.yesoptimist.com/" rel="noopener">Optimist</a>. She currently resides in Chicago with her two cats, Dumpling and Doughnut.</em></p></span>
</p>

</div></div>]]>
            </description>
            <link>https://www.purpose.jobs/blog/hiring-tech-jobs-has-increased-in-midwestern-cities</link>
            <guid isPermaLink="false">hacker-news-small-sites-24698449</guid>
            <pubDate>Tue, 06 Oct 2020 15:09:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Deploy to K8s without YAML using ShuttleOps]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 50 (<a href="https://news.ycombinator.com/item?id=24698326">thread link</a>) | @gscho
<br/>
October 6, 2020 | https://go.shuttleops.io/no-code-docker-kubernetes | <a href="https://web.archive.org/web/*/https://go.shuttleops.io/no-code-docker-kubernetes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<div data-widget-type="custom_widget" data-x="0" data-w="12">
<p><span id="hs_cos_wrapper_module_159802898093264_" data-hs-cos-general-type="widget" data-hs-cos-type="rich_text"><h2><span>See How No-Code </span><span id="5f0fb456-fdf5-4e5b-993a-ec7087c62a86" data-renderer-mark="true" data-mark-type="annotation" data-mark-annotation-type="inlineComment" data-id="5f0fb456-fdf5-4e5b-993a-ec7087c62a86">Continuous Delivery<br></span><span>&nbsp;Can Accelerate Your Business</span></h2>
<h5>The same powerful drag-and-drop interface, true multicloud integration and security and compliance you‚Äôve come to expect from ShuttleOps, now with Docker and Kubernetes support. See how easy it is to onboard your application, your team, and scale your delivery. Get started today for free. No credit card required!&nbsp;</h5>

<p><span><!--HubSpot Call-to-Action Code --><span id="hs-cta-wrapper-fcb53eb1-7328-44f8-b128-f953ffc8bab9"><span id="hs-cta-fcb53eb1-7328-44f8-b128-f953ffc8bab9"><!--[if lte IE 8]><div id="hs-cta-ie-element"></div><![endif]--><a href="https://cta-redirect.hubspot.com/cta/redirect/5669359/fcb53eb1-7328-44f8-b128-f953ffc8bab9"><img id="hs-cta-img-fcb53eb1-7328-44f8-b128-f953ffc8bab9" src="https://no-cache.hubspot.com/cta/default/5669359/fcb53eb1-7328-44f8-b128-f953ffc8bab9.png" alt="Get Started"></a></span></span><!-- end HubSpot Call-to-Action Code --></span></p></span></p>

</div><!--end widget-span -->
</div><!--end row-->
</div></div>]]>
            </description>
            <link>https://go.shuttleops.io/no-code-docker-kubernetes</link>
            <guid isPermaLink="false">hacker-news-small-sites-24698326</guid>
            <pubDate>Tue, 06 Oct 2020 14:58:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[4x4 Macro Pad Kit]]>
            </title>
            <description>
<![CDATA[
Score 73 | Comments 37 (<a href="https://news.ycombinator.com/item?id=24697624">thread link</a>) | @0xC45
<br/>
October 6, 2020 | https://0xc45.com/blog/4x4-macro-pad/ | <a href="https://web.archive.org/web/*/https://0xc45.com/blog/4x4-macro-pad/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <header>
        
    </header>
    <p>10/6/2020</p>
    <h2>Contents</h2>
    <ul>
        
        <li>
            <a href="https://0xc45.com/blog/4x4-macro-pad/#overview">Overview</a>
            
        </li>
        
        <li>
            <a href="https://0xc45.com/blog/4x4-macro-pad/#build-process">Build Process</a>
            
        </li>
        
        <li>
            <a href="https://0xc45.com/blog/4x4-macro-pad/#flash-firmware">Flash Firmware</a>
            
        </li>
        
        <li>
            <a href="https://0xc45.com/blog/4x4-macro-pad/#design-keycaps">Design Keycaps</a>
            
        </li>
        
        <li>
            <a href="https://0xc45.com/blog/4x4-macro-pad/#conclusion">Conclusion</a>
            
        </li>
        
        <li>
            <a href="https://0xc45.com/blog/4x4-macro-pad/#links">Links</a>
            
        </li>
        
    </ul>
    <section>
<h2 id="overview">Overview</h2>
<p>Last weekend, I built a 4x4 keyboard kit. By this point, many people are familiar with the growing (and outspoken) mechanical keyboard hobbyist community. However, this kit is a bit unique. It's not a full keyboard. Instead, it's a 4x4 "macro pad" intended for sending keyboard shortcut sequences such as muting my microphone, muting my audio, volume up, volume down, etc. Additionally, with some extra software such as AutoHotKey, vastly complex programs could be triggered with the press of a button.</p>
<h2 id="build-process">Build Process</h2>
<p>Overall, building the macro pad was a simple and straightforward process. The <a href="https://www.1upkeyboards.com/instructions-downloads/sweet-16-instructions/">kit's build guide</a> provides a nice set of instructions with pictures to explain things. However, unlike many (some?) keyboard kits, the Sweet 16 kit requires soldering a few smaller components, such as the diodes and microcontroller headers. Additionally, the kit requires soldering one "surface-mount" component, the reset switch.</p>
<p>The parts:
<img src="https://0xc45.com/blog/4x4-macro-pad/sweet16-parts.jpg" alt="Sweet16 Parts"></p>
<p>Completed build:
<img src="https://0xc45.com/blog/4x4-macro-pad/sweet16-solder-joints.jpg" alt="Sweet16 Solder Joints"></p>
<h2 id="flash-firmware">Flash Firmware</h2>
<p>To program my custom keymap (including multiple keypress macros), I used <a href="https://qmk.fm/">QMK firmware</a>, the most popular keyboard firmware project.</p>
<p>Using QMK, it's possible to create custom keycodes that, when pressed, trigger a sequence of inputs. So, by pressing one button on the macro pad (or keyboard), the firmware will submit an entire sequence of keycode presses.</p>
<p>To do this, I defined my custom keycodes in an enum:</p>
<pre><code><span>enum </span><span>macro_keycodes {
  MICMUTE = SAFE_RANGE,
  MACRO1,
  MACRO2,
  MACRO3,
  MACRO4,
  MACRO5,
  MACRO6,
  MACRO7,
  MACRO8
};
</span></code></pre>
<p>Next, I defined a "keymap" array. Each position in the array corresponds to a single button on the 4x4 macro pad:</p>
<pre><code><span>const </span><span>uint16_t PROGMEM keymaps[][MATRIX_ROWS][MATRIX_COLS] = {
  [</span><span>0</span><span>] = </span><span>LAYOUT_ortho_4x4</span><span>( </span><span>/* Base */</span><span>
    MICMUTE, KC_MUTE, KC_VOLD, KC_VOLU,
    XXXXXXX, XXXXXXX, XXXXXXX, XXXXXXX,
    MACRO1,  MACRO2,  MACRO3,  MACRO4,
    MACRO5,  MACRO6,  MACRO7,  MACRO8
  ),
};
</span></code></pre>
<p>Lastly, I implemented the <code>process_record_user</code> function to define what should happen when each custom keycode is pressed:</p>
<pre><code><span>bool </span><span>process_record_user</span><span>(uint16_t </span><span>keycode</span><span>, keyrecord_t *</span><span>record</span><span>) {
  </span><span>switch </span><span>(keycode) {
  </span><span>case</span><span> MICMUTE:
    </span><span>if </span><span>(record-&gt;event.</span><span>pressed</span><span>) {
      </span><span>SEND_STRING</span><span>(</span><span>SS_LCTL</span><span>(</span><span>SS_LALT</span><span>(</span><span>SS_LSFT</span><span>(</span><span>SS_TAP</span><span>(X_F10)))));
    }
    </span><span>break</span><span>;
  </span><span>case</span><span> MACRO1:
    </span><span>if </span><span>(record-&gt;event.</span><span>pressed</span><span>) {
      </span><span>SEND_STRING</span><span>(</span><span>SS_LCTL</span><span>(</span><span>SS_LALT</span><span>(</span><span>SS_LSFT</span><span>(</span><span>SS_TAP</span><span>(X_F1)))));
    }
    </span><span>break</span><span>;
  </span><span>/*
   * ... etc
   */
  </span><span>}
  </span><span>return </span><span>true
</span><span>}
</span></code></pre>
<p>As you can see, I have configured the <code>MICMUTE</code> button to send the entire sequence <code>CTRL+ALT+SHIFT+F10</code>. However, in practice, any arbitrary sequence could be sent for any button. And, that's only beginning to scratch the surface of the capabilities of the QMK firmware.</p>
<h2 id="design-keycaps">Design Keycaps</h2>
<p>For this "DIY" kit, it felt important to design my own icons. I'm no graphic designer, but it was kinda fun. To do this, I used "re-legendable" keycaps that snap together with a clear top. Then, I printed the icons on plain white paper, cut them out, and sandwiched each icon in the keycaps. Here's a photo of my efforts:</p>
<p><img src="https://0xc45.com/blog/4x4-macro-pad/sweet16-completed.jpg" alt="Sweet16 Completed"></p>
<h2 id="conclusion">Conclusion</h2>
<p>This was a pretty quick project, but I felt like it deserved a writeup nevertheless. As a relative beginner at soldering, this kit was a fantastic way to increase my skills and ability beyond the "absolute beginner" level required for most keyboard kits. Furthermore, the final product is quite useful and extensible. Beyond the specific purpose as a simple macro pad keyboard, this hardware is essentially a microcontroller connected to a set of buttons. There are numerous possible applications. It's ripe for hacking. This device could become a MIDI controller, home automation remote, or anything else my imagination might dream up. Until next time.</p>
<h2 id="links">Links</h2>
<ol>
<li>Sweeet 16 Macro Pad Kit: <a href="https://www.1upkeyboards.com/shop/keyboard-kits/macro-pads/sweet-16-macro-pad-black/">https://www.1upkeyboards.com/shop/keyboard-kits/macro-pads/sweet-16-macro-pad-black/</a></li>
<li>QMK Firmware: <a href="https://qmk.fm/">https://qmk.fm/</a></li>
<li>My Sweet 16 Keymap: <a href="https://github.com/0xC45/qmk-firmware/blob/master/keyboards/1upkeyboards/sweet16/keymaps/0xC45/keymap.c">https://github.com/0xC45/qmk-firmware/blob/master/keyboards/1upkeyboards/sweet16/keymaps/0xC45/keymap.c</a></li>
</ol>

    </section>
</article></div>]]>
            </description>
            <link>https://0xc45.com/blog/4x4-macro-pad/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24697624</guid>
            <pubDate>Tue, 06 Oct 2020 13:49:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cyclone Scheme]]>
            </title>
            <description>
<![CDATA[
Score 87 | Comments 28 (<a href="https://news.ycombinator.com/item?id=24696939">thread link</a>) | @andrenth
<br/>
October 6, 2020 | https://justinethier.github.io/cyclone/ | <a href="https://web.archive.org/web/*/https://justinethier.github.io/cyclone/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main_content_wrap">
      <section id="main_content">
      <p>Cyclone Scheme is a brand-new compiler that allows real-world application development using the R<sup>7</sup>RS Scheme Language standard. We provide modern features and a stable system capable of generating fast native binaries.</p>

<p><a href="https://github.com/justinethier/cyclone/raw/master/docs/research-papers/CheneyMTA.pdf">Cheney on the MTA</a> is used by Cyclone‚Äôs runtime to implement full tail recursion, continuations, and generational garbage collection. In addition, the Cheney on the MTA concept has been extended to allow execution of multiple native threads. An on-the-fly garbage collector is used to manage the second-generation heap and perform major collections without ‚Äústopping the world‚Äù.</p>



<ul>
  <li>Support for the majority of the Scheme language as specified by the latest <a href="https://justinethier.github.io/cyclone/docs/Scheme-Language-Compliance.html">R<sup>7</sup>RS standard</a>.</li>
  <li>New features from R<sup>7</sup>RS including libraries, exceptions, and record types.</li>
  <li>Built-in support for Unicode strings and characters.</li>
  <li>Hygienic macros based on <code>syntax-rules</code></li>
  <li>Low-level explicit renaming macros</li>
  <li>Guaranteed tail call optimizations</li>
  <li>Native multithreading support</li>
  <li>A foreign function interface that allows easy integration with C</li>
  <li>A concurrent, generational garbage collector based on Cheney on the MTA</li>
  <li>Includes an optimizing Scheme-to-C compiler,</li>
  <li>‚Ä¶ as well as an interpreter for debugging</li>
  <li>A <a href="https://github.com/cyclone-scheme/cyclone-winds">Package Manager</a> and a growing list of packages.</li>
  <li>Support for <a href="https://justinethier.github.io/cyclone/docs/API.html#srfi-libraries">many popular SRFI‚Äôs</a></li>
  <li>Online user manual and API documentation</li>
  <li>Support for Linux, Windows, FreeBSD, and Mac platforms.</li>
  <li>Known to run on x86-64, x86, and Arm (Raspberry Pi) architectures.</li>
</ul>



<p>There are several options available for installing Cyclone:</p>

<h2 id="docker">Docker</h2>
<p><img src="https://justinethier.github.io/cyclone/docs/images/docker-thumb.png" alt="Docker" title="Docker"></p>

<p>Cyclone can be run from a <a href="https://hub.docker.com/r/cyclonescm/cyclone">Docker Image</a>:</p>

<div><div><pre><code>docker run -it cyclonescm/cyclone bash
</code></pre></div></div>

<h2 id="homebrew">Homebrew</h2>
<p><img src="https://justinethier.github.io/cyclone/docs/images/homebrew-thumb.png" alt="Homebrew" title="Homebrew"></p>

<p>Mac (and Linux!) users wanting to use Homebrew can do the following.</p>

<p>Note if Homebrew is not already installed: follow the instructions at <a href="https://brew.sh/">https://brew.sh/</a> to install the homebrew package manager.</p>

<div><div><pre><code>brew tap cyclone-scheme/cyclone
brew install cyclone-scheme/cyclone/cyclone-bootstrap
</code></pre></div></div>

<h2 id="arch-linux">Arch Linux</h2>
<p><img src="https://justinethier.github.io/cyclone/docs/images/arch-linux-thumb.png" alt="Arch Linux" title="Arch Linux"></p>

<p>Arch Linux users can install using the <a href="https://aur.archlinux.org/packages/cyclone-scheme/">AUR</a>:</p>

<div><div><pre><code>git clone https://aur.archlinux.org/cyclone-scheme.git
cd cyclone-scheme
makepkg -si
</code></pre></div></div>

<h2 id="build-from-source">Build from Source</h2>
<p><img src="https://justinethier.github.io/cyclone/docs/images/build-thumb.png" alt="Build from Source" title="Build from Source"></p>

<p>To install Cyclone on your machine for the first time on Linux, Windows, FreeBSD, and for Mac users wanting to install without using Homebrew, use <a href="https://github.com/justinethier/cyclone-bootstrap"><strong>cyclone-bootstrap</strong></a> to build a set of binaries. Instructions are provided for Linux, Mac, Windows (via MSYS), and FreeBSD 12.</p>



<p>After installing you can run the <code>cyclone</code> command to compile a single Scheme file:</p>

<div><div><pre><code>$ cyclone examples/fac.scm
$ examples/fac
3628800
</code></pre></div></div>

<p>And the <code>icyc</code> command to start an interactive interpreter. Note you can use <a href="http://linux.die.net/man/1/rlwrap"><code>rlwrap</code></a> to make the interpreter more friendly, EG: <code>rlwrap icyc</code>:</p>

<div><div><pre><code>$ icyc

              :@
            @@@
          @@@@:
        `@@@@@+
       .@@@+@@@      
       @@     @@     Cyclone Scheme-&gt;C compiler
      ,@             http://justinethier.github.io/cyclone/
      '@
      .@
       @@     #@     (c) 2014-2019 Justin Ethier
       `@@@#@@@.     Version 0.11
        #@@@@@
        +@@@+
        @@#
      `@.
   
cyclone&gt; (write 'hello-world)
hello-world
</code></pre></div></div>

<p>Read the documentation below for more information on how to use Cyclone.</p>



<p><img src="https://justinethier.github.io/cyclone/docs/images/cyclone-winds-small.png" alt="Cyclone Winds" title="Cyclone Winds"></p>

<p>The <code>cyclone-winds</code> package manager provides the ability to install packaged libraries and programs for Cyclone. See the <a href="https://github.com/cyclone-scheme/cyclone-winds#cyclone-winds">cyclone-winds</a> site for more information.</p>



<ul>
  <li>
    <p>The <a href="https://justinethier.github.io/cyclone/docs/User-Manual">User Manual</a> covers in detail how to use Cyclone and provides information on the Scheme language features implemented by Cyclone.</p>
  </li>
  <li>
    <p>An <a href="https://justinethier.github.io/cyclone/docs/API">API Reference</a> is available for all libraries provided by Cyclone, including a complete alphabetical listing.</p>
  </li>
  <li>
    <p>If you need a resource to start learning the Scheme language you may want to try a classic textbook such as <a href="https://mitpress.mit.edu/sicp/full-text/book/book.html">Structure and Interpretation of Computer Programs</a>.</p>
  </li>
  <li>
    <p>Finally, this <a href="http://ecraven.github.io/r7rs-benchmarks/benchmark.html">benchmarks</a> page by <a href="https://github.com/ecraven">ecraven</a> compares the performance of Cyclone with other Schemes.</p>
  </li>
</ul>



<p>Cyclone provides several example programs, including:</p>

<ul>
  <li>
    <p><a href="https://github.com/justinethier/cyclone/blob/master/examples/tail-call-optimization.scm">Tail Call Optimization</a> - A simple example of Scheme tail call optimization; this program runs forever, calling into two mutually recursive functions.</p>
  </li>
  <li>
    <p><a href="https://github.com/justinethier/cyclone/blob/master/examples/threading">Threading</a> - Various examples of multi-threaded programs.</p>
  </li>
  <li>
    <p><a href="https://github.com/justinethier/cyclone/blob/master/examples/game-of-life">Game of Life</a> - The <a href="https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life">Conway‚Äôs game of life</a> example program and libraries from R<sup>7</sup>RS.</p>
  </li>
  <li>
    <p><a href="https://github.com/justinethier/cyclone/blob/master/examples/game-of-life-png">Game of Life PNG Image Generator</a> - A modified version of game of life that uses libpng to create an image of each iteration instead of writing it to console. This example also demonstrates basic usage of the C Foreign Function Interface (FFI).</p>
  </li>
  <li>
    <p>Finally, the largest program is the compiler itself. Most of the code is contained in a series of libraries which are used by <a href="https://github.com/justinethier/cyclone/blob/master/cyclone.scm"><code>cyclone.scm</code></a> and <a href="https://github.com/justinethier/cyclone/blob/master/icyc.scm"><code>icyc.scm</code></a> to create executables for Cyclone‚Äôs compiler and interpreter.</p>
  </li>
</ul>



<ul>
  <li>
    <p><a href="https://justinethier.github.io/cyclone/docs/Writing-the-Cyclone-Scheme-Compiler-Revised-2017">Writing the Cyclone Scheme Compiler</a> provides high-level details on how the compiler was written and how it works.</p>
  </li>
  <li>
    <p>There is a <a href="https://justinethier.github.io/cyclone/docs/Development">Development Guide</a> with instructions for common tasks when hacking on the compiler itself.</p>
  </li>
  <li>
    <p>Cyclone‚Äôs <a href="https://justinethier.github.io/cyclone/docs/Garbage-Collector">Garbage Collector</a> is documented at a high-level. This document includes details on extending Cheney on the MTA to support multiple stacks and fusing that approach with a tri-color marking collector.</p>
  </li>
  <li>
    <p>The garbage collector was subsequently enhanced to support <a href="https://justinethier.github.io/cyclone/docs/Garbage-Collection-Using-Lazy-Sweeping">Lazy Sweeping</a> which improves performance for a wide range of applications.</p>
  </li>
</ul>



<p>Copyright (C) 2014 <a href="http://github.com/justinethier">Justin Ethier</a>.</p>

<p>Cyclone is available under the <a href="http://www.opensource.org/licenses/mit-license.php">MIT license</a>.</p>

            <h2>Recent News</h2>
      
        <h4>
          <a href="https://justinethier.github.io/cyclone//2020/09/17/Released-Cyclone-Scheme-0.21.html">Released Cyclone Scheme 0.21</a>
        </h4>
        <span>September 17, 2020</span>
        <br>
        Various bug fixes and continuous integration support for FreeBSD.
      
        <h4>
          <a href="https://justinethier.github.io/cyclone//2020/08/14/Released-Cyclone-Scheme-0.20.html">Released Cyclone Scheme 0.20</a>
        </h4>
        <span>August 14, 2020</span>
        <br>
        We now have official support for calling Scheme from C.
      
        <h4>
          <a href="https://justinethier.github.io/cyclone//2020/08/03/Released-Cyclone-Scheme-0.19.html">Released Cyclone Scheme 0.19</a>
        </h4>
        <span>August  3, 2020</span>
        <br>
        This release improves error reporting and includes many bug fixes.
      


      </section>
    </div></div>]]>
            </description>
            <link>https://justinethier.github.io/cyclone/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24696939</guid>
            <pubDate>Tue, 06 Oct 2020 12:23:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I am building permapeople.org]]>
            </title>
            <description>
<![CDATA[
Score 131 | Comments 141 (<a href="https://news.ycombinator.com/item?id=24696688">thread link</a>) | @roboben
<br/>
October 6, 2020 | https://permapeople.org/blog/2020/10/05/why-i-am-building-permapeople-org.html | <a href="https://web.archive.org/web/*/https://permapeople.org/blog/2020/10/05/why-i-am-building-permapeople-org.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><img src="https://permapeople.org/blog/assets/why-permapeople.jpg" alt="Two potatoes in an Ikea bag"></p>

<p>Four years ago my grandfather gave me two potatoes. I had no idea what to do, so I put them in bought soil in a big blue Ikea bag on the balcony and with a bit watering, they turned out great and I got hooked on growing food for my family and me. It is really magical if you think of how much you spare our planet with growing your own food: You need to get a job to make money so that you can spend that money on buying food which was produced and delivered close to you by large, complex and very inefficient industries. This system spends incredible amounts of resources (time, energy, labor) which you can save by simply growing your own food. And it doesn‚Äôt stop with food only: People grow plants for medicinal uses, to help the nature and wildlife around them, or just for their own pleasure.</p>

<h2 id="the-problem">The Problem</h2>

<p>This season I really tried to scale up and created raised beds all over our small urban plot in Berlin, Germany. I wanted to do it sustainable and close to nature, so I read Toby Hemenway‚Äôs Gaia‚Äôs Garden, which is probably the most widely read book on permaculture. While it is a good base to start and there are a lot of resources around online, it is actually pretty hard to make all that info useful for my own garden. Most of the time I found myself random googling just to answer simple questions like</p>

<ul>
  <li>What plants in the herb layer are available in my zone?</li>
  <li>What are the best companion plants for Tomatoes?</li>
  <li>What is the best time to sow peas in the garden in my zone?</li>
</ul>

<p>I fell back to having a spreadsheet, a collection of browser bookmarks, and a few books to look up what plants I can grow and how they could fit together in my garden. This took me a lot of time, I‚Äôd rather spend in the garden.
After the garden was planned, the next challenge was where to find seeds, seedlings and plants to start the garden. Mostly I googled the plant name I wanted to buy and ordered in whatever shop came up but it would be so much easier to buy it directly from other fellow gardeners.
The season started and another thing I did was writing a diary of all my garden activities. The idea was to learn from past mistakes to grow better next year. It worked well for me but true learning comes from sharing experiences with others, which was not possible with that.
While this worked for this year, I wanted to have something better next year so I started building a platform around all these topics.</p>

<h2 id="a-platform-for-everyone">A Platform for Everyone</h2>

<p>Most of the resources about growing plants you find online are either anecdotal or very scientific. There is no place where a gardening enthusiast can share their experiences, see what other enthusiasts learned already, and collaborate on everything related to growing plants. I think to achieve that, we need:</p>

<p>A <strong>permaculture plant database</strong> which everyone can search easily by common permaculture plant attributes like Layer, preferred light and soil conditions, times when to plant and harvest and benefits for animals, human and the environment. In addition everyone can look up advanced topics like companion planting and guild design. To make this info useful, it needs to be verified by others through ratings, comments and linked sources. If someone could see that most people were successful with growing that specific variety of a plant in your area or that a certain guild really works for a lot of others, that would be a huge help for everyone.</p>

<p>A <strong>permaculture marketplace</strong> where people can share/trade/buy/sell seeds, plants and everything else they might need like equipment, books, courses. Others can use it to sell products from their permaculture gardens to make an income for themselves. Everything happens directly between fellow gardeners.</p>

<p>A <strong>permaculture garden log and planner</strong> where everyone can log their past garden activities, learn from each other and plan their next season or project. If this info is combined with all other gardeners, then it becomes citizen science and we can improve everyone‚Äôs gardening results. Imagine you could be notified when all the more advanced gardeners start their tomato seedlings in your area, so you could do that too.</p>

<h2 id="make-the-planet-a-better-place-for-real">Make the planet a better place (for real)</h2>

<p>There are many people who want to grow plants for many reasons but don‚Äôt know how. There are also many people already growing a few plants in their garden and learned it the hard way. I believe we need a platform where they can come together and share their experiences and learn from one another to help improve the life of eveveryone. If we would all start growing a bit of our own food, we could help the planet and ourselves in so many impactful ways.</p>

<p>There is a lot to write about the implications of having such a platform, which I will do in future posts.</p>

<p>In the meantime, you can check out the plant database <a href="https://permapeople.org/database">here</a> and if you are interested, either <a href="https://permapeople.org/users/sign_up">sign up</a>, write me an email to hello at permapeople org or sign up for the newsletter where I am posting regular updates.</p>

<p>Thanks for reading üå±‚úåÔ∏è,</p>

<p>ben</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://permapeople.org/blog/2020/10/05/why-i-am-building-permapeople-org.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24696688</guid>
            <pubDate>Tue, 06 Oct 2020 11:42:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Chat bot powered by GPT-3]]>
            </title>
            <description>
<![CDATA[
Score 70 | Comments 79 (<a href="https://news.ycombinator.com/item?id=24695710">thread link</a>) | @piotrgrudzien
<br/>
October 6, 2020 | https://blog.quickchat.ai/post/knowledge-base-chat-bot/ | <a href="https://web.archive.org/web/*/https://blog.quickchat.ai/post/knowledge-base-chat-bot/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><figure><img src="https://blog.quickchat.ai/images/blog-post-1-bg.png" alt="Knowledge-base chat bot for SaaS product sales"></figure><section><div><p><em>Brief summary of our GPT-3 chat bot for SaaS product sales.</em></p><p>The most natural way for us to communicate is, well, <em>natural language</em>. Chat bots are nothing new but unless they meet a high-enough quality bar, they tend to be a step backwards rather than forward. We believe huge language models such as <a href="https://openai.com/blog/openai-api/">OpenAI‚Äôs GPT-3</a> will form a foundation for a truly conversational human-computer interface. It is, however, a foundation rather than a solution in and of itself.</p><p>In this new paradigm, the big challenge becomes to ensure the chat bot strictly sticks to the topic it was designed for and provides accurate information - without depriving it of its creativity.</p><p>I will discuss this briefly in the context of what we refer to as <strong>knowledge-base chat bots</strong>. They are built to answer general questions and hold a conversation about a product, service or a topic delineated by a predetermined unstructured knowledge base.</p><p><img src="https://blog.quickchat.ai/images/zeroth_faster.gif" alt="Start a conversation - image" title="Start a conversation"></p><p>Our chat bot implementation approved by the OpenAI team (try it out live at <a href="https://itemsy.com/">itemsy.com</a>) is an expert on Itemsy - a software product for managing the content you read online. It relies on GPT-3 for its conversational capabilities.</p><p>Thanks to our <a href="https://quickchat.ai/">Quickchat</a> engine (on top of GPT-3), it makes full and accurate use of the Itemsy knowledge base it was provided with, focuses on the topic at hand and cannot be maneuvered away from it:</p><p><img src="https://blog.quickchat.ai/images/first_faster.gif" alt="Avoid off-topic conversations - image" title="Avoid off-topic conversations"></p><p>Ultimately, it‚Äôs all about <em>conversation</em>. It requires context, needs to be unscripted, adaptive and creative. You‚Äôre still talking to a machine but this time language feels more like natural language. üôÉ</p><p><img src="https://blog.quickchat.ai/images/second_faster.gif" alt="Creative conversation guided by the user - image" title="Creative conversation guided by the user"></p><p>We‚Äôre ready to work with you and launch conversational chat bots for a wide range of use cases. Reach out to us at <a href="https://quickchat.ai/">quickchat.ai</a>!</p><blockquote>‚Äî Dominik Posmyk (@dominikposmyk) <a href="https://twitter.com/dominikposmyk/status/1309497928810213376?ref_src=twsrc%5Etfw">September 25, 2020</a></blockquote></div></section></article><div><h2>Follow the Quickchat blog for product updates, user stories and technical posts about artificial intelligence.</h2><p>
<span>Please correct your email address</span></p></div></div>]]>
            </description>
            <link>https://blog.quickchat.ai/post/knowledge-base-chat-bot/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24695710</guid>
            <pubDate>Tue, 06 Oct 2020 08:22:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fooling Around with Foveated Rendering]]>
            </title>
            <description>
<![CDATA[
Score 172 | Comments 84 (<a href="https://news.ycombinator.com/item?id=24695275">thread link</a>) | @underanalyzer
<br/>
October 5, 2020 | https://www.peterstefek.me/focused-render.html | <a href="https://web.archive.org/web/*/https://www.peterstefek.me/focused-render.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
 <div>
  
  <p><label>Posted on <strong>28 September 2020</strong></label></p>
<p>Shadertoy is a wonderful tool which lets users create and share a type of program called a fragment shader online. The true magic of shadertoy is its community of very talented graphics programmers who build incredible works of art despite having access to only a sliver of the traditional graphics pipeline.  </p>
<p>Some of these shaders are very computationally intensive and even in a small window, they crawl along well below their intended 60 frames per second on my old laptop. Inspired by a technique in the VR community called Foveated Rendering, I decided to try to optimize these shaders by only rendering a fully detailed image within a small focal region. As you move away from the focal point the image quality decreases.   </p>
<p>This rendering scheme is motivated by biology. It turns out your eye notices more detail in the center of your vision than in the periphery. Some VR graphics programmers realized they could take advantage of this phenomenon to increase the effective resolution of images by increasing image quality towards the center of your vision. An in depth discussion of foveated rendering can be found in the ‚Äúprevious work section‚Äù of this <a href="https://ai.facebook.com/blog/deepfovea-using-deep-learning-for-foveated-reconstruction-in-ar-vr">paper</a>.  </p>
<p>I did not have the time, equipment or the background necessary to implement a full foveated rendering system but it was fun to fool around with the concept.  </p>
<p>Before diving into the technical details let‚Äôs look at a simple shadertoy fragment shader.   </p>
<p><code>
void mainImage(out vec4 fragColor, in vec2 fragCoord)<br>
{
</code></p><p><code>
    // Normalized pixel coordinates (from 0 to 1)<br>
    vec2 uv = fragCoord/iResolution.xy;
<div><pre><span></span><span>//</span> <span>Output</span> <span>the</span> <span>pixel</span> <span>coordinates</span> <span>as</span> <span>a</span> <span>color</span> <span>to</span> <span>screen</span>
<span>//</span> <span>fragColor</span> <span>is</span> <span>a</span> <span>4</span> <span>vector</span> <span>of</span> <span>the</span> <span>form</span>
<span>//</span> <span>(</span><span>red</span><span>,</span> <span>green</span><span>,</span> <span>blue</span><span>,</span> <span>transparency</span><span>)</span>
<span>fragColor</span> <span>=</span> <span>vec4</span><span>(</span><span>uv</span><span>,</span> <span>0</span><span>.</span><span>0</span><span>,</span> <span>1</span><span>.</span><span>0</span><span>);</span>
</pre></div>


</code></p><p><code>
}<br>
</code></p>
<p>This program runs once for each pixel on the screen. Each time it runs, we receive the input variable <code>fragCoord</code>. <code>fragCoord</code> is a 2d vector which contains the x and y coordinates of the pixel being drawn. We normalize those coordinates by dividing by <code>iResolution</code>, another 2d vector, which contains the width and height of the image. Finally we output a color to the screen, whose red and green channels are proportional to the x and y position of the pixel being drawn. The output of this shader looks like this:<br>
</p><p>
  <img src="https://www.peterstefek.me/images/focused-render/simple-shader-out.png" width="50%"> 
</p>
<p>Side note, why do these shader programs require their own language? Shaders are special because they run on the graphics card instead of the cpu. They are highly parallel. A helpful mental model might be imagining that each pixel is colored simultaneously. Therefore a lot of things that we take for granted in normal program languages such as liberally accessing memory and branching become much more difficult.  </p>
<p>In shadertoy shaders the bottleneck is always in the pixel rendering step. So to speed them up we want to only render a subset of the all the pixels on the screen. It seems like selectively rendering pixels should be as simple as adding a branch to the per pixel shader code that looks like:  </p>
<p><code>
void mainImage(out vec4 fragColor, in vec2 fragCoord) <br>
{<br>
</code></p><p><code>
    if (fragCoord is in the subset of pixels to render) {
      <p>
      ... do computationally intensive work 
      </p> 
    } else {
      <p>
      // return a black pixel<br>
      return vec4(0, 0, 0, 1); 
      </p> 
    } 
</code></p><p><code> 
}
</code></p>
<p>Unfortunately we cannot just use an if statement inside of the shader to save us from rendering all the pixels. Unlike normal programming languages, fragment shaders always execute both parts of each branch due to gpu limitations. So while our above code will still have to spend the sample amount of time evaluating compuationally intensive work.  </p>
<p>Luckily, it turns out that graphics drivers can selectively mark which pixels not to shade by writing their location to a special buffer called the stencil buffer. We can use this stencil buffer to only shade the subset of pixels we are interested in.</p>
<p>Once I could efficiently render a subset of the pixels, I needed to come up with a pre-generated sampling pattern. Most foveated rendering techniques seem to use a grid, but I decided to try a non uniform approach. Searching for some kind of optimal sampling pattern seemed like an interesting problem and if I was going to devote more time to this I'd explore options like <a href="https://blog.demofox.org/2018/01/30/what-the-heck-is-blue-noise/">blue noise</a>. However in the interest of time, I just decided fill in a small circle in the center and then use samples drawn from one low variance and one high variance gaussians centered at the middle of the screen to place the rest of the pixels. The final sampling pattern ended up looking like this:
</p><p>
  <img src="https://www.peterstefek.me/images/focused-render/final-sample-pattern.png" width="50%"> 
</p>
<p>Next, I needed a way to fill in all the missing pixels in the final image. The approach I took was pretty simple. I started by mapping each pixel in the final screen to its nearest neighbor. Since my sampling pattern was predetermined, I could create this map beforehand and pass it into the shader as a texture. Here's what this mapping looks like:<br>
</p><p>
  <img src="https://www.peterstefek.me/images/focused-render/nearest-mapping.png" width="50%"> 
</p>
<p>And here‚Äôs a gif of the mapping applied to a <a href="https://www.shadertoy.com/view/3lsSzf">shadertoy</a> created by the extremely talented <a href="https://www.iquilezles.org/">Inigo Quilez</a>:<br>
</p><p>
  <img src="https://www.peterstefek.me/images/focused-render/1-neighbor.gif"> 
</p>
<p>The above screen is 420x236 pixels and only 1/10th of those pixels are actually rendered. The focal point is directly in the center of the screen. Here's what the full resolution version looks like:</p>
<p>
  <img src="https://www.peterstefek.me/images/focused-render/original.gif"> 
</p>

<p>And here's what it looks like with only our sampling pixels:
</p><p>
  <img src="https://www.peterstefek.me/images/focused-render/sample-pixels.gif"> 
</p>
<p>One little improvement I tried was to make 4 different maps. The kth map mapped each pixel in the final image to its kth nearest sampled neighbor. I weighted each of neighbors by the inverse of their distance to the pixel in question. I actually even tried using some gradient descent based optimization to fine tune the weights but ended up seeing little improvement. It also seemed that increasing the number of maps beyond 4 did not improve things much either. Here's what the example from above looks like with weighted interpolation between the four closest neighbors of each pixel (we are still rendering only 1/10th of the total pixels):
</p><p>
  <img src="https://www.peterstefek.me/images/focused-render/4-neighbors.gif"> 
</p>
<p>Finally, here's the shader with 1/5th of the total pixels rendered (as opposed to 1/10th shown above):
</p><p>
  <img src="https://www.peterstefek.me/images/focused-render/1of5pixels.gif"> 
</p>
<p>Okay that's all cool but does this technique actually increase performance? I did not do a rigerous benchmark, but <a href="https://www.shadertoy.com/view/3l23Rh">this shader</a> goes from around 20-25 fps on my plugged in laptop to 60 fps when reduced to 1/5th of the total pixels. <a href="https://www.shadertoy.com/view/Ms2SD1">Another shader</a> went from around 15 fps to 60 fps.  </p>
<p>One last side note is that this method can be used with any 3d scene and is not exclusive to shader toys. I just chose to use them because they are always bottlenecked by the pixel rendering step and they are really pretty!</p>
<p>Further questions:</p>
<ul>
<li>How do we achive better temporal stability? (the <a href="https://ai.facebook.com/blog/deepfovea-using-deep-learning-for-foveated-reconstruction-in-ar-vr">paper</a> I mentioned earlier talks about this)</li>
<li>Can we dynamically change the sampling pattern to give us better results? For example what if we sampled along edges or areas where large amounts of motion is occuring? Of course to do this we would need to compute our nearest neighbor mappings on the fly (there are actually <a href="https://www.shadertoy.com/view/XtlGDS">some</a> <a href="https://www.shadertoy.com/view/ldl3W8">shadertoys</a> which already demonstrate capability).</li>
<li>How could this scheme improve if we had access to the internals of the 3d scene? For example, could we adjust our sampling pattern based on depth information?  </li>
<li>How does this actually look in VR?  </li>
</ul>
<p>Have questions / comments / corrections?<br>
Get in touch: <a href="mailto:pstefek.dev@gmail.com">pstefek.dev@gmail.com</a>   </p>
<p>Discussion on <a href="https://news.ycombinator.com/item?id=24695275">Hacker News</a></p>
 </div>
</div></div>]]>
            </description>
            <link>https://www.peterstefek.me/focused-render.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24695275</guid>
            <pubDate>Tue, 06 Oct 2020 06:44:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Probability and Statistics with Applications to Computing [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 66 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24693589">thread link</a>) | @ArtWomb
<br/>
October 5, 2020 | https://www.alextsun.com/files/Prob_Stat_for_CS_Book.pdf | <a href="https://web.archive.org/web/*/https://www.alextsun.com/files/Prob_Stat_for_CS_Book.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><i d]g(*h¬™¬Æjc≈°¬ª‚Ä¢√ü√ï]¬ø¬ø}[x√Ø^√Ær)≈†f3@="√ØJ¬ß‚Äúccc‚Äì/_^RRbs‚Äî¬¨m√à" ;√Ñ√ß√èe√°√ö?¬ß‚Äπ‚Ç¨√ë="" p8]x¬±<√Ö<¬≠}√ü√¥‚Ä°√ô‚Ä¶‚Äπ!kim2≈†‚Äπ‚Äπm1c√Ü¬°‚Äì‚Ä∫√è¬∑yyyb¬°'ÔøΩÔøΩa√Ä‚Ä°kd¬°8√ª√ª¬£‚Ä°="" √∂√ò¬Ω+√™√¶ÔøΩd√¥f√î√†:q√†eu√äju;~√ó¬®)?l7¬•="" √Ç="" √ñ¬Æ[bc¬£vciq√≤√ä!√°2√ú√ë√Ér√∏="" √å|√±√ù√™`‚Ä∞-¬ªÔøΩ8&7≈æ¬¢√É√Ω="" √Ω¬≠¬º‚Äû_√∂√á≈í)≈†√á3‚Ñ¢.d¬¢√ßl¬•&n≈ìx√ª√∂√≠'o≈æÀúo)¬≠√äÔøΩ‚Äú?y√â≈†vw-j√æb7rÔøΩ√Ö¬ªs="" ‚Ä†ÔøΩ√ßh<b¬¶i√¨¬≤√ì‚Äûa-√•p√ãm√â¬¨y-g="" "√¶¬≥g√è6n√úh¬°ÔøΩ\]¬∞x√é√Ω√∫zÔøΩ]g√≥‚Ä¢‚Ä†="" m√ä`4√ù√Æ‚Ä°qp;i√¨1‚Ñ¢√¨√¥≈∏√ø|√•√§√§√ë¬´w¬Ø#f,y¬≤√§√¢√Ö‚Äπ.mq√ï¬¥ÀÜÔøΩ¬£`‚Äπ√Ω√É≈Ω√∞¬¢√ü7a√Ø√ã√ô)√ës√î≈íh≈Ω,√öx√ï√ñ√≤(j¬Æa¬¨j√ãk¬≤y≈ìu√´√ñ√ôb√é¬°c-7≈∏o√≥√≥√≥√∑√¨√ô3y√≤√§&m≈°√∏√∏x‚Äú√âd"√ëÔøΩnw‚Äπq√©≈í√°√É¬º¬≤‚Äìn√õ~√∞@√å√ô√ì√ä‚Äπ√ß√ï¬π√ï9√î'ÔøΩ+√∂√Æ≈Ω=""><b n¬∏1¬†¬±√ú¬Æ3√î%√ïe!ÔøΩj¬°¬´≈í√Å¬±ÔøΩ√Ücv‚Ä∞ynglbpaÔøΩk¬Ø‚Äû¬´c√≤,¬¥√•ÔøΩ¬£(≈†√ú√ä"√ç^¬Øi√Æ2¬¢^?√•‚Äò√óue‚Ä∞ÔøΩm‚Äû√â√ù^√ès√è?¬ø}√áv√∏‚Äì.Àú_`6z√û√ë#√ê¬∂√Åo¬∞√Æ≈Ω;√Æp¬©d^¬Ø√¥¬´e√Ö\√ã¬∂√£√õ√ç≈∏|√Ω¬±u√±&√ó‚Ñ¢√ãb9%‚Ä¶n)√ò√§z¬µ(¬∂¬º'¬ß¬†o√Ω√ö√¢√≠w¬¨≈æk="" √ºau¬∏‚Ä∞;√Øpv‚Äù‚ÄúÔøΩ@&√´.‚Äòt‚Ä∞¬∫="" ‚Ä¶¬∞√±√Å√Ø¬¨x¬±√¢\√•¬§e√≠≈í="" n√ºÔøΩ?√æxe‚Äô√ù%bu√î¬•≈Ω¬∞j+r‚Ä¶¬§b_‚Ä∫√Ä√úu√ò.w√™‚Ä∞ÀÜs√¶√êimzua@j√ë√à≈ì¬°≈Ω√™.c!Àú√úÔøΩ√õ√õ‚Ä°∆í√∫=""><s ‚Äòh¬™√∑*^√≠√ï¬™j≈æi[j¬Ø≈∏!¬±¬º≈°gy√§1<`√Ä√ï="" √ú8(¬≤gp!z$_√µ√¥≈í√ªk√Å‚ÄùuqÔøΩ√†√¢t‚Ä°√ëh6:p<‚Ä∞√£√ó√Æ≈íÔøΩ√Ä√û$bx√Ä%¬µ¬®Àú‚Äò}h="" !="" l‚Äò"‚Äû‚Ä°b!q√ÇhÀÜ@b"ÔøΩp¬ºze‚Äö‚Äò≈í‚Ä¶ic"ÔøΩ(¬µ="‚Ñ¢41" ¬°¬§!¬Ω≈†l√Ä√à√å¬´fip7√±¬º√™√æ¬ø√ª√â‚Ä°¬Ωs√¨≈æ≈æÔøΩ¬†k√°uÔøΩ¬§√ë¬ºj9√î3√Æ‚Ä∞‚Äì√Ø√º√ø¬•="" w√º¬§√∞√∫+n≈∏f√≠√ïc√é.√∑≈ì√∑√°√í‚Ä¢‚Äìs‚Äöhh¬Ør‚Äö√éui‚Äôx5‚Äì4¬©¬º√ä¬´ÔøΩ&{¬Ø="" b√ö√ò‚Ñ¢e√∂¬´ÔøΩ‚Äì¬Æ√≤¬Æ6<u¬∫q¬µ√Ωv="" √Ø‚Ä∞o√àco≈ìuo√≠¬∑√®s="" ‚Ä∞√ßu&√ªÔøΩoÔøΩ√¥√™Àúw≈°]tc4gÀúwii¬¥‚Äôgz‚Ä¢'√±√™¬±ÔøΩm√Ø="" ‚Äπ≈∏:fb¬™√∞*="" ;k¬Ø√≤¬¨¬Ω√äÀÜ?√û@≈°¬æv√ß√π√≥*d^s≈Ωi‚Äòf√™√†u¬∏‚Ñ¢√é¬´√™√î√ï¬´∆ísxv¬Æx5ÔøΩ<√≤√àc¬∏√à√í"√è‚Äπ√º√à‚Äù¬™\√°√•p√Ω0√¶y0√£e~¬§|&¬Æ]∆í≈ì.¬™√ì√ª¬§ÔøΩ√®‚Ä∫a%‚Ä†h√∞‚Ä∞="" ≈°d!¬®_<‚Äùf∆í√ª‚Ñ¢="" √Åe‚Ñ¢a`l%¬§:i√Çq√¶h‚Äô√Üh\r√±‚Ä∞≈íb¬¨≈Ω&‚Äû√á‚Äú√Ühhli√Å¬´√é‚Ñ¢3√¢k√ª¬æ5<¬Ωj}¬∫¬©√´ÔøΩ¬ª√§kn√π}q√•√ªi="" ¬Ø√é¬µ≈æu√è|√ü¬∑_√°="" i∆í¬©¬°¬º'ÔøΩÔøΩ^√•="" √¶u‚Ä†q¬§¬©√û¬´b√ùg√Ø‚Ä∫√ñ8√±√Ödk√§g√é√™‚Ç¨ÔøΩ^¬Ωur√•%ÔøΩ'[-8t8!="" f‚Ç¨,¬Ø¬æ√øi√•qÔøΩ√áo√≠¬≤i¬Ø¬™√º√©hr√§√ïp¬Ø*≈ìdzu√çc%√∑t√∫ÔøΩ√ü√µk^¬≠"ÔøΩh0j√™ub≈°*¬´√†¬æk≈∏¬¨¬∞√¥√ÆÔøΩ√Ö‚Äù‚Äû√Ñ√≥¬™≈†$s¬Ø‚Äô‚Äûh7d√©¬øÔøΩ‚Äôx^{d√Æu¬±¬∫aj^="" ¬Ω≈†o2√â#ÔøΩ<√≤√Å8∆í√â√õ_pj="" n="" ‚Äπ¬•,j¬™√•¬†="C√´√•" √Ö="" ‚Ä∞¬®√ódq#√≤¬πz‚Ä°p="√ï¬´¬ºD‚Äö√∫3#¬°√äk!‚ÄôHWa¬≤√ß√í√ê‚Äû&nbsp;≈í√∫{6!" ¬¨y√å.mÀÜ2¬¶√©aÔøΩ?¬™√±*¬´√±¬ºj}¬∂¬•√≠w¬∫g√ô¬≠¬ø¬∫p¬æ¬¨‚Ç¨√≤*=""><i ‚Äπb#√Ö√Ñ(c≈í##e∆í*m√º‚Äúr≈†‚Ä∞‚Äπtx∆í∆í√†@1¬∏√ú‚Ä¢b√©√Æ√â√•√ì√†√∫√†¬∏‚Äπi¬ßr≈í¬§√†pm√Ü]≈†‚Ñ¢√öx="" ‚Ä°√Æ-&ÔøΩ¬©="" b‚Äû19[khy‚Äù3∆í¬ß√á\‚Äπ6‚Äû"'?≈í‚Äút√†¬¥1%‚Ä¢‚Äì√ºejq9‚Ä∫kÔøΩr¬¨∆í#="" √Öx="" ≈Ω¬Ø¬¥98√ó*="" ¬•x="√ó√Çfb&quot;#E√ü¬•" √≥j¬∏√ü√Ç@‚Ç¨√ù20g√å5≈†√Ä√Ç‚Äπ‚Ä∞¬¥√ák&‚Ä†[¬∂√¢¬ß9p="" m8le="v]√ê¬≠‚Ç¨$=ÀÜ√∂+¬§" =""><i √än<y¬æ"+x√ío%bwÔøΩo¬†v!√¶√á="" <a√´√Ç√ìj‚Ä°ÔøΩ¬¥‚Ä¶'¬†`xz(h≈æ,="" b√îa{√±¬¨g‚Ä°¬°‚Ä∞¬£:="" ov‚Ä∞√åco¬∫¬¥√óof‚Ä°!(‚Ä∫√ùxz‚Ç¨¬µ¬µ√èjkk√Ω√Ω√Ω¬±.√¨g¬£i√ìff¬£√°√ß≈∏op¬®√öpz¬∏p¬°√âh"≈∏ÔøΩ`√É√Å√ë¬±¬†¬∞√†√æ∆í√ª¬ØxÔøΩ¬≤√°="" ¬Æ√ècÔøΩjk≈∏<~¬ºl√Æ¬§√î0u=""><i ¬º,<-;l]?hÔøΩ="x√ô‚Ä∞'¬•`√ùÔøΩ¬¶√Ω‚Ä∫√∫∆ív√ì7¬±T≈æ?;¬∫Mb7wE62" g‚Äù√îj<b‚Äî.kwg¬∫+√ö√∫¬©√úcx√öx√ß√∏0e√ß="" c@1√™Àú4‚Ä¢√©o√ä√∞3v√≤√ï¬∑√±s√Ö¬¥‚Äù√∑‚Äò="" rd&ÀÜzhÔøΩpf9ÔøΩe√Ä5√ä‚Äú≈°&√¨)¬¢‚Ç¨k@yp[qh¬§="" √ú‚Ä¶‚Äπ√¨√ç√áf4¬∞ikahh#&¬∂*√Ñ_√Ä$cp√•!√ï¬Æh√ò√Ç}ÀÜ√ñ="" z¬æ√ús√Ø¬†spd;¬®√Çl=""><i √Ç'@√à√¢¬∞ji√∞$*ÀÜ_¬≥z√°p√Ω√õa‚Äö√Ø√Ä‚Äúj0]√Å‚Äú¬†="" cuwa‚Äû¬¢¬†¬≤="" √•r4uj√ü¬ß¬™√Ñsj√∑m√∞¬§(√òu<5j‚Ç¨¬Ω√Å√¥4√ÄÔøΩe√º√Ωf√≤$="¬¨-√±√∑7" ≈æ√è¬Æ√ç√ú√°j√µ¬ª‚Ä¢.√Ü2√ú√åx√£u√¨|y¬£¬¶√™¬π√∂√£xz√≥<√ª¬°√õ4√à;5√ä√∑≈æfw√ä‚Ç¨gj√Ä,c√¢d#‚Ä°5<‚Ä°e\¬∑√æ&.√ñ√º‚Ñ¢¬¶z3="" y3e¬Ø√±¬ß√â&&l√°joj√õ;¬±m√Ω¬π√É‚Ä†h∆í√†|¬≤=""><i √¢√Øa5√Å‚Äú¬¢="" √è√ô√ô√ª¬°i:aaa¬π¬π¬π√øf<u≈í¬¢√ú`¬∫ÀÜ¬ß‚Äùfya‚Ä¢xj¬¶="" ‚Äö√ê(xwww√©√í¬•√•√ã‚Äîc3¬ª√ª√ª√∏√°#¬≠‚Äö]√Ä‚Äú¬®`√ó√±d√àxr%√¢≈°√Öil0√•o‚Äî√∞‚Äù√í√°iuÔøΩp‚Ä¶$<¬øe√º2x=""><s k‚Ñ¢-s√≤≈°√¶s\√øh%=""><i ∆í∆í‚Ä¶="" ¬®="" ÀÜf√Ñ∆í√´≈°√°√øn√´1≈°$‚Ä¢√°,‚Äî√Å√ù≈í‚Ä°√Ä'≈∏nt√ú√ã√†="" √É¬¥3<√¢√πÀÜ¬≤√óÔøΩÔøΩ¬∂√ÇÀÜ¬∫√ó#‚Ç¨e0‚Äô‚ÄôÔøΩcp0‚Ä¢√±="" Àú¬¨¬ª√ç`="√Ü`+≈í√Äv3FÔøΩ¬´√Å0E|√∑2¬∏√ç`√å√∞√Æ√î√πHQ√≤98‚Ç¨‚Ä¶~√òv`¬¶√≠√Ç√Än¬≥¬≠√¨√õ¬ºk4U√ºk¬§w√°¬≥≈í‚Ä¶ÔøΩ¬∑√Ä√∞¬Æ¬π"><i><s ≈í¬¶√ú7√ã√àsÔøΩ\¬†‚Äìx≈†¬µ(`="" √ûÔøΩ√ø√®z√∞√∫~√¨√øtz~t√ô√ãcÔøΩ¬¢¬†¬∫≈ìj%ÔøΩ√π¬æ√Ö‚Ä¶≈í‚Äπ*ÔøΩ√àr√≤‚Äù@ÀÜ|)p√π√Ä√ú√ç√ñ4√≠√à‚Äò#.≈ì<y2¬ø√å√à√à0="" √Éw¬ø√è√Ω¬≠a¬¢="" √ò="" ¬™="" 0="" [ÔøΩo@vr‚Äò√ïj√Å¬£ÔøΩ‚Äì¬´‚Äô√õ√º≈æ¬¥√±¬≥="" √áÔøΩ(¬∏ÔøΩ="" c√Ü√•e{¬µ√Ädfb√ør="" sÀÜ¬•√°√Ö="" ‚Äö="" ‚Äî="" .0√Ñr≈†¬∞}¬≤;‚Äì¬¨¬∂‚Ä¶a$`√ò¬∞j="" √ú√ëy{‚Ñ¢¬™[z¬∑="" -yq√ìpÀÜ√ó√ã‚Ä†rcl*ov≈Ω¬£¬¥;v¬Æhb¬®r¬π√ç√è√â√ây¬ªv√≠√î¬©sg√ç≈°¬µc√á√ì4ub¬†√ä√∑√Çb]2‚Ä∞j`¬¢¬°ro,xp√•‚Ä¢w~√∂√ôg¬π¬π¬πg‚Ä¢√∑√≤¬ß:d√º#√ö¬¶m‚Ä∫¬∂m√õn√ö¬¥√©<{√ª√ï<√ò√≥√∏√øyyy√º√∑¬™=""><b><b ÔøΩb√â√∂vÔøΩj¬ß√Ö¬∫d√ÄÔøΩ8√ág√Ö.k\‚Ä†¬®‚Ä°≈í="" =""><i ¬¨≈Ωq√î¬•w¬¥√©:‚Ä°√µÔøΩ∆í√≥√≤_f√ß:¬ßu√í¬∂≈°¬™7¬Ω¬æ√¢fr√∏¬π√óe√∏≈†¬´√®5√±!_¬¢‚Äòq<d√±√°e√Ö=""><s ‚Äû√ª¬∑tb!a√à√ß√π*`lze;‚Äπ√ó5√ër∆í√∞¬¨¬∫√ê√åz√í√†¬∏gxl¬º√Ädiy√ª-y¬≠;o="" √é‚Ä†i√Ç+j‚Äì¬∂√¢o\^√•√äu√Ç‚Äúo*1`h≈æs√õ‚Ç¨="" ‚Äì¬©e√ävie;¬ø¬§√∑‚Äù√°¬£¬©√ñh‚Ñ¢c|√â√ô¬®b¬£p‚Ä¶edÔøΩ-√≠¬®r9¬π√ú=""><i ‚Äô√Æ√£q≈°∆í√¨}="" ¬Ø5√Ä7-}¬£√∞gzf√®√µ4n¬º¬¶kxÀú‚Ñ¢~≈ìcri¬≥¬Ø√àÔøΩg@√Ö¬¥)√Æ1‚Ä∞√æ_¬ºalsb√∑ÀÜk=""><b ¬≠√ä√´%jtÔøΩ="" √ï√ß¬¨,p1√Å√Ø¬æ√ªn]l="" hj‚Äö‚Äö‚Äö¬†√õy√õ¬∂m¬†_¬Æ√¨¬Ω√±√Ç¬∏="" ="" ¬ØÔøΩ√∂whÔøΩ√Ü√´¬†≈ì√†√∑g√Çnj2}¬≤?√°¬ß](‚Äûp√Üa`‚Ä†c¬™√≤√∞‚Ä∫√±√æ@≈Ωd="" t‚Äì√∏,uty√ä="" √à√∫√¨izzj)√∞‚Äú‚Äô¬ßiy‚Ñ¢yb‚Äì√òluy‚Äì≈†="" ≈∏=""><b><i o*d¬¥,w√ég¬∑¬Æ√Ä+≈ì¬∂*‚Äö‚Äπf\y‚Äû="" ¬´'y√®√è√ø¬•¬®¬ø¬©≈ì√ø‚Ä∫¬¥√é√øro√´‚Ä∫¬Æ¬∑5¬æw√´eq√è√Ωy‚Äù#√å‚Äî√π√Ç‚Äπn√ß√Ö¬¶p√∂√£y√∫ÔøΩ√õ,√í√ú¬≠√ù√ºn¬≥y√ñ√û¬≤≈Ω√ú="" 7√és√§="" ¬£√≠b√Æ&2x¬´√é‚Ä∞zq√∂√ö¬¢q≈í+¬°:√¨‚Ä¶]‚Äû!√î‚Äú√ú{√à≈Ω8^√á=""><s><b √Å7Àú√≥¬∏√£√ë√á√Üa$211y¬ºhqbb‚Ä†√©p√ò1*≈ìÀÜ‚Äúg0^3g√é:t√Ñ¬æ√Ω√ª¬¢¬¢¬¢√äÔøΩ^ÔøΩ¬≥¬©i‚Äú¬¶√§√™ccgggÀú√ù√π‚Äô√º√Ñ√Ñ‚Äû¬∑xq="" ‚Äû√Ö‚Ä∞*)‚Äô≈°¬∑}√ª≈Ωv√ü?z√î√®;w$‚Äô|x‚Äìhp√êk(√ø="" 9√π0≈í√ó√∂m√õ√´7hÔøΩy="" √è#√Ä"r¬©‚Äù√£√¢z¬∑jmhÀÜ="" √Üh√ô¬≤√•¬πs√ßÔøΩ¬•¬¨√¢√ç|¬¶√≤‚Ä°√å,yÔøΩ√¨≈Ω‚Ä°g¬≥√¶√ç!u‚Ä¢¬™u‚Äî√Ω¬µ√¨√ù¬ªw"4√©√∏@√Ä-√ª[-√ø√∑?rim¬ø√æ√Ω√∞√Å="" ¬∫t√ê1b∆í_¬ß√Ü√º√©u√Ä"‚Äî‚Äù‚Ä¢‚Äú~√õ?j√ç√•‚Ç¨√Å‚Ä∫√ú√∫¬Æ√É√ó√ü≈Ω√ª√õ√≥ÀÜk√∞√´√®√¥\‚Ä∞¬¨@¬Æ¬¨¬∞√Ωv√Ä√ú√îcx√è`j="" ¬ª√Ç@¬¥5f¬®b‚Ç¨≈æa="√ï‚Ç¨√æ&nbsp;¬æ" ¬ßh3Àú√ß‚Ä∫‚Ç¨≈†¬Ωlh√ì="" √Äo`√¢‚Ç¨s!¬Ωcq√≥Àúx√ç`√õÀú="√ØÔøΩ¬≤√åP'ÀÜ" ¬°√ïng√¨kvp¬±≈∏‚Äò√∑≈∏_√î√≤‚Äπ√è¬†√å¬≤√Ö√ñ3≈Ω=""><s><u><i s√ùs[≈Ω="" ¬¥‚Äö="" mpn¬¨i¬©√∏8¬¶¬∏_¬™s√∑w4¬¥:¬Æ∆íva√¶="" √í.v‚Ä∫b√≥:!¬Æ‚Ä†?j∆íz√ò√Öyr√¨√Ñ√°√®¬ß√£k√£≈æu√ã√µf√ã¬∏¬†yz√Ø√¢n√ã="" ¬´="" n√©√¨√ä√ÅÔøΩ¬¢‚Äπ¬ø¬ø√ô="" q="" gwh√ö√¨¬£√•z‚Ä¢√†‚Äπ‚Äû¬≤‚Äú¬π¬≠√ù√£^yÀÜ="" t¬≠≈Ω¬ªxhu="" ≈†5¬¶c¬∑‚Ä∫=""><u><i h√¶√®√ô√ü&≈†√™="" ¬¶m¬§‚Äô)‚ÄôÔøΩ#cm‚Ä∫5kÀú√¨√ëkld¬∫¬∞)u+¬°bt‚Ä¢ÔøΩ="" ~yt¬®√ñ="√ê‚Ä∞zUi√®%ÔøΩ¬¥¬∫T‚Ä∞‚Äö≈æ‚Ä¶" ∆ín√¥ht‚Äû)w¬´√åh√Ö√ê¬ªwc¬∑√ë%√Ñ√•ÔøΩ√Ä="" √ï@="" √®√ûb√®√æ√ù√õj√®√ºq4tx‚Ä∞ÔøΩÀÜ√Ø:%.¬®¬¨{√ãb)√Ülyj‚Äò√£¬†w√ë:¬•]u¬∫{i9#n√®√ù¬´b√è.√®‚Äô√çiwa'√™u¬•¬°‚Äî4√í√®r¬•√û≈ìx¬†v√Ø$‚Ä†^on√º¬ª¬∑‚Äπ6'g¬Æ‚Ç¨√µdjrwd≈Ωl‚Ç¨$ÀÜ¬∞c√Ñh√ã¬§¬µ√°*√º≈í¬ßd‚Äòj‚Äúc¬∂j√àx¬•ÔøΩ√∞√í‚Äú|‚Ç¨‚Äù1‚Äö$√å*f4="" |x√°'√¥#rb≈Ω¬∂p#√•¬°‚Äπde√ù+‚Ä†_="" tp‚Äù‚Ä¶n√Ö%≈íh¬µ*kkÀÜ2w¬Ω√òÀÜ:ÀÜ√ê√ê√•√ß"#¬≠‚Äûn`¬≠√§uqs‚Äì√¢u@√∑2√¢‚Äû^√éÀÜz≈æ√∂ty¬ß√∏=""><a √§‚Äπ≈∏¬≠9ÔøΩ1√Ø.‚Äú}(‚Äîx‚Äôd≈Ω|w√é-≈í√ä√É‚Äú4√ød¬¶¬º[b="" ‚Ä†¬©√πo0‚Ä¶≈ìly¬Æh¬ß.√£.√è√∫‚ÄπÔøΩ!√ñ¬©‚Ç¨w\√Ä√Ø√ùv√≤zv√ïc¬∏‚Ä°,j√ß√æ¬ª?√ú√¥%]¬£u√ò√û√≤'v~t√ò¬µÀúm¬¨√∫√çf¬º√Ö="" √ö¬°¬®y8j≈Ω¬ß¬∏.=""><u √Ω‚Ä¶ÔøΩ√Æ√ò¬ø?v9√•$;bii"i√ö√ü√üÔøΩ√¨d¬π√Çe$&&≈†¬§*¬°√ó(‚Ä¢j;;;√¨b√ä√®√ël√ö¬¥i$iy?t√ó¬Æ]√òy√≤√Ü√ô√ô√ô√ë√ëq$u="" √Ω¬•¬≠¬≠md¬¶ad$v="" √•mxx8$√û√ú√ú,‚Ä†¬™√±√±√±√∞√¶'n≈ì√Ä√é‚Äô7√ë√ë√ël6¬∫¬™√∫knn.≈í#g≈Ω`‚Äîp√û¬∞¬©√ú"uÔøΩ¬†}√®√§√§‚ÄûÔøΩ"√¨quÔøΩÀÜ1√∏√∏√∏Àú‚Ñ¢‚Ñ¢uuua‚Äîp√ûtvv≈°≈°≈°≈†√ëujiia_ÔøΩ√™√ª|ÔøΩ]√æ‚Äî¬∂¬≤¬≤¬¢¬Æ1≈°≈æ≈æ¬®!!!≈ì‚Äπ"√òzjj≈†¬∑¬∑√∑√ö¬µk¬ø√∫√™+√∏a√ü¬æ}√º¬∑e√≥√≥√≥∆í√¥√Åp‚Äûu‚Ä¢¬≠¬•\ww√á9="" √Ø‚Äπ="" ¬æx√ó]w-[¬∂≈í√ø√ïccc√Ö√´ÔøΩ√∫√´;p√û√ë#!!√°‚Ñ¢g≈æ¬πk√∞kp≈æ‚Äò√§√§√§@√∫vu="" √Ñn|w¬¨y¬≥‚Ä†i≈†√¢3lf√•√æ√Ω√ª‚Ä¶u‚Ä¢√ê_¬†√ìe¬¢¬£¬£∆í[!t*‚Ä¢cy√¥√ëg_√Ω√µ√ó^{√≠¬ß?√Ω¬©√¶‚Äî<√ó¬£`√∑√Ä√°≈†j:44‚Äû√òi:{√∂√¨¬™u¬´4b¬¢√∏="" ÔøΩ="" √Ä-¬†¬™‚Äû√æ2<<√å6√¢v√º√†‚Ä∫n√Æ√ú¬πp√æ|√∞√Å√ë‚Äπh√Åw0‚Äû√Å^‚ÄöÔøΩ="√ä-$¬∂‚Ä¢H!‚Äù¬™√ê√ªcS5¬π¬•&nbsp;!**j√Å‚Äö¬£‚Ä∫ÀÜX">√àO‚Äô√ër√ö(ÔøΩ√å√ºIY√¶√¶t√≤√Üt√ö¬≤:¬ª¬∑ÔøΩ0√àÔøΩ√æ√™√É-‚Ä¢¬£|√í+e¬©‚Ä∫¬º9V9-‚Äö√ésm5‚Äî'¬´√Ø¬≠S√ØoV¬ø?√á8√ó^6√ê√≠√õ+56√©/√ì√Ø¬¨06‚Ä°‚Ñ¢√ß‚Ä¢√µhk√Ü‚Äô‚Äöu¬æ¬≥√¶√ÜR√ï√ù¬µ√ä√ßÀÜ¬´∆í‚Äù¬§T√Ç√£‚Äö¬™1&gt;√¥ Us‚Ä∞√™f√Ç\g√æ√ÜT√≤√Ö√±¬§¬π¬Æ4
√üQ∆í^√¶H¬©9brvg]√¢L‚Ä°√øL‚Ä°√è¬®√Ñ‚Ä°[≈æ√îX≈ì‚Äû‚Äöjm~,=;‚ÄìU√û√ï`¬≠√¢Xv7Àú√ì¬≤}√ã∆í√±√±√à√Ωa¬¨¬Ø6¬©
√ØC\^≈°¬ØÔøΩ3k≈ìM}L¬ΩO≈∏
&gt;1rb&amp;√∏√Ñl√†‚Ä∞√ô`#¬•¬®√µ¬∑`√ïW¬ª&nbsp;¬¨¬™√´¬∫¬µ¬ºBÔøΩQc¬•]¬¨
4Y√è¬™¬ªk‚Ç¨!¬´j√ê¬º√™¬Ω¬ªw^√í¬Ø√ö√û√ï!√¶Àú¬∂√ù¬Ø√∫E‚Äô√©'‚Ä∞&amp;√Ω√°¬ø√å¬™0v≈†√∂.√Ä¬º√Ä¬™√ö¬º*5C√è√Ü0bkr≈°√ä¬±¬Ω√çQ#‚ÄôhvQF+1¬Ω¬π4¬´¬ø%uY‚Äúry.mu8K√Ω¬∫‚Äπv√ï‚Äù.U&nbsp;y√ïks¬¥9%e≈ìO√ë≈°u≈∏k√ü√é¬®¬Æ¬©!¬®p/
6∆íÀÜ√®o≈∏≈Ω√æ√Ø¬Ø¬°√ö√ü≈æN|√ø√Å√∏√ø√ær√æ~^√Ω¬ø[√π√©√£‚Ñ¢G3√≤Gs√≤‚Ä°¬≥¬≤{√ì√ê√≠√ñ¬®√∞√Ü¬®√†∆íU√π≈∏√Å{√ægÔøΩ:≈æ^‚Ä¢~rS√≤√π√âg‚ÄûÔøΩ¬Ø4_‚Ä°≈ΩL√º√™ÔøΩ√ëjp√∞lA¬´¬•11AU_√ñ√ó√Ω¬∫¬ªÀú‚Ä¶√†√Ä≈†√â‚Ä¶√õ¬¨:3¬•≈í‚Ä¢√íp√¨‚Äô√î&amp;pZK ¬´√¶√ÜCV√Å¬º*`UrZ(!)≈í‚Ç¨∆í¬¨¬∫√≠√ó√£‚Äú‚Ä¶\√µ#¬©U¬¥k5¬∞¬™√Ø√≥Q√à√Å.f‚Ç¨U¬ØD√É‚Äò7boD√û≈Ω2Àú/Oz¬≥yU"¬≤~¬±√∏√µk√µu‚Ç¨¬µ¬±‚Äú√Æ=¬ø≈æU√µ√´√üc√≠¬©√ærW^√µ√∂√≠√õ333√ª√∂¬´ba¬ø√™S¬§_√µ√ÉD^ÔøΩ‚Ä∞‚ÄìUu¬£√¨_h¬∏xÔøΩU∆íVE√≤¬™‚ÄûU√ì√¢¬πPo9	¬º√ä¬∏!Ads,¬ß$ÔøΩ_‚Äò√ûR‚Äì¬•¬¶\z√Ø≈°√≥¬ø_|_cdUÀúW¬•]≈°¬¨‚Ä†¬¨*&nbsp;"¬•¬ø≈íE¬≠√û√∂4h√µ√∂√≤`√≥¬Ω‚Ä¶¬∂?√ª√èo¬¶√ø√æ√ó¬π¬ø&gt;√ø√æ√±√∏√ü¬øYz√ª√ü?,√øh√º√ë√¨≈Ω√û"&amp;7G7√á]j√ø√°√ìÔøΩo&gt;√¨√π√¢A√ª‚Äú√ã√¢Oo¬Ωv_√∞p‚Äú¬ª¬ÆfM	h3√¢j√∞¬Ø?¬º√¥‚Äì¬º6V¬°√°‚Ä¢√∑6‚Äù√µ6√†¬ªYEp≈ì¬£@L*√úf√ïQ‚ÄùU‚Äú√ô%)Me‚Ä∞¬®√û√ís√¢¬´‚Äπ]4¬´‚ÄôRÔøΩ√û‚Ä†¬¢z‚Äπ√û√°¬Ω√ç‚Ä∞√≤√í√û
&amp;¬øp7√µ6√ú√ç&lt;√ê√ô,√ü√É√§¬¢¬∑√óco¬ΩÔøΩ4Àú¬®.|¬≥¬¨¬∫_√É‚Ä¶¬Æ√£√∫¬´.t√µV√óq]¬∑√ûeU+++√Ä¬™g√é≈ì√ë¬≥¬™~√ΩA√ñ/¬≤√™¬•√ΩYu¬º,y=√§√î‚Ä¶√∞S¬´√°¬∞Ar&gt;√¥T¬¥¬ΩÔøΩÔøΩ:G√¨9¬Æ‚Äöx√∏yC\&nbsp;SJ¬∞Kn¬¥sY‚ÄôSv‚Äûgv‚ÄûoI¬ºg
√é√è‚Äô1√åk√≤&lt;√ã‚Äú"H¬©a¬§√î¬®¬¢G‚Äπ=¬≥ ¬¶&amp;/≈ΩU√óP≈ím(Nj&amp;$√∂√≥‚Äö√ß{√ºz4√Ç()5CL√éi¬£√¶√≤√í√é¬´cWG¬±√ß√ïI=√µ¬®V√É)CM‚Äû¬°&amp;√¢0ÔøΩ¬∏√êÔøΩ_≈∏(i¬¶N&nbsp;h_√î¬Æ/‚Ä¢√ú8ÔøΩ√ü≈ì ≈æ‚Ä¢B‚Ç¨ÔøΩ√ï¬Æ‚Äúo≈ì/¬ø¬πR√∂√æ√π√≤√µ√í¬∂√•ÔøΩ≈í&gt;#¬¶√è√â¬©‚Äî¬¶K¬Æ/√•_≈°)X√¨.m¬°≈í¬∂‚ÄôFx‚Ä¢≈°f¬¢≈°‚Ä°≈Ω√µ7.‚Äúd≈∏W√á-k¬¢g:√£√§√ï‚Ä¶rZ√∏√ô$‚Äù,!)KP‚Ñ¢√ûQ3¬©√∞‚Äî¬π√µr¬Ω√™‚Äπpu‚Ä¶√êC&nbsp;6‚Äì√∑P3√Å√ìQ2-ÔøΩ√±√üf‚Äù,||Pq\√Ä&nbsp;¬™√ì‚ÄîÔøΩ‚Äö√™√≥dÔøΩ¬´yÀú¬≥iÔøΩ‚Äú‚Ä∞ÔøΩ¬Ω1√ã√´√îD√†√±¬©√Ä√£√£`√ª4T≈†[eoÀúU√∑√ó¬∏√ó¬≠√•‚Äö√ºR¬∑ √à√®pUWWW√õ√ò√ò√®Yu7¬´&gt;√ª√≤√ô¬£‚Ä°ÀÜ¬∑d√ï‚Ñ¢√ô√ô{w√Æ,-.¬æ‚ÄùU√õw|‚Ç¨¬°&gt;√ÄX√£≈æ¬£Y√ï√∫√•y√ïhmMZ@YR`c¬©√ß√¨Wu√®√°@V¬•V√ç√á√î√Ä√ò)vH:*ÔøΩh¬£'u5&amp;¬∂√ó%k‚Äû¬∏√≥C¬∏√çiAeL¬¥√•*i¬´√ñ‚Äì≈æ√´+¬ª¬µZ√±p¬´√™√™Y√äYe√ï√ª≈æ{¬∞Tk¬ª¬©¬ºÔøΩ=√ê≈°√ük√Ω√¶√É√æ&gt;S√ø√¥l√¥√©Z√á¬£√πWw√ø√£‚Ä∫√â≈∏≈æM√º√∏√π√∏√á¬∫LA¬¥√ªSm0v√ù<zi√ª√∂i√ó¬≥g√ä √â≈∏="l√ª√¢¬æ√∏√£√õ√º‚Ä°[√úK√µ√≥2√Ü≈í‚Äû">√ëJ¬ª¬®¬¶√ú]¬Ø¬∫¬∑A√ú≈ì$≈í‚Äπ√ã{¬´¬≤¬µ¬¨≈°/¬©*kKE√∫U¬£&amp;√§	√á√Ü¬ß5‚Ä¢¬°¬¨√è√àMÔøΩ√ó√∏#√Ω¬™¬≤7√à¬™¬∏√ß¬¨√∫BY√ä¬™√Å√é/e√ïg√ìÔøΩ¬®3¬®P√é¬´gfJ√Å	‚Ä¢¬ΩQV√ù5X
¬≠√ò√õ¬¨¬∫¬∑yj√Ø¬§¬ø√ΩKi√è¬©√∂≈æ√ü√é√éN√è¬™√∫√µ¬ª^¬ªY√µ√ã/&gt;G√ªU√ª√∫√Ä√ô\X\¬º}√≥√¶√ô¬≥g_Z√ú√ü√å√º4≈°¬Ω√Ω$√Å√§A≈ìQs‚Ç¨√±√Æ¬º¬™¬Æ√û‚Ä†¬πi√µV‚Ä∫W-√á√≤*√ù√ï¬≠¬∞_U√â¬¨
¬®-‚Ä†UM&lt;√Ñ√ï1√É√¢P¬µ J√ÜH√™lH√™¬®O√£VGq‚Ä∫3)F24‚Äö√º≈ìM√¢≈∏Uu√π¬Ωu√¢√ÉKU[‚Äú‚ÄùiiÀÜ|√ê6UTo¬´¬¢z¬ª}78√ê|gN√¥√≠√ì√æ&gt;√ó√º√¥√ï√ò¬£%√π‚Äπ≈†√Øk~√æj√≤√ßg‚Äú√Ωp√¥√©r√ß∆í¬©6√Ñp√ë√õQ√°√ç1√°‚Ä°‚Ä∫√≤o&gt;|¬Æ¬∑≈∏√ü}|‚Äπ¬Ωi]S√Ç¬ßi}ZR¬Ω1
'¬°√Ö√ìh√π6¬´6√Æ√å√≤c@¬ΩÔøΩ√©√Ä¬≠¬®c/G!cw‚Äô9√∏T√é6¬´√Ü√ìs¬ª¬Ω4"'¬µ√êAP√•	Y√∑"¬´b^dUDo√∑¬≤j¬Æ¬ª√âf√î‚Ñ¢‚Ä∫√ë‚Äî¬¢√é\‚Ä∞<s-√º√å(¬µp√æ¬∞√™?[o¬∂¬∑y√µ√µf¬®√©:√ê[‚ÄùumllÔøΩ¬´‚Äö√´yu¬ø√æ√´_fu¬π¬¨m¬§4y9√®√§r(√úk√°¬ß¬ß‚Äöod√ò≈æ√∂¬¥>√£og&nbsp;‚Äπ¬´√ö√¥
√êÔøΩ‚Ä°¬§@'B¬≤¬∑√ú23√Ç5-√Ñ¬ª0√éM≈†¬∞¬™ÀÜjA√â√¥(‚Ä∞‚Ä°√æ¬∑√â"¬™ÔøΩ‚ÄöiSÔøΩSÔøΩ‚Ä¶a√§√Ü‚Ç¨√ÄÀú‚Ñ¢√üP¬Ø¬®
≈æV¬∫O¬∑{‚Äπ√ΩEU√â¬≠√ÑAeV;+e¬∫#ri0t¬±?¬≤‚ÄîÔøΩ√ô√ΩR≈†¬∫Y¬∞√∏PU_6√Ä)ÔøΩV√§≈ì√à√®k ¬©!]V.√µlNgl√çd¬Æ≈Ω¬°#√É√∏‚Äù‚Ñ¢6√¢√ÜD√Æ√ñl√ñ¬•¬≥YG√≤gd√Ñ1u\Àú‚Äù2!"^√â√úÀúJ¬æ0‚Äô:-/`W6‚Ä¢√Æg√ÉKB√∞¬Ø√≠√≠¬®)√©√ßf√étD.√∂M)Cd¬¥LQU≈Ω√±f√ß‚Ä¢g√∞‚Ä∞¬∏√∂¬∫√†Q)P]')√ç¬ß6/¬©6^‚Äì¬¢√û√¨√§¬¥HzN&nbsp;≈ìa√öUo√ñYgF√é√∞.≈†√≥/√Ä√∏√¶√áx√Ø‚Ç¨√™vF¬ß√ì¬¶¬∫SUh@5√Ñ√â¬±g7bx≈ì√∂?:√¢l√à√Ø¬®√Ü√ß¬®√Ü√ü@√±√¶XU√∑√≤p¬Ø{√Ä√ûqÔøΩ{√†W¬ª¬µh‚Ä∫UuY√ç√ó≈ì<yr√è¬™;y√ïgh^uzxx,v¬Ω{√ß√é√¢ky¬µ¬£¬´c√Ñ¬ø‚Äúd√øÔøΩ‚Ñ¢√∑√∑0√û√®^≈ìqg¬∞‚Äò‚Äî√É¬∂¬∑√öt√û√ôasy‚Ç¨#x¬Øg¬Ω>√ê¬¶rtrQ\`ib`√ûs√∫√õu¬≥ÔøΩ¬®‚Ñ¢√∞T√ñ√§a9√±r√¥‚Äû&lt;`E¬∞:¬º&gt;¬∂1¬π&gt;sa{q,im<e¬∫=¬´ÔøΩq√î n?√óÔøΩ√ø\√©√ù5√Ç√•√ô√ä¬≥j√≤(ÔøΩ2-ÔøΩ√Ωs="" ¬™y‚Ç¨‚Äìj¬¨√≥;√ç¬™√´¬Ω≈ìÔøΩ¬æ¬¶¬´#√ç_√úw|√Ωa√á√óÔøΩ;√Ø√çi√û|¬∏¬Æ√∏√∂c√ïw√∑~√∑t√µ√©‚Ä¢√∂‚Ä∫√É√Ç‚Ä∫ÀÜ√ª√ôÔøΩ1√ö¬∏zwi√∞√Öc√©g√∑do¬Æ√∞="" ÔøΩ¬≤7√î√µ√ª√´‚Äì‚Äù¬µg%≈í¬≥r:√ï√Ü[¬´‚Äîh¬∑v="" ¬∑="" ‚Äì¬Æo√†√áde¬™¬∫r;u√Ø√åa‚Äìt≈íiq‚Äπ1√ß‚Ä°"f%1b2‚Äôw-√ù√â¬´√¶$√à¬æ="" ‚Ç¨t√¨√õ¬Æ√§√î]v-|}vu1]ÔøΩ8u1@[‚Äπ8¬Ωvj≈∏√∞√õ¬±√™~¬±‚Äú‚Äìuu√ç¬∫_√ù<¬•k√¥¬±‚Äîua√¨¬§gu√Ω√∫¬Ω¬Ø‚Äî√§u!¬´^√Æc¬º‚Ä¢o¬Ω‚Äùu‚Äò√π¬™√Ω\√¶‚Äúh¬£√ªqfw√¢≈í="">@√¶¬´r√º≈í|_n√¢‚Äò√º√¢t¬∞√ò¬Ø√öBt√§A`E¬≠)5¬∞*bÔøΩ‚Ä∫√ê√ÜÀÜÀú√©zxa4d}"√ë[√å‚Ä¶√ë√∏¬µ√±¬§‚Äπc)¬£‚Äô≈ì≈Ω≈°¬¢.VIO=~¬©√ªB√©¬Ω√µ≈†√ç√â√ä))y¬º√®-4@√µ¬µT√í√ï√õ3√º/(¬æ√π¬∞√≥√´√á]¬∑&amp;D√Ø?¬π√ö√æ√≠S¬®¬∑√ü&lt;√Æ√πhSqC#‚Äû√ÄÀÜ√û^√ì¬¥^√¶?\¬Ω√Ω√¥≈Ω√®√ë&amp;oc¬∞qS]¬°‚Äî¬µ √ü√ñ[&nbsp;√≠Sb√™
4≈ì¬º}a¬Ø√¶‚Ä¢∆íx√ç¬´v√Ä‚ÄìU¬®¬∑√ì√≠	√ß¬£‚Äî‚Ä°√Ç√π¬±¬≠‚Ä¢√â≈ìX¬ºÔøΩW√çN√®¬¨√∑TC`¬ªV‚Äô√á/¬≥√™N^5√∂EV√çq7¬æÀÜ√®√≠√Ö√à√ì√´√°¬ß7BO
S~#V√ïÔøΩ¬∂¬∑Yuo¬Ω‚Ñ¢n√ãK√µV¬∑√ûL√è¬™√∫√µ‚Ä°]√ª¬∞√™‚ÄöB"√æEVU‚Äî√†√¶√ΩÔøΩ√è≈∏{9√¨√îh√Ä√±P√´√Æ‚Äì¬ß|lN\
¬¥7v4√û5#√é√á√´√´X≈Ω¬≥√•-3√É√Ω¬Ω
cÔøΩetK√õ¬¢‚Ä¶hMH√∂(√Ñ@!¬∏*cÀú√±ÀÜ6¬§√î¬®¬™¬¥√à√™,‚Ç¨r√ë√¥≈ì√ò√ö√º8&gt;)dD√¨8,v√íÀÜ√ú‚Äû√§√ò√¶¬≤‚Äù√¶¬≤t!9¬•¬ø9b¬Æ√á√∑lÔøΩ√øPk≈í‚Äù≈°'¬´√éS√í√≥@√∞¬©d√Äj‚Äú1q√≤√ô√é√∏¬ÆBo}¬©¬™¬æ|F‚Ñ¢¬æ2≈í]√Å√éu¬•
p∆íMC\ √ê√π√∞√π‚Äû√ïQ√¨¬≤:qZ≈æ&gt;3√Ñ-√´k$¬™‚Ä∫K√ª√¢‚Äî5Q‚Äπ}ÀúQf7¬≥≈Ωv‚Ä¶u,EÔøΩ¬µ¬∞t¬∫'U*k2‚Ä†Z#f:=√áe√û√≤,ÔøΩÔøΩ√Ö¬´Hm!$¬≥K√íxDLg¬Ω√ªP¬´ÔøΩ≈†c√üXF√è≈Ω¬ße∆í‚Ç¨<w¬•‚Ä°s√Ç¬©√ô≈†≈°mv%¬•y√§√á√ÄÔøΩ¬™¬∫¬Ωo {ÔøΩ‚Äù√æ‚Ä†"¬†‚Äû≈Ω¬Ω¬∂1¬†¬∫√Ø√∑92√®s¬¥√ó√ªh≈∏√ß‚Äò="">√ü√ì
√ëf√ï‚Äî≈Ωk√ú√è=√†5`¬≠ ¬£¬¨¬™√ïd=¬´√Ç√µK¬¨zg_V√≠V≈†√∏√Ø'√ò√ù≈†6¬∏‚Ä∫√äo√Ü*
√ë
√†‚Äîg¬ªJ√ü√õ:√û√±√´FZ¬®P{%√î¬Ø‚ÄûO‚Ä¶¬±√æ√∏‚Äû‚Ç¨¬∫b√∑√æf√´ÔøΩ√õ√éz{√î‚ÄûO√¥≈ì81-|T√™¬£√≤C5√¢√∞I√îXf¬æ¬≥¬¢‚Ä∞¬Ω8?√õ‚Ä¢√öQ‚Äúp¬µÔøΩ^2)+¬º:Wps¬•hk¬∫tFQ¬°√°‚Äô'‚ÄûU;¬£`√ó√™¬º¬ºv‚Äù#	√ñ√ï√Æ√ÜÔøΩA√∂G7x≈∏√û|zWxs‚Ä†¬∑√ï√ó|s≈°√ø√ë5√ëÔøΩ$≈∏√ùz[‚Äö¬•+C¬º+C-‚Äî‚Ä°Z¬∂√∫‚Ä∫7¬∏√Ø√èr?¬∫√Ö}z∆ís√Ø4@[ÔøΩ1√ße¬µsmH√†$¬•M≈†¬©c&lt;√ä|g√Ö¬µ¬•‚Äô√∑√è\√ç‚Äìt¬≥J{√™¬∑‚Äú¬™
z≈æ‚Äû≈ì7*‚Ä∞≈∏√Ø‚ÄπX√¨V"√πD√Ä¬™ÀÜY7√¨≈∏≈†√áVJ√∑√†√ô√∞l¬§√ï√é¬§√î¬§_A√ñ√≠W√ù√ù?¬•√õ¬Ø√™j√¨Yu1√¥$ÀÜ≈°‚Ç¨l.‚Ä°≈æ\
99V√≤√¶Yu¬ø¬©√¥¬ø¬æYU;¬°¬¨¬™[‚Äú¬¶gU√Ω√∫¬Ω¬ØÔøΩU¬´¬™¬∏√å{7c&nbsp;√û√û‚Äπ5¬ºm√ê√†k√®√£`¬¢√õ√ã√å¬ΩM~√â|&nbsp;¬∑¬•‚Ä∞√æ\‚Äö√ê√õ√æf[√É¬•2%‚Äì‚Äì√Ö√à√Ö√ês¬∞√àÔøΩ¬∑¬ØZ4√ò:,≈Ω‚ÄòDÔøΩ¬µ√Ö.
`V‚Ä†√£.≈Ω%≈í¬∑e√Äh√û√ï√è*n≈ìz[¬º1Q:!!¬∑ÔøΩ'‚Ä¶U:¬¶√´√õz{I¬∞¬Ω¬Ω2√Ü√π√®&amp;√ø¬≥√ªPo¬ØÔøΩ¬∂l√∂6√ü‚Ñ¢o√Ω√∏¬¶√∏‚Äπ‚Ä°Po≈∏^]QC¬±E√µv√®√≠ √∑√∂√ê√õ¬¶'√ó√ô¬∑√è√ï√èKÀú¬≤√öyY
√ê[h√•!¬≠≈æR'Z¬´‚ÄìT‚Äû+√Ö√Ø≈∏√ã_√ï√§5√£¬ª√´√∞¬®¬∑‚Ñ¢√§4¬®¬∑SJ√åB√∏b_poSL√ë√õ‚Äôm¬Ω¬•e√á¬∑√ó¬π
√≤√≠Zl√∏‚Ä¢√Æ‚Ä¢)!H¬ø¬™v√®√ºs+`8¬πfGo¬µ7√πH¬ø¬™yÔøΩ¬≥Y¬∂¬ª√±R√î√õ√≥;z¬´¬¶¬ºyV}Eo‚Äùn√∞√´4¬´√Æ¬Ω√É√ó:ooo¬ØgU√Ω√∫¬£¬≠ÔøΩU√•¬´'M√ª‚Ä∫&lt;6p√ºl√∞‚Ä∞A¬ø¬£A√áÔøΩ√çOxZ≈æ√¥¬±&gt;√•g{&amp;√Ä¬≠√û≈æ‚Äö
B5  1≈æ¬∂√∏√ë"%√à&gt;√å√ô¬ª$√ÅZYk¬°b‚Ä∫¬≥≈†√¨
0≈æ¬πQ@‚Äö√º√ã‚Äô√º;√´,√π√é¬•	a√â¬°√§¬¥¬∞¬™√¥JF5√É*≈í√®m¬≤√ÆoÔøΩ)≈æVrxCqRc1≈Ω∆í√á‚Ä∞¬®Àú‚Ä∞√´¬∏√úu\√¶!¬•%¬∑√≥E¬§<iu≈æÀÜ\¬§`dÔøΩhbg$‚Äò2*^√â(p√êj‚Ä†‚Ä¶‚Ä∞s=!√≥¬Ω!√£m√±ÔøΩ¬µ¬•√ê¬¥√®'a√ço?√õ¬±√ò¬≤√ê:¬•ÀÜ√´¬©(z√êsw4¬•,0√ï√í√ó‚Äù‚Äö|≈∏<√ô√äh¬πm√àdfiu‚ÄìÀú‚Äù%$e*j1‚Ç¨¬£‚Ä°e≈Ω] √¨√¢¬¨√Ü‚Äô¬¥‚Ä†√¢va*≈∏√ú√ùh√ï√É¬∂ÔøΩt√õu¬•√ák)‚Ä¢‚Äùjl√Ö'‚ÄûsÔøΩ≈æw√ó‚Ä∫u√ï‚Ñ¢‚Ä¢&zdf√∏dfl≈†√Æ2s√í√µ="" u6a^√∫√õ√∏√ö≈ìv¬≥:er="">√ñ√≠u¬§√á√´H‚Ä°√ß√°N√∑C√ù√û¬ße√ÇVEG'‚Ç¨‚Ä¢
‚Ä¶J¬•√∫‚Ä¢¬¨¬∫≈∏{√ä¬™¬ø8√™M¬™¬æ√î√©N+√à(¬´M1¬∞6_s√¢√Ñ‚Ä∞√¶√¶f=¬´√ÆfU¬°p√¶√¨√ô¬ªw√Ø¬æ‚ÄöU/am¬ØF≈æ¬π≈í4‚Ä¢_‚Ä∞2ÔøΩ√∏≈∏√±¬∞‚Ä¶¬≥√©u√Ç¬ß=ck¬ÆFx&nbsp;K√π¬øb¬¨¬≥√êU√Ö¬∂√®m¬≤T0mI¬©‚Äò‚Äù≈íHdlMt[M`_¬≥¬ß√õX≈ì√Ñ-√É5RZ√ä√í‚Ä†√∏¬±¬Ω‚Äò+≈°√®√ô¬Æ‚Äû√é¬∫√¨6j¬°‚ÄöV¬§√¶√•¬ØOd^Y√à√ûÀú√å‚Ä∫V√†√ò√Ñ^%≈ìGÔøΩz&nbsp;‚Ä∞¬™√ßd¬¥‚Ä¢^√örcAÔøΩ¬ªW{X7YÔøΩ¬Ø√ó?¬æ√öpy¬¥q¬µ¬´q¬Ω≈∏}kÔøΩ√Ω√°ÔøΩ√Ü'√ó?|¬ø√±√∫4{¬≠‚Ä°¬≥¬¶b¬Ø√µ6^√®n\√≠¬Æ¬ø4√ézt‚Ä¶√±√∞√≠√¶y√ö¬¢¬¢v[¬Ø√∑E√î	!e¬¨‚Ä¢¬¨i&amp;MJ[√ì9‚Äî√ß2V‚Ä°3‚Ä†5%];&amp;√Ä¬≤√™1)wDs¬∂;h¬∂√ã¬ø¬∑)&lt;#v15Vb√¶√á√í¬≤¬∞b¬™Wo‚ÄúMo‚Äú‚Ä¢Àú√¢X‚Ñ¢\≈°R≈°&nbsp;[¬¨[¬Æ√ø¬¢/%;¬πÀú;‚Ñ¢F9‚Ä∫√å‚Ä†≈ìQ√ì&lt;√ò√Å'O√Ö¬øYV}ÔøΩi5{‚Ä∫U√ë¬£√∫R¬≥√Æ‚Äî‚Äì√í≈æSm√¨¬§gU√Ω√∫¬Ω¬Ø_`√ï¬•¬•[¬∑n√≠√É¬™ÔøΩ=M√å√∑√É√é&nbsp;z{#√Üp+√≤√ì√õ√Ä√ã√éX'
B√µVg√¥|√®√∂√ò&nbsp;¬∑√π&nbsp;¬∑√æ√∏x_N‚Ñ¢S/√áB√Ö¬±‚ÄôT;U√†b¬®‚Ñ¢Po√≥¬¢¬ª√Ω:√´∆í8√∏x√∂s¬ΩM‚Äú√Ü,√∂G¬ÆGO√à‚Äú:Àú92*¬¥¬¢aP9&nbsp;¬∑k√£√πc√¢¬≤!√î√õ¬±√ßzK‚Ä∫S√ê/√ê√éu"e-J√¶√∫√´√°%Do¬Ø4l¬≤ÔøΩ√û‚ÄöÔøΩwW√ò@i≈∏\o√º√†J√£√ï	√∂‚Ä¶N√éZ/{M√Ñ¬∂q¬µ¬ß√æ√ö√≥√ëe√∫√ΩMhApV@R√™¬¥¬∏√ï[&nbsp;√≠√É-‚Ä¢3≈†¬≤+Y‚Äî√é¬¶¬Ø¬®3¬∏ &nbsp;*√ë≈°¬Æ¬∑Q¬°√ûN*"√¶¬∫¬°√°dG}tS)¬ºÔøΩ√ÄaÀÜÔøΩGuf¬º¬¢√ñ¬•ÔøΩk√ù√ã¬±l¬©p%&amp;¬±
F√µ¬∂p¬ß=j√õX{‚Ñ¢√Øg¬ØÔøΩ‚Äò√Ä¬´
√¥6√ê√â4√ì√çh.√§√ÑJ√®I√∞√ï√õr√æd√ï7√í¬¨¬∫kZ√çK√´√ç¬¥¬¨jiiill|√∫√¥i=¬´√™√ód√Ω√´¬¨√ö√ñ√ñ[‚Äù4√™uT√£wT√£¬´√ä√∑ÀÜ¬ø√ôG√£¬£nf√á&lt;,NxYÔøΩ√î&amp;X∆íÔøΩU¬∂≈†t¬≥ÀÜp¬µ*√ÇZ‚Ä∞¬©¬¶√•√âfo¬ßF¬ºi√áRQcFHvL√µ√å≈í√∞√ä≈Ω√≤"¬ß;w√ï[P3ÔøΩ
c√±√±√Å√•IA√â!√Ñ‚Äù0bJ$=;PQc√û√Å2√Øn¬¥h¬≠tc√¶G√ó√¶%¬∞
‚Ç¨¬æI√©~√ÉB[ÔøΩ√ê^√ÖqS1¬º≈†4&gt;1¬≠ÔøΩ√ó√ü√¨?!w√´k√Ö√§&lt;)5¬´¬ø%|\√¶5!√∑R¬∑‚Ä†‚Äôm¬£√à¬™√≥e√ï√ä≈°ÔøΩ lR√°
√∂Àú√î_√Ö√ÜJ)%‚Äô¬™‚Äôvf√ä¬∞√à\√¶&gt;,√∂√™nÀÜWAÔøΩB8√çT¬¶¬∑√ì√∏0≈°√Ç-Kk!$(j¬ºy√ñ√†]¬¶¬µ√í‚ÄπU¬¢¬±K√Ω¬§4√õ√ÆsEÔøΩMm¬æ_e
‚Ä†‚Äù
≈æK(\‚ÄìTT≈í
 g¬∏√ã√®¬¶L√ìv¬¶)1√ï&gt;#√ú-9√ò=%√òe√á≈æ(√∞√ém!√¢&amp;
@#√Ñ√ô¬º¬∞‚Ç¨Rm√è√∏X≈∏√≤¬∞&lt;√©d~¬¢√ú√±ÀÜ√Ç√£ÔøΩ√í√£ÔøΩ√å√ΩÔøΩ√Ç√≠&nbsp;√ú√´¬§B√î¬™√¨√¨z∆í¬¨√∫√è≈Ωk|ÔøΩX¬∑Y√ï√ã√ãK√è¬™/¬¨_b√ï{√ª¬≥j¬ªÀú¬øk¬≥~z=√≤√¥¬•√à3‚Äò¬ß‚Ä¶¬æ¬ß√ùm≈í¬∂ÔøΩ√§&gt;¬∏≈°¬≥¬´nY‚Äòn¬πQ¬πQ&gt; 0¬®√âw¬ø√Ä√†√êIi‚Äì√â√§¬¥pRj#/LV√£√ïQ√Ø~√â‚Ñ¢√π	√µE‚Ä∞l|RCaZg}√åtG√à√í@√àLgTwc≈†ÀúW^'+√∑√ú n}wq<ur‚Äì√ü[_>√à)Ws+4-0ÀÜi¬©≈°‚Äò‚Äò.j*√é√∑‚Äô¬ß‚Äût√≥,(i¬∑‚Äì+√Ø¬Æ‚Äú√Æ^$_¬®YT¬≤‚Äì‚Äù¬¨¬µ¬°√ö√õ¬´√î√ª‚Ä∫‚Äù√ª‚Äù√∑¬´¬°√µ‚Ñ¢‚Äôu¬ÆÔøΩ¬π¬®¬ª√¶√¢√µ√∂√Ç¬≠√ï¬≤√ã¬≥√•¬≥R2M
)√£¬≠U jiÔøΩ√ù√•∆íl√Ç¬∑lE‚Äú¬∫6‚Äòp^ÔøΩ¬®n√çV√í‚Äπ√ê√©	m√ï√ôbr¬∂ÔøΩ‚Äù9,ÔøΩ√©√∞√∫&nbsp;d‚Ä†#‚Äìn	¬®√Ç≈†}JF≈ì‚Ç¨√¨√û√ï
√ê$√ª
2_5~g√û√ü√é√Ä≈°t√≠¬º¬øM‚Ç¨¬≥n√ì@'‚ÄúH'√£‚Ä∞&nbsp;√£ j≈°;√®√∏≈í√ø√±¬°B‚ÄûU√õ√ü¬´¬æ~¬≥¬™√ÆQ√ï¬≠√êmV√ïÔøΩÔøΩt√ç¬∫uc'‚ÄùUA√¨¬§gU√Ω√∫¬Ω¬ØW¬±¬™LX√µ√é¬≠[¬≥/e√ï√∂√é.√≥r√à√©ÔøΩÀÜ√ìk‚Äò¬ß¬ØDÔøΩ¬πq≈°√°y√Ü√ì√®¬≠√±Nd0
√Ö√ï√ªÔøΩ)¬´¬Æ@o¬≥¬°√ûz√¶F√π√á√π¬∞√±≈Ω@d@√îJ¬≤/KÀÜ¬¶d‚Äû‚ÄòR¬£‚Ñ¢‚Ä¶!ÔøΩ
√ÆRz √ê[√≥@¬Ω√Ö√ï¬§√∑5G√év≈∏‚Ñ¢ÔøΩc:√´√í$dÀú¬≤√¨i√à¬π0≈°‚Äî√ÜRGEE¬Ω
√•∆íM√•√™fToI#√çUg‚Ä¢‚Ä¢√´c‚Äû‚Ä¶√ä¬¥ÀÜ&gt;+¬°/¬´¬™o¬≠@¬Ω¬Ωs¬±j¬π¬ª√™¬≠¬¢nk¬¨√¶√é¬®¬∑w√ó¬®√ó√éV/√ä√´√†√Ä¬æv√¶‚Äö≈ì¬π¬®¬¨√ô¬©¬∫}¬°√º√¶r√ô√ñ$a¬≤‚Ä¢&gt;%F¬Ø¬´F√Å√∑o¬©Ts‚Ä∞∆í√Çp+~m¬∑6n0¬±¬Ø)OI/T√íQ√É√âl√î√õ≈í	Y√ê√õ1¬©‚Äî‚Äù√ùP‚ÄûC3¬™TÔøΩ√ûV¬•√áIi≈Ω√ùÔøΩ‚Äì]
√¶M√•.√®‚Äû^√¨¬¶√ìeÔøΩ&amp;U√ë¬™¬≥G‚Äú4W√É√âm¬Ω=√¥v√ñ√Øx√©√ç¬≥√™√´4¬´√™√∂F√Ω¬≥√É¬¥∆í√º√¥¬¨¬™_√Ä√µkX¬µ¬ª0q√Ä√≥H¬ø√è‚Äò&gt;√ü#√É√æG;&lt;{¬≤58√§l|√ò√ï√¥¬®¬ª√π1O‚Äπ√ûV¬ß|Qbu@K‚ÄöMB≈ì√ç¬±¬Ωl‚Äπ≈æF+√ï‚Ç¨j_‚Äú-√ó2-√î1)√ê5=√å¬•"√Ö¬©‚Äúe3√òb√ô√ì`√ã%√ò‚Äì&amp;√Ç*√Ñl@yR¬´√ê¬Ω‚Äúe√ó√õ¬æ√ñB¬ø∆í5ÔøΩ√®√â√à
¬ße√á2rbY‚Ä¶Qb¬™Ko‚Äú√•√ó¬∫‚Ä°√£√òU√Ø√í√ù√®√í√áu√§√ô√µ7;Ji!≈ì√¢<iux√ók-p√íÀÜ√¨‚Ä°√Å‚Äö¬ø√µ√®¬Æh%fh¬≠√Ñ√úv¬®z√†<"‚Ä†‚Äì¬ßjÔøΩ[g]‚Ç¨¬≤&xÔøΩ√Ø¬Æ8 ¬≥¬π√≠yn‚Ç¨‚Ä¶√•t@¬¶√ú2\s≈Ωs≈°√Ñf:,√™‚Äπax√æ)¬©¬∂√´io4√ñ="" ‚Ä†¬Ω≈ì√Æ√ò√Å¬≤√≠i¬∞ÔøΩ√ë¬≠√´≈†√ù="" ¬∏p‚Ñ¢s‚Äòky√Äs¬£f¬πi¬®¬∂√ù√µ¬∂}l‚Äπ^≈Ωe‚ÄúewÔøΩu[¬µ="" !√û¬ªb√Ωt¬ªs‚Äò¬´bws√∞2‚Äö3√ê√û√ê√è√∂≈í¬Ø√µi√∞"∆í‚Äî√ö√ï√¨Àú¬Ω√â¬±b¬ªcb¬∑∆ír¬∑∆íb√ób√ßb√∑="" ¬±√∞ÔøΩ¬∞√™¬´y¬∑y√µ√µ¬ß√ï√¨="" ‚Ç¨qv≈°¬¨ÔøΩÔøΩ√µ¬¨√∫‚Äπ¬¨z√øyu19√Üz5√¨√îr√ò√∂√î√ù√Øs¬Ævv‚Ä†¬Ø√Çu√ÑÔøΩ≈°e‚Äπop√é≈†√∞√äÔøΩ√∂¬¶√ß:u7ÀúÔøΩÀúÔøΩo¬≤(m'¬¶‚Äû‚Äô¬¢jd5n‚Äôj="" jf|m="">√µ@c√•'Kh√ë#b√ø¬πn√ü)eÔøΩ≈†√ã'√§J)Y‚Äô¬™√ú)%√∂¬º:fe8vB‚Äì√ñ]W√úS‚Ä°√Øk√Ñ√∑¬≥√ã¬¥4'$¬•√ã∆ís¬•√É√çU √†‚Ñ¢‚ÄìÔøΩ/≈∏-¬º¬æTpm¬°h¬±‚Äπ&lt;#¬°M‚Äπ√©s
√™√∫(√°√Ür√ë√µ√Ö‚Äô√´K√ÖK]U3:√≤W√ï√ìb√™R√°√™B√é‚Ä¢¬π√¨¬µ√ë√ú¬±V√íp√òDu3q¬®‚Ä∞¬∞√ù]^ÔøΩ√Øf‚Ä¢√év&amp;≈æ≈†Z√¨ÔøΩ√§%ÀÜF
√êD√§~E‚Äì‚Ç¨≈í√∏M√à]√Å‚ÄòQ√ÉÀú√π8≈ìJ√§%‚Ä†‚ÄìEN√É√∞*\:X√†h‚Ä∫√±+√≠K‚Äú‚Äπ√¢√Ä√∂√ùUÔøΩW∆í*x¬©C≈ìL√º≈í√É≈í‚Ä†≈ΩM86√™l√ú√ßXV¬Æ√∏MX√µÔøΩ&gt;^√ù¬¨√∫
¬£4v√í¬≥¬™~√Ω‚Ä∫¬≠W¬≥√™√¢+Y¬µ¬ª‚Ä∞¬πt√ï√õ√µÀÜ√ì√ß√ÇNQ√ùO¬ª[√Ä‚Äì¬®√≠√ª(w√ù√¨√™¬Æ‚Ä†¬∫√î√§√õ√Ñ¬∫f‚Ä†{√ßc¬ºJ√¨ÔøΩ√û¬©i*¬∑-≈Ω‚Äπ"¬•‚Äî'F7‚Äù√∏(Y≈Ω<r@ul;√ñ!z√ã√åo‚Äò√óf≈í√ã√º√¶z|√áe√ÅÔøΩ√µ ‚Äö≈†)%¬ª¬≠:g¬Æ¬≥¬¨‚Ä∞y≈Ω‚Ä¶ÔøΩk¬ª√µ¬∂rj‚Ä†_√ï√§o¬∑fz¬†√û√é)‚Ä∞w√¶¬∂√µvnk‚Ä¶√É.vr¬∂&√ã√û?√µ√∂√™|√â¬º‚Äö:#‚Ä†√µ¬Ωs¬¢√™="" ue¬†="" √®√≠√•¬≥√ô¬´√™m="" ¬∞√™m√Ö¬∂√û6‚Äì¬™√™√±¬ΩÔøΩ√Ö¬Ωq√ã√™√à‚Ä¶¬æ'√®¬≠√ï[r&¬ø"sx‚Ä¢4*√µ≈°ÔøΩ¬ª√¥¬∑¬∏√≥*¬£‚Ñ¢√πiÀÜ√ûb√®9¬∞c≈†‚Äù≈†q√¨:√´`c¬ª√å‚Äûleq@o√∑≈Ω‚Ä∫‚Ä°z√´o¬øk:¬™¬∑~√Ü)√é#ÀÜ√û≈Ω√Æ√®¬≠≈†‚Äù‚Ä°√¥¬ø1v√ï-ÔøΩ√ñmv}ÔøΩ‚Ä†‚Äπ¬Ω√ç¬™h√É√Ö¬Æfu4.¬¨="" 4v√è¬™√∫√µg[√èy√µo√ª√©√´¬Ø√ø)v√≠(h√¨v;√î√•}¬∏√ã√´√∞‚Ç¨√Ø‚Ñ¢√á!√∑3√Øy≈æz√è√é√†¬†¬£√°!'√£#.ÔøΩxÔøΩ#√Ñ√∫<√á`o≈ìhr_d,¬≠6‚Ä¢√êldsr‚Ä†yjÔøΩ="" √ñ√á="">√Å√è√§Xg√á)3√ß‚ÄùY¬¥TX√ñ√¶[`√ús¬£¬º√≥c|≈†√¢¬º¬©Y√é√ºJ¬´‚Äì
√´‚Äì
‚Ä∫¬¢M+√â¬¶¬Æ√à¬≠*=%"E√Ç≈í√ú0N‚Ñ¢¬ßÀúj'¬Ø¬±T√ñ≈°+j,√õh√∂¬≤'¬∑&lt;F√ë¬©-AmtW√ÉE√Üp‚Ä¢3√ú5¬Æ≈†ZW)√ï‚Ä∫∆íO√•‚Äì&amp;q√∞i<bl√ù|rq√æ√ñml√±v√π√ãk\dt‚Äî6√ò√ém4')√ç¬©‚Ä¢√§]wÀútwÀÜeb‚Ñ¢√à5 ¬¥≈°√âÔøΩ¬°√ß`h√ô√ê√î‚Äî[√îff7‚Äî3√å%√ï‚Äì√çz≈Ωwyr`i|pi¬º1√ñ¬Ø0‚Ä†¬∏9q="">‚Ç¨√ç√ôxn¬π%√∏√òXb6¬ß√î‚Äö]bVg‚Ä¶√µ¬±√Öxm¬∑¬¶√Æ¬¢T[X√¥^XO√ã√†Ev5=√™h|√ò√Ü√∞p¬æ√µ¬æ√≥{¬≠√éZ≈ì√ü√£9¬æ√ás=¬Æ√û,¬´√™vd√®v√Ä√≠√ß¬∞wZ
¬øTÔøΩQc¬•]1¬∞≈æU_√Ç¬™√ì√ç/¬≥¬™ÀÜ¬øi¬µ√á√Å¬©¬ª‚Äπ¬°'9≈æ'≈ì,N√ª√ö≈ì	¬∞G=√ê`1p√Ñ≈Ω≈†¬´	√æ≈ΩIN√ç‚Äπ√ä4¬ª√¥P√∑¬¨Z¬ÆCr√è√üÀÜ¬∑*≈†∆íM≈°¬•√±uE≈æ≈°5‚Äî√†IJ√Ö√í‚Äò≈Ω*@¬¨5¬π‚Ä∞√ç‚Äû√®^¬Æ√è¬§√úm¬¨√çS√ï√ä-√çT¬¶√±√äs√∫≈°√£f¬ªBB&amp;d¬±√ù√µY
@√ú√Ö,‚Äö¬£¬µe~√æ\W√ö‚Äû4¬ø¬Ø√êe√Ö0¬ø√º√¢X√ö√ÜT√ä√∫d√ö¬¥¬¨√¶xd@&nbsp;g√õ√±‚Ä∫√ìi√´‚Äú√©[¬≥¬©‚Äπ¬™√º1A√•≈∏4√å¬´{FQ¬∏6‚Äò¬∏6≈æpn y¬∞	√Ä)√ò¬•}H√à‚Äû6Àúw2√•√ï%√™√ñ√∏√ô√Æ√†¬≥=√æ-1
4gÔøΩ`iDSI¬¶ÀÜ5√Äs√ôw√î¬ªs√ä"9	5y1¬¥√¨h¬¥h≈∏Àú√ïLpjg≈°!¬¨jW
0√û/	≈ì√†-√ì√Æ≈íj(√íW√Ækgbg√ê√Øwt√Ñ√Ø√®√ò&gt;G√ï^GT√πqo‚ÄìU_g¬∞√î¬´c¬ß√ó,¬µ√∑≈æ√ü√ñ√ñV√è¬™√∫√µ¬ª^√ª¬∞√™‚Ä¶√°¬æ√û_`U√∞F√ã¬©=√Øb1√™√≠J√ò¬©¬πÔøΩ‚Äú$√ó‚Äú.‚Äì¬ß}aK‚Äù√ÄU¬§√òl√ó√µ √ê[‚Ç¨¬´√íj¬≥‚Äô‚Ä°¬¥√è≈ì(√∑√∫bx√ù¬≠dZ0√≠
b√Ç	¬∏&lt;6≈†S√Æ"¬•Y7‚Äù√∏‚Äú√ì√¢√®9Q5ÀÜ√û2r‚Äúx‚Ä¢C¬≠≈æ‚Äú
7√Ä}u‚Äò√çebzkE√∂ÔøΩ f^√¥vD√ü√â√åU√íÔøΩ‚Äûz[S&gt;"√å[P¬•≈Ω¬¥√∑7‚Ä∫*&amp;$√∏¬µ√±T¬®¬∑i√£√Ç≈†¬Ω¬≠\√¨.z¬ª1‚Ä¢&gt;√éw≈Ω√∞¬™F√π‚Ä¢√É-¬§&gt;q¬Æ+√®√≠√Ö√ë√ÑUZ_}%&nbsp;` ¬∂Z¬∑I√Ñ@¬©H√â(c√¶TÔøΩg¬ª√ΩTl¬¨¬∏*S@√ä‚Äûo‚Äû4ni≈°¬§:\#tz+¬Ø√µl(‚Ä∞a√§√Ñ∆í 
5≈ì¬¨JÔøΩ¬®H≈Ω‚Äôm:X¬´‚Äì:ÔøΩ¬®¬©√£‚Äî=v'wgTa¬∞¬¥m8√©¬≤m8√©cgÀú√§xz√ê√Ø√®¬®√ø√ëTo=ÔøΩtU¬æIV√ï-~ÔøΩ√°{¬ß∆í√©√ñ‚Ä∫¬°z¬´√õp¬±kÔøΩ`U###=¬´√™√óg√≠√è¬™√êxeU¬µZ‚ÄîU√•;¬¨¬™√àKP¬∫Tx‚Äù{√™√∂&gt;,r;√®|√≤m√ìco[ÔøΩ|√á√¶4 √ñÔøΩX¬ªÀú&nbsp;U√Å√áaU¬∞√µ)‚Ä∫3ÔøΩ‚Ä†o√É‚Äù√£≈í√ì‚ÄùS≈í¬ßy¬§P√®√ßc‚Ä∫`‚Äîf‚Ä∫n≈∏e≈∏√©ÔøΩ√™≈°}√ù=‚Ç¨:√•√á¬∏‚Äî$¬∏‚Ä¢$¬∏‚Äî&amp;z‚Äù%y‚Äô√Ω√π‚Äì%‚Äì%pA√Ñ√§ÔøΩ≈†√§√∞√ä√î√ê√™l√ø≈°|_f¬°¬≥√Ä¬Ø&amp;/ÀÜ‚ÄìQÔøΩ‚Ä∞¬°e√Ö√ísQF1√ÇX√°¬¨‚ÄöÀÜ¬∫B¬∏√´‚Äπ√Ç√´‚Äπ"‚Ñ¢√π¬∞√≤‚ÄûYx6¬Æ¬æ(¬™¬°8|¬≤¬æ&lt; ≈°USW√â*G¬æ0≈íYZ‚Ä∫≈Ω`)bÔøΩ¬ÆFiE√ªO‚Äò√ö√àpbrDej05√ì‚Ä°‚Äì√£I√ã√±¬®√ä√∞,√á√π@√∑√åsw√ü√ü$√∑√å‚Äî≈ì(√∞L3√É√≠√ÅO¬µM
¬±I
¬±≈†√∑‚Ä¶¬ØI$R√ä‚Äö
/tJ=∆íP*√å¬•¬∫‚Ä∫‚Äù√™lr√Ñ√ë√®ÔøΩÔøΩ√ÅA√ãS¬≤-√ûmr|‚Äî√´√¥.√õ√°]¬∂√Ω;¬ßc√≤7√á¬™¬ª`TÔøΩu`√ù¬™√ÇWÔøΩk√úoZÔøΩ‚ÄìU√ëX‚Ä∫¬Ø√ë¬≥√™V]≈∏√ñ¬®_√ç¬™2‚ÄûUg√Ç-fÔøΩOÔøΩÔøΩ√ìL√ê‚Ä∞:√∑√£f¬∞D√üw¬¥X¬ª8oG√ë‚Äö‚Äùf∆ípMqc√§√ô¬™√ò√¶ÔøΩu‚Äù,√ª¬ºhh√ÉX√öP√¢*¬§X√ï√§{‚Äôb(a√† √ê¬≤√Å√ß(FQ√´K‚ÄûN=N	≈Ω[≈°√í‚ÄûOS‚Ä†EÔøΩ3ÔøΩ√û√≤√ÄN¬ºÀú≈ì√üF√ç‚Äú√ì√≤≈í|√ü√ü≈ì6)ÔøΩU√≥3:k√ä`
‚Ç¨]¬º√îÔøΩY√ñD≈∏√ÇhZ√∫Q√∂$¬®y%‚Äπ¬Ω‚Ä∞0_&nbsp;‚Ä∞Y√¨√Éj√∏E√†√≥√†oAÀú4*√ä:7~n |¬∂3¬¶¬ª¬Æ¬§‚Äπ	M‚Äú:k√õ√°¬§chÔøΩ$¬ß√ß≈†√âJ&amp;nD√¢B¬ª√æ	%ÔøΩ[≈°√ï\≈æ√íT≈°\_ÔøΩ√ûF√∑√©k¬∂√´√£Z√à√ûÔøΩR¬≥b¬µ¬≠√•‚Ä¢¬©a¬•‚Ä∞M√•≈Ω(¬´√≤*l‚Äò¬ª&amp;√ü√ú¬¥√ß=¬™h√†√§¬≥c‚Ç¨‚Ä†V√¨;∆í√≥√´og√®ms&amp;√à√¶t¬∑74@SyQy√Æ√µ8√ú‚Ñ¢'¬´¬Ω√É√†√ø√±√ó¬∞√™~√çS¬øX¬´√ø√í√¶¬©W√ó√™√Ø¬Ω√ß√ó¬≥¬™~√Ω√û√ó¬æ¬¨√ö√ª√ã¬¨√ö√â¬©ÔøΩ√∑9&gt;t|*√®√ÑB√à√â√â&nbsp;√ß√£≈Ω√¶'¬ΩÔøΩ¬≥X`f√¨d√∂\oa√ò√´c√Ø√´(¬ß‚Ä∫‚Äî√Ñ√õ&amp;√∏¬πgE¬∏4√¢m‚Ç¨√û√ä√®‚Äì¬§t¬ß√ú¬®`|¬º_alxK‚Ä¶C+√â≈°‚Äì√≠WÔøΩ‚Äπ¬¶d‚Äû#zM√ã√Ü¬≤
¬£¬ª√ù√îB¬®¬∑√≠¬¨@&gt;√®-¬∑4]J√á≈Ω√ã|g¬∫¬º√á√ö‚Äö:√´p√¢¬™&lt;&nbsp;¬∑
¬®¬∑m‚ÄùR57¬≠√Ñ√¥7√•v√ï‚Äìv√ó√°‚Ä°Z√≤‚Äî¬∂√µvÔøΩ[√âÔøΩF‚Äû‚Äπ√Ω√±Po√ïÀú‚Ä¶√û√∏√Å¬¶R&nbsp;¬∑¬Ω
@≈†√±m¬©@o√ª#¬¶√òv¬°‚ÄπY‚Äû√®mÔøΩVoe¬¥\IU^G]√Ç¬∏√ú√®¬≠≈†$$√°¬∏e√ú√≤&gt;¬•¬±8YQ√´&gt;√Ä¬≥√©√•Z¬∑T√Ä¬±YÀú√™,J‚Äò√ì√Ç*S√Ç√∞	‚Äò¬≠$√à¬™]uf
%≈Ω√®√ù&gt;4¬Ø√ì5√æ}a√ñ√ºv√©¬Ø≈Ω√ûx√ô≈ì‚Ä∞¬∑?√ï∆í√®m¬™¬∑√Æ‚Ä°;ÀÜ¬πr‚Ä¶R¬Æ√¨P√ºjV√ùo8¬™¬∑¬∫≈Ω√´√ª
G√ò¬´¬∑¬∫≈Ω√´¬∫z¬´:ÔøΩ¬≤√™¬©S¬ß√Ä√£√µ¬¨¬™_‚Äû¬•√ã¬™?¬æ√à¬™√Ω√Ω√Ω[[[‚Äî/]√í¬ºÀúW‚Ä¢√âd
‚ÄûU¬•¬π√±¬ßb¬∑∆í`+&lt;¬µ¬∏¬∞?√∂g¬£√Éo‚Ñ¢√ª¬≥√Ö√±¬øX≈æ|√á√∫√î{vg8t2:x√ä√ï√¥Àú¬ª√πq√ã‚Äú¬ß√ù√ç√èxXz[√ª√òÀú√ö‚Ä∫‚ÄöP9√ú√ïI√ÆXF{XG¬π√õE{8`¬º√¢|Q{√í√§`g M¬©√Ån)√Å≈æ√©¬°^a√ûY√°¬æ√ô‚Äò¬æ¬π√ë¬æ√π√ü√ÇX√ü¬¢8¬ø¬¨?&gt;&gt;√© ∆ínE¬•‚Ä∞√°√•‚Ä∞√°‚Äû¬§`√ÉHi√ê¬£‚Ä∞‚ÄùIJÔøΩ&amp;¬•√ÜÔøΩ√íb√à`¬ßc¬™√í1‚ÄùXpDl&nbsp;√ø‚ÄùLx√áVe√ÑR2√†_ÔøΩ]‚Ä¶&lt;≈í≈í~IZ4√≤"IKC+SB‚Ä∞)¬°√â!\p9.¬®,	√∏√Ä'c∆í
0A√π1ÔøΩy√ë¬πQ√æ9Q~9Q√û9Q ¬¨EmB¬°iR¬∞3√¢\√ß‚Äû√µq≈†√µv≈í√±t≈í√∂¬∞‚Äπt¬≥ÔøΩp¬µ	u¬∂sÔøΩN,√õ‚Ä∞T√Ñ=√â√è√¶4‚Ç¨}@‚Ç¨R√æ¬ªÀúu2&gt;√¨`t√à√û√†&nbsp;√≠√©√∑¬¨N¬Ωkz√¨ÔøΩT¬≥¬∑√´√¨√üi¬∞‚Ä°i√∑√ã√¶m‚Äì√ÉQ¬π√®√ç¬∞√™¬Æ√∏u:√†^=¬Æq?AF^kc`‚ÄùUÔøΩ?√é√•r√µ¬¨√∫√è¬≤¬™B√Ñ¬µ√∑?6pl):¬≠q=jkO¬¢‚Äî√•	√∞√´√§¬´√£ÔøΩ¬∂√£¬∂dÔøΩ¬º√©√õ¬µTXP2-√º≈ì√íBa√™¬øÔøΩc√ëF¬∑(√Ä¬∏fG√∫‚Ç¨sW‚Ç¨√±√ß‚Äù:¬µ‚Äôl+√ì¬ºK¬∞√°√Ñ‚Äù`p√ä√à√©√°√§tG√Ö¬¥‚Äô<z√òv}√ç√ñ] √éÔøΩ%√ë¬¨‚Äö√§√Ü√¢d≈ì(‚Ñ¢aj¬°√´x‚Ä∫√†d15¬©‚Ä¢Àú#"e‚Äπ√à9j√∂="" bt√î√ìÀÜk¬£√âi√π√≠¬µ¬π√ì√≠√Åg¬ªf¬ª‚Äöz‚Ä∫2√ök≈†;k‚Äπ;jk¬∫xe≈°√ñ√Ñyu√Ä√ô¬Æ√†9u¬†≈°‚Ä°cf√µ‚Ä¢v√î="" 4'√èv√∫√ét√∫≈Ωjc√§√¥|¬§="" }√á√Ω≈í‚Äô%&g≈†hb¬ø"¬£¬´!`h√†√ò√ü√¢(¬•ÔøΩ≈∏¬™¬æ(¬π¬Æ0¬©¬°¬£d√ö¬©√ò2‚Ä†m]q="" ¬¢="" ¬∞3¬∑2√∞¬≤√ÑÔøΩ¬¢¬∏pv¬©∆í¬≤√Ün√ç5¬•‚Ä°yi)u√áÔøΩ√çvk‚Ç¨{¬¶ÔøΩ√Äi√áÔøΩ√≠≈í¬ß√ï)¬´‚Äú="" √è√É="≈æ‚Ä°√õ√Å√∂8√î√°vH‚Ñ¢ÔøΩ¬∫;√û¬´√™ÔøΩ√´}√¨7√©oo¬∞¬Æ√ë√á√û√¶)√îX√∑≈æ¬∞*ÀÜÔøΩlll√¥¬¨¬™_¬ø√´√µkX¬µ∆íS;√•ul<ÔøΩ√™√≠T√ê√±√°‚Ç¨cx√á¬£v&amp;√á√ù-Nx√©zN:‚Ä°√™¬∏-√Öx¬π¬∞‚Äú1√å√ãq‚Äì¬±^¬Æ¬π√ë√∂¬ºJ√ò√•√îJ¬≤√äÔøΩq√ã≈Ω√∞√çC√¥V@¬∂k*¬∑¬ØH√∂√É√á‚Äù!¬•‚Ä†√Å√´√±t¬¢Hi√é*√î[E¬≠√ê¬±¬∫B¬¢¬∑)]ÔøΩ¬æ√Éb‚Äî1¬©K'DDI√ë√™¬≠‚Äù‚Äô=," ‚Äòu¬∞√íe√îb9¬≠¬†¬ª!c¬∫#√ï√õ¬Æ√∫√ú¬†¬∑√å¬¢≈Ωz|w}√æ¬®8√ï√õyu√†ÔøΩ7¬≠¬£¬∂√®mgm¬°≈°√¥v¬∫√ùo#≈íÔøΩt‚Ä¢√à¬´√≥¬†√ûrw√ú&¬µzk√åp5y‚Äù√Æ√£:‚Ä∞¬™√Ç≈†‚Äú√´√†|√πdnidw¬Ω‚Ä¢≈†c!¬≠¬∂¬≠√â¬£d@ÔøΩg(5¬¥√µ¬∂0.‚Äù_i√ì√Å‚Äûz[wl≈∏√•¬•¬´¬∑¬∏@¬ß√∫,t="" '¬µ!‚ÄúÔøΩ√çi√ãs¬±¬∂'‚Ç¨√í¬™<+¬Ω√≠t="¬§¬¨‚Ç¨¬¨¬™h√ØP√à√•¬ø≈æUu√ó_s¬≤√™.√á√µ√óiVEM√óQV577√ó¬≥¬™~√Ω¬°√ñ.V√Ωa‚Ä°UA√î√õ√ó√ó¬∑¬π¬µu√•√≤e‚ÄùU√õ√ö√ötYÀÜ¬≥(√ã¬∑ÔøΩ√Ø√≤√è√•‚Ç¨√Ñ√≠" √õ√©="¬ª¬£o√∫‚Äú√â√°?‚Ñ¢y√ã√¥√®≈∏√çÔøΩ√Ω√Ö√≤√∏√õ√ñ'√ü$ef;√ç√™≈í¬§Y=-≈Ω{[¬°√í}√ö√ü√Æ√å√é}#√™?`√©n‚Ä†√å√õ5v√™d√¨√¨qÔøΩ)!≈Ω)!N√©¬°√é√©a√é√°p¬æÔøΩ√Ä≈ìH√è√ú(¬Ø¬ºh√Ø|8h√É¬ª0√ñ¬ª(√é¬ß8√é¬∑√´[√Ø√†¬±√¨√Ñ√Ä¬≤D8¬º" l√ùa√â`w√Ä≈ì,¬∫√Å≈∏∆í‚Ä∞√àgd#√Ä√†‚Ä†_r≈æ;g√ãp&√Ö√á√ª#5¬Ω¬∞√ü¬ø(p¬≥o="">b¬•≈æ√£‚Ä¢
~*ÔøΩ√¨√∑¬¨p¬∑√åp√ó√¥0√®√®‚Äπ√Ü¬¥IH‚Ä¢ √¢
‚Ä¢6√é√õ
qH¬∂≈í√≤0√è=√Ç√ï4√å√ô$√Ñ^√ò√∏#M¬©^V¬ß√êr_H¬©&amp;G ¬•¬≤;s√Ä√¶√î{V'√ü¬µ&lt;√±¬∂√ô¬±¬ø√æs¬¢√±≈∏√©6o√ó√ò¬æM¬≥y‚Ä∫f√Ω¬∫√ùa‚Ñ¢H√ê√û√ô¬•√ºu¬¨¬∫≈∏[√ã?¬øZÔøΩ¬µ√ÜJ√ö√ç√óM√ñ¬≥√™¬ø√à¬™B¬æ:√ò\√£√ãM‚Ä°√Ω√°√áj√ß#VG^¬®v¬∞9√≠gk&nbsp;√£ÔøΩ√°j√¶l√ùB4o¬Æ0√Å'YU¬¶[+j√åTÔøΩ‚Äì√µ√Ö‚Ä∞√æ≈æ√∞¬≤√Ö¬´√ß√öJ¬∂V√ôP2√ú√Ä√Ä√áÔøΩ√É‚Ä¶G¬£f√≥*≈ì√ìu√ñ‚Ñ¢¬∑3¬≠‚Ä∫	≈æ¬¥√¨xX'≈∏‚Ä∫√Ñ√ÜG)‚Ñ¢∆í&lt;√õ≈æ}W∆í‚Ä°ÔøΩ√ìZ‚Ñ¢(¬¢`¬ª√ºG%.C9#NP‚Äò+¬°¬§¬∂¬≥√¢F$cmncR;F√ÅHm¬£fK)yRj¬Æ¬≤6
|r¬º√çcB√¶¬Æ√∏w¬∞‚Äô¬§√î9#¬≠¬∑)lT√™:"qj√µP√îb¬•‚ÄùaeF+‚Äì¬∂√ù√è≈°√ã‚Äú¬πeIÔøΩ√Ö√©¬º≈†√àv√¨mog√ô√≤*¬Ω√´
¬£√´‚Äπ√ÇD‚Ä∫√é:‚Äπ‚Äì¬ª√î¬£*=≈íÀú√õr¬°Z`1xvI¬æ‚Ä¢i^&lt;¬¢M;x^,3√ô¬≤"√Ö1'√ö59√àDM¬®√ñgW≈ìP4?h‚Ç¨v√Ñ¬´¬Æ√¶'¬º-≈Ω‚Äπ√ù*√ù¬µÔøΩ√≠v¬∞√ç√•‚Ç¨,¬£P√à‚Ä¢]¬ø¬´¬æ¬¢=¬™¬∫¬µ√∫¬∫√ìjtk√µu√í¬¥¬±‚Äú≈æU√µ√´√üo√ΩVmg√ó≈ΩxU√ªB¬•¬∏:√†w¬¥√ê√ÆÀÜÔøΩ!√î[xQo¬°S√ê¬≤√£√†ÔøΩ√®-ÔøΩkyÔøΩ9¬ª√î¬§ √é‚Ä†≈æg√ô√Å2BD√è¬µ√ÇxfF@¬Ω%¬¶:¬∑√ë¬¨Z*√¨Hi%√∞N&gt;zN¬ΩM	¬£e‚Ä∞√àvH¬Ω‚Ä°¬π≈ìa√ã)√≥¬£√ß`k√≥√£jrq≈ì¬≤ÀÜ¬Æ‚ÄîA¬æ√≠@‚Äπ};√ãGP√¥VBÔøΩUq|√ÜeN<o)' √¶h¬´s¬∫¬¢¬µz√õ√ï‚Ç¨‚Ä¢√ì√ì!u"z√õy≈∏8√ñ√¶1.√≥ÀúÔøΩ¬ª="" ¬µ*kr¬•‚Äùemrs0√ê√õa‚Ä∞√´ÔøΩ√è¬ßÔøΩ≈Ω‚Äút¬•="" ¬†√û¬¶¬Ω√•√≠√®ms¬†f¬†√Äa]="" √êf¬æ√Ü¬æ‚Ñ¢√†√¥‚ÄìÔøΩ‚Äôt[w7‚Ç¨¬ßiyw√®mjbnl)√á∆í√à¬™$="">¬∞√ßKJ√∑UY‚Äö√ß√¥‚Äì[nU‚Äì√§‚Äù‚Ä∞√™√≠v√∏‚Ä∫¬§ÔøΩt√™√≥¬∫_c]√ÉIO√ã‚Äú.√¶'¬¢¬¨≈ΩI√úJ‚Ä¢¬∫‚Äô¬Ωu&gt; ¬Ø√à2¬´|¬£¬¨√∫≈†i5¬Ø√ôp¬°√ï√õ¬Ω√ÄzV√ï¬Ø?√∏z¬´√∂√∂√µmll\¬æ|yxxx/¬´√ä√õ√ö√ôX≈Ω√≠;¬ßw√Å√¶¬ª`9¬ækwl‚Ä∫U¬∑√∑¬°?‚Ñ¢~√ã√¨(‚Äôf=√±≈Ω√µ¬©w!¬¥‚Äû√êjtÀÜ‚Äì¬µ9‚Äû[¬∑}∆íC ¬∑≈°‚Äö`‚Äû√çQ√Æ√à√ù#:√´X¬¨¬Ø√≠6¬∫√∫;‚Ç¨√§‚Äù‚Äöf]C]√ì√Ç√ú√ía√Å0√ÄC√∑l√Ñ&gt;'√ä372,≈ì¬æA¬≤l‚Ä¢√õ√ô√ò√≠ÔøΩ‚Ä¶∆í9ÔøΩ√≠_‚Äû‚Ä¶√¨‚Ä∞√º~}@a≈ì_√°√éWÔøΩ√Ø¬æ√∏n‚Äú¬¢¬Ω√ê‚Äô.;√í#+√Ç‚Ä¶</o)'></z√∏v}√≠√∂]></bl√Ω|rq√æ√∂ml√±v√π√´k\dt‚Äî6√∏√Æm4')√≠¬©‚Ä¢√§]wÀútwÀÜeb‚Ñ¢√®5></r@ul;√∂!z√´√¨o‚Äò√óf≈ì√´√º√¶z|√ße√°ÔøΩ√µ></iux√ók-p√≤ÀÜ√¨‚Ä°√°‚Äö¬ø√µ√®¬Æh%fh¬≠√§√ºv¬®z√†<"‚Ä†‚Äì¬ßjÔøΩ[g]‚Ç¨¬≤&xÔøΩ√Ø¬Æ8></ur‚Äì√ü[_></iu≈æÀÜ\¬§`dÔøΩhbg$‚Äò2*^√©(p√∞j‚Ä†‚Ä¶‚Ä∞s=!√≥¬Ω!√£m√±ÔøΩ¬µ¬•√∞¬¥√®'a√≠o?√ª¬±√∏¬≤√∞:¬•ÀÜ√´¬©(z√∞sw4¬•,0√µ√≤√ó‚Äù‚Äö|√ø<√π√™h¬πm√®dfiu‚ÄìÀú‚Äù%$e*j1‚Ç¨¬£‚Ä°e≈æ]></w¬•‚Ä°s√¢¬©√π≈°≈°mv%¬•y√§√ß√†ÔøΩ¬™¬∫¬Ωo></e¬∫=¬´ÔøΩq√¥></yr√Ø¬™;y√µgh^uzxx,v¬Ω{√ß√Æ√¢ky¬µ¬£¬´c√§¬ø‚Äúd√øÔøΩ‚Ñ¢√∑√∑0√æ√®^≈ìqg¬∞‚Äò‚Äî√£¬∂¬∑√∫t√æ√πasy‚Ç¨#x¬Øg¬Ω></s-√º√¨(¬µp√æ¬∞√™?[o¬∂¬∑y√µ√µf¬®√©:√∞[‚ÄùumllÔøΩ¬´‚Äö√´yu¬ø√æ√´_fu¬π¬¨m¬§4y9√®√§r(√ºk√°¬ß¬ß‚Äöod√∏≈æ√∂¬¥></zi√ª√∂i√ó¬≥g√™></u></a></i></u></i></u></s></b></s></i></b></b></i></s></i></b></b></s></i></i></s></i></i></i></i></i></s></b></i></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.alextsun.com/files/Prob_Stat_for_CS_Book.pdf">https://www.alextsun.com/files/Prob_Stat_for_CS_Book.pdf</a></em></p>]]>
            </description>
            <link>https://www.alextsun.com/files/Prob_Stat_for_CS_Book.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24693589</guid>
            <pubDate>Tue, 06 Oct 2020 00:17:45 GMT</pubDate>
        </item>
    </channel>
</rss>
